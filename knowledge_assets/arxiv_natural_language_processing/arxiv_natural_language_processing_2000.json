[
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17307v1",
            "title": "RoKEPG: RoBERTa and Knowledge Enhancement for Prescription Generation of\n  Traditional Chinese Medicine",
            "updated": "2023-11-29T01:59:38Z",
            "published": "2023-11-29T01:59:38Z",
            "summary": "Traditional Chinese medicine (TCM) prescription is the most critical form of\nTCM treatment, and uncovering the complex nonlinear relationship between\nsymptoms and TCM is of great significance for clinical practice and assisting\nphysicians in diagnosis and treatment. Although there have been some studies on\nTCM prescription generation, these studies consider a single factor and\ndirectly model the symptom-prescription generation problem mainly based on\nsymptom descriptions, lacking guidance from TCM knowledge. To this end, we\npropose a RoBERTa and Knowledge Enhancement model for Prescription Generation\nof Traditional Chinese Medicine (RoKEPG). RoKEPG is firstly pre-trained by our\nconstructed TCM corpus, followed by fine-tuning the pre-trained model, and the\nmodel is guided to generate TCM prescriptions by introducing four classes of\nknowledge of TCM through the attention mask matrix. Experimental results on the\npublicly available TCM prescription dataset show that RoKEPG improves the F1\nmetric by about 2% over the baseline model with the best results.",
            "author": [
                "Hua Pu",
                "Jiacong Mi",
                "Shan Lu",
                "Jieyue He"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17307v1",
                "http://arxiv.org/pdf/2311.17307v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17305v1",
            "title": "Two-Step Reinforcement Learning for Multistage Strategy Card Game",
            "updated": "2023-11-29T01:31:21Z",
            "published": "2023-11-29T01:31:21Z",
            "summary": "In the realm of artificial intelligence and card games, this study introduces\na two-step reinforcement learning (RL) strategy tailored for \"The Lord of the\nRings: The Card Game (LOTRCG),\" a complex multistage strategy card game. This\nresearch diverges from conventional RL methods by adopting a phased learning\napproach, beginning with a foundational learning stage in a simplified version\nof the game and subsequently progressing to the complete, intricate game\nenvironment. This methodology notably enhances the AI agent's adaptability and\nperformance in the face of LOTRCG's unpredictable and challenging nature. The\npaper also explores a multi-agent system, where distinct RL agents are employed\nfor various decision-making aspects of the game. This approach has demonstrated\na remarkable improvement in game outcomes, with the RL agents achieving a\nwinrate of 78.5% across a set of 10,000 random games.",
            "author": [
                "Konrad Godlewski",
                "Bartosz Sawicki"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17305v1",
                "http://arxiv.org/pdf/2311.17305v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17303v2",
            "title": "Enhancing the Performance of Neural Networks Through Causal Discovery\n  and Integration of Domain Knowledge",
            "updated": "2023-12-01T01:34:47Z",
            "published": "2023-11-29T01:25:00Z",
            "summary": "In this paper, we develop a generic methodology to encode hierarchical\ncausality structure among observed variables into a neural network in order to\nimprove its predictive performance. The proposed methodology, called\ncausality-informed neural network (CINN), leverages three coherent steps to\nsystematically map the structural causal knowledge into the layer-to-layer\ndesign of neural network while strictly preserving the orientation of every\ncausal relationship. In the first step, CINN discovers causal relationships\nfrom observational data via directed acyclic graph (DAG) learning, where causal\ndiscovery is recast as a continuous optimization problem to avoid the\ncombinatorial nature. In the second step, the discovered hierarchical causality\nstructure among observed variables is systematically encoded into neural\nnetwork through a dedicated architecture and customized loss function. By\ncategorizing variables in the causal DAG as root, intermediate, and leaf nodes,\nthe hierarchical causal DAG is translated into CINN with a one-to-one\ncorrespondence between nodes in the causal DAG and units in the CINN while\nmaintaining the relative order among these nodes. Regarding the loss function,\nboth intermediate and leaf nodes in the DAG graph are treated as target outputs\nduring CINN training so as to drive co-learning of causal relationships among\ndifferent types of nodes. As multiple loss components emerge in CINN, we\nleverage the projection of conflicting gradients to mitigate gradient\ninterference among the multiple learning tasks. Computational experiments\nacross a broad spectrum of UCI data sets demonstrate substantial advantages of\nCINN in predictive performance over other state-of-the-art methods. In\naddition, an ablation study underscores the value of integrating structural and\nquantitative causal knowledge in enhancing the neural network's predictive\nperformance incrementally.",
            "author": [
                "Xiaoge Zhang",
                "Xiao-Lin Wang",
                "Fenglei Fan",
                "Yiu-Ming Cheung",
                "Indranil Bose"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17303v2",
                "http://arxiv.org/pdf/2311.17303v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17301v1",
            "title": "Language Models: A Guide for the Perplexed",
            "updated": "2023-11-29T01:19:02Z",
            "published": "2023-11-29T01:19:02Z",
            "summary": "Given the growing importance of AI literacy, we decided to write this\ntutorial to help narrow the gap between the discourse among those who study\nlanguage models -- the core technology underlying ChatGPT and similar products\n-- and those who are intrigued and want to learn more about them. In short, we\nbelieve the perspective of researchers and educators can add some clarity to\nthe public's understanding of the technologies beyond what's currently\navailable, which tends to be either extremely technical or promotional material\ngenerated about products by their purveyors.\n  Our approach teases apart the concept of a language model from products built\non them, from the behaviors attributed to or desired from those products, and\nfrom claims about similarity to human cognition. As a starting point, we (1)\noffer a scientific viewpoint that focuses on questions amenable to study\nthrough experimentation; (2) situate language models as they are today in the\ncontext of the research that led to their development; and (3) describe the\nboundaries of what is known about the models at this writing.",
            "author": [
                "Sofia Serrano",
                "Zander Brumbaugh",
                "Noah A. Smith"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17301v1",
                "http://arxiv.org/pdf/2311.17301v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.CY",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17295v1",
            "title": "Elo Uncovered: Robustness and Best Practices in Language Model\n  Evaluation",
            "updated": "2023-11-29T00:45:23Z",
            "published": "2023-11-29T00:45:23Z",
            "summary": "In Natural Language Processing (NLP), the Elo rating system, originally\ndesigned for ranking players in dynamic games such as chess, is increasingly\nbeing used to evaluate Large Language Models (LLMs) through \"A vs B\" paired\ncomparisons. However, while popular, the system's suitability for assessing\nentities with constant skill levels, such as LLMs, remains relatively\nunexplored. We study two fundamental axioms that evaluation methods should\nadhere to: reliability and transitivity. We conduct extensive evaluation of Elo\nbehaviour, illustrating that individual Elo computations exhibit volatility and\ndelving into the impact of varying the Elo rating system's hyperparameters. We\nshow that these axioms are not always satisfied raising questions about the\nreliability of current comparative evaluations of LLMs. If the current use of\nElo scores is intended to substitute the costly head-to-head comparison of\nLLMs, it is crucial to ensure the ranking is as robust as possible. Guided by\nthe axioms, our findings offer concrete guidelines for enhancing the\nreliability of LLM evaluation methods, suggesting a need for reassessment of\nexisting comparative approaches.",
            "author": [
                "Meriem Boubdir",
                "Edward Kim",
                "Beyza Ermis",
                "Sara Hooker",
                "Marzieh Fadaee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17295v1",
                "http://arxiv.org/pdf/2311.17295v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17290v1",
            "title": "Ferroelectric domain nucleation and switching pathways in hafnium oxide",
            "updated": "2023-11-29T00:23:47Z",
            "published": "2023-11-29T00:23:47Z",
            "summary": "Nanoscale ferroelectrics that can be integrated into microelectronic\nfabrication processes are highly desirable for low-power computing and\nnon-volatile memory devices. However, scalable novel ferroelectric materials,\nsuch as hafnium oxide (HfO2), remain in a state of development, and a clear\nunderstanding of the effects of relevant compositional and processing\nparameters to control their ferroelectric properties and the actual\npolarization switching mechanisms are still under investigation. One key\nfundamental knowledge gap is the polarization switching pathway in\nferroelectric hafnia. To further our fundamental understanding of domain\nnucleation and switching, we have studied polarization switching pathways in\nHfO2-x thin films in real-time at the atomic scale using transmission electron\nmicroscopy. We employed differential phase contrast imaging that allows for the\nacquisition of both hafnium and oxygen atomic column signals and facilitates\nthe observation of relative movement of atomic columns between both\nsublattices. Our results demonstrate that the switching pathway involves a\ntransient tetragonal-like local structure, as oxygen ions shift in locations\nand remain within their parent hafnium polyhedra.",
            "author": [
                "Sebastian Calderon V",
                "Samantha T. Jaszewski",
                "Kyle P. Kelley",
                "Jon F. Ihlefeld",
                "Elizabeth Dickey"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17290v1",
                "http://arxiv.org/pdf/2311.17290v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17286v1",
            "title": "LEOD: Label-Efficient Object Detection for Event Cameras",
            "updated": "2023-11-29T00:09:45Z",
            "published": "2023-11-29T00:09:45Z",
            "summary": "Object detection with event cameras enjoys the property of low latency and\nhigh dynamic range, making it suitable for safety-critical scenarios such as\nself-driving. However, labeling event streams with high temporal resolutions\nfor supervised training is costly. We address this issue with LEOD, the first\nframework for label-efficient event-based detection. Our method unifies weakly-\nand semi-supervised object detection with a self-training mechanism. We first\nutilize a detector pre-trained on limited labels to produce pseudo ground truth\non unlabeled events, and then re-train the detector with both real and\ngenerated labels. Leveraging the temporal consistency of events, we run\nbi-directional inference and apply tracking-based post-processing to enhance\nthe quality of pseudo labels. To stabilize training, we further design a soft\nanchor assignment strategy to mitigate the noise in labels. We introduce new\nexperimental protocols to evaluate the task of label-efficient event-based\ndetection on Gen1 and 1Mpx datasets. LEOD consistently outperforms supervised\nbaselines across various labeling ratios. For example, on Gen1, it improves mAP\nby 8.6% and 7.8% for RVT-S trained with 1% and 2% labels. On 1Mpx, RVT-S with\n10% labels even surpasses its fully-supervised counterpart using 100% labels.\nLEOD maintains its effectiveness even when all labeled data are available,\nreaching new state-of-the-art results. Finally, we show that our method readily\nscales to improve larger detectors as well.",
            "author": [
                "Ziyi Wu",
                "Mathias Gehrig",
                "Qing Lyu",
                "Xudong Liu",
                "Igor Gilitschenski"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17286v1",
                "http://arxiv.org/pdf/2311.17286v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.00054v1",
            "title": "Is Inverse Reinforcement Learning Harder than Standard Reinforcement\n  Learning?",
            "updated": "2023-11-29T00:09:01Z",
            "published": "2023-11-29T00:09:01Z",
            "summary": "Inverse Reinforcement Learning (IRL) -- the problem of learning reward\nfunctions from demonstrations of an \\emph{expert policy} -- plays a critical\nrole in developing intelligent systems, such as those that understand and\nimitate human behavior. While widely used in applications, theoretical\nunderstandings of IRL admit unique challenges and remain less developed\ncompared with standard RL theory. For example, it remains open how to do IRL\nefficiently in standard \\emph{offline} settings with pre-collected data, where\nstates are obtained from a \\emph{behavior policy} (which could be the expert\npolicy itself), and actions are sampled from the expert policy.\n  This paper provides the first line of results for efficient IRL in vanilla\noffline and online settings using polynomial samples and runtime. We first\ndesign a new IRL algorithm for the offline setting, Reward Learning with\nPessimism (RLP), and show that it achieves polynomial sample complexity in\nterms of the size of the MDP, a concentrability coefficient between the\nbehavior policy and the expert policy, and the desired accuracy. Building on\nRLP, we further design an algorithm Reward Learning with Exploration (RLE),\nwhich operates in a natural online setting where the learner can both actively\nexplore the environment and query the expert policy, and obtain a stronger\nnotion of IRL guarantee from polynomial samples. We establish sample complexity\nlower bounds for both settings showing that RLP and RLE are nearly optimal.\nFinally, as an application, we show that the learned reward functions can\n\\emph{transfer} to another target MDP with suitable guarantees when the target\nMDP satisfies certain similarity assumptions with the original (source) MDP.",
            "author": [
                "Lei Zhao",
                "Mengdi Wang",
                "Yu Bai"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00054v1",
                "http://arxiv.org/pdf/2312.00054v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17285v1",
            "title": "Redshifted iron emission and absorption lines in the Chandra X-ray\n  spectrum of Centaurus A",
            "updated": "2023-11-28T23:58:57Z",
            "published": "2023-11-28T23:58:57Z",
            "summary": "Cen A hosts the closest active galactic nucleus to the Milky Way, which makes\nit an ideal target for investigating the dynamical processes in the vicinity of\naccreting supermassive black holes. In this paper, we present 14 Chandra HETGS\nspectra of the nucleus of Cen A that were observed throughout 2022. We compared\nthem with each other, and contrasted them against the two previous Chandra\nHETGS spectra from 2001. This enabled an investigation into the spectral\nchanges occurring on timescales of months and 21 years. All Chandra spectra\ncould be well fitted by an absorbed power law with a strong and narrow Fe\nK$\\alpha$ line, a leaked power law feature at low energies, and Si and S\nK$\\alpha$ lines that could not be associated with the central engine. The flux\nof the continuum varied by a factor of $2.74\\pm0.05$ over the course of the\nobservations, whereas the Fe line only varied by $18.8\\pm8.8\\%$. The photon\nindex increased over 21 years, and the Hydrogen column density varied\nsignificantly within a few months as well. The Fe K$\\alpha$ line was found at a\nlower energy than expected from the Cen A redshift, amounting to an excess\nvelocity of $326^{+84}_{-94}~\\mathrm{km}~\\mathrm{s}^{-1}$ relative to Cen A. We\ninvestigated warped accretion disks, bulk motion, and outflows as possible\nexplanations of this shift. The spectra also featured ionized absorption lines\nfrom Fe XXV and Fe XXVI, describing a variable inflow.",
            "author": [
                "David Bogensberger",
                "Jon Miller",
                "Elias Kammoun",
                "Richard Mushotzky",
                "Laura Brenneman",
                "William N. Brandt",
                "Edward M. Cackett",
                "Andrew Fabian",
                "Jelle Kaastra",
                "Shashank Dattathri",
                "Ehud Behar",
                "Abderahmen Zoghbi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17285v1",
                "http://arxiv.org/pdf/2311.17285v1"
            ],
            "primary_category": "astro-ph.HE",
            "category": [
                "astro-ph.HE",
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17280v2",
            "title": "Does VLN Pretraining Work with Nonsensical or Irrelevant Instructions?",
            "updated": "2023-12-02T06:39:17Z",
            "published": "2023-11-28T23:40:13Z",
            "summary": "Data augmentation via back-translation is common when pretraining\nVision-and-Language Navigation (VLN) models, even though the generated\ninstructions are noisy. But: does that noise matter? We find that nonsensical\nor irrelevant language instructions during pretraining can have little effect\non downstream performance for both HAMT and VLN-BERT on R2R, and is still\nbetter than only using clean, human data. To underscore these results, we\nconcoct an efficient augmentation method, Unigram + Object, which generates\nnonsensical instructions that nonetheless improve downstream performance. Our\nfindings suggest that what matters for VLN R2R pretraining is the quantity of\nvisual trajectories, not the quality of instructions.",
            "author": [
                "Wang Zhu",
                "Ishika Singh",
                "Yuan Huang",
                "Robin Jia",
                "Jesse Thomason"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17280v2",
                "http://arxiv.org/pdf/2311.17280v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17279v1",
            "title": "LiveTune: Dynamic Parameter Tuning for Training Deep Neural Networks",
            "updated": "2023-11-28T23:38:42Z",
            "published": "2023-11-28T23:38:42Z",
            "summary": "Traditional machine learning training is a static process that lacks\nreal-time adaptability of hyperparameters. Popular tuning solutions during\nruntime involve checkpoints and schedulers. Adjusting hyper-parameters usually\nrequire the program to be restarted, wasting utilization and time, while\nplacing unnecessary strain on memory and processors. We present LiveTune, a new\nframework allowing real-time parameter tuning during training through\nLiveVariables. Live Variables allow for a continuous training session by\nstoring parameters on designated ports on the system, allowing them to be\ndynamically adjusted. Extensive evaluations of our framework show saving up to\n60 seconds and 5.4 Kilojoules of energy per hyperparameter change.",
            "author": [
                "Soheil Zibakhsh Shabgahi",
                "Nojan Sheybani",
                "Aiden Tabrizi",
                "Farinaz Koushanfar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17279v1",
                "http://arxiv.org/pdf/2311.17279v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.PF"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17277v1",
            "title": "An Online Optimization-Based Decision Support Tool for Small Farmers in\n  India: Learning in Non-stationary Environments",
            "updated": "2023-11-28T23:33:16Z",
            "published": "2023-11-28T23:33:16Z",
            "summary": "Crop management decision support systems are specialized tools for farmers\nthat reduce the riskiness of revenue streams, especially valuable for use under\nthe current climate changes that impact agricultural productivity.\nUnfortunately, small farmers in India, who could greatly benefit from these\ntools, do not have access to them. In this paper, we model an individual\ngreenhouse as a Markov Decision Process (MDP) and adapt Li and Li (2019)'s\nFollow the Weighted Leader (FWL) online learning algorithm to offer crop\nplanning advice. We successfully produce utility-preserving cropping pattern\nsuggestions in simulations. When we compare against an offline planning\nalgorithm, we achieve the same cumulative revenue with greatly reduced runtime.",
            "author": [
                "Tuxun Lu",
                "Aviva Prins"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17277v1",
                "http://arxiv.org/pdf/2311.17277v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17276v1",
            "title": "Machine Unlearning in Learned Databases: An Experimental Analysis",
            "updated": "2023-11-28T23:32:42Z",
            "published": "2023-11-28T23:32:42Z",
            "summary": "Machine learning models based on neural networks (NNs) are enjoying\never-increasing attention in the DB community. However, an important issue has\nbeen largely overlooked, namely the challenge of dealing with the highly\ndynamic nature of DBs, where data updates are fundamental, highly-frequent\noperations. Although some recent research has addressed the issues of\nmaintaining updated NN models in the presence of new data insertions, the\neffects of data deletions (a.k.a., \"machine unlearning\") remain a blind spot.\nWith this work, for the first time to our knowledge, we pose and answer the\nfollowing key questions: What is the effect of unlearning algorithms on\nNN-based DB models? How do these effects translate to effects on downstream DB\ntasks, such as selectivity estimation (SE), approximate query processing (AQP),\ndata generation (DG), and upstream tasks like data classification (DC)? What\nmetrics should we use to assess the impact and efficacy of unlearning\nalgorithms in learned DBs? Is the problem of machine unlearning in DBs\ndifferent from that of machine learning in DBs in the face of data insertions?\nIs the problem of machine unlearning for DBs different from unlearning in the\nML literature? what are the overhead and efficiency of unlearning algorithms?\nWhat is the sensitivity of unlearning on batching delete operations? If we have\na suitable unlearning algorithm, can we combine it with an algorithm handling\ndata insertions en route to solving the general adaptability/updatability\nrequirement in learned DBs in the face of both data inserts and deletes? We\nanswer these questions using a comprehensive set of experiments, various\nunlearning algorithms, a variety of downstream DB tasks, and an upstream task\n(DC), each with different NNs, and using a variety of metrics on a variety of\nreal datasets, making this also a first key step towards a benchmark for\nlearned DB unlearning.",
            "author": [
                "Meghdad Kurmanji",
                "Eleni Triantafillou",
                "Peter Triantafillou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17276v1",
                "http://arxiv.org/pdf/2311.17276v1"
            ],
            "primary_category": "cs.DB",
            "category": [
                "cs.DB"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17941v1",
            "title": "Advancing Attack-Resilient Scheduling of Integrated Energy Systems with\n  Demand Response via Deep Reinforcement Learning",
            "updated": "2023-11-28T23:29:36Z",
            "published": "2023-11-28T23:29:36Z",
            "summary": "Optimally scheduling multi-energy flow is an effective method to utilize\nrenewable energy sources (RES) and improve the stability and economy of\nintegrated energy systems (IES). However, the stable demand-supply of IES faces\nchallenges from uncertainties that arise from RES and loads, as well as the\nincreasing impact of cyber-attacks with advanced information and communication\ntechnologies adoption. To address these challenges, this paper proposes an\ninnovative model-free resilience scheduling method based on state-adversarial\ndeep reinforcement learning (DRL) for integrated demand response (IDR)-enabled\nIES. The proposed method designs an IDR program to explore the interaction\nability of electricity-gas-heat flexible loads. Additionally, a\nstate-adversarial Markov decision process (SA-MDP) model characterizes the\nenergy scheduling problem of IES under cyber-attack. The state-adversarial soft\nactor-critic (SA-SAC) algorithm is proposed to mitigate the impact of\ncyber-attacks on the scheduling strategy. Simulation results demonstrate that\nour method is capable of adequately addressing the uncertainties resulting from\nRES and loads, mitigating the impact of cyber-attacks on the scheduling\nstrategy, and ensuring a stable demand supply for various energy sources.\nMoreover, the proposed method demonstrates resilience against cyber-attacks.\nCompared to the original soft actor-critic (SAC) algorithm, it achieves a 10\\%\nimprovement in economic performance under cyber-attack scenarios.",
            "author": [
                "Yang Li",
                "Wenjie Ma",
                "Yuanzheng Li",
                "Sen Li",
                "Zhe Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17941v1",
                "http://arxiv.org/pdf/2311.17941v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.LG",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17274v1",
            "title": "Representation theoretic interpretation of the Springer correspondence\n  for dihedral groups",
            "updated": "2023-11-28T23:23:30Z",
            "published": "2023-11-28T23:23:30Z",
            "summary": "The Lusztig-Shoji algorithm is generalized to a complex reflection group $W$\nand give us a version of the Springer correspondence of $W$. We show that the\ncombinatorics of generalized Springer correspondences of dihedral groups of\norder $2n$ exhibit the Brauer-Humphreys type reciprocity as in the case of Weyl\ngroups for odd $n$, and these constitute a major portion of the stratification\nof the natural module categories attached to them.",
            "author": [
                "Susumu Higuchi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17274v1",
                "http://arxiv.org/pdf/2311.17274v1"
            ],
            "primary_category": "math.RT",
            "category": [
                "math.RT",
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17271v1",
            "title": "Spatial-Temporal Extreme Modeling for Point-to-Area Random Effects\n  (PARE)",
            "updated": "2023-11-28T23:09:36Z",
            "published": "2023-11-28T23:09:36Z",
            "summary": "One measurement modality for rainfall is a fixed location rain gauge.\nHowever, extreme rainfall, flooding, and other climate extremes often occur at\nlarger spatial scales and affect more than one location in a community. For\nexample, in 2017 Hurricane Harvey impacted all of Houston and the surrounding\nregion causing widespread flooding. Flood risk modeling requires understanding\nof rainfall for hydrologic regions, which may contain one or more rain gauges.\nFurther, policy changes to address the risks and damages of natural hazards\nsuch as severe flooding are usually made at the community/neighborhood level or\nhigher geo-spatial scale. Therefore, spatial-temporal methods which convert\nresults from one spatial scale to another are especially useful in applications\nfor evolving environmental extremes. We develop a point-to-area random effects\n(PARE) modeling strategy for understanding spatial-temporal extreme values at\nthe areal level, when the core information are time series at point locations\ndistributed over the region.",
            "author": [
                "Carlynn Fagnant",
                "Julia C. Schedler",
                "Katherine B. Ensor"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17271v1",
                "http://arxiv.org/pdf/2311.17271v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17268v1",
            "title": "Ab initio study on the stability and elasticity of brucite",
            "updated": "2023-11-28T23:04:43Z",
            "published": "2023-11-28T23:04:43Z",
            "summary": "Brucite (Mg(OH)$_2$) is a mineral of great interest owing to its various\napplications and roles in geological processes. Its structure, behavior under\ndifferent conditions, and unique properties have been the subject of numerous\nstudies and persistent debate. As a stable hydrous phase in subduction zones,\nits elastic anisotropy can significantly contribute to the seismological\nproperties of these regions. We performed ab initio calculations to investigate\nbrucite's stability, elasticity, and acoustic velocities. We tested several\nexchange-correlation functionals and managed to obtain stable phonons for the\nP$\\bar{3}$ phase with r$^2$SCAN for the first time at all relevant pressures up\nto the mantle transition zone. We show that r$^2$SCAN performs very well in\nbrucite, reproducing the experimental equation of state and several key\nstructure parameters related to hydrogen positions. The room temperature\nelasticity results in P$\\bar{3}$ reproduces the experimental results at ambient\npressure. These results, together with the stable phonon dispersion of\nP$\\bar{3}$ at all relevant pressures, indicate P$\\bar{3}$ is the stable\ncandidate phase not only at elevated pressures but also at ambient conditions.\nThe success of r$^2$SCAN in brucite, suggests this functional should be\nsuitable for other challenging layer-structured minerals, e.g., serpentines, of\ngreat geophysical significance.",
            "author": [
                "Hongjin Wang",
                "Chenxing Luo",
                "Renata M. Wentzcovitch"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17268v1",
                "http://arxiv.org/pdf/2311.17268v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "physics.geo-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17267v1",
            "title": "E-ViLM: Efficient Video-Language Model via Masked Video Modeling with\n  Semantic Vector-Quantized Tokenizer",
            "updated": "2023-11-28T22:57:17Z",
            "published": "2023-11-28T22:57:17Z",
            "summary": "To build scalable models for challenging real-world tasks, it is important to\nlearn from diverse, multi-modal data in various forms (e.g., videos, text, and\nimages). Among the existing works, a plethora of them have focused on\nleveraging large but cumbersome cross-modal architectures. Regardless of their\neffectiveness, larger architectures unavoidably prevent the models from being\nextended to real-world applications, so building a lightweight VL architecture\nand an efficient learning schema is of great practical value. In this paper, we\npropose an Efficient Video-Language Model (dubbed as E-ViLM) and a masked video\nmodeling (MVM) schema, assisted with a semantic vector-quantized tokenizer. In\nparticular, our E-ViLM learns to reconstruct the semantic labels of masked\nvideo regions, produced by the pre-trained vector-quantized tokenizer, which\ndiscretizes the continuous visual signals into labels. We show that with our\nsimple MVM task and regular VL pre-training modelings, our E-ViLM, despite its\ncompactness, is able to learn expressive representations from Video-Language\ncorpus and generalize well to extensive Video-Language tasks including video\nquestion answering, text-to-video retrieval, etc. In particular, our E-ViLM\nobtains obvious efficiency improvements by reaching competing performances with\nfaster inference speed, i.e., our model reaches $39.3$% Top-$1$ accuracy on the\nMSRVTT benchmark, retaining $91.4$% of the accuracy of state-of-the-art larger\nVL architecture with only $15%$ parameters and $94.8%$ fewer GFLOPs. We also\nprovide extensive ablative studies that validate the effectiveness of our\nproposed learning schema for E-ViLM.",
            "author": [
                "Jacob Zhiyuan Fang",
                "Skyler Zheng",
                "Vasu Sharma",
                "Robinson Piramuthu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17267v1",
                "http://arxiv.org/pdf/2311.17267v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17266v1",
            "title": "Revealing Impact of Critical Stellar Central Density on Galaxy Quenching\n  through Cosmic Time",
            "updated": "2023-11-28T22:57:09Z",
            "published": "2023-11-28T22:57:09Z",
            "summary": "In the previous work of Xu & Peng (2021), we investigated the structural and\nenvironmental dependence on quenching in the nearby universe. In this work we\nextend our investigations to higher redshifts by combining galaxies from SDSS\nand ZFOURGE surveys. In low density, we find a characteristic $\\Sigma_{1\\ kpc}$\nabove which the quenching is initiated as indicated by their\npopulation-averaged color. $\\Sigma^{crit}_{1\\ kpc}$ shows only weakly\nmass-dependency at all redshifts, which suggests that the internal quenching\nprocess is more related to the physics that acts in the central region of\ngalaxies. In high density, $\\Sigma^{crit}_{1\\ kpc}$ for galaxies at $z > 1$ is\nalmost indistinguishable with their low-density counterparts. At $z < 1$,\n$\\Sigma^{crit}_{1\\ kpc}$ for low-mass galaxies becomes progressively strongly\nmass-dependent, which is due to the increasingly stronger environmental effects\nat lower redshifts. $\\Sigma^{crit}_{1\\ kpc}$ in low density shows strong\nredshift evolution with $\\sim 1$ dex decrement from $z = 2.5$ to $z = 0$. It is\nlikely due to that at a given stellar mass, the host halo is on average more\nmassive and gas-rich at higher redshifts, hence a higher level of integrated\nenergy from more massive black hole is required to quench. As the halo evolves\nfrom cold to hot accretion phase at lower redshifts, the gas is shock-heated\nand becomes more vulnerable to AGN feedback processes, as predicted by theory.\nMeanwhile, angular momentum quenching also becomes more effective at low\nredshifts, which complements a lower level of integrated energy from black hole\nto quench.",
            "author": [
                "Bingxiao Xu",
                "Yingjie Peng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17266v1",
                "http://arxiv.org/pdf/2311.17266v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17264v1",
            "title": "RETSim: Resilient and Efficient Text Similarity",
            "updated": "2023-11-28T22:54:33Z",
            "published": "2023-11-28T22:54:33Z",
            "summary": "This paper introduces RETSim (Resilient and Efficient Text Similarity), a\nlightweight, multilingual deep learning model trained to produce robust metric\nembeddings for near-duplicate text retrieval, clustering, and dataset\ndeduplication tasks. We demonstrate that RETSim is significantly more robust\nand accurate than MinHash and neural text embeddings, achieving new\nstate-of-the-art performance on dataset deduplication, adversarial text\nretrieval benchmarks, and spam clustering tasks. We also introduce the W4NT3D\nbenchmark (Wiki-40B 4dversarial Near-T3xt Dataset) for evaluating multilingual,\nnear-duplicate text retrieval capabilities under adversarial settings. RETSim\nand the W4NT3D benchmark are open-sourced under the MIT License at\nhttps://github.com/google/unisim.",
            "author": [
                "Marina Zhang",
                "Owen Vallis",
                "Aysegul Bumin",
                "Tanay Vakharia",
                "Elie Bursztein"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17264v1",
                "http://arxiv.org/pdf/2311.17264v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17263v1",
            "title": "Giant Generation of Polarization-Entangled Photons in Metal Organic\n  Framework Waveguides",
            "updated": "2023-11-28T22:51:41Z",
            "published": "2023-11-28T22:51:41Z",
            "summary": "Parametric nonlinear optical processes are instrumental in optical quantum\ntechnology for generating entangled light. However, the range of materials\nconventionally used for producing entangled photons is limited. Metal-organic\nframeworks (MOFs) have emerged as a novel class of optical materials with\ncustomizable nonlinear properties and proven chemical and optical stability.\nThe large number of combinations of metal atoms and organic ligand from which\nbulk MOF crystals are known to form, facilitates the search of promising\ncandidates for nonlinear optics. To accelerate the discovery of next-generation\nquantum light sources, we employ a multi-scale modeling approach to study\nphase-matching conditions for collinear degenerate type-II spontaneous\nparametric down conversion (SPDC) with MOF-based one dimensional waveguides.\nUsing periodic-DFT calculations to compute the nonlinear optical properties of\nselected zinc-based MOF crystals, we predict polarization-entangled pair\ngeneration rates of $\\sim 10^3-10^6$ s$^{-1}$mW$^{-1}$mm$^{-1}$ at 1064 nm,\nwhich are comparable with industry materials used in quantum optics. We find\nthat the biaxial MOF crystal Zn(4-pyridylacrylate)$_2$ improves two-fold the\nconversion efficiency over a periodically-poled KTP waveguide of identical\ndimensions. This work underscores the great potential of MOF single crystals as\nentangled light sources for applications in quantum communication and sensing.",
            "author": [
                "Sim\u00f3n Paiva",
                "Ruben A. Fritz",
                "Sanoj Raj",
                "Yamil J. Col\u00f3n",
                "Felipe Herrera"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17263v1",
                "http://arxiv.org/pdf/2311.17263v1"
            ],
            "primary_category": "physics.optics",
            "category": [
                "physics.optics",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17259v2",
            "title": "SoUnD Framework: Analyzing (So)cial Representation in (Un)structured\n  (D)ata",
            "updated": "2023-12-01T18:41:59Z",
            "published": "2023-11-28T22:48:00Z",
            "summary": "The unstructured nature of data used in foundation model development is a\nchallenge to systematic analyses for making data use and documentation\ndecisions. From a Responsible AI perspective, these decisions often rely upon\nunderstanding how people are represented in data. We propose a framework\ndesigned to guide analysis of human representation in unstructured data and\nidentify downstream risks. We apply the framework in two toy examples using the\nCommon Crawl web text corpus (C4) and LAION-400M. We also propose a set of\nhypothetical action steps in service of dataset use, development, and\ndocumentation.",
            "author": [
                "Mark D\u00edaz",
                "Sunipa Dev",
                "Emily Reif",
                "Emily Denton",
                "Vinodkumar Prabhakaran"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17259v2",
                "http://arxiv.org/pdf/2311.17259v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17256v1",
            "title": "Pattern retrieval of traffic congestion using graph-based associations\n  of traffic domain-specific features",
            "updated": "2023-11-28T22:33:22Z",
            "published": "2023-11-28T22:33:22Z",
            "summary": "The fast-growing amount of traffic data brings many opportunities for\nrevealing more insightful information about traffic dynamics. However, it also\ndemands an effective database management system in which information retrieval\nis arguably an important feature. The ability to locate similar patterns in big\ndatasets potentially paves the way for further valuable analyses in traffic\nmanagement. This paper proposes a content-based retrieval system for\nspatiotemporal patterns of highway traffic congestion. There are two main\ncomponents in our framework, namely pattern representation and similarity\nmeasurement. To effectively interpret retrieval outcomes, the paper proposes a\ngraph-based approach (relation-graph) for the former component, in which\nfundamental traffic phenomena are encoded as nodes and their spatiotemporal\nrelationships as edges. In the latter component, the similarities between\ncongestion patterns are customizable with various aspects according to user\nexpectations. We evaluated the proposed framework by applying it to a dataset\nof hundreds of patterns with various complexities (temporally and spatially).\nThe example queries indicate the effectiveness of the proposed method, i.e. the\nobtained patterns present similar traffic phenomena as in the given examples.\nIn addition, the success of the proposed approach directly derives a new\nopportunity for semantic retrieval, in which expected patterns are described by\nadopting the relation-graph notion to associate fundamental traffic phenomena.",
            "author": [
                "Tin T. Nguyen",
                "Simeon C. Calvert",
                "Guopeng Li",
                "Hans van Lint"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17256v1",
                "http://arxiv.org/pdf/2311.17256v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17253v1",
            "title": "Simulation of ionizing radiation in cell phone camera image sensors",
            "updated": "2023-11-28T22:29:13Z",
            "published": "2023-11-28T22:29:13Z",
            "summary": "The Distributed Electronic Cosmic-ray Observatory (DECO) is a cell phone app\nthat uses a cell phone camera image sensor to detect cosmic-ray particles and\nparticles from radioactive decay. Images recorded by DECO are classified by a\nconvolutional neural network (CNN) according to their morphology. In this\nproject, we develop a GEANT4-derived simulation of particle interactions inside\nthe CMOS sensor using the Allpix$^2$ modular framework. We simulate muons,\nelectrons, and photons with energy range 10 keV to 100 GeV, and their deposited\nenergy agrees well with expectations. Simulated events are recorded and\nprocessed in a similar way as data images taken by DECO, and the result shows\nboth similar image morphology with data events and good quantitative data-Monte\nCarlo agreement.",
            "author": [
                "Runze Li",
                "Alex Pizzuto",
                "Justin Vandenbroucke",
                "Brent Mode"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17253v1",
                "http://arxiv.org/pdf/2311.17253v1"
            ],
            "primary_category": "astro-ph.IM",
            "category": [
                "astro-ph.IM",
                "astro-ph.HE",
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17940v1",
            "title": "Scene Summarization: Clustering Scene Videos into Spatially Diverse\n  Frames",
            "updated": "2023-11-28T22:18:26Z",
            "published": "2023-11-28T22:18:26Z",
            "summary": "We propose scene summarization as a new video-based scene understanding task.\nIt aims to summarize a long video walkthrough of a scene into a small set of\nframes that are spatially diverse in the scene, which has many impotant\napplications, such as in surveillance, real estate, and robotics. It stems from\nvideo summarization but focuses on long and continuous videos from moving\ncameras, instead of user-edited fragmented video clips that are more commonly\nstudied in existing video summarization works. Our solution to this task is a\ntwo-stage self-supervised pipeline named SceneSum. Its first stage uses\nclustering to segment the video sequence. Our key idea is to combine visual\nplace recognition (VPR) into this clustering process to promote spatial\ndiversity. Its second stage needs to select a representative keyframe from each\ncluster as the summary while respecting resource constraints such as memory and\ndisk space limits. Additionally, if the ground truth image trajectory is\navailable, our method can be easily augmented with a supervised loss to enhance\nthe clustering and keyframe selection. Extensive experiments on both real-world\nand simulated datasets show our method outperforms common video summarization\nbaselines by 50%",
            "author": [
                "Chao Chen",
                "Mingzhi Zhu",
                "Ankush Pratap Singh",
                "Yu Yan",
                "Felix Juefei Xu",
                "Chen Feng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17940v1",
                "http://arxiv.org/pdf/2311.17940v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17251v1",
            "title": "SubZero: Subspace Zero-Shot MRI Reconstruction",
            "updated": "2023-11-28T22:16:51Z",
            "published": "2023-11-28T22:16:51Z",
            "summary": "Recently introduced zero-shot self-supervised learning (ZS-SSL) has shown\npotential in accelerated MRI in a scan-specific scenario, which enabled\nhigh-quality reconstructions without access to a large training dataset. ZS-SSL\nhas been further combined with the subspace model to accelerate 2D T2-shuffling\nacquisitions. In this work, we propose a parallel network framework and\nintroduce an attention mechanism to improve subspace-based zero-shot\nself-supervised learning and enable higher acceleration factors. We name our\nmethod SubZero and demonstrate that it can achieve improved performance\ncompared with current methods in T1 and T2 mapping acquisitions.",
            "author": [
                "Heng Yu",
                "Yamin Arefeen",
                "Berkin Bilgic"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17251v1",
                "http://arxiv.org/pdf/2311.17251v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.02993v1",
            "title": "ZTCloudGuard: Zero Trust Context-Aware Access Management Framework to\n  Avoid Misuse Cases in the Era of Generative AI and Cloud-based Health\n  Information Ecosystem",
            "updated": "2023-11-28T22:12:07Z",
            "published": "2023-11-28T22:12:07Z",
            "summary": "Managing access between large numbers of distributed medical devices has\nbecome a crucial aspect of modern healthcare systems, enabling the\nestablishment of smart hospitals and telehealth infrastructure. However, as\ntelehealth technology continues to evolve and Internet of Things (IoT) devices\nbecome more widely used, they are also becoming increasingly exposed to various\ntypes of vulnerabilities and medical errors. In healthcare information systems,\nabout 90\\% of vulnerabilities emerged from misuse cases and human errors. As a\nresult, there is a need for additional research and development of security\ntools to prevent such attacks. This article proposes a zero-trust-based\ncontext-aware framework for managing access to the main components of the cloud\necosystem, including users, devices and output data. The main goal and benefit\nof the proposed framework is to build a scoring system to prevent or alleviate\nmisuse cases while using distributed medical devices in cloud-based healthcare\ninformation systems. The framework has two main scoring schemas to maintain the\nchain of trust. First, it proposes a critical trust score based on cloud-native\nmicro-services of authentication, encryption, logging, and authorizations.\nSecond, creating a bond trust scoring to assess the real-time semantic and\nsyntactic analysis of attributes stored in a healthcare information system. The\nanalysis is based on a pre-trained machine learning model to generate the\nsemantic and syntactic scores. The framework also takes into account regulatory\ncompliance and user consent to create a scoring system. The advantage of this\nmethod is that it is applicable to any language and adapts to all attributes as\nit relies on a language model, not just a set of predefined and limited\nattributes. The results show a high F1 score of 93.5%, which proves that it is\nvalid for detecting misuse cases.",
            "author": [
                "Khalid Al-hammuri",
                "Fayez Gebali",
                "Awos Kanan"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02993v1",
                "http://arxiv.org/pdf/2312.02993v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17248v1",
            "title": "Deep Regularized Compound Gaussian Network for Solving Linear Inverse\n  Problems",
            "updated": "2023-11-28T21:53:57Z",
            "published": "2023-11-28T21:53:57Z",
            "summary": "Incorporating prior information into inverse problems, e.g. via\nmaximum-a-posteriori estimation, is an important technique for facilitating\nrobust inverse problem solutions. In this paper, we devise two novel approaches\nfor linear inverse problems that permit problem-specific statistical prior\nselections within the compound Gaussian (CG) class of distributions. The CG\nclass subsumes many commonly used priors in signal and image reconstruction\nmethods including those of sparsity-based approaches. The first method\ndeveloped is an iterative algorithm, called generalized compound Gaussian least\nsquares (G-CG-LS), that minimizes a regularized least squares objective\nfunction where the regularization enforces a CG prior. G-CG-LS is then\nunrolled, or unfolded, to furnish our second method, which is a novel deep\nregularized (DR) neural network, called DR-CG-Net, that learns the prior\ninformation. A detailed computational theory on convergence properties of\nG-CG-LS and thorough numerical experiments for DR-CG-Net are provided. Due to\nthe comprehensive nature of the CG prior, these experiments show that our\nunrolled DR-CG-Net outperforms competitive prior art methods in tomographic\nimaging and compressive sensing, especially in challenging low-training\nscenarios.",
            "author": [
                "Carter Lyons",
                "Raghu G. Raj",
                "Margaret Cheney"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17248v1",
                "http://arxiv.org/pdf/2311.17248v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.AI",
                "cs.NA",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17245v2",
            "title": "LightGaussian: Unbounded 3D Gaussian Compression with 15x Reduction and\n  200+ FPS",
            "updated": "2023-12-04T07:30:36Z",
            "published": "2023-11-28T21:39:20Z",
            "summary": "Recent advancements in real-time neural rendering using point-based\ntechniques have paved the way for the widespread adoption of 3D\nrepresentations. However, foundational approaches like 3D Gaussian Splatting\ncome with a substantial storage overhead caused by growing the SfM points to\nmillions, often demanding gigabyte-level disk space for a single unbounded\nscene, posing significant scalability challenges and hindering the splatting\nefficiency.\n  To address this challenge, we introduce LightGaussian, a novel method\ndesigned to transform 3D Gaussians into a more efficient and compact format.\nDrawing inspiration from the concept of Network Pruning, LightGaussian\nidentifies Gaussians that are insignificant in contributing to the scene\nreconstruction and adopts a pruning and recovery process, effectively reducing\nredundancy in Gaussian counts while preserving visual effects. Additionally,\nLightGaussian employs distillation and pseudo-view augmentation to distill\nspherical harmonics to a lower degree, allowing knowledge transfer to more\ncompact representations while maintaining reflectance. Furthermore, we propose\na hybrid scheme, VecTree Quantization, to quantize all attributes, resulting in\nlower bitwidth representations with minimal accuracy losses.\n  In summary, LightGaussian achieves an averaged compression rate over 15x\nwhile boosting the FPS from 139 to 215, enabling an efficient representation of\ncomplex scenes on Mip-NeRF 360, Tank and Temple datasets.\n  Project website: https://lightgaussian.github.io/",
            "author": [
                "Zhiwen Fan",
                "Kevin Wang",
                "Kairun Wen",
                "Zehao Zhu",
                "Dejia Xu",
                "Zhangyang Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17245v2",
                "http://arxiv.org/pdf/2311.17245v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17243v1",
            "title": "PHG-Net: Persistent Homology Guided Medical Image Classification",
            "updated": "2023-11-28T21:34:06Z",
            "published": "2023-11-28T21:34:06Z",
            "summary": "Modern deep neural networks have achieved great successes in medical image\nanalysis. However, the features captured by convolutional neural networks\n(CNNs) or Transformers tend to be optimized for pixel intensities and neglect\nkey anatomical structures such as connected components and loops. In this\npaper, we propose a persistent homology guided approach (PHG-Net) that explores\ntopological features of objects for medical image classification. For an input\nimage, we first compute its cubical persistence diagram and extract topological\nfeatures into a vector representation using a small neural network (called the\nPH module). The extracted topological features are then incorporated into the\nfeature map generated by CNN or Transformer for feature fusion. The PH module\nis lightweight and capable of integrating topological features into any CNN or\nTransformer architectures in an end-to-end fashion. We evaluate our PHG-Net on\nthree public datasets and demonstrate its considerable improvements on the\ntarget classification tasks over state-of-the-art methods.",
            "author": [
                "Yaopeng Peng",
                "Hongxiao Wang",
                "Milan Sonka",
                "Danny Z. Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17243v1",
                "http://arxiv.org/pdf/2311.17243v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17235v1",
            "title": "Photochemistry and Haze Formation",
            "updated": "2023-11-28T21:16:46Z",
            "published": "2023-11-28T21:16:46Z",
            "summary": "One of the many exciting revelations of the New Horizons flyby of Pluto was\nthe observation of global haze layers at altitudes as high as 200 km in the\nvisible wavelengths. This haze is produced in the upper atmosphere through\nphotochemical processes, similar to the processes in Titan's atmosphere. As the\nhaze particles grow in size and descend to the lower atmosphere, they coagulate\nand interact with the gases in the atmosphere through condensation and sticking\nprocesses that serve as temporary and permanent loss processes. New Horizons\nobservations confirm studies of Titan haze analogs suggesting that\nphotochemically produced haze particles harden as they grow in size. We outline\nin this chapter what is known about the photochemical processes that lead to\nhaze production and outline feedback processes resulting from the presence of\nhaze in the atmosphere, connect this to the evolution of Pluto's atmosphere,\nand discuss open questions that need to be addressed in future work.",
            "author": [
                "Mandt K. E.",
                "Luspay-Kuti A.",
                "Cheng A.",
                "Jessup K. -L.",
                "Gao P"
            ],
            "link": [
                "http://dx.doi.org/10.2458/azu_uapress_9780816540945-ch012",
                "http://arxiv.org/abs/2311.17235v1",
                "http://arxiv.org/pdf/2311.17235v1"
            ],
            "primary_category": "astro-ph.EP",
            "category": [
                "astro-ph.EP",
                "85-01"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17233v1",
            "title": "Quantifying the redundancy between prosody and text",
            "updated": "2023-11-28T21:15:24Z",
            "published": "2023-11-28T21:15:24Z",
            "summary": "Prosody -- the suprasegmental component of speech, including pitch, loudness,\nand tempo -- carries critical aspects of meaning. However, the relationship\nbetween the information conveyed by prosody vs. by the words themselves remains\npoorly understood. We use large language models (LLMs) to estimate how much\ninformation is redundant between prosody and the words themselves. Using a\nlarge spoken corpus of English audiobooks, we extract prosodic features aligned\nto individual words and test how well they can be predicted from LLM\nembeddings, compared to non-contextual word embeddings. We find a high degree\nof redundancy between the information carried by the words and prosodic\ninformation across several prosodic features, including intensity, duration,\npauses, and pitch contours. Furthermore, a word's prosodic information is\nredundant with both the word itself and the context preceding as well as\nfollowing it. Still, we observe that prosodic features can not be fully\npredicted from text, suggesting that prosody carries information above and\nbeyond the words. Along with this paper, we release a general-purpose data\nprocessing pipeline for quantifying the relationship between linguistic\ninformation and extra-linguistic features.",
            "author": [
                "Lukas Wolf",
                "Tiago Pimentel",
                "Evelina Fedorenko",
                "Ryan Cotterell",
                "Alex Warstadt",
                "Ethan Wilcox",
                "Tamar Regev"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17233v1",
                "http://arxiv.org/pdf/2311.17233v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.IT",
                "cs.LG",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17232v1",
            "title": "ReWaRD: Retinal Waves for Pre-Training Artificial Neural Networks\n  Mimicking Real Prenatal Development",
            "updated": "2023-11-28T21:14:05Z",
            "published": "2023-11-28T21:14:05Z",
            "summary": "Computational models trained on a large amount of natural images are the\nstate-of-the-art to study human vision - usually adult vision. Computational\nmodels of infant vision and its further development are gaining more and more\nattention in the community. In this work we aim at the very beginning of our\nvisual experience - pre- and post-natal retinal waves which suggest to be a\npre-training mechanism for the primate visual system at a very early stage of\ndevelopment. We see this approach as an instance of biologically plausible data\ndriven inductive bias through pre-training. We built a computational model that\nmimics this development mechanism by pre-training different artificial\nconvolutional neural networks with simulated retinal wave images. The resulting\nfeatures of this biologically plausible pre-training closely match the V1\nfeatures of the primate visual system. We show that the performance gain by\npre-training with retinal waves is similar to a state-of-the art pre-training\npipeline. Our framework contains the retinal wave generator, as well as a\ntraining strategy, which can be a first step in a curriculum learning based\ntraining diet for various models of development. We release code, data and\ntrained networks to build the basis for future work on visual development and\nbased on a curriculum learning approach including prenatal development to\nsupport studies of innate vs. learned properties of the primate visual system.\nAn additional benefit of our pre-trained networks for neuroscience or computer\nvision applications is the absence of biases inherited from datasets like\nImageNet.",
            "author": [
                "Benjamin Cappell",
                "Andreas Stoll",
                "Williams Chukwudi Umah",
                "Bernhard Egger"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17232v1",
                "http://arxiv.org/pdf/2311.17232v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17227v1",
            "title": "War and Peace (WarAgent): Large Language Model-based Multi-Agent\n  Simulation of World Wars",
            "updated": "2023-11-28T20:59:49Z",
            "published": "2023-11-28T20:59:49Z",
            "summary": "Can we avoid wars at the crossroads of history? This question has been\npursued by individuals, scholars, policymakers, and organizations throughout\nhuman history. In this research, we attempt to answer the question based on the\nrecent advances of Artificial Intelligence (AI) and Large Language Models\n(LLMs). We propose \\textbf{WarAgent}, an LLM-powered multi-agent AI system, to\nsimulate the participating countries, their decisions, and the consequences, in\nhistorical international conflicts, including the World War I (WWI), the World\nWar II (WWII), and the Warring States Period (WSP) in Ancient China. By\nevaluating the simulation effectiveness, we examine the advancements and\nlimitations of cutting-edge AI systems' abilities in studying complex\ncollective human behaviors such as international conflicts under diverse\nsettings. In these simulations, the emergent interactions among agents also\noffer a novel perspective for examining the triggers and conditions that lead\nto war. Our findings offer data-driven and AI-augmented insights that can\nredefine how we approach conflict resolution and peacekeeping strategies. The\nimplications stretch beyond historical analysis, offering a blueprint for using\nAI to understand human history and possibly prevent future international\nconflicts. Code and data are available at\n\\url{https://github.com/agiresearch/WarAgent}.",
            "author": [
                "Wenyue Hua",
                "Lizhou Fan",
                "Lingyao Li",
                "Kai Mei",
                "Jianchao Ji",
                "Yingqiang Ge",
                "Libby Hemphill",
                "Yongfeng Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17227v1",
                "http://arxiv.org/pdf/2311.17227v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17226v1",
            "title": "Composition schemes: q-enumerations and phase transitions",
            "updated": "2023-11-28T20:58:22Z",
            "published": "2023-11-28T20:58:22Z",
            "summary": "Composition schemes are ubiquitous in combinatorics, statistical mechanics\nand probability theory. We give a unifying explanation to various phenomena\nobserved in the combinatorial and statistical physics literature in the context\nof $q$-enumeration (this is a model where objects with a parameter of value $k$\nhave a Gibbs measure/Boltzmann weight $q^k$). This leads to phase transition\ndiagrams, highlighting the effect of $q$-enumeration and $q$-distributions on\nthe nature of the limit laws. We build upon the classical distinction between\nsubcritical, critical and supercritical composition schemes, as well as recent\nresults. We apply our results to a wealth of parameters, adding new limit laws\nto various families of lattice paths and quarter plane walks. We also explain\npreviously observed limit laws for pattern restricted permutations, and a\nphenomenon observed by Krattenthaler for the wall contacts in watermelons with\na wall.",
            "author": [
                "Cyril Banderier",
                "Markus Kuba",
                "Stephan Wagner",
                "Michael Wallner"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17226v1",
                "http://arxiv.org/pdf/2311.17226v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "math.PR",
                "60C05, 60E07, 60G50"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17224v1",
            "title": "On the Complexity of the Median and Closest Permutation Problems",
            "updated": "2023-11-28T20:54:53Z",
            "published": "2023-11-28T20:54:53Z",
            "summary": "Genome rearrangements are events where large blocks of DNA exchange places\nduring evolution. The analysis of these events is a promising tool for\nunderstanding evolutionary genomics, providing data for phylogenetic\nreconstruction based on genome rearrangement measures. Many pairwise\nrearrangement distances have been proposed, based on finding the minimum number\nof rearrangement events to transform one genome into the other, using some\npredefined operation. When more than two genomes are considered, we have the\nmore challenging problem of rearrangement-based phylogeny reconstruction. Given\na set of genomes and a distance notion, there are at least two natural ways to\ndefine the \"target\" genome. On the one hand, finding a genome that minimizes\nthe sum of the distances from this to any other, called the median genome.\nFinding a genome that minimizes the maximum distance to any other, called the\nclosest genome. Considering genomes as permutations, some distance metrics have\nbeen extensively studied. We investigate median and closest problems on\npermutations over the metrics: breakpoint, swap, block-interchange,\nshort-block-move, and transposition. In biological matters some values are\nusually small, such as the solution value d or the number k of input\npermutations. For each of these metrics and parameters d or k, we analyze the\nclosest and the median problems from the viewpoint of parameterized complexity.\nWe obtain the following results: NP-hardness for finding the median/closest\npermutation for some metrics, even for k = 3; Polynomial kernels for the\nproblems of finding the median permutation of all studied metrics, considering\nthe target distance d as parameter; NP-hardness result for finding the closest\npermutation by short-block-moves; FPT algorithms and infeasibility of\npolynomial kernels for finding the closest permutation for some metrics\nparameterized by the target distance d.",
            "author": [
                "Lu\u00eds Cunha",
                "Ignasi Sau",
                "U\u00e9verton Souza"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17224v1",
                "http://arxiv.org/pdf/2311.17224v1"
            ],
            "primary_category": "cs.CC",
            "category": [
                "cs.CC",
                "math.CO",
                "68R05, 68Q27, 68Q25"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17223v1",
            "title": "Enhanced three-minute oscillation above a sunspot during a solar flare",
            "updated": "2023-11-28T20:53:35Z",
            "published": "2023-11-28T20:53:35Z",
            "summary": "Three-minute oscillations are a common phenomenon in the solar chromosphere\nabove a sunspot. Oscillations can be affected by the energy release process\nrelated to solar flares. In this paper, we report on an enhanced oscillation in\nflare event SOL2012-07-05T21:42 with a period of around three minutes, that\noccurred at the location of a flare ribbon at a sunspot umbra-penumbra\nboundary, and was observed both in chromo-spheric and coronal passbands. An\nanalysis of this oscillation was carried out using simultaneous ground-based\nobservations from the Goode Solar Telescope (GST) at the Big Bear Solar\nObservatory (BBSO) and space-based observations from the Solar Dynamics\nObservatory (SDO). A frequency shift was observed before and after the flare,\nwith the running penumbral wave that was present with a period of about 200 s\nbefore the flare co-existing with a strengthened oscillation with a period of\n180 s at the same locations after the flare. We also found a phase difference\nbetween different passbands, with the oscillation occurring from\nhigh-temperature to low-temperature passbands. Theoretically, the change in\nfrequency is strongly dependent on the variation of the inclination of the\nmagnetic field and the chromospheric temperature. Following an analysis of the\nproperties of the region, we find the frequency change is caused by the slight\ndecrease of the magnetic inclination angle to the local vertical. In addition,\nwe suggest that the enhanced three-minute oscillation is related to the\nadditional heating, maybe due to the downflow, during the EUV late phase of the\nflare.",
            "author": [
                "Ya Wang",
                "Lyndsay Fletcher",
                "Sargam Mulay",
                "Haisheng Ji",
                "Wenda Cao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17223v1",
                "http://arxiv.org/pdf/2311.17223v1"
            ],
            "primary_category": "astro-ph.SR",
            "category": [
                "astro-ph.SR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17219v1",
            "title": "Charge transport battery with quantum feedback",
            "updated": "2023-11-28T20:44:49Z",
            "published": "2023-11-28T20:44:49Z",
            "summary": "A battery is a work storage device, i.e. a device that stores energy in the\nform of work for later use by other devices. In this work, we study the\nrealization of a quantum battery in a double quantum dot in series, charged by\ntwo electrodes at different chemical potentials and optimized by a Markovian\nquantum feedback protocol. Using the concept of ergotropy as a figure of merit,\nwe first establish a simple expression for the maximum ergotropy in a two-level\nsystem, and then find the parameters under which a Markovian feedback can\nachieve this optimal ergotropy. We also study the influence of interaction with\na phonon environment on the charging and discharging process of the battery.",
            "author": [
                "Oscar Bohorquez"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17219v1",
                "http://arxiv.org/pdf/2311.17219v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17218v1",
            "title": "BIM: Block-Wise Self-Supervised Learning with Masked Image Modeling",
            "updated": "2023-11-28T20:42:30Z",
            "published": "2023-11-28T20:42:30Z",
            "summary": "Like masked language modeling (MLM) in natural language processing, masked\nimage modeling (MIM) aims to extract valuable insights from image patches to\nenhance the feature extraction capabilities of the underlying deep neural\nnetwork (DNN). Contrasted with other training paradigms like supervised\nlearning and unsupervised contrastive learning, masked image modeling (MIM)\npretraining typically demands significant computational resources in order to\nmanage large training data batches (e.g., 4096). The significant memory and\ncomputation requirements pose a considerable challenge to its broad adoption.\nTo mitigate this, we introduce a novel learning framework,\ntermed~\\textit{Block-Wise Masked Image Modeling} (BIM). This framework involves\ndecomposing the MIM tasks into several sub-tasks with independent computation\npatterns, resulting in block-wise back-propagation operations instead of the\ntraditional end-to-end approach. Our proposed BIM maintains superior\nperformance compared to conventional MIM while greatly reducing peak memory\nconsumption. Moreover, BIM naturally enables the concurrent training of\nnumerous DNN backbones of varying depths. This leads to the creation of\nmultiple trained DNN backbones, each tailored to different hardware platforms\nwith distinct computing capabilities. This approach significantly reduces\ncomputational costs in comparison with training each DNN backbone individually.\nOur framework offers a promising solution for resource constrained training of\nMIM.",
            "author": [
                "Yixuan Luo",
                "Mengye Ren",
                "Sai Qian Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17218v1",
                "http://arxiv.org/pdf/2311.17218v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17213v2",
            "title": "General-Purpose vs. Domain-Adapted Large Language Models for Extraction\n  of Data from Thoracic Radiology Reports",
            "updated": "2023-12-01T19:56:22Z",
            "published": "2023-11-28T20:34:40Z",
            "summary": "Radiologists produce unstructured data that could be valuable for clinical\ncare when consumed by information systems. However, variability in style limits\nusage. Study compares performance of system using domain-adapted language model\n(RadLing) and general-purpose large language model (GPT-4) in extracting common\ndata elements (CDE) from thoracic radiology reports. Three radiologists\nannotated a retrospective dataset of 1300 thoracic reports (900 training, 400\ntest) and mapped to 21 pre-selected relevant CDEs. RadLing was used to generate\nembeddings for sentences and identify CDEs using cosine-similarity, which were\nmapped to values using light-weight mapper. GPT-4 system used OpenAI's\ngeneral-purpose embeddings to identify relevant CDEs and used GPT-4 to map to\nvalues. The output CDE:value pairs were compared to the reference standard; an\nidentical match was considered true positive. Precision (positive predictive\nvalue) was 96% (2700/2824) for RadLing and 99% (2034/2047) for GPT-4. Recall\n(sensitivity) was 94% (2700/2876) for RadLing and 70% (2034/2887) for GPT-4;\nthe difference was statistically significant (P<.001). RadLing's domain-adapted\nembeddings were more sensitive in CDE identification (95% vs 71%) and its\nlight-weight mapper had comparable precision in value assignment (95.4% vs\n95.0%). RadLing system exhibited higher performance than GPT-4 system in\nextracting CDEs from radiology reports. RadLing system's domain-adapted\nembeddings outperform general-purpose embeddings from OpenAI in CDE\nidentification and its light-weight value mapper achieves comparable precision\nto large GPT-4. RadLing system offers operational advantages including local\ndeployment and reduced runtime costs. Domain-adapted RadLing system surpasses\nGPT-4 system in extracting common data elements from radiology reports, while\nproviding benefits of local deployment and lower costs.",
            "author": [
                "Ali H. Dhanaliwala",
                "Rikhiya Ghosh",
                "Sanjeev Kumar Karn",
                "Poikavila Ullaskrishnan",
                "Oladimeji Farri",
                "Dorin Comaniciu",
                "Charles E. Kahn"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17213v2",
                "http://arxiv.org/pdf/2311.17213v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17206v1",
            "title": "MUSE observations of the optical nebula surrounding the central compact\n  object in the Vela Junior Supernova Remnant",
            "updated": "2023-11-28T20:20:27Z",
            "published": "2023-11-28T20:20:27Z",
            "summary": "Central Compact Objects (CCOs), neutron stars found near the centre of some\nSupernova Remnants (SNRs), have been almost exclusively studied in X-rays and\nare thought to lack the wind nebulae typically seen around young,\nrotation-powered pulsars. We present the first, spatially-resolved,\nmorphological and spectroscopic study of the optical nebula observed at the\nlocation of CXOU J085201.4-461753, the CCO in the heart of the Vela Junior SNR.\nIt is currently the only Galactic CCO with a spatially coincident nebula\ndetected at optical wavelengths, whose exact nature remains uncertain. New MUSE\nintegral field spectroscopy data confirm that the nebula, shaped like a smooth\nblob extending 8\" in diameter, is dominated by [N II]$\\lambda\\lambda$6548,6583\nemission. The data reveals a distinct and previously unobserved morphology of\nthe H$\\alpha$ emission, exhibiting an arc-like shape reminiscent of a bow shock\nnebula. We observe a significantly strong [N II] emission relative to\nH$\\alpha$, with the [N II]$\\lambda\\lambda$6548,6583 up to 34 times the\nintensity of the H$\\alpha$ emission within the optical nebula environment.\nNotably, the [N II] and H$\\alpha$ structures are not spatially coincident, with\nthe [N II] nebula concentrated to the south of the CCO and delimited by the\nH$\\alpha$ arc-like structure. We detect additional emission in [N I], He I, [S\nII], [Ar III], [Fe II], and [S III]. We discuss our findings in the light of a\nphotoionization or Wolf-Rayet nebula, pointing to a very massive progenitor and\nfurther suggesting that very massive stars do not necessarily make black holes.",
            "author": [
                "Janette Suherli",
                "Samar Safi-Harb",
                "Ivo R. Seitenzahl",
                "Parviz Ghavamian",
                "Wynn C. G. Ho",
                "Chuan-Jui Li",
                "Ashley J. Ruiter",
                "Ralph S. Sutherland",
                "Fr\u00e9d\u00e9ric P. A. Vogt"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17206v1",
                "http://arxiv.org/pdf/2311.17206v1"
            ],
            "primary_category": "astro-ph.HE",
            "category": [
                "astro-ph.HE",
                "astro-ph.SR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17204v1",
            "title": "Optimal EEG Electrode Set for Emotion Recognition From Brain Signals: An\n  Empirical Quest",
            "updated": "2023-11-28T20:18:42Z",
            "published": "2023-11-28T20:18:42Z",
            "summary": "The human brain is a complex organ, still completely undiscovered, that\ncontrols almost all the parts of the body. Apart from survival, the human brain\nstimulates emotions. Recent research indicates that brain signals can be very\neffective for emotion recognition. However, which parts of the brain exhibit\nmost of the emotions is still under-explored. In this study, we empirically\nanalyze the contribution of each part of the brain in exhibiting emotions. We\nuse the DEAP dataset to find the most optimal electrode set which eventually\nleads to the effective brain part associated with emotions. We use Fast Fourier\nTransformation for effective feature extraction and a 1D-CNN with residual\nconnection for classification. Though 32 electrodes from the DEAP dataset got\nan accuracy of 97.34%, only 12 electrodes (F7, P8, O1, F8, C4, T7, PO3, Fp1,\nFp2, O2, P3, and Fz) achieve 95.81% accuracy. This study also shows that adding\nmore than 10 electrodes does not improve performance significantly. Moreover,\nthe frontal lobe is the most important for recognizing emotion.",
            "author": [
                "Rumman Ahmed Prodhan",
                "Sumya Akter",
                "Tanmoy Sarkar Pias",
                "Md. Akhtaruzzaman Adnan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17204v1",
                "http://arxiv.org/pdf/2311.17204v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17202v1",
            "title": "Charting the Galactic acceleration field II. A global mass model of the\n  Milky Way from the STREAMFINDER Atlas of Stellar Streams detected in Gaia DR3",
            "updated": "2023-11-28T20:16:51Z",
            "published": "2023-11-28T20:16:51Z",
            "summary": "We present an atlas and follow-up spectroscopic observations of 87 thin\nstream-like structures detected with the STREAMFINDER algorithm in Gaia DR3, of\nwhich 29 are new discoveries. Here we focus on using these streams to refine\nmass models of the Galaxy. Fits with a double power law halo with the outer\npower law slope set to $-\\beta_h=3$ yield an inner power law slope\n$-\\gamma_h=0.97^{+0.17}_{-0.21}$, a scale radius of $r_{0,\nh}=14.7^{+4.7}_{-1.0}$ kpc, a halo density flattening $q_{m, h}=0.75\\pm0.03$,\nand a local dark matter density of $\\rho_{h, \\odot}=0.0114\\pm0.0007 {\\rm\nM_\\odot pc^{-3}}$. Freeing $\\beta$ yields $\\beta=2.53^{+0.42}_{-0.16}$, but\nthis value is heavily influenced by our chosen virial mass limit. The stellar\ndisks are found to have a combined mass of $4.20^{+0.44}_{-0.53}\\times10^{10}\n{\\rm M_\\odot}$, with the thick disk contributing $12.4\\pm0.7$\\% to the local\nstellar surface density. The scale length of the thin and thick disks are\n$2.17^{+0.18}_{-0.08}$ kpc and $1.62^{+0.72}_{-0.13}$ kpc, respectively, while\ntheir scale heights are $0.347^{+0.007}_{-0.010}$ kpc and\n$0.86^{+0.03}_{-0.02}$ kpc, respectively. The virial mass of the favored model\nis $M_{200}=1.09^{+0.19}_{-0.14}\\times 10^{12} {\\rm M_\\odot}$, while the mass\ninside of 50 kpc is $M_{R<50}=0.46\\pm0.03\\times 10^{12} {\\rm M_\\odot}$. We\nintroduce the Large Magellanic Cloud (LMC) into the derived potential models,\nand fit the \"Orphan\" stream therein, finding a mass for the LMC that is\nconsistent with recent estimates. Some highlights of the atlas include the\nnearby trailing arm of $\\omega$-Cen, and a nearby very metal-poor stream that\nwas once a satellite of the Sagittarius dwarf galaxy. Finally, we unambiguously\ndetect a hot component around the GD-1 stream, consistent with it having been\ntidally pre-processed within its own DM subhalo.",
            "author": [
                "Rodrigo Ibata",
                "Khyati Malhan",
                "Wassim Tenachi",
                "Anke Ardern-Arentsen",
                "Michele Bellazzini",
                "Paolo Bianchini",
                "Piercarlo Bonifacio",
                "Elisabetta Caffau",
                "Foivos Diakogiannis",
                "Raphael Errani",
                "Benoit Famaey",
                "Salvatore Ferrone",
                "Nicolas Martin",
                "Paola di Matteo",
                "Giacomo Monari",
                "Florent Renaud",
                "Else Starkenburg",
                "Guillaume Thomas",
                "Akshara Viswanathan",
                "Zhen Yuan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17202v1",
                "http://arxiv.org/pdf/2311.17202v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17195v1",
            "title": "Viscous heating as the dominant heat source inside the water snowline of\n  V883 Ori",
            "updated": "2023-11-28T19:55:09Z",
            "published": "2023-11-28T19:55:09Z",
            "summary": "FU Orionis-type objects(FUors) are embedded protostars that undergo episodes\nof high accretion, potentially indicating a widespread but poorly understood\nphase in the formation of low-mass stars. Gaining a better understanding of the\ninfluence exerted by these outbursts on the evolution of the surrounding\nprotoplanetary disc may hold significant implications for the process of planet\nformation and the evolution of disc chemistry. The heating due to outbursts of\nhigh accretion in FUors pushes the snowlines of key volatiles farther out in\nthe disc, so they become easier to observe and study. Among the known FUors,\nV883 Ori is of particular interest. V883 Ori was the first FUor to show\nindirect evidence of a resolvable snowline beyond 40 au. By introducing a\nradial-dependent model of this source including viscous heating, we show that\nactive heating is needed to reproduce the steep thermal profile of dust in the\ninner disc of V883 Ori. Our disc modeling combines the effect of stellar\nirradiation and the influence on the disc shape caused by the outburst of\naccretion. The accuracy of our model is tested by comparing synthetic ALMA\nimages with continuum observations of V883 Ori, showing that the model\nsuccessfully reproduces the 1.3 mm emission of V883 Ori at high spatial\nresolution. Our final predictions underline the importance of viscous heating\nas a predominant heat source for this type of object, changing the physical\nconditions (shape and temperature) of the disc, and influencing its evolution.",
            "author": [
                "Felipe Alarc\u00f3n",
                "Sim\u00f3n Casassus",
                "Wladimir lyra",
                "Sebasti\u00e1n P\u00e9rez",
                "Lucas Cieza"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17195v1",
                "http://arxiv.org/pdf/2311.17195v1"
            ],
            "primary_category": "astro-ph.SR",
            "category": [
                "astro-ph.SR",
                "astro-ph.EP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17193v1",
            "title": "El tequila para consumo nacional como una ventana de oportunidades para\n  el peque\u00f1o productor agavero",
            "updated": "2023-11-28T19:54:11Z",
            "published": "2023-11-28T19:54:11Z",
            "summary": "The objective of this research was to determine the degree of knowledge that\nthe inhabitants of the Guadalajara Metropolitan Area (made up of the\nmunicipalities Guadalajara, Tlajomulco de Z\\'u\\~niga, Tlaquepaque, Zapopan and\nTonal\\'a) had regarding tequila and the brands produced in Los Altos of\nJalisco. For this, a survey consisting of five questions was designed, which\nwas applied in the central square, center or z\\'ocalo of each municipality. The\nresults show that the big brands, when acquired by international companies,\nfocused their attention on capturing the consumer in international markets,\nsince the prices of the same products that they export have been out of the\npocket of those who like That drink, so it could be considered that the big\nbrands, have left the national market a little behind, of course they did not\nabandon it completely, but it stopped being their main objective. Therefore, it\ncan be concluded that the national market is the window of opportunity to join\nthe small and still unknown producers to work together and in a grouped way,\nthey are able to standardize a series of products that being of the same\nquality and same packaging, they can cover the national market, and perhaps, in\nthe future, become a large company distributed throughout the territory and\nbegin the export process only with national capital.",
            "author": [
                "Guillermo Jos\u00e9 Navarro del Toro"
            ],
            "link": [
                "http://dx.doi.org/10.23913/ricea.v10i19.159",
                "http://arxiv.org/abs/2311.17193v1",
                "http://arxiv.org/pdf/2311.17193v1"
            ],
            "primary_category": "econ.GN",
            "category": [
                "econ.GN",
                "q-fin.EC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.00053v1",
            "title": "Anti-Sexism Alert System: Identification of Sexist Comments on Social\n  Media Using AI Techniques",
            "updated": "2023-11-28T19:48:46Z",
            "published": "2023-11-28T19:48:46Z",
            "summary": "Social relationships in the digital sphere are becoming more usual and\nfrequent, and they constitute a very important aspect for all of us. {Violent\ninteractions in this sphere are very frequent, and have serious effects on the\nvictims}. Within this global scenario, there is one kind of digital violence\nthat is becoming really worrying: sexism against women. Sexist comments that\nare publicly posted in social media (newspaper comments, social networks,\netc.), usually obtain a lot of attention and become viral, with consequent\ndamage to the persons involved. In this paper, we introduce an anti-sexism\nalert system, based on natural language processing (NLP) and artificial\nintelligence (AI), that analyzes any public post, and decides if it could be\nconsidered a sexist comment or not. Additionally, this system also works on\nanalyzing all the public comments linked to any multimedia content (piece of\nnews, video, tweet, etc.) and decides, using a color-based system similar to\ntraffic lights, if there is sexism in the global set of posts. We have created\na labeled data set in Spanish, since the majority of studies focus on English,\nto train our system, which offers a very good performance after the validation\nexperiments.",
            "author": [
                "Rebeca P. D\u00edaz Redondo",
                "Ana Fern\u00e1ndez Vilas",
                "Mateo Ramos Merino",
                "Sonia Valladares",
                "Soledad Torres Guijarro",
                "Manar Mohamed Hafez"
            ],
            "link": [
                "http://dx.doi.org/10.3390/app13074341",
                "http://arxiv.org/abs/2312.00053v1",
                "http://arxiv.org/pdf/2312.00053v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17192v2",
            "title": "Vortex pair dynamics in three-dimensional homogeneous dipolar\n  superfluids",
            "updated": "2023-12-04T14:45:58Z",
            "published": "2023-11-28T19:48:23Z",
            "summary": "The static and dynamic properties of vortices in dipolar Bose-Einstein\ncondensates (dBECs) can be considerably modified relative to their nondipolar\ncounterparts by the anisotropic and long-ranged nature of the dipole-dipole\ninteraction. Working in a uniform dBEC, we analyze the structure of single\nvortices and the dynamics of vortex pairs, investigating the deviations from\nthe nondipolar paradigm. For a straight vortex line, we find that the induced\ndipolar interaction potential is axially anisotropic when the dipole moments\nhave a nonzero projection orthogonal to the vortex line. This results in a\ncorresponding elongation of the vortex core along this projection as well as an\nanisotropic superfluid phase and enhanced compressibility in the vicinity of\nthe vortex core. Consequently, the trajectories of like-signed vortex pairs are\ndescribed by a family of elliptical and oval-like curves rather than the\nfamiliar circular orbits. Similarly for opposite-signed vortex pairs their\ntranslation speeds along the binormal are found to be dipole\ninteraction-dependent. We expect that these findings will shed light on the\nunderlying mechanisms of many-vortex phenomena in dBECs such as quantum\nturbulence, vortex reconnections, and vortex lattices.",
            "author": [
                "Srivatsa B. Prasad",
                "Nick G. Parker",
                "Andrew W. Baggaley"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17192v2",
                "http://arxiv.org/pdf/2311.17192v2"
            ],
            "primary_category": "cond-mat.quant-gas",
            "category": [
                "cond-mat.quant-gas"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17189v1",
            "title": "TorchAmi: Generalized CPU/GPU Implementation of Algorithmic Matsubara\n  Integration",
            "updated": "2023-11-28T19:33:51Z",
            "published": "2023-11-28T19:33:51Z",
            "summary": "We present torchami, an advanced implementation of algorithmic Matsubara\nintegration (AMI) that utilizes pytorch as a backend to provide easy\nparallelization and GPU support. AMI is a tool for analytically resolving the\nsequence of nested Matsubara integrals that arise in virtually all Feynman\nperturbative expansions. In this implementation we present a new AMI algorithm\nthat creates a more natural symbolic representation of the Feynman integrands.\nIn addition, we include peripheral tools that allow for import and labelling of\nsimple graph structures and conversion to torchami input. The code is written\nin c++ with python bindings provided.",
            "author": [
                "M. D. Burke",
                "J. P. F. LeBlanc"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17189v1",
                "http://arxiv.org/pdf/2311.17189v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "cond-mat.other",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17938v1",
            "title": "Active Open-Vocabulary Recognition: Let Intelligent Moving Mitigate CLIP\n  Limitations",
            "updated": "2023-11-28T19:24:07Z",
            "published": "2023-11-28T19:24:07Z",
            "summary": "Active recognition, which allows intelligent agents to explore observations\nfor better recognition performance, serves as a prerequisite for various\nembodied AI tasks, such as grasping, navigation and room arrangements. Given\nthe evolving environment and the multitude of object classes, it is impractical\nto include all possible classes during the training stage. In this paper, we\naim at advancing active open-vocabulary recognition, empowering embodied agents\nto actively perceive and classify arbitrary objects. However, directly adopting\nrecent open-vocabulary classification models, like Contrastive Language Image\nPretraining (CLIP), poses its unique challenges. Specifically, we observe that\nCLIP's performance is heavily affected by the viewpoint and occlusions,\ncompromising its reliability in unconstrained embodied perception scenarios.\nFurther, the sequential nature of observations in agent-environment\ninteractions necessitates an effective method for integrating features that\nmaintains discriminative strength for open-vocabulary classification. To\naddress these issues, we introduce a novel agent for active open-vocabulary\nrecognition. The proposed method leverages inter-frame and inter-concept\nsimilarities to navigate agent movements and to fuse features, without relying\non class-specific knowledge. Compared to baseline CLIP model with 29.6%\naccuracy on ShapeNet dataset, the proposed agent could achieve 53.3% accuracy\nfor open-vocabulary recognition, without any fine-tuning to the equipped CLIP\nmodel. Additional experiments conducted with the Habitat simulator further\naffirm the efficacy of our method.",
            "author": [
                "Lei Fan",
                "Jianxiong Zhou",
                "Xiaoying Xing",
                "Ying Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17938v1",
                "http://arxiv.org/pdf/2311.17938v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17179v2",
            "title": "SatCLIP: Global, General-Purpose Location Embeddings with Satellite\n  Imagery",
            "updated": "2023-11-30T20:25:24Z",
            "published": "2023-11-28T19:14:40Z",
            "summary": "Geographic location is essential for modeling tasks in fields ranging from\necology to epidemiology to the Earth system sciences. However, extracting\nrelevant and meaningful characteristics of a location can be challenging, often\nentailing expensive data fusion or data distillation from global imagery\ndatasets. To address this challenge, we introduce Satellite Contrastive\nLocation-Image Pretraining (SatCLIP), a global, general-purpose geographic\nlocation encoder that learns an implicit representation of locations from\nopenly available satellite imagery. Trained location encoders provide vector\nembeddings summarizing the characteristics of any given location for convenient\nusage in diverse downstream tasks. We show that SatCLIP embeddings, pretrained\non globally sampled multi-spectral Sentinel-2 satellite data, can be used in\nvarious predictive tasks that depend on location information but not\nnecessarily satellite imagery, including temperature prediction, animal\nrecognition in imagery, and population density estimation. Across tasks,\nSatCLIP embeddings consistently outperform embeddings from existing pretrained\nlocation encoders, ranging from models trained on natural images to models\ntrained on semantic context. SatCLIP embeddings also help to improve geographic\ngeneralization. This demonstrates the potential of general-purpose location\nencoders and opens the door to learning meaningful representations of our\nplanet from the vast, varied, and largely untapped modalities of geospatial\ndata.",
            "author": [
                "Konstantin Klemmer",
                "Esther Rolf",
                "Caleb Robinson",
                "Lester Mackey",
                "Marc Ru\u00dfwurm"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17179v2",
                "http://arxiv.org/pdf/2311.17179v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CY",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17175v1",
            "title": "Kicking it Off(-shell) with Direct Diffusion",
            "updated": "2023-11-28T19:08:04Z",
            "published": "2023-11-28T19:08:04Z",
            "summary": "Off-shell effects in large LHC backgrounds are crucial for precision\npredictions and, at the same time, challenging to simulate. We show how a\ngenerative diffusion network learns off-shell kinematics given the much simpler\non-shell process. It generates off-shell configurations fast and precisely,\nwhile reproducing even challenging on-shell features.",
            "author": [
                "Anja Butter",
                "Tomas Jezo",
                "Michael Klasen",
                "Mathias Kuschick",
                "Sofia Palacios Schweitzer",
                "Tilman Plehn"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17175v1",
                "http://arxiv.org/pdf/2311.17175v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17169v1",
            "title": "Third-generation-philic Hidden Naturalness",
            "updated": "2023-11-28T19:03:47Z",
            "published": "2023-11-28T19:03:47Z",
            "summary": "We present a solution to the electroweak hierarchy problem, where the\nrelevant new particles are third-generation-philic and hidden in SM processes\nwith third-generation fermions. Due to this feature, the mass bounds from\ndirect searches are much weaker and the required fine-tuning can be reduced\ndrastically. A concrete model is constructed based on a $SU(6)/Sp(6)$\nfundamental composite Higgs model with collective symmetry breaking and\nextended hypercolor mechanism. The construction allows to raise the scale $f$\nto $\\sim 3\\,$TeV, corresponding to resonances at $M_\\rho \\gtrsim 10$ TeV,\nwithout much tuning - employing ingredients that are naturally inherent in the\n(composite) Goldstone-Higgs framework. The experimental signatures are\ndiscussed in detail. It is found that current bounds allow for a model with\nnegligible tuning.",
            "author": [
                "Yi Chung",
                "Florian Goertz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17169v1",
                "http://arxiv.org/pdf/2311.17169v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17168v1",
            "title": "Probing nuclear properties and neutrino physics with current and future\n  CE\u03bdNS experiments",
            "updated": "2023-11-28T19:02:42Z",
            "published": "2023-11-28T19:02:42Z",
            "summary": "The recent observation of Coherent Elastic Neutrino Nucleus Scattering\n(CE{\\nu}NS) with neutrinos from pion decay at rest ({\\pi}-DAR) sources by the\nCOHERENT Collaboration has raised interest in this process in the search for\nnew physics. Unfortunately, current uncertainties in the determination of\nnuclear parameters relevant to those processes can hide new physics effects.\nThis is not the case for processes involving lower-energy neutrino sources such\nas nuclear reactors. Note, however, that a CE{\\nu}NS measurement with reactor\nneutrinos depends largely on the determination of the quenching factor, making\nits observation more challenging. In the upcoming years, once this signal is\nconfirmed, a combined analysis of {\\pi}-DAR and reactor CE{\\nu}NS experiments\nwill be very useful to probe particle and nuclear physics, with a reduced\ndependence on the nuclear uncertainties. In this work, we explore this idea by\nsimultaneously testing the sensitivity of current and future CE{\\nu}NS\nexperiments to neutrino non-standard interactions (NSI) and the neutron root\nmean square (rms) radius, considering different neutrino sources as well as\nseveral detection materials. We show how the interplay between future reactor\nand accelerator CE{\\nu}NS experiments can help to get robust constraints on the\nneutron rms, and to break degeneracies between the NSI parameters. Our forecast\ncould be used as a guide to optimize the experimental sensitivity to the\nparameters under study.",
            "author": [
                "R. R. Rossi",
                "G. Sanchez Garcia",
                "M. T\u00f3rtola"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17168v1",
                "http://arxiv.org/pdf/2311.17168v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17166v2",
            "title": "Is stochastic thermodynamics the key to understanding the energy costs\n  of computation?",
            "updated": "2023-11-30T22:23:15Z",
            "published": "2023-11-28T19:01:37Z",
            "summary": "The relationship between the thermodynamic and computational characteristics\nof dynamical physical systems has been a major theoretical interest since at\nleast the 19th century, and has been of increasing practical importance as the\nenergetic cost of digital devices has exploded over the last half century. One\nof the most important thermodynamic features of real-world computers is that\nthey operate very far from thermal equilibrium, in finite time, with many\nquickly (co-)evolving degrees of freedom. Such computers also must almost\nalways obey multiple physical constraints on how they work. For example, all\nmodern digital computers are periodic processes, governed by a global clock.\nAnother example is that many computers are modular, hierarchical systems, with\nstrong restrictions on the connectivity of their subsystems. This properties\nhold both for naturally occurring computers, like brains or Eukaryotic cells,\nas well as digital systems. These features of real-world computers are absent\nin 20th century analyses of the thermodynamics of computational processes,\nwhich focused on quasi-statically slow processes. However, the field of\nstochastic thermodynamics has been developed in the last few decades - and it\nprovides the formal tools for analyzing systems that have exactly these\nfeatures of real-world computers. We argue here that these tools, together with\nother tools currently being developed in stochastic thermodynamics, may help us\nunderstand at a far deeper level just how the fundamental physical properties\nof dynamic systems are related to the computation that they perform.",
            "author": [
                "David Wolpert",
                "Jan Korbel",
                "Christopher Lynn",
                "Farita Tasnim",
                "Joshua Grochow",
                "G\u00fclce Karde\u015f",
                "James Aimone",
                "Vijay Balasubramanian",
                "Eric de Giuli",
                "David Doty",
                "Nahuel Freitas",
                "Matteo Marsili",
                "Thomas E. Ouldridge",
                "Andrea Richa",
                "Paul Riechers",
                "\u00c9dgar Rold\u00e1n",
                "Brenda Rubenstein",
                "Zoltan Toroczkai",
                "Joseph Paradiso"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17166v2",
                "http://arxiv.org/pdf/2311.17166v2"
            ],
            "primary_category": "cond-mat.stat-mech",
            "category": [
                "cond-mat.stat-mech",
                "cs.CC",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17164v1",
            "title": "Dark Matter Isocurvature from Curvature",
            "updated": "2023-11-28T19:00:43Z",
            "published": "2023-11-28T19:00:43Z",
            "summary": "Isocurvature fluctuations, where the relative number density of particle\nspecies spatially varies, can be generated from initially adiabatic or\ncurvature fluctuations if the various species fall out of or were never in\nthermal equilibrium. The freezing of the thermal relic dark matter abundance is\none such case, but for modes that are still outside the horizon the amplitude\nis highly suppressed and originates from the small change in the local\nexpansion rate due to the local space curvature produced by the curvature\nfluctuation. We establish a simple separate-universe method for calculating\nthis generation that applies to both freeze-in and freeze-out models, identify\nthree critical epochs for this process, and give general scaling behaviors for\nthe amplitude in each case: the freezing epoch, the kinetic decoupling epoch\nand matter-radiation equality. Freeze-out models are typically dominated by\nspatially modulated annihilation from the latter epochs and can generate much\nlarger isocurvature fluctuations compared with typical freeze-in models, albeit\nstill very small and observationally allowed by cosmic microwave background\nmeasurements. We illustrate these results with concrete models where the dark\nmatter interactions are vector or scalar mediated.",
            "author": [
                "Ian Holst",
                "Wayne Hu",
                "Leah Jenks"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17164v1",
                "http://arxiv.org/pdf/2311.17164v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO",
                "hep-ph",
                "hep-th"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17163v1",
            "title": "A Site-Resolved 2D Quantum Simulator with Hundreds of Trapped Ions under\n  Tunable Couplings",
            "updated": "2023-11-28T19:00:39Z",
            "published": "2023-11-28T19:00:39Z",
            "summary": "A large qubit capacity and an individual readout capability are two crucial\nrequirements for large-scale quantum computing and simulation. As one of the\nleading physical platforms for quantum information processing, the ion trap has\nachieved quantum simulation of tens of ions with site-resolved readout in 1D\nPaul trap, and that of hundreds of ions with global observables in 2D Penning\ntrap. However, integrating these two features into a single system is still\nvery challenging. Here we report the stable trapping of 512 ions in a 2D Wigner\ncrystal and the sideband cooling of their transverse motion. We demonstrate the\nquantum simulation of long-range quantum Ising models with tunable coupling\nstrengths and patterns, with or without frustration, using 300 ions. Enabled by\nthe site resolution in the single-shot measurement, we observe rich spatial\ncorrelation patterns in the quasi-adiabatically prepared ground states. This\nspatial resolution further allows us to verify quantum simulation results by\ncomparing with the calculated collective phonon modes. Our work paves the way\nfor simulating classically intractable quantum dynamics and for running NISQ\nalgorithms using 2D ion trap quantum simulators. With the further development\nof 2D individual addressing, our work also makes a building block for a\nlarge-scale ion trap quantum computer.",
            "author": [
                "S. -A. Guo",
                "Y. -K. Wu",
                "J. Ye",
                "L. Zhang",
                "W. -Q. Lian",
                "R. Yao",
                "Y. Wang",
                "R. -Y. Yan",
                "Y. -J. Yi",
                "Y. -L. Xu",
                "B. -W. Li",
                "Y. -H. Hou",
                "Y. -Z. Xu",
                "W. -X. Guo",
                "C. Zhang",
                "B. -X. Qi",
                "Z. -C. Zhou",
                "L. He",
                "L. -M. Duan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17163v1",
                "http://arxiv.org/pdf/2311.17163v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17161v1",
            "title": "JOYS+: mid-infrared detection of gas-phase SO$_2$ emission in a low-mass\n  protostar. The case of NGC 1333 IRAS2A: hot core or accretion shock?",
            "updated": "2023-11-28T19:00:15Z",
            "published": "2023-11-28T19:00:15Z",
            "summary": "JWST/MIRI has sharpened our infrared eyes toward the star formation process.\nThis paper presents the first mid-infrared detection of gaseous SO$_2$ emission\nin an embedded low-mass protostellar system. MIRI-MRS observations of the\nlow-mass protostellar binary NGC 1333 IRAS2A are presented from the JWST\nObservations of Young protoStars (JOYS+) program, revealing emission from the\nSO$_2~\\nu_3$ asymmetric stretching mode at 7.35 micron. The results are\ncompared to those derived from high-angular resolution SO$_2$ data obtained\nwith ALMA. The SO$_2$ emission from the $\\nu_3$ band is predominantly located\non $\\sim50-100$ au scales around the main component of the binary, IRAS2A1. A\nrotational temperature of $92\\pm8$ K is derived from the $\\nu_3$ lines. This is\nin good agreement with the rotational temperature derived from pure rotational\nlines in the vibrational ground state (i.e., $\\nu=0$) with ALMA ($104\\pm5$ K).\nHowever, the emission of the $\\nu_3$ lines is not in LTE given that the total\nnumber of molecules predicted by a LTE model is found to be a factor\n$2\\times10^4$ higher than what is derived for the $\\nu=0$ state. This\ndifference can be explained by a vibrational temperature that is $\\sim100$ K\nhigher than the derived rotational temperature of the $\\nu=0$ state. The\nbrightness temperature derived from the continuum around the $\\nu_3$ band of\nSO$_2$ is $\\sim180$ K, which confirms that the $\\nu_3=1$ level is not\ncollisionally populated but rather infrared pumped by scattered radiation. This\nis also consistent with the non-detection of the $\\nu_2$ bending mode at 18-20\nmicron. Given the rotational temperature, the extent of the emission ($\\sim100$\nau in radius), and the narrow line widths in the ALMA data (3.5 km/s), the\nSO$_2$ in IRAS2A likely originates from ice sublimation in the central hot core\naround the protostar rather than from an accretion shock at the disk-envelope\nboundary.",
            "author": [
                "M. L. van Gelder",
                "M. E. Ressler",
                "E. F. van Dishoeck",
                "P. Nazari",
                "B. Tabone",
                "J. H. Black",
                "\u0141. Tychoniec",
                "L. Francis",
                "M. Barsony",
                "H. Beuther",
                "A. Caratti o Garatti",
                "Y. Chen",
                "C. Gieser",
                "V. J. M. le Gouellec",
                "P. J. Kavanagh",
                "P. D. Klaassen",
                "B. W. P. Lew",
                "H. Linnartz",
                "L. Majumdar",
                "G. Perotti",
                "W. R. M. Rocha"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17161v1",
                "http://arxiv.org/pdf/2311.17161v1"
            ],
            "primary_category": "astro-ph.SR",
            "category": [
                "astro-ph.SR",
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17157v1",
            "title": "Dark matter relic density in strongly interacting dark sectors with\n  light vector mesons",
            "updated": "2023-11-28T19:00:04Z",
            "published": "2023-11-28T19:00:04Z",
            "summary": "Stable dark matter particles may arise as pseudo-Goldstone bosons from the\nconfinement of dark quarks interacting via a non-Abelian gauge force. Their\nrelic abundance is determined not by annihilations into visible particles but\nby dark pion number-changing processes within the dark sector, such as $3 \\pi_D\n\\to 2 \\pi_D$. However, if the dark vector mesons $\\rho_D$ are light enough for\n$3 \\pi_D \\to \\pi_D \\rho_D$ annihilations to be kinematically allowed, this\nprocess dominates and significantly delays freeze-out. As a result, the\npreferred dark matter mass scale increases and bounds from the Bullet Cluster\ncan be evaded.",
            "author": [
                "Elias Bernreuther",
                "Nicoline Hemme",
                "Felix Kahlhoefer",
                "Suchita Kulkarni"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17157v1",
                "http://arxiv.org/pdf/2311.17157v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "astro-ph.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17154v1",
            "title": "Pragmatic Radiology Report Generation",
            "updated": "2023-11-28T19:00:03Z",
            "published": "2023-11-28T19:00:03Z",
            "summary": "When pneumonia is not found on a chest X-ray, should the report describe this\nnegative observation or omit it? We argue that this question cannot be answered\nfrom the X-ray alone and requires a pragmatic perspective, which captures the\ncommunicative goal that radiology reports serve between radiologists and\npatients. However, the standard image-to-text formulation for radiology report\ngeneration fails to incorporate such pragmatic intents. Following this\npragmatic perspective, we demonstrate that the indication, which describes why\na patient comes for an X-ray, drives the mentions of negative observations and\nintroduce indications as additional input to report generation. With respect to\nthe output, we develop a framework to identify uninferable information from the\nimage as a source of model hallucinations, and limit them by cleaning\ngroundtruth reports. Finally, we use indications and cleaned groundtruth\nreports to develop pragmatic models, and show that they outperform existing\nmethods not only in new pragmatics-inspired metrics (+4.3 Negative F1) but also\nin standard metrics (+6.3 Positive F1 and +11.0 BLEU-2).",
            "author": [
                "Dang Nguyen",
                "Chacha Chen",
                "He He",
                "Chenhao Tan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17154v1",
                "http://arxiv.org/pdf/2311.17154v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.CY",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17152v1",
            "title": "On the Quantum Bousso Bound in de Sitter JT gravity",
            "updated": "2023-11-28T19:00:02Z",
            "published": "2023-11-28T19:00:02Z",
            "summary": "We prove the validity of the Strominger-Thompson quantum Bousso bound in the\ninfinite class of conformal vacua of de Sitter space in semiclassical JT\ngravity. The Bousso-Fisher-Leichenauer-Wall quantum Bousso bound follows from\nan analogous derivation, requiring only initial quantum non-expansion. In this\nprocess, we show that the quantity ${2\\pi\nk^{\\mu}k^{\\nu}<:T_{\\mu\\nu}:>-S\"-\\frac{6}{c}(S')^2}$ vanishes in any vacuum\nstate, entailing a stronger version of Wall's quantum null energy condition. We\nderive an entropy formula in the presence of a generic class of two reflecting\nboundaries, in order to apply our argument to the half reduction model of de\nSitter JT gravity.",
            "author": [
                "Victor Franken",
                "Fran\u00e7ois Rondeau"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17152v1",
                "http://arxiv.org/pdf/2311.17152v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th",
                "gr-qc"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17937v1",
            "title": "Unlocking Spatial Comprehension in Text-to-Image Diffusion Models",
            "updated": "2023-11-28T19:00:02Z",
            "published": "2023-11-28T19:00:02Z",
            "summary": "We propose CompFuser, an image generation pipeline that enhances spatial\ncomprehension and attribute assignment in text-to-image generative models. Our\npipeline enables the interpretation of instructions defining spatial\nrelationships between objects in a scene, such as `An image of a gray cat on\nthe left of an orange dog', and generate corresponding images. This is\nespecially important in order to provide more control to the user. CompFuser\novercomes the limitation of existing text-to-image diffusion models by decoding\nthe generation of multiple objects into iterative steps: first generating a\nsingle object and then editing the image by placing additional objects in their\ndesignated positions. To create training data for spatial comprehension and\nattribute assignment we introduce a synthetic data generation process, that\nleverages a frozen large language model and a frozen layout-based diffusion\nmodel for object placement. We compare our approach to strong baselines and\nshow that our model outperforms state-of-the-art image generation models in\nspatial comprehension and attribute assignment, despite being 3x to 5x smaller\nin parameters.",
            "author": [
                "Mohammad Mahdi Derakhshani",
                "Menglin Xia",
                "Harkirat Behl",
                "Cees G. M. Snoek",
                "Victor R\u00fchle"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17937v1",
                "http://arxiv.org/pdf/2311.17937v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17139v1",
            "title": "Avoided metallicity in a hole-doped Mott insulator on a triangular\n  lattice",
            "updated": "2023-11-28T19:00:00Z",
            "published": "2023-11-28T19:00:00Z",
            "summary": "Charge carrier doping of a Mott insulator is known to give rise to a wide\nvariety of exotic emergent states, from high-temperature superconductivity to\nvarious charge, spin, and orbital orders. The physics underpinning their\nevolution is, however, poorly understood. A major challenge is the chemical\ncomplexity associated with traditional routes to the addition or removal of\ncarriers. Here, we study the Mott insulating CrO$_2$ layer of the delafossite\noxide PdCrO$_2$, where an intrinsic polar catastrophe provides a clean route to\ninduce substantial doping of the surface layer. Despite this, from scanning\ntunneling microscopy and angle-resolved photoemission, we find that the surface\nretains an insulating character, but with a modified electronic structure and\nthe development of a short-range ordered state with a distinct\n$(\\sqrt{7}\\times\\sqrt{7})\\mathrm{R}\\pm 19.1^\\circ$ periodicity. From density\nfunctional theory, we demonstrate how this reflects the formation of an\nintricate charge disproportionation that results in an insulating ground state\nof the surface layer that is disparate from the hidden Mott insulator found in\nthe bulk. By applying voltage pulses to the surface layer, we induce\nsubstantial local modifications to this state, which we find relax on a time\nscale of tens of minutes, pointing to a glassy nature of the\ncharge-disproportionated insulator realised here.",
            "author": [
                "Chi Ming Yim",
                "Gesa-R. Siemann",
                "Srdjan Stavri\u0107",
                "Seunghyun Khim",
                "Izidor Benedi\u010di\u010d",
                "Philip A. E. Murgatroyd",
                "Tommaso Antonelli",
                "Matthew D. Watson",
                "Andrew P. Mackenzie",
                "Silvia Picozzi",
                "Phil D. C. King",
                "Peter Wahl"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17139v1",
                "http://arxiv.org/pdf/2311.17139v1"
            ],
            "primary_category": "cond-mat.str-el",
            "category": [
                "cond-mat.str-el"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17148v2",
            "title": "Energy diffusion in weakly interacting chains with fermionic\n  dissipation-assisted operator evolution",
            "updated": "2023-12-01T17:14:37Z",
            "published": "2023-11-28T19:00:00Z",
            "summary": "Interacting lattice Hamiltonians at high temperature generically give rise to\nenergy transport governed by the classical diffusion equation; however,\npredicting the rate of diffusion requires numerical simulation of the\nmicroscopic quantum dynamics. For the purpose of predicting such transport\nproperties, computational time evolution methods must be paired with schemes to\ncontrol the growth of entanglement to tractably simulate for sufficiently long\ntimes. One such truncation scheme -- dissipation-assisted operator evolution\n(DAOE) -- controls entanglement by damping out components of operators with\nlarge Pauli weight. In this paper, we generalize DAOE to treat fermionic\nsystems. Our method instead damps out components of operators with large\nfermionic weight. We investigate the performance of DAOE, the new fermionic\nDAOE (FDAOE), and another simulation method, density matrix truncation (DMT),\nin simulating energy transport in an interacting one-dimensional Majorana\nchain. The chain is found to have a diffusion coefficient scaling like\ninteraction strength to the fourth power, contrary to naive expectations based\non Fermi's Golden rule -- but consistent with recent predictions based on the\ntheory of \\emph{weak integrability breaking}. In the weak interaction regime\nwhere the fermionic nature of the system is most relevant, FDAOE is found to\nsimulate the system more efficiently than DAOE.",
            "author": [
                "En-Jui Kuo",
                "Brayden Ware",
                "Peter Lunts",
                "Mohammad Hafezi",
                "Christopher David White"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17148v2",
                "http://arxiv.org/pdf/2311.17148v2"
            ],
            "primary_category": "cond-mat.str-el",
            "category": [
                "cond-mat.str-el",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17061v1",
            "title": "HumanGaussian: Text-Driven 3D Human Generation with Gaussian Splatting",
            "updated": "2023-11-28T18:59:58Z",
            "published": "2023-11-28T18:59:58Z",
            "summary": "Realistic 3D human generation from text prompts is a desirable yet\nchallenging task. Existing methods optimize 3D representations like mesh or\nneural fields via score distillation sampling (SDS), which suffers from\ninadequate fine details or excessive training time. In this paper, we propose\nan efficient yet effective framework, HumanGaussian, that generates\nhigh-quality 3D humans with fine-grained geometry and realistic appearance. Our\nkey insight is that 3D Gaussian Splatting is an efficient renderer with\nperiodic Gaussian shrinkage or growing, where such adaptive density control can\nbe naturally guided by intrinsic human structures. Specifically, 1) we first\npropose a Structure-Aware SDS that simultaneously optimizes human appearance\nand geometry. The multi-modal score function from both RGB and depth space is\nleveraged to distill the Gaussian densification and pruning process. 2)\nMoreover, we devise an Annealed Negative Prompt Guidance by decomposing SDS\ninto a noisier generative score and a cleaner classifier score, which well\naddresses the over-saturation issue. The floating artifacts are further\neliminated based on Gaussian size in a prune-only phase to enhance generation\nsmoothness. Extensive experiments demonstrate the superior efficiency and\ncompetitive quality of our framework, rendering vivid 3D humans under diverse\nscenarios. Project Page: https://alvinliu0.github.io/projects/HumanGaussian",
            "author": [
                "Xian Liu",
                "Xiaohang Zhan",
                "Jiaxiang Tang",
                "Ying Shan",
                "Gang Zeng",
                "Dahua Lin",
                "Xihui Liu",
                "Ziwei Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17061v1",
                "http://arxiv.org/pdf/2311.17061v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17056v1",
            "title": "Self-Supervised Motion Magnification by Backpropagating Through Optical\n  Flow",
            "updated": "2023-11-28T18:59:51Z",
            "published": "2023-11-28T18:59:51Z",
            "summary": "This paper presents a simple, self-supervised method for magnifying subtle\nmotions in video: given an input video and a magnification factor, we\nmanipulate the video such that its new optical flow is scaled by the desired\namount. To train our model, we propose a loss function that estimates the\noptical flow of the generated video and penalizes how far if deviates from the\ngiven magnification factor. Thus, training involves differentiating through a\npretrained optical flow network. Since our model is self-supervised, we can\nfurther improve its performance through test-time adaptation, by finetuning it\non the input video. It can also be easily extended to magnify the motions of\nonly user-selected objects. Our approach avoids the need for synthetic\nmagnification datasets that have been used to train prior learning-based\napproaches. Instead, it leverages the existing capabilities of off-the-shelf\nmotion estimators. We demonstrate the effectiveness of our method through\nevaluations of both visual quality and quantitative metrics on a range of\nreal-world and synthetic videos, and we show our method works for both\nsupervised and unsupervised optical flow methods.",
            "author": [
                "Zhaoying Pan",
                "Daniel Geng",
                "Andrew Owens"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17056v1",
                "http://arxiv.org/pdf/2311.17056v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17055v1",
            "title": "No Representation Rules Them All in Category Discovery",
            "updated": "2023-11-28T18:59:46Z",
            "published": "2023-11-28T18:59:46Z",
            "summary": "In this paper we tackle the problem of Generalized Category Discovery (GCD).\nSpecifically, given a dataset with labelled and unlabelled images, the task is\nto cluster all images in the unlabelled subset, whether or not they belong to\nthe labelled categories. Our first contribution is to recognize that most\nexisting GCD benchmarks only contain labels for a single clustering of the\ndata, making it difficult to ascertain whether models are using the available\nlabels to solve the GCD task, or simply solving an unsupervised clustering\nproblem. As such, we present a synthetic dataset, named 'Clevr-4', for category\ndiscovery. Clevr-4 contains four equally valid partitions of the data, i.e\nbased on object shape, texture, color or count. To solve the task, models are\nrequired to extrapolate the taxonomy specified by the labelled set, rather than\nsimply latching onto a single natural grouping of the data. We use this dataset\nto demonstrate the limitations of unsupervised clustering in the GCD setting,\nshowing that even very strong unsupervised models fail on Clevr-4. We further\nuse Clevr-4 to examine the weaknesses of existing GCD algorithms, and propose a\nnew method which addresses these shortcomings, leveraging consistent findings\nfrom the representation learning literature to do so. Our simple solution,\nwhich is based on 'mean teachers' and termed $\\mu$GCD, substantially\noutperforms implemented baselines on Clevr-4. Finally, when we transfer these\nfindings to real data on the challenging Semantic Shift Benchmark (SSB), we\nfind that $\\mu$GCD outperforms all prior work, setting a new state-of-the-art.\nFor the project webpage, see https://www.robots.ox.ac.uk/~vgg/data/clevr4/",
            "author": [
                "Sagar Vaze",
                "Andrea Vedaldi",
                "Andrew Zisserman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17055v1",
                "http://arxiv.org/pdf/2311.17055v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.IT",
                "cs.LG",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17137v1",
            "title": "Generative Models: What do they know? Do they know things? Let's find\n  out!",
            "updated": "2023-11-28T18:59:02Z",
            "published": "2023-11-28T18:59:02Z",
            "summary": "Generative models have been shown to be capable of synthesizing highly\ndetailed and realistic images. It is natural to suspect that they implicitly\nlearn to model some image intrinsics such as surface normals, depth, or\nshadows. In this paper, we present compelling evidence that generative models\nindeed internally produce high-quality scene intrinsic maps. We introduce\nIntrinsic LoRA (I LoRA), a universal, plug-and-play approach that transforms\nany generative model into a scene intrinsic predictor, capable of extracting\nintrinsic scene maps directly from the original generator network without\nneeding additional decoders or fully fine-tuning the original network. Our\nmethod employs a Low-Rank Adaptation (LoRA) of key feature maps, with newly\nlearned parameters that make up less than 0.6% of the total parameters in the\ngenerative model. Optimized with a small set of labeled images, our\nmodel-agnostic approach adapts to various generative architectures, including\nDiffusion models, GANs, and Autoregressive models. We show that the scene\nintrinsic maps produced by our method compare well with, and in some cases\nsurpass those generated by leading supervised techniques.",
            "author": [
                "Xiaodan Du",
                "Nicholas Kolkin",
                "Greg Shakhnarovich",
                "Anand Bhattad"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17137v1",
                "http://arxiv.org/pdf/2311.17137v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.GR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17053v1",
            "title": "DiffuseBot: Breeding Soft Robots With Physics-Augmented Generative\n  Diffusion Models",
            "updated": "2023-11-28T18:58:48Z",
            "published": "2023-11-28T18:58:48Z",
            "summary": "Nature evolves creatures with a high complexity of morphological and\nbehavioral intelligence, meanwhile computational methods lag in approaching\nthat diversity and efficacy. Co-optimization of artificial creatures'\nmorphology and control in silico shows promise for applications in physical\nsoft robotics and virtual character creation; such approaches, however, require\ndeveloping new learning algorithms that can reason about function atop pure\nstructure. In this paper, we present DiffuseBot, a physics-augmented diffusion\nmodel that generates soft robot morphologies capable of excelling in a wide\nspectrum of tasks. DiffuseBot bridges the gap between virtually generated\ncontent and physical utility by (i) augmenting the diffusion process with a\nphysical dynamical simulation which provides a certificate of performance, and\n(ii) introducing a co-design procedure that jointly optimizes physical design\nand control by leveraging information about physical sensitivities from\ndifferentiable simulation. We showcase a range of simulated and fabricated\nrobots along with their capabilities. Check our website at\nhttps://diffusebot.github.io/",
            "author": [
                "Tsun-Hsuan Wang",
                "Juntian Zheng",
                "Pingchuan Ma",
                "Yilun Du",
                "Byungchul Kim",
                "Andrew Spielberg",
                "Joshua Tenenbaum",
                "Chuang Gan",
                "Daniela Rus"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17053v1",
                "http://arxiv.org/pdf/2311.17053v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17050v1",
            "title": "Surf-D: High-Quality Surface Generation for Arbitrary Topologies using\n  Diffusion Models",
            "updated": "2023-11-28T18:56:01Z",
            "published": "2023-11-28T18:56:01Z",
            "summary": "In this paper, we present Surf-D, a novel method for generating high-quality\n3D shapes as Surfaces with arbitrary topologies using Diffusion models.\nSpecifically, we adopt Unsigned Distance Field (UDF) as the surface\nrepresentation, as it excels in handling arbitrary topologies, enabling the\ngeneration of complex shapes. While the prior methods explored shape generation\nwith different representations, they suffer from limited topologies and\ngeometry details. Moreover, it's non-trivial to directly extend prior diffusion\nmodels to UDF because they lack spatial continuity due to the discrete volume\nstructure. However, UDF requires accurate gradients for mesh extraction and\nlearning. To tackle the issues, we first leverage a point-based auto-encoder to\nlearn a compact latent space, which supports gradient querying for any input\npoint through differentiation to effectively capture intricate geometry at a\nhigh resolution. Since the learning difficulty for various shapes can differ, a\ncurriculum learning strategy is employed to efficiently embed various surfaces,\nenhancing the whole embedding process. With pretrained shape latent space, we\nemploy a latent diffusion model to acquire the distribution of various shapes.\nOur approach demonstrates superior performance in shape generation across\nmultiple modalities and conducts extensive experiments in unconditional\ngeneration, category conditional generation, 3D reconstruction from images, and\ntext-to-shape tasks.",
            "author": [
                "Zhengming Yu",
                "Zhiyang Dou",
                "Xiaoxiao Long",
                "Cheng Lin",
                "Zekun Li",
                "Yuan Liu",
                "Norman M\u00fcller",
                "Taku Komura",
                "Marc Habermann",
                "Christian Theobalt",
                "Xin Li",
                "Wenping Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17050v1",
                "http://arxiv.org/pdf/2311.17050v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17136v1",
            "title": "UniIR: Training and Benchmarking Universal Multimodal Information\n  Retrievers",
            "updated": "2023-11-28T18:55:52Z",
            "published": "2023-11-28T18:55:52Z",
            "summary": "Existing information retrieval (IR) models often assume a homogeneous format,\nlimiting their applicability to diverse user needs, such as searching for\nimages with text descriptions, searching for a news article with a headline\nimage, or finding a similar photo with a query image. To approach such\ndifferent information-seeking demands, we introduce UniIR, a unified\ninstruction-guided multimodal retriever capable of handling eight distinct\nretrieval tasks across modalities. UniIR, a single retrieval system jointly\ntrained on ten diverse multimodal-IR datasets, interprets user instructions to\nexecute various retrieval tasks, demonstrating robust performance across\nexisting datasets and zero-shot generalization to new tasks. Our experiments\nhighlight that multi-task training and instruction tuning are keys to UniIR's\ngeneralization ability. Additionally, we construct the M-BEIR, a multimodal\nretrieval benchmark with comprehensive results, to standardize the evaluation\nof universal multimodal information retrieval.",
            "author": [
                "Cong Wei",
                "Yang Chen",
                "Haonan Chen",
                "Hexiang Hu",
                "Ge Zhang",
                "Jie Fu",
                "Alan Ritter",
                "Wenhu Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17136v1",
                "http://arxiv.org/pdf/2311.17136v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17049v1",
            "title": "MobileCLIP: Fast Image-Text Models through Multi-Modal Reinforced\n  Training",
            "updated": "2023-11-28T18:55:42Z",
            "published": "2023-11-28T18:55:42Z",
            "summary": "Contrastive pretraining of image-text foundation models, such as CLIP,\ndemonstrated excellent zero-shot performance and improved robustness on a wide\nrange of downstream tasks. However, these models utilize large\ntransformer-based encoders with significant memory and latency overhead which\npose challenges for deployment on mobile devices. In this work, we introduce\nMobileCLIP -- a new family of efficient image-text models optimized for runtime\nperformance along with a novel and efficient training approach, namely\nmulti-modal reinforced training. The proposed training approach leverages\nknowledge transfer from an image captioning model and an ensemble of strong\nCLIP encoders to improve the accuracy of efficient models. Our approach avoids\ntrain-time compute overhead by storing the additional knowledge in a reinforced\ndataset. MobileCLIP sets a new state-of-the-art latency-accuracy tradeoff for\nzero-shot classification and retrieval tasks on several datasets. Our\nMobileCLIP-S2 variant is 2.3$\\times$ faster while more accurate compared to\nprevious best CLIP model based on ViT-B/16. We further demonstrate the\neffectiveness of our multi-modal reinforced training by training a CLIP model\nbased on ViT-B/16 image backbone and achieving +2.9% average performance\nimprovement on 38 evaluation benchmarks compared to the previous best.\nMoreover, we show that the proposed approach achieves 10$\\times$-1000$\\times$\nimproved learning efficiency when compared with non-reinforced CLIP training.",
            "author": [
                "Pavan Kumar Anasosalu Vasu",
                "Hadi Pouransari",
                "Fartash Faghri",
                "Raviteja Vemulapalli",
                "Oncel Tuzel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17049v1",
                "http://arxiv.org/pdf/2311.17049v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17048v1",
            "title": "Zero-shot Referring Expression Comprehension via Structural Similarity\n  Between Images and Captions",
            "updated": "2023-11-28T18:55:37Z",
            "published": "2023-11-28T18:55:37Z",
            "summary": "Zero-shot referring expression comprehension aims at localizing bounding\nboxes in an image corresponding to the provided textual prompts, which\nrequires: (i) a fine-grained disentanglement of complex visual scene and\ntextual context, and (ii) a capacity to understand relationships among\ndisentangled entities. Unfortunately, existing large vision-language alignment\n(VLA) models, e.g., CLIP, struggle with both aspects so cannot be directly used\nfor this task. To mitigate this gap, we leverage large foundation models to\ndisentangle both images and texts into triplets in the format of (subject,\npredicate, object). After that, grounding is accomplished by calculating the\nstructural similarity matrix between visual and textual triplets with a VLA\nmodel, and subsequently propagate it to an instance-level similarity matrix.\nFurthermore, to equip VLA models with the ability of relationship\nunderstanding, we design a triplet-matching objective to fine-tune the VLA\nmodels on a collection of curated dataset containing abundant entity\nrelationships. Experiments demonstrate that our visual grounding performance\nincrease of up to 19.5% over the SOTA zero-shot model on RefCOCO/+/g. On the\nmore challenging Who's Waldo dataset, our zero-shot approach achieves\ncomparable accuracy to the fully supervised model.",
            "author": [
                "Zeyu Han",
                "Fangrui Zhu",
                "Qianru Lao",
                "Huaizu Jiang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17048v1",
                "http://arxiv.org/pdf/2311.17048v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17135v2",
            "title": "TLControl: Trajectory and Language Control for Human Motion Synthesis",
            "updated": "2023-11-30T20:36:16Z",
            "published": "2023-11-28T18:54:16Z",
            "summary": "Controllable human motion synthesis is essential for applications in AR/VR,\ngaming, movies, and embodied AI. Existing methods often focus solely on either\nlanguage or full trajectory control, lacking precision in synthesizing motions\naligned with user-specified trajectories, especially for multi-joint control.\nTo address these issues, we present TLControl, a new method for realistic human\nmotion synthesis, incorporating both low-level trajectory and high-level\nlanguage semantics controls. Specifically, we first train a VQ-VAE to learn a\ncompact latent motion space organized by body parts. We then propose a Masked\nTrajectories Transformer to make coarse initial predictions of full\ntrajectories of joints based on the learned latent motion space, with\nuser-specified partial trajectories and text descriptions as conditioning.\nFinally, we introduce an efficient test-time optimization to refine these\ncoarse predictions for accurate trajectory control. Experiments demonstrate\nthat TLControl outperforms the state-of-the-art in trajectory accuracy and time\nefficiency, making it practical for interactive and high-quality animation\ngeneration.",
            "author": [
                "Weilin Wan",
                "Zhiyang Dou",
                "Taku Komura",
                "Wenping Wang",
                "Dinesh Jayaraman",
                "Lingjie Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17135v2",
                "http://arxiv.org/pdf/2311.17135v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17043v1",
            "title": "LLaMA-VID: An Image is Worth 2 Tokens in Large Language Models",
            "updated": "2023-11-28T18:53:43Z",
            "published": "2023-11-28T18:53:43Z",
            "summary": "In this work, we present a novel method to tackle the token generation\nchallenge in Vision Language Models (VLMs) for video and image understanding,\ncalled LLaMA-VID. Current VLMs, while proficient in tasks like image captioning\nand visual question answering, face computational burdens when processing long\nvideos due to the excessive visual tokens. LLaMA-VID addresses this issue by\nrepresenting each frame with two distinct tokens, namely context token and\ncontent token. The context token encodes the overall image context based on\nuser input, whereas the content token encapsulates visual cues in each frame.\nThis dual-token strategy significantly reduces the overload of long videos\nwhile preserving critical information. Generally, LLaMA-VID empowers existing\nframeworks to support hour-long videos and pushes their upper limit with an\nextra context token. It is proved to surpass previous methods on most of video-\nor image-based benchmarks. Code is available\nhttps://github.com/dvlab-research/LLaMA-VID}{https://github.com/dvlab-research/LLaMA-VID",
            "author": [
                "Yanwei Li",
                "Chengyao Wang",
                "Jiaya Jia"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17043v1",
                "http://arxiv.org/pdf/2311.17043v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17041v2",
            "title": "Efficient In-Context Learning in Vision-Language Models for Egocentric\n  Videos",
            "updated": "2023-11-29T15:52:55Z",
            "published": "2023-11-28T18:53:06Z",
            "summary": "Recent advancements in text-only large language models (LLMs) have\nhighlighted the benefit of in-context learning for adapting to new tasks with a\nfew demonstrations. However, extending in-context learning to large\nvision-language models (VLMs) using a huge amount of naturalistic\nvision-language data has shown limited success, particularly for egocentric\nvideos, due to high data collection costs. We propose a novel training method\n$\\mathbb{E}$fficient $\\mathbb{I}$n-context $\\mathbb{L}$earning on\n$\\mathbb{E}$gocentric $\\mathbb{V}$ideos ($\\mathbb{EILEV}$), which elicits\nin-context learning in VLMs for egocentric videos without requiring massive,\nnaturalistic egocentric video datasets. $\\mathbb{EILEV}$ involves architectural\nand training data adaptations to allow the model to process contexts\ninterleaved with video clips and narrations, sampling of in-context examples\nwith clusters of similar verbs and nouns, use of data with skewed marginal\ndistributions with a long tail of infrequent verbs and nouns, as well as\nhomonyms and synonyms. Our evaluations show that $\\mathbb{EILEV}$-trained\nmodels outperform larger VLMs trained on a huge amount of naturalistic data in\nin-context learning. Furthermore, they can generalize to not only\nout-of-distribution, but also novel, rare egocentric videos and texts via\nin-context learning, demonstrating potential for applications requiring\ncost-effective training, and rapid post-deployment adaptability. Our code and\ndemo are available at \\url{https://github.com/yukw777/EILEV}.",
            "author": [
                "Keunwoo Peter Yu",
                "Zheyuan Zhang",
                "Fengyuan Hu",
                "Joyce Chai"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17041v2",
                "http://arxiv.org/pdf/2311.17041v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17040v1",
            "title": "Rumors with Changing Credibility",
            "updated": "2023-11-28T18:52:38Z",
            "published": "2023-11-28T18:52:38Z",
            "summary": "Randomized rumor spreading processes diffuse information on an undirected\ngraph and have been widely studied. In this work, we present a generic\nframework for analyzing a broad class of such processes on regular graphs. Our\nanalysis is protocol-agnostic, as it only requires the expected proportion of\nnewly informed vertices in each round to be bounded, and a natural negative\ncorrelation property.\n  This framework allows us to analyze various protocols, including PUSH, PULL,\nand PUSH-PULL, thereby extending prior research. Unlike previous work, our\nframework accommodates message failures at any time $t\\geq 0$ with a\nprobability of $1-q(t)$, where the credibility $q(t)$ is any function of time.\nThis enables us to model real-world scenarios in which the transmissibility of\nrumors may fluctuate, as seen in the spread of ``fake news'' and viruses.\nAdditionally, our framework is sufficiently broad to cover dynamic graphs.",
            "author": [
                "Charlotte Out",
                "Nicol\u00e1s Rivera",
                "Thomas Sauerwald",
                "John Sylvester"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17040v1",
                "http://arxiv.org/pdf/2311.17040v1"
            ],
            "primary_category": "cs.DM",
            "category": [
                "cs.DM",
                "cs.DC",
                "math.CO",
                "math.PR",
                "05C85, 68R10"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17039v1",
            "title": "Optimal control of interacting active particles on complex landscapes",
            "updated": "2023-11-28T18:50:23Z",
            "published": "2023-11-28T18:50:23Z",
            "summary": "Active many-body systems composed of many interacting degrees of freedom\noften operate out of equilibrium, giving rise to non-trivial emergent behaviors\nwhich can be functional in both evolved and engineered contexts. This naturally\nsuggests the question of control to optimize function. Using navigation as a\nparadigm for function, we deploy the language of stochastic optimal control\ntheory to formulate the inverse problem of shepherding a system of interacting\nactive particles across a complex landscape. We implement a solution to this\nhigh-dimensional problem using an Adjoint-based Path Integral Control (APIC)\nalgorithm that combines the power of recently introduced continuous-time\nback-propagation methods and automatic differentiation with the classical\nFeynman-Kac path integral formulation in statistical mechanics. Numerical\nexperiments for controlling individual and interacting particles in complex\nlandscapes show different classes of successful navigation strategies as a\nfunction of landscape complexity, as well as the intrinsic noise and drive of\nthe active particles. However, in all cases, we see the emergence of paths that\ncorrespond to traversal along the edges of ridges and ravines, which we can\nunderstand using a variational analysis. We also show that the work associated\nwith optimal strategies is inversely proportional to the length of the time\nhorizon of optimal control, a result that follows from scaling considerations.\nAll together, our approach serves as a foundational framework to control active\nnon-equilibrium systems optimally to achieve functionality, embodied as a path\non a high-dimensional manifold.",
            "author": [
                "Sumit Sinha",
                "Vishaal Krishnan",
                "L Mahadevan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17039v1",
                "http://arxiv.org/pdf/2311.17039v1"
            ],
            "primary_category": "cond-mat.soft",
            "category": [
                "cond-mat.soft",
                "cond-mat.dis-nn",
                "cond-mat.other",
                "cond-mat.stat-mech"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17037v1",
            "title": "Concurrent Stochastic Lossy Channel Games",
            "updated": "2023-11-28T18:49:14Z",
            "published": "2023-11-28T18:49:14Z",
            "summary": "Concurrent stochastic games are an important formalism for the rational\nverification of probabilistic multi-agent systems, which involves verifying\nwhether a temporal logic property is satisfied in some or all game-theoretic\nequilibria of such systems. In this work, we study the rational verification of\nprobabilistic multi-agent systems where agents can cooperate by communicating\nover unbounded lossy channels. To model such systems, we present concurrent\nstochastic lossy channel games (CSLCG) and employ an equilibrium concept from\ncooperative game theory known as the core, which is the most fundamental and\nwidely studied cooperative equilibrium concept. Our main contribution is\ntwofold. First, we show that the rational verification problem is undecidable\nfor systems whose agents have almost-sure LTL objectives. Second, we provide a\ndecidable fragment of such a class of objectives that subsumes almost-sure\nreachability and safety. Our techniques involve reductions to solving\ninfinite-state zero-sum games with conjunctions of qualitative objectives. To\nthe best of our knowledge, our result represents the first decidability result\non the rational verification of stochastic multi-agent systems on infinite\narenas.",
            "author": [
                "Daniel Stan",
                "Muhammad Najib",
                "Anthony Widjaja Lin",
                "Parosh Aziz Abdulla"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17037v1",
                "http://arxiv.org/pdf/2311.17037v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT",
                "cs.FL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17035v1",
            "title": "Scalable Extraction of Training Data from (Production) Language Models",
            "updated": "2023-11-28T18:47:03Z",
            "published": "2023-11-28T18:47:03Z",
            "summary": "This paper studies extractable memorization: training data that an adversary\ncan efficiently extract by querying a machine learning model without prior\nknowledge of the training dataset. We show an adversary can extract gigabytes\nof training data from open-source language models like Pythia or GPT-Neo,\nsemi-open models like LLaMA or Falcon, and closed models like ChatGPT. Existing\ntechniques from the literature suffice to attack unaligned models; in order to\nattack the aligned ChatGPT, we develop a new divergence attack that causes the\nmodel to diverge from its chatbot-style generations and emit training data at a\nrate 150x higher than when behaving properly. Our methods show practical\nattacks can recover far more data than previously thought, and reveal that\ncurrent alignment techniques do not eliminate memorization.",
            "author": [
                "Milad Nasr",
                "Nicholas Carlini",
                "Jonathan Hayase",
                "Matthew Jagielski",
                "A. Feder Cooper",
                "Daphne Ippolito",
                "Christopher A. Choquette-Choo",
                "Eric Wallace",
                "Florian Tram\u00e8r",
                "Katherine Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17035v1",
                "http://arxiv.org/pdf/2311.17035v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17034v1",
            "title": "Telling Left from Right: Identifying Geometry-Aware Semantic\n  Correspondence",
            "updated": "2023-11-28T18:45:13Z",
            "published": "2023-11-28T18:45:13Z",
            "summary": "While pre-trained large-scale vision models have shown significant promise\nfor semantic correspondence, their features often struggle to grasp the\ngeometry and orientation of instances. This paper identifies the importance of\nbeing geometry-aware for semantic correspondence and reveals a limitation of\nthe features of current foundation models under simple post-processing. We show\nthat incorporating this information can markedly enhance semantic\ncorrespondence performance with simple but effective solutions in both\nzero-shot and supervised settings. We also construct a new challenging\nbenchmark for semantic correspondence built from an existing animal pose\nestimation dataset, for both pre-training validating models. Our method\nachieves a PCK@0.10 score of 64.2 (zero-shot) and 85.6 (supervised) on the\nchallenging SPair-71k dataset, outperforming the state-of-the-art by 4.3p and\n11.0p absolute gains, respectively. Our code and datasets will be publicly\navailable.",
            "author": [
                "Junyi Zhang",
                "Charles Herrmann",
                "Junhwa Hur",
                "Eric Chen",
                "Varun Jampani",
                "Deqing Sun",
                "Ming-Hsuan Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17034v1",
                "http://arxiv.org/pdf/2311.17034v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17030v2",
            "title": "Is This the Subspace You Are Looking for? An Interpretability Illusion\n  for Subspace Activation Patching",
            "updated": "2023-12-06T14:28:46Z",
            "published": "2023-11-28T18:32:19Z",
            "summary": "Mechanistic interpretability aims to understand model behaviors in terms of\nspecific, interpretable features, often hypothesized to manifest as\nlow-dimensional subspaces of activations. Specifically, recent studies have\nexplored subspace interventions (such as activation patching) as a way to\nsimultaneously manipulate model behavior and attribute the features behind it\nto given subspaces.\n  In this work, we demonstrate that these two aims diverge, potentially leading\nto an illusory sense of interpretability. Counterintuitively, even if a\nsubspace intervention makes the model's output behave as if the value of a\nfeature was changed, this effect may be achieved by activating a dormant\nparallel pathway leveraging another subspace that is causally disconnected from\nmodel outputs. We demonstrate this phenomenon in a distilled mathematical\nexample, in two real-world domains (the indirect object identification task and\nfactual recall), and present evidence for its prevalence in practice. In the\ncontext of factual recall, we further show a link to rank-1 fact editing,\nproviding a mechanistic explanation for previous work observing an\ninconsistency between fact editing performance and fact localization.\n  However, this does not imply that activation patching of subspaces is\nintrinsically unfit for interpretability. To contextualize our findings, we\nalso show what a success case looks like in a task (indirect object\nidentification) where prior manual circuit analysis informs an understanding of\nthe location of a feature. We explore the additional evidence needed to argue\nthat a patched subspace is faithful.",
            "author": [
                "Aleksandar Makelov",
                "Georg Lange",
                "Neel Nanda"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17030v2",
                "http://arxiv.org/pdf/2311.17030v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17027v1",
            "title": "NLO electroweak corrections to doubly-polarized $W^+W^-$ production at\n  the LHC",
            "updated": "2023-11-28T18:30:31Z",
            "published": "2023-11-28T18:30:31Z",
            "summary": "We present new results of next-to-leading order (NLO) electroweak corrections\nto doubly-polarized cross sections of $W^+W^-$ production at the LHC. The\ncalculation is performed for the leptonic final state of $e^+\\mu_e \\mu^-\n\\bar{\\nu}_\\mu$ using the double-pole approximation in the diboson\ncenter-of-mass frame. NLO QCD corrections and subleading contributions from the\n$gg$, $b\\bar{b}$, $\\gamma\\gamma$ induced processes are taken into account in\nthe numerical results. We found that NLO EW corrections are small for angular\ndistributions but can reach tens of percent for transverse momentum\ndistributions at high energies, e.g. reaching $-40\\%$ at $p_{T,e}\\approx 300$\nGeV. In these high $p_T$ regions, EW corrections are largest for the\ndoubly-transverse mode.",
            "author": [
                "Thi Nhung Dao",
                "Duc Ninh Le"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17027v1",
                "http://arxiv.org/pdf/2311.17027v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17024v1",
            "title": "Diffusion 3D Features (Diff3F): Decorating Untextured Shapes with\n  Distilled Semantic Features",
            "updated": "2023-11-28T18:27:15Z",
            "published": "2023-11-28T18:27:15Z",
            "summary": "We present Diff3F as a simple, robust, and class-agnostic feature descriptor\nthat can be computed for untextured input shapes (meshes or point clouds). Our\nmethod distills diffusion features from image foundational models onto input\nshapes. Specifically, we use the input shapes to produce depth and normal maps\nas guidance for conditional image synthesis, and in the process produce\n(diffusion) features in 2D that we subsequently lift and aggregate on the\noriginal surface. Our key observation is that even if the conditional image\ngenerations obtained from multi-view rendering of the input shapes are\ninconsistent, the associated image features are robust and can be directly\naggregated across views. This produces semantic features on the input shapes,\nwithout requiring additional data or training. We perform extensive experiments\non multiple benchmarks (SHREC'19, SHREC'20, and TOSCA) and demonstrate that our\nfeatures, being semantic instead of geometric, produce reliable correspondence\nacross both isometeric and non-isometrically related shape families.",
            "author": [
                "Niladri Shekhar Dutt",
                "Sanjeev Muralikrishnan",
                "Niloy J. Mitra"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17024v1",
                "http://arxiv.org/pdf/2311.17024v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17025v1",
            "title": "Automorphisms of the procongruence pants complex",
            "updated": "2023-11-28T18:27:15Z",
            "published": "2023-11-28T18:27:15Z",
            "summary": "We show that every automorphism of the congruence completion of the extended\nmapping class group which preserves the set of conjugacy classes of procyclic\ngroups generated by Dehn twists is inner and that their automorphism group is\nnaturally isomorphic to the automorphism group of the procongruence pants\ncomplex. In the genus $0$ case, we prove the stronger result that all\nautomorphism of the profinite completion of the extended mapping class group\nare inner.",
            "author": [
                "Marco Boggi",
                "Louis Funar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17025v1",
                "http://arxiv.org/pdf/2311.17025v1"
            ],
            "primary_category": "math.GT",
            "category": [
                "math.GT",
                "math.AG",
                "math.GR",
                "14G32, 11R32, 14D23, 20F34, 57M10"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.03741v1",
            "title": "Comparing Generative Chatbots Based on Process Requirements",
            "updated": "2023-11-28T18:25:22Z",
            "published": "2023-11-28T18:25:22Z",
            "summary": "Business processes are commonly represented by modelling languages, such as\nEvent-driven Process Chain (EPC), Yet Another Workflow Language (YAWL), and the\nmost popular standard notation for modelling business processes, the Business\nProcess Model and Notation (BPMN). Most recently, chatbots, programs that allow\nusers to interact with a machine using natural language, have been increasingly\nused for business process execution support. A recent category of chatbots\nworth mentioning is generative-based chatbots, powered by Large Language Models\n(LLMs) such as OpenAI's Generative Pre-Trained Transformer (GPT) model and\nGoogle's Pathways Language Model (PaLM), which are trained on billions of\nparameters and support conversational intelligence. However, it is not clear\nwhether generative-based chatbots are able to understand and meet the\nrequirements of constructs such as those provided by BPMN for process execution\nsupport. This paper presents a case study to compare the performance of\nprominent generative models, GPT and PaLM, in the context of process execution\nsupport. The research sheds light into the challenging problem of using\nconversational approaches supported by generative chatbots as a means to\nunderstand process-aware modelling notations and support users to execute their\ntasks.",
            "author": [
                "Luis Fernando Lins",
                "Nathalia Nascimento",
                "Paulo Alencar",
                "Toacy Oliveira",
                "Donald Cowan"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03741v1",
                "http://arxiv.org/pdf/2312.03741v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17019v1",
            "title": "Homogeneous Algebraic Complexity Theory and Algebraic Formulas",
            "updated": "2023-11-28T18:17:28Z",
            "published": "2023-11-28T18:17:28Z",
            "summary": "We study algebraic complexity classes and their complete polynomials under\n\\emph{homogeneous linear} projections, not just under the usual affine linear\nprojections that were originally introduced by Valiant in 1979. These\nreductions are weaker yet more natural from a geometric complexity theory (GCT)\nstandpoint, because the corresponding orbit closure formulations do not require\nthe padding of polynomials. We give the \\emph{first} complete polynomials for\nVF, the class of sequences of polynomials that admit small algebraic formulas,\nunder homogeneous linear projections: The sum of the entries of the\nnon-commutative elementary symmetric polynomial in 3 by 3 matrices of\nhomogeneous linear forms.\n  Even simpler variants of the elementary symmetric polynomial are hard for the\ntopological closure of a large subclass of VF: the sum of the entries of the\nnon-commutative elementary symmetric polynomial in 2 by 2 matrices of\nhomogeneous linear forms, and homogeneous variants of the continuant polynomial\n(Bringmann, Ikenmeyer, Zuiddam, JACM '18). This requires a careful study of\ncircuits with arity-3 product gates.",
            "author": [
                "Pranjal Dutta",
                "Fulvio Gesmundo",
                "Christian Ikenmeyer",
                "Gorav Jindal",
                "Vladimir Lysikov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17019v1",
                "http://arxiv.org/pdf/2311.17019v1"
            ],
            "primary_category": "cs.CC",
            "category": [
                "cs.CC",
                "math.AG",
                "68Qxx",
                "F.1.3"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17017v1",
            "title": "Foundational Moral Values for AI Alignment",
            "updated": "2023-11-28T18:11:24Z",
            "published": "2023-11-28T18:11:24Z",
            "summary": "Solving the AI alignment problem requires having clear, defensible values\ntowards which AI systems can align. Currently, targets for alignment remain\nunderspecified and do not seem to be built from a philosophically robust\nstructure. We begin the discussion of this problem by presenting five core,\nfoundational values, drawn from moral philosophy and built on the requisites\nfor human existence: survival, sustainable intergenerational existence,\nsociety, education, and truth. We show that these values not only provide a\nclearer direction for technical alignment work, but also serve as a framework\nto highlight threats and opportunities from AI systems to both obtain and\nsustain these values.",
            "author": [
                "Betty Li Hou",
                "Brian Patrick Green"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17017v1",
                "http://arxiv.org/pdf/2311.17017v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17015v1",
            "title": "Regge constraints on local four-point scattering amplitudes of massive\n  particles with spin",
            "updated": "2023-11-28T18:09:31Z",
            "published": "2023-11-28T18:09:31Z",
            "summary": "In this work, we classify all the possible local four-point couplings\nrelevant for tree-level flat space $2 \\rightarrow 2$ scattering of external\nmassive particles of spin one and spin two which do not grow faster than $s^2$\nat large $s$ and fixed t. This kinematic constraint on local growth of\ntree-level S-matrices is known as Classical Regge Growth criteria or CRG. We\nfirst construct the spin one and spin two tree-level contact S-matrices as\nmodules of polarisation tensors and momenta over the ring of polynomials\ngenerated by Mandelstam invariants. We then consider a general scattering\nprocess where the external scattering particles are of different masses but of\nsame spin and constrain this space to obtain a finite number of CRG allowed\nlocal Lagrangians. Our concrete results are primarily for $D\\geq 8$ but the\nprocess outlined is easily generalised to lower dimensions to include low\ndimensional parity violating structures. The space of CRG allowed structures\nreduces when we specialise to identical scattering and restrict to parity even\ncouplings in $D=4$. We show that tree-level scattering amplitudes involving\nexchange diagrams and contact terms in de Rham-Gabadadze-Tolley massive gravity\n(dRGT) violate CRG unless the parameters of the theory take special values. The\nCRG allowed S-matrices, in the context of large $N$ conformal field theories\n(CFTs), can also be interpreted as bulk $AdS$ counterterms consistent with\nChaos bound. Our classified structures therefore can be thought of as\nambiguities arising in the context of conformal field theory inversion formula\nfor four point functions of unconserved spin one and spin two operators in\nlarge $N$ CFTs.",
            "author": [
                "Subham Dutta Chowdhury",
                "Vipul Kumar",
                "Suman Kundu",
                "Asikur Rahaman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17015v1",
                "http://arxiv.org/pdf/2311.17015v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th",
                "gr-qc"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17013v2",
            "title": "Superradiance Termination: The Cloud Strikes Back",
            "updated": "2023-12-06T17:09:50Z",
            "published": "2023-11-28T18:08:03Z",
            "summary": "A superradiant cloud of ultralight bosons near a rotating black hole provides\na smoking gun for particle physics in the infrared. However, tidal\nperturbations from a nearby binary companion can destabilise the boson cloud\nand even terminate superradiance. In this work, we consider the backreaction of\nsuperradiance termination to the dynamics of general binary orbits parametrised\nby their semi-latus rectum, eccentricity and inclination angle. Our analysis\nfocuses on Extreme Mass Ratio Inspiral (EMRI) systems and employs the\nperiod-average approximation to derive evolution equations of these binary\nparameters in the Newtonian limit. We find that the binary evolution history\ncan be significantly modulated by the backreaction towards large circular\nequatorial orbits with reduced termination rate. This process can generically\nhappen even away from the resonance bands. Our work therefore serves as a first\nstep towards probing ultralight bosons through the statistics of EMRI binary\nparameters in the future.",
            "author": [
                "Kaiyuan Fan",
                "Xi Tong",
                "Yi Wang",
                "Hui-Yu Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17013v2",
                "http://arxiv.org/pdf/2311.17013v2"
            ],
            "primary_category": "gr-qc",
            "category": [
                "gr-qc",
                "astro-ph.HE",
                "hep-ph",
                "hep-th"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17009v2",
            "title": "Space-Time Diffusion Features for Zero-Shot Text-Driven Motion Transfer",
            "updated": "2023-12-03T12:30:05Z",
            "published": "2023-11-28T18:03:27Z",
            "summary": "We present a new method for text-driven motion transfer - synthesizing a\nvideo that complies with an input text prompt describing the target objects and\nscene while maintaining an input video's motion and scene layout. Prior methods\nare confined to transferring motion across two subjects within the same or\nclosely related object categories and are applicable for limited domains (e.g.,\nhumans). In this work, we consider a significantly more challenging setting in\nwhich the target and source objects differ drastically in shape and\nfine-grained motion characteristics (e.g., translating a jumping dog into a\ndolphin). To this end, we leverage a pre-trained and fixed text-to-video\ndiffusion model, which provides us with generative and motion priors. The\npillar of our method is a new space-time feature loss derived directly from the\nmodel. This loss guides the generation process to preserve the overall motion\nof the input video while complying with the target object in terms of shape and\nfine-grained motion traits.",
            "author": [
                "Danah Yatim",
                "Rafail Fridman",
                "Omer Bar-Tal",
                "Yoni Kasten",
                "Tali Dekel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17009v2",
                "http://arxiv.org/pdf/2311.17009v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17132v1",
            "title": "TransNeXt: Robust Foveal Visual Perception for Vision Transformers",
            "updated": "2023-11-28T18:03:27Z",
            "published": "2023-11-28T18:03:27Z",
            "summary": "Due to the depth degradation effect in residual connections, many efficient\nVision Transformers models that rely on stacking layers for information\nexchange often fail to form sufficient information mixing, leading to unnatural\nvisual perception. To address this issue, in this paper, we propose Aggregated\nAttention, a biomimetic design-based token mixer that simulates biological\nfoveal vision and continuous eye movement while enabling each token on the\nfeature map to have a global perception. Furthermore, we incorporate learnable\ntokens that interact with conventional queries and keys, which further\ndiversifies the generation of affinity matrices beyond merely relying on the\nsimilarity between queries and keys. Our approach does not rely on stacking for\ninformation exchange, thus effectively avoiding depth degradation and achieving\nnatural visual perception. Additionally, we propose Convolutional GLU, a\nchannel mixer that bridges the gap between GLU and SE mechanism, which empowers\neach token to have channel attention based on its nearest neighbor image\nfeatures, enhancing local modeling capability and model robustness. We combine\naggregated attention and convolutional GLU to create a new visual backbone\ncalled TransNeXt. Extensive experiments demonstrate that our TransNeXt achieves\nstate-of-the-art performance across multiple model sizes. At a resolution of\n$224^2$, TransNeXt-Tiny attains an ImageNet accuracy of 84.0%, surpassing\nConvNeXt-B with 69% fewer parameters. Our TransNeXt-Base achieves an ImageNet\naccuracy of 86.2% and an ImageNet-A accuracy of 61.6% at a resolution of\n$384^2$, a COCO object detection mAP of 57.1, and an ADE20K semantic\nsegmentation mIoU of 54.7.",
            "author": [
                "Dai Shi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17132v1",
                "http://arxiv.org/pdf/2311.17132v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17007v1",
            "title": "Computational Hypergraph Discovery, a Gaussian Process framework for\n  connecting the dots",
            "updated": "2023-11-28T18:02:06Z",
            "published": "2023-11-28T18:02:06Z",
            "summary": "Most scientific challenges can be framed into one of the following three\nlevels of complexity of function approximation. Type 1: Approximate an unknown\nfunction given input/output data. Type 2: Consider a collection of variables\nand functions, some of which are unknown, indexed by the nodes and hyperedges\nof a hypergraph (a generalized graph where edges can connect more than two\nvertices). Given partial observations of the variables of the hypergraph\n(satisfying the functional dependencies imposed by its structure), approximate\nall the unobserved variables and unknown functions. Type 3: Expanding on Type\n2, if the hypergraph structure itself is unknown, use partial observations of\nthe variables of the hypergraph to discover its structure and approximate its\nunknown functions. While most Computational Science and Engineering and\nScientific Machine Learning challenges can be framed as Type 1 and Type 2\nproblems, many scientific problems can only be categorized as Type 3. Despite\ntheir prevalence, these Type 3 challenges have been largely overlooked due to\ntheir inherent complexity. Although Gaussian Process (GP) methods are sometimes\nperceived as well-founded but old technology limited to Type 1 curve fitting,\ntheir scope has recently been expanded to Type 2 problems. In this paper, we\nintroduce an interpretable GP framework for Type 3 problems, targeting the\ndata-driven discovery and completion of computational hypergraphs. Our approach\nis based on a kernel generalization of Row Echelon Form reduction from linear\nsystems to nonlinear ones and variance-based analysis. Here, variables are\nlinked via GPs and those contributing to the highest data variance unveil the\nhypergraph's structure. We illustrate the scope and efficiency of the proposed\napproach with applications to (algebraic) equation discovery, network discovery\n(gene pathways, chemical, and mechanical) and raw data analysis.",
            "author": [
                "Th\u00e9o Bourdais",
                "Pau Batlle",
                "Xianjin Yang",
                "Ricardo Baptista",
                "Nicolas Rouquette",
                "Houman Owhadi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17007v1",
                "http://arxiv.org/pdf/2311.17007v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.NA",
                "cs.SI",
                "math.NA",
                "stat.ML",
                "62A09, 62H22, 65S05, 90C35, 94C15, 46E22, 62J02, 15A83, 62D20, 68R10"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17008v1",
            "title": "An Investigation of Time Reversal Symmetry in Reinforcement Learning",
            "updated": "2023-11-28T18:02:06Z",
            "published": "2023-11-28T18:02:06Z",
            "summary": "One of the fundamental challenges associated with reinforcement learning (RL)\nis that collecting sufficient data can be both time-consuming and expensive. In\nthis paper, we formalize a concept of time reversal symmetry in a Markov\ndecision process (MDP), which builds upon the established structure of\ndynamically reversible Markov chains (DRMCs) and time-reversibility in\nclassical physics. Specifically, we investigate the utility of this concept in\nreducing the sample complexity of reinforcement learning. We observe that\nutilizing the structure of time reversal in an MDP allows every environment\ntransition experienced by an agent to be transformed into a feasible\nreverse-time transition, effectively doubling the number of experiences in the\nenvironment. To test the usefulness of this newly synthesized data, we develop\na novel approach called time symmetric data augmentation (TSDA) and investigate\nits application in both proprioceptive and pixel-based state within the realm\nof off-policy, model-free RL. Empirical evaluations showcase how these\nsynthetic transitions can enhance the sample efficiency of RL agents in time\nreversible scenarios without friction or contact. We also test this method in\nmore realistic environments where these assumptions are not globally satisfied.\nWe find that TSDA can significantly degrade sample efficiency and policy\nperformance, but can also improve sample efficiency under the right conditions.\nUltimately we conclude that time symmetry shows promise in enhancing the sample\nefficiency of reinforcement learning and provide guidance when the environment\nand reward structures are of an appropriate form for TSDA to be employed\neffectively.",
            "author": [
                "Brett Barkley",
                "Amy Zhang",
                "David Fridovich-Keil"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17008v1",
                "http://arxiv.org/pdf/2311.17008v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17006v1",
            "title": "On the Impact of Sampling on Deep Sequential State Estimation",
            "updated": "2023-11-28T17:59:49Z",
            "published": "2023-11-28T17:59:49Z",
            "summary": "State inference and parameter learning in sequential models can be\nsuccessfully performed with approximation techniques that maximize the evidence\nlower bound to the marginal log-likelihood of the data distribution. These\nmethods may be referred to as Dynamical Variational Autoencoders, and our\nspecific focus lies on the deep Kalman filter. It has been shown that the ELBO\nobjective can oversimplify data representations, potentially compromising\nestimation quality. Tighter Monte Carlo objectives have been proposed in the\nliterature to enhance generative modeling performance. For instance, the IWAE\nobjective uses importance weights to reduce the variance of marginal\nlog-likelihood estimates. In this paper, importance sampling is applied to the\nDKF framework for learning deep Markov models, resulting in the IW-DKF, which\nshows an improvement in terms of log-likelihood estimates and KL divergence\nbetween the variational distribution and the transition model. The framework\nusing the sampled DKF update rule is also accommodated to address sequential\nstate and parameter estimation when working with highly non-linear\nphysics-based models. An experiment with the 3-space Lorenz attractor shows an\nenhanced generative modeling performance and also a decrease in RMSE when\nestimating the model parameters and latent states, indicating that tighter MCOs\nlead to improved state inference performance.",
            "author": [
                "Helena Calatrava",
                "Ricardo Augusto Borsoi",
                "Tales Imbiriba",
                "Pau Closas"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17006v1",
                "http://arxiv.org/pdf/2311.17006v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17005v2",
            "title": "MVBench: A Comprehensive Multi-modal Video Understanding Benchmark",
            "updated": "2023-12-03T16:37:39Z",
            "published": "2023-11-28T17:59:04Z",
            "summary": "With the rapid development of Multi-modal Large Language Models (MLLMs), a\nnumber of diagnostic benchmarks have recently emerged to evaluate the\ncomprehension capabilities of these models. However, most benchmarks\npredominantly assess spatial understanding in the static image tasks, while\noverlooking temporal understanding in the dynamic video tasks. To alleviate\nthis issue, we introduce a comprehensive Multi-modal Video understanding\nBenchmark, namely MVBench, which covers 20 challenging video tasks that cannot\nbe effectively solved with a single frame. Specifically, we first introduce a\nnovel static-to-dynamic method to define these temporal-related tasks. By\ntransforming various static tasks into dynamic ones, we enable the systematic\ngeneration of video tasks that require a broad spectrum of temporal skills,\nranging from perception to cognition. Then, guided by the task definition, we\nautomatically convert public video annotations into multiple-choice QA to\nevaluate each task. On one hand, such a distinct paradigm allows us to build\nMVBench efficiently, without much manual intervention. On the other hand, it\nguarantees evaluation fairness with ground-truth video annotations, avoiding\nthe biased scoring of LLMs. Moreover, we further develop a robust video MLLM\nbaseline, i.e., VideoChat2, by progressive multi-modal training with diverse\ninstruction-tuning data. The extensive results on our MVBench reveal that, the\nexisting MLLMs are far from satisfactory in temporal understanding, while our\nVideoChat2 largely surpasses these leading models by over 15% on MVBench. All\nmodels and data are available at https://github.com/OpenGVLab/Ask-Anything.",
            "author": [
                "Kunchang Li",
                "Yali Wang",
                "Yinan He",
                "Yizhuo Li",
                "Yi Wang",
                "Yi Liu",
                "Zun Wang",
                "Jilan Xu",
                "Guo Chen",
                "Ping Luo",
                "Limin Wang",
                "Yu Qiao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17005v2",
                "http://arxiv.org/pdf/2311.17005v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17002v2",
            "title": "Ranni: Taming Text-to-Image Diffusion for Accurate Instruction Following",
            "updated": "2023-11-30T09:30:19Z",
            "published": "2023-11-28T17:57:44Z",
            "summary": "Existing text-to-image (T2I) diffusion models usually struggle in\ninterpreting complex prompts, especially those with quantity, object-attribute\nbinding, and multi-subject descriptions. In this work, we introduce a semantic\npanel as the middleware in decoding texts to images, supporting the generator\nto better follow instructions. The panel is obtained through arranging the\nvisual concepts parsed from the input text by the aid of large language models,\nand then injected into the denoising network as a detailed control signal to\ncomplement the text condition. To facilitate text-to-panel learning, we come up\nwith a carefully designed semantic formatting protocol, accompanied by a\nfully-automatic data preparation pipeline. Thanks to such a design, our\napproach, which we call Ranni, manages to enhance a pre-trained T2I generator\nregarding its textual controllability. More importantly, the introduction of\nthe generative middleware brings a more convenient form of interaction (i.e.,\ndirectly adjusting the elements in the panel or using language instructions)\nand further allows users to finely customize their generation, based on which\nwe develop a practical system and showcase its potential in continuous\ngeneration and chatting-based editing. Our project page is at\nhttps://ranni-t2i.github.io/Ranni.",
            "author": [
                "Yutong Feng",
                "Biao Gong",
                "Di Chen",
                "Yujun Shen",
                "Yu Liu",
                "Jingren Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17002v2",
                "http://arxiv.org/pdf/2311.17002v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17001v1",
            "title": "New Approximation Bounds for Small-Set Vertex Expansion",
            "updated": "2023-11-28T17:57:24Z",
            "published": "2023-11-28T17:57:24Z",
            "summary": "The vertex expansion of the graph is a fundamental graph parameter. Given a\ngraph $G=(V,E)$ and a parameter $\\delta \\in (0,1/2]$, its $\\delta$-Small-Set\nVertex Expansion (SSVE) is defined as \\[ \\min_{S : |S| = \\delta |V|}\n\\frac{|{\\partial^V(S)}|}{ \\min \\{ |S|, |S^c| \\} } \\] where $\\partial^V(S)$ is\nthe vertex boundary of a set $S$. The SSVE~problem, in addition to being of\nindependent interest as a natural graph partitioning problem, is also of\ninterest due to its connections to the Strong Unique Games problem. We give a\nrandomized algorithm running in time $n^{{\\sf poly}(1/\\delta)}$, which outputs\na set $S$ of size $\\Theta(\\delta n)$, having vertex expansion at most \\[\n\\max\\left(O(\\sqrt{\\phi^* \\log d \\log (1/\\delta)}) ,\n\\tilde{O}(d\\log^2(1/\\delta)) \\cdot \\phi^* \\right), \\] where $d$ is the largest\nvertex degree of the graph, and $\\phi^*$ is the optimal $\\delta$-SSVE. The\nprevious best-known guarantees for this were the bi-criteria bounds of\n$\\tilde{O}(1/\\delta)\\sqrt{\\phi^* \\log d}$ and $\\tilde{O}(1/\\delta)\\phi^*\n\\sqrt{\\log n}$ due to Louis-Makarychev [TOC'16].\n  Our algorithm uses the basic SDP relaxation of the problem augmented with\n${\\rm poly}(1/\\delta)$ rounds of the Lasserre/SoS hierarchy. Our rounding\nalgorithm is a combination of the rounding algorithms of Raghavendra-Tan\n[SODA'12] and Austrin-Benabbas-Georgiou [SODA'13]. A key component of our\nanalysis is novel Gaussian rounding lemma for hyperedges which might be of\nindependent interest.",
            "author": [
                "Suprovat Ghoshal",
                "Anand Louis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17001v1",
                "http://arxiv.org/pdf/2311.17001v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.03740v1",
            "title": "Prompting in Autoregressive Large Language Models",
            "updated": "2023-11-28T17:56:34Z",
            "published": "2023-11-28T17:56:34Z",
            "summary": "Autoregressive Large Language Models have transformed the landscape of\nNatural Language Processing. Pre-train and prompt paradigm has replaced the\nconventional approach of pre-training and fine-tuning for many downstream NLP\ntasks. This shift has been possible largely due to LLMs and innovative\nprompting techniques. LLMs have shown great promise for a variety of downstream\ntasks owing to their vast parameters and huge datasets that they are\npre-trained on. However, in order to fully realize their potential, their\noutputs must be guided towards the desired outcomes. Prompting, in which a\nspecific input or instruction is provided to guide the LLMs toward the intended\noutput, has become a tool for achieving this goal. In this paper, we discuss\nthe various prompting techniques that have been applied to fully harness the\npower of LLMs. We present a taxonomy of existing literature on prompting\ntechniques and provide a concise survey based on this taxonomy. Further, we\nidentify some open problems in the realm of prompting in autoregressive LLMs\nwhich could serve as a direction for future research.",
            "author": [
                "Prabin Bhandari"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03740v1",
                "http://arxiv.org/pdf/2312.03740v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.02179v1",
            "title": "Training Chain-of-Thought via Latent-Variable Inference",
            "updated": "2023-11-28T17:47:32Z",
            "published": "2023-11-28T17:47:32Z",
            "summary": "Large language models (LLMs) solve problems more accurately and interpretably\nwhen instructed to work out the answer step by step using a\n``chain-of-thought'' (CoT) prompt. One can also improve LLMs' performance on a\nspecific task by supervised fine-tuning, i.e., by using gradient ascent on some\ntunable parameters to maximize the average log-likelihood of correct answers\nfrom a labeled training set. Naively combining CoT with supervised tuning\nrequires supervision not just of the correct answers, but also of detailed\nrationales that lead to those answers; these rationales are expensive to\nproduce by hand. Instead, we propose a fine-tuning strategy that tries to\nmaximize the \\emph{marginal} log-likelihood of generating a correct answer\nusing CoT prompting, approximately averaging over all possible rationales. The\ncore challenge is sampling from the posterior over rationales conditioned on\nthe correct answer; we address it using a simple Markov-chain Monte Carlo\n(MCMC) expectation-maximization (EM) algorithm inspired by the self-taught\nreasoner (STaR), memoized wake-sleep, Markovian score climbing, and persistent\ncontrastive divergence. This algorithm also admits a novel control-variate\ntechnique that drives the variance of our gradient estimates to zero as the\nmodel improves. Applying our technique to GSM8K and the tasks in BIG-Bench\nHard, we find that this MCMC-EM fine-tuning technique typically improves the\nmodel's accuracy on held-out examples more than STaR or prompt-tuning with or\nwithout CoT.",
            "author": [
                "Du Phan",
                "Matthew D. Hoffman",
                "David Dohan",
                "Sholto Douglas",
                "Tuan Anh Le",
                "Aaron Parisi",
                "Pavel Sountsov",
                "Charles Sutton",
                "Sharad Vikram",
                "Rif A. Saurous"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02179v1",
                "http://arxiv.org/pdf/2312.02179v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16991v1",
            "title": "Asteroseismology of the young open cluster NGC 2516 I: Photometric and\n  spectroscopic observations",
            "updated": "2023-11-28T17:45:35Z",
            "published": "2023-11-28T17:45:35Z",
            "summary": "Asteroseismic modelling of isolated star presents significant challenges due\nto the difficulty in accurately determining stellar parameters, particularly\nthe stellar age. These challenges can be overcomed by observing stars in open\nclusters, whose coeval members share an initial chemical composition. The light\ncurves by TESS allow us to investigate and analyse stellar variations in\nclusters with an unprecedented level. We aim to detect gravity-mode\noscillations in the early-type main-sequence members of the young open cluster\nNGC 2516. We selected the 301 member stars as our sample and analysed the TESS\nFFI light curves. We also collected high-resolution spectra using the FEROS for\nthe g-mode pulsators. By fitting the theoretical isochrones to the\ncolour-magnitude diagram (CMD) of a cluster, we determined an age of 102 $\\pm$\n15 Myr and inferred the extinction at 550 nm ($A_0$) is 0.53 $\\pm$ 0.04 mag. We\nidentified 147 stars with surface brightness modulations, 24 with g-mode\npulsations ($\\gamma$ Doradus or Slowly Pulsating B stars), and 35 with p-mode\npulsations ($\\delta$ Sct stars). When sorted by colour index, the amplitude\nspectra of the $\\delta$ Sct stars show a distinct ordering and reveal a\ndiscernible frequency-temperature relationship. The near-core rotation rates,\nmeasured from period spacing patterns in two SPB and nine $\\gamma$ Dor stars,\nreach up to 3/d . This is at the high end of the values found from Kepler data\nof field stars of similar variability type. The $\\gamma$ Dor stars have\ninternal rotation rates as high as 50% of their critical value, whereas the SPB\nstars exhibit rotation rates close to their critical rate. We did not find\nlong-term brightness and colour variations in the mid-infrared, which suggests\nthat there are no disk or shell formation events in our sample. We also\ndiscussed the results of our spectroscopic observations for the g-mode\npulsators.",
            "author": [
                "Gang Li",
                "Conny Aerts",
                "Timothy R. Bedding",
                "Dario J. Fritzewski",
                "Simon J. Murphy",
                "Timothy Van Reeth",
                "Benjamin T. Monter",
                "Mingjie Jian",
                "Joey S. G. Mombarg",
                "Seth Gossage"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16991v1",
                "http://arxiv.org/pdf/2311.16991v1"
            ],
            "primary_category": "astro-ph.SR",
            "category": [
                "astro-ph.SR",
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16989v3",
            "title": "ChatGPT's One-year Anniversary: Are Open-Source Large Language Models\n  Catching up?",
            "updated": "2023-12-05T16:58:46Z",
            "published": "2023-11-28T17:44:51Z",
            "summary": "Upon its release in late 2022, ChatGPT has brought a seismic shift in the\nentire landscape of AI, both in research and commerce. Through\ninstruction-tuning a large language model (LLM) with supervised fine-tuning and\nreinforcement learning from human feedback, it showed that a model could answer\nhuman questions and follow instructions on a broad panel of tasks. Following\nthis success, interests in LLMs have intensified, with new LLMs flourishing at\nfrequent interval across academia and industry, including many start-ups\nfocused on LLMs. While closed-source LLMs (e.g., OpenAI's GPT, Anthropic's\nClaude) generally outperform their open-source counterparts, the progress on\nthe latter has been rapid with claims of achieving parity or even better on\ncertain tasks. This has crucial implications not only on research but also on\nbusiness. In this work, on the first anniversary of ChatGPT, we provide an\nexhaustive overview of this success, surveying all tasks where an open-source\nLLM has claimed to be on par or better than ChatGPT.",
            "author": [
                "Hailin Chen",
                "Fangkai Jiao",
                "Xingxuan Li",
                "Chengwei Qin",
                "Mathieu Ravaut",
                "Ruochen Zhao",
                "Caiming Xiong",
                "Shafiq Joty"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16989v3",
                "http://arxiv.org/pdf/2311.16989v3"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16988v1",
            "title": "A Wasserstein-type Distance for Gaussian Mixtures on Vector Bundles with\n  Applications to Shape Analysis",
            "updated": "2023-11-28T17:44:01Z",
            "published": "2023-11-28T17:44:01Z",
            "summary": "This paper uses sample data to study the problem of comparing populations on\nfinite-dimensional parallelizable Riemannian manifolds and more general trivial\nvector bundles. Utilizing triviality, our framework represents populations as\nmixtures of Gaussians on vector bundles and estimates the population parameters\nusing a mode-based clustering algorithm. We derive a Wasserstein-type metric\nbetween Gaussian mixtures, adapted to the manifold geometry, in order to\ncompare estimated distributions. Our contributions include an identifiability\nresult for Gaussian mixtures on manifold domains and a convenient\ncharacterization of optimal couplings of Gaussian mixtures under the derived\nmetric. We demonstrate these tools on some example domains, including the\npre-shape space of planar closed curves, with applications to the shape space\nof triangles and populations of nanoparticles. In the nanoparticle application,\nwe consider a sequence of populations of particle shapes arising from a\nmanufacturing process, and utilize the Wasserstein-type distance to perform\nchange-point detection.",
            "author": [
                "Michael Wilson",
                "Tom Needham",
                "Chiwoo Park",
                "Suprateek Kundu",
                "Anuj Srivastava"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16988v1",
                "http://arxiv.org/pdf/2311.16988v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16987v1",
            "title": "A Non-Archimedean Approach to Stratifications",
            "updated": "2023-11-28T17:39:33Z",
            "published": "2023-11-28T17:39:33Z",
            "summary": "These are notes from a mini-course about the main results of\narXiv:2206.03438: I explain how, using suitable valued fields, one obtains a\nnatural notion of canonical stratifications (of e.g. algebraic subsets of\n$\\mathbb{R}^n$). I also explain how the same techniques yield more invariants\nof singularities, and I present an application to Poincar\\'e series. While some\nrudimentary knowledge of model theory is useful, the notes should also be\naccessible without such knowledge. In particular, they contain an introduction\nto the non-standard analysis needed for this approach.",
            "author": [
                "Immanuel Halupczok"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16987v1",
                "http://arxiv.org/pdf/2311.16987v1"
            ],
            "primary_category": "math.AG",
            "category": [
                "math.AG",
                "14B05, 32S60, 12J25, 03C98, 03H05, 14B20"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16985v2",
            "title": "RIS-Enhanced MIMO Channels in Urban Environments: Experimental Insights",
            "updated": "2023-11-29T07:33:07Z",
            "published": "2023-11-28T17:36:04Z",
            "summary": "Can the smart radio environment paradigm measurably enhance the performance\nof contemporary urban macrocells? In this study, we explore the impact of\nreconfigurable intelligent surfaces (RISs) on a real-world sub-6 GHz MIMO\nchannel. A rooftop-mounted macrocell antenna has been adapted to enable\nfrequency domain channel measurements to be ascertained. A nature-inspired beam\nsearch algorithm has been employed to maximize channel gain at user positions,\nrevealing a potential 50% increase in channel capacity in certain\ncircumstances. Analysis reveals, however, that the spatial characteristics of\nthe channel can be adversely affected through the introduction of a RIS in\nthese settings. The RIS prototype schematics, Gerber files, and source code\nhave been made available to aid in future experimental efforts of the wireless\nresearch community.",
            "author": [
                "James Rains",
                "Anvar Tukmanov",
                "Qammer Abbasi",
                "Muhammad Imran"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16985v2",
                "http://arxiv.org/pdf/2311.16985v2"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16983v1",
            "title": "HARQ Retransmissions in C-V2X: A BSM Latency Analysis",
            "updated": "2023-11-28T17:33:13Z",
            "published": "2023-11-28T17:33:13Z",
            "summary": "Cellular vehicular-to-everything (C-V2X) systems offer the potential for\nimproving road safety, in part through the exchange of periodic basic safety\nmessages (BSMs) between nearby vehicles. The reliability and latency of these\nmessages is a key metric. Hybrid automatic repeat request (HARQ)\nretransmissions are one technique used to this end. However, HARQ may come at\nthe expense of consuming the limited available wireless resources, especially\nin highly congested scenarios. This paper studies BSM transmission latency and\nreliability when HARQ retransmissions are used with the semi-persistent\nscheduling (SPS) in C-V2X transmission mode 4. We do so through extensive\nsystem-level simulations that closely follow the SPS process. Furthermore, we\nprovide an analytical model for the tail behavior of the BSM latency\ndistribution with HARQ retransmissions that is a good approximation to the\nsimulation results. Our study reveals the impact of several deployment settings\n(e.g., bandwidth configurations and vehicle density).",
            "author": [
                "Abdurrahman Fouda",
                "Randall Berry",
                "Ivan Vukovic"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16983v1",
                "http://arxiv.org/pdf/2311.16983v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.NA",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16982v1",
            "title": "Robust Parallel Laser Driving of Quantum Dots for Multiplexing of\n  Quantum Light Sources",
            "updated": "2023-11-28T17:32:45Z",
            "published": "2023-11-28T17:32:45Z",
            "summary": "Deterministic sources of quantum light (i.e. single photons or pairs of\nentangled photons) are required for a whole host of applications in quantum\ntechnology, including quantum imaging, quantum cryptography and the\nlong-distance transfer of quantum information in future quantum networks.\nSemiconductor quantum dots are ideal candidates for solid-state quantum\nemitters as these artificial atoms have large dipole moments and a quantum\nconfined energy level structure, enabling the realization of single photon\nsources with high repetition rates and high single photon purity. Quantum dots\nmay also be triggered using a laser pulse for on-demand operation. The\nnaturally-occurring size variations in ensembles of quantum dots offers the\npotential to increase the bandwidth of quantum communication systems through\nwavelength-division multiplexing, but conventional laser triggering schemes\nbased on Rabi rotations are ineffective when applied to inequivalent emitters.\nHere we report the demonstration of the simultaneous triggering of >10 quantum\ndots using adiabatic rapid passage. We show that high-fidelity quantum state\ninversion is possible in a system of quantum dots with a 15~meV range of\noptical transition energies using a single broadband, chirped laser pulse,\nlaying the foundation for high-bandwidth, multiplexed quantum networks.",
            "author": [
                "Ajan Ramachandran",
                "Grant R. Wilbur",
                "Reuble Mathew",
                "Allister Mason",
                "Sabine ONeal",
                "Dennis G. Deppe",
                "Kimberley C. Hall"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16982v1",
                "http://arxiv.org/pdf/2311.16982v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cond-mat.mes-hall"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16978v1",
            "title": "Assessing the influence of attractor-verb distance on grammatical\n  agreement in humans and language models",
            "updated": "2023-11-28T17:25:34Z",
            "published": "2023-11-28T17:25:34Z",
            "summary": "Subject-verb agreement in the presence of an attractor noun located between\nthe main noun and the verb elicits complex behavior: judgments of\ngrammaticality are modulated by the grammatical features of the attractor. For\nexample, in the sentence \"The girl near the boys likes climbing\", the attractor\n(boys) disagrees in grammatical number with the verb (likes), creating a\nlocally implausible transition probability. Here, we parametrically modulate\nthe distance between the attractor and the verb while keeping the length of the\nsentence equal. We evaluate the performance of both humans and two artificial\nneural network models: both make more mistakes when the attractor is closer to\nthe verb, but neural networks get close to the chance level while humans are\nmostly able to overcome the attractor interference. Additionally, we report a\nlinear effect of attractor distance on reaction times. We hypothesize that a\npossible reason for the proximity effect is the calculation of transition\nprobabilities between adjacent words. Nevertheless, classical models of\nattraction such as the cue-based model might suffice to explain this\nphenomenon, thus paving the way for new research. Data and analyses available\nat https://osf.io/d4g6k",
            "author": [
                "Christos-Nikolaos Zacharopoulos",
                "Th\u00e9o Desbordes",
                "Mathias Sabl\u00e9-Meyer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16978v1",
                "http://arxiv.org/pdf/2311.16978v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16977v1",
            "title": "Bidirectional Reactive Programming for Machine Learning",
            "updated": "2023-11-28T17:25:16Z",
            "published": "2023-11-28T17:25:16Z",
            "summary": "Reactive languages are dedicated to the programming of systems which interact\ncontinuously and concurrently with their environment. Values take the form of\nunbounded streams modeling the (discrete) passing of time or the sequence of\nconcurrent interactions. While conventional reactivity models recurrences\nforward in time, we introduce a symmetric reactive construct enabling backward\nrecurrences. Constraints on the latter allow to make the implementation\npractical. Machine Learning (ML) systems provide numerous motivations for all\nof this: we demonstrate that reverse-mode automatic differentiation,\nbackpropagation, batch normalization, bidirectional recurrent neural networks,\ntraining and reinforcement learning algorithms, are all naturally captured as\nbidirectional reactive programs.",
            "author": [
                "Dumitru Potop Butucaru",
                "Albert Cohen",
                "Gordon Plotkin",
                "Hugo Pompougnac"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16977v1",
                "http://arxiv.org/pdf/2311.16977v1"
            ],
            "primary_category": "cs.PL",
            "category": [
                "cs.PL",
                "cs.LG",
                "D.3; D.3.1; I.2; I.2.5"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17935v1",
            "title": "Strategic Workforce Planning in Crowdsourced Delivery with Hybrid Driver\n  Fleets",
            "updated": "2023-11-28T17:23:42Z",
            "published": "2023-11-28T17:23:42Z",
            "summary": "Nowadays, logistics service providers (LSPs) increasingly consider using a\ncrowdsourced workforce on the last mile to fulfill customers' expectations\nregarding same-day or on-demand delivery at reduced costs. The crowdsourced\nworkforce's availability is, however, uncertain. Therefore, LSPs often hire\nadditional fixed employees to perform deliveries when the availability of\ncrowdsourced drivers is low. In this context, the reliability versus\nflexibility trade-off which LSPs face over a longer period, e.g., a year,\nremains unstudied. Against this background, we jointly study a workforce\nplanning problem that considers fixed drivers (FDs) and the temporal\ndevelopment of the crowdsourced driver (CD) fleet over a long-term time\nhorizon. We consider two types of CDs, gigworkers (GWs) and occasional drivers\n(ODs). While GWs are not sensitive to the request's destination and typically\nexhibit high availability, ODs only serve requests whose origin and destination\ncoincide with their own private route's origin and destination. Moreover, to\naccount for time horizon-specific dynamics, we consider stochastic turnover for\nboth FDs and CDs as well as stochastic CD fleet growth. We formulate the\nresulting workforce planning problem as a Markov decision process (MDP) whose\nreward function reflects total costs, i.e., wages and operational costs arising\nfrom serving demand with FDs and CDs, and solve it via approximate dynamic\nprogramming (ADP). Applying our approach to an environment based on real-world\ndemand data from GrubHub, we find that in fleets consisting of FDs and CDs,\nADP-based hiring policies can outperform myopic hiring policies by up to 19% in\ntotal costs. In the studied setting, we observed that GWs reduce the LSP's\ntotal costs more than ODs. When we account for CDs' increased resignation\nprobability when not being matched with enough requests, the amount of required\nFDs increases.",
            "author": [
                "Julius Luy",
                "Gerhard Hiermann",
                "Maximilian Schiffer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17935v1",
                "http://arxiv.org/pdf/2311.17935v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16974v1",
            "title": "COLE: A Hierarchical Generation Framework for Graphic Design",
            "updated": "2023-11-28T17:22:17Z",
            "published": "2023-11-28T17:22:17Z",
            "summary": "Graphic design, which has been evolving since the 15th century, plays a\ncrucial role in advertising. The creation of high-quality designs demands\ncreativity, innovation, and lateral thinking. This intricate task involves\nunderstanding the objective, crafting visual elements such as the background,\ndecoration, font, color, and shape, formulating diverse professional layouts,\nand adhering to fundamental visual design principles. In this paper, we\nintroduce COLE, a hierarchical generation framework designed to comprehensively\naddress these challenges. This COLE system can transform a straightforward\nintention prompt into a high-quality graphic design, while also supporting\nflexible editing based on user input. Examples of such input might include\ndirectives like ``design a poster for Hisaishi's concert.'' The key insight is\nto dissect the complex task of text-to-design generation into a hierarchy of\nsimpler sub-tasks, each addressed by specialized models working\ncollaboratively. The results from these models are then consolidated to produce\na cohesive final output. Our hierarchical task decomposition can streamline the\ncomplex process and significantly enhance generation reliability. Our COLE\nsystem consists of multiple fine-tuned Large Language Models (LLMs), Large\nMultimodal Models (LMMs), and Diffusion Models (DMs), each specifically\ntailored for a design-aware text or image generation task. Furthermore, we\nconstruct the DESIGNERINTENTION benchmark to highlight the superiority of our\nCOLE over existing methods in generating high-quality graphic designs from user\nintent. We perceive our COLE as an important step towards addressing more\ncomplex visual design generation tasks in the future.",
            "author": [
                "Peidong Jia",
                "Chenxuan Li",
                "Zeyu Liu",
                "Yichao Shen",
                "Xingru Chen",
                "Yuhui Yuan",
                "Yinglin Zheng",
                "Dong Chen",
                "Ji Li",
                "Xiaodong Xie",
                "Shanghang Zhang",
                "Baining Guo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16974v1",
                "http://arxiv.org/pdf/2311.16974v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16975v1",
            "title": "Managing Vehicle Charging During Emergencies via Conservative\n  Distribution System Modeling",
            "updated": "2023-11-28T17:22:17Z",
            "published": "2023-11-28T17:22:17Z",
            "summary": "Combinatorial distribution system optimization problems, such as scheduling\nelectric vehicle (EV) charging during evacuations, present significant\ncomputational challenges. These challenges stem from the large numbers of\nconstraints, continuous variables, and discrete variables, coupled with the\nunbalanced nature of distribution systems. In response to the escalating\nfrequency of extreme events impacting electric power systems, this paper\nintroduces a method that integrates sample-based conservative linear power flow\napproximations (CLAs) into an optimization framework. In particular, this\nintegration aims to ameliorate the aforementioned challenges of distribution\nsystem optimization in the context of efficiently minimizing the charging time\nrequired for EVs in urban evacuation scenarios.",
            "author": [
                "Alejandro D. Owen Aquino",
                "Samuel Talkington",
                "Daniel K. Molzahn"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16975v1",
                "http://arxiv.org/pdf/2311.16975v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16965v1",
            "title": "Natural Language Processing Through Transfer Learning: A Case Study on\n  Sentiment Analysis",
            "updated": "2023-11-28T17:12:06Z",
            "published": "2023-11-28T17:12:06Z",
            "summary": "Artificial intelligence and machine learning have significantly bolstered the\ntechnological world. This paper explores the potential of transfer learning in\nnatural language processing focusing mainly on sentiment analysis. The models\ntrained on the big data can also be used where data are scarce. The claim is\nthat, compared to training models from scratch, transfer learning, using\npre-trained BERT models, can increase sentiment classification accuracy. The\nstudy adopts a sophisticated experimental design that uses the IMDb dataset of\nsentimentally labelled movie reviews. Pre-processing includes tokenization and\nencoding of text data, making it suitable for NLP models. The dataset is used\non a BERT based model, measuring its performance using accuracy. The result\ncomes out to be 100 per cent accurate. Although the complete accuracy could\nappear impressive, it might be the result of overfitting or a lack of\ngeneralization. Further analysis is required to ensure the model's ability to\nhandle diverse and unseen data. The findings underscore the effectiveness of\ntransfer learning in NLP, showcasing its potential to excel in sentiment\nanalysis tasks. However, the research calls for a cautious interpretation of\nperfect accuracy and emphasizes the need for additional measures to validate\nthe model's generalization.",
            "author": [
                "Aman Yadav",
                "Abhishek Vichare"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16965v1",
                "http://arxiv.org/pdf/2311.16965v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16963v1",
            "title": "Electroweak corrections to double Higgs production at the LHC",
            "updated": "2023-11-28T17:10:11Z",
            "published": "2023-11-28T17:10:11Z",
            "summary": "We present the results for the complete next-to-leading order electroweak\ncorrections to $pp \\to HH$ at the Large Hadron Collider, focusing on the\ndominant gluon-gluon fusion process. While the corrections at the total\ncross-section level are approximately $-4\\%$, those near the energy of $HH$\nproduction threshold exceed $+15\\%$, and corrections at the high-energy region\nare around $-10\\%$, leading to a shape distortion for the differential\ndistributions. Our findings substantially diminish the theoretical\nuncertainties associated with this pivotal process, providing valuable input\nfor understanding the shape of the Higgs boson potential upon comparison with\nexperimental measurements.",
            "author": [
                "Huan-Yu Bi",
                "Li-Hong Huang",
                "Rui-Jun Huang",
                "Yan-Qing Ma",
                "Huai-Min Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16963v1",
                "http://arxiv.org/pdf/2311.16963v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16961v1",
            "title": "HumanRef: Single Image to 3D Human Generation via Reference-Guided\n  Diffusion",
            "updated": "2023-11-28T17:06:28Z",
            "published": "2023-11-28T17:06:28Z",
            "summary": "Generating a 3D human model from a single reference image is challenging\nbecause it requires inferring textures and geometries in invisible views while\nmaintaining consistency with the reference image. Previous methods utilizing 3D\ngenerative models are limited by the availability of 3D training data.\nOptimization-based methods that lift text-to-image diffusion models to 3D\ngeneration often fail to preserve the texture details of the reference image,\nresulting in inconsistent appearances in different views. In this paper, we\npropose HumanRef, a 3D human generation framework from a single-view input. To\nensure the generated 3D model is photorealistic and consistent with the input\nimage, HumanRef introduces a novel method called reference-guided score\ndistillation sampling (Ref-SDS), which effectively incorporates image guidance\ninto the generation process. Furthermore, we introduce region-aware attention\nto Ref-SDS, ensuring accurate correspondence between different body regions.\nExperimental results demonstrate that HumanRef outperforms state-of-the-art\nmethods in generating 3D clothed humans with fine geometry, photorealistic\ntextures, and view-consistent appearances.",
            "author": [
                "Jingbo Zhang",
                "Xiaoyu Li",
                "Qi Zhang",
                "Yanpei Cao",
                "Ying Shan",
                "Jing Liao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16961v1",
                "http://arxiv.org/pdf/2311.16961v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16958v1",
            "title": "From Simulations to Reality: Enhancing Multi-Robot Exploration for Urban\n  Search and Rescue",
            "updated": "2023-11-28T17:05:25Z",
            "published": "2023-11-28T17:05:25Z",
            "summary": "In this study, we present a novel hybrid algorithm, combining Levy Flight\n(LF) and Particle Swarm Optimization (PSO) (LF-PSO), tailored for efficient\nmulti-robot exploration in unknown environments with limited communication and\nno global positioning information. The research addresses the growing interest\nin employing multiple autonomous robots for exploration tasks, particularly in\nscenarios such as Urban Search and Rescue (USAR) operations. Multiple robots\noffer advantages like increased task coverage, robustness, flexibility, and\nscalability. However, existing approaches often make assumptions such as search\narea, robot positioning, communication restrictions, and target information\nthat may not hold in real-world situations. The hybrid algorithm leverages LF,\nknown for its effectiveness in large space exploration with sparse targets, and\nincorporates inter-robot repulsion as a social component through PSO. This\ncombination enhances area exploration efficiency. We redefine the local best\nand global best positions to suit scenarios without continuous target\ninformation. Experimental simulations in a controlled environment demonstrate\nthe algorithm's effectiveness, showcasing improved area coverage compared to\ntraditional methods. In the process of refining our approach and testing it in\ncomplex, obstacle-rich environments, the presented work holds promise for\nenhancing multi-robot exploration in scenarios with limited information and\ncommunication capabilities.",
            "author": [
                "Gautam Siddharth Kashyap",
                "Deepkashi Mahajan",
                "Orchid Chetia Phukan",
                "Ankit Kumar",
                "Alexander E. I. Brownlee",
                "Jiechao Gao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16958v1",
                "http://arxiv.org/pdf/2311.16958v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16957v1",
            "title": "Space-Efficient Data Structures for Polyominoes and Bar Graphs",
            "updated": "2023-11-28T17:04:27Z",
            "published": "2023-11-28T17:04:27Z",
            "summary": "We provide a compact data structure for representing polyominoes that\nsupports neighborhood and visibility queries. Neighborhood queries concern\nreporting adjacent cells to a given cell, and visibility queries determine\nwhether a straight line can be drawn within the polyomino that connects two\nspecified cells. For an arbitrary small $\\epsilon >0$, our data structure can\nencode a polyomino with $n$ cells in $(3+\\epsilon)n + o(n)$ bits while\nsupporting all queries in constant time. The space complexity can be improved\nto $3n+o(n)$, while supporting neighborhood queries in $\\mathcal{O}(1)$ and\nvisibility queries in $\\mathcal{O}(t(n))$ for any arbitrary $t(n) \\in\n\\omega(1)$. Previous attempts at enumerating polyominoes have indicated that at\nleast $2.00091n - o(n)$ bits are required to differentiate between distinct\npolyominoes, which shows our data structure is compact.\n  In addition, we introduce a succinct data structure tailored for bar graphs,\na specific subclass of polyominoes resembling histograms. We demonstrate that a\nbar graph comprising $n$ cells can be encoded using only $n + o(n)$ bits,\nenabling constant-time query processing. Meanwhile, $n-1$ bits are necessary to\nrepresent any bar graph, proving our data structure is succinct.",
            "author": [
                "Magnus Berg",
                "Shahin Kamali",
                "Katherine Ling",
                "Cooper Sigrist"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16957v1",
                "http://arxiv.org/pdf/2311.16957v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "E.1"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16951v1",
            "title": "Three-dimensional internal flow evolution of an evaporating droplet and\n  its role in particle deposition pattern",
            "updated": "2023-11-28T16:58:12Z",
            "published": "2023-11-28T16:58:12Z",
            "summary": "The internal flow within an evaporating sessile droplet is one of the driving\nmechanisms that lead to the variety of particle deposition patterns seen in\napplications such as inkjet printing, surface patterning, and blood stain\nanalysis. Despite decades of research, the causal link between droplet internal\nflow and particle deposition patterns has not been fully established. In this\nstudy, we employ a 3D imaging technique based on digital inline holography to\nquantitatively assess the evolution of internal flow fields and particle\nmigration in three distinct types of wetting droplets: water, sucrose aqueous\nsolution, and SDS aqueous solution droplets, throughout their entire\nevaporation process. Our imaging reveals the three-stage evolution of the 3D\ninternal flow regimes driven by changes in the relative importance of capillary\nflow, Marangoni flow, and droplet boundary movement during evaporation, each\nexhibiting unique dynamics. The migration of particles from their initial\nlocations to deposition can be divided into five categories, with particles\ndepositing either at the contact line or inside the droplet. We observe the\nchanging migration directions of particles due to competing Marangoni and\ncapillary flows during droplet evaporation. We further develop an analytical\nmodel that predicts the droplet internal flow and deposition patterns and\ndetermines the dependence of the deposition mechanisms of particles on their\ninitial locations and the evolving internal flow field. The model, validated\nusing different types of droplets from our experiment and the literature, can\nbe further expanded to other Newtonian and non-Newtonian droplets, which can\npotentially serve as a real-time assessment tool for particle deposition in\nvarious applications.",
            "author": [
                "Jiaqi Li",
                "Jiarong Hong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16951v1",
                "http://arxiv.org/pdf/2311.16951v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16945v1",
            "title": "UC-NeRF: Neural Radiance Field for Under-Calibrated multi-view cameras\n  in autonomous driving",
            "updated": "2023-11-28T16:47:59Z",
            "published": "2023-11-28T16:47:59Z",
            "summary": "Multi-camera setups find widespread use across various applications, such as\nautonomous driving, as they greatly expand sensing capabilities. Despite the\nfast development of Neural radiance field (NeRF) techniques and their wide\napplications in both indoor and outdoor scenes, applying NeRF to multi-camera\nsystems remains very challenging. This is primarily due to the inherent\nunder-calibration issues in multi-camera setup, including inconsistent imaging\neffects stemming from separately calibrated image signal processing units in\ndiverse cameras, and system errors arising from mechanical vibrations during\ndriving that affect relative camera poses. In this paper, we present UC-NeRF, a\nnovel method tailored for novel view synthesis in under-calibrated multi-view\ncamera systems. Firstly, we propose a layer-based color correction to rectify\nthe color inconsistency in different image regions. Second, we propose virtual\nwarping to generate more viewpoint-diverse but color-consistent virtual views\nfor color correction and 3D recovery. Finally, a spatiotemporally constrained\npose refinement is designed for more robust and accurate pose calibration in\nmulti-camera systems. Our method not only achieves state-of-the-art performance\nof novel view synthesis in multi-camera setups, but also effectively\nfacilitates depth estimation in large-scale outdoor scenes with the synthesized\nnovel views.",
            "author": [
                "Kai Cheng",
                "Xiaoxiao Long",
                "Wei Yin",
                "Jin Wang",
                "Zhiqiang Wu",
                "Yuexin Ma",
                "Kaixuan Wang",
                "Xiaozhi Chen",
                "Xuejin Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16945v1",
                "http://arxiv.org/pdf/2311.16945v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16943v1",
            "title": "Image segmentation with traveling waves in an exactly solvable recurrent\n  neural network",
            "updated": "2023-11-28T16:46:44Z",
            "published": "2023-11-28T16:46:44Z",
            "summary": "We study image segmentation using spatiotemporal dynamics in a recurrent\nneural network where the state of each unit is given by a complex number. We\nshow that this network generates sophisticated spatiotemporal dynamics that can\neffectively divide an image into groups according to a scene's structural\ncharacteristics. Using an exact solution of the recurrent network's dynamics,\nwe present a precise description of the mechanism underlying object\nsegmentation in this network, providing a clear mathematical interpretation of\nhow the network performs this task. We then demonstrate a simple algorithm for\nobject segmentation that generalizes across inputs ranging from simple\ngeometric objects in grayscale images to natural images. Object segmentation\nacross all images is accomplished with one recurrent neural network that has a\nsingle, fixed set of weights. This demonstrates the expressive potential of\nrecurrent neural networks when constructed using a mathematical approach that\nbrings together their structure, dynamics, and computation.",
            "author": [
                "Luisa H. B. Liboni",
                "Roberto C. Budzinski",
                "Alexandra N. Busch",
                "Sindy L\u00f6we",
                "Thomas A. Keller",
                "Max Welling",
                "Lyle E. Muller"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16943v1",
                "http://arxiv.org/pdf/2311.16943v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16941v1",
            "title": "Debiasing Multimodal Models via Causal Information Minimization",
            "updated": "2023-11-28T16:46:14Z",
            "published": "2023-11-28T16:46:14Z",
            "summary": "Most existing debiasing methods for multimodal models, including causal\nintervention and inference methods, utilize approximate heuristics to represent\nthe biases, such as shallow features from early stages of training or unimodal\nfeatures for multimodal tasks like VQA, etc., which may not be accurate. In\nthis paper, we study bias arising from confounders in a causal graph for\nmultimodal data and examine a novel approach that leverages causally-motivated\ninformation minimization to learn the confounder representations. Robust\npredictive features contain diverse information that helps a model generalize\nto out-of-distribution data. Hence, minimizing the information content of\nfeatures obtained from a pretrained biased model helps learn the simplest\npredictive features that capture the underlying data distribution. We treat\nthese features as confounder representations and use them via methods motivated\nby causal theory to remove bias from models. We find that the learned\nconfounder representations indeed capture dataset biases, and the proposed\ndebiasing methods improve out-of-distribution (OOD) performance on multiple\nmultimodal datasets without sacrificing in-distribution performance.\nAdditionally, we introduce a novel metric to quantify the sufficiency of\nspurious features in models' predictions that further demonstrates the\neffectiveness of our proposed methods. Our code is available at:\nhttps://github.com/Vaidehi99/CausalInfoMin",
            "author": [
                "Vaidehi Patil",
                "Adyasha Maharana",
                "Mohit Bansal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16941v1",
                "http://arxiv.org/pdf/2311.16941v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL",
                "cs.CV",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16940v1",
            "title": "FP-Fed: Privacy-Preserving Federated Detection of Browser Fingerprinting",
            "updated": "2023-11-28T16:43:17Z",
            "published": "2023-11-28T16:43:17Z",
            "summary": "Browser fingerprinting often provides an attractive alternative to\nthird-party cookies for tracking users across the web. In fact, the increasing\nrestrictions on third-party cookies placed by common web browsers and recent\nregulations like the GDPR may accelerate the transition. To counter browser\nfingerprinting, previous work proposed several techniques to detect its\nprevalence and severity. However, these rely on 1) centralized web crawls\nand/or 2) computationally intensive operations to extract and process signals\n(e.g., information-flow and static analysis). To address these limitations, we\npresent FP-Fed, the first distributed system for browser fingerprinting\ndetection. Using FP-Fed, users can collaboratively train on-device models based\non their real browsing patterns, without sharing their training data with a\ncentral entity, by relying on Differentially Private Federated Learning\n(DP-FL). To demonstrate its feasibility and effectiveness, we evaluate FP-Fed's\nperformance on a set of 18.3k popular websites with different privacy levels,\nnumbers of participants, and features extracted from the scripts. Our\nexperiments show that FP-Fed achieves reasonably high detection performance and\ncan perform both training and inference efficiently, on-device, by only relying\non runtime signals extracted from the execution trace, without requiring any\nresource-intensive operation.",
            "author": [
                "Meenatchi Sundaram Muthu Selva Annamalai",
                "Igor Bilogrevic",
                "Emiliano De Cristofaro"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16940v1",
                "http://arxiv.org/pdf/2311.16940v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16938v1",
            "title": "New insights into the doubly charmed exotic mesons",
            "updated": "2023-11-28T16:41:11Z",
            "published": "2023-11-28T16:41:11Z",
            "summary": "Using effective Lagrangians constrained by the heavy quark spin symmetry and\nchiral symmetry, for the light quarks, we analyze the $D^0 D^0\\pi^+$,\n$\\bar{D}^0D^0\\pi^0$ and $D^0\\bar{D}^{*0}$ invariant mass spectra. Performing a\nsimultaneous analysis of the doubly charmed and charm-anti-charm states gives\nfurther insights into the nature of the $T^+_{cc}$ and $\\chi^0_{c1}(3872)$,\nexotic hadrons. We find that both states lie below the respective open-charm\n$DD^*$/$D\\bar{D}^*$ thresholds. This finding, together with the fact that the\ncontributions of the triangle and box diagrams are negligible, suggests that\nboth resonances are likely to be genuine bound states. We also predict the\ndecay rates for their possible charge partners.",
            "author": [
                "Di Guo",
                "Qin-He Yang",
                "Ling-Yun Dai",
                "A. P. Szczepaniak"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16938v1",
                "http://arxiv.org/pdf/2311.16938v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "nucl-th"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16936v1",
            "title": "Charged particle motion and acceleration around Kerr-MOG black hole",
            "updated": "2023-11-28T16:37:29Z",
            "published": "2023-11-28T16:37:29Z",
            "summary": "One of the most important issues in relativistic astrophysics is to explain\nthe origin mechanisms of (ultra)high energy charged particle components of\ncosmic rays. Black holes (BHs) being huge reservoirs of (gravitational) energy\ncan be candidates for such particle sources. The main idea of this work is to\nstudy the effects of scalar-tensor-vector gravity (STVG) on particle\nacceleration by examining charged particle dynamics and their acceleration\nthrough the magnetic Penrose process (MPP) near magnetized Kerr-MOG BHs. First,\nwe study the horizon structure of the BH. Also, we study the effective\npotential to gain insight into the stability of circular orbits. Our results\nshow that the magnetic field can extend the region of stable circular orbits,\nwhereas the STVG parameter reduces the {instability} of the circular orbit. The\nmotion of charged particles around the magnetized BH reveals various feasible\nregimes of the ionized Keplerian disk behavior. Thus, from the examination of\nparticle trajectories we observe that at fixed values of other parameters, the\nSchwarzschild BH captures the test particle; in the case of Kerr BH, the test\nparticle escapes to infinity or is captured by the BH, while in Kerr-MOG BH,\nthe test particle is trapped in some region around BH and starts orbiting it.\nOn investigating the MPP, we found that with increasing magnetic field, the\nbehavior of orbits becomes more chaotic. As a result, the particle escapes to\ninfinity more quickly.",
            "author": [
                "Saeed Ullah Khan",
                "Javlon Rayimbaev",
                "Zhi-Min Chen",
                "Zdenek Stuchl\u00edk"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16936v1",
                "http://arxiv.org/pdf/2311.16936v1"
            ],
            "primary_category": "gr-qc",
            "category": [
                "gr-qc",
                "hep-th"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16933v1",
            "title": "SparseCtrl: Adding Sparse Controls to Text-to-Video Diffusion Models",
            "updated": "2023-11-28T16:33:08Z",
            "published": "2023-11-28T16:33:08Z",
            "summary": "The development of text-to-video (T2V), i.e., generating videos with a given\ntext prompt, has been significantly advanced in recent years. However, relying\nsolely on text prompts often results in ambiguous frame composition due to\nspatial uncertainty. The research community thus leverages the dense structure\nsignals, e.g., per-frame depth/edge sequences, to enhance controllability,\nwhose collection accordingly increases the burden of inference. In this work,\nwe present SparseCtrl to enable flexible structure control with temporally\nsparse signals, requiring only one or a few inputs, as shown in Figure 1. It\nincorporates an additional condition encoder to process these sparse signals\nwhile leaving the pre-trained T2V model untouched. The proposed approach is\ncompatible with various modalities, including sketches, depth maps, and RGB\nimages, providing more practical control for video generation and promoting\napplications such as storyboarding, depth rendering, keyframe animation, and\ninterpolation. Extensive experiments demonstrate the generalization of\nSparseCtrl on both original and personalized T2V generators. Codes and models\nwill be publicly available at https://guoyww.github.io/projects/SparseCtrl .",
            "author": [
                "Yuwei Guo",
                "Ceyuan Yang",
                "Anyi Rao",
                "Maneesh Agrawala",
                "Dahua Lin",
                "Bo Dai"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16933v1",
                "http://arxiv.org/pdf/2311.16933v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16928v1",
            "title": "Pointwise Ergodic Theorems for Uniformly Behaved in ${\\mathbb N}$\n  Sequences",
            "updated": "2023-11-28T16:32:04Z",
            "published": "2023-11-28T16:32:04Z",
            "summary": "We define a uniformly behaved in ${\\mathbb N}$ arithmetic sequence ${\\bf a}$.\nWe give several examples, including the counting function of the prime factors\nin natural numbers, the Thue-Morse sequence, the Rudin-Shapiro sequence, the\nsequence of even (or odd) prime factor natural numbers, and the sequence of\nsquare-free natural numbers. We define an ${\\bf a}$-mean Lyapunov stable\ndynamical system $f$. We consider the mean partial sum of a continuous function\n$\\phi$ over the ${\\bf a}$-orbit of $f$ up to ${\\mathbb N}$. The main result we\nprove in the paper is that the mean partial sum converges pointwise if ${\\bf\na}$ is uniformly behaved in ${\\mathbb N}$ and $f$ is minimal and uniquely\nergodic and ${\\bf a}$-mean Lyapunov stable. In addition, if ${\\bf a}$ is also\ncompletely additive or multiplicative, we then prove that the mean partial sum\nof a continuous function $\\phi$ over the square-free ${\\bf a}$-orbit of $f$ up\nto ${\\mathbb N}$ converges pointwise too. We derive other consequences from the\nmain result relevant to dynamical systems/ergodic theory and number theory.",
            "author": [
                "Yunping Jiang",
                "Jessica Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16928v1",
                "http://arxiv.org/pdf/2311.16928v1"
            ],
            "primary_category": "math.NT",
            "category": [
                "math.NT",
                "math.DS",
                "Primary 11K65, 37A44, Secondary 11N37, 37A30"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16927v1",
            "title": "Study of speaker localization under dynamic and reverberant environments",
            "updated": "2023-11-28T16:31:36Z",
            "published": "2023-11-28T16:31:36Z",
            "summary": "Speaker localization in a reverberant environment is a fundamental problem in\naudio signal processing. Many solutions have been developed to tackle this\nproblem. However, previous algorithms typically assume a stationary environment\nin which both the microphone array and the sound sources are not moving. With\nthe emergence of wearable microphone arrays, acoustic scenes have become\ndynamic with moving sources and arrays. This calls for algorithms that perform\nwell in dynamic environments. In this article, we study the performance of a\nspeaker localization algorithm in such an environment. The study is based on\nthe recently published EasyCom speech dataset recorded in reverberant and noisy\nenvironments using a wearable array on glasses. Although the localization\nalgorithm performs well in static environments, its performance degraded\nsubstantially when used on the EasyCom dataset. The paper presents performance\nanalysis and proposes methods for improvement.",
            "author": [
                "Daniel A. Mitchell",
                "Boaz Rafaely"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16927v1",
                "http://arxiv.org/pdf/2311.16927v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16926v3",
            "title": "LLaFS: When Large-Language Models Meet Few-Shot Segmentation",
            "updated": "2023-12-05T10:04:37Z",
            "published": "2023-11-28T16:31:27Z",
            "summary": "This paper proposes LLaFS, the first attempt to leverage large language\nmodels (LLMs) in few-shot segmentation. In contrast to the conventional\nfew-shot segmentation methods that only rely on the limited and biased\ninformation from the annotated support images, LLaFS leverages the vast prior\nknowledge gained by LLM as an effective supplement and directly uses the LLM to\nsegment images in a few-shot manner. To enable the text-based LLM to handle\nimage-related tasks, we carefully design an input instruction that allows the\nLLM to produce segmentation results represented as polygons, and propose a\nregion-attribute table to simulate the human visual mechanism and provide\nmulti-modal guidance. We also synthesize pseudo samples and use curriculum\nlearning for pretraining to augment data and achieve better optimization. LLaFS\nachieves state-of-the-art results on multiple datasets, showing the potential\nof using LLMs for few-shot computer vision tasks. Code will be available at\nhttps://github.com/lanyunzhu99/LLaFS.",
            "author": [
                "Lanyun Zhu",
                "Tianrun Chen",
                "Deyi Ji",
                "Jieping Ye",
                "Jun Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16926v3",
                "http://arxiv.org/pdf/2311.16926v3"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16924v1",
            "title": "Fill-ins with scalar curvature lower bounds and applications to positive\n  mass theorems",
            "updated": "2023-11-28T16:28:44Z",
            "published": "2023-11-28T16:28:44Z",
            "summary": "Given a constant C and a smooth closed $(n-1)$-dimensional Riemannian\nmanifold $(\\Sigma, g)$ equipped with a positive function $H$, a natural\nquestion to ask is whether this manifold can be realised as the boundary of a\nsmooth $n$-dimensional Riemannian manifold with scalar curvature bounded below\nby C. That is, does there exist a fill-in of $(\\Sigma,g,H)$ with scalar\ncurvature bounded below by C?\n  We use variations of an argument due to Miao and the author\n[arXiv:1701.04805] to explicitly construct fill-ins with different scalar\ncurvature lower bounds, where we permit the fill-in to contain another boundary\ncomponent provided it is a minimal surface. Our main focus is to illustrate the\napplications of such fill-ins to geometric inequalities in the context of\ngeneral relativity. By filling in a manifold beyond a boundary, one is able to\nobtain lower bounds on the mass in terms of the boundary geometry through\npositive mass theorems and Penrose inequalities. We consider fill-ins with both\npositive and negative scalar curvature lower bounds, which from the perspective\nof general relativity corresponds to the sign of the cosmological constant, as\nwell as a fill-in suitable for the inclusion of electric charge.",
            "author": [
                "Stephen McCormick"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16924v1",
                "http://arxiv.org/pdf/2311.16924v1"
            ],
            "primary_category": "math.DG",
            "category": [
                "math.DG",
                "gr-qc",
                "53C99"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16922v1",
            "title": "Mitigating Object Hallucinations in Large Vision-Language Models through\n  Visual Contrastive Decoding",
            "updated": "2023-11-28T16:26:35Z",
            "published": "2023-11-28T16:26:35Z",
            "summary": "Large Vision-Language Models (LVLMs) have advanced considerably, intertwining\nvisual recognition and language understanding to generate content that is not\nonly coherent but also contextually attuned. Despite their success, LVLMs still\nsuffer from the issue of object hallucinations, where models generate plausible\nyet incorrect outputs that include objects that do not exist in the images. To\nmitigate this issue, we introduce Visual Contrastive Decoding (VCD), a simple\nand training-free method that contrasts output distributions derived from\noriginal and distorted visual inputs. The proposed VCD effectively reduces the\nover-reliance on statistical bias and unimodal priors, two essential causes of\nobject hallucinations. This adjustment ensures the generated content is closely\ngrounded to visual inputs, resulting in contextually accurate outputs. Our\nexperiments show that VCD, without either additional training or the usage of\nexternal tools, significantly mitigates the object hallucination issue across\ndifferent LVLM families. Beyond mitigating object hallucinations, VCD also\nexcels in general LVLM benchmarks, highlighting its wide-ranging applicability.",
            "author": [
                "Sicong Leng",
                "Hang Zhang",
                "Guanzheng Chen",
                "Xin Li",
                "Shijian Lu",
                "Chunyan Miao",
                "Lidong Bing"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16922v1",
                "http://arxiv.org/pdf/2311.16922v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16920v1",
            "title": "$\u039e(1620)$ production in $K^- p$ scattering process",
            "updated": "2023-11-28T16:24:57Z",
            "published": "2023-11-28T16:24:57Z",
            "summary": "In the present work, the production of $\\Xi(1620)$ in the $K^- p$ scattering\nprocess is investigated by using an effective Lagrangian approach, where\n$\\Xi(1620)$ is considered as a $\\bar{K} \\Lambda$ molecular state. Our\nestimations indicate that the cross sections for $K^-p\\to K^+ \\Xi(1620)^-$ are\n$(1.48 ^{+ 1.12}_{-0.69}) \\ \\mathrm{\\mu b}$ at $P_K=2.8 \\ \\mathrm{GeV}$, where\nthe uncertainties are resulted from the variation of the model parameter. As\nfor the $K^-p\\to K^+ \\pi^0 \\Xi^-$ process, the cross sections are estimated to\nbe $(0.61 ^{+0.47}_{-0.29})\\ \\mathrm{\\mu b}$ at $P_K =2.8 \\ \\mathrm{GeV}$,\nwhich is consistent with the experimental measurements.",
            "author": [
                "Quan-Yun Guo",
                "Zi-Li Yue",
                "Dian-Yong Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16920v1",
                "http://arxiv.org/pdf/2311.16920v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16918v1",
            "title": "RichDreamer: A Generalizable Normal-Depth Diffusion Model for Detail\n  Richness in Text-to-3D",
            "updated": "2023-11-28T16:22:33Z",
            "published": "2023-11-28T16:22:33Z",
            "summary": "Lifting 2D diffusion for 3D generation is a challenging problem due to the\nlack of geometric prior and the complex entanglement of materials and lighting\nin natural images. Existing methods have shown promise by first creating the\ngeometry through score-distillation sampling (SDS) applied to rendered surface\nnormals, followed by appearance modeling. However, relying on a 2D RGB\ndiffusion model to optimize surface normals is suboptimal due to the\ndistribution discrepancy between natural images and normals maps, leading to\ninstability in optimization. In this paper, recognizing that the normal and\ndepth information effectively describe scene geometry and be automatically\nestimated from images, we propose to learn a generalizable Normal-Depth\ndiffusion model for 3D generation. We achieve this by training on the\nlarge-scale LAION dataset together with the generalizable image-to-depth and\nnormal prior models. In an attempt to alleviate the mixed illumination effects\nin the generated materials, we introduce an albedo diffusion model to impose\ndata-driven constraints on the albedo component. Our experiments show that when\nintegrated into existing text-to-3D pipelines, our models significantly enhance\nthe detail richness, achieving state-of-the-art results. Our project page is\nhttps://lingtengqiu.github.io/RichDreamer/.",
            "author": [
                "Lingteng Qiu",
                "Guanying Chen",
                "Xiaodong Gu",
                "Qi Zuo",
                "Mutian Xu",
                "Yushuang Wu",
                "Weihao Yuan",
                "Zilong Dong",
                "Liefeng Bo",
                "Xiaoguang Han"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16918v1",
                "http://arxiv.org/pdf/2311.16918v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16911v1",
            "title": "Diffusive evaporation dynamics in polymer solutions is ubiquitous",
            "updated": "2023-11-28T16:15:01Z",
            "published": "2023-11-28T16:15:01Z",
            "summary": "Recent theory and experiments have shown how the buildup of a\nhigh-concentration polymer layer at a one-dimensional solvent-air interface can\nlead to an evaporation rate that scales with time as $t^{-1/2}$ and that is\ninsensitive to the ambient humidity. Using phase field modelling we show that\nthis scaling law constitutes a naturally emerging robust regime,\nDiffusion-Limited Evaporation (DLE). This regime dominates the dynamical state\ndiagram of the system, which also contains regions of constant and arrested\nevaporation, confirming and extending understanding of recent experimental\nobservations and theoretical predictions. We provide a theoretical argument to\nshow that the scaling observed in the DLE regime occurs for a wide range of\nparameters, and our simulations predict that it can occur in two-dimensional\ngeometries as well. Finally, we discuss possible extensions to more complex\nsystems.",
            "author": [
                "Max Huisman",
                "Wilson C. K. Poon",
                "Patrick B. Warren",
                "Simon Titmuss",
                "Davide Marenduzzo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16911v1",
                "http://arxiv.org/pdf/2311.16911v1"
            ],
            "primary_category": "cond-mat.soft",
            "category": [
                "cond-mat.soft"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16905v1",
            "title": "Analyzing the Influence of Language Model-Generated Responses in\n  Mitigating Hate Speech on Social Media Directed at Ukrainian Refugees in\n  Poland",
            "updated": "2023-11-28T16:08:42Z",
            "published": "2023-11-28T16:08:42Z",
            "summary": "In the context of escalating hate speech and polarization on social media,\nthis study investigates the potential of employing responses generated by Large\nLanguage Models (LLM), complemented with pertinent verified knowledge links, to\ncounteract such trends. Through extensive A/B testing involving the posting of\n753 automatically generated responses, the goal was to minimize the propagation\nof hate speech directed at Ukrainian refugees in Poland.\n  The results indicate that deploying LLM-generated responses as replies to\nharmful tweets effectively diminishes user engagement, as measured by\nlikes/impressions. When we respond to an original tweet, i.e., which is not a\nreply, we reduce the engagement of users by over 20\\% without increasing the\nnumber of impressions. On the other hand, our responses increase the ratio of\nthe number of replies to a harmful tweet to impressions, especially if the\nharmful tweet is not original. Additionally, the study examines how generated\nresponses influence the overall sentiment of tweets in the discussion,\nrevealing that our intervention does not significantly alter the mean\nsentiment.\n  This paper suggests the implementation of an automatic moderation system to\ncombat hate speech on social media and provides an in-depth analysis of the A/B\nexperiment, covering methodology, data collection, and statistical outcomes.\nEthical considerations and challenges are also discussed, offering guidance for\nthe development of discourse moderation systems leveraging the capabilities of\ngenerative AI.",
            "author": [
                "Jakub Podolak",
                "Szymon \u0141ukasik",
                "Pawe\u0142 Balawender",
                "Jan Ossowski",
                "Katarzyna B\u0105kowicz",
                "Piotr Sankowski"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16905v1",
                "http://arxiv.org/pdf/2311.16905v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16904v1",
            "title": "Study of BSM Inter-Packet Gap Tails in C-V2X Networks",
            "updated": "2023-11-28T16:08:00Z",
            "published": "2023-11-28T16:08:00Z",
            "summary": "Cellular vehicle-to-everything (C-V2X) enables safety-critical connected\nvehicular service by exchanging basic safety messages (BSMs) among nearby\nvehicular users (VUEs). Timely transmission of BSMs is crucial to avoid stale\ninformation at VUEs. However, successive packet losses can lead to large\ninter-packet gaps (IPGs), reducing the BSMs' reliability. This paper\ninvestigates the tail behavior of IPG and information age (IA) distributions in\nC-V2X mode 4, a decentralized resource allocation method based on\nsemi-persistent scheduling (SPS). We study the improvements and trade-offs\nintroduced by SAE one-shot transmission to decrease the number of successive\nBSM losses at destination VUEs. The study employs high-fidelity system-level\nsimulations that closely follow the SPS process of CV2X mode 4 to evaluate the\nperformance of interleaved one-shot SPS transmissions. The numerical results\ndemonstrate significant improvement in the IPG and IA tail distributions in\nvarious simulation scenarios. Additionally, we propose an accurate analytical\nmodel to characterize the IPG tail behavior of C-V2X BSM transmissions. The\nproposed model is validated by comparing its results with those obtained using\nthe system-level simulations. Our validation shows that the proposed model\ngenerates analytical results that coincide with the asymptotic slopes of IPG\ndistribution in different BSM transmission modes.",
            "author": [
                "Abdurrahman Fouda",
                "Randall Berry",
                "Ivan Vukovic"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16904v1",
                "http://arxiv.org/pdf/2311.16904v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.NA",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.03739v1",
            "title": "Syntax-Informed Interactive Model for Comprehensive Aspect-Based\n  Sentiment Analysis",
            "updated": "2023-11-28T16:03:22Z",
            "published": "2023-11-28T16:03:22Z",
            "summary": "Aspect-based sentiment analysis (ABSA), a nuanced task in text analysis,\nseeks to discern sentiment orientation linked to specific aspect terms in text.\nTraditional approaches often overlook or inadequately model the explicit\nsyntactic structures of sentences, crucial for effective aspect term\nidentification and sentiment determination. Addressing this gap, we introduce\nan innovative model: Syntactic Dependency Enhanced Multi-Task Interaction\nArchitecture (SDEMTIA) for comprehensive ABSA. Our approach innovatively\nexploits syntactic knowledge (dependency relations and types) using a\nspecialized Syntactic Dependency Embedded Interactive Network (SDEIN). We also\nincorporate a novel and efficient message-passing mechanism within a multi-task\nlearning framework to bolster learning efficacy. Our extensive experiments on\nbenchmark datasets showcase our model's superiority, significantly surpassing\nexisting methods. Additionally, incorporating BERT as an auxiliary feature\nextractor further enhances our model's performance.",
            "author": [
                "Ullman Galen",
                "Frey Lee",
                "Woods Ali"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03739v1",
                "http://arxiv.org/pdf/2312.03739v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16900v1",
            "title": "Lane-Keeping Control of Autonomous Vehicles Through a Soft-Constrained\n  Iterative LQR",
            "updated": "2023-11-28T15:58:13Z",
            "published": "2023-11-28T15:58:13Z",
            "summary": "The accurate prediction of smooth steering inputs is crucial for autonomous\nvehicle applications because control actions with jitter might cause the\nvehicle system to become unstable. To address this problem in automobile\nlane-keeping control without the use of additional smoothing algorithms, we\ndeveloped a soft-constrained iterative linear-quadratic regulator (soft-CILQR)\nalgorithm by integrating CILQR algorithm and a model predictive control (MPC)\nconstraint relaxation method. We incorporated slack variables into the state\nand control barrier functions of the soft-CILQR solver to soften the\nconstraints in the optimization process so that stabilizing control inputs can\nbe calculated in a relatively simple manner. Two types of automotive\nlane-keeping experiments were conducted with a linear system dynamics model to\ntest the performance of the proposed soft-CILQR algorithm and to compare its\nperformance with that of the CILQR algorithm: numerical simulations and\nexperiments involving challenging vision-based maneuvers. In the numerical\nsimulations, the soft-CILQR and CILQR solvers managed to drive the system\ntoward the reference state asymptotically; however, the soft-CILQR solver\nobtained smooth steering input trajectories more easily than did the CILQR\nsolver under conditions involving additive disturbances. In the experiments\nwith visual inputs, the soft-CILQR controller outperformed the CILQR controller\nin terms of tracking accuracy and steering smoothness during the driving of an\nego vehicle on TORCS.",
            "author": [
                "Der-Hau Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16900v1",
                "http://arxiv.org/pdf/2311.16900v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.RO",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16888v1",
            "title": "Technological Challenges of Ambient Serious Games in Higher Education",
            "updated": "2023-11-28T15:38:47Z",
            "published": "2023-11-28T15:38:47Z",
            "summary": "Naturally, university courses should be designed to attract students,\nengaging them to achieve learning goals. Toward this end, the use of Serious\nGames has been proposed in the literature. To address positive effects, such as\ncontent memorability and attendance rates, we propose Ambient Serious Games as\ngames embedded in a computer-enriched environment, which is only partially\nperceived mentally by players. In this paper, we describe five technological\nkey challenges that must be overcome to seamlessly and beneficially integrate\nan Ambient Serious Game into teaching. These challenges, derived from a\nscenario, focus on the technological provision and conduct of such games based\non a software platform. They include (1) the integration of physical smart\nlearning objects in heterogeneous environments under dynamic constraints, (2)\nthe representation of abstract subject matter using smart learning objects, (3)\nthe guided or automatic connection of all involved components, (4) the\nexplanation of the components, their interaction, as well as the serious game\nitself, and (5) feedback on the game state.",
            "author": [
                "Lea C. Brandl",
                "B\u00f6rge Kordts",
                "Andreas Schrader"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16888v1",
                "http://arxiv.org/pdf/2311.16888v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16886v1",
            "title": "Maximal Elements of Quantum Communication",
            "updated": "2023-11-28T15:33:49Z",
            "published": "2023-11-28T15:33:49Z",
            "summary": "A prepare-and-measure scenario is naturally described by a communication\nmatrix which collects all conditional outcome probabilities of the scenario\ninto a row-stochastic matrix. The set of all possible communication matrices is\npartially ordered via the ultraweak matrix majorization relation. By\nconsidering maximal elements in this preorder for a subset of matrices\nimplementable in a given theory, it becomes possible to identify communication\nmatrices of maximum utility, i.e., matrices that are not majorized by any other\nmatrices in the theory. The identity matrix of an appropriate size is the\ngreatest element in classical theories, while the maximal elements in quantum\ntheory have remain unknown. We completely characterize the maximal elements in\nquantum theory. In particular, we show that the identity matrix is the only\nmaximal element in quantum theory but, as opposed to a classical theory, it is\nnot the greatest element. Quantum theory can hence be seen to be distinct from\nclassical theory by the existence of incompatible communication matrices.",
            "author": [
                "Teiko Heinosaari",
                "Oskari Kerppo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16886v1",
                "http://arxiv.org/pdf/2311.16886v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16885v1",
            "title": "Is Betelgeuse really rotating? Synthetic ALMA observations of\n  large-scale convection in 3D simulations of Red Supergiants",
            "updated": "2023-11-28T15:33:04Z",
            "published": "2023-11-28T15:33:04Z",
            "summary": "The evolved stages of massive stars are poorly understood, but invaluable\nconstraints can be derived from spatially resolved observations of nearby red\nsupergiants, such as Betelgeuse. ALMA observations of Betelgeuse showing a\ndipolar velocity field have been interpreted as evidence for a rotation rate of\n$v\\sin i \\sim 5\\, \\mathrm{km\\, s^{-1}}$. This is two orders of magnitude larger\nthan predicted by single-star evolution, leading to the suggestion that\nBetelgeuse is a binary merger product. We propose instead that the velocity\nfield could be due to large-scale convective motions. The resulting surface\nvelocity maps can sometimes be mistaken for rotation, especially when the\nturbulent motions are only partially resolved, as is the case for the current\nALMA beam. We support this claim with 3D CO5BOLD simulations of non-rotating\nred supergiants post-processed to predict synthetic ALMA images and SiO spectra\nto compare with observed radial velocity maps. Our simulations show a $\\sim\n50\\%$ chance to be interpreted as evidence for a rotation rate as high as\nclaimed for Betelgeuse. We conclude that we need at least another ALMA\nobservation to firmly establish whether Betelgeuse is indeed rapidly rotating.\nSuch observations would also provide insight into the role of angular momentum\nand binary interaction in the late evolutionary stages. The data will further\nprobe the structure and complex physical processes in the atmospheres of red\nsupergiants, which are immediate progenitors of supernovae and are believed to\nbe essential in the formation of gravitational wave sources.",
            "author": [
                "Jing-Ze Ma",
                "Andrea Chiavassa",
                "Selma E. de Mink",
                "Ruggero Valli",
                "Stephen Justham",
                "Bernd Freytag"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16885v1",
                "http://arxiv.org/pdf/2311.16885v1"
            ],
            "primary_category": "astro-ph.SR",
            "category": [
                "astro-ph.SR",
                "astro-ph.IM",
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16884v1",
            "title": "Statistical inference for a service system with non-stationary arrivals\n  and unobserved balking",
            "updated": "2023-11-28T15:31:39Z",
            "published": "2023-11-28T15:31:39Z",
            "summary": "We study a multi-server queueing system with a periodic arrival rate and\ncustomers whose joining decision is based on their patience and a delay proxy.\nSpecifically, each customer has a patience level sampled from a common\ndistribution. Upon arrival, they receive an estimate of their delay before\njoining service and then join the system only if this delay is not more than\ntheir patience, otherwise they balk. The main objective is to estimate the\nparameters pertaining to the arrival rate and patience distribution. Here the\ncomplication factor is that this inference should be performed based on the\nobserved process only, i.e., balking customers remain unobserved. We set up a\nlikelihood function of the state dependent effective arrival process (i.e.,\ncorresponding to the customers who join), establish strong consistency of the\nMLE, and derive the asymptotic distribution of the estimation error. Due to the\nintrinsic non-stationarity of the Poisson arrival process, the proof techniques\nused in previous work become inapplicable. The novelty of the proving mechanism\nin this paper lies in the procedure of constructing i.i.d. objects from\ndependent samples by decomposing the sample path into i.i.d.\\ regeneration\ncycles. The feasibility of the MLE-approach is discussed via a sequence of\nnumerical experiments, for multiple choices of functions which provide delay\nestimates. In particular, it is observed that the arrival rate is best\nestimated at high service capacities, and the patience distribution is best\nestimated at lower service capacities.",
            "author": [
                "Shreehari Anand Bodas",
                "Michel Mandjes",
                "Liron Ravner"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16884v1",
                "http://arxiv.org/pdf/2311.16884v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR",
                "math.ST",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16882v1",
            "title": "Optimisation-Based Multi-Modal Semantic Image Editing",
            "updated": "2023-11-28T15:31:11Z",
            "published": "2023-11-28T15:31:11Z",
            "summary": "Image editing affords increased control over the aesthetics and content of\ngenerated images. Pre-existing works focus predominantly on text-based\ninstructions to achieve desired image modifications, which limit edit precision\nand accuracy. In this work, we propose an inference-time editing optimisation,\ndesigned to extend beyond textual edits to accommodate multiple editing\ninstruction types (e.g. spatial layout-based; pose, scribbles, edge maps). We\npropose to disentangle the editing task into two competing subtasks: successful\nlocal image modifications and global content consistency preservation, where\nsubtasks are guided through two dedicated loss functions. By allowing to adjust\nthe influence of each loss function, we build a flexible editing solution that\ncan be adjusted to user preferences. We evaluate our method using text, pose\nand scribble edit conditions, and highlight our ability to achieve complex\nedits, through both qualitative and quantitative experiments.",
            "author": [
                "Bowen Li",
                "Yongxin Yang",
                "Steven McDonagh",
                "Shifeng Zhang",
                "Petru-Daniel Tudosiu",
                "Sarah Parisot"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16882v1",
                "http://arxiv.org/pdf/2311.16882v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.03738v1",
            "title": "Syntactic Fusion: Enhancing Aspect-Level Sentiment Analysis Through\n  Multi-Tree Graph Integration",
            "updated": "2023-11-28T15:28:22Z",
            "published": "2023-11-28T15:28:22Z",
            "summary": "Recent progress in aspect-level sentiment classification has been propelled\nby the incorporation of graph neural networks (GNNs) leveraging syntactic\nstructures, particularly dependency trees. Nevertheless, the performance of\nthese models is often hampered by the innate inaccuracies of parsing\nalgorithms. To mitigate this challenge, we introduce SynthFusion, an innovative\ngraph ensemble method that amalgamates predictions from multiple parsers. This\nstrategy blends diverse dependency relations prior to the application of GNNs,\nenhancing robustness against parsing errors while avoiding extra computational\nburdens. SynthFusion circumvents the pitfalls of overparameterization and\ndiminishes the risk of overfitting, prevalent in models with stacked GNN\nlayers, by optimizing graph connectivity. Our empirical evaluations on the\nSemEval14 and Twitter14 datasets affirm that SynthFusion not only outshines\nmodels reliant on single dependency trees but also eclipses alternative\nensemble techniques, achieving this without an escalation in model complexity.",
            "author": [
                "Jane Sunny",
                "Tom Padraig",
                "Roggie Terry",
                "Woods Ali"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03738v1",
                "http://arxiv.org/pdf/2312.03738v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16878v1",
            "title": "Temporal Importance Factor for Loss Functions for CTR Prediction",
            "updated": "2023-11-28T15:28:12Z",
            "published": "2023-11-28T15:28:12Z",
            "summary": "Click-through rate (CTR) prediction is an important task for the companies to\nrecommend products which better match user preferences. User behavior in\ndigital advertising is dynamic and changes over time. It is crucial for the\ncompanies to capture the most recent trends to provide more accurate\nrecommendations for users. In CTR prediction, most models use binary\ncross-entropy loss function. However, it does not focus on the data\ndistribution shifts occurring over time. To address this problem, we propose a\nfactor for the loss functions by utilizing the sequential nature of user-item\ninteractions. This approach aims to focus on the most recent samples by\npenalizing them more through the loss function without forgetting the long-term\ninformation. Our solution is model-agnostic, and the temporal importance factor\ncan be used with different loss functions. Offline experiments in both public\nand company datasets show that the temporal importance factor for loss\nfunctions outperforms the baseline loss functions considered.",
            "author": [
                "Ramazan Tar\u0131k T\u00fcrksoy",
                "Beyza T\u00fcrkmen",
                "Furkan Durmu\u015f"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16878v1",
                "http://arxiv.org/pdf/2311.16878v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16867v2",
            "title": "The Falcon Series of Open Language Models",
            "updated": "2023-11-29T19:45:10Z",
            "published": "2023-11-28T15:12:47Z",
            "summary": "We introduce the Falcon series: 7B, 40B, and 180B parameters causal\ndecoder-only models trained on a diverse high-quality corpora predominantly\nassembled from web data. The largest model, Falcon-180B, has been trained on\nover 3.5 trillion tokens of text--the largest openly documented pretraining\nrun. Falcon-180B significantly outperforms models such as PaLM or Chinchilla,\nand improves upon concurrently developed models such as LLaMA 2 or\nInflection-1. It nears the performance of PaLM-2-Large at a reduced pretraining\nand inference cost, making it, to our knowledge, one of the three best language\nmodels in the world along with GPT-4 and PaLM-2-Large. We report detailed\nevaluations, as well as a deep dive into the methods and custom tooling\nemployed to pretrain Falcon. Notably, we report on our custom distributed\ntraining codebase, allowing us to efficiently pretrain these models on up to\n4,096 A100s on cloud AWS infrastructure with limited interconnect. We release a\n600B tokens extract of our web dataset, as well as the Falcon-7/40/180B models\nunder a permissive license to foster open-science and accelerate the\ndevelopment of an open ecosystem of large language models.",
            "author": [
                "Ebtesam Almazrouei",
                "Hamza Alobeidli",
                "Abdulaziz Alshamsi",
                "Alessandro Cappelli",
                "Ruxandra Cojocaru",
                "M\u00e9rouane Debbah",
                "\u00c9tienne Goffinet",
                "Daniel Hesslow",
                "Julien Launay",
                "Quentin Malartic",
                "Daniele Mazzotta",
                "Badreddine Noune",
                "Baptiste Pannier",
                "Guilherme Penedo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16867v2",
                "http://arxiv.org/pdf/2311.16867v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16866v1",
            "title": "Quantum Metric Learning for New Physics Searches at the LHC",
            "updated": "2023-11-28T15:12:43Z",
            "published": "2023-11-28T15:12:43Z",
            "summary": "In the NISQ (Noisy intermediate-scale quantum) area, Quantum computers can be\nutilized for deep learning by treating variational quantum circuits as neural\nnetwork models. This can be achieved by first encoding the input data onto\nquantum computers using nonparametric unitary gates. An alternative approach is\nto train the data encoding to map input data from different classes to\nseparated locations in the Hilbert space. The separation is achieved with\nmetric loss functions, hence the naming ``Quantum Metric Learning\". With the\nlimited number of qubits in the NISQ area, this approach works naturally as a\nhybrid classical-quantum computation enabling embedding of high-dimensional\nfeature data into a small number of qubits. Here, we consider an example of the\nglobal QCD color structure of hard b-jets emerging from color singlet scalar\ndecays to optimize the signal to background discrimination with a hybrid\nclassical-quantum metric learning. Due to the sparsity of data, self-supervised\nmethods with data augmentation have been utilized so far. Compared to the this\nclassical self-supervised approach, our hybrid method shows the better\nclassification performance without data augmentations. We emphasize that\nperformance enhancements independent of data augmentation techniques are devoid\nof the artificial risks introduced by data augmentation.",
            "author": [
                "A. Hammad",
                "Kyoungchul Kong",
                "Myeonghun Park",
                "Soyoung Shim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16866v1",
                "http://arxiv.org/pdf/2311.16866v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16865v1",
            "title": "A Benchmark for Evaluating Machine Translation Metrics on Dialects\n  Without Standard Orthography",
            "updated": "2023-11-28T15:12:11Z",
            "published": "2023-11-28T15:12:11Z",
            "summary": "For sensible progress in natural language processing, it is important that we\nare aware of the limitations of the evaluation metrics we use. In this work, we\nevaluate how robust metrics are to non-standardized dialects, i.e. spelling\ndifferences in language varieties that do not have a standard orthography. To\ninvestigate this, we collect a dataset of human translations and human\njudgments for automatic machine translations from English to two Swiss German\ndialects. We further create a challenge set for dialect variation and benchmark\nexisting metrics' performances. Our results show that existing metrics cannot\nreliably evaluate Swiss German text generation outputs, especially on segment\nlevel. We propose initial design adaptations that increase robustness in the\nface of non-standardized dialects, although there remains much room for further\nimprovement. The dataset, code, and models are available here:\nhttps://github.com/textshuttle/dialect_eval",
            "author": [
                "No\u00ebmi Aepli",
                "Chantal Amrhein",
                "Florian Schottmann",
                "Rico Sennrich"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16865v1",
                "http://arxiv.org/pdf/2311.16865v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16864v1",
            "title": "SAGE: A tool to constrain impacts of stellar activity on transmission\n  spectroscopy",
            "updated": "2023-11-28T15:10:56Z",
            "published": "2023-11-28T15:10:56Z",
            "summary": "Transmission spectroscopy is a proven technique to study a transiting\nexoplanet's atmosphere. However, stellar surface inhomogeneities, spots and\nfaculae, alter the observed transmission spectra: the stellar contamination\neffect. The variable nature of the stellar activity also makes it difficult to\nstitch together multi-epoch observations and evaluate any potential variability\nin the exoplanet's atmosphere. This paper introduces SAGE, a tool to correct\nfor the time-dependent impact of stellar activity on transmission spectra. It\nuses a pixelation approach to model the stellar surface with spots and faculae,\nwhile fully accounting for limb-darkening and rotational line-broadening. The\ncurrent version is designed for low to medium-resolution spectra. We used SAGE\nto evaluate stellar contamination for F to M-type hosts, testing various spot\nsizes and locations, and quantify the impact of limb-darkening. We find that\nlimb-darkening enhances the importance of the spot location on the stellar\ndisk, with spots close to the disk center impacting the transmission spectra\nmore strongly than spots near the limb. Moreover, due to the chromaticity of\nlimb darkening, the shape of the contamination spectrum is also altered.\nAdditionally, SAGE can be used to retrieve the properties and distribution of\nactive regions on the stellar surface from photometric monitoring. We\ndemonstrate this for WASP-69 using TESS data, finding that two spots at\nmid-latitudes and a combined coverage fraction of $\\sim$1% are favoured. SAGE\nallows us to connect the photometric variability to the stellar contamination\nof transmission spectra, enhancing our ability to jointly interpret\ntransmission spectra obtained at different epochs.",
            "author": [
                "Hritam Chakraborty",
                "Monika Lendl",
                "Babatunde Akinsanmi",
                "Dominique J. M. Petit dit de la Roche",
                "Adrien Deline"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16864v1",
                "http://arxiv.org/pdf/2311.16864v1"
            ],
            "primary_category": "astro-ph.EP",
            "category": [
                "astro-ph.EP",
                "astro-ph.IM",
                "astro-ph.SR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16863v1",
            "title": "Power Hungry Processing: Watts Driving the Cost of AI Deployment?",
            "updated": "2023-11-28T15:09:36Z",
            "published": "2023-11-28T15:09:36Z",
            "summary": "Recent years have seen a surge in the popularity of commercial AI products\nbased on generative, multi-purpose AI systems promising a unified approach to\nbuilding machine learning (ML) models into technology. However, this ambition\nof \"generality\" comes at a steep cost to the environment, given the amount of\nenergy these systems require and the amount of carbon that they emit. In this\nwork, we propose the first systematic comparison of the ongoing inference cost\nof various categories of ML systems, covering both task-specific (i.e.\nfinetuned models that carry out a single task) and `general-purpose' models,\n(i.e. those trained for multiple tasks). We measure deployment cost as the\namount of energy and carbon required to perform 1,000 inferences on\nrepresentative benchmark dataset using these models. We find that\nmulti-purpose, generative architectures are orders of magnitude more expensive\nthan task-specific systems for a variety of tasks, even when controlling for\nthe number of model parameters. We conclude with a discussion around the\ncurrent trend of deploying multi-purpose generative ML systems, and caution\nthat their utility should be more intentionally weighed against increased costs\nin terms of energy and emissions. All the data from our study can be accessed\nvia an interactive demo to carry out further exploration and analysis.",
            "author": [
                "Alexandra Sasha Luccioni",
                "Yacine Jernite",
                "Emma Strubell"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16863v1",
                "http://arxiv.org/pdf/2311.16863v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16858v1",
            "title": "Electronic Lieb lattice signatures embedded in two-dimensional polymers\n  with square lattice",
            "updated": "2023-11-28T15:06:27Z",
            "published": "2023-11-28T15:06:27Z",
            "summary": "Exotic band features, such as Dirac cones and flat bands, arise directly from\nthe lattice symmetry of materials. The Lieb lattice is one of the most\nintriguing topologies, because it possesses both Dirac cones and flat bands\nwhich intersect at the Fermi level. However, materials with Lieb lattice remain\nexperimentally unreached. Here, we explore two-dimensional poly-mers (2DPs)\nderived from zinc-phthalocyanine (ZnPc) building blocks with a square lattice\n(sql) as potential electronic Lieb lattice materials. By systematically varying\nthe linker lengths (ZnPc-xP), we found that some ZnPc-xP exhibit a\ncharacteristic Lieb lattice band structure. Interestingly though, fes bands are\nalso observed in ZnPc-xP. The coexistence of fes and Lieb in sql 2DPs\nchallenges the conventional perception of the structure-electronic structure\nrelation. In addition, we show that manipula-tion of the Fermi level, achieved\nby electron removal or atom substitution, effectively preserves the unique\ncharacteristics of Lieb bands. Chern number calculations confirm the\nnon-trivial nature of the Lieb Dirac bands. Our discoveries provide a fresh\nperspective on 2D polymers and redefine the search for Lieb lattice materials\ninto a well-defined chemical synthesis task.",
            "author": [
                "Yingying Zhang",
                "Shuangjie Zhao",
                "Miroslav Polo\u017eij",
                "Thomas Heine"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16858v1",
                "http://arxiv.org/pdf/2311.16858v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16857v1",
            "title": "SERENADE II: An ALMA Multi-Band Dust-Continuum Analysis of 28 Galaxies\n  at $5<z<8$ and the Physical Origin of the Dust Temperature Evolution",
            "updated": "2023-11-28T15:05:15Z",
            "published": "2023-11-28T15:05:15Z",
            "summary": "We present an analysis of ALMA multi-band dust-continuum observations for 28\nspectroscopically-confirmed bright Lyman-break galaxies at $5<z<8$. Our sample\nconsists of 11 galaxies at $z\\sim6$ newly observed in our ALMA program, which\nsubstantially increases the number of $5<z<8$ galaxies with both rest-frame 88\nand 158 $\\mu{\\rm m}$ continuum observations, allowing us to simultaneously\nmeasure the IR luminosity and dust temperature for a statistical sample of\n$z\\gtrsim5$ galaxies for the first time. We derive the relationship between the\nUV slope ($\\beta_{\\rm UV}$) and infrared excess (IRX) for the $z\\sim6$\ngalaxies, and find a shallower IRX-$\\beta_{\\rm UV}$ relation compared to the\nprevious results at $z\\sim2$--4. Based on the IRX-$\\beta_{\\rm UV}$ relation\nconsistent with our results and the $\\beta_{\\rm UV}$-$M_{\\rm UV}$ relation\nincluding fainter galaxies in the literature, we find a limited contribution of\nthe dust-obscured star formation to the total SFR density, $\\sim30\\%$ at\n$z\\sim6$. Our measurements of the dust temperature at $z\\sim6-7$, $T_{\\rm\ndust}=40.9_{-9.1}^{+10.0}\\,{\\rm K}$ on average, supports a gentle increase of\n$T_{\\rm dust}$ from $z=0$ to $z\\sim6$--7. Using an analytic model with\nparameters consistent with recent {\\it{JWST}} results, we discuss that the\nobserved redshift evolution of the dust temperature can be reproduced by an\n$\\sim0.6\\,{\\rm dex}$ increase in the gas depletion timescale and $\\sim0.4\\,{\\rm\ndex}$ decrease of the metallicity. The variety of $T_{\\rm dust}$ observed at\nhigh redshifts can also be naturally explained by scatters around the\nstar-formation main sequence and average mass-metallicity relation, including\nan extremely high dust temperature of $T_{\\rm dust}>80\\,{\\rm K}$ observed in a\ngalaxy at $z=8.3$.",
            "author": [
                "Ikki Mitsuhashi",
                "Yuichi Harikane",
                "Franz E. Bauer",
                "Tom Bakx",
                "Andrea Ferrara",
                "Seiji Fujimoto",
                "Takuya Hashimoto",
                "Akio K. Inoue",
                "Kazushi Iwasawa",
                "Yuri Nishimura",
                "Masatoshi Imanishi",
                "Yoshiaki Ono",
                "Toshiki Saito",
                "Yuma Sugahara",
                "Hideki Umehata",
                "Livia Vallini",
                "Tao Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16857v1",
                "http://arxiv.org/pdf/2311.16857v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16856v1",
            "title": "Attentional Graph Neural Networks for Robust Massive Network\n  Localization",
            "updated": "2023-11-28T15:05:13Z",
            "published": "2023-11-28T15:05:13Z",
            "summary": "Graph neural networks (GNNs) have gained significant popularity for\nclassification tasks in machine learning, yet their applications to regression\nproblems remain limited. Concurrently, attention mechanisms have emerged as\npowerful tools in sequential learning tasks. In this paper, we employ GNNs and\nattention mechanisms to address a classical but challenging nonlinear\nregression problem: network localization. We propose a novel GNN-based network\nlocalization method that achieves exceptional stability and accuracy in the\npresence of severe non-line-of-sight (NLOS) propagations, while eliminating the\nneed for laborious offline calibration or NLOS identification. Extensive\nexperimental results validate the effectiveness and high accuracy of our\nGNN-based localization model, particularly in challenging NLOS scenarios.\nHowever, the proposed GNN-based model exhibits limited flexibility, and its\naccuracy is highly sensitive to a specific hyperparameter that determines the\ngraph structure. To address the limitations and extend the applicability of the\nGNN-based model to real scenarios, we introduce two attentional graph neural\nnetworks (AGNNs) that offer enhanced flexibility and the ability to\nautomatically learn the optimal hyperparameter for each node. Experimental\nresults confirm that the AGNN models are able to enhance localization accuracy,\nproviding a promising solution for real-world applications. We also provide\nsome analyses of the improved performance achieved by the AGNN models from the\nperspectives of dynamic attention and signal denoising characteristics.",
            "author": [
                "Wenzhong Yan",
                "Juntao Wang",
                "Feng Yin",
                "Abdelhak M. Zoubir"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16856v1",
                "http://arxiv.org/pdf/2311.16856v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "eess.SP",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16849v1",
            "title": "Identifiable Feature Learning for Spatial Data with Nonlinear ICA",
            "updated": "2023-11-28T15:00:11Z",
            "published": "2023-11-28T15:00:11Z",
            "summary": "Recently, nonlinear ICA has surfaced as a popular alternative to the many\nheuristic models used in deep representation learning and disentanglement. An\nadvantage of nonlinear ICA is that a sophisticated identifiability theory has\nbeen developed; in particular, it has been proven that the original components\ncan be recovered under sufficiently strong latent dependencies. Despite this\ngeneral theory, practical nonlinear ICA algorithms have so far been mainly\nlimited to data with one-dimensional latent dependencies, especially\ntime-series data. In this paper, we introduce a new nonlinear ICA framework\nthat employs $t$-process (TP) latent components which apply naturally to data\nwith higher-dimensional dependency structures, such as spatial and\nspatio-temporal data. In particular, we develop a new learning and inference\nalgorithm that extends variational inference methods to handle the combination\nof a deep neural network mixing function with the TP prior, and employs the\nmethod of inducing points for computational efficacy. On the theoretical side,\nwe show that such TP independent components are identifiable under very general\nconditions. Further, Gaussian Process (GP) nonlinear ICA is established as a\nlimit of the TP Nonlinear ICA model, and we prove that the identifiability of\nthe latent components at this GP limit is more restricted. Namely, those\ncomponents are identifiable if and only if they have distinctly different\ncovariance kernels. Our algorithm and identifiability theorems are explored on\nsimulated spatial data and real world spatio-temporal data.",
            "author": [
                "Hermanni H\u00e4lv\u00e4",
                "Jonathan So",
                "Richard E. Turner",
                "Aapo Hyv\u00e4rinen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16849v1",
                "http://arxiv.org/pdf/2311.16849v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16848v1",
            "title": "Localization of a Passive Source with a Sensor Network based\n  Experimental Molecular Communication Platform",
            "updated": "2023-11-28T14:59:18Z",
            "published": "2023-11-28T14:59:18Z",
            "summary": "In a practical molecular communication scenario such as monitoring air\npollutants released from an unknown source, it is essential to estimate the\nlocation of the molecular transmitter (TX). This paper presents a novel Sensor\nNetwork-based Localization Algorithm (SNCLA) for passive transmission by using\na novel experimental platform which mainly comprises a clustered sensor network\n(SN) with $24$ sensor nodes and evaporating ethanol molecules as the passive\nTX. In SNCLA, a Gaussian plume model is employed to derive the location\nestimator. The parameters such as transmitted mass, wind velocity, detection\ntime, and actual concentration are calculated or estimated from the measured\nsignals via the SN to be employed as the input for the location estimator. The\nnumerical results show that the performance of SNCLA is better for stronger\nwinds in the medium. Our findings show that evaporated molecules do not\npropagate homogeneously through the SN due to the presence of the wind. In\naddition, our statistical analysis based on the measured experimental data\nshows that the sensed signals by the SN have a log-normal distribution, while\nthe additive noise follows a Student's t-distribution in contrast to the\nGaussian assumption in the literature.",
            "author": [
                "Fatih Gulec",
                "Damla Yagmur Koda",
                "Baris Atakan",
                "Andrew W. Eckford"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16848v1",
                "http://arxiv.org/pdf/2311.16848v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.ET"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16847v1",
            "title": "Introducing STRAUSS: A flexible sonification Python package",
            "updated": "2023-11-28T14:58:53Z",
            "published": "2023-11-28T14:58:53Z",
            "summary": "We introduce STRAUSS (Sonification Tools and Resources for Analysis Using\nSound Synthesis) a modular, self-contained and flexible Python sonification\npackage, operating in a free and open source (FOSS) capacity. STRAUSS is\nintended to be a flexible tool suitable for both scientific data exploration\nand analysis as well as for producing sonifications that are suitable for\npublic outreach and artistic contexts. We explain the motivations behind\nSTRAUSS, and how these lead to our design choices. We also describe the basic\ncode structure and concepts. We then present output sonification examples,\nspecifically: (1) multiple representations of univariate data (i.e., single\ndata series) for data exploration; (2) how multi-variate data can be mapped\nonto sound to help interpret how those data variables are related and; (3) a\nfull spatial audio example for immersive Virtual Reality. We summarise,\nalluding to some of the future functionality as STRAUSS development\naccelerates.",
            "author": [
                "James W. Trayford",
                "Chris M. Harrison"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16847v1",
                "http://arxiv.org/pdf/2311.16847v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "astro-ph.IM",
                "cs.HC",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16846v1",
            "title": "Normalized Ground State Solutions for Fractional Schrodinger Systems\n  with General Nonlinearities",
            "updated": "2023-11-28T14:58:41Z",
            "published": "2023-11-28T14:58:41Z",
            "summary": "Normalized ground state solutions (NGSS) of Schrodinger equations (SE) have\nattracted the attention of many research groups during the last decades. This\nis essentially due to their relevance in many fields in physics and\nengineering, where the stable and most attractive solutions happen to be the\nnormalized ones. For a single (SE), recent developments lead to the\nestablishment of existence and non-existence results for a wide range of\nnatural nonlinearities in (SE) in the sub-critical, critical and super-critical\nregimes. However for systems of (SE), there are still many interesting open\nquestions for basic nonlinearities. It certainly requires innovative ideas to\nshed some light to treat these complex situations. So far, only a very few\nspecific nonlinearities have been addressed. Unlike the single (SE), the\ncorresponding strict sub-additivity inequality is challenging and an improved\nconcentration-compactness theorem is critical to treat (NGSS) of systems of\n(SE). The aim of this paper is to establish the existence of (NGSS) for a large\nclass of nonlinearities. This class includes many relevant pure-power type\nnonlinearities and can be easily extended to Hartree type nonlinearities (and a\ncombination of both). The presence of the fractional Laplacian adds a\nconsiderable difficulty to rule out the dichotomy. We were able to overcome\nthis challenge and establish very general assumptions ensuring the strict\nsubadditivity of the constrained energy functional. We believe that our\napproach will open the door to many unresolved problems.",
            "author": [
                "Hichem Hajaiej",
                "Linjie Song"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16846v1",
                "http://arxiv.org/pdf/2311.16846v1"
            ],
            "primary_category": "math.AP",
            "category": [
                "math.AP",
                "49K99"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16844v1",
            "title": "A Direct Lazy Sampling Proof Technique in Probabilistic Relational Hoare\n  Logic",
            "updated": "2023-11-28T14:58:12Z",
            "published": "2023-11-28T14:58:12Z",
            "summary": "Programs using random values can either make all choices in advance (eagerly)\nor sample as needed (lazily). In formal proofs, we focus on\nindistinguishability between two lazy programs, a common requirement in the\nrandom oracle model (ROM). While rearranging sampling instructions often solves\nthis, it gets complex when sampling is spread across procedures. The\ntraditional approach, introduced by Bellare and Rogaway in 2004, converts\nprograms to eager sampling, but requires assuming finite memory, a polynomial\nbound, and artificial resampling functions. We introduce a novel approach in\nprobabilistic Relational Hoare Logic (pRHL) that directly proves\nindistinguishability, eliminating the need for conversions and the mentioned\nassumptions. We also implement this approach in the EasyCrypt theorem prover,\nshowing that it can be a convenient alternative to the traditional method.",
            "author": [
                "Roberto Metere",
                "Changyu Dong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16844v1",
                "http://arxiv.org/pdf/2311.16844v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.FL",
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16842v1",
            "title": "RELIC: Investigating Large Language Model Responses using\n  Self-Consistency",
            "updated": "2023-11-28T14:55:52Z",
            "published": "2023-11-28T14:55:52Z",
            "summary": "Large Language Models (LLMs) are notorious for blending fact with fiction and\ngenerating non-factual content, known as hallucinations. To tackle this\nchallenge, we propose an interactive system that helps users obtain insights\ninto the reliability of the generated text. Our approach is based on the idea\nthat the self-consistency of multiple samples generated by the same LLM relates\nto its confidence in individual claims in the generated texts. Using this idea,\nwe design RELIC, an interactive system that enables users to investigate and\nverify semantic-level variations in multiple long-form responses. This allows\nusers to recognize potentially inaccurate information in the generated text and\nmake necessary corrections. From a user study with ten participants, we\ndemonstrate that our approach helps users better verify the reliability of the\ngenerated text. We further summarize the design implications and lessons\nlearned from this research for inspiring future studies on reliable human-LLM\ninteractions.",
            "author": [
                "Furui Cheng",
                "Vil\u00e9m Zouhar",
                "Simran Arora",
                "Mrinmaya Sachan",
                "Hendrik Strobelt",
                "Mennatallah El-Assady"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16842v1",
                "http://arxiv.org/pdf/2311.16842v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16841v1",
            "title": "Two-step dynamic obstacle avoidance",
            "updated": "2023-11-28T14:55:50Z",
            "published": "2023-11-28T14:55:50Z",
            "summary": "Dynamic obstacle avoidance (DOA) is a fundamental challenge for any\nautonomous vehicle, independent of whether it operates in sea, air, or land.\nThis paper proposes a two-step architecture for handling DOA tasks by combining\nsupervised and reinforcement learning (RL). In the first step, we introduce a\ndata-driven approach to estimate the collision risk of an obstacle using a\nrecurrent neural network, which is trained in a supervised fashion and offers\nrobustness to non-linear obstacle movements. In the second step, we include\nthese collision risk estimates into the observation space of an RL agent to\nincrease its situational awareness.~We illustrate the power of our two-step\napproach by training different RL agents in a challenging environment that\nrequires to navigate amid multiple obstacles. The non-linear movements of\nobstacles are exemplarily modeled based on stochastic processes and periodic\npatterns, although our architecture is suitable for any obstacle dynamics. The\nexperiments reveal that integrating our collision risk metrics into the\nobservation space doubles the performance in terms of reward, which is\nequivalent to halving the number of collisions in the considered environment.\nFurthermore, we show that the architecture's performance improvement is\nindependent of the applied RL algorithm.",
            "author": [
                "Fabian Hart",
                "Martin Waltz",
                "Ostap Okhrin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16841v1",
                "http://arxiv.org/pdf/2311.16841v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16840v1",
            "title": "The Claire French Dialogue Dataset",
            "updated": "2023-11-28T14:55:22Z",
            "published": "2023-11-28T14:55:22Z",
            "summary": "We present the Claire French Dialogue Dataset (CFDD), a resource created by\nmembers of LINAGORA Labs in the context of the OpenLLM France initiative. CFDD\nis a corpus containing roughly 160 million words from transcripts and stage\nplays in French that we have assembled and publicly released in an effort to\nfurther the development of multilingual, open source language models. This\npaper describes the 24 individual corpora of which CFDD is composed and\nprovides links and citations to their original sources. It also provides our\nproposed breakdown of the full CFDD dataset into eight categories of subcorpora\nand describes the process we followed to standardize the format of the final\ndataset. We conclude with a discussion of similar work and future directions.",
            "author": [
                "Julie Hunter",
                "J\u00e9r\u00f4me Louradour",
                "Virgile Rennard",
                "Isma\u00efl Harrando",
                "Guokan Shang",
                "Jean-Pierre Lorr\u00e9"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16840v1",
                "http://arxiv.org/pdf/2311.16840v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16839v1",
            "title": "Beyond Hallucinations: Enhancing LVLMs through Hallucination-Aware\n  Direct Preference Optimization",
            "updated": "2023-11-28T14:54:37Z",
            "published": "2023-11-28T14:54:37Z",
            "summary": "Multimodal large language models have made significant advancements in recent\nyears, yet they still suffer from a common issue known as the \"hallucination\nproblem\" where the models generate textual descriptions that contain inaccurate\nor non-existent content from the image. To address this issue, this paper\nintroduces a novel strategy: Hallucination-Aware Direct Preference Optimization\n(HA-DPO). Our approach treats the hallucination problem as a unique preference\nselection issue, where the model is trained to favor the non-hallucinating\nresponse when presented with two responses of the same image (one accurate and\none hallucinating). This paper also presents an efficient process for\nconstructing hallucination sample pairs to ensure high-quality,\nstyle-consistent pairs for stable HA-DPO training. We applied this strategy to\ntwo mainstream multimodal models, and the results showed a significant\nreduction in the hallucination problem and an enhancement in the models'\ngeneralization capabilities. With HA-DPO, the MiniGPT-4 model demonstrates\nsignificant advancements: POPE accuracy increases from 51.13% to 85.66% (34.5%\nabsolute improvement), and the MME score escalates from 968.58 to 1365.76 (41%\nrelative improvement). The code, models, and datasets will be made publicly\navailable.",
            "author": [
                "Zhiyuan Zhao",
                "Bin Wang",
                "Linke Ouyang",
                "Xiaoyi Dong",
                "Jiaqi Wang",
                "Conghui He"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16839v1",
                "http://arxiv.org/pdf/2311.16839v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16838v1",
            "title": "Increasing Transparency of Reinforcement Learning using Shielding for\n  Human Preferences and Explanations",
            "updated": "2023-11-28T14:53:47Z",
            "published": "2023-11-28T14:53:47Z",
            "summary": "The adoption of Reinforcement Learning (RL) in several human-centred\napplications provides robots with autonomous decision-making capabilities and\nadaptability based on the observations of the operating environment. In such\nscenarios, however, the learning process can make robots' behaviours unclear\nand unpredictable to humans, thus preventing a smooth and effective Human-Robot\nInteraction (HRI). As a consequence, it becomes crucial to avoid robots\nperforming actions that are unclear to the user. In this work, we investigate\nwhether including human preferences in RL (concerning the actions the robot\nperforms during learning) improves the transparency of a robot's behaviours.\nFor this purpose, a shielding mechanism is included in the RL algorithm to\ninclude human preferences and to monitor the learning agent's decisions. We\ncarried out a within-subjects study involving 26 participants to evaluate the\nrobot's transparency in terms of Legibility, Predictability, and Expectability\nin different settings. Results indicate that considering human preferences\nduring learning improves Legibility with respect to providing only\nExplanations, and combining human preferences with explanations elucidating the\nrationale behind the robot's decisions further amplifies transparency. Results\nalso confirm that an increase in transparency leads to an increase in the\nsafety, comfort, and reliability of the robot. These findings show the\nimportance of transparency during learning and suggest a paradigm for robotic\napplications with human in the loop.",
            "author": [
                "Georgios Angelopoulos",
                "Luigi Mangiacapra",
                "Alessandra Rossi",
                "Claudia Di Napoli",
                "Silvia Rossi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16838v1",
                "http://arxiv.org/pdf/2311.16838v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17126v1",
            "title": "Reason out Your Layout: Evoking the Layout Master from Large Language\n  Models for Text-to-Image Synthesis",
            "updated": "2023-11-28T14:51:13Z",
            "published": "2023-11-28T14:51:13Z",
            "summary": "Recent advancements in text-to-image (T2I) generative models have shown\nremarkable capabilities in producing diverse and imaginative visuals based on\ntext prompts. Despite the advancement, these diffusion models sometimes\nstruggle to translate the semantic content from the text into images entirely.\nWhile conditioning on the layout has shown to be effective in improving the\ncompositional ability of T2I diffusion models, they typically require manual\nlayout input. In this work, we introduce a novel approach to improving T2I\ndiffusion models using Large Language Models (LLMs) as layout generators. Our\nmethod leverages the Chain-of-Thought prompting of LLMs to interpret text and\ngenerate spatially reasonable object layouts. The generated layout is then used\nto enhance the generated images' composition and spatial accuracy. Moreover, we\npropose an efficient adapter based on a cross-attention mechanism, which\nexplicitly integrates the layout information into the stable diffusion models.\nOur experiments demonstrate significant improvements in image quality and\nlayout accuracy, showcasing the potential of LLMs in augmenting generative\nimage models.",
            "author": [
                "Xiaohui Chen",
                "Yongfei Liu",
                "Yingxiang Yang",
                "Jianbo Yuan",
                "Quanzeng You",
                "Li-Ping Liu",
                "Hongxia Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17126v1",
                "http://arxiv.org/pdf/2311.17126v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16832v1",
            "title": "CharacterGLM: Customizing Chinese Conversational AI Characters with\n  Large Language Models",
            "updated": "2023-11-28T14:49:23Z",
            "published": "2023-11-28T14:49:23Z",
            "summary": "In this paper, we present CharacterGLM, a series of models built upon\nChatGLM, with model sizes ranging from 6B to 66B parameters. Our CharacterGLM\nis designed for generating Character-based Dialogues (CharacterDial), which\naims to equip a conversational AI system with character customization for\nsatisfying people's inherent social desires and emotional needs. On top of\nCharacterGLM, we can customize various AI characters or social agents by\nconfiguring their attributes (identities, interests, viewpoints, experiences,\nachievements, social relationships, etc.) and behaviors (linguistic features,\nemotional expressions, interaction patterns, etc.). Our model outperforms most\nmainstream close-source large langauge models, including the GPT series,\nespecially in terms of consistency, human-likeness, and engagement according to\nmanual evaluations. We will release our 6B version of CharacterGLM and a subset\nof training data to facilitate further research development in the direction of\ncharacter-based dialogue generation.",
            "author": [
                "Jinfeng Zhou",
                "Zhuang Chen",
                "Dazhen Wan",
                "Bosi Wen",
                "Yi Song",
                "Jifan Yu",
                "Yongkang Huang",
                "Libiao Peng",
                "Jiaming Yang",
                "Xiyao Xiao",
                "Sahand Sabour",
                "Xiaohan Zhang",
                "Wenjing Hou",
                "Yijia Zhang",
                "Yuxiao Dong",
                "Jie Tang",
                "Minlie Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16832v1",
                "http://arxiv.org/pdf/2311.16832v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16831v1",
            "title": "Tracking a Year of Polarized Twitter Discourse on Abortion",
            "updated": "2023-11-28T14:49:17Z",
            "published": "2023-11-28T14:49:17Z",
            "summary": "Abortion is one of the most contentious issues in American politics. The\nDobbs v. Jackson Women's Health Organization ruling in 2022, which shifted the\nauthority to regulate abortion from the federal government to the states,\ntriggering intense protests and emotional debates across the nation. Yet,\nlittle is known about how online discourse about abortion rights fluctuated on\nsocial media platforms. This study analyzes a corpus of over 57M\nabortion-related tweets from January 2022 to January 2023 to show how emotions,\nhateful rhetoric, toxic speech, use of obscenities and insults, and also\nframing strategies fluctuated over the span of one year among liberal and\nconservative users. We offer three key findings. (1) Fluctuations in emotions\nwere temporary; key events during the analyzed period did not bring about\nlasting shifts in expressed emotions. (2) We observe significant ideological\ndifferences in the use of hate speech: conservatives resorted to hateful\nrhetoric more than liberals. Yet, liberals were especially likely to use\nobscenities and insults, especially on the days the ruling was leaked and after\nthe Dobbs decision. In turn, toxic language sharply increased among both groups\nfollowing the leak and after the SCOTUS ruling. (3) Conservatives employ\nreligious and fetal personhood frames, while liberals emphasize women's health\nand bodily autonomy, with each group reacting negatively to the other group's\nframes. Our results offer an in-depth insight into the dynamics of online\ndiscourse on one of the most contentious issues in contemporary America.",
            "author": [
                "Ashwin Rao",
                "Rong-Ching Chang",
                "Qiankun Zhong",
                "Kristina Lerman",
                "Magdalena Wojcieszak"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16831v1",
                "http://arxiv.org/pdf/2311.16831v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16828v1",
            "title": "SARA: Controllable Makeup Transfer with Spatial Alignment and\n  Region-Adaptive Normalization",
            "updated": "2023-11-28T14:46:51Z",
            "published": "2023-11-28T14:46:51Z",
            "summary": "Makeup transfer is a process of transferring the makeup style from a\nreference image to the source images, while preserving the source images'\nidentities. This technique is highly desirable and finds many applications.\nHowever, existing methods lack fine-level control of the makeup style, making\nit challenging to achieve high-quality results when dealing with large spatial\nmisalignments. To address this problem, we propose a novel Spatial Alignment\nand Region-Adaptive normalization method (SARA) in this paper. Our method\ngenerates detailed makeup transfer results that can handle large spatial\nmisalignments and achieve part-specific and shade-controllable makeup transfer.\nSpecifically, SARA comprises three modules: Firstly, a spatial alignment module\nthat preserves the spatial context of makeup and provides a target semantic map\nfor guiding the shape-independent style codes. Secondly, a region-adaptive\nnormalization module that decouples shape and makeup style using per-region\nencoding and normalization, which facilitates the elimination of spatial\nmisalignments. Lastly, a makeup fusion module blends identity features and\nmakeup style by injecting learned scale and bias parameters. Experimental\nresults show that our SARA method outperforms existing methods and achieves\nstate-of-the-art performance on two public datasets.",
            "author": [
                "Xiaojing Zhong",
                "Xinyi Huang",
                "Zhonghua Wu",
                "Guosheng Lin",
                "Qingyao Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16828v1",
                "http://arxiv.org/pdf/2311.16828v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16824v1",
            "title": "The $B^0 \\to J/\u03c8f_0(1370,1500,1710)$ decays: an opportunity for\n  scalar glueball hunting",
            "updated": "2023-11-28T14:37:41Z",
            "published": "2023-11-28T14:37:41Z",
            "summary": "The scalars $f_0$ closest to 1.5 GeV contain the mesons $f_0(1370)$,\n$f_0(1500)$ and $f_0(1710)$, and the latter two ones are usually viewed as the\npotential candidates for the scalar glueballs. In this work, by including the\nimportant contributions from the vertex corrections, we study the decays $B^0\n\\to J/\\psi f_0$ within the improved perturbative QCD approach and analyze the\npossible scalar glueball hunting. Together with the two mixing models, namely,\n$f_0(1500) (f_0(1710))$ being the primary scalar glueball in model I (II), and\ntwo classification scenarios, namely, $f_0$ being the $q\\bar q$ excited\n(ground) states in scenario 1 (2), the branching fractions associated with\ntheir ratios for $B^0 \\to J/\\psi f_0$ are evaluated comprehensively. The\npredictions with still large uncertainties in the considered two mixing models\nare roughly consistent with currently limited data, which indicates that both\nmore rich data and more precise predictions are urgently demanded to figure out\nthe scalar glueball clearly in the future. Moreover, several interesting ratios\nbetween the branching fractions of $B^0 \\to J/\\psi f_0(\\to \\pi^+ \\pi^-/K^+\nK^-)$ and $B^0 \\to J/\\psi \\rho^0/\\phi (\\to \\pi^+ \\pi^-/ K^+ K^-)$ that could\nhelp us to understand the nature of scalar $f_0$ are defined and predicted\ntheoretically. These ratios should be examined in future experiments.",
            "author": [
                "Jia-Le Ren",
                "Min-Qi Li",
                "Xin Liu",
                "Zhi-Tian Zou",
                "Ying Li",
                "Zhen-Jun Xiao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16824v1",
                "http://arxiv.org/pdf/2311.16824v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16823v1",
            "title": "Engineering Ratchet-Based Particle Separation via Shortcuts to\n  Isothermality",
            "updated": "2023-11-28T14:37:21Z",
            "published": "2023-11-28T14:37:21Z",
            "summary": "Microscopic particle separation plays vital role in various scientific and\nindustrial domains. In this Letter, we propose a universal non-equilibrium\nthermodynamic approach, employing the concept of Shortcuts to Isothermality, to\nrealize controllable separation of overdamped Brownian particles. By utilizing\na designed ratchet potential with temporal period $\\tau$, we find in the\nslow-driving regime that the average particle velocity\n$\\Bar{v}_s\\propto\\left(1-D/D^*\\right)\\tau^{-1}$, indicating that particles with\ndifferent diffusion coefficients $D$ can be guided to move in distinct\ndirections with a preset $D^*$. Furthermore, we reveal that there exists an\nextra energetic cost with a lower bound\n$W_{\\rm{ex}}^{(\\rm{min})}\\propto\\mathcal{L}^{2}\\Bar{v}_s$, alongside a\nquasi-static work consumption. Here, $\\mathcal{L}$ is the thermodynamic length\nof the driving loop in the parametric space. We numerically validate our\ntheoretical findings and illustrate the optimal separation protocol (associated\nwith $W_{\\rm{ex}}^{(\\rm{min})}$) with a sawtooth potential. This study\nestablishes a bridge between thermodynamic process engineering and particle\nseparation, paving the way for further explorations of thermodynamic constrains\nand optimal control in ratchet-based particle separation.",
            "author": [
                "Xiu-Hua Zhao",
                "Z. C. Tu",
                "Yu-Han Ma"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16823v1",
                "http://arxiv.org/pdf/2311.16823v1"
            ],
            "primary_category": "cond-mat.stat-mech",
            "category": [
                "cond-mat.stat-mech",
                "cond-mat.mes-hall",
                "physics.app-ph",
                "physics.chem-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16822v1",
            "title": "Large Language Models Suffer From Their Own Output: An Analysis of the\n  Self-Consuming Training Loop",
            "updated": "2023-11-28T14:36:43Z",
            "published": "2023-11-28T14:36:43Z",
            "summary": "Large language models (LLM) have become state of the art in many benchmarks\nand conversational LLM applications like ChatGPT are now widely used by the\npublic. Those LLMs can be used to generate large amounts of content which is\nposted on the internet to various platforms. As LLMs are trained on datasets\nusually collected from the internet, this LLM-generated content might be used\nto train the next generation of LLMs. Therefore, a self-consuming training loop\nemerges in which new LLM generations are trained on the output from the\nprevious generations. We empirically study this self-consuming training loop\nusing a novel dataset to analytically and accurately measure quality and\ndiversity of generated outputs. We find that this self-consuming training loop\ninitially improves both quality and diversity. However, after a few generations\nthe output inevitably degenerates in diversity. We find that the rate of\ndegeneration depends on the proportion of real and generated data.",
            "author": [
                "Martin Briesch",
                "Dominik Sobania",
                "Franz Rothlauf"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16822v1",
                "http://arxiv.org/pdf/2311.16822v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16821v1",
            "title": "Denoising Diffusion Probabilistic Models for Image Inpainting of Cell\n  Distributions in the Human Brain",
            "updated": "2023-11-28T14:34:04Z",
            "published": "2023-11-28T14:34:04Z",
            "summary": "Recent advances in imaging and high-performance computing have made it\npossible to image the entire human brain at the cellular level. This is the\nbasis to study the multi-scale architecture of the brain regarding its\nsubdivision into brain areas and nuclei, cortical layers, columns, and cell\nclusters down to single cell morphology Methods for brain mapping and cell\nsegmentation exploit such images to enable rapid and automated analysis of\ncytoarchitecture and cell distribution in complete series of histological\nsections. However, the presence of inevitable processing artifacts in the image\ndata caused by missing sections, tears in the tissue, or staining variations\nremains the primary reason for gaps in the resulting image data. To this end we\naim to provide a model that can fill in missing information in a reliable way,\nfollowing the true cell distribution at different scales. Inspired by the\nrecent success in image generation, we propose a denoising diffusion\nprobabilistic model (DDPM), trained on light-microscopic scans of cell-body\nstained sections. We extend this model with the RePaint method to impute\nmissing or replace corrupted image data. We show that our trained DDPM is able\nto generate highly realistic image information for this purpose, generating\nplausible cell statistics and cytoarchitectonic patterns. We validate its\noutputs using two established downstream task models trained on the same data.",
            "author": [
                "Jan-Oliver Kropp",
                "Christian Schiffer",
                "Katrin Amunts",
                "Timo Dickscheid"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16821v1",
                "http://arxiv.org/pdf/2311.16821v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17124v1",
            "title": "A knowledge-driven AutoML architecture",
            "updated": "2023-11-28T14:31:38Z",
            "published": "2023-11-28T14:31:38Z",
            "summary": "This paper proposes a knowledge-driven AutoML architecture for pipeline and\ndeep feature synthesis. The main goal is to render the AutoML process\nexplainable and to leverage domain knowledge in the synthesis of pipelines and\nfeatures. The architecture explores several novel ideas: first, the\nconstruction of pipelines and deep features is approached in an unified way.\nNext, synthesis is driven by a shared knowledge system, interactively queried\nas to what pipeline operations to use or features to compute. Lastly, the\nsynthesis processes takes decisions at runtime using partial solutions and\nresults of their application on data. Two experiments are conducted to\ndemonstrate the functionality of a na\\\"{\\i}ve implementation of the proposed\narchitecture and to discuss its advantages, trade-offs as well as future\npotential for AutoML.",
            "author": [
                "Corneliu Cofaru",
                "Johan Loeckx"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17124v1",
                "http://arxiv.org/pdf/2311.17124v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16817v1",
            "title": "Acquisition of high-quality three-dimensional electron diffuse\n  scattering data",
            "updated": "2023-11-28T14:28:07Z",
            "published": "2023-11-28T14:28:07Z",
            "summary": "The diffraction patterns of crystalline materials with local order contain\nsharp Bragg reflections as well as highly structured diffuse scattering. The\ninstrumental requirements, experimental parameters and data processing\ntechniques for obtaining high-quality diffuse scattering data have previously\nbeen determined for X-ray and neutron diffraction, but not yet for electron\ndiffraction. In this study, we show that the spatial resolution of the diffuse\nscattering in three-dimensional electron diffraction (3D ED) data depends on\nvarious effects, including the convergence of the electron beam, the point\nspread function of the detector and the crystal mosaicity. In contrast to\nsingle-crystal X-ray diffraction, the detector point spread function for 3D ED\nis broader for a hybrid pixel detector than for a CCD. In our study, we also\ncompare the diffuse scattering in 3D ED data with the diffuse scattering in\nsingle-crystal X-ray diffraction data and show that the diffuse scattering in\n3D ED data can be obtained with a quality comparable to that from\nsingle-crystal X-ray diffraction. As electron diffraction requires much smaller\ncrystal sizes than X-ray diffraction, this opens up the possibility to\ninvestigate the local structure of many technologically relevant materials for\nwhich no crystals large enough for single-crystal X-ray diffraction are\navailable.",
            "author": [
                "Romy Poppe",
                "Joke Hadermann"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16817v1",
                "http://arxiv.org/pdf/2311.16817v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16812v1",
            "title": "Accuracy requirements on intrinsic alignments for Stage-IV cosmic shear",
            "updated": "2023-11-28T14:21:06Z",
            "published": "2023-11-28T14:21:06Z",
            "summary": "In the context of cosmological weak lensing studies, intrinsic alignments\n(IAs) are one the most complicated astrophysical systematic to model, given the\npoor understanding of the physical processes that cause them. A number of\nmodelling frameworks for IAs have been proposed in the literature, both purely\nphenomenological or grounded on a perturbative treatment of symmetry-based\narguments. However, the accuracy with which any of these approaches is able to\ndescribe the impact of IAs on cosmic shear data, particularly on the\ncomparatively small scales ($k\\simeq 1\\,{\\rm Mpc}^{-1}$) to which this\nobservable is sensitive, is not clear. Here we quantify the level of\ndisagreement between the true underlying intrinsic alignments and the\ntheoretical model used to describe them that can be allowed in the context of\ncosmic shear analyses with future Stage-IV surveys. We consider various models\ndescribing this ``IA residual'', covering both physics-based approaches, as\nwell as completely agnostic prescriptions. The same qualitative results are\nrecovered in all cases explored: for a Stage-IV cosmic shear survey, a\nmis-modelling of the IA contribution at the $\\sim10\\%$ level produces shifts of\n$\\lesssim0.5\\sigma$ on the final cosmological parameter constraints. Current\nand future IA models should therefore aim to achieve this level of accuracy, a\nprospect that is not unfeasible for models with sufficient flexibility.",
            "author": [
                "Anya Paopiamsap",
                "Natalia Porqueres",
                "David Alonso",
                "Joachim Harnois-Deraps",
                "C. Danielle Leonard"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16812v1",
                "http://arxiv.org/pdf/2311.16812v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16810v1",
            "title": "A Short Overview of 6G V2X Communication Standards",
            "updated": "2023-11-28T14:17:35Z",
            "published": "2023-11-28T14:17:35Z",
            "summary": "We are on the verge of a new age of linked autonomous cars with unheard-of\nuser experiences, dramatically improved air quality and road safety, extremely\nvaried transportation settings, and a plethora of cutting-edge apps. A\nsubstantially improved Vehicle-to-Everything (V2X) communication network that\ncan simultaneously support massive hyper-fast, ultra-reliable, and low-latency\ninformation exchange is necessary to achieve this ambitious goal. These needs\nof the upcoming V2X are expected to be satisfied by the Sixth Generation (6G)\ncommunication system. In this article, we start by introducing the history of\nV2X communications by giving details on the current, developing, and future\ndevelopments. We compare the applications of communication technologies such as\nWi-Fi, LTE, 5G, and 6G. we focus on the new technologies for 6G V2X which are\nbrain-vehicle interface, blocked-based V2X, and Machine Learning (ML). To\nachieve this, we provide a summary of the most recent ML developments in 6G\nvehicle networks. we discuss the security challenges of 6G V2X. We address the\nstrengths, open challenges, development, and improving areas of further study\nin this field.",
            "author": [
                "Donglin Wang",
                "Yann Nana Nganso",
                "Hans D. Schotten"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16810v1",
                "http://arxiv.org/pdf/2311.16810v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.NI",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16807v1",
            "title": "Agent-Aware Training for Agent-Agnostic Action Advising in Deep\n  Reinforcement Learning",
            "updated": "2023-11-28T14:09:43Z",
            "published": "2023-11-28T14:09:43Z",
            "summary": "Action advising endeavors to leverage supplementary guidance from expert\nteachers to alleviate the issue of sampling inefficiency in Deep Reinforcement\nLearning (DRL). Previous agent-specific action advising methods are hindered by\nimperfections in the agent itself, while agent-agnostic approaches exhibit\nlimited adaptability to the learning agent. In this study, we propose a novel\nframework called Agent-Aware trAining yet Agent-Agnostic Action Advising (A7)\nto strike a balance between the two. The underlying concept of A7 revolves\naround utilizing the similarity of state features as an indicator for\nsoliciting advice. However, unlike prior methodologies, the measurement of\nstate feature similarity is performed by neither the error-prone learning agent\nnor the agent-agnostic advisor. Instead, we employ a proxy model to extract\nstate features that are both discriminative (adaptive to the agent) and\ngenerally applicable (robust to agent noise). Furthermore, we utilize behavior\ncloning to train a model for reusing advice and introduce an intrinsic reward\nfor the advised samples to incentivize the utilization of expert guidance.\nExperiments are conducted on the GridWorld, LunarLander, and six prominent\nscenarios from Atari games. The results demonstrate that A7 significantly\naccelerates the learning process and surpasses existing methods (both\nagent-specific and agent-agnostic) by a substantial margin. Our code will be\nmade publicly available.",
            "author": [
                "Yaoquan Wei",
                "Shunyu Liu",
                "Jie Song",
                "Tongya Zheng",
                "Kaixuan Chen",
                "Yong Wang",
                "Mingli Song"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16807v1",
                "http://arxiv.org/pdf/2311.16807v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16800v1",
            "title": "Temporal Entropy Evolution in Stochastic and Delayed Dynamics",
            "updated": "2023-11-28T14:04:38Z",
            "published": "2023-11-28T14:04:38Z",
            "summary": "We review the behaviour of the Gibbs' and conditional entropies in\ndeterministic and stochastic systems with the added twist of a formulation\nappropriate for a stochastically perturbed system with {\\it delayed} dynamics.\nThe underlying question driving these investigations: ``Is the origin of the\nuniversally observed unidirectionality of time in our universe connected to the\nbehaviour of entropy?\"\n  We focus on temporal entropic behaviour with a review of previous results in\ndeterministic and stochastic systems. Our emphasis is on the temporal behaviour\nof the Gibbs' and conditional entropies as they give equilibrium results in\nconcordance with experimental findings. In invertible deterministic systems\nboth entropies are temporally constant as has been well known for decades. The\naddition of stochastic perturbations (Wiener process) leads to an indeterminate\n(either increasing or decreasing) behaviour of the Gibbs' entropy, but the\nconditional entropy monotonically approaches equilibrium with increasing time.\nThe presence of delays in the dynamics, whether stochastically perturbed or\nnot, leads to situations in which the Gibbs' and conditional entropies\nevolution can be oscillatory and not monotone, and may not approach\nequilibrium.",
            "author": [
                "Michael C. Mackey",
                "Marta Tyran-Kaminska"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16800v1",
                "http://arxiv.org/pdf/2311.16800v1"
            ],
            "primary_category": "math-ph",
            "category": [
                "math-ph",
                "math.MP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16798v1",
            "title": "A Novel 3D Non-stationary Localization-assisted ISAC Channel Model",
            "updated": "2023-11-28T14:02:13Z",
            "published": "2023-11-28T14:02:13Z",
            "summary": "Integrated sensing and communication (ISAC) has attracted wide attention as\nan emerging application scenario for the sixth generation (6G) wireless\ncommunication system. In this paper, a novel three-dimensional (3D)\nnon-stationary localization-assisted ISAC geometry-based stochastic model\n(GBSM) is proposed. The locations of the first-bounce scatterer and last-bounce\nscatterer in the communication channel can be estimated by the particle filter\nwith the assistance of backscattering sensing. The important channel\nstatistical properties of the proposed channel model are simulated and compared\nwith the ray tracing (RT) results, including the delay spread, azimuth angle of\ndeparture/arrival (AAoD/AAoA) spread, and elevation angle of departure/arrival\n(EAoD/EAoA) spread. The simulation results of the proposed channel model show a\ngood agreement with the RT results, which proves the correctness of the\nproposed channel model. Utilizing the localization parameters of scatterers,\nthe proposed ISAC channel model can better map the real environment.",
            "author": [
                "Runruo Yang",
                "Yang Wu",
                "Jie Huang",
                "Cheng-Xiang Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16798v1",
                "http://arxiv.org/pdf/2311.16798v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16790v1",
            "title": "Epitaxial two-dimensional membranes under intrinsic and extrinsic\n  strains",
            "updated": "2023-11-28T13:55:04Z",
            "published": "2023-11-28T13:55:04Z",
            "summary": "Two-dimensional (2D) materials naturally form moir\\'{e} patterns with other\ncrystalline layers, such as other 2D material or the surface of a substrate.\nThese patterns add a nanoscale characteristic length in the form of a\nsuperlattice: the moir\\'{e} wavelength. Understanding the origin and\ncharacteristics of these patterns is crucial to design/interpret\nmoir\\'{e}-induced physical properties. Here, we use a mixed continuum mechanics\n+ atomistic modeling to study two experimentally relevant epitaxial 2D\nmaterials -- graphene on Ir(111) and MoS$_2$ on Au(111) -- under extrinsic and\nintrinsic strain. We consider three different scenarios affecting substantially\nthe lattice constant of the 2D materials, the wavelength and corrugation of the\nmoir\\'{e} pattern. (i) Under the influence of the interaction with the\nsubstrate, bending energy produces non trivial variations of the moir\\'{e}\nproperties, even when the strain is small; (ii) When locked on a progressively\nstrained substrate via the valleys of the moir\\'{e}, the membranes'\nnanorippling amplitude goes through several jumps related to relatively smaller\njumps in the interatomic distance of the 2D materials; (iii) Finally,\nincreasing the zero-deformation value of this interatomic distance (possibly\ncontrolable with temperature or illumination in experiments) the moir\\'{e}\nwavelength can either increase or decrease.",
            "author": [
                "Nicolas Rougemaille",
                "Johann Coraux"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16790v1",
                "http://arxiv.org/pdf/2311.16790v1"
            ],
            "primary_category": "cond-mat.mes-hall",
            "category": [
                "cond-mat.mes-hall",
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16789v1",
            "title": "A Survey of the Evolution of Language Model-Based Dialogue Systems",
            "updated": "2023-11-28T13:51:32Z",
            "published": "2023-11-28T13:51:32Z",
            "summary": "Dialogue systems, including task-oriented_dialogue_system (TOD) and\nopen-domain_dialogue_system (ODD), have undergone significant transformations,\nwith language_models (LM) playing a central role. This survey delves into the\nhistorical trajectory of dialogue systems, elucidating their intricate\nrelationship with advancements in language models by categorizing this\nevolution into four distinct stages, each marked by pivotal LM breakthroughs:\n1) Early_Stage: characterized by statistical LMs, resulting in rule-based or\nmachine-learning-driven dialogue_systems; 2) Independent development of TOD and\nODD based on neural_language_models (NLM; e.g., LSTM and GRU), since NLMs lack\nintrinsic knowledge in their parameters; 3) fusion between different types of\ndialogue systems with the advert of pre-trained_language_models (PLMs),\nstarting from the fusion between four_sub-tasks_within_TOD, and then\nTOD_with_ODD; and 4) current LLM-based_dialogue_system, wherein LLMs can be\nused to conduct TOD and ODD seamlessly. Thus, our survey provides a\nchronological perspective aligned with LM breakthroughs, offering a\ncomprehensive review of state-of-the-art research outcomes. What's more, we\nfocus on emerging topics and discuss open challenges, providing valuable\ninsights into future directions for LLM-based_dialogue_systems. Through this\nexploration, we pave the way for a deeper_comprehension of the evolution,\nguiding future developments in LM-based dialogue_systems.",
            "author": [
                "Hongru Wang",
                "Lingzhi Wang",
                "Yiming Du",
                "Liang Chen",
                "Jingyan Zhou",
                "Yufei Wang",
                "Kam-Fai Wong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16789v1",
                "http://arxiv.org/pdf/2311.16789v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16787v1",
            "title": "Evaluating Optimal Reference Translations",
            "updated": "2023-11-28T13:50:50Z",
            "published": "2023-11-28T13:50:50Z",
            "summary": "The overall translation quality reached by current machine translation (MT)\nsystems for high-resourced language pairs is remarkably good. Standard methods\nof evaluation are not suitable nor intended to uncover the many translation\nerrors and quality deficiencies that still persist. Furthermore, the quality of\nstandard reference translations is commonly questioned and comparable quality\nlevels have been reached by MT alone in several language pairs. Navigating\nfurther research in these high-resource settings is thus difficult. In this\narticle, we propose a methodology for creating more reliable document-level\nhuman reference translations, called \"optimal reference translations,\" with the\nsimple aim to raise the bar of what should be deemed \"human translation\nquality.\" We evaluate the obtained document-level optimal reference\ntranslations in comparison with \"standard\" ones, confirming a significant\nquality increase and also documenting the relationship between evaluation and\ntranslation editing.",
            "author": [
                "Vil\u00e9m Zouhar",
                "V\u011bra Kloudov\u00e1",
                "Martin Popel",
                "Ond\u0159ej Bojar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16787v1",
                "http://arxiv.org/pdf/2311.16787v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16783v1",
            "title": "A General 3D Non-Stationary 5G Wireless Channel Model",
            "updated": "2023-11-28T13:46:04Z",
            "published": "2023-11-28T13:46:04Z",
            "summary": "A novel unified framework of geometry-based stochastic models (GBSMs) for the\nfifth generation (5G) wireless communication systems is proposed in this paper.\nThe proposed general 5G channel model aims at capturing small-scale fading\nchannel characteristics of key 5G communication scenarios, such as massive\nmultiple-input multiple-output (MIMO), high-speed train (HST),\nvehicle-to-vehicle (V2V), and millimeter wave (mmWave) communication scenarios.\nIt is a three-dimensional (3D) non-stationary channel model based on the WINNER\nII and Saleh-Valenzuela (SV) channel models considering array-time cluster\nevolution. Moreover, it can easily be reduced to various simplified channel\nmodels by properly adjusting model parameters. Statistical properties of the\nproposed general 5G small-scale fading channel model are investigated to\ndemonstrate its capability of capturing channel characteristics of various\nscenarios, with excellent fitting to some corresponding channel measurements.",
            "author": [
                "Shangbin Wu",
                "Cheng-Xiang Wang",
                "el-Hadi M. Aggoune",
                "Mohammed M. Alwakeel",
                "Xiao-Hu You"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16783v1",
                "http://arxiv.org/pdf/2311.16783v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16782v1",
            "title": "The curse of language biases in remote sensing VQA: the role of spatial\n  attributes, language diversity, and the need for clear evaluation",
            "updated": "2023-11-28T13:45:15Z",
            "published": "2023-11-28T13:45:15Z",
            "summary": "Remote sensing visual question answering (RSVQA) opens new opportunities for\nthe use of overhead imagery by the general public, by enabling human-machine\ninteraction with natural language. Building on the recent advances in natural\nlanguage processing and computer vision, the goal of RSVQA is to answer a\nquestion formulated in natural language about a remote sensing image. Language\nunderstanding is essential to the success of the task, but has not yet been\nthoroughly examined in RSVQA. In particular, the problem of language biases is\noften overlooked in the remote sensing community, which can impact model\nrobustness and lead to wrong conclusions about the performances of the model.\nThus, the present work aims at highlighting the problem of language biases in\nRSVQA with a threefold analysis strategy: visual blind models, adversarial\ntesting and dataset analysis. This analysis focuses both on model and data.\nMoreover, we motivate the use of more informative and complementary evaluation\nmetrics sensitive to the issue. The gravity of language biases in RSVQA is then\nexposed for all of these methods with the training of models discarding the\nimage data and the manipulation of the visual input during inference. Finally,\na detailed analysis of question-answer distribution demonstrates the root of\nthe problem in the data itself. Thanks to this analytical study, we observed\nthat biases in remote sensing are more severe than in standard VQA, likely due\nto the specifics of existing remote sensing datasets for the task, e.g.\ngeographical similarities and sparsity, as well as a simpler vocabulary and\nquestion generation strategies. While new, improved and less-biased datasets\nappear as a necessity for the development of the promising field of RSVQA, we\ndemonstrate that more informed, relative evaluation metrics remain much needed\nto transparently communicate results of future RSVQA methods.",
            "author": [
                "Christel Chappuis",
                "Eliot Walt",
                "Vincent Mendez",
                "Sylvain Lobry",
                "Bertrand Le Saux",
                "Devis Tuia"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16782v1",
                "http://arxiv.org/pdf/2311.16782v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17122v1",
            "title": "Large Model Based Referring Camouflaged Object Detection",
            "updated": "2023-11-28T13:45:09Z",
            "published": "2023-11-28T13:45:09Z",
            "summary": "Referring camouflaged object detection (Ref-COD) is a recently-proposed\nproblem aiming to segment out specified camouflaged objects matched with a\ntextual or visual reference. This task involves two major challenges: the COD\ndomain-specific perception and multimodal reference-image alignment. Our\nmotivation is to make full use of the semantic intelligence and intrinsic\nknowledge of recent Multimodal Large Language Models (MLLMs) to decompose this\ncomplex task in a human-like way. As language is highly condensed and\ninductive, linguistic expression is the main media of human knowledge learning,\nand the transmission of knowledge information follows a multi-level progression\nfrom simplicity to complexity. In this paper, we propose a large-model-based\nMulti-Level Knowledge-Guided multimodal method for Ref-COD termed MLKG, where\nmulti-level knowledge descriptions from MLLM are organized to guide the large\nvision model of segmentation to perceive the camouflage-targets and\ncamouflage-scene progressively and meanwhile deeply align the textual\nreferences with camouflaged photos. To our knowledge, our contributions mainly\ninclude: (1) This is the first time that the MLLM knowledge is studied for\nRef-COD and COD. (2) We, for the first time, propose decomposing Ref-COD into\ntwo main perspectives of perceiving the target and scene by integrating MLLM\nknowledge, and contribute a multi-level knowledge-guided method. (3) Our method\nachieves the state-of-the-art on the Ref-COD benchmark outperforming numerous\nstrong competitors. Moreover, thanks to the injected rich knowledge, it\ndemonstrates zero-shot generalization ability on uni-modal COD datasets. We\nwill release our code soon.",
            "author": [
                "Shupeng Cheng",
                "Ge-Peng Ji",
                "Pengda Qin",
                "Deng-Ping Fan",
                "Bowen Zhou",
                "Peng Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17122v1",
                "http://arxiv.org/pdf/2311.17122v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16773v1",
            "title": "Multi-Channel Cross Modal Detection of Synthetic Face Images",
            "updated": "2023-11-28T13:30:10Z",
            "published": "2023-11-28T13:30:10Z",
            "summary": "Synthetically generated face images have shown to be indistinguishable from\nreal images by humans and as such can lead to a lack of trust in digital\ncontent as they can, for instance, be used to spread misinformation. Therefore,\nthe need to develop algorithms for detecting entirely synthetic face images is\napparent. Of interest are images generated by state-of-the-art deep\nlearning-based models, as these exhibit a high level of visual realism. Recent\nworks have demonstrated that detecting such synthetic face images under\nrealistic circumstances remains difficult as new and improved generative models\nare proposed with rapid speed and arbitrary image post-processing can be\napplied. In this work, we propose a multi-channel architecture for detecting\nentirely synthetic face images which analyses information both in the frequency\nand visible spectra using Cross Modal Focal Loss. We compare the proposed\narchitecture with several related architectures trained using Binary Cross\nEntropy and show in cross-model experiments that the proposed architecture\nsupervised using Cross Modal Focal Loss, in general, achieves most competitive\nperformance.",
            "author": [
                "M. Ibsen",
                "C. Rathgeb",
                "S. Marcel",
                "C. Busch"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16773v1",
                "http://arxiv.org/pdf/2311.16773v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.03737v1",
            "title": "A Generic NLI approach for Classification of Sentiment Associated with\n  Therapies",
            "updated": "2023-11-28T13:27:21Z",
            "published": "2023-11-28T13:27:21Z",
            "summary": "This paper describes our system for addressing SMM4H 2023 Shared Task 2 on\n\"Classification of sentiment associated with therapies (aspect-oriented)\". In\nour work, we adopt an approach based on Natural language inference (NLI) to\nformulate this task as a sentence pair classification problem, and train\ntransformer models to predict sentiment associated with a therapy on a given\ntext. Our best model achieved 75.22\\% F1-score which was 11\\% (4\\%) more than\nthe mean (median) score of all teams' submissions.",
            "author": [
                "Rajaraman Kanagasabai",
                "Anitha Veeramani"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03737v1",
                "http://arxiv.org/pdf/2312.03737v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16771v1",
            "title": "The HR-Calculus: Enabling Information Processing with Quaternion Algebra",
            "updated": "2023-11-28T13:25:34Z",
            "published": "2023-11-28T13:25:34Z",
            "summary": "From their inception, quaternions and their division algebra have proven to\nbe advantageous in modelling rotation/orientation in three-dimensional spaces\nand have seen use from the initial formulation of electromagnetic filed theory\nthrough to forming the basis of quantum filed theory. Despite their impressive\nversatility in modelling real-world phenomena, adaptive information processing\ntechniques specifically designed for quaternion-valued signals have only\nrecently come to the attention of the machine learning, signal processing, and\ncontrol communities. The most important development in this direction is\nintroduction of the HR-calculus, which provides the required mathematical\nfoundation for deriving adaptive information processing techniques directly in\nthe quaternion domain. In this article, the foundations of the HR-calculus are\nrevised and the required tools for deriving adaptive learning techniques\nsuitable for dealing with quaternion-valued signals, such as the gradient\noperator, chain and product derivative rules, and Taylor series expansion are\npresented. This serves to establish the most important applications of adaptive\ninformation processing in the quaternion domain for both single-node and\nmulti-node formulations. The article is supported by Supplementary Material,\nwhich will be referred to as SM.",
            "author": [
                "Danilo P. Mandic",
                "Sayed Pouria Talebi",
                "Clive Cheong Took",
                "Yili Xia",
                "Dongpo Xu",
                "Min Xiang",
                "Pauline Bourigault"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16771v1",
                "http://arxiv.org/pdf/2311.16771v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.03736v1",
            "title": "De-identification of clinical free text using natural language\n  processing: A systematic review of current approaches",
            "updated": "2023-11-28T13:20:41Z",
            "published": "2023-11-28T13:20:41Z",
            "summary": "Background: Electronic health records (EHRs) are a valuable resource for\ndata-driven medical research. However, the presence of protected health\ninformation (PHI) makes EHRs unsuitable to be shared for research purposes.\nDe-identification, i.e. the process of removing PHI is a critical step in\nmaking EHR data accessible. Natural language processing has repeatedly\ndemonstrated its feasibility in automating the de-identification process.\nObjectives: Our study aims to provide systematic evidence on how the\nde-identification of clinical free text has evolved in the last thirteen years,\nand to report on the performances and limitations of the current\nstate-of-the-art systems. In addition, we aim to identify challenges and\npotential research opportunities in this field. Methods: A systematic search in\nPubMed, Web of Science and the DBLP was conducted for studies published between\nJanuary 2010 and February 2023. Titles and abstracts were examined to identify\nthe relevant studies. Selected studies were then analysed in-depth, and\ninformation was collected on de-identification methodologies, data sources, and\nmeasured performance. Results: A total of 2125 publications were identified for\nthe title and abstract screening. 69 studies were found to be relevant. Machine\nlearning (37 studies) and hybrid (26 studies) approaches are predominant, while\nsix studies relied only on rules. Majority of the approaches were trained and\nevaluated on public corpora. The 2014 i2b2/UTHealth corpus is the most\nfrequently used (36 studies), followed by the 2006 i2b2 (18 studies) and 2016\nCEGS N-GRID (10 studies) corpora.",
            "author": [
                "Aleksandar Kova\u010devi\u0107",
                "Bojana Ba\u0161aragin",
                "Nikola Milo\u0161evi\u0107",
                "Goran Nenadi\u0107"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03736v1",
                "http://arxiv.org/pdf/2312.03736v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.CR",
                "cs.DL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16768v2",
            "title": "Detecting the coupling of axion-like particles with fermions at the ILC",
            "updated": "2023-12-07T02:56:29Z",
            "published": "2023-11-28T13:19:26Z",
            "summary": "New pseudoscalars, axion-like particles (ALPs), provide the exciting target\nfor present and future collider-based experiments. Search for ALPs is performed\nin this paper via the $W^{+}W^{-}$ fusion process\n$e^{-}e^{+}\\rightarrow\\nu_{e}\\overline{\\nu_{e}}a\\rightarrow\\nu_{e}\\overline{\\nu_{e}}f\\overline{f}$\nat the $1$ TeV ILC corresponding to an integrated luminosity of $1$ ab$^{-1}$\nand the beam polarization $P(e^{-}$, $e^{+}) = (-80\\%$, $+20\\%)$. Owing to the\ngood capability of the ILC in performing b-tagging and the sufficiently large\nbranching ratio of the ALP decaying into a pair of b quarks, the decay channel\n$a\\rightarrow{b\\overline{b}}$ is mainly concerned. The prospective\nsensitivities provided by the ILC on the ALP-fermion coupling as low as $1$\nTeV$^{-1}$ and $1.75$ TeV$^{-1}$ are derived at $95\\%$ confidence level in the\nALP mass intervals $37-50$ GeV and $52-300$ GeV, respectively. Our results will\nhelp to probe significant parameter space in an unexplored region beyond the\nexisting constraints.",
            "author": [
                "Chong-Xing Yue",
                "Han Wang",
                "Yue-Qi Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16768v2",
                "http://arxiv.org/pdf/2311.16768v2"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16764v1",
            "title": "Radiology-Aware Model-Based Evaluation Metric for Report Generation",
            "updated": "2023-11-28T13:08:26Z",
            "published": "2023-11-28T13:08:26Z",
            "summary": "We propose a new automated evaluation metric for machine-generated radiology\nreports using the successful COMET architecture adapted for the radiology\ndomain. We train and publish four medically-oriented model checkpoints,\nincluding one trained on RadGraph, a radiology knowledge graph. Our results\nshow that our metric correlates moderately to high with established metrics\nsuch as BERTscore, BLEU, and CheXbert scores. Furthermore, we demonstrate that\none of our checkpoints exhibits a high correlation with human judgment, as\nassessed using the publicly available annotations of six board-certified\nradiologists, using a set of 200 reports. We also performed our own analysis\ngathering annotations with two radiologists on a collection of 100 reports. The\nresults indicate the potential effectiveness of our method as a\nradiology-specific evaluation metric. The code, data, and model checkpoints to\nreproduce our findings will be publicly available.",
            "author": [
                "Amos Calamida",
                "Farhad Nooralahzadeh",
                "Morteza Rohanian",
                "Koji Fujimoto",
                "Mizuho Nishio",
                "Michael Krauthammer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16764v1",
                "http://arxiv.org/pdf/2311.16764v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16762v1",
            "title": "Machine learning methods for American-style path-dependent contracts",
            "updated": "2023-11-28T13:05:06Z",
            "published": "2023-11-28T13:05:06Z",
            "summary": "In the present work, we introduce and compare state-of-the-art algorithms,\nthat are now classified under the name of machine learning, to price Asian and\nlook-back products with early-termination features. These include randomized\nfeed-forward neural networks, randomized recurrent neural networks, and a novel\nmethod based on signatures of the underlying price process. Additionally, we\nexplore potential applications on callable certificates. Furthermore, we\npresent an innovative approach for calculating sensitivities, specifically\nDelta and Gamma, leveraging Chebyshev interpolation techniques.",
            "author": [
                "Matteo Gambara",
                "Giulia Livieri",
                "Andrea Pallavicini"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16762v1",
                "http://arxiv.org/pdf/2311.16762v1"
            ],
            "primary_category": "q-fin.PR",
            "category": [
                "q-fin.PR",
                "q-fin.CP",
                "65C05, 91G20, 91G60"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16752v1",
            "title": "A three-point velocity estimation method for turbulent flows in two\n  spatial dimensions",
            "updated": "2023-11-28T12:50:56Z",
            "published": "2023-11-28T12:50:56Z",
            "summary": "Time delay and velocity estimation has been a widely studied subject in the\ncontext of signal processing, with applications in many different fields of\nphysics. The velocity of fluctuation structures is typically estimated as the\ndistance between two measurement points divided by the time lag that maximizes\nthe cross-correlation function between the measured signals. In this\ncontribution, we demonstrate that this technique is not suitable in two spatial\ndimensions unless the velocity is aligned with the separation between the\nmeasurement points. We present an improved method to accurately estimate both\ncomponents of the velocity vector relying on three non-aligned measurement\npoints. The cross-correlation based three-point time delay method is shown to\ngive exact results for the velocity components in the case of a super-position\nof uncorrelated Gaussian pulses. The new technique is tested on synthetic data\ngenerated from realizations of such processes for which the underlying velocity\ncomponents are known. The results are compared with and found vastly superior\nto those obtained using the standard two-point technique. Finally, we\ndemonstrate the applicability of the three-point method on gas puff imaging\ndata of strongly intermittent plasma fluctuations at the boundary of the\nAlcator C-Mod tokamak.",
            "author": [
                ". M. Losada",
                "A. D. Helgeland",
                "J. L. Terry",
                "O. E. Garcia"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16752v1",
                "http://arxiv.org/pdf/2311.16752v1"
            ],
            "primary_category": "physics.plasm-ph",
            "category": [
                "physics.plasm-ph",
                "physics.ins-det",
                "physics.space-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16744v1",
            "title": "Blockchain-based Zero Trust on the Edge",
            "updated": "2023-11-28T12:43:21Z",
            "published": "2023-11-28T12:43:21Z",
            "summary": "Internet of Things (IoT) devices pose significant security challenges due to\ntheir heterogeneity (i.e., hardware and software) and vulnerability to\nextensive attack surfaces. Today's conventional perimeter-based systems use\ncredential-based authentication (e.g., username/password, certificates, etc.)\nto decide whether an actor can access a network. However, the verification\nprocess occurs only at the system's perimeter because most IoT devices lack\nrobust security measures due to their limited hardware and software\ncapabilities, making them highly vulnerable. Therefore, this paper proposes a\nnovel approach based on Zero Trust Architecture (ZTA) extended with blockchain\nto further enhance security. The blockchain component serves as an immutable\ndatabase for storing users' requests and is used to verify trustworthiness by\nanalyzing and identifying potentially malicious user activities. We discuss the\nframework, processes of the approach, and the experiments carried out on a\ntestbed to validate its feasibility and applicability in the smart city\ncontext. Lastly, the evaluation focuses on non-functional properties such as\nperformance, scalability, and complexity.",
            "author": [
                "Cem Bicer",
                "Ilir Murturi",
                "Praveen Kumar Donta",
                "Schahram Dustdar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16744v1",
                "http://arxiv.org/pdf/2311.16744v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16743v1",
            "title": "About some works of Boris Polyak on convergence of gradient methods and\n  their development",
            "updated": "2023-11-28T12:42:41Z",
            "published": "2023-11-28T12:42:41Z",
            "summary": "The paper presents a review of the state-of-the-art of subgradient and\naccelerated methods of convex optimization, including in the presence of\ndisturbances and access to various information about the objective function\n(function value, gradient, stochastic gradient, higher derivatives). For\nnonconvex problems, the Polak-Lojasiewicz condition is considered and a review\nof the main results is given. The behavior of numerical methods in the presence\nof sharp minima is considered. The purpose of this survey is to show the\ninfluence of the works of B.T. Polyak (1935 -- 2023) on gradient optimization\nmethods and their neighborhoods on the modern development of numerical\noptimization methods.",
            "author": [
                "Seydamet Ablaev",
                "Aleksandr Beznosikov",
                "Alexander Gasnikov",
                "Darina Dvinskikh",
                "Aleksandr Lobanov",
                "Sergei Puchinin",
                "Fedor Stonyakin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16743v1",
                "http://arxiv.org/pdf/2311.16743v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16739v1",
            "title": "As-Plausible-As-Possible: Plausibility-Aware Mesh Deformation Using 2D\n  Diffusion Priors",
            "updated": "2023-11-28T12:35:13Z",
            "published": "2023-11-28T12:35:13Z",
            "summary": "We present As-Plausible-as-Possible (APAP) mesh deformation technique that\nleverages 2D diffusion priors to preserve the plausibility of a mesh under\nuser-controlled deformation. Our framework uses per-face Jacobians to represent\nmesh deformations, where mesh vertex coordinates are computed via a\ndifferentiable Poisson Solve. The deformed mesh is rendered, and the resulting\n2D image is used in the Score Distillation Sampling (SDS) process, which\nenables extracting meaningful plausibility priors from a pretrained 2D\ndiffusion model. To better preserve the identity of the edited mesh, we\nfine-tune our 2D diffusion model with LoRA. Gradients extracted by SDS and a\nuser-prescribed handle displacement are then backpropagated to the per-face\nJacobians, and we use iterative gradient descent to compute the final\ndeformation that balances between the user edit and the output plausibility. We\nevaluate our method with 2D and 3D meshes and demonstrate qualitative and\nquantitative improvements when using plausibility priors over\ngeometry-preservation or distortion-minimization priors used by previous\ntechniques.",
            "author": [
                "Seungwoo Yoo",
                "Kunho Kim",
                "Vladimir G. Kim",
                "Minhyuk Sung"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16739v1",
                "http://arxiv.org/pdf/2311.16739v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16737v1",
            "title": "Point'n Move: Interactive Scene Object Manipulation on Gaussian\n  Splatting Radiance Fields",
            "updated": "2023-11-28T12:33:49Z",
            "published": "2023-11-28T12:33:49Z",
            "summary": "We propose Point'n Move, a method that achieves interactive scene object\nmanipulation with exposed region inpainting. Interactivity here further comes\nfrom intuitive object selection and real-time editing. To achieve this, we\nadopt Gaussian Splatting Radiance Field as the scene representation and fully\nleverage its explicit nature and speed advantage. Its explicit representation\nformulation allows us to devise a 2D prompt points to 3D mask dual-stage\nself-prompting segmentation algorithm, perform mask refinement and merging,\nminimize change as well as provide good initialization for scene inpainting and\nperform editing in real-time without per-editing training, all leads to\nsuperior quality and performance. We test our method by performing editing on\nboth forward-facing and 360 scenes. We also compare our method against existing\nscene object removal methods, showing superior quality despite being more\ncapable and having a speed advantage.",
            "author": [
                "Jiajun Huang",
                "Hongchuan Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16737v1",
                "http://arxiv.org/pdf/2311.16737v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.03735v1",
            "title": "Advancing State of the Art in Language Modeling",
            "updated": "2023-11-28T12:30:43Z",
            "published": "2023-11-28T12:30:43Z",
            "summary": "Generalization is arguably the most important goal of statistical language\nmodeling research. Publicly available benchmarks and papers published with an\nopen-source code have been critical to advancing the field. However, it is\noften very difficult, and sometimes even impossible, to reproduce the results\nfully as reported in publications. In this paper, we propose a simple framework\nthat should help advance the state of the art in language modeling in terms of\ngeneralization. We propose to publish not just the code, but also probabilities\non dev and test sets with future publications so that one can easily add the\nnew model into an ensemble. This has crucial advantages: it is much easier to\ndetermine whether a newly proposed model is actually complementary to the\ncurrent baseline. Therefore, instead of inventing new names for the old tricks,\nthe scientific community can advance faster. Finally, this approach promotes\ndiversity of ideas: one does not need to create an individual model that is the\nnew state of the art to attract attention; it will be sufficient to develop a\nnew model that learns patterns which other models do not. Thus, even a\nsuboptimal model can be found to have value. Remarkably, our approach has\nyielded new state-of-the-art results across various language modeling\nbenchmarks up to 10%.",
            "author": [
                "David Herel",
                "Tomas Mikolov"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03735v1",
                "http://arxiv.org/pdf/2312.03735v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16733v3",
            "title": "LLMs for Science: Usage for Code Generation and Data Analysis",
            "updated": "2023-12-07T15:30:28Z",
            "published": "2023-11-28T12:29:33Z",
            "summary": "Large language models (LLMs) have been touted to enable increased\nproductivity in many areas of today's work life. Scientific research as an area\nof work is no exception: the potential of LLM-based tools to assist in the\ndaily work of scientists has become a highly discussed topic across\ndisciplines. However, we are only at the very onset of this subject of study.\nIt is still unclear how the potential of LLMs will materialise in research\npractice. With this study, we give first empirical evidence on the use of LLMs\nin the research process. We have investigated a set of use cases for LLM-based\ntools in scientific research, and conducted a first study to assess to which\ndegree current tools are helpful. In this paper we report specifically on use\ncases related to software engineering, such as generating application code and\ndeveloping scripts for data analytics. While we studied seemingly simple use\ncases, results across tools differ significantly. Our results highlight the\npromise of LLM-based tools in general, yet we also observe various issues,\nparticularly regarding the integrity of the output these tools provide.",
            "author": [
                "Mohamed Nejjar",
                "Luca Zacharias",
                "Fabian Stiehle",
                "Ingo Weber"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16733v3",
                "http://arxiv.org/pdf/2311.16733v3"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16732v1",
            "title": "Collisional radiative modelling with improved cross sections to\n  investigate plasma molecular interactions in divertor plasmas",
            "updated": "2023-11-28T12:28:43Z",
            "published": "2023-11-28T12:28:43Z",
            "summary": "Power exhaust is one of the main challenges for the realization of practical\nfusion energy production. The magnetic confinement approach to fusion often\nuses a divertor configuration, where power loads are critical. Recent SOLPS\nsimulations of divertor plasmas in MAST-U and TCV show significant deviations\nfrom the experimental results [36, 35]. A possible explanation for this is the\nincorrect incorporation of plasma-molecular interactions in current SOLPS\nsimulations. SOLPS uses tabulated rate data for the particle physics part of\nthe simulations [37, 23]. There are, however, large concerns about the accuracy\nof these rates, especially for plasma-molecular interactions [33]. Therefore,\nin this work, improved rate data from different sources, such as the\nLaporta[18] and MCCCDB[29, 27, 28] databases was used, to construct a\nCollisional Radiative Model (CRM) to investigate the plasma molecular\ninteractions in conditions relevant to the MAST-U Super-X divertor. It was\nshown that using these rates, a better correspondence with experiment is\nachieved than with the tabulated rates. In particular, increased Molecular\nActivated Recombination (MAR) and Dissociation (MAD) was observed. Additionally\nit was found that molecular processes may be a significant contributor to\ndivertor physics. The effect of different processes on the vibrational\ndistribution was also investigated, as well as the radiative emission spectra\ngenerated from the CRM. It was demonstrated that re-evaluation of reaction\nrates for plasma-molecular interactions in plasma-edge modelling is necessary.",
            "author": [
                "Stijn Kobussen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16732v1",
                "http://arxiv.org/pdf/2311.16732v1"
            ],
            "primary_category": "physics.plasm-ph",
            "category": [
                "physics.plasm-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16727v1",
            "title": "Sluggish and Chemically-Biased Interstitial Diffusion in Concentrated\n  Solid Solution Alloys: Mechanisms and Methods",
            "updated": "2023-11-28T12:16:06Z",
            "published": "2023-11-28T12:16:06Z",
            "summary": "Interstitial diffusion is a pivotal process that governs the phase stability\nand irradiation response of materials in non-equilibrium conditions. In this\nwork, we study sluggish and chemically-biased interstitial diffusion in Fe-Ni\nconcentrated solid solution alloys (CSAs) by combining machine learning (ML)\nand kinetic Monte Carlo (kMC), where ML is used to accurately and efficiently\npredict the migration energy barriers on-the-fly. The ML-kMC reproduces the\ndiffusivity that was reported by molecular dynamics results at high\ntemperatures. With this powerful tool, we find that the observed sluggish\ndiffusion and the \"Ni-Ni-Ni\"-biased diffusion in Fe-Ni alloys are ascribed to a\nunique \"Barrier Lock\" mechanism, whereas the \"Fe-Fe-Fe\"-biased diffusion is\ninfluenced by a \"Component Dominance\" mechanism. Inspired by the mentioned\nmechanisms, a practical AvgS-kMC method is proposed for conveniently and\nswiftly determining interstitial-mediated diffusivity by only relying on the\nmean energy barriers of migration patterns. Combining the AvgS-kMC with the\ndifferential evolutionary algorithm, an inverse design strategy for optimizing\nsluggish diffusion properties is applied to emphasize the crucial role of\nfavorable migration patterns.",
            "author": [
                "Biao Xu",
                "Haijun Fu",
                "Shasha Huang",
                "Shihua Ma",
                "Yaoxu Xiong",
                "Jun Zhang",
                "Xuepeng Xiang",
                "Wenyu Lu",
                "Ji-Jung Kai",
                "Shijun Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16727v1",
                "http://arxiv.org/pdf/2311.16727v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "cs.LG",
                "physics.atm-clus"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16725v1",
            "title": "Temperature dependence of the magnon-phonon interaction in high overtone\n  bulk acoustic resonator-ferromagnetic thin film hybrids",
            "updated": "2023-11-28T12:11:44Z",
            "published": "2023-11-28T12:11:44Z",
            "summary": "Tailored magnon-phonon hybrid systems, where high overtone bulk acoustic\nresonators couple resonantly to the magnonic mode of a ferromagnetic thin film,\nare considered optimal for the creation of acoustic phonons with a defined\ncircular polarization. This class of devices is therefore ideal for the\ninvestigation of phonon propagation properties and assessing their capacity to\ntransport angular momentum in the classical and potentially even in the quantum\nregime. Here, we study the coupling between the magnons in a ferromagnetic\n\\ch{Co25Fe75} thin film and the transverse acoustic phonons in a bulk acoustic\nwave resonators formed by the sapphire substrate onto which the film is\ndeposited. Using broadband ferromagnetic resonance experiments as a function of\ntemperature, we investigate the strength of the coherent magnon-phonon\ninteraction and the individual damping rates of the magnons and phonons\nparticipating in the process. This demonstrates that this coupled magnon-phonon\nsystem can reach a cooperativity $C\\approx 1$ at cryogenic temperatures. Our\nexperiments also showcase the potential of strongly coupled magnon-phonon\nsystems for strain sensing applications.",
            "author": [
                "Manuel M\u00fcller",
                "Johannes Weber",
                "Sebastian T. B. Goennenwein",
                "S. Viola Kusminskiy",
                "Rudolf Gross",
                "Matthias Althammer",
                "Hans Huebl"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16725v1",
                "http://arxiv.org/pdf/2311.16725v1"
            ],
            "primary_category": "cond-mat.mes-hall",
            "category": [
                "cond-mat.mes-hall"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16721v1",
            "title": "Analytic solution of Markovian epidemics without re-infections on\n  heterogeneous networks",
            "updated": "2023-11-28T12:05:31Z",
            "published": "2023-11-28T12:05:31Z",
            "summary": "Most epidemic processes on networks can be modelled by a compartmental model,\nthat specifies the spread of a disease in a population. The corresponding\ncompartmental graph describes how the viral state of the nodes (individuals)\nchanges from one compartment to another. If the compartmental graph does not\ncontain directed cycles (e.g. the famous SIR model satisfies this property),\nthen we provide an analytic, closed-form solution of the continuous-time\nMarkovian compartmental model on heterogeneous networks. The eigenvalues of the\nMarkovian process are related to cut sets in the contact graph between nodes\nwith different viral states. We illustrate our finding by analytically solving\nthe continuous-time Markovian SI and SIR processes on heterogeneous networks.\nWe show that analytic extensions to e.g. non-Markovian dynamics, temporal\nnetworks, simplicial contagion and more advanced compartmental models are\npossible. Our exact and explicit formula contains sums over all paths between\ntwo states in the SIR Markov graph, which prevents the computation of the exact\nsolution for arbitrary large graphs.",
            "author": [
                "Massimo A. Achterberg",
                "Piet Van Mieghem"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16721v1",
                "http://arxiv.org/pdf/2311.16721v1"
            ],
            "primary_category": "physics.soc-ph",
            "category": [
                "physics.soc-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16720v1",
            "title": "RankingGPT: Empowering Large Language Models in Text Ranking with\n  Progressive Enhancement",
            "updated": "2023-11-28T12:04:19Z",
            "published": "2023-11-28T12:04:19Z",
            "summary": "Text ranking is a critical task in various information retrieval\napplications, and the recent success of Large Language Models (LLMs) in natural\nlanguage processing has sparked interest in their application to text ranking.\nThese methods primarily involve combining query and candidate documents and\nleveraging prompt learning to determine query-document relevance using the\nLLM's output probabilities for specific tokens or by directly generating a\nranked list of candidate documents. Although these approaches have demonstrated\npromise, a noteworthy disparity arises between the training objective of LLMs,\nwhich typically centers around next token prediction, and the objective of\nevaluating query-document relevance. To address this gap and fully leverage LLM\npotential in text ranking tasks, we propose a progressive multi-stage training\nstrategy. Firstly, we introduce a large-scale weakly supervised dataset of\nrelevance texts to enable the LLMs to acquire the ability to predict relevant\ntokens without altering their original training objective. Subsequently, we\nincorporate supervised training to further enhance LLM ranking capability. Our\nexperimental results on multiple benchmarks demonstrate the superior\nperformance of our proposed method compared to previous competitive approaches,\nboth in in-domain and out-of-domain scenarios.",
            "author": [
                "Longhui Zhang",
                "Yanzhao Zhang",
                "Dingkun Long",
                "Pengjun Xie",
                "Meishan Zhang",
                "Min Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16720v1",
                "http://arxiv.org/pdf/2311.16720v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16719v1",
            "title": "Proof-theoretic Semantics for the Logic of Bunched Implications",
            "updated": "2023-11-28T12:01:03Z",
            "published": "2023-11-28T12:01:03Z",
            "summary": "Typically, substructural logics are used in applications because of their\nresource interpretations, and these interpretations often refer to the\ncelebrated number-of-uses reading of their implications. However, despite its\nprominence, this reading is not at all reflected in the truth-functional\nsemantics of these logics. It is a proof-theoretic interpretation of the logic.\nHence, one desires a \\emph{proof-theoretic semantics} of such logics in which\nthis reading is naturally expressed. This paper delivers such a semantics for\nthe logic of Bunched Implications (BI), generalizing earlier work on IMLL,\nwhich is well-known as a logic of resources with numerous applications to\nverification and modelling. Specifically, it delivers a base-extension\nsemantics (B-eS) for BI in which resources are \\emph{bunches} of atoms that get\npassed from antecedent to consequent in precisely the expected way.",
            "author": [
                "Tao Gu",
                "Alexander V. Gheorghiu",
                "David J. Pym"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16719v1",
                "http://arxiv.org/pdf/2311.16719v1"
            ],
            "primary_category": "cs.LO",
            "category": [
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16716v1",
            "title": "Graph Pre-training and Prompt Learning for Recommendation",
            "updated": "2023-11-28T12:00:06Z",
            "published": "2023-11-28T12:00:06Z",
            "summary": "GNN-based recommenders have excelled in modeling intricate user-item\ninteractions through multi-hop message passing. However, existing methods often\noverlook the dynamic nature of evolving user-item interactions, which impedes\nthe adaption to changing user preferences and distribution shifts in newly\narriving data. Thus, their scalability and performances in real-world dynamic\nenvironments are limited. In this study, we propose GraphPL, a framework that\nincorporates parameter-efficient and dynamic graph pre-training with prompt\nlearning. This novel combination empowers GNNs to effectively capture both\nlong-term user preferences and short-term behavior dynamics, enabling the\ndelivery of accurate and timely recommendations. Our GraphPL framework\naddresses the challenge of evolving user preferences by seamlessly integrating\na temporal prompt mechanism and a graph-structural prompt learning mechanism\ninto the pre-trained GNN model. The temporal prompt mechanism encodes time\ninformation on user-item interaction, allowing the model to naturally capture\ntemporal context, while the graph-structural prompt learning mechanism enables\nthe transfer of pre-trained knowledge to adapt to behavior dynamics without the\nneed for continuous incremental training. We further bring in a dynamic\nevaluation setting for recommendation to mimic real-world dynamic scenarios and\nbridge the offline-online gap to a better level. Our extensive experiments\nincluding a large-scale industrial deployment showcases the lightweight plug-in\nscalability of our GraphPL when integrated with various state-of-the-art\nrecommenders, emphasizing the advantages of GraphPL in terms of effectiveness,\nrobustness and efficiency.",
            "author": [
                "Yuhao Yang",
                "Lianghao Xia",
                "Da Luo",
                "Kangyi Lin",
                "Chao Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16716v1",
                "http://arxiv.org/pdf/2311.16716v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16714v1",
            "title": "Embodied Multi-Modal Agent trained by an LLM from a Parallel TextWorld",
            "updated": "2023-11-28T11:53:56Z",
            "published": "2023-11-28T11:53:56Z",
            "summary": "While large language models (LLMs) excel in a simulated world of texts, they\nstruggle to interact with the more realistic world without perceptions of other\nmodalities such as visual or audio signals. Although vision-language models\n(VLMs) integrate LLM modules (1) aligned with static image features, and (2)\nmay possess prior knowledge of world dynamics (as demonstrated in the text\nworld), they have not been trained in an embodied visual world and thus cannot\nalign with its dynamics. On the other hand, training an embodied agent in a\nnoisy visual world without expert guidance is often challenging and\ninefficient. In this paper, we train a VLM agent living in a visual world using\nan LLM agent excelling in a parallel text world (but inapplicable to the visual\nworld). Specifically, we distill LLM's reflection outcomes (improved actions by\nanalyzing mistakes) in a text world's tasks to finetune the VLM on the same\ntasks of the visual world, resulting in an Embodied Multi-Modal Agent (EMMA)\nquickly adapting to the visual world dynamics. Such cross-modality imitation\nlearning between the two parallel worlds enables EMMA to generalize to a broad\nscope of new tasks without any further guidance from the LLM expert. Extensive\nevaluations on the ALFWorld benchmark highlight EMMA's superior performance to\nSOTA VLM-based agents across diverse tasks, e.g., 20%-70% improvement in the\nsuccess rate.",
            "author": [
                "Yijun Yang",
                "Tianyi Zhou",
                "Kanxue Li",
                "Dapeng Tao",
                "Lusong Li",
                "Li Shen",
                "Xiaodong He",
                "Jing Jiang",
                "Yuhui Shi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16714v1",
                "http://arxiv.org/pdf/2311.16714v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16712v1",
            "title": "Onedata4Sci: Life science data management solution based on Onedata",
            "updated": "2023-11-28T11:52:35Z",
            "published": "2023-11-28T11:52:35Z",
            "summary": "Life-science experimental methods generate vast and ever-increasing volumes\nof data, which provide highly valuable research resources. However, management\nof these data is nontrivial and applicable software solutions are currently\nsubject to intensive development. The solutions mainly fall into one of the two\ngroups: general data management systems (e.g. Onedata, iRODS, B2SHARE, CERNBox)\nor very specialised data management solutions (e.g. solutions for biomolecular\nsimulation data, biological imaging data, genomic data).\n  To bridge this gap between them, we provide Onedata4Sci, a prototype data\nmanagement solution, which is focused on the management of life science data\nand covers four key steps of the data life cycle, i.e. data acquisition, user\naccess, computational processing and archiving. Onedata4Sci is based on the\nOnedata data management system. It is written in Python, fully containerised,\nwith the support for processing the stored data in Kubernetes. The\napplicability of Onedata4Sci is shown in three distinct use cases -- plant\nimaging data, cellular imaging data, and cryo-electron microscopy data. Despite\nthe use cases covering very different types of data and user patterns,\nOnedata4Sci demonstrated an ability to successfully handle all these\nconditions. Complete source codes of Onedata4Sci are available on GitHub\n(https://github.com/CERIT-SC/onedata4sci), and its documentation and manual for\ninstallation are also provided.",
            "author": [
                "Tom\u00e1\u0161 Svoboda",
                "Tom\u00e1\u0161 Ra\u010dek",
                "Josef Handl",
                "Jozef Sabo",
                "Adri\u00e1n Ro\u0161inec",
                "\u0141ukasz Opio\u0142a",
                "Wojciech Jesionek",
                "Milan E\u0161ner",
                "Mark\u00e9ta Pernisov\u00e1",
                "Natallia Madzia Valasevich",
                "Ale\u0161 K\u0159enek",
                "Radka Svobodov\u00e1"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16712v1",
                "http://arxiv.org/pdf/2311.16712v1"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16707v1",
            "title": "Full-resolution MLPs Empower Medical Dense Prediction",
            "updated": "2023-11-28T11:32:23Z",
            "published": "2023-11-28T11:32:23Z",
            "summary": "Dense prediction is a fundamental requirement for many medical vision tasks\nsuch as medical image restoration, registration, and segmentation. The most\npopular vision model, Convolutional Neural Networks (CNNs), has reached\nbottlenecks due to the intrinsic locality of convolution operations. Recently,\ntransformers have been widely adopted for dense prediction for their capability\nto capture long-range visual dependence. However, due to the high computational\ncomplexity and large memory consumption of self-attention operations,\ntransformers are usually used at downsampled feature resolutions. Such usage\ncannot effectively leverage the tissue-level textural information available\nonly at the full image resolution. This textural information is crucial for\nmedical dense prediction as it can differentiate the subtle human anatomy in\nmedical images. In this study, we hypothesize that Multi-layer Perceptrons\n(MLPs) are superior alternatives to transformers in medical dense prediction\nwhere tissue-level details dominate the performance, as MLPs enable long-range\ndependence at the full image resolution. To validate our hypothesis, we develop\na full-resolution hierarchical MLP framework that uses MLPs beginning from the\nfull image resolution. We evaluate this framework with various MLP blocks on a\nwide range of medical dense prediction tasks including restoration,\nregistration, and segmentation. Extensive experiments on six public\nwell-benchmarked datasets show that, by simply using MLPs at full resolution,\nour framework outperforms its CNN and transformer counterparts and achieves\nstate-of-the-art performance on various medical dense prediction tasks.",
            "author": [
                "Mingyuan Meng",
                "Yuxin Xue",
                "Dagan Feng",
                "Lei Bi",
                "Jinman Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16707v1",
                "http://arxiv.org/pdf/2311.16707v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16703v2",
            "title": "CADTalk: An Algorithm and Benchmark for Semantic Commenting of CAD\n  Programs",
            "updated": "2023-11-30T09:35:09Z",
            "published": "2023-11-28T11:27:48Z",
            "summary": "CAD programs are a popular way to compactly encode shapes as a sequence of\noperations that are easy to parametrically modify. However, without sufficient\nsemantic comments and structure, such programs can be challenging to\nunderstand, let alone modify. We introduce the problem of semantic commenting\nCAD programs, wherein the goal is to segment the input program into code blocks\ncorresponding to semantically meaningful shape parts and assign a semantic\nlabel to each block. We solve the problem by combining program parsing with\nvisual-semantic analysis afforded by recent advances in foundational language\nand vision models. Specifically, by executing the input programs, we create\nshapes, which we use to generate conditional photorealistic images to make use\nof semantic annotators for such images. We then distill the information across\nthe images and link back to the original programs to semantically comment on\nthem. Additionally, we collected and annotated a benchmark dataset, CADTalk,\nconsisting of 5,280 machine-made programs and 45 human-made programs with\nground truth semantic comments to foster future research. We extensively\nevaluated our approach, compared to a GPT-based baseline approach, and an\nopen-set shape segmentation baseline, i.e., PartSLIP, and reported an 83.24%\naccuracy on the new CADTalk dataset. Project page:\nhttps://enigma-li.github.io/CADTalk/.",
            "author": [
                "Haocheng Yuan",
                "Jing Xu",
                "Hao Pan",
                "Adrien Bousseau",
                "Niloy Mitra",
                "Changjian Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16703v2",
                "http://arxiv.org/pdf/2311.16703v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16702v1",
            "title": "iMagLS: Interaural Level Difference with Magnitude Least-Squares Loss\n  for Optimized First-Order Head-Related Transfer Function",
            "updated": "2023-11-28T11:25:12Z",
            "published": "2023-11-28T11:25:12Z",
            "summary": "Binaural reproduction for headphone-based listening is an active research\narea due to its widespread use in evolving technologies such as augmented and\nvirtual reality (AR and VR). On the one hand, these applications demand high\nquality spatial audio perception to preserve the sense of immersion. On the\nother hand, recording devices may only have a few microphones, leading to\nlow-order representations such as first-order Ambisonics (FOA). However,\nfirst-order Ambisonics leads to limited externalization and spatial resolution.\nIn this paper, a novel head-related transfer function (HRTF) preprocessing\noptimization loss is proposed, and is minimized using nonlinear programming.\nThe new method, denoted iMagLS, involves the introduction of an interaural\nlevel difference (ILD) error term to the now widely used MagLS optimization\nloss for the lateral plane angles. Results indicate that the ILD error could be\nsubstantially reduced, while the HRTF magnitude error remains similar to that\nobtained with MagLS. These results could prove beneficial to the overall\nspatial quality of first-order Ambisonics, while other reproduction methods\ncould also benefit from considering this modified loss.",
            "author": [
                "Or Berebi",
                "Zamir Ben-Hur",
                "David Lou Alon",
                "Boaz Rafaely"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16702v1",
                "http://arxiv.org/pdf/2311.16702v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16701v1",
            "title": "Morpho-kinematical modelling in the molecular zoo beyond CO: the case of\n  M 1-92",
            "updated": "2023-11-28T11:23:50Z",
            "published": "2023-11-28T11:23:50Z",
            "summary": "Ongoing improvements of sub-mm- and mm-range interferometers and single-dish\nradiotelescopes are progressively allowing the detailed study of planetary\nnebulae (PNe) in molecular species other than 12CO and 13CO. We are\nimplementing a new set of tables for extending the capabilities of the\nmorpho-kinematical modelling tool SHAPE+shapemol, so radiative transfer in\nmolecular species beyond 12CO and 13CO, namely C17O, C18O, HCN, HNC, CS, SiO,\nHCO+, and N2H+, are enabled under the Large Velocity Gradient approximation\nwith the ease of use of SHAPE. We present preliminary results on the\nsimultaneous analysis of a plethora of IRAM-30m and HERSCHEL/HIFI spectra, and\nNOEMA maps of different species in the pre-PN nebula M~1-92, which show\ninteresting features such as a previously undetected pair of polar, turbulent,\nhigh-temperature blobs, or a 17O/18O isotopic ratio of 1.7, which indicates the\nAGB should have turned C-rich, as opposed to the apparent nature of its O-rich\nnebula.",
            "author": [
                "M. Santander-Garc\u00eda",
                "E. Masa",
                "J. Alcolea",
                "V. Bujarrabal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16701v1",
                "http://arxiv.org/pdf/2311.16701v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA",
                "astro-ph.SR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.03734v1",
            "title": "Conditional Prompt Tuning for Multimodal Fusion",
            "updated": "2023-11-28T11:05:20Z",
            "published": "2023-11-28T11:05:20Z",
            "summary": "We show that the representation of one modality can effectively guide the\nprompting of another modality for parameter-efficient multimodal fusion.\nSpecifically, we first encode one modality and use its representation as a\nprior to conditionally prompt all frozen layers of the other modality. This is\nachieved by disentangling the vanilla prompt vectors into three types of\nspecialized prompts that adaptively capture global-level and instance-level\nfeatures. To better produce the instance-wise prompt, we introduce the mixture\nof prompt experts (MoPE) to dynamically route each instance to the most\nsuitable prompt experts for encoding. We further study a regularization term to\navoid degenerated prompt expert routing. Thanks to our design, our method can\neffectively transfer the pretrained knowledge in unimodal encoders for\ndownstream multimodal tasks. Compared with vanilla prompting, we show that our\nMoPE-based conditional prompting is more expressive, thereby scales better with\ntraining data and the total number of prompts. We also demonstrate that our\nprompt tuning is architecture-agnostic, thereby offering high modularity.\nExtensive experiments over three multimodal datasets demonstrate\nstate-of-the-art results, matching or surpassing the performance achieved\nthrough fine-tuning, while only necessitating 0.7% of the trainable parameters.\nCode will be released: https://github.com/songrise/ConditionalPrompt.",
            "author": [
                "Ruixiang Jiang",
                "Lingbo Liu",
                "Changwen Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03734v1",
                "http://arxiv.org/pdf/2312.03734v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16692v1",
            "title": "Learning how to find targets in the micro-world: The case of\n  intermittent active Brownian particles",
            "updated": "2023-11-28T11:05:13Z",
            "published": "2023-11-28T11:05:13Z",
            "summary": "Finding the best strategy to minimize the time needed to find a given target\nis a crucial task both in nature and in reaching decisive technological\nadvances. By considering learning agents able to switch their dynamics between\nstandard and active Brownian motion, here we focus on developing effective\ntarget-search behavioral policies for microswimmers navigating a homogeneous\nenvironment and searching for targets of unknown position. We exploit\nProjective Simulation, a reinforcement learning algorithm, to acquire an\nefficient stochastic policy represented by the probability of switching the\nphase, i.e. the navigation mode, in response to the type and the duration of\nthe current phase. Our findings reveal that the target-search efficiency\nincreases with the particle's self-propulsion during the active phase and that,\nwhile the optimal duration of the passive case decreases monotonically with the\nactivity, the optimal duration of the active phase displays a non-monotonic\nbehavior.",
            "author": [
                "Michele Caraglio",
                "Harpreet Kaur",
                "Lukas J. Fiderer",
                "Andrea L\u00f3pez-Incera",
                "Hans J. Briegel",
                "Thomas Franosch",
                "Gorka Mu\u00f1oz-Gil"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16692v1",
                "http://arxiv.org/pdf/2311.16692v1"
            ],
            "primary_category": "cond-mat.soft",
            "category": [
                "cond-mat.soft",
                "cond-mat.stat-mech",
                "physics.bio-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16691v1",
            "title": "Unveiling the spectacular over 24-hour flare of star CD-36 3202",
            "updated": "2023-11-28T11:04:14Z",
            "published": "2023-11-28T11:04:14Z",
            "summary": "We studied the light curve of the star CD-36 3202, observed by TESS for the\npresence of stellar spots and to analyze the rotationally modulated flare. We\nmainly wanted to model the light curve of this flare and estimate its location\nregarding stellar spots. The flare lasted approximately 27$\\,$h. Using our tool\nnew \\texttt{findinc\\_mc} we managed to estimate the inclination angle of the\nstar to $70^\\circ\\pm8^\\circ$. With \\texttt{BASSMAN} we modeled the light curve\nof the CD-36 3202 and we estimated that three spots are present on the surface\nof this star. The mean temperature of the spots was about $4000\\pm 765\\,$K, and\nthe total spottedness was on average $11.61\\%\\pm0.13\\,$\\%. We created a new\ntool named \\texttt{MFUEA} to model rotationally modulated flares. Using this\nsoftware we estimated the latitude of the flare long-duration event equal to\n$69^{+2}_{-1}\\,$deg in latitude. Our estimation of the flare's location was the\nfirst recreation of the exact position of a flare compared with the spots. The\nflare is placed 12$^\\circ$ from the center of the coolest spot. This makes the\nflare related to the magnetic processes above the active region represented by\nthe spot. Removing the effects of rotational modulation from the flare light\ncurve allowed us to correct the estimation of bolometric energy released during\nthe event from $(1.15\\pm 0.35)\\times 10^{35}\\,$erg to $(3.99\\pm 1.22)\\times\n10^{35}\\,$erg.",
            "author": [
                "Kamil Bicz",
                "Robert Falewicz",
                "Ma\u0142gorzata Pietras"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16691v1",
                "http://arxiv.org/pdf/2311.16691v1"
            ],
            "primary_category": "astro-ph.SR",
            "category": [
                "astro-ph.SR",
                "astro-ph.HE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17110v1",
            "title": "XAI for time-series classification leveraging image highlight methods",
            "updated": "2023-11-28T10:59:18Z",
            "published": "2023-11-28T10:59:18Z",
            "summary": "Although much work has been done on explainability in the computer vision and\nnatural language processing (NLP) fields, there is still much work to be done\nto explain methods applied to time series as time series by nature can not be\nunderstood at first sight. In this paper, we present a Deep Neural Network\n(DNN) in a teacher-student architecture (distillation model) that offers\ninterpretability in time-series classification tasks. The explainability of our\napproach is based on transforming the time series to 2D plots and applying\nimage highlight methods (such as LIME and GradCam), making the predictions\ninterpretable. At the same time, the proposed approach offers increased\naccuracy competing with the baseline model with the trade-off of increasing the\ntraining time.",
            "author": [
                "Georgios Makridis",
                "Georgios Fatouros",
                "Vasileios Koukos",
                "Dimitrios Kotios",
                "Dimosthenis Kyriazis",
                "Ioannis Soldatos"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17110v1",
                "http://arxiv.org/pdf/2311.17110v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16687v1",
            "title": "Enhancing exotic quantum fluctuations in a strongly entangled cavity BEC\n  system",
            "updated": "2023-11-28T10:58:14Z",
            "published": "2023-11-28T10:58:14Z",
            "summary": "We show that the strong coupling of a quantum light field and correlated\nquantum matter induces exotic quantum fluctuations in the matter sector. We\ndetermine their spectral characteristics and reveal the impact of the atomic\ns-wave scattering. In particular, we derive the dissipative Landau and Beliaev\nprocesses from the microscopic Hamiltonian using imaginary time path integrals.\nBy this, their strongly sub-Ohmic nature is revealed analytically. A\ncompetition between damping and antidamping channels is uncovered. Their\nintricate influence on physical observables is quantified analytically and the\nStokes shift of the critical point is determined. This illustrates the\ntunability of the quantum matter fluctuations by exploiting strong light-matter\ncoupling.",
            "author": [
                "Leon Mixa",
                "Hans Ke\u00dfler",
                "Andreas Hemmerich",
                "Michael Thorwart"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16687v1",
                "http://arxiv.org/pdf/2311.16687v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cond-mat.quant-gas"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16681v1",
            "title": "Understanding the (Extra-)Ordinary: Validating Deep Model Decisions with\n  Prototypical Concept-based Explanations",
            "updated": "2023-11-28T10:53:26Z",
            "published": "2023-11-28T10:53:26Z",
            "summary": "Ensuring both transparency and safety is critical when deploying Deep Neural\nNetworks (DNNs) in high-risk applications, such as medicine. The field of\nexplainable AI (XAI) has proposed various methods to comprehend the\ndecision-making processes of opaque DNNs. However, only few XAI methods are\nsuitable of ensuring safety in practice as they heavily rely on repeated\nlabor-intensive and possibly biased human assessment. In this work, we present\na novel post-hoc concept-based XAI framework that conveys besides instance-wise\n(local) also class-wise (global) decision-making strategies via prototypes.\nWhat sets our approach apart is the combination of local and global strategies,\nenabling a clearer understanding of the (dis-)similarities in model decisions\ncompared to the expected (prototypical) concept use, ultimately reducing the\ndependence on human long-term assessment. Quantifying the deviation from\nprototypical behavior not only allows to associate predictions with specific\nmodel sub-strategies but also to detect outlier behavior. As such, our approach\nconstitutes an intuitive and explainable tool for model validation. We\ndemonstrate the effectiveness of our approach in identifying\nout-of-distribution samples, spurious model behavior and data quality issues\nacross three datasets (ImageNet, CUB-200, and CIFAR-10) utilizing VGG, ResNet,\nand EfficientNet architectures. Code is available on\nhttps://github.com/maxdreyer/pcx.",
            "author": [
                "Maximilian Dreyer",
                "Reduan Achtibat",
                "Wojciech Samek",
                "Sebastian Lapuschkin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16681v1",
                "http://arxiv.org/pdf/2311.16681v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16680v2",
            "title": "ROSO: Improving Robotic Policy Inference via Synthetic Observations",
            "updated": "2023-11-29T05:16:40Z",
            "published": "2023-11-28T10:52:35Z",
            "summary": "In this paper, we propose the use of generative artificial intelligence (AI)\nto improve zero-shot performance of a pre-trained policy by altering\nobservations during inference. Modern robotic systems, powered by advanced\nneural networks, have demonstrated remarkable capabilities on pre-trained\ntasks. However, generalizing and adapting to new objects and environments is\nchallenging, and fine-tuning visuomotor policies is time-consuming. To overcome\nthese issues we propose Robotic Policy Inference via Synthetic Observations\n(ROSO). ROSO uses stable diffusion to pre-process a robot's observation of\nnovel objects during inference time to fit within its distribution of\nobservations of the pre-trained policies. This novel paradigm allows us to\ntransfer learned knowledge from known tasks to previously unseen scenarios,\nenhancing the robot's adaptability without requiring lengthy fine-tuning. Our\nexperiments show that incorporating generative AI into robotic inference\nsignificantly improves successful outcomes, finishing up to 57% of tasks\notherwise unsuccessful with the pre-trained policy.",
            "author": [
                "Yusuke Miyashita",
                "Dimitris Gahtidis",
                "Colin La",
                "Jeremy Rabinowicz",
                "Jurgen Leitner"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16680v2",
                "http://arxiv.org/pdf/2311.16680v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16678v1",
            "title": "Entity-Aspect-Opinion-Sentiment Quadruple Extraction for Fine-grained\n  Sentiment Analysis",
            "updated": "2023-11-28T10:50:00Z",
            "published": "2023-11-28T10:50:00Z",
            "summary": "Product reviews often contain a large number of implicit aspects and\nobject-attribute co-existence cases. Unfortunately, many existing studies in\nAspect-Based Sentiment Analysis (ABSA) have overlooked this issue, which can\nmake it difficult to extract opinions comprehensively and fairly. In this\npaper, we propose a new task called Entity-Aspect-Opinion-Sentiment Quadruple\nExtraction (EASQE), which aims to hierarchically decompose aspect terms into\nentities and aspects to avoid information loss, non-exclusive annotations, and\nopinion misunderstandings in ABSA tasks. To facilitate research in this new\ntask, we have constructed four datasets (Res14-EASQE, Res15-EASQE, Res16-EASQE,\nand Lap14-EASQE) based on the SemEval Restaurant and Laptop datasets. We have\nalso proposed a novel two-stage sequence-tagging based Trigger-Opinion\nframework as the baseline for the EASQE task. Empirical evaluations show that\nour Trigger-Opinion framework can generate satisfactory EASQE results and can\nalso be applied to other ABSA tasks, significantly outperforming\nstate-of-the-art methods. We have made the four datasets and source code of\nTrigger-Opinion publicly available to facilitate further research in this area.",
            "author": [
                "Dan Ma",
                "Jun Xu",
                "Zongyu Wang",
                "Xuezhi Cao",
                "Yunsen Xian"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16678v1",
                "http://arxiv.org/pdf/2311.16678v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16675v1",
            "title": "A Distribution-Based Threshold for Determining Sentence Similarity",
            "updated": "2023-11-28T10:42:35Z",
            "published": "2023-11-28T10:42:35Z",
            "summary": "We hereby present a solution to a semantic textual similarity (STS) problem\nin which it is necessary to match two sentences containing, as the only\ndistinguishing factor, highly specific information (such as names, addresses,\nidentification codes), and from which we need to derive a definition for when\nthey are similar and when they are not. The solution revolves around the use of\na neural network, based on the siamese architecture, to create the\ndistributions of the distances between similar and dissimilar pairs of\nsentences. The goal of these distributions is to find a discriminating factor,\nthat we call \"threshold\", which represents a well-defined quantity that can be\nused to distinguish vector distances of similar pairs from vector distances of\ndissimilar pairs in new predictions and later analyses. In addition, we\ndeveloped a way to score the predictions by combining attributes from both the\ndistributions' features and the way the distance function works. Finally, we\ngeneralize the results showing that they can be transferred to a wider range of\ndomains by applying the system discussed to a well-known and widely used\nbenchmark dataset for STS problems.",
            "author": [
                "Gioele Cadamuro",
                "Marco Gruppo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16675v1",
                "http://arxiv.org/pdf/2311.16675v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16674v1",
            "title": "Exploring the Synergy of Kinematics and Dynamics for Collider Physics",
            "updated": "2023-11-28T10:41:07Z",
            "published": "2023-11-28T10:41:07Z",
            "summary": "In collider experiments, an event is characterized by two distinct yet\nmutually complementary features: the `global features' and the `local\nfeatures'. Kinematic information such as the event topology of a hard process,\nmasses, and spins of particles comprises global features spanning the entire\nphase space. This global feature can be inferred from reconstructed objects. In\ncontrast, representations of particles in gauge groups, such as Quantum\nChromodynamics (QCD), offer localized features revealing the dynamics of an\nunderlying theory. These local features, particularly observed in the patterns\nof radiation as raw data in various detector components, complement the global\nkinematic features. In this letter, we propose a simple but effective neural\nnetwork architecture that seamlessly integrates information from both\nkinematics and QCD to enhance the signal sensitivity at colliders.",
            "author": [
                "Kayoung Ban",
                "Kyoungchul Kong",
                "Myeonghun Park",
                "Seong Chan Park"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16674v1",
                "http://arxiv.org/pdf/2311.16674v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16673v1",
            "title": "Large Language Models Meet Computer Vision: A Brief Survey",
            "updated": "2023-11-28T10:39:19Z",
            "published": "2023-11-28T10:39:19Z",
            "summary": "Recently, the intersection of Large Language Models (LLMs) and Computer\nVision (CV) has emerged as a pivotal area of research, driving significant\nadvancements in the field of Artificial Intelligence (AI). As transformers have\nbecome the backbone of many state-of-the-art models in both Natural Language\nProcessing (NLP) and CV, understanding their evolution and potential\nenhancements is crucial. This survey paper delves into the latest progressions\nin the domain of transformers and their subsequent successors, emphasizing\ntheir potential to revolutionize Vision Transformers (ViTs) and LLMs. This\nsurvey also presents a comparative analysis, juxtaposing the performance\nmetrics of several leading paid and open-source LLMs, shedding light on their\nstrengths and areas of improvement as well as a literature review on how LLMs\nare being used to tackle vision related tasks. Furthermore, the survey presents\na comprehensive collection of datasets employed to train LLMs, offering\ninsights into the diverse data available to achieve high performance in various\npre-training and downstream tasks of LLMs. The survey is concluded by\nhighlighting open directions in the field, suggesting potential venues for\nfuture research and development. This survey aims to underscores the profound\nintersection of LLMs on CV, leading to a new era of integrated and advanced AI\nmodels.",
            "author": [
                "Raby Hamadi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16673v1",
                "http://arxiv.org/pdf/2311.16673v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16672v2",
            "title": "Second leptogenesis: Unraveling the baryon-lepton asymmetry discrepancy",
            "updated": "2023-12-06T14:14:43Z",
            "published": "2023-11-28T10:38:34Z",
            "summary": "We propose a novel scenario to explain the matter-antimatter asymmetry by\ntwofold leptogenesis, wherein heavy Majorana neutrinos exhibit\ntemperature-dependent masses and engage in $CP$-violating decays. This scenario\nenvisages two distinct phases of leptogenesis: one occurring above the\nelectroweak scale and the other below it. The sphaleron process converts the\nfirst lepton asymmetry to baryon asymmetry, but not the second one due to its\ndecoupling. This mechanism potentially explains the significant discrepancy\nbetween baryon and lepton asymmetries, as suggested by recent observations of\nHelium-4. Furthermore, our model implies that the present masses of Majorana\nneutrinos are lighter than the electroweak scale, offering a tangible avenue\nfor experimental verification in various terrestrial settings.",
            "author": [
                "YeolLin ChoeJo",
                "Kazuki Enomoto",
                "Yechan Kim",
                "Hye-Sung Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16672v2",
                "http://arxiv.org/pdf/2311.16672v2"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "astro-ph.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16670v1",
            "title": "PyTorch Geometric High Order: A Unified Library for High Order Graph\n  Neural Network",
            "updated": "2023-11-28T10:34:48Z",
            "published": "2023-11-28T10:34:48Z",
            "summary": "We introduce PyTorch Geometric High Order (PyGHO), a library for High Order\nGraph Neural Networks (HOGNNs) that extends PyTorch Geometric (PyG). Unlike\nordinary Message Passing Neural Networks (MPNNs) that exchange messages between\nnodes, HOGNNs, encompassing subgraph GNNs and k-WL GNNs, encode node tuples, a\nmethod previously lacking a standardized framework and often requiring complex\ncoding. PyGHO's main objective is to provide an unified and user-friendly\ninterface for various HOGNNs. It accomplishes this through streamlined data\nstructures for node tuples, comprehensive data processing utilities, and a\nflexible suite of operators for high-order GNN methodologies. In this work, we\npresent a detailed in-depth of PyGHO and compare HOGNNs implemented with PyGHO\nwith their official implementation on real-world tasks. PyGHO achieves up to\n$50\\%$ acceleration and reduces the code needed for implementation by an order\nof magnitude. Our library is available at\n\\url{https://github.com/GraphPKU/PygHO}.",
            "author": [
                "Xiyuan Wang",
                "Muhan Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16670v1",
                "http://arxiv.org/pdf/2311.16670v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17107v1",
            "title": "ClimateX: Do LLMs Accurately Assess Human Expert Confidence in Climate\n  Statements?",
            "updated": "2023-11-28T10:26:57Z",
            "published": "2023-11-28T10:26:57Z",
            "summary": "Evaluating the accuracy of outputs generated by Large Language Models (LLMs)\nis especially important in the climate science and policy domain. We introduce\nthe Expert Confidence in Climate Statements (ClimateX) dataset, a novel,\ncurated, expert-labeled dataset consisting of 8094 climate statements collected\nfrom the latest Intergovernmental Panel on Climate Change (IPCC) reports,\nlabeled with their associated confidence levels. Using this dataset, we show\nthat recent LLMs can classify human expert confidence in climate-related\nstatements, especially in a few-shot learning setting, but with limited (up to\n47%) accuracy. Overall, models exhibit consistent and significant\nover-confidence on low and medium confidence statements. We highlight\nimplications of our results for climate communication, LLMs evaluation\nstrategies, and the use of LLMs in information retrieval systems.",
            "author": [
                "Romain Lacombe",
                "Kerrie Wu",
                "Eddie Dilworth"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17107v1",
                "http://arxiv.org/pdf/2311.17107v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL",
                "cs.CY",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16663v1",
            "title": "Unclonable Cryptography in the Plain Model",
            "updated": "2023-11-28T10:25:22Z",
            "published": "2023-11-28T10:25:22Z",
            "summary": "By leveraging the no-cloning principle of quantum mechanics, unclonable\ncryptography enables us to achieve novel cryptographic protocols that are\notherwise impossible classically. Two most notable examples of unclonable\ncryptography are quantum copy-protection and unclonable encryption. Despite\nreceiving a lot of attention in recent years, two important open questions\nstill remain: copy-protection for point functions in the plain model, which is\nusually considered as feasibility demonstration, and unclonable encryption with\nunclonable indistinguishability security in the plain model.\n  In this work, by relying on previous works of Coladangelo, Liu, Liu, and\nZhandry (Crypto'21) and Culf and Vidick (Quantum'22), we establish a new\nmonogamy-of-entanglement property for subspace coset states, which allows us to\nobtain the following new results:\n  - We show that copy-protection of point functions exists in the plain model,\nwith different challenge distributions (including arguably the most natural\nones).\n  - We show, for the first time, that unclonable encryption with unclonable\nindistinguishability security exists in the plain model.",
            "author": [
                "C\u00e9line Chevalier",
                "Paul Hermouet",
                "Quoc-Huy Vu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16663v1",
                "http://arxiv.org/pdf/2311.16663v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16662v1",
            "title": "On the arithmetic of ultraproducts of commutative cancellative monoids",
            "updated": "2023-11-28T10:23:44Z",
            "published": "2023-11-28T10:23:44Z",
            "summary": "We develop first steps in the study of factorizations of elements in\nultraproducts of commutative cancellative monoids into irreducible elements. A\ncomplete characterization of the (multi-)sets of lengths in such objects is\ngiven. As applications, we show that several important properties from\nfactorization theory cannot be expressed as first-order statements in the\nlanguage of monoids, and we construct integral domains that realize every\nmultiset of integers larger $1$ as a multiset of lengths. Finally, we give a\nnew proof (based on our ultraproduct techniques) of a theorem by Geroldinger,\nSchmid and Zhong from additive combinatorics and we propose a general method\nfor applying ultraproducts in the setting of non-unique factorizations.",
            "author": [
                "Daniel Windisch"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16662v1",
                "http://arxiv.org/pdf/2311.16662v1"
            ],
            "primary_category": "math.AC",
            "category": [
                "math.AC",
                "math.LO",
                "primary: 13F15, 03C20, secondary: 13L05, 03C60, 13A15"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16661v1",
            "title": "Cooperative Abnormal Node Detection with Adversary Resistance: A\n  Probabilistic Approach",
            "updated": "2023-11-28T10:21:51Z",
            "published": "2023-11-28T10:21:51Z",
            "summary": "This paper presents a novel probabilistic detection scheme called Cooperative\nStatistical Detection (CSD) for abnormal node detection while defending against\nadversarial attacks in cluster-tree networks. The CSD performs a two-phase\nprocess: 1) designing a likelihood ratio test (LRT) for a non-root node at its\nchildren from the perspective of packet loss; 2) making an overall decision at\nthe root node based on the aggregated detection data of the nodes over tree\nbranches. In most adversarial scenarios, malicious children knowing the\ndetection policy can generate falsified data to protect the abnormal parent\nfrom being detected or frame its normal parent as an anomalous node. To resolve\nthis issue, a modified Z-score-based falsification-resistant mechanism is\npresented in the CSD to remove untrustworthy information. Through theoretical\nanalysis, we show that the LRT-based method achieves perfect detection, i.e.,\nboth the false alarm and missed detection probabilities decay exponentially to\nzero. Furthermore, the optimal removal threshold of the modified Z-score method\nis derived for falsifications with uncertain strategies and guarantees perfect\ndetection of the CSD. As our simulation results show, the CSD approach is\nrobust to falsifications and can rapidly reach $99\\%$ detection accuracy, even\nin existing adversarial scenarios, which outperforms state-of-the-art\ntechnology.",
            "author": [
                "Yingying Huangfu",
                "Tian Bai"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16661v1",
                "http://arxiv.org/pdf/2311.16661v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16658v1",
            "title": "Quantum steering for two-mode states with Continuous-variable in laser\n  channel",
            "updated": "2023-11-28T10:18:49Z",
            "published": "2023-11-28T10:18:49Z",
            "summary": "The Einstein-Podolsky-Rosen steering is an important resource for one-sided\ndevice independent quantum information processing. This steering property will\nbe destroyed during the interaction between quantum system and environment for\nsome practical applications. In this paper, we use the representation of\ncharacteristic function for probability to examine the quantum steering of\ntwo-mode states with continuous-variable in laser channel, where both the gain\nfactor and the loss effect are considered. Firstly, we analyse the steering\ntime of two-mode squeezed vacuum state under one-mode and two-mode laser\nchannel respectively. We find the gain process will introduce additional noise\nto the two-mode squeezed vacuum state such that the steerable time is reduced.\nSecondly, by quantising quantum Einstein-Podolsky-Rosen steering, it shows that\ntwo-side loss presents a smaller steerability than one-side loss although they\nshare the same two-way steerable time. In addition, we find the more gained\nparty can steer the others state, while the other party cannot steer the gained\nparty in a certain threshold value. In this sense, it seems that the gain\neffect in one party is equivalent to the loss effect in the others party. Our\nresults pave way for the distillation of Einstein-Podolsky-Rosen steering and\nthe quantum information processing in practical quantum channels.",
            "author": [
                "Kaimin Zheng",
                "Jifeng Sun",
                "Liyun Hu",
                "Lijian Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16658v1",
                "http://arxiv.org/pdf/2311.16658v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16657v1",
            "title": "SCALAR-NeRF: SCAlable LARge-scale Neural Radiance Fields for Scene\n  Reconstruction",
            "updated": "2023-11-28T10:18:16Z",
            "published": "2023-11-28T10:18:16Z",
            "summary": "In this work, we introduce SCALAR-NeRF, a novel framework tailored for\nscalable large-scale neural scene reconstruction. We structure the neural\nrepresentation as an encoder-decoder architecture, where the encoder processes\n3D point coordinates to produce encoded features, and the decoder generates\ngeometric values that include volume densities of signed distances and colors.\nOur approach first trains a coarse global model on the entire image dataset.\nSubsequently, we partition the images into smaller blocks using KMeans with\neach block being modeled by a dedicated local model. We enhance the overlapping\nregions across different blocks by scaling up the bounding boxes of each local\nblock. Notably, the decoder from the global model is shared across distinct\nblocks and therefore promoting alignment in the feature space of local\nencoders. We propose an effective and efficient methodology to fuse the outputs\nfrom these local models to attain the final reconstruction. Employing this\nrefined coarse-to-fine strategy, our method outperforms state-of-the-art NeRF\nmethods and demonstrates scalability for large-scale scene reconstruction. The\ncode will be available on our project page at\nhttps://aibluefisher.github.io/SCALAR-NeRF/",
            "author": [
                "Yu Chen",
                "Gim Hee Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16657v1",
                "http://arxiv.org/pdf/2311.16657v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16652v1",
            "title": "Augmenting x-ray single particle imaging reconstruction with\n  self-supervised machine learning",
            "updated": "2023-11-28T10:05:44Z",
            "published": "2023-11-28T10:05:44Z",
            "summary": "The development of X-ray Free Electron Lasers (XFELs) has opened numerous\nopportunities to probe atomic structure and ultrafast dynamics of various\nmaterials. Single Particle Imaging (SPI) with XFELs enables the investigation\nof biological particles in their natural physiological states with unparalleled\ntemporal resolution, while circumventing the need for cryogenic conditions or\ncrystallization. However, reconstructing real-space structures from\nreciprocal-space x-ray diffraction data is highly challenging due to the\nabsence of phase and orientation information, which is further complicated by\nweak scattering signals and considerable fluctuations in the number of photons\nper pulse. In this work, we present an end-to-end, self-supervised machine\nlearning approach to recover particle orientations and estimate reciprocal\nspace intensities from diffraction images only. Our method demonstrates great\nrobustness under demanding experimental conditions with significantly enhanced\nreconstruction capabilities compared with conventional algorithms, and\nsignifies a paradigm shift in SPI as currently practiced at XFELs.",
            "author": [
                "Zhantao Chen",
                "Cong Wang",
                "Mingye Gao",
                "Chun Hong Yoon",
                "Jana B. Thayer",
                "Joshua J. Turner"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16652v1",
                "http://arxiv.org/pdf/2311.16652v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV",
                "physics.app-ph",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16650v1",
            "title": "Text2Tree: Aligning Text Representation to the Label Tree Hierarchy for\n  Imbalanced Medical Classification",
            "updated": "2023-11-28T10:02:08Z",
            "published": "2023-11-28T10:02:08Z",
            "summary": "Deep learning approaches exhibit promising performances on various text\ntasks. However, they are still struggling on medical text classification since\nsamples are often extremely imbalanced and scarce. Different from existing\nmainstream approaches that focus on supplementary semantics with external\nmedical information, this paper aims to rethink the data challenges in medical\ntexts and present a novel framework-agnostic algorithm called Text2Tree that\nonly utilizes internal label hierarchy in training deep learning models. We\nembed the ICD code tree structure of labels into cascade attention modules for\nlearning hierarchy-aware label representations. Two new learning schemes,\nSimilarity Surrogate Learning (SSL) and Dissimilarity Mixup Learning (DML), are\ndevised to boost text classification by reusing and distinguishing samples of\nother labels following the label representation hierarchy, respectively.\nExperiments on authoritative public datasets and real-world medical records\nshow that our approach stably achieves superior performances over classical and\nadvanced imbalanced classification methods.",
            "author": [
                "Jiahuan Yan",
                "Haojun Gao",
                "Zhang Kai",
                "Weize Liu",
                "Danny Chen",
                "Jian Wu",
                "Jintai Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16650v1",
                "http://arxiv.org/pdf/2311.16650v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16648v1",
            "title": "Master constraint approach to quantum-reduced loop gravity",
            "updated": "2023-11-28T10:01:04Z",
            "published": "2023-11-28T10:01:04Z",
            "summary": "We introduce a master constraint operator on the kinematical Hilbert space of\nloop quantum gravity representing a set of gauge conditions which classically\nfix the densitized triad to be diagonal. We argue that the master constraint\napproach provides a natural and systematic way of carrying out the quantum\ngauge-fixing procedure which underlies the model known as quantum-reduced loop\ngravity. The Hilbert space of quantum-reduced loop gravity is obtained as a\nparticular space of solutions of the gauge-fixing master constraint operator.\nWe give a concise summary of the fundamental structure of the quantum-reduced\nframework, and consider several possible extensions thereof, for which the\nmaster constraint formulation provides a convenient starting point. In\nparticular, we propose a generalization of the standard Hilbert space of\nquantum-reduced loop gravity, which may be relevant in the application of the\nquantum-reduced model to physical situations in which the Ashtekar connection\nis not diagonal.",
            "author": [
                "Ilkka M\u00e4kinen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16648v1",
                "http://arxiv.org/pdf/2311.16648v1"
            ],
            "primary_category": "gr-qc",
            "category": [
                "gr-qc"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16644v1",
            "title": "Finnish 5th and 6th graders' misconceptions about Artificial\n  Intelligence",
            "updated": "2023-11-28T09:49:11Z",
            "published": "2023-11-28T09:49:11Z",
            "summary": "Research on children's initial conceptions of AI is in an emerging state,\nwhich, from a constructivist viewpoint, challenges the development of\npedagogically sound AI-literacy curricula, methods, and materials. To\ncontribute to resolving this need in the present paper, qualitative survey data\nfrom 195 children were analyzed abductively to answer the following three\nresearch questions: What kind of misconceptions do Finnish 5th and 6th graders'\nhave about the essence AI?; 2) How do these misconceptions relate to common\nmisconception types?; and 3) How profound are these misconceptions? As a\nresult, three misconception categories were identified: 1) Non-technological\nAI, in which AI was conceptualized as peoples' cognitive processes (factual\nmisconception); 2) Anthropomorphic AI, in which AI was conceptualized as a\nhuman-like entity (vernacular, non-scientific, and conceptual misconception);\nand 3) AI as a machine with a pre-installed intelligence or knowledge (factual\nmisconception). Majority of the children evaluated their AI-knowledge low,\nwhich implies that the misconceptions are more superficial than profound. The\nfindings suggest that context-specific linguistic features can contribute to\nstudents' AI misconceptions. Implications for future research and AI literacy\neducation are discussed.",
            "author": [
                "Pekka Mertala",
                "Janne Fagerlund"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16644v1",
                "http://arxiv.org/pdf/2311.16644v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.AI",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16639v1",
            "title": "Scaling Political Texts with ChatGPT",
            "updated": "2023-11-28T09:45:02Z",
            "published": "2023-11-28T09:45:02Z",
            "summary": "We use GPT-4 to obtain position estimates of political texts in continuous\nspaces. We develop and validate a new approach by positioning British party\nmanifestos on the economic, social, and immigration policy dimensions and\ntweets by members of the US Congress on the left-right ideological spectrum.\nFor the party manifestos, the correlation between the positions produced by\nGPT-4 and experts is 93% or higher, a performance similar to or better than\nthat obtained with crowdsourced position estimates. For individual tweets, the\npositions obtained with GPT-4 achieve a correlation of 91% with crowdsourced\nposition estimates. For senators of the 117th US Congress, the positions\nobtained with GPT-4 achieve a correlation of 97% with estimates based on roll\ncall votes and of 96% with those based on campaign funding. Correlations are\nalso substantial within party, indicating that position estimates produced with\nGPT-4 capture within-party differences between senators. Overall, using GPT-4\nfor ideological scaling is fast, cost-efficient, and reliable. This approach\nprovides a viable alternative to scaling by both expert raters and\ncrowdsourcing.",
            "author": [
                "Ga\u00ebl Le Mens",
                "Aina Gallego"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16639v1",
                "http://arxiv.org/pdf/2311.16639v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16638v1",
            "title": "Simultaneous Analysis of Continuously Embedded Reissner-Mindlin Shells\n  in 3D Bulk Domains",
            "updated": "2023-11-28T09:44:51Z",
            "published": "2023-11-28T09:44:51Z",
            "summary": "A mechanical model and numerical method for the simultaneous analysis of\nReissner-Mindlin shells with geometries implied by a continuous set of level\nsets (isosurfaces) over some three-dimensional bulk domain is presented. A\nthree-dimensional mesh in the bulk domain is used in a tailored FEM formulation\nwhere the elements are by no means conforming to the level sets representing\nthe shape of the individual shells. However, the shell geometries are bounded\nby the intersection curves of the level sets with the boundary of the bulk\ndomain so that the boundaries are meshed conformingly. This results in a method\nwhich was coined Bulk Trace FEM before. The simultaneously considered,\ncontinuously embedded shells may be useful in the structural design process or\nfor the continuous reinforcement of bulk domains. Numerical results confirm\nhigher-order convergence rates.",
            "author": [
                "Michael Wolfgang Kaiser",
                "Thomas-Peter Fries"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16638v1",
                "http://arxiv.org/pdf/2311.16638v1"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16635v1",
            "title": "MotionZero:Exploiting Motion Priors for Zero-shot Text-to-Video\n  Generation",
            "updated": "2023-11-28T09:38:45Z",
            "published": "2023-11-28T09:38:45Z",
            "summary": "Zero-shot Text-to-Video synthesis generates videos based on prompts without\nany videos. Without motion information from videos, motion priors implied in\nprompts are vital guidance. For example, the prompt \"airplane landing on the\nrunway\" indicates motion priors that the \"airplane\" moves downwards while the\n\"runway\" stays static. Whereas the motion priors are not fully exploited in\nprevious approaches, thus leading to two nontrivial issues: 1) the motion\nvariation pattern remains unaltered and prompt-agnostic for disregarding motion\npriors; 2) the motion control of different objects is inaccurate and entangled\nwithout considering the independent motion priors of different objects. To\ntackle the two issues, we propose a prompt-adaptive and disentangled motion\ncontrol strategy coined as MotionZero, which derives motion priors from prompts\nof different objects by Large-Language-Models and accordingly applies motion\ncontrol of different objects to corresponding regions in disentanglement.\nFurthermore, to facilitate videos with varying degrees of motion amplitude, we\npropose a Motion-Aware Attention scheme which adjusts attention among frames by\nmotion amplitude. Extensive experiments demonstrate that our strategy could\ncorrectly control motion of different objects and support versatile\napplications including zero-shot video edit.",
            "author": [
                "Sitong Su",
                "Litao Guo",
                "Lianli Gao",
                "Hengtao Shen",
                "Jingkuan Song"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16635v1",
                "http://arxiv.org/pdf/2311.16635v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16633v2",
            "title": "21-cm Signal from the Epoch of Reionization: A Machine Learning upgrade\n  to Foreground Removal with Gaussian Process Regression",
            "updated": "2023-11-29T11:07:01Z",
            "published": "2023-11-28T09:36:38Z",
            "summary": "In recent years, a Gaussian Process Regression (GPR) based framework has been\ndeveloped for foreground mitigation from data collected by the LOw-Frequency\nARray (LOFAR), to measure the 21-cm signal power spectrum from the Epoch of\nReionization (EoR) and Cosmic Dawn. However, it has been noted that through\nthis method there can be a significant amount of signal loss if the EoR signal\ncovariance is misestimated. To obtain better covariance models, we propose to\nuse a kernel trained on the {\\tt GRIZZLY} simulations using a Variational\nAuto-Encoder (VAE) based algorithm. In this work, we explore the abilities of\nthis Machine Learning based kernel (VAE kernel) used with GPR, by testing it on\nmock signals from a variety of simulations, exploring noise levels\ncorresponding to $\\approx$10 nights ($\\approx$141 hours) and $\\approx$100\nnights ($\\approx$1410 hours) of observations with LOFAR. Our work suggests the\npossibility of successful extraction of the 21-cm signal within 2$\\sigma$\nuncertainty in most cases using the VAE kernel, with better recovery of both\nshape and power than with previously used covariance models. We also explore\nthe role of the excess noise component identified in past applications of GPR\nand additionally analyse the possibility of redshift dependence on the\nperformance of the VAE kernel. The latter allows us to prepare for future LOFAR\nobservations at a range of redshifts, as well as compare with results from\nother telescopes.",
            "author": [
                "Anshuman Acharya",
                "Florent Mertens",
                "Benedetta Ciardi",
                "Raghunath Ghara",
                "L\u00e9on V. E. Koopmans",
                "Sambit K. Giri",
                "Ian Hothi",
                "Qing-Bo Ma",
                "Garrelt Mellema",
                "Satyapan Munshi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16633v2",
                "http://arxiv.org/pdf/2311.16633v2"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO",
                "astro-ph.IM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17105v1",
            "title": "On the Calibration of Human Pose Estimation",
            "updated": "2023-11-28T09:31:09Z",
            "published": "2023-11-28T09:31:09Z",
            "summary": "Most 2D human pose estimation frameworks estimate keypoint confidence in an\nad-hoc manner, using heuristics such as the maximum value of heatmaps. The\nconfidence is part of the evaluation scheme, e.g., AP for the MSCOCO dataset,\nyet has been largely overlooked in the development of state-of-the-art methods.\nThis paper takes the first steps in addressing miscalibration in pose\nestimation. From a calibration point of view, the confidence should be aligned\nwith the pose accuracy. In practice, existing methods are poorly calibrated. We\nshow, through theoretical analysis, why a miscalibration gap exists and how to\nnarrow the gap. Simply predicting the instance size and adjusting the\nconfidence function gives considerable AP improvements. Given the black-box\nnature of deep neural networks, however, it is not possible to fully close this\ngap with only closed-form adjustments. As such, we go one step further and\nlearn network-specific adjustments by enforcing consistency between confidence\nand pose accuracy. Our proposed Calibrated ConfidenceNet (CCNet) is a\nlight-weight post-hoc addition that improves AP by up to 1.4% on off-the-shelf\npose estimation frameworks. Applied to the downstream task of mesh recovery,\nCCNet facilitates an additional 1.0mm decrease in 3D keypoint error.",
            "author": [
                "Kerui Gu",
                "Rongyu Chen",
                "Angela Yao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17105v1",
                "http://arxiv.org/pdf/2311.17105v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16628v1",
            "title": "Symmetry-regularized neural ordinary differential equations",
            "updated": "2023-11-28T09:27:44Z",
            "published": "2023-11-28T09:27:44Z",
            "summary": "Neural Ordinary Differential Equations (Neural ODEs) is a class of deep\nneural network models that interpret the hidden state dynamics of neural\nnetworks as an ordinary differential equation, thereby capable of capturing\nsystem dynamics in a continuous time framework. In this work, I integrate\nsymmetry regularization into Neural ODEs. In particular, I use continuous Lie\nsymmetry of ODEs and PDEs associated with the model to derive conservation laws\nand add them to the loss function, making it physics-informed. This\nincorporation of inherent structural properties into the loss function could\nsignificantly improve robustness and stability of the model during training. To\nillustrate this method, I employ a toy model that utilizes a cosine rate of\nchange in the hidden state, showcasing the process of identifying Lie\nsymmetries, deriving conservation laws, and constructing a new loss function.",
            "author": [
                "Wenbo Hao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16628v1",
                "http://arxiv.org/pdf/2311.16628v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16625v1",
            "title": "Gaussian Processes for Monitoring Air-Quality in Kampala",
            "updated": "2023-11-28T09:25:23Z",
            "published": "2023-11-28T09:25:23Z",
            "summary": "Monitoring air pollution is of vital importance to the overall health of the\npopulation. Unfortunately, devices that can measure air quality can be\nexpensive, and many cities in low and middle-income countries have to rely on a\nsparse allocation of them. In this paper, we investigate the use of Gaussian\nProcesses for both nowcasting the current air-pollution in places where there\nare no sensors and forecasting the air-pollution in the future at the sensor\nlocations. In particular, we focus on the city of Kampala in Uganda, using data\nfrom AirQo's network of sensors. We demonstrate the advantage of removing\noutliers, compare different kernel functions and additional inputs. We also\ncompare two sparse approximations to allow for the large amounts of temporal\ndata in the dataset.",
            "author": [
                "Clara Stoddart",
                "Lauren Shrack",
                "Richard Sserunjogi",
                "Usman Abdul-Ganiy",
                "Engineer Bainomugisha",
                "Deo Okure",
                "Ruth Misener",
                "Jose Pablo Folch",
                "Ruby Sedgwick"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16625v1",
                "http://arxiv.org/pdf/2311.16625v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16620v1",
            "title": "On the Long Range Abilities of Transformers",
            "updated": "2023-11-28T09:21:48Z",
            "published": "2023-11-28T09:21:48Z",
            "summary": "Despite their dominance in modern DL and, especially, NLP domains,\ntransformer architectures exhibit sub-optimal performance on long-range tasks\ncompared to recent layers that are specifically designed for this purpose. In\nthis work, drawing inspiration from key attributes of long-range layers, such\nas state-space layers, linear RNN layers, and global convolution layers, we\ndemonstrate that minimal modifications to the transformer architecture can\nsignificantly enhance performance on the Long Range Arena (LRA) benchmark, thus\nnarrowing the gap with these specialized layers. We identify that two key\nprinciples for long-range tasks are (i) incorporating an inductive bias towards\nsmoothness, and (ii) locality. As we show, integrating these ideas into the\nattention mechanism improves results with a negligible amount of additional\ncomputation and without any additional trainable parameters. Our theory and\nexperiments also shed light on the reasons for the inferior performance of\ntransformers on long-range tasks and identify critical properties that are\nessential for successfully capturing long-range dependencies.",
            "author": [
                "Itamar Zimerman",
                "Lior Wolf"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16620v1",
                "http://arxiv.org/pdf/2311.16620v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL",
                "F.2.2; I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17104v1",
            "title": "Single-Cell Clustering via Dual-Graph Alignment",
            "updated": "2023-11-28T09:14:55Z",
            "published": "2023-11-28T09:14:55Z",
            "summary": "In recent years, the field of single-cell RNA sequencing has seen a surge in\nthe development of clustering methods. These methods enable the identification\nof cell subpopulations, thereby facilitating the understanding of tumor\nmicroenvironments. Despite their utility, most existing clustering algorithms\nprimarily focus on the attribute information provided by the cell matrix or the\nnetwork structure between cells, often neglecting the network between genes.\nThis oversight could lead to loss of information and clustering results that\nlack clinical significance. To address this limitation, we develop an advanced\nsingle-cell clustering model incorporating dual-graph alignment, which\nintegrates gene network information into the clustering process based on\nself-supervised and unsupervised optimization. Specifically, we designed a\ngraph-based autoencoder enhanced by an attention mechanism to effectively\ncapture relationships between cells. Moreover, we performed the node2vec method\non Protein-Protein Interaction (PPI) networks to derive the gene network\nstructure and maintained this structure throughout the clustering process. Our\nproposed method has been demonstrated to be effective through experimental\nresults, showcasing its ability to optimize clustering outcomes while\npreserving the original associations between cells and genes. This research\ncontributes to obtaining accurate cell subpopulations and generates clustering\nresults that more closely resemble real-world biological scenarios. It provides\nbetter insights into the characteristics and distribution of diseased cells,\nultimately building a foundation for early disease diagnosis and treatment.",
            "author": [
                "Dayu Hu",
                "Ke Liang",
                "Xinwang Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17104v1",
                "http://arxiv.org/pdf/2311.17104v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "q-bio.MN"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16613v1",
            "title": "Filter-Pruning of Lightweight Face Detectors Using a Geometric Median\n  Criterion",
            "updated": "2023-11-28T09:02:38Z",
            "published": "2023-11-28T09:02:38Z",
            "summary": "Face detectors are becoming a crucial component of many applications,\nincluding surveillance, that often have to run on edge devices with limited\nprocessing power and memory. Therefore, there's a pressing demand for compact\nface detection models that can function efficiently across resource-constrained\ndevices. Over recent years, network pruning techniques have attracted a lot of\nattention from researchers. These methods haven't been well examined in the\ncontext of face detectors, despite their expanding popularity. In this paper,\nwe implement filter pruning on two already small and compact face detectors,\nnamed EXTD (Extremely Tiny Face Detector) and EResFD (Efficient ResNet Face\nDetector). The main pruning algorithm that we utilize is Filter Pruning via\nGeometric Median (FPGM), combined with the Soft Filter Pruning (SFP) iterative\nprocedure. We also apply L1 Norm pruning, as a baseline to compare with the\nproposed approach. The experimental evaluation on the WIDER FACE dataset\nindicates that the proposed approach has the potential to further reduce the\nmodel size of already lightweight face detectors, with limited accuracy loss,\nor even with small accuracy gain for low pruning rates.",
            "author": [
                "Konstantinos Gkrispanis",
                "Nikolaos Gkalelis",
                "Vasileios Mezaris"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16613v1",
                "http://arxiv.org/pdf/2311.16613v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16611v1",
            "title": "Numerical Method for a Controlled Sweeping Process with Nonsmooth\n  Sweeping Set",
            "updated": "2023-11-28T08:59:36Z",
            "published": "2023-11-28T08:59:36Z",
            "summary": "The numerical method developed in [30] for optimal control problems involving\nsweeping processes with smooth sweeping set C is generalized to the case where\nC is nonsmooth, namely, C is the intersection of a finite number of sublevel\nsets of smooth functions. The novelty of this extension resides in producing\nfor the general setting a different approach, since the one used for the smooth\nsweeping sets is not applicable here.",
            "author": [
                "Chadi Nour",
                "Vera Zeidan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16611v1",
                "http://arxiv.org/pdf/2311.16611v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "34A60-49K21-65K10"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16609v1",
            "title": "Eigenmatrix for unstructured sparse recovery",
            "updated": "2023-11-28T08:54:29Z",
            "published": "2023-11-28T08:54:29Z",
            "summary": "This paper considers the unstructured sparse recovery problems in a general\nform. Examples include rational approximation, spectral function estimation,\nFourier inversion, Laplace inversion, and sparse deconvolution. The main\nchallenges are the noise in the sample values and the unstructured nature of\nthe sample locations. This paper proposes the eigenmatrix, a data-driven\nconstruction with desired approximate eigenvalues and eigenvectors. The\neigenmatrix offers a new way for these sparse recovery problems. Numerical\nresults are provided to demonstrate the efficiency of the proposed method.",
            "author": [
                "Lexing Ying"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16609v1",
                "http://arxiv.org/pdf/2311.16609v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.IT",
                "cs.LG",
                "cs.NA",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16607v1",
            "title": "Extending the WMSO+U Logic With Quantification Over Tuples",
            "updated": "2023-11-28T08:52:45Z",
            "published": "2023-11-28T08:52:45Z",
            "summary": "We study a new extension of the weak MSO logic, talking about boundedness.\nInstead of a previously considered quantifier U, expressing the fact that there\nexist arbitrarily large finite sets satisfying a given property, we consider a\ngeneralized quantifier U, expressing the fact that there exist tuples of\narbitrarily large finite sets satisfying a given property. First, we prove that\nthe new logic WMSO+U_tup is strictly more expressive than WMSO+U. In\nparticular, WMSO+U_tup is able to express the so-called simultaneous\nunboundedness property, for which we prove that it is not expressible in\nWMSO+U. Second, we prove that it is decidable whether the tree generated by a\ngiven higher-order recursion scheme satisfies a given sentence of WMSO+K_tup.",
            "author": [
                "Anita Badyl",
                "Pawe\u0142 Parys"
            ],
            "link": [
                "http://dx.doi.org/10.4230/LIPIcs.CSL.2024.2",
                "http://arxiv.org/abs/2311.16607v1",
                "http://arxiv.org/pdf/2311.16607v1"
            ],
            "primary_category": "cs.LO",
            "category": [
                "cs.LO",
                "cs.FL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16604v1",
            "title": "LC4SV: A Denoising Framework Learning to Compensate for Unseen Speaker\n  Verification Models",
            "updated": "2023-11-28T08:44:04Z",
            "published": "2023-11-28T08:44:04Z",
            "summary": "The performance of speaker verification (SV) models may drop dramatically in\nnoisy environments. A speech enhancement (SE) module can be used as a front-end\nstrategy. However, existing SE methods may fail to bring performance\nimprovements to downstream SV systems due to artifacts in the predicted signals\nof SE models. To compensate for artifacts, we propose a generic denoising\nframework named LC4SV, which can serve as a pre-processor for various unknown\ndownstream SV models. In LC4SV, we employ a learning-based interpolation agent\nto automatically generate the appropriate coefficients between the enhanced\nsignal and its noisy input to improve SV performance in noisy environments. Our\nexperimental results demonstrate that LC4SV consistently improves the\nperformance of various unseen SV systems. To the best of our knowledge, this\nwork is the first attempt to develop a learning-based interpolation scheme\naiming at improving SV performance in noisy environments.",
            "author": [
                "Chi-Chang Lee",
                "Hong-Wei Chen",
                "Chu-Song Chen",
                "Hsin-Min Wang",
                "Tsung-Te Liu",
                "Yu Tsao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16604v1",
                "http://arxiv.org/pdf/2311.16604v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16603v1",
            "title": "l2Match: Optimization Techniques on Subgraph Matching Algorithm using\n  Label Pair, Neighboring Label Index, and Jump-Redo method",
            "updated": "2023-11-28T08:44:01Z",
            "published": "2023-11-28T08:44:01Z",
            "summary": "Graph database is designed to store bidirectional relationships between\nobjects and facilitate the traversal process to extract a subgraph. However,\nthe subgraph matching process is an NP-Complete problem. Existing solutions to\nthis problem usually employ a filter-and-verification framework and a\ndivide-and-conquer method. The filter-and-verification framework minimizes the\nnumber of inputs to the verification stage by filtering and pruning invalid\ncandidates as much as possible. Meanwhile, subgraph matching is performed on\nthe substructure decomposed from the larger graph to yield partial embedding.\nSubsequently, the recursive traversal or set intersection technique combines\nthe partial embedding into a complete subgraph. In this paper, we first present\na comprehensive literature review of the state-of-the-art solutions. l2Match, a\nsubgraph isomorphism algorithm for small queries utilizing a Label-Pair Index\nand filtering method, is then proposed and presented as a proof of concept.\nEmpirical experimentation shows that l2Match outperforms related\nstate-of-the-art solutions, and the proposed methods optimize the existing\nalgorithms.",
            "author": [
                "C. Q. Cheng",
                "K. S. Wong",
                "L. K. Soon"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16603v1",
                "http://arxiv.org/pdf/2311.16603v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.IR",
                "05C60 (Primary), 05C30 (Secondary), 68R10",
                "G.4.1; H.3.3"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16602v1",
            "title": "GSP-KalmanNet: Tracking Graph Signals via Neural-Aided Kalman Filtering",
            "updated": "2023-11-28T08:43:10Z",
            "published": "2023-11-28T08:43:10Z",
            "summary": "Dynamic systems of graph signals are encountered in various applications,\nincluding social networks, power grids, and transportation. While such systems\ncan often be described as state space (SS) models, tracking graph signals via\nconventional tools based on the Kalman filter (KF) and its variants is\ntypically challenging. This is due to the nonlinearity, high dimensionality,\nirregularity of the domain, and complex modeling associated with real-world\ndynamic systems of graph signals. In this work, we study the tracking of graph\nsignals using a hybrid model-based/data-driven approach. We develop the\nGSP-KalmanNet, which tracks the hidden graphical states from the graphical\nmeasurements by jointly leveraging graph signal processing (GSP) tools and deep\nlearning (DL) techniques. The derivations of the GSP-KalmanNet are based on\nextending the KF to exploit the inherent graph structure via graph frequency\ndomain filtering, which considerably simplifies the computational complexity\nentailed in processing high-dimensional signals and increases the robustness to\nsmall topology changes. Then, we use data to learn the Kalman gain following\nthe recently proposed KalmanNet framework, which copes with partial and\napproximated modeling, without forcing a specific model over the noise\nstatistics. Our empirical results demonstrate that the proposed GSP-KalmanNet\nachieves enhanced accuracy and run time performance as well as improved\nrobustness to model misspecifications compared with both model-based and\ndata-driven benchmarks.",
            "author": [
                "Itay Buchnik",
                "Guy Sagi",
                "Nimrod Leinwand",
                "Yuval Loya",
                "Nir Shlezinger",
                "Tirza Routtenberg"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16602v1",
                "http://arxiv.org/pdf/2311.16602v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16600v1",
            "title": "Morphisms of Cuntz-Pimsner algebras from completely positive maps",
            "updated": "2023-11-28T08:42:10Z",
            "published": "2023-11-28T08:42:10Z",
            "summary": "We introduce positive correspondences as right C*-modules with left actions\ngiven by completely positive maps. Positive correspondences form a\nsemi-category that contains the C*-correspondence (Enchilada) category as a\n\"retract\". Kasparov's KSGNS construction provides a semi-functor from this\nsemi-category onto the C*-correspondence category. The need for left actions by\ncompletely positive maps appears naturally when we consider morphisms between\nCuntz-Pimsner algebras, and we describe classes of examples arising from\nprojections on C*-correspondences and Fock spaces, as well as examples from\nconjugation by bi-Hilbertian bimodules of finite index.",
            "author": [
                "Kevin Aguyar Brix",
                "Alexander Mundey",
                "Adam Rennie"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16600v1",
                "http://arxiv.org/pdf/2311.16600v1"
            ],
            "primary_category": "math.OA",
            "category": [
                "math.OA",
                "46L55 (Primary), 37A55, 46L08 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.02992v1",
            "title": "Advancing Web Accessibility -- A guide to transitioning Design Systems\n  from WCAG 2.0 to WCAG 2.1",
            "updated": "2023-11-28T08:33:32Z",
            "published": "2023-11-28T08:33:32Z",
            "summary": "This research focuses on the critical process of upgrading a Design System\nfrom Web Content Accessibility Guidelines (WCAG) 2.0 to WCAG 2.1, which is an\nessential step in enhancing web accessibility. It emphasizes the importance of\nstaying up to date on increasing accessibility requirements, as well as the\ncritical function of Design Systems in supporting inclusion in digital\nenvironments. The article lays out a complete strategy for meeting WCAG 2.1\ncompliance. Assessment, strategic planning, implementation, and testing are all\npart of this strategy. The need for collaboration and user involvement is\nemphasized as critical strategies and best practices for a successful migration\njourney. In addition, the article digs into migration barriers and discusses\nsignificant lessons acquired, offering a realistic view of the intricacies of\nthis transforming road. Finally, it is a practical guide and a necessary\nresource for organizations committed to accessible and user-centered design.\nThe document provides them with the knowledge and resources they need to\nnavigate the changing world of web accessibility properly.",
            "author": [
                "Hardik Shah"
            ],
            "link": [
                "http://dx.doi.org/10.5121/csit.2023.132218",
                "http://arxiv.org/abs/2312.02992v1",
                "http://arxiv.org/pdf/2312.02992v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16595v1",
            "title": "D4AM: A General Denoising Framework for Downstream Acoustic Models",
            "updated": "2023-11-28T08:27:27Z",
            "published": "2023-11-28T08:27:27Z",
            "summary": "The performance of acoustic models degrades notably in noisy environments.\nSpeech enhancement (SE) can be used as a front-end strategy to aid automatic\nspeech recognition (ASR) systems. However, existing training objectives of SE\nmethods are not fully effective at integrating speech-text and noisy-clean\npaired data for training toward unseen ASR systems. In this study, we propose a\ngeneral denoising framework, D4AM, for various downstream acoustic models. Our\nframework fine-tunes the SE model with the backward gradient according to a\nspecific acoustic model and the corresponding classification objective. In\naddition, our method aims to consider the regression objective as an auxiliary\nloss to make the SE model generalize to other unseen acoustic models. To\njointly train an SE unit with regression and classification objectives, D4AM\nuses an adjustment scheme to directly estimate suitable weighting coefficients\nrather than undergoing a grid search process with additional training costs.\nThe adjustment scheme consists of two parts: gradient calibration and\nregression objective weighting. The experimental results show that D4AM can\nconsistently and effectively provide improvements to various unseen acoustic\nmodels and outperforms other combination setups. Specifically, when evaluated\non the Google ASR API with real noisy data completely unseen during SE\ntraining, D4AM achieves a relative WER reduction of 24.65% compared with the\ndirect feeding of noisy input. To our knowledge, this is the first work that\ndeploys an effective combination scheme of regression (denoising) and\nclassification (ASR) objectives to derive a general pre-processor applicable to\nvarious unseen ASR systems. Our code is available at\nhttps://github.com/ChangLee0903/D4AM.",
            "author": [
                "Chi-Chang Lee",
                "Yu Tsao",
                "Hsin-Min Wang",
                "Chu-Song Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16595v1",
                "http://arxiv.org/pdf/2311.16595v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.LG",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17102v1",
            "title": "Splinets -- Orthogonal Splines and FDA for the Classification Problem",
            "updated": "2023-11-28T08:26:56Z",
            "published": "2023-11-28T08:26:56Z",
            "summary": "This study introduces an efficient workflow for functional data analysis in\nclassification problems, utilizing advanced orthogonal spline bases. The\nmethodology is based on the flexible Splinets package, featuring a novel spline\nrepresentation designed for enhanced data efficiency. Several innovative\nfeatures contribute to this efficiency: 1)Utilization of Orthonormal Spline\nBases 2)Consideration of Spline Support Sets 3)Data-Driven Knot Selection.\nIllustrating this approach, we applied the workflow to the Fashion MINST\ndataset. We demonstrate the classification process and highlight significant\nefficiency gains. Particularly noteworthy are the improvements that can be\nachieved through the 2D generalization of our methodology, especially in\nscenarios where data sparsity and dimension reduction are critical factors. A\nkey advantage of our workflow is the projection operation into the space of\nsplines with arbitrarily chosen knots, allowing for versatile functional data\nanalysis associated with classification problems. Moreover, the study explores\nSplinets package features suited for functional data analysis. The algebra and\ncalculus of splines use Taylor expansions at the knots within the support sets.\nVarious orthonormalization techniques for B-splines are implemented, including\nthe highly recommended dyadic method, which leads to the creation of splinets.\nImportantly, the locality of B-splines concerning support sets is preserved in\nthe corresponding splinet. Using this locality, along with implemented\nalgorithms, provides a powerful computational tool for functional data\nanalysis.",
            "author": [
                "Rani Basna",
                "Hiba Nassar",
                "Krzysztof Podg\u00f3rski"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17102v1",
                "http://arxiv.org/pdf/2311.17102v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16594v1",
            "title": "Monitor Placement for Fault Localization in Deep Neural Network\n  Accelerators",
            "updated": "2023-11-28T08:21:34Z",
            "published": "2023-11-28T08:21:34Z",
            "summary": "Systolic arrays are a prominent choice for deep neural network (DNN)\naccelerators because they offer parallelism and efficient data reuse. Improving\nthe reliability of DNN accelerators is crucial as hardware faults can degrade\nthe accuracy of DNN inferencing. Systolic arrays make use of a large number of\nprocessing elements (PEs) for parallel processing, but when one PE is faulty,\nthe error propagates and affects the outcomes of downstream PEs. Due to the\nlarge number of PEs, the cost associated with implementing hardware-based\nruntime monitoring of every single PE is infeasible. We present a solution to\noptimize the placement of hardware monitors within systolic arrays. We first\nprove that $2N-1$ monitors are needed to localize a single faulty PE and we\nalso derive the monitor placement. We show that a second placement optimization\nproblem, which minimizes the set of candidate faulty PEs for a given number of\nmonitors, is NP-hard. Therefore, we propose a heuristic approach to balance the\nreliability and hardware resource utilization in DNN accelerators when number\nof monitors is limited. Experimental evaluation shows that to localize a single\nfaulty PE, an area overhead of only 0.33% is incurred for a $256\\times 256$\nsystolic array.",
            "author": [
                "Wei-Kai Liu",
                "Benjamin Tan",
                "Krishnendu Chakrabarty"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16594v1",
                "http://arxiv.org/pdf/2311.16594v1"
            ],
            "primary_category": "cs.AR",
            "category": [
                "cs.AR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16593v1",
            "title": "Empowering COVID-19 Detection: Optimizing Performance Through Fine-Tuned\n  EfficientNet Deep Learning Architecture",
            "updated": "2023-11-28T08:18:30Z",
            "published": "2023-11-28T08:18:30Z",
            "summary": "The worldwide COVID-19 pandemic has profoundly influenced the health and\neveryday experiences of individuals across the planet. It is a highly\ncontagious respiratory disease requiring early and accurate detection to curb\nits rapid transmission. Initial testing methods primarily revolved around\nidentifying the genetic composition of the coronavirus, exhibiting a relatively\nlow detection rate and requiring a time-intensive procedure. To address this\nchallenge, experts have suggested using radiological imagery, particularly\nchest X-rays, as a valuable approach within the diagnostic protocol. This study\ninvestigates the potential of leveraging radiographic imaging (X-rays) with\ndeep learning algorithms to swiftly and precisely identify COVID-19 patients.\nThe proposed approach elevates the detection accuracy by fine-tuning with\nappropriate layers on various established transfer learning models. The\nexperimentation was conducted on a COVID-19 X-ray dataset containing 2000\nimages. The accuracy rates achieved were impressive of 100% for EfficientNetB4\nmodel. The fine-tuned EfficientNetB4 achieved an excellent accuracy score,\nshowcasing its potential as a robust COVID-19 detection model. Furthermore,\nEfficientNetB4 excelled in identifying Lung disease using Chest X-ray dataset\ncontaining 4,350 Images, achieving remarkable performance with an accuracy of\n99.17%, precision of 99.13%, recall of 99.16%, and f1-score of 99.14%. These\nresults highlight the promise of fine-tuned transfer learning for efficient\nlung detection through medical imaging, especially with X-ray images. This\nresearch offers radiologists an effective means of aiding rapid and precise\nCOVID-19 diagnosis and contributes valuable assistance for healthcare\nprofessionals in accurately identifying affected patients.",
            "author": [
                "Md. Alamin Talukder",
                "Md. Abu Layek",
                "Mohsin Kazi",
                "Md Ashraf Uddin",
                "Sunil Aryal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16593v1",
                "http://arxiv.org/pdf/2311.16593v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16592v1",
            "title": "RGBGrasp: Image-based Object Grasping by Capturing Multiple Views during\n  Robot Arm Movement with Neural Radiance Fields",
            "updated": "2023-11-28T08:17:58Z",
            "published": "2023-11-28T08:17:58Z",
            "summary": "Robotic research encounters a significant hurdle when it comes to the\nintricate task of grasping objects that come in various shapes, materials, and\ntextures. Unlike many prior investigations that heavily leaned on specialized\npoint-cloud cameras or abundant RGB visual data to gather 3D insights for\nobject-grasping missions, this paper introduces a pioneering approach called\nRGBGrasp. This method depends on a limited set of RGB views to perceive the 3D\nsurroundings containing transparent and specular objects and achieve accurate\ngrasping. Our method utilizes pre-trained depth prediction models to establish\ngeometry constraints, enabling precise 3D structure estimation, even under\nlimited view conditions. Finally, we integrate hash encoding and a proposal\nsampler strategy to significantly accelerate the 3D reconstruction process.\nThese innovations significantly enhance the adaptability and effectiveness of\nour algorithm in real-world scenarios. Through comprehensive experimental\nvalidation, we demonstrate that RGBGrasp achieves remarkable success across a\nwide spectrum of object-grasping scenarios, establishing it as a promising\nsolution for real-world robotic manipulation tasks. The demo of our method can\nbe found on: https://sites.google.com/view/rgbgrasp",
            "author": [
                "Chang Liu",
                "Kejian Shi",
                "Kaichen Zhou",
                "Haoxiao Wang",
                "Jiyao Zhang",
                "Hao Dong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16592v1",
                "http://arxiv.org/pdf/2311.16592v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16590v1",
            "title": "Atomic diffusion-induced polarization and superconductivity in\n  topological insulator-based heterostructures",
            "updated": "2023-11-28T08:17:13Z",
            "published": "2023-11-28T08:17:13Z",
            "summary": "The proximity effect at a highly transparent interface of an s-wave\nsuperconductor (S) and a topological insulator (TI) provides a promising\nplatform to create Majorana zero modes in artificially designed\nheterostructures. However, structural and chemical issues pertinent to such\ninterfaces are poorly explored so far. Here, we report the discovery of Pd\ndiffusion induced polarization at interfaces between superconductive\nPd$_{1+x}$(Bi$_{0.4}$Te$_{0.6}$)$_2$ (xPBT, $0\\le x \\le 1$) and Pd-intercalated\nBi$_2$Te$_3$ by using atomic-resolution scanning transmission electron\nmicroscopy. Our quantitative image analysis reveals that nanoscale lattice\nstrain and QL polarity synergistically suppress and promote the Pd diffusion at\nthe normal and parallel interfaces, formed between Te-Pd-Bi triple layers (TLs)\nand Te-Bi-Te-Bi-Te quintuple layers (QLs), respectively. Further, our\nfirst-principles calculations unveil that the superconductivity of xPBT phase\nand topological nature of Pd-intercalated Bi$_2$Te$_3$ phase are robust against\nthe broken inversion symmetry. These findings point out the necessity of\nconsidering coexistence of electric polarization with superconductivity and\ntopology in such S-TI systems.",
            "author": [
                "Xian-Kui Wei",
                "Abdur Rehman Jalil",
                "Philipp R\u00fc\u00dfmann",
                "Yoichi Ando",
                "Detlev Gr\u00fctzmacher",
                "Stefan Bl\u00fcgel",
                "Joachim Mayer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16590v1",
                "http://arxiv.org/pdf/2311.16590v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "cond-mat.supr-con"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16588v1",
            "title": "MedGen: A Python Natural Language Processing Toolkit for Medical Text\n  Processing",
            "updated": "2023-11-28T08:13:29Z",
            "published": "2023-11-28T08:13:29Z",
            "summary": "This study introduces MedGen, a comprehensive natural language processing\n(NLP) toolkit designed for medical text processing. MedGen is tailored for\nbiomedical researchers and healthcare professionals with an easy-to-use,\nall-in-one solution that requires minimal programming expertise. It includes\n(1) Generative Functions: For the first time, MedGen includes four advanced\ngenerative functions: question answering, text summarization, text\nsimplification, and machine translation; (2) Basic NLP Functions: MedGen\nintegrates 12 essential NLP functions such as word tokenization and sentence\nsegmentation; and (3) Query and Search Capabilities: MedGen provides\nuser-friendly query and search functions on text corpora. We fine-tuned 32\ndomain-specific language models, evaluated them thoroughly on 24 established\nbenchmarks and conducted manual reviews with clinicians. Additionally, we\nexpanded our toolkit by introducing query and search functions, while also\nstandardizing and integrating functions from third-party libraries. The\ntoolkit, its models, and associated data are publicly available via\nhttps://github.com/Yale-LILY/MedGen.",
            "author": [
                "Rui Yang",
                "Qingcheng Zeng",
                "Keen You",
                "Yujie Qiao",
                "Lucas Huang",
                "Chia-Chun Hsieh",
                "Benjamin Rosand",
                "Jeremy Goldwasser",
                "Amisha D Dave",
                "Tiarnan D. L. Keenan",
                "Emily Y Chew",
                "Dragomir Radev",
                "Zhiyong Lu",
                "Hua Xu",
                "Qingyu Chen",
                "Irene Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16588v1",
                "http://arxiv.org/pdf/2311.16588v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16583v1",
            "title": "The Inverse of the Complex Gamma Function",
            "updated": "2023-11-28T08:00:38Z",
            "published": "2023-11-28T08:00:38Z",
            "summary": "We consider the functional inverse of the Gamma function in the complex\nplane, where it is multi-valued, and define a set of suitable branches by\nproposing a natural extension from the real case.",
            "author": [
                "David J. Jeffrey",
                "Stephen M. Watt"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16583v1",
                "http://arxiv.org/pdf/2311.16583v1"
            ],
            "primary_category": "math.CV",
            "category": [
                "math.CV",
                "cs.SC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16581v1",
            "title": "GeoScaler: Geometry and Rendering-Aware Downsampling of 3D Mesh Textures",
            "updated": "2023-11-28T07:55:25Z",
            "published": "2023-11-28T07:55:25Z",
            "summary": "High-resolution texture maps are necessary for representing real-world\nobjects accurately with 3D meshes. The large sizes of textures can bottleneck\nthe real-time rendering of high-quality virtual 3D scenes on devices having low\ncomputational budgets and limited memory. Downsampling the texture maps\ndirectly addresses the issue, albeit at the cost of visual fidelity.\nTraditionally, downsampling of texture maps is performed using methods like\nbicubic interpolation and the Lanczos algorithm. These methods ignore the\ngeometric layout of the mesh and its UV parametrization and also do not account\nfor the rendering process used to obtain the final visualization that the users\nwill experience. Towards filling these gaps, we introduce GeoScaler, which is a\nmethod of downsampling texture maps of 3D meshes while incorporating geometric\ncues, and by maximizing the visual fidelity of the rendered views of the\ntextured meshes. We show that the textures generated by GeoScaler deliver\nsignificantly better quality rendered images compared to those generated by\ntraditional downsampling methods",
            "author": [
                "Sai Karthikey Pentapati",
                "Anshul Rai",
                "Arkady Ten",
                "Chaitanya Atluru",
                "Alan Bovik"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16581v1",
                "http://arxiv.org/pdf/2311.16581v1"
            ],
            "primary_category": "cs.GR",
            "category": [
                "cs.GR",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16579v1",
            "title": "Recognizing Conditional Causal Relationships about Emotions and Their\n  Corresponding Conditions",
            "updated": "2023-11-28T07:47:25Z",
            "published": "2023-11-28T07:47:25Z",
            "summary": "The study of causal relationships between emotions and causes in texts has\nrecently received much attention. Most works focus on extracting causally\nrelated clauses from documents. However, none of these works has considered\nthat the causal relationships among the extracted emotion and cause clauses can\nonly be valid under some specific context clauses. To highlight the context in\nsuch special causal relationships, we propose a new task to determine whether\nor not an input pair of emotion and cause has a valid causal relationship under\ndifferent contexts and extract the specific context clauses that participate in\nthe causal relationship. Since the task is new for which no existing dataset is\navailable, we conduct manual annotation on a benchmark dataset to obtain the\nlabels for our tasks and the annotations of each context clause's type that can\nalso be used in some other applications. We adopt negative sampling to\nconstruct the final dataset to balance the number of documents with and without\ncausal relationships. Based on the constructed dataset, we propose an\nend-to-end multi-task framework, where we design two novel and general modules\nto handle the two goals of our task. Specifically, we propose a context masking\nmodule to extract the context clauses participating in the causal\nrelationships. We propose a prediction aggregation module to fine-tune the\nprediction results according to whether the input emotion and causes depend on\nspecific context clauses. Results of extensive comparative experiments and\nablation studies demonstrate the effectiveness and generality of our proposed\nframework.",
            "author": [
                "Xinhong Chen",
                "Zongxi Li",
                "Yaowei Wang",
                "Haoran Xie",
                "Jianping Wang",
                "Qing Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16579v1",
                "http://arxiv.org/pdf/2311.16579v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16578v1",
            "title": "Counting 7-Arcs in Projective Planes over Finite Fields",
            "updated": "2023-11-28T07:46:44Z",
            "published": "2023-11-28T07:46:44Z",
            "summary": "Given a collection of points in the plane, classifying which subsets are\ncollinear is a natural problem and is related to classical geometric\nconstructions. We consider collections of points in a projective plane over a\nfinite field such that no three are collinear. This is a finite set and its\nsize is both combinatorially interesting and has deeper topological\nconsequences. We count the number of such collections classified by the\nalgebraic symmetries of the finite field. Variations of this problem have been\nconsidered by Glynn, Bergvall, Das, O'Connor et al. We obtain the counts for 7\npoints over fields of characteristic 2. These new counts are governed by the\nexistence and classification of a configuration of points called the Fano\nplane.",
            "author": [
                "Andrei Staicu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16578v1",
                "http://arxiv.org/pdf/2311.16578v1"
            ],
            "primary_category": "math.AG",
            "category": [
                "math.AG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16576v1",
            "title": "Wireless Powered Metaverse: Joint Task Scheduling and Trajectory Design\n  for Multi-Devices and Multi-UAVs",
            "updated": "2023-11-28T07:32:32Z",
            "published": "2023-11-28T07:32:32Z",
            "summary": "To support the running of human-centric metaverse applications on mobile\ndevices, Unmanned Aerial Vehicle (UAV)-assisted Wireless Powered Mobile Edge\nComputing (WPMEC) is promising to compensate for limited computational\ncapabilities and energy supplies of mobile devices. The high-speed\ncomputational processing demands and significant energy consumption of\nmetaverse applications require joint resource scheduling of multiple devices\nand UAVs, but existing WPMEC solutions address either device or UAV scheduling\ndue to the complexity of combinatorial optimization. To solve the above\nchallenge, we propose a two-stage alternating optimization algorithm based on\nmulti-task Deep Reinforcement Learning (DRL) to jointly allocate charging time,\nschedule computation tasks, and optimize trajectory of UAVs and mobile devices\nin a wireless powered metaverse scenario. First, considering energy constraints\nof both UAVs and mobile devices, we formulate an optimization problem to\nmaximize the computation efficiency of the system. Second, we propose a\nheuristic algorithm to efficiently perform time allocation and charging\nscheduling for mobile devices. Following this, we design a multi-task DRL\nscheme to make charging scheduling and trajectory design decisions for UAVs.\nFinally, theoretical analysis and performance results demonstrate that our\nalgorithm exhibits significant advantages over representative methods in terms\nof convergence speed and average computation efficiency.",
            "author": [
                "Xiaojie Wang",
                "Jiameng Li",
                "Zhaolong Ning",
                "Qingyang Song",
                "Lei Guo",
                "Abbas Jamalipour"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16576v1",
                "http://arxiv.org/pdf/2311.16576v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16575v1",
            "title": "Secure Traversable Event logging for Responsible Identification of\n  Vertically Partitioned Health Data",
            "updated": "2023-11-28T07:32:26Z",
            "published": "2023-11-28T07:32:26Z",
            "summary": "We aim to provide a solution for the secure identification of sensitive\nmedical information. We consider a repository of de-identified medical data\nthat is stored in the custody of a Healthcare Institution. The identifying\ninformation that is stored separately can be associated with the medical\ninformation only by a subset of users referred to as custodians. This paper\nintends to secure the process of associating identifying information with\nsensitive medical information. We also enforce the responsibility of the\ncustodians by maintaining an immutable ledger documenting the events of such\ninformation identification. The paper proposes a scheme for constructing ledger\nentries that allow the custodians and patients to browse through the entries\nwhich they are associated with. However, in order to respect their privacy,\nsuch traversal requires appropriate credentials to ensure that a user cannot\ngain any information regarding the other users involved in the system unless\nthey are both involved in the same operation.",
            "author": [
                "Sunanda Bose",
                "Dusica Marijan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16575v1",
                "http://arxiv.org/pdf/2311.16575v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16568v1",
            "title": "Active RIS Enhanced Spectrum Sensing for Cognitive Radio Networks",
            "updated": "2023-11-28T07:22:51Z",
            "published": "2023-11-28T07:22:51Z",
            "summary": "In opportunistic cognitive radio networks, when the primary signal is very\nweak compared to the background noise, the secondary user requires long sensing\ntime to achieve a reliable spectrum sensing performance, leading to little\nremaining time for the secondary transmission. To tackle this issue, we propose\nan active reconfigurable intelligent surface (RIS) assisted spectrum sensing\nsystem, where the received signal strength from the interested primary user can\nbe enhanced and underlying interference within the background noise can be\nmitigated as well. In comparison with the passive RIS, the active RIS can not\nonly adapt the phase shift of each reflecting element but also amplify the\nincident signals. Notably, we study the reflecting coefficient matrix (RCM)\noptimization problem to improve the detection probability given a maximum\ntolerable false alarm probability and limited sensing time. Then, we show that\nthe formulated problem can be equivalently transformed to a weighted mean\nsquare error minimization problem using the principle of the well-known\nweighted minimum mean square error (WMMSE) algorithm, and an iterative\noptimization approach is proposed to obtain the optimal RCM. In addition, to\nfairly compare passive RIS and active RIS, we study the required power budget\nof the RIS to achieve a target detection probability under a special case where\nthe direct links are neglected and the RIS-related channels are line-of-sight.\nVia extensive simulations, the effectiveness of the WMMSE-based RCM\noptimization approach is demonstrated. Furthermore, the results reveal that the\nactive RIS can outperform the passive RIS when the underlying interference\nwithin the background noise is relatively weak, whereas the passive RIS\nperforms better in strong interference scenarios because the same power budget\ncan support a vast number of passive reflecting elements for interference\nmitigation.",
            "author": [
                "Jungang Ge",
                "Ying-Chang Liang",
                "Sumei Sun",
                "Yonghong Zeng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16568v1",
                "http://arxiv.org/pdf/2311.16568v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16565v2",
            "title": "DiffusionTalker: Personalization and Acceleration for Speech-Driven 3D\n  Face Diffuser",
            "updated": "2023-12-02T16:48:09Z",
            "published": "2023-11-28T07:13:20Z",
            "summary": "Speech-driven 3D facial animation has been an attractive task in both\nacademia and industry. Traditional methods mostly focus on learning a\ndeterministic mapping from speech to animation. Recent approaches start to\nconsider the non-deterministic fact of speech-driven 3D face animation and\nemploy the diffusion model for the task. However, personalizing facial\nanimation and accelerating animation generation are still two major limitations\nof existing diffusion-based methods. To address the above limitations, we\npropose DiffusionTalker, a diffusion-based method that utilizes contrastive\nlearning to personalize 3D facial animation and knowledge distillation to\naccelerate 3D animation generation. Specifically, to enable personalization, we\nintroduce a learnable talking identity to aggregate knowledge in audio\nsequences. The proposed identity embeddings extract customized facial cues\nacross different people in a contrastive learning manner. During inference,\nusers can obtain personalized facial animation based on input audio, reflecting\na specific talking style. With a trained diffusion model with hundreds of\nsteps, we distill it into a lightweight model with 8 steps for acceleration.\nExtensive experiments are conducted to demonstrate that our method outperforms\nstate-of-the-art methods. The code will be released.",
            "author": [
                "Peng Chen",
                "Xiaobao Wei",
                "Ming Lu",
                "Yitong Zhu",
                "Naiming Yao",
                "Xingyu Xiao",
                "Hui Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16565v2",
                "http://arxiv.org/pdf/2311.16565v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16556v1",
            "title": "Scalable Label Distribution Learning for Multi-Label Classification",
            "updated": "2023-11-28T06:52:53Z",
            "published": "2023-11-28T06:52:53Z",
            "summary": "Multi-label classification (MLC) refers to the problem of tagging a given\ninstance with a set of relevant labels. Most existing MLC methods are based on\nthe assumption that the correlation of two labels in each label pair is\nsymmetric, which is violated in many real-world scenarios. Moreover, most\nexisting methods design learning processes associated with the number of\nlabels, which makes their computational complexity a bottleneck when scaling up\nto large-scale output space. To tackle these issues, we propose a novel MLC\nlearning method named Scalable Label Distribution Learning (SLDL) for\nmulti-label classification which can describe different labels as distributions\nin a latent space, where the label correlation is asymmetric and the dimension\nis independent of the number of labels. Specifically, SLDL first converts\nlabels into continuous distributions within a low-dimensional latent space and\nleverages the asymmetric metric to establish the correlation between different\nlabels. Then, it learns the mapping from the feature space to the latent space,\nresulting in the computational complexity is no longer related to the number of\nlabels. Finally, SLDL leverages a nearest-neighbor-based strategy to decode the\nlatent representations and obtain the final predictions. Our extensive\nexperiments illustrate that SLDL can achieve very competitive classification\nperformances with little computational consumption.",
            "author": [
                "Xingyu Zhao",
                "Yuexuan An",
                "Lei Qi",
                "Xin Geng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16556v1",
                "http://arxiv.org/pdf/2311.16556v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.00051v1",
            "title": "MIA-BAD: An Approach for Enhancing Membership Inference Attack and its\n  Mitigation with Federated Learning",
            "updated": "2023-11-28T06:51:26Z",
            "published": "2023-11-28T06:51:26Z",
            "summary": "The membership inference attack (MIA) is a popular paradigm for compromising\nthe privacy of a machine learning (ML) model. MIA exploits the natural\ninclination of ML models to overfit upon the training data. MIAs are trained to\ndistinguish between training and testing prediction confidence to infer\nmembership information. Federated Learning (FL) is a privacy-preserving ML\nparadigm that enables multiple clients to train a unified model without\ndisclosing their private data. In this paper, we propose an enhanced Membership\nInference Attack with the Batch-wise generated Attack Dataset (MIA-BAD), a\nmodification to the MIA approach. We investigate that the MIA is more accurate\nwhen the attack dataset is generated batch-wise. This quantitatively decreases\nthe attack dataset while qualitatively improving it. We show how training an ML\nmodel through FL, has some distinct advantages and investigate how the threat\nintroduced with the proposed MIA-BAD approach can be mitigated with FL\napproaches. Finally, we demonstrate the qualitative effects of the proposed\nMIA-BAD methodology by conducting extensive experiments with various target\ndatasets, variable numbers of federated clients, and training batch sizes.",
            "author": [
                "Soumya Banerjee",
                "Sandip Roy",
                "Sayyed Farid Ahamed",
                "Devin Quinn",
                "Marc Vucovich",
                "Dhruv Nandakumar",
                "Kevin Choi",
                "Abdul Rahman",
                "Edward Bowen",
                "Sachin Shetty"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00051v1",
                "http://arxiv.org/pdf/2312.00051v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16554v1",
            "title": "Large in-plane negative piezoelectricity and giant nonlinear optical\n  susceptibility in elementary ferroelectric monolayers",
            "updated": "2023-11-28T06:44:30Z",
            "published": "2023-11-28T06:44:30Z",
            "summary": "Negative piezoelectrics contract in the direction of applied electric field,\nwhich are opposite to normal piezoelectrics and rare in dielectric materials.\nThe raising of low dimensional ferroelectrics, with unconventional mechanisms\nof polarity, opens a fertile branch for candidates with prominent negative\npiezoelectricity. Here, the distorted $\\alpha$-Bi monolayer, a newly-identified\nelementary ferroelectric with puckered black phosphorous-like structure [J.\nGuo, {\\it et al}. Nature \\textbf{617}, 67 (2023)], is computationally studied,\nwhich manifests a large negative in-plane piezoelectricity (with\n$d_{33}\\sim-26$ pC/N). Its negative piezoelectricity originates from its unique\nbuckling ferroelectric mechanism, namely the inter-column sliding.\nConsequently, a moderate tensile strain can significantly reduce its\nferroelectric switching energy barrier, while the compressive strain can\nsignificantly enhance its prominent nonlinear optical response. The physical\nmechanism of in-plane negative piezoelectricity also applies to other\nelementary ferroeletric monolayers.",
            "author": [
                "Ziwen Wang",
                "Shuai Dong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16554v1",
                "http://arxiv.org/pdf/2311.16554v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "cond-mat.mes-hall"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17095v1",
            "title": "Plug-and-Play, Dense-Label-Free Extraction of Open-Vocabulary Semantic\n  Segmentation from Vision-Language Models",
            "updated": "2023-11-28T06:42:58Z",
            "published": "2023-11-28T06:42:58Z",
            "summary": "From an enormous amount of image-text pairs, large-scale vision-language\nmodels (VLMs) learn to implicitly associate image regions with words, which is\nvital for tasks such as image captioning and visual question answering.\nHowever, leveraging such pre-trained models for open-vocabulary semantic\nsegmentation remains a challenge. In this paper, we propose a simple, yet\nextremely effective, training-free technique, Plug-and-Play Open-Vocabulary\nSemantic Segmentation (PnP-OVSS) for this task. PnP-OVSS leverages a VLM with\ndirect text-to-image cross-attention and an image-text matching loss to produce\nsemantic segmentation. However, cross-attention alone tends to over-segment,\nwhereas cross-attention plus GradCAM tend to under-segment. To alleviate this\nissue, we introduce Salience Dropout; by iteratively dropping patches that the\nmodel is most attentive to, we are able to better resolve the entire extent of\nthe segmentation mask. Compared to existing techniques, the proposed method\ndoes not require any neural network training and performs hyperparameter tuning\nwithout the need for any segmentation annotations, even for a validation set.\nPnP-OVSS demonstrates substantial improvements over a comparable baseline\n(+29.4% mIoU on Pascal VOC, +13.2% mIoU on Pascal Context, +14.0% mIoU on MS\nCOCO, +2.4% mIoU on COCO Stuff) and even outperforms most baselines that\nconduct additional network training on top of pretrained VLMs.",
            "author": [
                "Luo Jiayun",
                "Siddhesh Khandelwal",
                "Leonid Sigal",
                "Boyang Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17095v1",
                "http://arxiv.org/pdf/2311.17095v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16548v1",
            "title": "Graph Theoretic Analysis of Three-Terminal Quantum Dot Thermocouples:\n  Onsager Relations and Spin-Thermoelectric Effects",
            "updated": "2023-11-28T06:35:02Z",
            "published": "2023-11-28T06:35:02Z",
            "summary": "We introduce a simplified model for a three-terminal quantum thermocouple\nconsisting of two strongly-coupled quantum dots. To elucidate spin-dependent\nSeebeck and Peltier effects, we employ a microscopic Hamiltonian and map the\nLindblad master equation onto a quantum transition network, capturing the key\nworking principles for both reciprocal effects. Our analysis reveals quantum\nthermodynamic networks encompassing both Coulomb interaction and spin-flipping\nprocesses, lead to the emergence of spin-thermolectric effects. Using algebraic\ngraph theory, we recover the phenomenological law of irreversible\nthermodynamics from the stochastic version of the entropy production rate\nexpressed in terms of cycle flux and cycle forces. Remarkably, Onsager\nreciprocity and Kelvin relation for transport coefficients find their premises\nin the properties of cycle flux trajectories within the quantum transition\nnetwork. This underscores the universal generality of thermodynamic principles\nacross classical and quantum realms, despite their fundamentally different\nbasis from classical laws of irreversible thermodynamics relying on local\nequilibrium assumptions.",
            "author": [
                "Nikhil Gupt",
                "Shuvadip Ghosh",
                "Arnab Ghosh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16548v1",
                "http://arxiv.org/pdf/2311.16548v1"
            ],
            "primary_category": "cond-mat.mes-hall",
            "category": [
                "cond-mat.mes-hall",
                "cond-mat.stat-mech",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16507v1",
            "title": "Exploring Straighter Trajectories of Flow Matching with Diffusion\n  Guidance",
            "updated": "2023-11-28T06:19:30Z",
            "published": "2023-11-28T06:19:30Z",
            "summary": "Flow matching as a paradigm of generative model achieves notable success\nacross various domains. However, existing methods use either multi-round\ntraining or knowledge within minibatches, posing challenges in finding a\nfavorable coupling strategy for straight trajectories. To address this issue,\nwe propose a novel approach, Straighter trajectories of Flow Matching\n(StraightFM). It straightens trajectories with the coupling strategy guided by\ndiffusion model from entire distribution level. First, we propose a coupling\nstrategy to straighten trajectories, creating couplings between image and noise\nsamples under diffusion model guidance. Second, StraightFM also integrates real\ndata to enhance training, employing a neural network to parameterize another\ncoupling process from images to noise samples. StraightFM is jointly optimized\nwith couplings from above two mutually complementary directions, resulting in\nstraighter trajectories and enabling both one-step and few-step generation.\nExtensive experiments demonstrate that StraightFM yields high quality samples\nwith fewer step. StraightFM generates visually appealing images with a lower\nFID among diffusion and traditional flow matching methods within 5 sampling\nsteps when trained on pixel space. In the latent space (i.e., Latent\nDiffusion), StraightFM achieves a lower KID value compared to existing methods\non the CelebA-HQ 256 dataset in fewer than 10 sampling steps.",
            "author": [
                "Siyu Xing",
                "Jie Cao",
                "Huaibo Huang",
                "Xiao-Yu Zhang",
                "Ran He"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16507v1",
                "http://arxiv.org/pdf/2311.16507v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16543v1",
            "title": "RTLFixer: Automatically Fixing RTL Syntax Errors with Large Language\n  Models",
            "updated": "2023-11-28T06:18:54Z",
            "published": "2023-11-28T06:18:54Z",
            "summary": "This paper presents RTLFixer, a novel framework enabling automatic syntax\nerrors fixing for Verilog code with Large Language Models (LLMs). Despite LLM's\npromising capabilities, our analysis indicates that approximately 55% of errors\nin LLM-generated Verilog are syntax-related, leading to compilation failures.\nTo tackle this issue, we introduce a novel debugging framework that employs\nRetrieval-Augmented Generation (RAG) and ReAct prompting, enabling LLMs to act\nas autonomous agents in interactively debugging the code with feedback. This\nframework demonstrates exceptional proficiency in resolving syntax errors,\nsuccessfully correcting about 98.5% of compilation errors in our debugging\ndataset, comprising 212 erroneous implementations derived from the VerilogEval\nbenchmark. Our method leads to 32.3% and 10.1% increase in pass@1 success rates\nin the VerilogEval-Machine and VerilogEval-Human benchmarks, respectively.",
            "author": [
                "YunDa Tsai",
                "Mingjie Liu",
                "Haoxing Ren"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16543v1",
                "http://arxiv.org/pdf/2311.16543v1"
            ],
            "primary_category": "cs.AR",
            "category": [
                "cs.AR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16542v1",
            "title": "Agents meet OKR: An Object and Key Results Driven Agent System with\n  Hierarchical Self-Collaboration and Self-Evaluation",
            "updated": "2023-11-28T06:16:30Z",
            "published": "2023-11-28T06:16:30Z",
            "summary": "In this study, we introduce the concept of OKR-Agent designed to enhance the\ncapabilities of Large Language Models (LLMs) in task-solving. Our approach\nutilizes both self-collaboration and self-correction mechanism, facilitated by\nhierarchical agents, to address the inherent complexities in task-solving. Our\nkey observations are two-fold: first, effective task-solving demands in-depth\ndomain knowledge and intricate reasoning, for which deploying specialized\nagents for individual sub-tasks can markedly enhance LLM performance. Second,\ntask-solving intrinsically adheres to a hierarchical execution structure,\ncomprising both high-level strategic planning and detailed task execution.\nTowards this end, our OKR-Agent paradigm aligns closely with this hierarchical\nstructure, promising enhanced efficacy and adaptability across a range of\nscenarios. Specifically, our framework includes two novel modules: hierarchical\nObjects and Key Results generation and multi-level evaluation, each\ncontributing to more efficient and robust task-solving. In practical,\nhierarchical OKR generation decomposes Objects into multiple sub-Objects and\nassigns new agents based on key results and agent responsibilities. These\nagents subsequently elaborate on their designated tasks and may further\ndecompose them as necessary. Such generation operates recursively and\nhierarchically, culminating in a comprehensive set of detailed solutions. The\nmulti-level evaluation module of OKR-Agent refines solution by leveraging\nfeedback from all associated agents, optimizing each step of the process. This\nensures solution is accurate, practical, and effectively address intricate task\nrequirements, enhancing the overall reliability and quality of the outcome.\nExperimental results also show our method outperforms the previous methods on\nseveral tasks. Code and demo are available at https://okr-agent.github.io/",
            "author": [
                "Yi Zheng",
                "Chongyang Ma",
                "Kanle Shi",
                "Haibin Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16542v1",
                "http://arxiv.org/pdf/2311.16542v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16540v1",
            "title": "Communication Efficiency Optimization of Federated Learning for\n  Computing and Network Convergence of 6G Networks",
            "updated": "2023-11-28T06:12:57Z",
            "published": "2023-11-28T06:12:57Z",
            "summary": "Federated learning effectively addresses issues such as data privacy by\ncollaborating across participating devices to train global models. However,\nfactors such as network topology and device computing power can affect its\ntraining or communication process in complex network environments. A new\nnetwork architecture and paradigm with computing-measurable, perceptible,\ndistributable, dispatchable, and manageable capabilities, computing and network\nconvergence (CNC) of 6G networks can effectively support federated learning\ntraining and improve its communication efficiency. By guiding the participating\ndevices' training in federated learning based on business requirements,\nresource load, network conditions, and arithmetic power of devices, CNC can\nreach this goal. In this paper, to improve the communication efficiency of\nfederated learning in complex networks, we study the communication efficiency\noptimization of federated learning for computing and network convergence of 6G\nnetworks, methods that gives decisions on its training process for different\nnetwork conditions and arithmetic power of participating devices in federated\nlearning. The experiments address two architectures that exist for devices in\nfederated learning and arrange devices to participate in training based on\narithmetic power while achieving optimization of communication efficiency in\nthe process of transferring model parameters. The results show that the method\nwe proposed can (1) cope well with complex network situations (2) effectively\nbalance the delay distribution of participating devices for local training (3)\nimprove the communication efficiency during the transfer of model parameters\n(4) improve the resource utilization in the network.",
            "author": [
                "Yizhuo Cai",
                "Bo Lei",
                "Qianying Zhao",
                "Jing Peng",
                "Min Wei",
                "Yushun Zhang",
                "Xing Zhang"
            ],
            "link": [
                "http://dx.doi.org/10.1631/FITEE.2300122",
                "http://arxiv.org/abs/2311.16540v1",
                "http://arxiv.org/pdf/2311.16540v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC",
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16538v1",
            "title": "Federated Learning with Diffusion Models for Privacy-Sensitive Vision\n  Tasks",
            "updated": "2023-11-28T06:08:16Z",
            "published": "2023-11-28T06:08:16Z",
            "summary": "Diffusion models have shown great potential for vision-related tasks,\nparticularly for image generation. However, their training is typically\nconducted in a centralized manner, relying on data collected from publicly\navailable sources. This approach may not be feasible or practical in many\ndomains, such as the medical field, which involves privacy concerns over data\ncollection. Despite the challenges associated with privacy-sensitive data, such\ndomains could still benefit from valuable vision services provided by diffusion\nmodels. Federated learning (FL) plays a crucial role in enabling decentralized\nmodel training without compromising data privacy. Instead of collecting data,\nan FL system gathers model parameters, effectively safeguarding the private\ndata of different parties involved. This makes FL systems vital for managing\ndecentralized learning tasks, especially in scenarios where privacy-sensitive\ndata is distributed across a network of clients. Nonetheless, FL presents its\nown set of challenges due to its distributed nature and privacy-preserving\nproperties. Therefore, in this study, we explore the FL strategy to train\ndiffusion models, paving the way for the development of federated diffusion\nmodels. We conduct experiments on various FL scenarios, and our findings\ndemonstrate that federated diffusion models have great potential to deliver\nvision services to privacy-sensitive domains.",
            "author": [
                "Ye Lin Tun",
                "Chu Myaet Thwal",
                "Ji Su Yoon",
                "Sun Moo Kang",
                "Chaoning Zhang",
                "Choong Seon Hong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16538v1",
                "http://arxiv.org/pdf/2311.16538v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17092v1",
            "title": "SEED-Bench-2: Benchmarking Multimodal Large Language Models",
            "updated": "2023-11-28T05:53:55Z",
            "published": "2023-11-28T05:53:55Z",
            "summary": "Multimodal large language models (MLLMs), building upon the foundation of\npowerful large language models (LLMs), have recently demonstrated exceptional\ncapabilities in generating not only texts but also images given interleaved\nmultimodal inputs (acting like a combination of GPT-4V and DALL-E 3). However,\nexisting MLLM benchmarks remain limited to assessing only models' comprehension\nability of single image-text inputs, failing to keep up with the strides made\nin MLLMs. A comprehensive benchmark is imperative for investigating the\nprogress and uncovering the limitations of current MLLMs. In this work, we\ncategorize the capabilities of MLLMs into hierarchical levels from $L_0$ to\n$L_4$ based on the modalities they can accept and generate, and propose\nSEED-Bench-2, a comprehensive benchmark that evaluates the\n\\textbf{hierarchical} capabilities of MLLMs. Specifically, SEED-Bench-2\ncomprises 24K multiple-choice questions with accurate human annotations, which\nspans 27 dimensions, including the evaluation of both text and image\ngeneration. Multiple-choice questions with groundtruth options derived from\nhuman annotation enables an objective and efficient assessment of model\nperformance, eliminating the need for human or GPT intervention during\nevaluation. We further evaluate the performance of 23 prominent open-source\nMLLMs and summarize valuable observations. By revealing the limitations of\nexisting MLLMs through extensive evaluations, we aim for SEED-Bench-2 to\nprovide insights that will motivate future research towards the goal of General\nArtificial Intelligence. Dataset and evaluation code are available at\n\\href{https://github.com/AILab-CVC/SEED-Bench}",
            "author": [
                "Bohao Li",
                "Yuying Ge",
                "Yixiao Ge",
                "Guangzhi Wang",
                "Rui Wang",
                "Ruimao Zhang",
                "Ying Shan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17092v1",
                "http://arxiv.org/pdf/2311.17092v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16536v1",
            "title": "Personalized Predictions of Glioblastoma Infiltration: Mathematical\n  Models, Physics-Informed Neural Networks and Multimodal Scans",
            "updated": "2023-11-28T05:45:20Z",
            "published": "2023-11-28T05:45:20Z",
            "summary": "Predicting the infiltration of Glioblastoma (GBM) from medical MRI scans is\ncrucial for understanding tumor growth dynamics and designing personalized\nradiotherapy treatment plans.Mathematical models of GBM growth can complement\nthe data in the prediction of spatial distributions of tumor cells. However,\nthis requires estimating patient-specific parameters of the model from clinical\ndata, which is a challenging inverse problem due to limited temporal data and\nthe limited time between imaging and diagnosis. This work proposes a method\nthat uses Physics-Informed Neural Networks (PINNs) to estimate patient-specific\nparameters of a reaction-diffusion PDE model of GBM growth from a single 3D\nstructural MRI snapshot. PINNs embed both the data and the PDE into a loss\nfunction, thus integrating theory and data. Key innovations include the\nidentification and estimation of characteristic non-dimensional parameters, a\npre-training step that utilizes the non-dimensional parameters and a\nfine-tuning step to determine the patient specific parameters. Additionally,\nthe diffuse domain method is employed to handle the complex brain geometry\nwithin the PINN framework. Our method is validated both on synthetic and\npatient datasets, and shows promise for real-time parametric inference in the\nclinical setting for personalized GBM treatment.",
            "author": [
                "Ray Zirui Zhang",
                "Ivan Ezhov",
                "Michal Balcerak",
                "Andy Zhu",
                "Benedikt Wiestler",
                "Bjoern Menze",
                "John Lowengrub"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16536v1",
                "http://arxiv.org/pdf/2311.16536v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "eess.IV",
                "q-bio.QM",
                "92-08, 92C50, 35Q92",
                "J.3; J.2; I.2.6"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.03733v1",
            "title": "Methods to Estimate Large Language Model Confidence",
            "updated": "2023-11-28T05:44:06Z",
            "published": "2023-11-28T05:44:06Z",
            "summary": "Large Language Models have difficulty communicating uncertainty, which is a\nsignificant obstacle to applying LLMs to complex medical tasks. This study\nevaluates methods to measure LLM confidence when suggesting a diagnosis for\nchallenging clinical vignettes. GPT4 was asked a series of challenging case\nquestions using Chain of Thought and Self Consistency prompting. Multiple\nmethods were investigated to assess model confidence and evaluated on their\nability to predict the models observed accuracy. The methods evaluated were\nIntrinsic Confidence, SC Agreement Frequency and CoT Response Length. SC\nAgreement Frequency correlated with observed accuracy, yielding a higher Area\nunder the Receiver Operating Characteristic Curve compared to Intrinsic\nConfidence and CoT Length analysis. SC agreement is the most useful proxy for\nmodel confidence, especially for medical diagnosis. Model Intrinsic Confidence\nand CoT Response Length exhibit a weaker ability to differentiate between\ncorrect and incorrect answers, preventing them from being reliable and\ninterpretable markers for model confidence. We conclude GPT4 has a limited\nability to assess its own diagnostic accuracy. SC Agreement Frequency is the\nmost useful method to measure GPT4 confidence.",
            "author": [
                "Maia Kotelanski",
                "Robert Gallo",
                "Ashwin Nayak",
                "Thomas Savage"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03733v1",
                "http://arxiv.org/pdf/2312.03733v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16534v1",
            "title": "Graph Prompt Learning: A Comprehensive Survey and Beyond",
            "updated": "2023-11-28T05:36:59Z",
            "published": "2023-11-28T05:36:59Z",
            "summary": "Artificial General Intelligence (AGI) has revolutionized numerous fields, yet\nits integration with graph data, a cornerstone in our interconnected world,\nremains nascent. This paper presents a pioneering survey on the emerging domain\nof graph prompts in AGI, addressing key challenges and opportunities in\nharnessing graph data for AGI applications. Despite substantial advancements in\nAGI across natural language processing and computer vision, the application to\ngraph data is relatively underexplored. This survey critically evaluates the\ncurrent landscape of AGI in handling graph data, highlighting the distinct\nchallenges in cross-modality, cross-domain, and cross-task applications\nspecific to graphs. Our work is the first to propose a unified framework for\nunderstanding graph prompt learning, offering clarity on prompt tokens, token\nstructures, and insertion patterns in the graph domain. We delve into the\nintrinsic properties of graph prompts, exploring their flexibility,\nexpressiveness, and interplay with existing graph models. A comprehensive\ntaxonomy categorizes over 100 works in this field, aligning them with\npre-training tasks across node-level, edge-level, and graph-level objectives.\nAdditionally, we present, ProG, a Python library, and an accompanying website,\nto support and advance research in graph prompting. The survey culminates in a\ndiscussion of current challenges and future directions, offering a roadmap for\nresearch in graph prompting within AGI. Through this comprehensive analysis, we\naim to catalyze further exploration and practical applications of AGI in graph\ndata, underlining its potential to reshape AGI fields and beyond. ProG and the\nwebsite can be accessed by\n\\url{https://github.com/WxxShirley/Awesome-Graph-Prompt}, and\n\\url{https://github.com/sheldonresearch/ProG}, respectively.",
            "author": [
                "Xiangguo Sun",
                "Jiawen Zhang",
                "Xixi Wu",
                "Hong Cheng",
                "Yun Xiong",
                "Jia Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16534v1",
                "http://arxiv.org/pdf/2311.16534v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16531v1",
            "title": "Channel Modeling for Terahertz Communications in Rain",
            "updated": "2023-11-28T05:30:10Z",
            "published": "2023-11-28T05:30:10Z",
            "summary": "Terahertz (THz) communication channels, integral to outdoor applications, are\ncritically influenced by natural factors like rainfall. Our research focused on\nthe nuanced effects of rain on these channels, employing an advanced rainfall\nemulation system. By analyzing key parameters such as rain rate, altitude based\nvariations in rainfall, and diverse raindrop sizes, we identified the paramount\nsignificance of the number of raindrops in the THz channel, particularly in\nscenarios with constant rain rates but varying drop sizes. Central to our\nfindings is a novel model grounded in Mie scattering theory, which adeptly\nincorporates the variability of raindrop size distributions at different\naltitudes. This model has displayed strong congruence with our experimental\nresults. In essence, our study underscores the inadequacy of solely depending\non a fixed ground-based rain rate and emphasizes the imperative of calibrating\ndistribution metrics to cater to specific environmental and operational\ncontexts.",
            "author": [
                "Peian Li",
                "Wenbo Liu",
                "Jiacheng Liu",
                "Da Li",
                "Guohao Liu",
                "Yuanshuai Lei",
                "Jiabiao Zhao",
                "Xiaopeng Wang",
                "Houjun Sun",
                "Jianjun Ma",
                "John F. Federici"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16531v1",
                "http://arxiv.org/pdf/2311.16531v1"
            ],
            "primary_category": "physics.app-ph",
            "category": [
                "physics.app-ph",
                "cs.SY",
                "eess.SY",
                "physics.ao-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17091v1",
            "title": "Beyond Sole Strength: Customized Ensembles for Generalized\n  Vision-Language Models",
            "updated": "2023-11-28T05:17:25Z",
            "published": "2023-11-28T05:17:25Z",
            "summary": "Fine-tuning pre-trained vision-language models (VLMs), e.g., CLIP, for the\nopen-world generalization has gained increasing popularity due to its practical\nvalue. However, performance advancements are limited when relying solely on\nintricate algorithmic designs for a single model, even one exhibiting strong\nperformance, e.g., CLIP-ViT-B/16. This paper, for the first time, explores the\ncollaborative potential of leveraging much weaker VLMs to enhance the\ngeneralization of a robust single model. The affirmative findings motivate us\nto address the generalization problem from a novel perspective, i.e., ensemble\nof pre-trained VLMs. We introduce three customized ensemble strategies, each\ntailored to one specific scenario. Firstly, we introduce the zero-shot\nensemble, automatically adjusting the logits of different models based on their\nconfidence when only pre-trained VLMs are available. Furthermore, for scenarios\nwith extra few-shot samples, we propose the training-free and tuning ensemble,\noffering flexibility based on the availability of computing resources. The\nproposed ensemble strategies are evaluated on zero-shot, base-to-new, and\ncross-dataset generalization, achieving new state-of-the-art performance.\nNotably, this work represents an initial stride toward enhancing the\ngeneralization performance of VLMs via ensemble. The code is available at\nhttps://github.com/zhiheLu/Ensemble_VLM.git.",
            "author": [
                "Zhihe Lu",
                "Jiawang Bai",
                "Xin Li",
                "Zeyu Xiao",
                "Xinchao Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17091v1",
                "http://arxiv.org/pdf/2311.17091v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16525v1",
            "title": "On the effectiveness of the early introduction of modern physics in\n  school curriculum: the case of the structure of atom versus wave-particle\n  duality",
            "updated": "2023-11-28T05:10:21Z",
            "published": "2023-11-28T05:10:21Z",
            "summary": "The dual nature of matter and radiation and the concept of the structure of\nan atom share a number of key conceptual elements from quantum mechanics.\nDespite the similarities, we find that the concept of the structure of an atom\nis well understood by students, in contrast to the wave-particle duality. The\nstudy analyzes students' comprehension of these two concepts by conducting a\nsemi-structured focus group interview and questionnaire. Through students'\nperformance in the questionnaire and their descriptive responses, we find that\nthe difficulties in their learning and understandings reflect the treatment of\nthe respective topic in the curriculum. The introduction of the structure of an\natom is early and repeated, whereas the dual nature of matter and radiation is\nintroduced late and abruptly. Based on our findings, we propose reforms in the\npresent curriculum that are necessary for an improved way of introducing the\nconcept of modern physics, like wave particle duality, to Indian students.",
            "author": [
                "Somya Swarnkar",
                "Rittick Roy",
                "Tejinder Kaur",
                "David Blair"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16525v1",
                "http://arxiv.org/pdf/2311.16525v1"
            ],
            "primary_category": "physics.ed-ph",
            "category": [
                "physics.ed-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16522v1",
            "title": "Evaluation of dynamic characteristics of power grid based on GNN and\n  application on knowledge graph",
            "updated": "2023-11-28T05:00:27Z",
            "published": "2023-11-28T05:00:27Z",
            "summary": "A novel method for detecting faults in power grids using a graph neural\nnetwork (GNN) has been developed, aimed at enhancing intelligent fault\ndiagnosis in network operation and maintenance. This GNN-based approach\nidentifies faulty nodes within the power grid through a specialized electrical\nfeature extraction model coupled with a knowledge graph. Incorporating temporal\ndata, the method leverages the status of nodes from preceding and subsequent\ntime periods to aid in current fault detection. To validate the effectiveness\nof this GNN in extracting node features, a correlation analysis of the output\nfeatures from each node within the neural network layer was conducted. The\nresults from experiments show that this method can accurately locate fault\nnodes in simulated scenarios with a remarkable 99.53% accuracy. Additionally,\nthe graph neural network's feature modeling allows for a qualitative\nexamination of how faults spread across nodes, providing valuable insights for\nanalyzing fault nodes.",
            "author": [
                "Hao Pei",
                "Si Lin",
                "Chuanfu Li",
                "Che Wang",
                "Haoming Chen",
                "Sizhe Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16522v1",
                "http://arxiv.org/pdf/2311.16522v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16521v1",
            "title": "Inspo: Writing Stories with a Flock of AIs and Humans",
            "updated": "2023-11-28T05:00:18Z",
            "published": "2023-11-28T05:00:18Z",
            "summary": "Large Language Models (LLMs) have advanced automated writing assistance,\nenabling complex tasks like co-writing novels and poems. However, real-world\nwriting typically requires various support and collaboration across stages and\nscenarios. Existing research mainly examines how writers utilize single text\ngenerators, neglecting this broader context. This paper introduces Inspo, a\nweb-based editor that incorporates various text generators and online crowd\nworkers. Through a three-phase user study, we examine writers' interactions\nwith Inspo for novel writing. Quantitative analyses of writing logs highlight\nchanges in participants' writing progress and the influence of various\ntext-generation models. Complementing this with qualitative insights from\nsemi-structured interviews, we illustrate participants' perceptions of these\nmodels and the crowd. Based on the findings, we provide design recommendations\nfor the next generation of intelligent writing tools and discuss the potential\nsociocultural implications of integrating AI and human input in the writing\nprocess.",
            "author": [
                "Chieh-Yang Huang",
                "Sanjana Gautam",
                "Shannon McClellan Brooks",
                "Ya-Fang Lin",
                "Ting-Hao 'Kenneth' Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16521v1",
                "http://arxiv.org/pdf/2311.16521v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16520v1",
            "title": "Value Approximation for Two-Player General-Sum Differential Games with\n  State Constraints",
            "updated": "2023-11-28T04:58:41Z",
            "published": "2023-11-28T04:58:41Z",
            "summary": "Solving Hamilton-Jacobi-Isaacs (HJI) PDEs enables equilibrial feedback\ncontrol in two-player differential games, yet faces the curse of dimensionality\n(CoD). While physics-informed machine learning has been adopted to address CoD\nin solving PDEs, this method falls short in learning discontinuous solutions\ndue to its sampling nature, leading to poor safety performance of the resulting\ncontrollers in robotics applications where values are discontinuous due to\nstate or other temporal logic constraints. In this study, we explore three\npotential solutions to this problem: (1) a hybrid learning method that uses\nboth equilibrium demonstrations and the HJI PDE, (2) a value-hardening method\nwhere a sequence of HJIs are solved with increasing Lipschitz constant on the\nconstraint violation penalty, and (3) the epigraphical technique that lifts the\nvalue to a higher dimensional auxiliary state space where the value becomes\ncontinuous. Evaluations through 5D and 9D vehicle simulations and 13D drone\nsimulations reveal that the hybrid method outperforms others in terms of\ngeneralization and safety performance.",
            "author": [
                "Lei Zhang",
                "Mukesh Ghimire",
                "Wenlong Zhang",
                "Zhe Xu",
                "Yi Ren"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16520v1",
                "http://arxiv.org/pdf/2311.16520v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.GT",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16509v1",
            "title": "StyleCap: Automatic Speaking-Style Captioning from Speech Based on\n  Speech and Language Self-supervised Learning Models",
            "updated": "2023-11-28T04:49:17Z",
            "published": "2023-11-28T04:49:17Z",
            "summary": "We propose StyleCap, a method to generate natural language descriptions of\nspeaking styles appearing in speech. Although most of conventional techniques\nfor para-/non-linguistic information recognition focus on the category\nclassification or the intensity estimation of pre-defined labels, they cannot\nprovide the reasoning of the recognition result in an interpretable manner. As\na first step towards an end-to-end method for generating speaking-style prompts\nfrom speech, i.e., automatic speaking-style captioning, StyleCap uses paired\ndata of speech and natural language descriptions to train neural networks that\npredict prefix vectors fed into a large language model (LLM)-based text decoder\nfrom a speech representation vector. We explore an appropriate text decoder and\nspeech feature representation suitable for this new task. The experimental\nresults demonstrate that our StyleCap leveraging richer LLMs for the text\ndecoder, speech self-supervised learning (SSL) features, and sentence\nrephrasing augmentation improves the accuracy and diversity of generated\nspeaking-style captions. Samples of speaking-style captions generated by our\nStyleCap are publicly available.",
            "author": [
                "Kazuki Yamauchi",
                "Yusuke Ijima",
                "Yuki Saito"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16509v1",
                "http://arxiv.org/pdf/2311.16509v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17090v1",
            "title": "Dynamic Change of Amplitude for OCT Functional Imaging",
            "updated": "2023-11-28T04:39:03Z",
            "published": "2023-11-28T04:39:03Z",
            "summary": "Optical coherence tomography (OCT) is capable of non-destructively obtaining\ncross-sectional information of samples with micrometer spatial resolution,\nwhich plays an important role in ophthalmology and endovascular medicine.\nMeasuring OCT amplitude can obtain three-dimensional structural information of\nthe sample, such as the layered structure of the retina, but is of limited use\nfor functional information such as tissue specificity, blood flow, and\nmechanical properties. OCT functional imaging techniques based on other optical\nfield properties including phase, polarization state, and wavelength have\nemerged, such as Doppler OCT, optical coherence elastography,\npolarization-sensitive OCT, and visible-light OCT. Among them, functional\nimaging techniques based on dynamic changes of amplitude have significant\nrobustness and complexity advantages, and achieved significant clinical success\nin label-free blood flow imaging. In addition, dynamic light scattering OCT for\n3D blood flow velocity measurement, dynamic OCT with the ability to display\nlabel-free tissue/cell specificity, and OCT thermometry for monitoring the\ntemperature field of thermophysical treatments are the frontiers in OCT\nfunctional imaging. In this paper, the principles and applications of the above\ntechnologies are summarized, the remaining technical challenges are analyzed,\nand the future development is envisioned.",
            "author": [
                "Yang Jianlong",
                "Zhang Haoran",
                "Liu Chang",
                "Gu Chengfu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17090v1",
                "http://arxiv.org/pdf/2311.17090v1"
            ],
            "primary_category": "physics.med-ph",
            "category": [
                "physics.med-ph",
                "eess.IV",
                "physics.optics"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16468v1",
            "title": "AvatarGPT: All-in-One Framework for Motion Understanding, Planning,\n  Generation and Beyond",
            "updated": "2023-11-28T04:10:07Z",
            "published": "2023-11-28T04:10:07Z",
            "summary": "Large Language Models(LLMs) have shown remarkable emergent abilities in\nunifying almost all (if not every) NLP tasks. In the human motion-related\nrealm, however, researchers still develop siloed models for each task. Inspired\nby InstuctGPT, and the generalist concept behind Gato, we introduce AvatarGPT,\nan All-in-One framework for motion understanding, planning, generations as well\nas other tasks such as motion in-between synthesis. AvatarGPT treats each task\nas one type of instruction fine-tuned on the shared LLM. All the tasks are\nseamlessly interconnected with language as the universal interface,\nconstituting a closed-loop within the framework. To achieve this, human motion\nsequences are first encoded as discrete tokens, which serve as the extended\nvocabulary of LLM. Then, an unsupervised pipeline to generate natural language\ndescriptions of human action sequences from in-the-wild videos is developed.\nFinally, all tasks are jointly trained. Extensive experiments show that\nAvatarGPT achieves SOTA on low-level tasks, and promising results on high-level\ntasks, demonstrating the effectiveness of our proposed All-in-One framework.\nMoreover, for the first time, AvatarGPT enables a principled approach by\niterative traversal of the tasks within the closed-loop for unlimited\nlong-motion synthesis.",
            "author": [
                "Zixiang Zhou",
                "Yu Wan",
                "Baoyuan Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16468v1",
                "http://arxiv.org/pdf/2311.16468v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16466v1",
            "title": "Enhancing Human Persuasion With Large Language Models",
            "updated": "2023-11-28T04:07:34Z",
            "published": "2023-11-28T04:07:34Z",
            "summary": "Although large language models (LLMs) are reshaping various aspects of human\nlife, our current understanding of their impacts remains somewhat constrained.\nHere we investigate the impact of LLMs on human communication, in the context\nof consumer complaints in the financial industry. Employing an AI detection\ntool on more than 780K complaints gathered by the Consumer Financial Protection\nBureau (CFPB), we find evidence of LLM usage in the writing of complaints -\nshortly after the release of ChatGPT. Our analyses reveal that LLM usage is\npositively correlated with the likelihood of obtaining desirable outcomes\n(i.e., offer of relief from financial firms) and suggest that this positive\ncorrelation may be partly due to the linguistic features improved by LLMs. We\ntest this conjecture with a preregistered experiment, which reveals results\nconsistent with those from observational studies: Consumer complaints written\nwith ChatGPT for improved linguistic qualities were more likely to receive\nhypothetical relief offers than the original consumer complaints, demonstrating\nthe LLM's ability to enhance message persuasiveness in human communication.\nBeing some of the earliest empirical evidence on LLM usage for enhancing\npersuasion, our results highlight the transformative potential of LLMs in human\ncommunication.",
            "author": [
                "Minkyu Shin",
                "Jin Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16466v1",
                "http://arxiv.org/pdf/2311.16466v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16465v1",
            "title": "TextDiffuser-2: Unleashing the Power of Language Models for Text\n  Rendering",
            "updated": "2023-11-28T04:02:40Z",
            "published": "2023-11-28T04:02:40Z",
            "summary": "The diffusion model has been proven a powerful generative model in recent\nyears, yet remains a challenge in generating visual text. Several methods\nalleviated this issue by incorporating explicit text position and content as\nguidance on where and what text to render. However, these methods still suffer\nfrom several drawbacks, such as limited flexibility and automation, constrained\ncapability of layout prediction, and restricted style diversity. In this paper,\nwe present TextDiffuser-2, aiming to unleash the power of language models for\ntext rendering. Firstly, we fine-tune a large language model for layout\nplanning. The large language model is capable of automatically generating\nkeywords for text rendering and also supports layout modification through\nchatting. Secondly, we utilize the language model within the diffusion model to\nencode the position and texts at the line level. Unlike previous methods that\nemployed tight character-level guidance, this approach generates more diverse\ntext images. We conduct extensive experiments and incorporate user studies\ninvolving human participants as well as GPT-4V, validating TextDiffuser-2's\ncapacity to achieve a more rational text layout and generation with enhanced\ndiversity. The code and model will be available at\n\\url{https://aka.ms/textdiffuser-2}.",
            "author": [
                "Jingye Chen",
                "Yupan Huang",
                "Tengchao Lv",
                "Lei Cui",
                "Qifeng Chen",
                "Furu Wei"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16465v1",
                "http://arxiv.org/pdf/2311.16465v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16464v1",
            "title": "Bridging the Gap: A Unified Video Comprehension Framework for Moment\n  Retrieval and Highlight Detection",
            "updated": "2023-11-28T03:55:23Z",
            "published": "2023-11-28T03:55:23Z",
            "summary": "Video Moment Retrieval (MR) and Highlight Detection (HD) have attracted\nsignificant attention due to the growing demand for video analysis. Recent\napproaches treat MR and HD as similar video grounding problems and address them\ntogether with transformer-based architecture. However, we observe that the\nemphasis of MR and HD differs, with one necessitating the perception of local\nrelationships and the other prioritizing the understanding of global contexts.\nConsequently, the lack of task-specific design will inevitably lead to\nlimitations in associating the intrinsic specialty of two tasks. To tackle the\nissue, we propose a Unified Video COMprehension framework (UVCOM) to bridge the\ngap and jointly solve MR and HD effectively. By performing progressive\nintegration on intra and inter-modality across multi-granularity, UVCOM\nachieves the comprehensive understanding in processing a video. Moreover, we\npresent multi-aspect contrastive learning to consolidate the local relation\nmodeling and global knowledge accumulation via well aligned multi-modal space.\nExtensive experiments on QVHighlights, Charades-STA, TACoS , YouTube Highlights\nand TVSum datasets demonstrate the effectiveness and rationality of UVCOM which\noutperforms the state-of-the-art methods by a remarkable margin.",
            "author": [
                "Yicheng Xiao",
                "Zhuoyan Luo",
                "Yong Liu",
                "Yue Ma",
                "Hengwei Bian",
                "Yatai Ji",
                "Yujiu Yang",
                "Xiu Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16464v1",
                "http://arxiv.org/pdf/2311.16464v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16462v1",
            "title": "Viewport Prediction for Volumetric Video Streaming by Exploring Video\n  Saliency and Trajectory Information",
            "updated": "2023-11-28T03:45:29Z",
            "published": "2023-11-28T03:45:29Z",
            "summary": "Volumetric video, also known as hologram video, is a novel medium that\nportrays natural content in Virtual Reality (VR), Augmented Reality (AR), and\nMixed Reality (MR). It is expected to be the next-gen video technology and a\nprevalent use case for 5G and beyond wireless communication. Considering that\neach user typically only watches a section of the volumetric video, known as\nthe viewport, it is essential to have precise viewport prediction for optimal\nperformance. However, research on this topic is still in its infancy. In the\nend, this paper presents and proposes a novel approach, named Saliency and\nTrajectory Viewport Prediction (STVP), which aims to improve the precision of\nviewport prediction in volumetric video streaming. The STVP extensively\nutilizes video saliency information and viewport trajectory. To our knowledge,\nthis is the first comprehensive study of viewport prediction in volumetric\nvideo streaming. In particular, we introduce a novel sampling method, Uniform\nRandom Sampling (URS), to reduce computational complexity while still\npreserving video features in an efficient manner. Then we present a saliency\ndetection technique that incorporates both spatial and temporal information for\ndetecting static, dynamic geometric, and color salient regions. Finally, we\nintelligently fuse saliency and trajectory information to achieve more accurate\nviewport prediction. We conduct extensive simulations to evaluate the\neffectiveness of our proposed viewport prediction methods using\nstate-of-the-art volumetric video sequences. The experimental results show the\nsuperiority of the proposed method over existing schemes. The dataset and\nsource code will be publicly accessible after acceptance.",
            "author": [
                "Jie Li",
                "Zhixin Li",
                "Zhi Liu",
                "Pengyuan Zhou",
                "Richang Hong",
                "Qiyue Li",
                "Han Hu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16462v1",
                "http://arxiv.org/pdf/2311.16462v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16461v1",
            "title": "Can the solar p-modes contribute to the high-frequency transverse\n  oscillations of spicules?",
            "updated": "2023-11-28T03:43:08Z",
            "published": "2023-11-28T03:43:08Z",
            "summary": "Lateral motions of spicules serve as vital indicators of transverse waves in\nthe solar atmosphere, and their study is crucial for understanding the wave\nheating process of the corona. Recent observations have focused on\n\"high-frequency\" transverse waves (periods < 100 s), which have the potential\nto transport sufficient energy for coronal heating. These high-frequency\nspicule oscillations are distinct from granular motions, which have much longer\ntime scales of 5-10 min. Instead, it is proposed that they are generated\nthrough the mode conversion from high-frequency longitudinal waves that arise\nfrom a shock steepening process. Therefore, these oscillations may not solely\nbe produced by the horizontal buffeting motions of granulation but also by the\nleakage of p-mode oscillations. To investigate the contribution of p-modes, our\nstudy employs a two-dimensional magneto-convection simulation spanning from the\nupper convection zone to the corona. During the course of the simulation, we\nintroduce a p-mode-like driver at the bottom boundary. We reveal a notable\nincrease in the mean velocity amplitude of the transverse oscillations in\nspicules, ranging from 10% to 30%, and attribute this to the energy transfer\nfrom longitudinal to transverse waves. This effect results in an enhancement of\nthe estimated energy flux by 30-80%.",
            "author": [
                "Hidetaka Kuniyoshi",
                "Munehito Shoda",
                "Richard J. Morton",
                "Takaaki Yokoyama"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16461v1",
                "http://arxiv.org/pdf/2311.16461v1"
            ],
            "primary_category": "astro-ph.SR",
            "category": [
                "astro-ph.SR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16457v1",
            "title": "Fixation dynamics on multilayer networks",
            "updated": "2023-11-28T03:31:56Z",
            "published": "2023-11-28T03:31:56Z",
            "summary": "Network structure has a large impact on constant-selection evolutionary\ndynamics, with which multiple types of different fitnesses (i.e., strengths)\ncompete on the network. Here we study constant-selection dynamics on two-layer\nnetworks in which the fitness of a node in one layer affects that in the other\nlayer, under birth-death processes and uniform initialization, which are\ncommonly assumed. We show mathematically and numerically that two-layer\nnetworks are suppressors of selection, which suppresses the effects of the\ndifferent fitness values between the different types on final outcomes of the\nevolutionary dynamics (called fixation probability), relative to the\nconstituent one-layer networks. In fact, many two-layer networks are\nsuppressors of selection relative to the most basic baseline, the Moran\nprocess. This result is in stark contrast with the results for conventional\none-layer networks for which most networks are amplifiers of selection.",
            "author": [
                "Ruodan Liu",
                "Naoki Masuda"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16457v1",
                "http://arxiv.org/pdf/2311.16457v1"
            ],
            "primary_category": "physics.soc-ph",
            "category": [
                "physics.soc-ph",
                "cs.SI",
                "60J20, 91D30, 92D15, 92D25"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16456v1",
            "title": "Spiking Neural Networks with Dynamic Time Steps for Vision Transformers",
            "updated": "2023-11-28T03:30:43Z",
            "published": "2023-11-28T03:30:43Z",
            "summary": "Spiking Neural Networks (SNNs) have emerged as a popular spatio-temporal\ncomputing paradigm for complex vision tasks. Recently proposed SNN training\nalgorithms have significantly reduced the number of time steps (down to 1) for\nimproved latency and energy efficiency, however, they target only convolutional\nneural networks (CNN). These algorithms, when applied on the recently\nspotlighted vision transformers (ViT), either require a large number of time\nsteps or fail to converge. Based on analysis of the histograms of the ANN and\nSNN activation maps, we hypothesize that each ViT block has a different\nsensitivity to the number of time steps. We propose a novel training framework\nthat dynamically allocates the number of time steps to each ViT module\ndepending on a trainable score assigned to each timestep. In particular, we\ngenerate a scalar binary time step mask that filters spikes emitted by each\nneuron in a leaky-integrate-and-fire (LIF) layer. The resulting SNNs have high\nactivation sparsity and require only accumulate operations (AC), except for the\ninput embedding layer, in contrast to expensive multiply-and-accumulates (MAC)\nneeded in traditional ViTs. This yields significant improvements in energy\nefficiency. We evaluate our training framework and resulting SNNs on image\nrecognition tasks including CIFAR10, CIFAR100, and ImageNet with different ViT\narchitectures. We obtain a test accuracy of 95.97% with 4.97 time steps with\ndirect encoding on CIFAR10.",
            "author": [
                "Gourav Datta",
                "Zeyu Liu",
                "Anni Li",
                "Peter A. Beerel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16456v1",
                "http://arxiv.org/pdf/2311.16456v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.03732v1",
            "title": "A Rank Stabilization Scaling Factor for Fine-Tuning with LoRA",
            "updated": "2023-11-28T03:23:20Z",
            "published": "2023-11-28T03:23:20Z",
            "summary": "As large language models (LLMs) have become increasingly compute and memory\nintensive, parameter-efficient fine-tuning (PEFT) methods are now a common\nstrategy to fine-tune LLMs. A popular PEFT method is Low-Rank Adapters (LoRA),\nwhich adds trainable low-rank \"adapters\" to selected layers. Each adapter\nconsists of a low-rank matrix product, multiplicatively scaled by a\nrank-dependent factor. This scaling factor, which divides adapters by a factor\nof the rank, results in slowed learning and stunted performance for LoRA with\nhigher-rank adapters. Consequently, the use of LoRA in practice has generally\nbeen limited to very low ranks. In this work, we study the impact of the\nscaling factor on the learning process and prove that LoRA adapters should be\ndivided by a factor of the square root of the rank. Modifying LoRA with the\nappropriate scaling factor, which we call the rank-stabilized LoRA (rsLoRA)\nmethod, easily provides for a fine-tuning compute/performance trade-off, where\nlarger ranks can be used to trade off increased computational resources during\ntraining for better fine-tuning performance, with no change in inference\ncomputing cost.",
            "author": [
                "Damjan Kalajdzievski"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03732v1",
                "http://arxiv.org/pdf/2312.03732v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG",
                "I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16452v1",
            "title": "Can Generalist Foundation Models Outcompete Special-Purpose Tuning? Case\n  Study in Medicine",
            "updated": "2023-11-28T03:16:12Z",
            "published": "2023-11-28T03:16:12Z",
            "summary": "Generalist foundation models such as GPT-4 have displayed surprising\ncapabilities in a wide variety of domains and tasks. Yet, there is a prevalent\nassumption that they cannot match specialist capabilities of fine-tuned models.\nFor example, most explorations to date on medical competency benchmarks have\nleveraged domain-specific training, as exemplified by efforts on BioGPT and\nMed-PaLM. We build on a prior study of GPT-4's capabilities on medical\nchallenge benchmarks in the absence of special training. Rather than using\nsimple prompting to highlight the model's out-of-the-box capabilities, we\nperform a systematic exploration of prompt engineering. We find that prompting\ninnovation can unlock deeper specialist capabilities and show that GPT-4 easily\ntops prior leading results for medical benchmarks. The prompting methods we\nexplore are general purpose, and make no specific use of domain expertise,\nremoving the need for expert-curated content. Our experimental design carefully\ncontrols for overfitting during the prompt engineering process. We introduce\nMedprompt, based on a composition of several prompting strategies. With\nMedprompt, GPT-4 achieves state-of-the-art results on all nine of the benchmark\ndatasets in the MultiMedQA suite. The method outperforms leading specialist\nmodels such as Med-PaLM 2 by a significant margin with an order of magnitude\nfewer calls to the model. Steering GPT-4 with Medprompt achieves a 27%\nreduction in error rate on the MedQA dataset over the best methods to date\nachieved with specialist models and surpasses a score of 90% for the first\ntime. Beyond medical problems, we show the power of Medprompt to generalize to\nother domains and provide evidence for the broad applicability of the approach\nvia studies of the strategy on exams in electrical engineering, machine\nlearning, philosophy, accounting, law, nursing, and clinical psychology.",
            "author": [
                "Harsha Nori",
                "Yin Tat Lee",
                "Sheng Zhang",
                "Dean Carignan",
                "Richard Edgar",
                "Nicolo Fusi",
                "Nicholas King",
                "Jonathan Larson",
                "Yuanzhi Li",
                "Weishung Liu",
                "Renqian Luo",
                "Scott Mayer McKinney",
                "Robert Osazuwa Ness",
                "Hoifung Poon",
                "Tao Qin",
                "Naoto Usuyama",
                "Chris White",
                "Eric Horvitz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16452v1",
                "http://arxiv.org/pdf/2311.16452v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.00812v1",
            "title": "Empowering Autonomous Driving with Large Language Models: A Safety\n  Perspective",
            "updated": "2023-11-28T03:13:09Z",
            "published": "2023-11-28T03:13:09Z",
            "summary": "Autonomous Driving (AD) faces crucial hurdles for commercial launch, notably\nin the form of diminished public trust and safety concerns from long-tail\nunforeseen driving scenarios. This predicament is due to the limitation of deep\nneural networks in AD software, which struggle with interpretability and\nexhibit poor generalization capabilities in out-of-distribution and uncertain\nscenarios. To this end, this paper advocates for the integration of Large\nLanguage Models (LLMs) into the AD system, leveraging their robust common-sense\nknowledge, reasoning abilities, and human-interaction capabilities. The\nproposed approach deploys the LLM as an intelligent decision-maker in planning,\nincorporating safety verifiers for contextual safety learning to enhance\noverall AD performance and safety. We present results from two case studies\nthat affirm the efficacy of our approach. We further discuss the potential\nintegration of LLM for other AD software components including perception,\nprediction, and simulation. Despite the observed challenges in the case\nstudies, the integration of LLMs is promising and beneficial for reinforcing\nboth safety and performance in AD.",
            "author": [
                "Yixuan Wang",
                "Ruochen Jiao",
                "Chengtian Lang",
                "Sinong Simon Zhan",
                "Chao Huang",
                "Zhaoran Wang",
                "Zhuoran Yang",
                "Qi Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00812v1",
                "http://arxiv.org/pdf/2312.00812v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16449v1",
            "title": "Revealing novel aspects of light-matter coupling in terahertz\n  two-dimensional coherent spectroscopy: the case of the amplitude mode in\n  superconductors",
            "updated": "2023-11-28T03:06:31Z",
            "published": "2023-11-28T03:06:31Z",
            "summary": "Recently developed terahertz (THz) two-dimensional coherent spectroscopy\n(2DCS) is a powerful technique to obtain materials information in a fashion\nqualitatively different from other spectroscopies. Here, we utilized THz 2DCS\nto investigate the THz nonlinear response of conventional superconductor NbN.\nUsing broad-band THz pulses as light sources, we observed a third-order\nnonlinear signal whose spectral components are peaked at twice the\nsuperconducting gap energy $2\\Delta$. With narrow-band THz pulses, a THz\nnonlinear signal was identified at the driving frequency $\\Omega$ and exhibited\na resonant enhancement at temperature when $\\Omega = 2\\Delta$. General\ntheoretical considerations show that such a resonance can only arise from a\ndisorder-activated paramagnetic coupling between the light and the electronic\ncurrent. This proves that the nonlinear THz response can access processes\ndistinct from the diamagnetic Raman-like density fluctuations, which are\nbelieved to dominate the nonlinear response at optical frequencies in metals.\nOur numerical simulations reveal that even for a small amount of disorder, the\n$\\Omega=2\\Delta$ resonance is dominated by the superconducting amplitude mode\nover the entire investigated disorder range. This is in contrast to other\nresonances, whose amplitude-mode contribution depends on disorder. Our findings\ndemonstrate the unique ability of THz 2DCS to explore collective excitations\ninaccessible in other spectroscopies.",
            "author": [
                "Kota Katsumi",
                "Jacopo Fiore",
                "Mattia Udina",
                "Ralph Romero III",
                "David Barbalas",
                "John Jesudasan",
                "Pratap Raychaudhuri",
                "Goetz Seibold",
                "Lara Benfatto",
                "N. P. Armitage"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16449v1",
                "http://arxiv.org/pdf/2311.16449v1"
            ],
            "primary_category": "cond-mat.supr-con",
            "category": [
                "cond-mat.supr-con"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16447v2",
            "title": "TopoSemiSeg: Enforcing Topological Consistency for Semi-Supervised\n  Segmentation of Histopathology Images",
            "updated": "2023-12-06T20:53:15Z",
            "published": "2023-11-28T03:04:35Z",
            "summary": "In computational pathology, segmenting densely distributed objects like\nglands and nuclei is crucial for downstream analysis. To alleviate the burden\nof obtaining pixel-wise annotations, semi-supervised learning methods learn\nfrom large amounts of unlabeled data. Nevertheless, existing semi-supervised\nmethods overlook the topological information hidden in the unlabeled images and\nare thus prone to topological errors, e.g., missing or incorrectly\nmerged/separated glands or nuclei. To address this issue, we propose\nTopoSemiSeg, the first semi-supervised method that learns the topological\nrepresentation from unlabeled data. In particular, we propose a topology-aware\nteacher-student approach in which the teacher and student networks learn shared\ntopological representations. To achieve this, we introduce topological\nconsistency loss, which contains signal consistency and noise removal losses to\nensure the learned representation is robust and focuses on true topological\nsignals. Extensive experiments on public pathology image datasets show the\nsuperiority of our method, especially on topology-wise evaluation metrics. Code\nis available at https://github.com/Melon-Xu/TopoSemiSeg.",
            "author": [
                "Meilong Xu",
                "Xiaoling Hu",
                "Saumya Gupta",
                "Shahira Abousamra",
                "Chao Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16447v2",
                "http://arxiv.org/pdf/2311.16447v2"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16445v1",
            "title": "CLAP: Contrastive Learning with Augmented Prompts for Robustness on\n  Pretrained Vision-Language Models",
            "updated": "2023-11-28T03:00:59Z",
            "published": "2023-11-28T03:00:59Z",
            "summary": "Contrastive vision-language models, e.g., CLIP, have garnered substantial\nattention for their exceptional generalization capabilities. However, their\nrobustness to perturbations has ignited concerns. Existing strategies typically\nreinforce their resilience against adversarial examples by enabling the image\nencoder to \"see\" these perturbed examples, often necessitating a complete\nretraining of the image encoder on both natural and adversarial samples. In\nthis study, we propose a new method to enhance robustness solely through text\naugmentation, eliminating the need for retraining the image encoder on\nadversarial examples. Our motivation arises from the realization that text and\nimage data inherently occupy a shared latent space, comprising latent content\nvariables and style variables. This insight suggests the feasibility of\nlearning to disentangle these latent content variables using text data\nexclusively. To accomplish this, we introduce an effective text augmentation\nmethod that focuses on modifying the style while preserving the content in the\ntext data. By changing the style part of the text data, we empower the text\nencoder to emphasize latent content variables, ultimately enhancing the\nrobustness of vision-language models. Our experiments across various datasets\ndemonstrate substantial improvements in the robustness of the pre-trained CLIP\nmodel.",
            "author": [
                "Yichao Cai",
                "Yuhang Liu",
                "Zhen Zhang",
                "Javen Qinfeng Shi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16445v1",
                "http://arxiv.org/pdf/2311.16445v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16444v2",
            "title": "Exo2EgoDVC: Dense Video Captioning of Egocentric Procedural Activities\n  Using Web Instructional Videos",
            "updated": "2023-11-29T06:01:34Z",
            "published": "2023-11-28T02:51:13Z",
            "summary": "We propose a novel benchmark for cross-view knowledge transfer of dense video\ncaptioning, adapting models from web instructional videos with exocentric views\nto an egocentric view. While dense video captioning (predicting time segments\nand their captions) is primarily studied with exocentric videos (e.g.,\nYouCook2), benchmarks with egocentric videos are restricted due to data\nscarcity. To overcome the limited video availability, transferring knowledge\nfrom abundant exocentric web videos is demanded as a practical approach.\nHowever, learning the correspondence between exocentric and egocentric views is\ndifficult due to their dynamic view changes. The web videos contain mixed views\nfocusing on either human body actions or close-up hand-object interactions,\nwhile the egocentric view is constantly shifting as the camera wearer moves.\nThis necessitates the in-depth study of cross-view transfer under complex view\nchanges. In this work, we first create a real-life egocentric dataset (EgoYC2)\nwhose captions are shared with YouCook2, enabling transfer learning between\nthese datasets assuming their ground-truth is accessible. To bridge the view\ngaps, we propose a view-invariant learning method using adversarial training in\nboth the pre-training and fine-tuning stages. While the pre-training is\ndesigned to learn invariant features against the mixed views in the web videos,\nthe view-invariant fine-tuning further mitigates the view gaps between both\ndatasets. We validate our proposed method by studying how effectively it\novercomes the view change problem and efficiently transfers the knowledge to\nthe egocentric domain. Our benchmark pushes the study of the cross-view\ntransfer into a new task domain of dense video captioning and will envision\nmethodologies to describe egocentric videos in natural language.",
            "author": [
                "Takehiko Ohkawa",
                "Takuma Yagi",
                "Taichi Nishimura",
                "Ryosuke Furuta",
                "Atsushi Hashimoto",
                "Yoshitaka Ushiku",
                "Yoichi Sato"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16444v2",
                "http://arxiv.org/pdf/2311.16444v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16442v1",
            "title": "Enabling Fast 2-bit LLM on GPUs: Memory Alignment, Sparse Outlier, and\n  Asynchronous Dequantization",
            "updated": "2023-11-28T02:44:59Z",
            "published": "2023-11-28T02:44:59Z",
            "summary": "Large language models (LLMs) have demonstrated impressive abilities in\nvarious domains while the inference cost is expensive. The state-of-the-art\nmethods use 2-bit quantization for mainstream LLMs. However, challenges still\nexist: (1) Nonnegligible accuracy loss for 2-bit quantization. Weights are\nquantized by groups, while the ranges of weights are large in some groups,\nresulting in large quantization errors and nonnegligible accuracy loss (e.g.\n>3% for Llama2-7b with 2-bit quantization in GPTQ and Greenbit). (2) Limited\naccuracy improvement by adding 4-bit weights. Increasing 10% extra average bit\nmore 4-bit weights only leads to <0.5% accuracy improvement on a quantized\nLlama2-7b. (3) Time-consuming dequantization operations on GPUs. The\ndequantization operations lead to >50% execution time, hindering the potential\nof reducing LLM inference cost. To tackle these challenges, we propose the\nfollowing techniques: (1) We only quantize a small fraction of groups with the\nlarger range using 4-bit with memory alignment consideration on GPUs. (2) We\npoint out that the distribution of the sparse outliers with larger weights is\ndifferent in 2-bit and 4-bit groups, and only a small fraction of outliers\nrequire 16-bit quantization. Such design leads to >0.5% accuracy improvement\nwith <3% average increased bit for Llama2-7b. (3) We design the asynchronous\ndequantization on GPUs, leading to up to 3.92X speedup. We conduct extensive\nexperiments on different model families and model sizes. We achieve 2.85-bit\nfor each weight and the end-to-end speedup for Llama2-7b is 1.74X over the\noriginal model, and we reduce both runtime cost and hardware cost by up to\n2.70X and 2.81X with less GPU requirements.",
            "author": [
                "Jinhao Li",
                "Shiyao Li",
                "Jiaming Xu",
                "Shan Huang",
                "Yaoxiu Lian",
                "Jun Liu",
                "Yu Wang",
                "Guohao Dai"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16442v1",
                "http://arxiv.org/pdf/2311.16442v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16441v1",
            "title": "ControlRec: Bridging the Semantic Gap between Language Model and\n  Personalized Recommendation",
            "updated": "2023-11-28T02:43:02Z",
            "published": "2023-11-28T02:43:02Z",
            "summary": "The successful integration of large language models (LLMs) into\nrecommendation systems has proven to be a major breakthrough in recent studies,\npaving the way for more generic and transferable recommendations. However, LLMs\nstruggle to effectively utilize user and item IDs, which are crucial\nidentifiers for successful recommendations. This is mainly due to their\ndistinct representation in a semantic space that is different from the natural\nlanguage (NL) typically used to train LLMs. To tackle such issue, we introduce\nControlRec, an innovative Contrastive prompt learning framework for\nRecommendation systems. ControlRec treats user IDs and NL as heterogeneous\nfeatures and encodes them individually. To promote greater alignment and\nintegration between them in the semantic space, we have devised two auxiliary\ncontrastive objectives: (1) Heterogeneous Feature Matching (HFM) aligning item\ndescription with the corresponding ID or user's next preferred ID based on\ntheir interaction sequence, and (2) Instruction Contrastive Learning (ICL)\neffectively merging these two crucial data sources by contrasting probability\ndistributions of output sequences generated by diverse tasks. Experimental\nresults on four public real-world datasets demonstrate the effectiveness of the\nproposed method on improving model performance.",
            "author": [
                "Junyan Qiu",
                "Haitao Wang",
                "Zhaolin Hong",
                "Yiping Yang",
                "Qiang Liu",
                "Xingxing Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16441v1",
                "http://arxiv.org/pdf/2311.16441v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.03731v1",
            "title": "MultiGPrompt for Multi-Task Pre-Training and Prompting on Graphs",
            "updated": "2023-11-28T02:36:53Z",
            "published": "2023-11-28T02:36:53Z",
            "summary": "Graphs can inherently model interconnected objects on the Web, thereby\nfacilitating a series of Web applications, such as web analyzing and content\nrecommendation. Recently, Graph Neural Networks (GNNs) have emerged as a\nmainstream technique for graph representation learning. However, their efficacy\nwithin an end-to-end supervised framework is significantly tied to the\navailabilityof task-specific labels. To mitigate labeling costs and enhance\nrobustness in few-shot settings, pre-training on self-supervised tasks has\nemerged as a promising method, while prompting has been proposed to further\nnarrow the objective gap between pretext and downstream tasks. Although there\nhas been some initial exploration of prompt-based learning on graphs, they\nprimarily leverage a single pretext task, resulting in a limited subset of\ngeneral knowledge that could be learned from the pre-training data. Hence, in\nthis paper, we propose MultiGPrompt, a novel multi-task pre-training and\nprompting framework to exploit multiple pretext tasks for more comprehensive\npre-trained knowledge. First, in pre-training, we design a set of pretext\ntokens to synergize multiple pretext tasks. Second, we propose a dual-prompt\nmechanism consisting of composed and open prompts to leverage task-specific and\nglobal pre-training knowledge, to guide downstream tasks in few-shot settings.\nFinally, we conduct extensive experiments on six public datasets to evaluate\nand analyze MultiGPrompt.",
            "author": [
                "Xingtong Yu",
                "Chang Zhou",
                "Yuan Fang",
                "Xinming Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03731v1",
                "http://arxiv.org/pdf/2312.03731v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17086v1",
            "title": "PEA-Diffusion: Parameter-Efficient Adapter with Knowledge Distillation\n  in non-English Text-to-Image Generation",
            "updated": "2023-11-28T02:31:52Z",
            "published": "2023-11-28T02:31:52Z",
            "summary": "Text-to-image diffusion models are well-known for their ability to generate\nrealistic images based on textual prompts. However, the existing works have\npredominantly focused on English, lacking support for non-English text-to-image\nmodels. The most commonly used translation methods cannot solve the generation\nproblem related to language culture, while training from scratch on a specific\nlanguage dataset is prohibitively expensive. In this paper, we are inspired to\npropose a simple plug-and-play language transfer method based on knowledge\ndistillation. All we need to do is train a lightweight MLP-like\nparameter-efficient adapter (PEA) with only 6M parameters under teacher\nknowledge distillation along with a small parallel data corpus. We are\nsurprised to find that freezing the parameters of UNet can still achieve\nremarkable performance on the language-specific prompt evaluation set,\ndemonstrating that PEA can stimulate the potential generation ability of the\noriginal UNet. Additionally, it closely approaches the performance of the\nEnglish text-to-image model on a general prompt evaluation set. Furthermore,\nour adapter can be used as a plugin to achieve significant results in\ndownstream tasks in cross-lingual text-to-image generation. Code will be\navailable at: https://github.com/OPPO-Mente-Lab/PEA-Diffusion",
            "author": [
                "Jian Ma",
                "Chen Chen",
                "Qingsong Xie",
                "Haonan Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17086v1",
                "http://arxiv.org/pdf/2311.17086v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16433v1",
            "title": "Energy Efficiency Optimization in Active Reconfigurable Intelligent\n  Surface-Aided Integrated Sensing and Communication Systems",
            "updated": "2023-11-28T02:30:02Z",
            "published": "2023-11-28T02:30:02Z",
            "summary": "Energy efficiency (EE) is a challenging task in integrated sensing and\ncommunication (ISAC) systems, where high spectral efficiency and low energy\nconsumption appear as conflicting requirements. Although passive reconfigurable\nintelligent surface (RIS) has emerged as a promising technology for enhancing\nthe EE of the ISAC system, the multiplicative fading feature hinders its\neffectiveness. This paper proposes the use of active RIS with its amplification\ngains to assist the ISAC system for EE improvement. Specifically, we formulate\nan EE optimization problem in an active RIS-aided ISAC system under system\npower budgets, considering constraints on user communication quality of service\nand sensing signal-to-noise ratio (SNR). A novel alternating optimization\nalgorithm is developed to address the highly non-convex problem by leveraging a\ncombination of the generalized Rayleigh quotient optimization approach,\nsemidefinite relaxation (SDR), and the majorization-minimization (MM)\nframework. Furthermore, to accelerate the algorithm and reduce computational\ncomplexity, we derive a semi-closed form for eigenvalue determination.\nNumerical results demonstrate the effectiveness of the proposed approach,\nshowcasing significant improvements in EE compared to both passive RIS and\nspectrum efficiency optimization cases.",
            "author": [
                "Junjie Ye",
                "Mohamed Rihan",
                "Peichang Zhang",
                "Lei Huang",
                "Stefano Buzzi",
                "Zhen Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16433v1",
                "http://arxiv.org/pdf/2311.16433v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17085v1",
            "title": "Beyond Visual Cues: Synchronously Exploring Target-Centric Semantics for\n  Vision-Language Tracking",
            "updated": "2023-11-28T02:28:12Z",
            "published": "2023-11-28T02:28:12Z",
            "summary": "Single object tracking aims to locate one specific target in video sequences,\ngiven its initial state. Classical trackers rely solely on visual cues,\nrestricting their ability to handle challenges such as appearance variations,\nambiguity, and distractions. Hence, Vision-Language (VL) tracking has emerged\nas a promising approach, incorporating language descriptions to directly\nprovide high-level semantics and enhance tracking performance. However, current\nVL trackers have not fully exploited the power of VL learning, as they suffer\nfrom limitations such as heavily relying on off-the-shelf backbones for feature\nextraction, ineffective VL fusion designs, and the absence of VL-related loss\nfunctions. Consequently, we present a novel tracker that progressively explores\ntarget-centric semantics for VL tracking. Specifically, we propose the first\nSynchronous Learning Backbone (SLB) for VL tracking, which consists of two\nnovel modules: the Target Enhance Module (TEM) and the Semantic Aware Module\n(SAM). These modules enable the tracker to perceive target-related semantics\nand comprehend the context of both visual and textual modalities at the same\npace, facilitating VL feature extraction and fusion at different semantic\nlevels. Moreover, we devise the dense matching loss to further strengthen\nmulti-modal representation learning. Extensive experiments on VL tracking\ndatasets demonstrate the superiority and effectiveness of our methods.",
            "author": [
                "Jiawei Ge",
                "Xiangmei Chen",
                "Jiuxin Cao",
                "Xuelin Zhu",
                "Weijia Liu",
                "Bo Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17085v1",
                "http://arxiv.org/pdf/2311.17085v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16432v1",
            "title": "Text-Driven Image Editing via Learnable Regions",
            "updated": "2023-11-28T02:27:31Z",
            "published": "2023-11-28T02:27:31Z",
            "summary": "Language has emerged as a natural interface for image editing. In this paper,\nwe introduce a method for region-based image editing driven by textual prompts,\nwithout the need for user-provided masks or sketches. Specifically, our\napproach leverages an existing pretrained text-to-image model and introduces a\nbounding box generator to find the edit regions that are aligned with the\ntextual prompts. We show that this simple approach enables flexible editing\nthat is compatible with current image generation models, and is able to handle\ncomplex prompts featuring multiple objects, complex sentences or long\nparagraphs. We conduct an extensive user study to compare our method against\nstate-of-the-art methods. Experiments demonstrate the competitive performance\nof our method in manipulating images with high fidelity and realism that align\nwith the language descriptions provided. Our project webpage:\nhttps://yuanze-lin.me/LearnableRegions_page.",
            "author": [
                "Yuanze Lin",
                "Yi-Wen Chen",
                "Yi-Hsuan Tsai",
                "Lu Jiang",
                "Ming-Hsuan Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16432v1",
                "http://arxiv.org/pdf/2311.16432v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16430v1",
            "title": "Identification of Blue Horizontal-Branch Stars From LAMOST DR5",
            "updated": "2023-11-28T02:21:55Z",
            "published": "2023-11-28T02:21:55Z",
            "summary": "We construct a new catalog of the blue horizontal-branch (BHB) stars from the\nLarge Sky Area Multi-Object Fiber Spectroscopic Telescope (LAMOST) DR5 dataset,\nwhich contains 5355+81 BHB stars at high Galactic latitude\n(($|Glat|>20^{\\circ}$). We combine the spectral line indices with a set of\nBalmer line profile selection criteria to identify the BHB stars. During the\nselection process, we use the line index of \\ion{Ca}{2}\\,K to exclude the\nmetal-rich A-type dwarfs. We obtain their atmospheric parameters by\ncross-matching our BHB stars with the catalog provided by \\citet{Xiang2022}.\nThe results show that our sample is consistent with the theoretical $T_{\\rm\neff}$-log\\,$g$ evolutionary tracks of the BHB stars, indicating that our method\nis robust for identifying BHB stars from the LAMOST spectra. Their spatial\ndistribution indicates that most of our BHB stars are located in the inner halo\nor the disk of the Milky Way. Combined with other BHB samples from the\nliterature, the BHB stars can cover a large Galactic volume, which makes it a\nbetter probe for studying the kinematics, dynamics, and structural\ncharacteristics of the Milky Way.",
            "author": [
                "Jie Ju",
                "Wenyuan Cui",
                "Zhenyan Huo",
                "Chao liu",
                "Xiangxiang Xue",
                "Jiaming Liu",
                "Shuai Feng",
                "Mingxu Sun",
                "Linlin Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16430v1",
                "http://arxiv.org/pdf/2311.16430v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA",
                "astro-ph.SR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16429v1",
            "title": "The Transformative Influence of Large Language Models on Software\n  Development",
            "updated": "2023-11-28T02:18:54Z",
            "published": "2023-11-28T02:18:54Z",
            "summary": "The increasing adoption and commercialization of generalized Large Language\nModels (LLMs) have profoundly impacted various aspects of our daily lives.\nInitially embraced by the computer science community, the versatility of LLMs\nhas found its way into diverse domains. In particular, the software engineering\nrealm has witnessed the most transformative changes. With LLMs increasingly\nserving as AI Pair Programming Assistants spurred the development of\nspecialized models aimed at aiding software engineers. Although this new\nparadigm offers numerous advantages, it also presents critical challenges and\nopen problems. To identify the potential and prevailing obstacles, we\nsystematically reviewed contemporary scholarly publications, emphasizing the\nperspectives of software developers and usability concerns. Preliminary\nfindings underscore pressing concerns about data privacy, bias, and\nmisinformation. Additionally, we identified several usability challenges,\nincluding prompt engineering, increased cognitive demands, and mistrust.\nFinally, we introduce 12 open problems that we have identified through our\nsurvey, covering these various domains.",
            "author": [
                "Sajed Jalil"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16429v1",
                "http://arxiv.org/pdf/2311.16429v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.HC",
                "68T07",
                "D.2.3; I.2.5; I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16424v1",
            "title": "Manifold Preserving Guided Diffusion",
            "updated": "2023-11-28T02:08:06Z",
            "published": "2023-11-28T02:08:06Z",
            "summary": "Despite the recent advancements, conditional image generation still faces\nchallenges of cost, generalizability, and the need for task-specific training.\nIn this paper, we propose Manifold Preserving Guided Diffusion (MPGD), a\ntraining-free conditional generation framework that leverages pretrained\ndiffusion models and off-the-shelf neural networks with minimal additional\ninference cost for a broad range of tasks. Specifically, we leverage the\nmanifold hypothesis to refine the guided diffusion steps and introduce a\nshortcut algorithm in the process. We then propose two methods for on-manifold\ntraining-free guidance using pre-trained autoencoders and demonstrate that our\nshortcut inherently preserves the manifolds when applied to latent diffusion\nmodels. Our experiments show that MPGD is efficient and effective for solving a\nvariety of conditional generation applications in low-compute settings, and can\nconsistently offer up to 3.8x speed-ups with the same number of diffusion steps\nwhile maintaining high sample quality compared to the baselines.",
            "author": [
                "Yutong He",
                "Naoki Murata",
                "Chieh-Hsin Lai",
                "Yuhta Takida",
                "Toshimitsu Uesaka",
                "Dongjun Kim",
                "Wei-Hsiang Liao",
                "Yuki Mitsufuji",
                "J. Zico Kolter",
                "Ruslan Salakhutdinov",
                "Stefano Ermon"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16424v1",
                "http://arxiv.org/pdf/2311.16424v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16423v1",
            "title": "Mechanical stability of homogeneous holographic solids under finite\n  shear strain",
            "updated": "2023-11-28T02:04:29Z",
            "published": "2023-11-28T02:04:29Z",
            "summary": "We study the linear stability of holographic homogeneous solids (HHS) at\nfinite temperature and in presence of a background shear strain by means of a\nlarge scale quasi-normal mode analysis which extends beyond the hydrodynamic\nlimit. We find that mechanical instability can arise either as a result of a\ncomplex speed of sound -- gradient instability -- or of a negative diffusion\nconstant. Surprisingly, the simplest HHS models are linearly stable for\narbitrarily large values of the background strain. For more complex HHS, the\nonset of the diffusive instability always precedes that of the gradient\ninstability, which becomes the dominant destabilizing process only above a\ncritical value of the background shear strain. Finally, we observe that the\ncritical strains for the two instabilities approach each other at low\ntemperatures. We conclude by presenting a phase diagram for HHS as a function\nof temperature and background shear strain which shows interesting similarities\nwith the physics of superfluids in presence of background superfluid velocity.",
            "author": [
                "Matteo Baggioli",
                "Li Li",
                "Wei-Jia Li",
                "Hao-Tian Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16423v1",
                "http://arxiv.org/pdf/2311.16423v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th",
                "cond-mat.soft",
                "cond-mat.str-el"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16422v1",
            "title": "Spatial Variations of Jovian Tropospheric Ammonia via Ground-Based\n  Imaging",
            "updated": "2023-11-28T02:02:20Z",
            "published": "2023-11-28T02:02:20Z",
            "summary": "Optical bandpass-filter observations can be simply processed to determine\nsimilar horizontal ammonia distributions above the Jovian cloud tops as\nmid-infrared and microwave observations. Current understanding of this\ndistribution and its relationship to aerosol opacity, cloud-top pressure, and\ncirculation is provided by atmospheric retrieval models using observations from\nmajor ground-based facilities and spacecraft. These techniques recover high\nfidelity information on the ammonia distribution but are limited in spatial and\ntemporal coverage. Part of this coverage gap - upper tropospheric abundance -\ncan be bridged by using continuum-divided ammonia and methane absorption images\nas suggested by Combes and Encrenaz [1979]. In 2020-21, Jupiter was imaged in\nthe 645 nm ammonia absorption band and adjacent continuum bands, demonstrating\nthat the spatially-resolved optical depth in that band could be determined with\na 0.28-m Schmidt-Cassegrain telescope (SCT). In 2022, a 620 nm filter was added\nto include methane absorption images in the same wavelength range. Methane\nabundance provides a constant reference against which to determine the ammonia\nabundance, specifically the column-averaged mole fraction above the clouds.\nVLT/MUSE results are compared to these SCT results and those from the TEXES\nmid-infrared spectrometer used on the IRTF and the Gemini telescopes.\nMeridional and longitudinal features are examined, including the Equatorial\nZone (EZ) ammonia enhancement, the North Equatorial Belt (NEB) depletion,\ndepletion above the Great Red Spot (GRS), and suggested enhancements over\nbright plumes in the northern EZ. This work demonstrates meaningful ammonia\nmonitoring that can provide synoptic coverage and continuity between spacecraft\nor major ground-based facility campaigns.",
            "author": [
                "Steven M Hill",
                "Patrick G. J. Irwin",
                "Charlotte Alexander",
                "John H. Rogers"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16422v1",
                "http://arxiv.org/pdf/2311.16422v1"
            ],
            "primary_category": "astro-ph.EP",
            "category": [
                "astro-ph.EP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16421v1",
            "title": "CDEval: A Benchmark for Measuring the Cultural Dimensions of Large\n  Language Models",
            "updated": "2023-11-28T02:01:25Z",
            "published": "2023-11-28T02:01:25Z",
            "summary": "As the scaling of Large Language Models (LLMs) has dramatically enhanced\ntheir capabilities, there has been a growing focus on the alignment problem to\nensure their responsible and ethical use. While existing alignment efforts\npredominantly concentrate on universal values such as the HHH principle, the\naspect of culture, which is inherently pluralistic and diverse, has not\nreceived adequate attention. This work introduces a new benchmark, CDEval,\naimed at evaluating the cultural dimensions of LLMs. CDEval is constructed by\nincorporating both GPT-4's automated generation and human verification,\ncovering six cultural dimensions across seven domains. Our comprehensive\nexperiments provide intriguing insights into the culture of mainstream LLMs,\nhighlighting both consistencies and variations across different dimensions and\ndomains. The findings underscore the importance of integrating cultural\nconsiderations in LLM development, particularly for applications in diverse\ncultural settings. Through CDEval, we aim to broaden the horizon of LLM\nalignment research by including cultural dimensions, thus providing a more\nholistic framework for the future development and evaluation of LLMs. This\nbenchmark serves as a valuable resource for cultural studies in LLMs, paving\nthe way for more culturally aware and sensitive models.",
            "author": [
                "Yuhang Wang",
                "Yanxu Zhu",
                "Chao Kong",
                "Shuyu Wei",
                "Xiaoyuan Yi",
                "Xing Xie",
                "Jitao Sang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16421v1",
                "http://arxiv.org/pdf/2311.16421v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16417v1",
            "title": "Challenges and Opportunities to Enable Large-Scale Computing via\n  Heterogeneous Chiplets",
            "updated": "2023-11-28T01:50:09Z",
            "published": "2023-11-28T01:50:09Z",
            "summary": "Fast-evolving artificial intelligence (AI) algorithms such as large language\nmodels have been driving the ever-increasing computing demands in today's data\ncenters. Heterogeneous computing with domain-specific architectures (DSAs)\nbrings many opportunities when scaling up and scaling out the computing system.\nIn particular, heterogeneous chiplet architecture is favored to keep scaling up\nand scaling out the system as well as to reduce the design complexity and the\ncost stemming from the traditional monolithic chip design. However, how to\ninterconnect computing resources and orchestrate heterogeneous chiplets is the\nkey to success. In this paper, we first discuss the diversity and evolving\ndemands of different AI workloads. We discuss how chiplet brings better cost\nefficiency and shorter time to market. Then we discuss the challenges in\nestablishing chiplet interface standards, packaging, and security issues. We\nfurther discuss the software programming challenges in chiplet systems.",
            "author": [
                "Zhuoping Yang",
                "Shixin Ji",
                "Xingzhen Chen",
                "Jinming Zhuang",
                "Weifeng Zhang",
                "Dharmesh Jani",
                "Peipei Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16417v1",
                "http://arxiv.org/pdf/2311.16417v1"
            ],
            "primary_category": "cs.AR",
            "category": [
                "cs.AR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16416v1",
            "title": "A Combinatorial Approach to Robust PCA",
            "updated": "2023-11-28T01:49:51Z",
            "published": "2023-11-28T01:49:51Z",
            "summary": "We study the problem of recovering Gaussian data under adversarial\ncorruptions when the noises are low-rank and the corruptions are on the\ncoordinate level. Concretely, we assume that the Gaussian noises lie in an\nunknown $k$-dimensional subspace $U \\subseteq \\mathbb{R}^d$, and $s$ randomly\nchosen coordinates of each data point fall into the control of an adversary.\nThis setting models the scenario of learning from high-dimensional yet\nstructured data that are transmitted through a highly-noisy channel, so that\nthe data points are unlikely to be entirely clean.\n  Our main result is an efficient algorithm that, when $ks^2 = O(d)$, recovers\nevery single data point up to a nearly-optimal $\\ell_1$ error of $\\tilde\nO(ks/d)$ in expectation. At the core of our proof is a new analysis of the\nwell-known Basis Pursuit (BP) method for recovering a sparse signal, which is\nknown to succeed under additional assumptions (e.g., incoherence or the\nrestricted isometry property) on the underlying subspace $U$. In contrast, we\npresent a novel approach via studying a natural combinatorial problem and show\nthat, over the randomness in the support of the sparse signal, a\nhigh-probability error bound is possible even if the subspace $U$ is arbitrary.",
            "author": [
                "Weihao Kong",
                "Mingda Qiao",
                "Rajat Sen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16416v1",
                "http://arxiv.org/pdf/2311.16416v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16409v1",
            "title": "A Deep Q-Learning based, Base-Station Connectivity-Aware, Decentralized\n  Pheromone Mobility Model for Autonomous UAV Networks",
            "updated": "2023-11-28T01:33:39Z",
            "published": "2023-11-28T01:33:39Z",
            "summary": "UAV networks consisting of low SWaP (size, weight, and power), fixed-wing\nUAVs are used in many applications, including area monitoring, search and\nrescue, surveillance, and tracking. Performing these operations efficiently\nrequires a scalable, decentralized, autonomous UAV network architecture with\nhigh network connectivity. Whereas fast area coverage is needed for quickly\nsensing the area, strong node degree and base station (BS) connectivity are\nneeded for UAV control and coordination and for transmitting sensed information\nto the BS in real time. However, the area coverage and connectivity exhibit a\nfundamental trade-off: maintaining connectivity restricts the UAVs' ability to\nexplore. In this paper, we first present a node degree and BS\nconnectivity-aware distributed pheromone (BS-CAP) mobility model to\nautonomously coordinate the UAV movements in a decentralized UAV network. This\nmodel maintains a desired connectivity among 1-hop neighbors and to the BS\nwhile achieving fast area coverage. Next, we propose a deep Q-learning policy\nbased BS-CAP model (BSCAP-DQN) to further tune and improve the coverage and\nconnectivity trade-off. Since it is not practical to know the complete topology\nof such a network in real time, the proposed mobility models work online, are\nfully distributed, and rely on neighborhood information. Our simulations\ndemonstrate that both proposed models achieve efficient area coverage and\ndesired node degree and BS connectivity, improving significantly over existing\nschemes.",
            "author": [
                "Shreyas Devaraju",
                "Alexander Ihler",
                "Sunil Kumar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16409v1",
                "http://arxiv.org/pdf/2311.16409v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16408v1",
            "title": "Pathway selectivity in time-resolved spectroscopy using two-photon\n  coincidence counting with quantum entangled photons",
            "updated": "2023-11-28T01:31:26Z",
            "published": "2023-11-28T01:31:26Z",
            "summary": "Ultrafast optical spectroscopy is a powerful technique for studying the\ndynamic processes of molecular systems in condensed phases. However, in\nmolecular systems containing many dye molecules, the spectra can become crowded\nand difficult to interpret owing to the presence of multiple nonlinear optical\ncontributions. In this work, we theoretically propose time-resolved\nspectroscopy based on the coincidence counting of two entangled photons\ngenerated via parametric down-conversion with a monochromatic laser. We\ndemonstrate that the use of two-photon counting detection of entangled photon\npairs enables the selective elimination of the excited-state absorption signal.\nThis selective elimination cannot be realized with classical coherent light. We\nanticipate that the proposed spectroscopy will help to simplify the spectral\ninterpretation in complex molecular and materials systems comprising multiple\nmolecules.",
            "author": [
                "Yuta Fujihashi",
                "Akihito Ishizaki",
                "Ryosuke Shimizu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16408v1",
                "http://arxiv.org/pdf/2311.16408v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17082v2",
            "title": "DreamPropeller: Supercharge Text-to-3D Generation with Parallel Sampling",
            "updated": "2023-12-06T07:15:58Z",
            "published": "2023-11-28T01:28:58Z",
            "summary": "Recent methods such as Score Distillation Sampling (SDS) and Variational\nScore Distillation (VSD) using 2D diffusion models for text-to-3D generation\nhave demonstrated impressive generation quality. However, the long generation\ntime of such algorithms significantly degrades the user experience. To tackle\nthis problem, we propose DreamPropeller, a drop-in acceleration algorithm that\ncan be wrapped around any existing text-to-3D generation pipeline based on\nscore distillation. Our framework generalizes Picard iterations, a classical\nalgorithm for parallel sampling an ODE path, and can account for non-ODE paths\nsuch as momentum-based gradient updates and changes in dimensions during the\noptimization process as in many cases of 3D generation. We show that our\nalgorithm trades parallel compute for wallclock time and empirically achieves\nup to 4.7x speedup with a negligible drop in generation quality for all tested\nframeworks.",
            "author": [
                "Linqi Zhou",
                "Andy Shih",
                "Chenlin Meng",
                "Stefano Ermon"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17082v2",
                "http://arxiv.org/pdf/2311.17082v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16404v1",
            "title": "A multi-physics compiler for generating numerical solvers from\n  differential equations",
            "updated": "2023-11-28T01:15:33Z",
            "published": "2023-11-28T01:15:33Z",
            "summary": "We develop a tool that enables domain experts to quickly generate numerical\nsolvers for emerging multi-physics phenomena starting from a high-level\ndescription based on ordinary/partial differential equations and their initial\nand boundary conditions over a symbolic spacetime domain. This \"multi-physics\"\ncompiler aims to bridge the gap between problem formulation and computation,\nwhich historically has spanned years or even decades. Specialized numerical\nsolvers in areas such as computational fluid dynamics (CFD) often present a\nbarrier to novice end users not well-versed in the intricacies of their\nunderlying schemes, and requiring surgical modifications when coupling with\nadditional physical components initially not accounted for by the solver.\nThrough the use of an intermediate language that is neutral between classical\nand exterior calculus, the compiler generates correct-by-construction numerical\nsource code that offers guarantees of immutable physical principles like\nconservation laws at the discrete level. We present a proof of concept for the\nmulti-physics compiler through some examples involving compilation to OpenFOAM\n[1]. A specific use case that the compiler is well-suited for involves equation\nmodification approaches, where the aim is to use simple numerical schemes such\nas central differencing through the additional of artificial terms to the\noriginal governing equations of the multi-physics problem [2, 3, 4].",
            "author": [
                "John T. Maxwell III",
                "Morad Behandish",
                "S\u00f8ren Taverniers"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16404v1",
                "http://arxiv.org/pdf/2311.16404v1"
            ],
            "primary_category": "physics.comp-ph",
            "category": [
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16402v1",
            "title": "A unified description of DGLAP, CSS, and BFKL: TMD factorization\n  bridging large and small x",
            "updated": "2023-11-28T01:10:10Z",
            "published": "2023-11-28T01:10:10Z",
            "summary": "This paper introduces a transverse-momentum dependent (TMD) factorization\nscheme designed to unify both large and small Bjorken-x regimes. We compute the\nnext-to-leading order (NLO) quantum chromodynamics (QCD) corrections to the\ngluon TMD operator for an unpolarized hadron within this proposed scheme. This\nleads to the emergence of a new TMD evolution, incorporating those in\ntransverse momentum, rapidity, and Bjorken-x. When matched to the collinear\nfactorization scheme, our factorization scheme faithfully reproduces the\nwell-established Dokshitzer-Gribov-Lipatov-Altarelli-Parisi (DGLAP) and\nCollins-Soper-Sterman (CSS) evolutions. Conversely, matching with high-energy\nfactorization not only yields the Balitsky-Fadin-Kuraev-Lipatov (BFKL)\nevolution but also reveals distinctive signatures of CSS logarithms. The\ndevelopment of this novel TMD factorization scheme, capable of seamlessly\nreconciling disparate Bjorken-x regimes and faithfully reproducing established\nQCD evolution equations, has the potential to significantly advance our\ncomprehension of high-energy processes and three-dimensional parton structures\nof hadrons.",
            "author": [
                "Swagato Mukherjee",
                "Vladimir V. Skokov",
                "Andrey Tarasov",
                "Shaswat Tiwari"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16402v1",
                "http://arxiv.org/pdf/2311.16402v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "hep-ex",
                "hep-lat",
                "hep-th",
                "nucl-th"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16388v1",
            "title": "Understanding the Process of Data Labeling in Cybersecurity",
            "updated": "2023-11-28T00:20:07Z",
            "published": "2023-11-28T00:20:07Z",
            "summary": "Many domains now leverage the benefits of Machine Learning (ML), which\npromises solutions that can autonomously learn to solve complex tasks by\ntraining over some data. Unfortunately, in cyberthreat detection, high-quality\ndata is hard to come by. Moreover, for some specific applications of ML, such\ndata must be labeled by human operators. Many works \"assume\" that labeling is\ntough/challenging/costly in cyberthreat detection, thereby proposing solutions\nto address such a hurdle. Yet, we found no work that specifically addresses the\nprocess of labeling 'from the viewpoint of ML security practitioners'. This is\na problem: to this date, it is still mostly unknown how labeling is done in\npractice -- thereby preventing one from pinpointing \"what is needed\" in the\nreal world.\n  In this paper, we take the first step to build a bridge between academic\nresearch and security practice in the context of data labeling. First, we reach\nout to five subject matter experts and carry out open interviews to identify\npain points in their labeling routines. Then, by using our findings as a\nscaffold, we conduct a user study with 13 practitioners from large security\ncompanies, and ask detailed questions on subjects such as active learning,\ncosts of labeling, and revision of labels. Finally, we perform proof-of-concept\nexperiments addressing labeling-related aspects in cyberthreat detection that\nare sometimes overlooked in research. Altogether, our contributions and\nrecommendations serve as a stepping stone to future endeavors aimed at\nimproving the quality and robustness of ML-driven security systems. We release\nour resources.",
            "author": [
                "Tobias Braun",
                "Irdin Pekaric",
                "Giovanni Apruzzese"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16388v1",
                "http://arxiv.org/pdf/2311.16388v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16386v1",
            "title": "Coil Optimization for Quasi-helically Symmetric Stellarator\n  Configurations",
            "updated": "2023-11-28T00:19:37Z",
            "published": "2023-11-28T00:19:37Z",
            "summary": "Filament-based coil optimizations are performed for several quasihelical\nstellarator configurations, notably the one from [M. Landreman, E. Paul, PRL\n128, 035001, 2022], demonstrating that precise quasihelical symmetry can be\nachieved with realistic coils. Several constraints are placed on the shape and\nspacing of the coils, such as low curvature and sufficient plasma-coil distance\nfor neutron shielding. The coils resulting from this optimization have a\nmaximum curvature 0.8 times that of the coils of the Helically Symmetric\neXperiment (HSX) and a mean squared curvature 0.4 times that of the HSX coils\nwhen scaled to the same plasma minor radius. When scaled up to reactor size and\nmagnetic field strength, no fast particle losses were found in the\nfree-boundary configuration when simulating 5000 alpha particles launched at\n3.5 MeV on the flux surface with normalized toroidal flux of s=0.5. An analysis\nof the tolerance of the coils to manufacturing errors is performed using a\nGaussian process model, and the coils are found to maintain low particle losses\nfor smooth, large-scale errors up to amplitudes of about 0.15 m. Another coil\noptimization is performed for the Landreman-Paul configuration with the\nadditional constraint that the coils are purely planar. Visual inspection of\nthe Poincar\\'e plot of the resulting magnetic field-lines reveal that the\nplanar modular coils alone do a poor job of reproducing the target equilibrium.\nAdditional non-planar coil optimizations are performed for the quasihelical\nconfiguration with 5% volume-averaged plasma beta from [M. Landreman, S.\nBuller, M. Drevlak, PoP 29, 082501, 2022], and a similar configuration also\noptimized to satisfy the Mercier criterion. The finite beta configurations had\nlarger fast-particle losses, with the free-boundary Mercier-optimized\nconfiguration performing the worst, losing about 5.5% of alpha particles\nlaunched at s=0.5.",
            "author": [
                "Alexander Vyacheslav Wiedman",
                "Stefan Buller",
                "Matt Landreman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16386v1",
                "http://arxiv.org/pdf/2311.16386v1"
            ],
            "primary_category": "physics.plasm-ph",
            "category": [
                "physics.plasm-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16378v1",
            "title": "Bayesian Formulations for Graph Spectral Denoising",
            "updated": "2023-11-27T23:53:19Z",
            "published": "2023-11-27T23:53:19Z",
            "summary": "We consider noisy signals which are defined on the vertices of a graph and\npresent smoothing algorithms for the cases of Gaussian, dropout, and uniformly\ndistributed noise. The signals are assumed to follow a prior distribution\ndefined in the frequency domain which favors signals which are smooth across\nthe edges of the graph. By pairing this prior distribution with our three\nmodels of noise generation, we propose \\textit{Maximum A Posteriori} (M.A.P.)\nestimates of the true signal in the presence of noisy data and provide\nalgorithms for computing the M.A.P. Finally, we demonstrate the algorithms'\nability to effectively restore white noise on image data, and from severe\ndropout in toy \\& EHR data.",
            "author": [
                "Sam Leone",
                "Xingzhi Sun",
                "Michael Perlmutter",
                "Smita Krishnaswamy"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16378v1",
                "http://arxiv.org/pdf/2311.16378v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16376v1",
            "title": "Pinching and Probing of Polygonal Grain Boundaries",
            "updated": "2023-11-27T23:45:07Z",
            "published": "2023-11-27T23:45:07Z",
            "summary": "In this study, sub-angstrom spatial resolution is achieved in mapping and\nspectroscopy of atoms and bonds within polygonal grain boundaries (GBs) of\ngraphite using Scanning Tunneling Microscopy (STM). Robust van Hove\nsingularities (VHS) are observed in addition to edge states under ambient\nconditions. The bias-dependent nature of these states reveals metallic traits\nof GB, through the charge accumulation and dissipation of localized electronic\nstates. Utilizing a surface elastic deformation technique induced by STM tip\nallows pico-pinching of the GB, providing insights into its mechanical strength\nas well as in-situ strain-induced modification of their unique spectroscopy,\nrevealing a tendency toward flattening of the electronic energy band\ndispersion. An initial atomic-level experimental technique of probing\nspin-polarized magnetic states is demonstrated, suggesting different densities\nfor spin-up and spin-down states within a spin-degenerate band structure\npotentially applicable in spin transport or quantum spin sensing.",
            "author": [
                "Nirjhar Sarkar",
                "Prabhakar R. Bandaru",
                "Robert C. Dynes"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16376v1",
                "http://arxiv.org/pdf/2311.16376v1"
            ],
            "primary_category": "cond-mat.mes-hall",
            "category": [
                "cond-mat.mes-hall",
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16372v1",
            "title": "Joint Deep Image Restoration and Unsupervised Quality Assessment",
            "updated": "2023-11-27T23:32:20Z",
            "published": "2023-11-27T23:32:20Z",
            "summary": "Deep learning techniques have revolutionized the fields of image restoration\nand image quality assessment in recent years. While image restoration methods\ntypically utilize synthetically distorted training data for training, deep\nquality assessment models often require expensive labeled subjective data.\nHowever, recent studies have shown that activations of deep neural networks\ntrained for visual modeling tasks can also be used for perceptual quality\nassessment of images. Following this intuition, we propose a novel\nattention-based convolutional neural network capable of simultaneously\nperforming both image restoration and quality assessment. We achieve this by\ntraining a JPEG deblocking network augmented with \"quality attention\" maps and\ndemonstrating state-of-the-art deblocking accuracy, achieving a high\ncorrelation of predicted quality with human opinion scores.",
            "author": [
                "Hakan Emre Gedik",
                "Abhinau K. Venkataramanan",
                "Alan C. Bovik"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16372v1",
                "http://arxiv.org/pdf/2311.16372v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16366v1",
            "title": "Continuous-time open quantum walks in one dimension: matrix-valued\n  orthogonal polynomials and Lindblad generators",
            "updated": "2023-11-27T23:12:51Z",
            "published": "2023-11-27T23:12:51Z",
            "summary": "We study continuous-time open quantum walks in one dimension through a matrix\nrepresentation, focusing on nearest-neighbor transitions for which an\nassociated weight matrix exists. Statistics such as site recurrence are studied\nin terms of matrix-valued orthogonal polynomials and explicit calculations are\nobtained for classes of Lindblad generators that model quantum versions of\nbirth-death processes. Emphasis is given to the technical distinction between\nthe cases of a finite or infinite number of vertices. Recent results for open\nquantum walks are adapted in order to apply the folding trick to\ncontinuous-time birth-death chains on the integers. Finally, we investigate the\nmatrix-valued Stieltjes transform associated to the weights.",
            "author": [
                "Newton Loebens"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16366v1",
                "http://arxiv.org/pdf/2311.16366v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16363v1",
            "title": "Bifurcation delay and front propagation in the real Ginzburg-Landau\n  equation on a time-dependent domain",
            "updated": "2023-11-27T23:03:38Z",
            "published": "2023-11-27T23:03:38Z",
            "summary": "This work analyzes bifurcation delay and front propagation in the\none-dimensional real Ginzburg-Landau equation (RGLE) with periodic boundary\nconditions on monotonically growing or shrinking domains. First, we obtain\nclosed-form expressions for the delay of primary bifurcations on a growing\ndomain and show that the additional domain growth before the appearance of a\npattern is independent of the growth time scale. We also quantify primary\nbifurcation delay on a shrinking domain; the time scale of domain compression\nis reflected in the additional compression before the pattern decays. For\nsecondary bifurcations such as the Eckhaus instability, we obtain a lower bound\non the delay of phase slips due to a time-dependent domain. We also construct a\nheuristic model to classify regimes with arrested phase slips, i.e. phase slips\nthat fail to develop. Then, we study how fronts are influenced by a\ntime-dependent domain. We derive expressions for the velocity and profile of\nhomogeneous fronts on a time-dependent domain. We also derive the natural\n``asymptotic'' velocity and front profile and show that these deviate from\npredictions based on the marginal stability criterion familiar from fixed\ndomain theory. This difference arises because the time-dependence of the domain\nlifts the degeneracy of the spatial eigenvalues associated with speed selection\nand represents a fundamental distinction from the fixed domain theory that we\nverify using direct numerical simulations. The effect of a growing domain on\npattern-spreading and Eckhaus front velocities is inspected qualitatively and\nfound to be similar to that of homogeneous fronts. These more complex fronts\ncan also experience delayed onset. Lastly, we show that dilution -- an effect\npresent when the order parameter is conserved -- increases bifurcation delay\nand amplifies changes in the homogeneous front velocity on time-dependent\ndomains.",
            "author": [
                "Troy Tsubota",
                "Chang Liu",
                "Benjamin Foster",
                "Edgar Knobloch"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16363v1",
                "http://arxiv.org/pdf/2311.16363v1"
            ],
            "primary_category": "nlin.PS",
            "category": [
                "nlin.PS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16362v1",
            "title": "Reducing Gender Bias in Machine Translation through Counterfactual Data\n  Generation",
            "updated": "2023-11-27T23:03:01Z",
            "published": "2023-11-27T23:03:01Z",
            "summary": "Recent advances in neural methods have led to substantial improvement in the\nquality of Neural Machine Translation (NMT) systems. However, these systems\nfrequently produce translations with inaccurate gender (Stanovsky et al.,\n2019), which can be traced to bias in training data. Saunders and Byrne (2020)\ntackle this problem with a handcrafted dataset containing balanced gendered\nprofession words. By using this data to fine-tune an existing NMT model, they\nshow that gender bias can be significantly mitigated, albeit at the expense of\ntranslation quality due to catastrophic forgetting. They recover some of the\nlost quality with modified training objectives or additional models at\ninference. We find, however, that simply supplementing the handcrafted dataset\nwith a random sample from the base model training corpus is enough to\nsignificantly reduce the catastrophic forgetting. We also propose a novel\ndomain-adaptation technique that leverages in-domain data created with the\ncounterfactual data generation techniques proposed by Zmigrod et al. (2019) to\nfurther improve accuracy on the WinoMT challenge test set without significant\nloss in translation quality. We show its effectiveness in NMT systems from\nEnglish into three morphologically rich languages French, Spanish, and Italian.\nThe relevant dataset and code will be available at Github.",
            "author": [
                "Ranjita Naik",
                "Spencer Rarrick",
                "Vishal Chowdhary"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16362v1",
                "http://arxiv.org/pdf/2311.16362v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17078v1",
            "title": "Data Imbalance, Uncertainty Quantification, and Generalization via\n  Transfer Learning in Data-driven Parameterizations: Lessons from the\n  Emulation of Gravity Wave Momentum Transport in WACCM",
            "updated": "2023-11-27T22:51:10Z",
            "published": "2023-11-27T22:51:10Z",
            "summary": "Neural networks (NNs) are increasingly used for data-driven subgrid-scale\nparameterization in weather and climate models. While NNs are powerful tools\nfor learning complex nonlinear relationships from data, there are several\nchallenges in using them for parameterizations. Three of these challenges are\n1) data imbalance related to learning rare (often large-amplitude) samples; 2)\nuncertainty quantification (UQ) of the predictions to provide an accuracy\nindicator; and 3) generalization to other climates, e.g., those with higher\nradiative forcing. Here, we examine the performance of methods for addressing\nthese challenges using NN-based emulators of the Whole Atmosphere Community\nClimate Model (WACCM) physics-based gravity wave (GW) parameterizations as the\ntest case. WACCM has complex, state-of-the-art parameterizations for\norography-, convection- and frontal-driven GWs. Convection- and\norography-driven GWs have significant data imbalance due to the absence of\nconvection or orography in many grid points. We address data imbalance using\nresampling and/or weighted loss functions, enabling the successful emulation of\nparameterizations for all three sources. We demonstrate that three UQ methods\n(Bayesian NNs, variational auto-encoders, and dropouts) provide ensemble\nspreads that correspond to accuracy during testing, offering criteria on when a\nNN gives inaccurate predictions. Finally, we show that the accuracy of these\nNNs decreases for a warmer climate (4XCO2). However, the generalization\naccuracy is significantly improved by applying transfer learning, e.g.,\nre-training only one layer using ~1% new data from the warmer climate. The\nfindings of this study offer insights for developing reliable and generalizable\ndata-driven parameterizations for various processes, including (but not\nlimited) to GWs.",
            "author": [
                "Y. Qiang Sun",
                "Hamid A. Pahlavan",
                "Ashesh Chattopadhyay",
                "Pedram Hassanzadeh",
                "Sandro W. Lubis",
                "M. Joan Alexander",
                "Edwin Gerber",
                "Aditi Sheshadri",
                "Yifei Guan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17078v1",
                "http://arxiv.org/pdf/2311.17078v1"
            ],
            "primary_category": "physics.ao-ph",
            "category": [
                "physics.ao-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16356v2",
            "title": "What Really is `Molecule' in Molecular Communications? The Quest for\n  Physics of Particle-based Information Carriers",
            "updated": "2023-12-03T12:06:13Z",
            "published": "2023-11-27T22:38:19Z",
            "summary": "Molecular communication, as implied by its name, uses molecules as\ninformation carriers for communication between objects. It has an advantage\nover traditional electromagnetic-wave-based communication in that\nmolecule-based systems could be biocompatible, operable in challenging\nenvironments, and energetically undemanding. Consequently, they are envisioned\nto have a broad range of applications, such as in the Internet of Bio-nano\nThings, targeted drug delivery, and agricultural monitoring. Despite the rapid\ndevelopment of the field, with an increasing number of theoretical models and\nexperimental testbeds established by researchers, a fundamental aspect of the\nfield has often been sidelined, namely, the nature of the molecule in molecular\ncommunication.\n  The potential information molecules could exhibit a wide range of properties,\nmaking them require drastically different treatments when being modeled and\nexperimented upon. Therefore, in this paper, we delve into the intricacies of\ncommonly used information molecules, examining their fundamental physical\ncharacteristics, associated communication systems, and potential applications\nin a more realistic manner, focusing on the influence of their own properties.\nThrough this comprehensive survey, we aim to offer a novel yet essential\nperspective on molecular communication, thereby bridging the current gap\nbetween theoretical research and real-world applications.",
            "author": [
                "Hanlin Xiao",
                "Kamela Dokaj",
                "Ozgur B. Akan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16356v2",
                "http://arxiv.org/pdf/2311.16356v2"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16353v1",
            "title": "Improving Denoising Diffusion Probabilistic Models via Exploiting Shared\n  Representations",
            "updated": "2023-11-27T22:30:26Z",
            "published": "2023-11-27T22:30:26Z",
            "summary": "In this work, we address the challenge of multi-task image generation with\nlimited data for denoising diffusion probabilistic models (DDPM), a class of\ngenerative models that produce high-quality images by reversing a noisy\ndiffusion process. We propose a novel method, SR-DDPM, that leverages\nrepresentation-based techniques from few-shot learning to effectively learn\nfrom fewer samples across different tasks. Our method consists of a core meta\narchitecture with shared parameters, i.e., task-specific layers with exclusive\nparameters. By exploiting the similarity between diverse data distributions,\nour method can scale to multiple tasks without compromising the image quality.\nWe evaluate our method on standard image datasets and show that it outperforms\nboth unconditional and conditional DDPM in terms of FID and SSIM metrics.",
            "author": [
                "Delaram Pirhayatifard",
                "Mohammad Taha Toghani",
                "Guha Balakrishnan",
                "C\u00e9sar A. Uribe"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16353v1",
                "http://arxiv.org/pdf/2311.16353v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV",
                "eess.IV",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16351v1",
            "title": "Microscopic Mechanism of the Thermal Amorphization of ZIF-4 and Melting\n  of ZIF-zni Revealed via Molecular Dynamics and Machine Learning Techniques",
            "updated": "2023-11-27T22:29:50Z",
            "published": "2023-11-27T22:29:50Z",
            "summary": "We investigate the microscopic mechanism of the thermally induced ambient\npressure ordered-disordered phase transitions of two zeolitic imidazolate\nframeworks of formula Zn(C$_3$H$_3$N$_2$)$_2$: a porous (ZIF-4) and a dense,\nnon-porous (ZIF-zni) polymorph via a combination of data science and computer\nsimulation approaches. Molecular dynamics simulations are carried out at the\natomistic level through the nb-ZIF-FF force field that incorporates\nligand-metal reactivity and relies on dummy atoms to reproduce the correct\ntetrahedral topology around Zn$^{2+}$ centres. The force field is capable of\nreproducing the structure of ZIF-4, ZIF-zni and the amorphous (ZIF$\\_$a) and\nliquid (ZIF$\\_$liq) phases that respectively result when these crystalline\nmaterials are heated. Symmetry functions computed over a database of structures\nof the four phases, are used as inputs to train a neural network that predicts\nthe probabilities of belonging to each of the four phases at the local\nZn$^{2+}$ level with 90$\\%$ accuracy. We apply this methodology to follow the\ntime-evolution of the amorphization of ZIF-4 and the melting of ZIF-zni along a\nseries of molecular dynamics trajectories. We first computed the transition\ntemperature and determined associated thermodynamic state functions.\nSubsequently, we studied the mechanisms. Both processes consist of two steps:\n(i) for ZIF-4, a low-density amorphous phase is first formed, followed by the\nfinal ZIF$\\_$a phase while (ii) for ZIF-zni, a ZIF$\\_$a-like phase precedes the\nformation of the liquid phase. These processes involve connectivity changes in\nthe first neighbour ligands around the central Zn$^{2+}$ cations. We find that\nthe amorphization of ZIF-4 is a non-isotropic processes and we trace back the\norigins of this anisotropic behaviour to density and lability of coordination\nbonds.",
            "author": [
                "Emilio Mendez",
                "Rocio Semino"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16351v1",
                "http://arxiv.org/pdf/2311.16351v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16350v1",
            "title": "Early warning signs of critical transitions -- The $\u03b1$-stable case",
            "updated": "2023-11-27T22:28:29Z",
            "published": "2023-11-27T22:28:29Z",
            "summary": "Statistical early warning signs can be used to identify an approaching\nbifurcation in stochastic dynamical systems and are now regularly employed in\napplications concerned with the identification of potential rapid, non-linear\nchange or tipping points. However, the reliability of these early warning signs\nrelies on a number of key mathematical assumptions, most notably the presence\nof Gaussian noise. We here show that for systems driven by non-Gaussian,\n$\\alpha$-stable noise, the classical early warning signs of rising variance and\nautocorrelation are not supported by mathematical theory and their use poses\nthe danger of spurious, false-positive results. To address this, we provide a\ngeneralized approach by introduce the scaling factor $\\gamma_X$ as an\nalternative early warning sign. We show that in the case of the\nOrnstein-Uhlenbeck process, there exists a direct inverse relationship between\n$\\gamma_{X}$ and the bifurcation parameter, telling us that $\\gamma_{X}$ will\nincrease as we approach the bifurcation. Our numerical simulations confirm\ntheoretical results and show that our findings generalize well to non-linear,\nnon-equilibrium systems. We thus provide a generalized, robust and applicable\nstatistical early warning sign for systems driven by Gaussian and non-Gaussian\n$\\alpha$-stable noise.",
            "author": [
                "Lucia S. Layritz",
                "Ilya Pavlyukevich",
                "Anja Rammig",
                "Christian Kuehn"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16350v1",
                "http://arxiv.org/pdf/2311.16350v1"
            ],
            "primary_category": "math.DS",
            "category": [
                "math.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16347v1",
            "title": "Random generation of group elements using combinatorial group theory and\n  automata theory, along with a hardware example",
            "updated": "2023-11-27T22:26:58Z",
            "published": "2023-11-27T22:26:58Z",
            "summary": "In this paper, we introduce a novel approach for generating random elements\nof a finite group given a set of generators of that. Our method draws upon\ncombinatorial group theory and automata theory to achieve this objective.\nFurthermore, we explore the application of this method in generating random\nelements of a particularly significant group, namely the symmetric group (or\ngroup of permutations on a set). Through rigorous analysis, we demonstrate that\nour proposed method requires fewer average swaps to generate permutations\ncompared to existing approaches. However, recognizing the need for practical\napplications, we propose a hardware-based implementation based on our\ntheoretical approach, and provide a comprehensive comparison with previous\nmethods. Our evaluation reveals that our method outperforms existing approaches\nin certain scenarios. Although our primary proposed method only aims to speed\nup the shuffling and does not decrease its time complexity, we also extend our\nmethod to improve the time complexity.",
            "author": [
                "MohammadJavad Vaez",
                "Marjan Kaedi",
                "Mahdi Kalbasi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16347v1",
                "http://arxiv.org/pdf/2311.16347v1"
            ],
            "primary_category": "cs.FL",
            "category": [
                "cs.FL",
                "cs.DM",
                "math.CO",
                "math.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16346v1",
            "title": "Small and Dim Target Detection in IR Imagery: A Review",
            "updated": "2023-11-27T22:25:46Z",
            "published": "2023-11-27T22:25:46Z",
            "summary": "While there has been significant progress in object detection using\nconventional image processing and machine learning algorithms, exploring small\nand dim target detection in the IR domain is a relatively new area of study.\nThe majority of small and dim target detection methods are derived from\nconventional object detection algorithms, albeit with some alterations. The\ntask of detecting small and dim targets in IR imagery is complex. This is\nbecause these targets often need distinct features, the background is cluttered\nwith unclear details, and the IR signatures of the scene can change over time\ndue to fluctuations in thermodynamics. The primary objective of this review is\nto highlight the progress made in this field. This is the first review in the\nfield of small and dim target detection in infrared imagery, encompassing\nvarious methodologies ranging from conventional image processing to\ncutting-edge deep learning-based approaches. The authors have also introduced a\ntaxonomy of such approaches. There are two main types of approaches:\nmethodologies using several frames for detection, and single-frame-based\ndetection techniques. Single frame-based detection techniques encompass a\ndiverse range of methods, spanning from traditional image processing-based\napproaches to more advanced deep learning methodologies. Our findings indicate\nthat deep learning approaches perform better than traditional image\nprocessing-based approaches. In addition, a comprehensive compilation of\nvarious available datasets has also been provided. Furthermore, this review\nidentifies the gaps and limitations in existing techniques, paving the way for\nfuture research and development in this area.",
            "author": [
                "Nikhil Kumar",
                "Pravendra Singh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16346v1",
                "http://arxiv.org/pdf/2311.16346v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17076v1",
            "title": "Compositional Chain-of-Thought Prompting for Large Multimodal Models",
            "updated": "2023-11-27T22:23:27Z",
            "published": "2023-11-27T22:23:27Z",
            "summary": "The combination of strong visual backbones and Large Language Model (LLM)\nreasoning has led to Large Multimodal Models (LMMs) becoming the current\nstandard for a wide range of vision and language (VL) tasks. However, recent\nresearch has shown that even the most advanced LMMs still struggle to capture\naspects of compositional visual reasoning, such as attributes and relationships\nbetween objects. One solution is to utilize scene graphs (SGs)--a formalization\nof objects and their relations and attributes that has been extensively used as\na bridge between the visual and textual domains. Yet, scene graph data requires\nscene graph annotations, which are expensive to collect and thus not easily\nscalable. Moreover, finetuning an LMM based on SG data can lead to catastrophic\nforgetting of the pretraining objective. To overcome this, inspired by\nchain-of-thought methods, we propose Compositional Chain-of-Thought (CCoT), a\nnovel zero-shot Chain-of-Thought prompting method that utilizes SG\nrepresentations in order to extract compositional knowledge from an LMM.\nSpecifically, we first generate an SG using the LMM, and then use that SG in\nthe prompt to produce a response. Through extensive experiments, we find that\nthe proposed CCoT approach not only improves LMM performance on several vision\nand language VL compositional benchmarks but also improves the performance of\nseveral popular LMMs on general multimodal benchmarks, without the need for\nfine-tuning or annotated ground-truth SGs.",
            "author": [
                "Chancharik Mitra",
                "Brandon Huang",
                "Trevor Darrell",
                "Roei Herzig"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17076v1",
                "http://arxiv.org/pdf/2311.17076v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16338v1",
            "title": "Releasing the CRaQAn (Coreference Resolution in Question-Answering): An\n  open-source dataset and dataset creation methodology using\n  instruction-following models",
            "updated": "2023-11-27T21:54:50Z",
            "published": "2023-11-27T21:54:50Z",
            "summary": "Instruction-following language models demand robust methodologies for\ninformation retrieval to augment instructions for question-answering\napplications. A primary challenge is the resolution of coreferences in the\ncontext of chunking strategies for long documents. The critical barrier to\nexperimentation of handling coreferences is a lack of open source datasets,\nspecifically in question-answering tasks that require coreference resolution.\nIn this work we present our Coreference Resolution in Question-Answering\n(CRaQAn) dataset, an open-source dataset that caters to the nuanced information\nretrieval requirements of coreference resolution in question-answering tasks by\nproviding over 250 question-answer pairs containing coreferences. To develop\nthis dataset, we developed a novel approach for creating high-quality datasets\nusing an instruction-following model (GPT-4) and a Recursive Criticism and\nImprovement Loop.",
            "author": [
                "Rob Grzywinski",
                "Joshua D'Arcy",
                "Rob Naidoff",
                "Ashish Shukla",
                "Alex Browne",
                "Ren Gibbons",
                "Brinnae Bent"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16338v1",
                "http://arxiv.org/pdf/2311.16338v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16337v2",
            "title": "Multi-3D-Models Registration-Based Augmented Reality (AR) Instructions\n  for Assembly",
            "updated": "2023-11-29T03:24:31Z",
            "published": "2023-11-27T21:53:17Z",
            "summary": "This paper introduces a novel, markerless, step-by-step, in-situ 3D Augmented\nReality (AR) instruction method and its application - BRICKxAR (Multi 3D\nModels/M3D) - for small parts assembly. BRICKxAR (M3D) realistically visualizes\nrendered 3D assembly parts at the assembly location of the physical assembly\nmodel (Figure 1). The user controls the assembly process through a user\ninterface. BRICKxAR (M3D) utilizes deep learning-trained 3D model-based\nregistration. Object recognition and tracking become challenging as the\nassembly model updates at each step. Additionally, not every part in a 3D\nassembly may be visible to the camera during the assembly. BRICKxAR (M3D)\ncombines multiple assembly phases with a step count to address these\nchallenges. Thus, using fewer phases simplifies the complex assembly process\nwhile step count facilitates accurate object recognition and precise\nvisualization of each step. A testing and heuristic evaluation of the BRICKxAR\n(M3D) prototype and qualitative analysis were conducted with users and experts\nin visualization and human-computer interaction. Providing robust 3D AR\ninstructions and allowing the handling of the assembly model, BRICKxAR (M3D)\nhas the potential to be used at different scales ranging from manufacturing\nassembly to construction.",
            "author": [
                "Seda Tuzun Canadinc",
                "Wei Yan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16337v2",
                "http://arxiv.org/pdf/2311.16337v2"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.01521v1",
            "title": "Neural Markov Prolog",
            "updated": "2023-11-27T21:41:47Z",
            "published": "2023-11-27T21:41:47Z",
            "summary": "The recent rapid advance of AI has been driven largely by innovations in\nneural network architectures. A concomitant concern is how to understand these\nresulting systems. In this paper, we propose a tool to assist in both the\ndesign of further innovative architectures and the simple yet precise\ncommunication of their structure. We propose the language Neural Markov Prolog\n(NMP), based on both Markov logic and Prolog, as a means to both bridge first\norder logic and neural network design and to allow for the easy generation and\npresentation of architectures for images, text, relational databases, or other\ntarget data types or their mixtures.",
            "author": [
                "Alexander Thomson",
                "David Page"
            ],
            "link": [
                "http://arxiv.org/abs/2312.01521v1",
                "http://arxiv.org/pdf/2312.01521v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG",
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16335v1",
            "title": "Zero-field spin wave turns",
            "updated": "2023-11-27T21:38:23Z",
            "published": "2023-11-27T21:38:23Z",
            "summary": "Spin-wave computing, a potential successor to CMOS-based technologies, relies\non the efficient manipulation of spin waves for information processing. While\nbasic logic devices like magnon transistors, gates, and adders have been\nexperimentally demonstrated, the challenge for complex magnonic circuits lies\nin steering spin waves through sharp turns. In this study we demonstrate with\nmicromagnetic simulations and Brillouin light scattering microscopy\nexperiments, that dipolar spin waves can propagate through 90-degree turns\nwithout distortion. The key lies in carefully designed in-plane magnetization\nlandscapes, addressing challenges posed by anisotropic dispersion. The\nexperimental realization of the required magnetization landscape is enabled by\nspatial manipulation of the uniaxial anisotropy using corrugated magnonic\nwaveguides. The findings presented in this work should be considered in any\nmagnonic circuit design dealing with anisotropic dispersion and spin wave\nturns.",
            "author": [
                "Jan Kl\u00edma",
                "Ond\u0159ej Wojewoda",
                "V\u00e1clav Rou\u010dka",
                "Tom\u00e1\u0161 Moln\u00e1r",
                "Jakub Holobr\u00e1dek",
                "Michal Urb\u00e1nek"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16335v1",
                "http://arxiv.org/pdf/2311.16335v1"
            ],
            "primary_category": "cond-mat.mes-hall",
            "category": [
                "cond-mat.mes-hall",
                "physics.app-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16334v2",
            "title": "Robust Basket Recommendation via Noise-tolerated Graph Contrastive\n  Learning",
            "updated": "2023-12-01T02:07:06Z",
            "published": "2023-11-27T21:38:10Z",
            "summary": "The growth of e-commerce has seen a surge in popularity of platforms like\nAmazon, eBay, and Taobao. This has given rise to a unique shopping behavior\ninvolving baskets - sets of items purchased together. As a less studied\ninteraction mode in the community, the question of how should shopping basket\ncomplement personalized recommendation systems remains under-explored. While\nprevious attempts focused on jointly modeling user purchases and baskets, the\ndistinct semantic nature of these elements can introduce noise when directly\nintegrated. This noise negatively impacts the model's performance, further\nexacerbated by significant noise (e.g., a user is misled to click an item or\nrecognizes it as uninteresting after consuming it) within both user and basket\nbehaviors. In order to cope with the above difficulties, we propose a novel\nBasket recommendation framework via Noise-tolerated Contrastive Learning, named\nBNCL, to handle the noise existing in the cross-behavior integration and\nwithin-behavior modeling. First, we represent the basket-item interactions as\nthe hypergraph to model the complex basket behavior, where all items appearing\nin the same basket are treated as a single hyperedge. Second, cross-behavior\ncontrastive learning is designed to suppress the noise during the fusion of\ndiverse behaviors. Next, to further inhibit the within-behavior noise of the\nuser and basket interactions, we propose to exploit invariant properties of the\nrecommenders w.r.t augmentations through within-behavior contrastive learning.\nA novel consistency-aware augmentation approach is further designed to better\nidentify noisy interactions with the consideration of the above two types of\ninteractions. Our framework BNCL offers a generic training paradigm that is\napplicable to different backbones. Extensive experiments on three shopping\ntransaction datasets verify the effectiveness of our proposed method.",
            "author": [
                "Xinrui He",
                "Tianxin Wei",
                "Jingrui He"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3583780.3615039",
                "http://arxiv.org/abs/2311.16334v2",
                "http://arxiv.org/pdf/2311.16334v2"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16329v1",
            "title": "Evidence of Indium impurity band in superconducting (Sn,In)Te thin films",
            "updated": "2023-11-27T21:33:35Z",
            "published": "2023-11-27T21:33:35Z",
            "summary": "Sn1-xInxTe has been synthesized and studied recently as a candidate\ntopological superconductor. Its superconducting critical temperature increases\nwith Indium concentration. However, the role of Indium in altering the normal\nstate band structure and generating superconductivity is not well-understood.\nHere, we explore this question in Sn1-xInxTe (0<x<0.3) thin films,\ncharacterized by magneto-transport, infrared transmission and photoemission\nspectroscopy measurement. We show that Indium is forming an impurity band below\nthe valence band edge which pins the Fermi energy and effectively generates\nelectron doping. An enhanced density-of-states due to this impurity band leads\nto the enhancement of superconducting transition temperature measured in\nmultiple previous studies. The existence of the In impurity band and the role\nof In as a resonant impurity should be more carefully considered when\ndiscussing the topological nature of Sn1-xInxTe.",
            "author": [
                "Jiashu Wang",
                "Trisha Musall",
                "Bo-An Chen",
                "Marie Gerges",
                "Sylwia Ptasinska",
                "Xinyu Liu",
                "Badih A. Assaf"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16329v1",
                "http://arxiv.org/pdf/2311.16329v1"
            ],
            "primary_category": "cond-mat.supr-con",
            "category": [
                "cond-mat.supr-con"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16326v1",
            "title": "Atomic Cluster Expansion for semilocal interactions beyond equivariant\n  message passing",
            "updated": "2023-11-27T21:19:55Z",
            "published": "2023-11-27T21:19:55Z",
            "summary": "We extend the basis functions of the Atomic Cluster Expansion to graphs. This\nnaturally leads to a representation that enables us to describe semilocal\ninteractions in physiscally and chemically transparent form. Simplifications of\nthe graph Atomic Cluster Expansion recover the currently most accurate\nmessage-passing representations of atomic interactions. We demonstrate the\naccuracy and efficiency of our expansion for a number of small molecules,\nclusters and a general-purpose model for carbon.",
            "author": [
                "Anton Bochkarev",
                "Yury Lysogorskiy",
                "Ralf Drautz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16326v1",
                "http://arxiv.org/pdf/2311.16326v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16321v1",
            "title": "A Ceph S3 Object Data Store for HEP",
            "updated": "2023-11-27T21:10:52Z",
            "published": "2023-11-27T21:10:52Z",
            "summary": "We present a novel data format design that obviates the need for data tiers\nby storing individual event data products in column objects. The objects are\nstored and retrieved through Ceph S3 technology, with a layout designed to\nminimize metadata volume and maximize data processing parallelism. Performance\nbenchmarks of data storage and retrieval are presented.",
            "author": [
                "Nick Smith",
                "Bo Jayatilaka",
                "David Mason",
                "Oliver Gutsche",
                "Alison Peisker",
                "Robert Illingworth",
                "Chris Jones"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16321v1",
                "http://arxiv.org/pdf/2311.16321v1"
            ],
            "primary_category": "physics.data-an",
            "category": [
                "physics.data-an",
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16317v1",
            "title": "A generating function perspective on the transmission forest",
            "updated": "2023-11-27T21:06:07Z",
            "published": "2023-11-27T21:06:07Z",
            "summary": "In a previous paper, we showed that a compartmental stochastic process model\nof SARS-CoV-2 transmission could be fit to time series data and then\nreinterpreted as a collection of interacting branching processes drawn from a\ndynamic degree distribution. We called this reinterpretation a transmission\nforest. This paper builds on that idea. Specifically, leveraging generating\nfunction methods from analytic combinatorics, we develop a theory describing\nthe transmission forest's properties, allowing us to show for example that\ntransmission tree interactions fade with increasing disease prevalence. We then\nvalidate the theory by computing forest statistics, like the tree survival\nfunction, which we compare to estimates based on the sampling method developed\npreviously. The accuracy and flexibility of the analytic approach is clear, and\nit allows us to comment on multi-scale features of more general transmission\nprocesses.",
            "author": [
                "Niket Thakkar",
                "Mike Famulare"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16317v1",
                "http://arxiv.org/pdf/2311.16317v1"
            ],
            "primary_category": "q-bio.PE",
            "category": [
                "q-bio.PE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.03730v1",
            "title": "FakeWatch ElectionShield: A Benchmarking Framework to Detect Fake News\n  for Credible US Elections",
            "updated": "2023-11-27T21:01:21Z",
            "published": "2023-11-27T21:01:21Z",
            "summary": "In today's technologically driven world, the spread of fake news,\nparticularly during crucial events such as elections, presents an increasing\nchallenge to the integrity of information. To address this challenge, we\nintroduce FakeWatch ElectionShield, an innovative framework carefully designed\nto detect fake news. We have created a novel dataset of North American\nelection-related news articles through a blend of advanced language models\n(LMs) and thorough human verification, for precision and relevance. We propose\na model hub of LMs for identifying fake news. Our goal is to provide the\nresearch community with adaptable and accurate classification models in\nrecognizing the dynamic nature of misinformation. Extensive evaluation of fake\nnews classifiers on our dataset and a benchmark dataset shows our that while\nstate-of-the-art LMs slightly outperform the traditional ML models, classical\nmodels are still competitive with their balance of accuracy, explainability,\nand computational efficiency. This research sets the foundation for future\nstudies to address misinformation related to elections.",
            "author": [
                "Tahniat Khan",
                "Mizanur Rahman",
                "Veronica Chatrath",
                "Oluwanifemi Bamgbose",
                "Shaina Raza"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03730v1",
                "http://arxiv.org/pdf/2312.03730v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16311v1",
            "title": "Characterizing Video Question Answering with Sparsified Inputs",
            "updated": "2023-11-27T21:00:20Z",
            "published": "2023-11-27T21:00:20Z",
            "summary": "In Video Question Answering, videos are often processed as a full-length\nsequence of frames to ensure minimal loss of information. Recent works have\ndemonstrated evidence that sparse video inputs are sufficient to maintain high\nperformance. However, they usually discuss the case of single frame selection.\nIn our work, we extend the setting to multiple number of inputs and other\nmodalities. We characterize the task with different input sparsity and provide\na tool for doing that. Specifically, we use a Gumbel-based learnable selection\nmodule to adaptively select the best inputs for the final task. In this way, we\nexperiment over public VideoQA benchmarks and provide analysis on how\nsparsified inputs affect the performance. From our experiments, we have\nobserved only 5.2%-5.8% loss of performance with only 10% of video lengths,\nwhich corresponds to 2-4 frames selected from each video. Meanwhile, we also\nobserved the complimentary behaviour between visual and textual inputs, even\nunder highly sparsified settings, suggesting the potential of improving data\nefficiency for video-and-language tasks.",
            "author": [
                "Shiyuan Huang",
                "Robinson Piramuthu",
                "Vicente Ordonez",
                "Shih-Fu Chang",
                "Gunnar A. Sigurdsson"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16311v1",
                "http://arxiv.org/pdf/2311.16311v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16308v1",
            "title": "Compression-based inference of network motif sets",
            "updated": "2023-11-27T20:49:11Z",
            "published": "2023-11-27T20:49:11Z",
            "summary": "Physical and functional constraints on biological networks lead to complex\ntopological patterns across multiple scales in their organization. A particular\ntype of higher-order network feature that has received considerable interest is\nnetwork motifs, defined as statistically regular subgraphs. These may implement\nfundamental logical and computational circuits and are referred as ``building\nblocks of complex networks''. Their well-defined structures and small sizes\nalso enables the testing of their functions in synthetic and natural biological\nexperiments. The statistical inference of network motifs is however fraught\nwith difficulties, from defining and sampling the right null model to\naccounting for the large number of possible motifs and their potential\ncorrelations in statistical testing. Here we develop a framework for motif\nmining based on lossless network compression using subgraph contractions. The\nminimum description length principle allows us to select the most significant\nset of motifs as well as other prominent network features in terms of their\ncombined compression of the network. The approach inherently accounts for\nmultiple testing and correlations between subgraphs and does not rely on a\npriori specification of an appropriate null model. This provides an alternative\ndefinition of motif significance which guarantees more robust statistical\ninference. Our approach overcomes the common problems in classic testing-based\nmotif analysis. We apply our methodology to perform comparative connectomics by\nevaluating the compressibility and the circuit motifs of a range of\nsynaptic-resolution neural connectomes.",
            "author": [
                "Alexis B\u00e9nichou",
                "Jean-Baptiste Masson",
                "Christian L. Vestergaard"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16308v1",
                "http://arxiv.org/pdf/2311.16308v1"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM",
                "cond-mat.stat-mech",
                "cs.SI",
                "physics.data-an",
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.00188v1",
            "title": "REACT: Recognize Every Action Everywhere All At Once",
            "updated": "2023-11-27T20:48:54Z",
            "published": "2023-11-27T20:48:54Z",
            "summary": "Group Activity Recognition (GAR) is a fundamental problem in computer vision,\nwith diverse applications in sports video analysis, video surveillance, and\nsocial scene understanding. Unlike conventional action recognition, GAR aims to\nclassify the actions of a group of individuals as a whole, requiring a deep\nunderstanding of their interactions and spatiotemporal relationships. To\naddress the challenges in GAR, we present REACT (\\textbf{R}ecognize\n\\textbf{E}very \\textbf{Act}ion Everywhere All At Once), a novel architecture\ninspired by the transformer encoder-decoder model explicitly designed to model\ncomplex contextual relationships within videos, including multi-modality and\nspatio-temporal features. Our architecture features a cutting-edge\nVision-Language Encoder block for integrated temporal, spatial, and multi-modal\ninteraction modeling. This component efficiently encodes spatiotemporal\ninteractions, even with sparsely sampled frames, and recovers essential local\ninformation. Our Action Decoder Block refines the joint understanding of text\nand video data, allowing us to precisely retrieve bounding boxes, enhancing the\nlink between semantics and visual reality. At the core, our Actor Fusion Block\norchestrates a fusion of actor-specific data and textual features, striking a\nbalance between specificity and context. Our method outperforms\nstate-of-the-art GAR approaches in extensive experiments, demonstrating\nsuperior accuracy in recognizing and understanding group activities. Our\narchitecture's potential extends to diverse real-world applications, offering\nempirical evidence of its performance gains. This work significantly advances\nthe field of group activity recognition, providing a robust framework for\nnuanced scene comprehension.",
            "author": [
                "Naga VS Raviteja Chappa",
                "Pha Nguyen",
                "Page Daniel Dobbs",
                "Khoa Luu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00188v1",
                "http://arxiv.org/pdf/2312.00188v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16302v1",
            "title": "Comprehensive Benchmarking of Entropy and Margin Based Scoring Metrics\n  for Data Selection",
            "updated": "2023-11-27T20:33:54Z",
            "published": "2023-11-27T20:33:54Z",
            "summary": "While data selection methods have been studied extensively in active\nlearning, data pruning, and data augmentation settings, there is little\nevidence for the efficacy of these methods in industry scale settings,\nparticularly in low-resource languages. Our work presents ways of assessing\nprospective training examples in those settings for their \"usefulness\" or\n\"difficulty\". We also demonstrate how these measures can be used in selecting\nimportant examples for training supervised machine learning models. We\nprimarily experiment with entropy and Error L2-Norm (EL2N) scores. We use these\nmetrics to curate high quality datasets from a large pool of \\textit{Weak\nSignal Labeled} data, which assigns no-defect high confidence hypotheses during\ninference as ground truth labels. We then conduct training data augmentation\nexperiments using these de-identified datasets and demonstrate that score-based\nselection can result in a 2% decrease in semantic error rate and 4%-7% decrease\nin domain classification error rate when compared to the baseline technique of\nrandom selection.",
            "author": [
                "Anusha Sabbineni",
                "Nikhil Anand",
                "Maria Minakova"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16302v1",
                "http://arxiv.org/pdf/2311.16302v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16298v1",
            "title": "Influence Scores at Scale for Efficient Language Data Sampling",
            "updated": "2023-11-27T20:19:22Z",
            "published": "2023-11-27T20:19:22Z",
            "summary": "Modern ML systems ingest data aggregated from diverse sources, such as\nsynthetic, human-annotated, and live customer traffic. Understanding\n\\textit{which} examples are important to the performance of a learning\nalgorithm is crucial for efficient model training. Recently, a growing body of\nliterature has given rise to various \"influence scores,\" which use training\nartifacts such as model confidence or checkpointed gradients to identify\nimportant subsets of data. However, these methods have primarily been developed\nin computer vision settings, and it remains unclear how well they generalize to\nlanguage-based tasks using pretrained models.\n  In this paper, we explore the applicability of influence scores in language\nclassification tasks. We evaluate a diverse subset of these scores on the SNLI\ndataset by quantifying accuracy changes in response to pruning training data\nthrough random and influence-score-based sampling. We then stress-test one of\nthe scores -- \"variance of gradients\" (VoG) from Agarwal et al. (2022) -- in an\nNLU model stack that was exposed to dynamic user speech patterns in a voice\nassistant type of setting. Our experiments demonstrate that in many cases,\nencoder-based language models can be finetuned on roughly 50% of the original\ndata without degradation in performance metrics. Along the way, we summarize\nlessons learned from applying out-of-the-box implementations of influence\nscores, quantify the effects of noisy and class-imbalanced data, and offer\nrecommendations on score-based sampling for better accuracy and training\nefficiency.",
            "author": [
                "Nikhil Anand",
                "Joshua Tan",
                "Maria Minakova"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16298v1",
                "http://arxiv.org/pdf/2311.16298v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16293v1",
            "title": "FHEmem: A Processing In-Memory Accelerator for Fully Homomorphic\n  Encryption",
            "updated": "2023-11-27T20:11:38Z",
            "published": "2023-11-27T20:11:38Z",
            "summary": "Fully Homomorphic Encryption (FHE) is a technique that allows arbitrary\ncomputations to be performed on encrypted data without the need for decryption,\nmaking it ideal for securing many emerging applications. However, FHE\ncomputation is significantly slower than computation on plain data due to the\nincrease in data size after encryption. Processing In-Memory (PIM) is a\npromising technology that can accelerate data-intensive workloads with\nextensive parallelism. However, FHE is challenging for PIM acceleration due to\nthe long-bitwidth multiplications and complex data movements involved. We\npropose a PIM-based FHE accelerator, FHEmem, which exploits a novel processing\nin-memory architecture to achieve high-throughput and efficient acceleration\nfor FHE. We propose an optimized end-to-end processing flow, from low-level\nhardware processing to high-level application mapping, that fully exploits the\nhigh throughput of FHEmem hardware. Our evaluation shows FHEmem achieves\nsignificant speedup and efficiency improvement over state-of-the-art FHE\naccelerators.",
            "author": [
                "Minxuan Zhou",
                "Yujin Nam",
                "Pranav Gangwar",
                "Weihong Xu",
                "Arpan Dutta",
                "Kartikeyan Subramanyam",
                "Chris Wilkerson",
                "Rosario Cammarota",
                "Saransh Gupta",
                "Tajana Rosing"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16293v1",
                "http://arxiv.org/pdf/2311.16293v1"
            ],
            "primary_category": "cs.AR",
            "category": [
                "cs.AR",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16292v1",
            "title": "Student Mastery or AI Deception? Analyzing ChatGPT's Assessment\n  Proficiency and Evaluating Detection Strategies",
            "updated": "2023-11-27T20:10:13Z",
            "published": "2023-11-27T20:10:13Z",
            "summary": "Generative AI systems such as ChatGPT have a disruptive effect on learning\nand assessment. Computer science requires practice to develop skills in problem\nsolving and programming that are traditionally developed using assignments.\nGenerative AI has the capability of completing these assignments for students\nwith high accuracy, which dramatically increases the potential for academic\nintegrity issues and students not achieving desired learning outcomes. This\nwork investigates the performance of ChatGPT by evaluating it across three\ncourses (CS1,CS2,databases). ChatGPT completes almost all introductory\nassessments perfectly. Existing detection methods, such as MOSS and JPlag\n(based on similarity metrics) and GPTzero (AI detection), have mixed success in\nidentifying AI solutions. Evaluating instructors and teaching assistants using\nheuristics to distinguish between student and AI code shows that their\ndetection is not sufficiently accurate. These observations emphasize the need\nfor adapting assessments and improved detection methods.",
            "author": [
                "Kevin Wang",
                "Seth Akins",
                "Abdallah Mohammed",
                "Ramon Lawrence"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16292v1",
                "http://arxiv.org/pdf/2311.16292v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16291v1",
            "title": "Frame Change Technique for Phase Transient Cancellation",
            "updated": "2023-11-27T20:08:01Z",
            "published": "2023-11-27T20:08:01Z",
            "summary": "The precise control of complex quantum mechanical systems can unlock\napplications ranging from quantum simulation to quantum computation.\nControlling strongly interacting many-body systems often relies on Floquet\nHamiltonian engineering that is achieved by fast switching between Hamiltonian\nprimitives via external control. For example, in our solid-state NMR system, we\nperform quantum simulation by modulating the natural Hamiltonian with control\npulses. As the Floquet heating errors scale with the interpulse delay, $\\delta\nt$, it is favorable to keep $\\delta t$ as short as possible, forcing our\ncontrol pulses to be short duration and high power. Additionally, high-power\npulses help to minimize undesirable evolution from occurring during the\nduration of the pulse. However, such pulses introduce an appreciable\nphase-transient control error, a form of unitary error. In this work, we detail\nour ability to diagnose the error, calibrate its magnitude, and correct it for\n$\\pi/2$-pulses of arbitrary phase. We demonstrate the improvements gained by\ncorrecting for the phase transient error, using a method which we call the\n``frame-change technique'', in a variety of experimental settings of interest.\nGiven that the correction mechanism adds no real control overhead, we recommend\nthat any resonance probe be checked for these phase transient control errors,\nand correct them using the frame-change technique.",
            "author": [
                "Andrew Stasiuk",
                "Pai Peng",
                "Garrett Heller",
                "Paola Cappellaro"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16291v1",
                "http://arxiv.org/pdf/2311.16291v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16290v1",
            "title": "Lightcone Hamiltonian for Ising Field Theory I: T < T_c",
            "updated": "2023-11-27T20:06:52Z",
            "published": "2023-11-27T20:06:52Z",
            "summary": "We study 2d Ising Field Theory (IFT) in the low-temperature phase in\nlightcone quantization, and show that integrating out zero modes generates a\nvery compact form for the effective lightcone interaction that depends on the\nfinite volume vacuum expectation value of the $\\sigma$ operator. This form is\nmost naturally understood in a conformal basis for the lightcone Hilbert space.\nWe further verify that this simple form reproduces to high accuracy results for\nthe spectra, the $c$-function, and the form-factors from integrability methods\nfor the magnetic deformation of IFT. For generic non-integrable values of\nparameters we also compute the above observables and compare our numeric\nresults to those of equal-time truncation. In particular, we report on new\nmeasurements of various bound-state form-factors as well as the stress-tensor\nspectral density. We find that the stress tensor spectral density provides\nadditional evidence that certain resonances of IFT are surprisingly narrow,\neven at generic strong coupling. Explicit example code for constructing the\neffective Hamiltonian is included in an appendix.",
            "author": [
                "A. Liam Fitzpatrick",
                "Emanuel Katz",
                "Yuan Xin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16290v1",
                "http://arxiv.org/pdf/2311.16290v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16286v1",
            "title": "A statistical approach to latent dynamic modeling with differential\n  equations",
            "updated": "2023-11-27T20:02:55Z",
            "published": "2023-11-27T20:02:55Z",
            "summary": "Ordinary differential equations (ODEs) can provide mechanistic models of\ntemporally local changes of processes, where parameters are often informed by\nexternal knowledge. While ODEs are popular in systems modeling, they are less\nestablished for statistical modeling of longitudinal cohort data, e.g., in a\nclinical setting. Yet, modeling of local changes could also be attractive for\nassessing the trajectory of an individual in a cohort in the immediate future\ngiven its current status, where ODE parameters could be informed by further\ncharacteristics of the individual. However, several hurdles so far limit such\nuse of ODEs, as compared to regression-based function fitting approaches. The\npotentially higher level of noise in cohort data might be detrimental to ODEs,\nas the shape of the ODE solution heavily depends on the initial value. In\naddition, larger numbers of variables multiply such problems and might be\ndifficult to handle for ODEs. To address this, we propose to use each\nobservation in the course of time as the initial value to obtain multiple local\nODE solutions and build a combined estimator of the underlying dynamics. Neural\nnetworks are used for obtaining a low-dimensional latent space for dynamic\nmodeling from a potentially large number of variables, and for obtaining\npatient-specific ODE parameters from baseline variables. Simultaneous\nidentification of dynamic models and of a latent space is enabled by recently\ndeveloped differentiable programming techniques. We illustrate the proposed\napproach in an application with spinal muscular atrophy patients and a\ncorresponding simulation study. In particular, modeling of local changes in\nhealth status at any point in time is contrasted to the interpretation of\nfunctions obtained from a global regression. This more generally highlights how\ndifferent application settings might demand different modeling strategies.",
            "author": [
                "Maren Hackenberg",
                "Astrid Pechmann",
                "Clemens Kreutz",
                "Janbernd Kirschner",
                "Harald Binder"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16286v1",
                "http://arxiv.org/pdf/2311.16286v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "cs.LG",
                "stat.AP",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16284v1",
            "title": "Simultaneous Energy Harvesting and Hand Gesture Recognition in Large\n  Area Monolithic Dye-Sensitized Solar Cells",
            "updated": "2023-11-27T19:57:38Z",
            "published": "2023-11-27T19:57:38Z",
            "summary": "Internet of Things (IoT) devices have become prevalent, embedding\nintelligence into our environment. It is projected that over 75 billion IoT\ndevices will be connected by 2025 worldwide, with the majority being operated\nindoors. Dye-sensitized solar cells (DSSC) have recently been optimized for\nambient light, having the capabilities of providing sufficient energy for\nself-powered IoT devices. Interaction with digital technologies, termed Human\nComputer Interaction (HCI), is often achieved via physical mechanisms (e.g.\nremote controls, cell phones) which can hinder the natural interface between\nusers and IoT devices, a key consideration for HCI. What if the solar cell that\nis powering the IoT device can also recognize hand gestures which would allow\nthe user to naturally interact with the system? Previous attempts to achieve\nthis have necessarily employed an array of solar cell/photodiodes to detect\ndirectionality. In this work, we demonstrate that by monitoring the\nphotocurrent output of an asymmetrically patterned monolithic (i.e., single\ncell) DSSC, and using machine learning, we can recognize simple hand gestures,\nachieving an accuracy prediction of 97.71%. This work shows that, DSSCs are the\nperfect choice for self-powered interactive technologies, both in terms of\npowering IoT devices in ambient light conditions and having aesthetic qualities\nthat are prioritized by users. As well as powering interactive technologies,\nthey can also provide a means of interactive control.",
            "author": [
                "Gethin Thomas",
                "Adam Pockett",
                "Kris Seunarine",
                "Matt Carnie"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16284v1",
                "http://arxiv.org/pdf/2311.16284v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "cs.HC",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16267v1",
            "title": "Applications of Large Language Models in Data Processing: Innovative\n  Approaches to Segmenting and Renewing Information",
            "updated": "2023-11-27T19:17:39Z",
            "published": "2023-11-27T19:17:39Z",
            "summary": "Our paper investigates effective methods for code generation in\n\"specific-domain\" applications, including the use of Large Language Models\n(LLMs) for data segmentation and renewal, as well as stimulating deeper\nthinking in LLMs through prompt adjustments. Using a real company product as an\nexample, we provide user manuals, API documentation, and other data. The ideas\ndiscussed in this paper help segment and then convert this data into semantic\nvectors to better reflect their true positioning. Subsequently, user\nrequirements are transformed into vectors to retrieve the most relevant\ncontent, achieving about 70% accuracy in simple to medium-complexity tasks\nthrough various prompt techniques. This paper is the first to enhance\nspecific-domain code generation effectiveness from this perspective.\nAdditionally, we experiment with generating more scripts from a limited number\nusing llama2-based fine-tuning to test its effectiveness in professional domain\ncode generation. This is a challenging and promising field, and once achieved,\nit will not only lead to breakthroughs in LLM development across multiple\nindustries but also enable LLMs to understand and learn any new knowledge\neffectively.",
            "author": [
                "Yu-Chen Lin",
                "Akhilesh Kumar",
                "Wen-Liang Zhang",
                "Norman Chang",
                "Muhammad Zakir",
                "Rucha Apte",
                "Chao Wang",
                "Jyh-Shing Roger Jang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16267v1",
                "http://arxiv.org/pdf/2311.16267v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16263v1",
            "title": "MinIndy: Uma Ferramenta de In\u00edcio R\u00e1pido do Hyperledger Indy",
            "updated": "2023-11-27T19:11:58Z",
            "published": "2023-11-27T19:11:58Z",
            "summary": "The Hyperledger Indy blockchain platform, aimed at identity management\nnetworks, has gained importance, but instantiating a complete network is\ncomplex and requires experience. Therefore, the present work describes MinIndy,\na tool designed to simplify the installation and configuration of Hyperledger\nIndy networks. This simplification will allow people with a lower level of\nexpertise to create their Indy networks. Which makes it a viable alternative\nfor organizations looking to adopt Hyperledger Indy Blockchain networks with\nless effort.",
            "author": [
                "Alan Veloso",
                "Jeffson Sousa",
                "Bruno Evaristo",
                "Ant\u00f4nio Abel\u00e9m"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16263v1",
                "http://arxiv.org/pdf/2311.16263v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16258v1",
            "title": "An Exploration of Left-Corner Transformations",
            "updated": "2023-11-27T19:04:37Z",
            "published": "2023-11-27T19:04:37Z",
            "summary": "The left-corner transformation (Rosenkrantz and Lewis, 1970) is used to\nremove left recursion from context-free grammars, which is an important step\ntowards making the grammar parsable top-down with simple techniques. This paper\ngeneralizes prior left-corner transformations to support semiring-weighted\nproduction rules and to provide finer-grained control over which left corners\nmay be moved. Our generalized left-corner transformation (GLCT) arose from\nunifying the left-corner transformation and speculation transformation (Eisner\nand Blatz, 2007), originally for logic programming. Our new transformation and\nspeculation define equivalent weighted languages. Yet, their derivation trees\nare structurally different in an important way: GLCT replaces left recursion\nwith right recursion, and speculation does not. We also provide several\ntechnical results regarding the formal relationships between the outputs of\nGLCT, speculation, and the original grammar. Lastly, we empirically investigate\nthe efficiency of GLCT for left-recursion elimination from grammars of nine\nlanguages.",
            "author": [
                "Andreas Opedal",
                "Eleftheria Tsipidi",
                "Tiago Pimentel",
                "Ryan Cotterell",
                "Tim Vieira"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16258v1",
                "http://arxiv.org/pdf/2311.16258v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.DS",
                "cs.FL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16254v1",
            "title": "Removing NSFW Concepts from Vision-and-Language Models for Text-to-Image\n  Retrieval and Generation",
            "updated": "2023-11-27T19:02:17Z",
            "published": "2023-11-27T19:02:17Z",
            "summary": "Vision-and-Language models such as CLIP have demonstrated remarkable\neffectiveness across a wide range of tasks. However, these models are typically\ntrained on web-scale data, which can introduce inappropriate content and lead\nto the development of unsafe and biased behavior. This, in turn, hampers their\napplicability in sensitive and trustworthy contexts and could raise significant\nconcern in their adoption. To overcome these limitations, we introduce a\nmethodology to make Vision-and-Language models safer by removing their\nsensitivity to not-safe-for-work concepts. We show how this can be done by\ndistilling from a large language model which converts between safe and unsafe\nsentences and which is fine-tuned starting from just 100 manually-curated\npairs. We conduct extensive experiments on the resulting embedding space for\nboth retrieval and text-to-image generation, where we show that our model can\nalso be properly employed with pre-trained image generators. Our source code\nand trained models are available at: https://github.com/aimagelab/safe-clip.",
            "author": [
                "Samuele Poppi",
                "Tobia Poppi",
                "Federico Cocchi",
                "Marcella Cornia",
                "Lorenzo Baraldi",
                "Rita Cucchiara"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16254v1",
                "http://arxiv.org/pdf/2311.16254v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16252v1",
            "title": "Mock Modularity In CHL Models",
            "updated": "2023-11-27T19:01:48Z",
            "published": "2023-11-27T19:01:48Z",
            "summary": "Dabholkar, Murthy and Zagier (DMZ) proved that there is a canonical\ndecomposition of a meromorphic Jacobi form of integral index for\n$\\mathrm{SL}(2, \\mathbb{Z})$ with poles on torsion points\n$z\\in\\mathbb{Q}\\tau+\\mathbb{Q}$ into polar and finite parts, and showed that\nthe finite part is a mock Jacobi form. In this paper we generalize the results\nof DMZ to meromorphic Jacobi forms of rational index for congruence subgroups\nof $\\mathrm{SL}(2, \\mathbb{Z})$. As an application, we establish that a large\nclass of single-centered black hole degeneracies in CHL models are given by the\nFourier coefficients of mock Jacobi forms. In this process we refine the result\nof DMZ regarding the set of charges for which the single-centered black hole\ndegeneracies are given by a mock modular form. In particular, in the case\nstudied by DMZ, we present examples of charges for which the single-centered\ndegeneracies are not captured by the mock modular form of the expected index.",
            "author": [
                "Ajit Bhand",
                "Ashoke Sen",
                "Ranveer Kumar Singh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16252v1",
                "http://arxiv.org/pdf/2311.16252v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th",
                "math.NT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16245v1",
            "title": "Underluminous Type Ia supernovae are standardizable candles",
            "updated": "2023-11-27T19:00:26Z",
            "published": "2023-11-27T19:00:26Z",
            "summary": "It is widely accepted that the width-luminosity relation used to standardize\nnormal Type Ia supernovae (SNe Ia) breaks down in underluminous, 1991bg-like\nSNe Ia. This breakdown may be due to the choice of parameter used as a stand-in\nfor the width of the SN Ia light curve. Using the colour stretch parameter\n$s_\\mathrm{BV}$ instead of older parameters resolves this issue. Here, I\nassemble a sample of 13 nearby 1991bg-like SNe Ia from the literature, all of\nwhich have independent host-galaxy distance moduli and little to no reddening.\nI use Gaussian process regression to fit the light curves of these SNe in\n$U/u$, $g$, $B$, $V$, $R/r$, and $I/i$, and measure their peak absolute\nmagnitudes. I find statistically significant ($>5\\sigma$ confidence level)\ncorrelations between the peak absolute magnitudes of the underluminous SNe and\ntheir $s_\\mathrm{BV}$ values in the range $0.2<s_\\mathrm{BV}<0.6$. These\ncorrelations are broadly consistent with fits to $s_\\mathrm{BV}<0.7$ SNe Ia\nwith preliminary $B$- and $V$-band peak absolute magnitudes from the Carnegie\nSupernova Project and significantly inconsistent with similar fits to normal\nand transitional SNe Ia (with $0.7<s_\\mathrm{BV}<1.1$). The underluminous\nwidth-luminosity relation shown here needs to be properly calibrated with a\nhomogeneous sample of 1991bg-like SNe Ia, after which it could be used as a\nrung on a new cosmological distance ladder. With surface-brightness\nfluctuations (or another non-Cepheid method) used to calibrate distances to\nnearby 1991bg-like SNe, such a ladder could produce an independent measurement\nof the Hubble-Lema\\^{i}tre Constant, $H_\\mathrm{0}$.",
            "author": [
                "Or Graur"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16245v1",
                "http://arxiv.org/pdf/2311.16245v1"
            ],
            "primary_category": "astro-ph.HE",
            "category": [
                "astro-ph.HE",
                "astro-ph.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16244v1",
            "title": "Black Holes, Cavities and Blinking Islands",
            "updated": "2023-11-27T19:00:22Z",
            "published": "2023-11-27T19:00:22Z",
            "summary": "Placing a black hole in a cavity is known to be a natural way to study\ndifferent scales in gravity, issues related to the thermodynamic instability\nand gravity effective theories. In this paper, we consider the evolution of the\nentanglement entropy and entanglement islands in the two-sided generalization\nof the Schwarzschild black hole in a cavity. Introducing a reflecting boundary\nin the eternal black exteriors we regulate infrared modes of Hawking radiation\nand find that entanglement entropy saturates at some constant value. This value\ncould be lower than black hole thermodynamic entropy, thus not leading to Page\nformulation of information paradox. Concerning the entanglement islands, we\nfind a universal effect induced by the boundary presence, which we call\n``blinking island\" -- for some time the entanglement island inevitably\ndisappears, thus leading to a short-time information paradox.",
            "author": [
                "Dmitry S. Ageev",
                "Irina Ya. Aref'eva",
                "Timofei A. Rusalev"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16244v1",
                "http://arxiv.org/pdf/2311.16244v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th",
                "gr-qc",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16243v1",
            "title": "On the nature of the ultraluminous X-ray source Holmberg II X-1",
            "updated": "2023-11-27T19:00:10Z",
            "published": "2023-11-27T19:00:10Z",
            "summary": "We present a comprehensive spectral analysis of the ultraluminous X-ray\nsource Holmberg II X-1 using broadband and high-resolution X-ray spectra taken\nwith the XMM-Newton satellite over a period of 19 years benefiting from a\nrecent campaign. We tested several models for the broadband spectra among which\na double thermal component provided a reasonable description for the continuum\nbetween 0.3-10 keV and enabled us to constrain the properties of the accretion\ndisc. The Luminosity-Temperature trends of the inner and outer disc components\nbroadly agree with the expectations for a thin disc, although the exact values\nof the slopes are slightly sensitive to the adopted model. However, all tested\nmodels show L-T trends which deviate from a power law above a bolometric\nluminosity of about 5 $\\times \\ 10^{39} $erg/s, particularly for the hot\nthermal component associated to the inner accretion flow. Assuming that such\ndeviations are due to the accretion rate exceeding its Eddington limit or, most\nlikely, the super-critical rate, a compact object with a mass 16-36 Msun, i.e.\na stellar-mass black hole, is inferred. The time-averaged (2021) high\nresolution spectra present narrow emission lines at 1 keV primarily from Ne\nIX-X and a very strong at 0.5 keV from N VII, which indicate Ne-N-rich gas with\nnon-Solar abundances. This favours a nitrogen-rich donor star, such as a\nblue/red supergiant, which has escaped from its native stellar cluster\ncharacterised by a low-metallicity environment.",
            "author": [
                "F. Barra",
                "C. Pinto",
                "M. Middleton",
                "T. Di Salvo",
                "D. J. Walton",
                "A. G\u00farpide",
                "T. P. Roberts"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16243v1",
                "http://arxiv.org/pdf/2311.16243v1"
            ],
            "primary_category": "astro-ph.HE",
            "category": [
                "astro-ph.HE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16241v1",
            "title": "SemiVL: Semi-Supervised Semantic Segmentation with Vision-Language\n  Guidance",
            "updated": "2023-11-27T19:00:06Z",
            "published": "2023-11-27T19:00:06Z",
            "summary": "In semi-supervised semantic segmentation, a model is trained with a limited\nnumber of labeled images along with a large corpus of unlabeled images to\nreduce the high annotation effort. While previous methods are able to learn\ngood segmentation boundaries, they are prone to confuse classes with similar\nvisual appearance due to the limited supervision. On the other hand,\nvision-language models (VLMs) are able to learn diverse semantic knowledge from\nimage-caption datasets but produce noisy segmentation due to the image-level\ntraining. In SemiVL, we propose to integrate rich priors from VLM pre-training\ninto semi-supervised semantic segmentation to learn better semantic decision\nboundaries. To adapt the VLM from global to local reasoning, we introduce a\nspatial fine-tuning strategy for label-efficient learning. Further, we design a\nlanguage-guided decoder to jointly reason over vision and language. Finally, we\npropose to handle inherent ambiguities in class labels by providing the model\nwith language guidance in the form of class definitions. We evaluate SemiVL on\n4 semantic segmentation datasets, where it significantly outperforms previous\nsemi-supervised methods. For instance, SemiVL improves the state-of-the-art by\n+13.5 mIoU on COCO with 232 annotated images and by +6.1 mIoU on Pascal VOC\nwith 92 labels. Project page: https://github.com/google-research/semivl",
            "author": [
                "Lukas Hoyer",
                "David Joseph Tan",
                "Muhammad Ferjad Naeem",
                "Luc Van Gool",
                "Federico Tombari"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16241v1",
                "http://arxiv.org/pdf/2311.16241v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17072v1",
            "title": "IG Captioner: Information Gain Captioners are Strong Zero-shot\n  Classifiers",
            "updated": "2023-11-27T19:00:06Z",
            "published": "2023-11-27T19:00:06Z",
            "summary": "Generative training has been demonstrated to be powerful for building\nvisual-language models. However, on zero-shot discriminative benchmarks, there\nis still a performance gap between models trained with generative and\ndiscriminative objectives. In this paper, we aim to narrow this gap by\nimproving the efficacy of generative training on classification tasks, without\nany finetuning processes or additional modules.\n  Specifically, we focus on narrowing the gap between the generative captioner\nand the CLIP classifier. We begin by analysing the predictions made by the\ncaptioner and classifier and observe that the caption generation inherits the\ndistribution bias from the language model trained with pure text modality,\nmaking it less grounded on the visual signal. To tackle this problem, we\nredesign the scoring objective for the captioner to alleviate the\ndistributional bias and focus on measuring the gain of information brought by\nthe visual inputs. We further design a generative training objective to match\nthe evaluation objective. We name our model trained and evaluated from the\nnovel procedures as Information Gain (IG) captioner. We pretrain the models on\nthe public Laion-5B dataset and perform a series of discriminative evaluations.\nFor the zero-shot classification on ImageNet, IG captioner achieves $> 18\\%$\nimprovements over the standard captioner, achieving comparable performances\nwith the CLIP classifier. IG captioner also demonstrated strong performance on\nzero-shot image-text retrieval tasks on MSCOCO and Flickr30K. We hope this\npaper inspires further research towards unifying generative and discriminative\ntraining procedures for visual-language models.",
            "author": [
                "Chenglin Yang",
                "Siyuan Qiao",
                "Yuan Cao",
                "Yu Zhang",
                "Tao Zhu",
                "Alan Yuille",
                "Jiahui Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17072v1",
                "http://arxiv.org/pdf/2311.17072v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16239v1",
            "title": "Euclid Preparation. TBD. Galaxy colour selections with Euclid and ground\n  photometry for cluster weak-lensing analyses",
            "updated": "2023-11-27T19:00:04Z",
            "published": "2023-11-27T19:00:04Z",
            "summary": "We derive galaxy colour selections from Euclid and ground-based photometry,\naiming to accurately define background galaxy samples in cluster weak-lensing\nanalyses. These selections are implemented in the Euclid data analysis\npipelines for galaxy clusters. Given any set of photometric bands, we develop a\nmethod for the calibration of optimal galaxy colour selections that maximises\nthe selection completeness, given a threshold on purity. Such colour selections\nare expressed as a function of the lens redshift. We calibrate galaxy\nselections using ground-based $griz$ and Euclid $Y_{\\rm E}J_{\\rm E}H_{\\rm E}$\nbands. Both selections produce a purity higher than 97%. The $griz$ selection\ncompleteness ranges from 30% to 84% in the lens redshift range $z_{\\rm\nl}\\in[0.2,0.8]$. With the full $grizY_{\\rm E}J_{\\rm E}H_{\\rm E}$ selection, the\ncompleteness improves by up to $25$ percentage points, and the $z_{\\rm l}$\nrange extends up to $z_{\\rm l}=1.5$. The calibrated colour selections are\nstable to changes in the sample limiting magnitudes and redshift, and the\nselection based on $griz$ bands provides excellent results on real and\nsimulated external data sets. Furthermore, the calibrated selections provide\nstable results using alternative photometric aperture definitions obtained from\ndifferent ground-based telescopes. The $griz$ selection is also purer at high\nredshift and more complete at low redshift compared to colour selections found\nin the literature. We show that the calibrated colour selections provide robust\nresults even when observations from a single band are missing from the\nground-based data. Finally, we show that colour selections imply variations\nwithin the 1$\\sigma$ uncertainty in the mean multiplicative shear bias, $m$,\nfor stage III surveys. The first Euclid data releases will provide further\ninsights into the impact of background selections on $m$.",
            "author": [
                "Euclid Collaboration",
                "G. F. Lesci",
                "M. Sereno",
                "M. Radovich",
                "G. Castignani",
                "L. Bisigello",
                "F. Marulli",
                "L. Moscardini",
                "L. Baumont",
                "G. Covone",
                "S. Farrens",
                "C. Giocoli",
                "L. Ingoglia",
                "S. Miranda La Hera",
                "M. Vannier",
                "A. Biviano",
                "S. Maurogordato",
                "N. Aghanim",
                "A. Amara",
                "S. Andreon",
                "N. Auricchio",
                "M. Baldi",
                "S. Bardelli",
                "R. Bender",
                "C. Bodendorf",
                "D. Bonino",
                "E. Branchini",
                "M. Brescia",
                "J. Brinchmann",
                "S. Camera",
                "V. Capobianco",
                "C. Carbone",
                "J. Carretero",
                "S. Casas",
                "F. J. Castander",
                "M. Castellano",
                "S. Cavuoti",
                "A. Cimatti",
                "G. Congedo",
                "C. J. Conselice",
                "L. Conversi",
                "Y. Copin",
                "L. Corcione",
                "F. Courbin",
                "H. M. Courtois",
                "A. Da Silva",
                "H. Degaudenzi",
                "A. M. Di Giorgio",
                "J. Dinis",
                "F. Dubath",
                "C. A. J. Duncan",
                "X. Dupac",
                "S. Dusini",
                "M. Farina",
                "S. Ferriol",
                "P. Fosalba",
                "S. Fotopoulou",
                "M. Frailis",
                "E. Franceschi",
                "P. Franzetti",
                "M. Fumana",
                "S. Galeotta",
                "B. Garilli",
                "B. Gillis",
                "A. Grazian",
                "F. Grupp",
                "S. V. H. Haugan",
                "I. Hook",
                "F. Hormuth",
                "A. Hornstrup",
                "P. Hudelot",
                "K. Jahnke",
                "M. K\u00fcmmel",
                "S. Kermiche",
                "A. Kiessling",
                "M. Kilbinger",
                "B. Kubik",
                "M. Kunz",
                "H. Kurki-Suonio",
                "S. Ligori",
                "P. B. Lilje",
                "V. Lindholm",
                "I. Lloro",
                "E. Maiorano",
                "O. Mansutti",
                "O. Marggraf",
                "K. Markovic",
                "N. Martinet",
                "R. Massey",
                "E. Medinaceli",
                "M. Melchior",
                "Y. Mellier",
                "M. Meneghetti",
                "E. Merlin",
                "G. Meylan",
                "M. Moresco",
                "E. Munari",
                "R. Nakajima",
                "S. -M. Niemi",
                "C. Padilla",
                "S. Paltani",
                "F. Pasian",
                "K. Pedersen",
                "V. Pettorino",
                "S. Pires",
                "G. Polenta",
                "M. Poncet",
                "L. A. Popa",
                "L. Pozzetti",
                "F. Raison",
                "R. Rebolo",
                "A. Renzi",
                "J. Rhodes",
                "G. Riccio",
                "E. Romelli",
                "M. Roncarelli",
                "E. Rossetti",
                "R. Saglia",
                "D. Sapone",
                "B. Sartoris",
                "M. Schirmer",
                "P. Schneider",
                "A. Secroun",
                "G. Seidel",
                "S. Serrano",
                "C. Sirignano",
                "G. Sirri",
                "J. Skottfelt",
                "L. Stanco",
                "J. -L. Starck",
                "P. Tallada-Cresp\u00ed",
                "A. N. Taylor",
                "H. I. Teplitz",
                "I. Tereno",
                "R. Toledo-Moreo",
                "F. Torradeflot",
                "I. Tutusaus",
                "E. A. Valentijn",
                "L. Valenziano",
                "T. Vassallo",
                "A. Veropalumbo",
                "Y. Wang",
                "J. Weller",
                "A. Zacchei",
                "G. Zamorani",
                "J. Zoubian",
                "E. Zucca",
                "M. Bolzonella",
                "E. Bozzo",
                "C. Colodro-Conde",
                "D. Di Ferdinando",
                "J. Graci\u00e1-Carpio",
                "S. Marcin",
                "N. Mauri",
                "C. Neissner",
                "A. A. Nucita",
                "Z. Sakr",
                "V. Scottez",
                "M. Tenti",
                "M. Viel",
                "M. Wiesmann",
                "Y. Akrami",
                "S. Anselmi",
                "C. Baccigalupi",
                "M. Ballardini",
                "S. Borgani",
                "A. S. Borlaff",
                "S. Bruton",
                "C. Burigana",
                "R. Cabanac",
                "A. Calabro",
                "A. Cappi",
                "C. S. Carvalho",
                "T. Castro",
                "G. Ca\u00f1as-Herrera",
                "K. C. Chambers",
                "A. R. Cooray",
                "J. Coupon",
                "O. Cucciati",
                "S. Davini",
                "S. de la Torre",
                "G. De Lucia",
                "G. Desprez",
                "S. Di Domizio",
                "H. Dole",
                "A. D\u00edaz-S\u00e1nchez",
                "J. A. Escartin Vigo",
                "S. Escoffier",
                "I. Ferrero",
                "F. Finelli",
                "L. Gabarra",
                "K. Ganga",
                "J. Garc\u00eda-Bellido",
                "F. Giacomini",
                "G. Gozaliasl",
                "S. Gwyn",
                "H. Hildebrandt",
                "M. Huertas-Company",
                "A. Jimenez Mu\u00f1oz",
                "J. J. E. Kajava",
                "V. Kansal",
                "C. C. Kirkpatrick",
                "L. Legrand",
                "A. Loureiro",
                "J. Macias-Perez",
                "M. Magliocchetti",
                "G. Mainetti",
                "R. Maoli",
                "M. Martinelli",
                "C. J. A. P. Martins",
                "S. Matthew",
                "M. Maturi",
                "L. Maurin",
                "R. B. Metcalf",
                "M. Migliaccio",
                "P. Monaco",
                "G. Morgante",
                "S. Nadathur",
                "L. Patrizii",
                "A. Pezzotta",
                "C. Porciani",
                "D. Potter",
                "M. P\u00f6ntinen",
                "P. Reimberg",
                "P. -F. Rocci",
                "A. G. S\u00e1nchez",
                "A. Schneider",
                "M. Schultheis",
                "E. Sefusatti",
                "P. Simon",
                "A. Spurio Mancini",
                "S. A. Stanford",
                "J. Steinwagner",
                "G. Testera",
                "R. Teyssier",
                "S. Toft",
                "S. Tosi",
                "A. Troja",
                "M. Tucci",
                "J. Valiviita",
                "D. Vergani"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16239v1",
                "http://arxiv.org/pdf/2311.16239v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO",
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16240v1",
            "title": "Quantum hard disks on a lattice",
            "updated": "2023-11-27T19:00:04Z",
            "published": "2023-11-27T19:00:04Z",
            "summary": "Motivated by the recent impressive experimental progress in quantum\nsimulators the study of quantum matter with local constraints has gained\nsignificant attention. In this work, we investigate a paradigmatic class of\nconstrained matter - the hard-disk problem. We introduce a quantum version on\nlattices, which exhibits a natural realization in Rydberg atom arrays due to\nthe Rydberg blockade mechanism. While the static properties on a general level\nturn out to be equivalent to the classical case, yielding crystalline phases at\nsufficiently high particle densities, we find that the dynamical properties are\nfundamentally different. In one dimension, we identify genuine quantum features\nin the melting process of a finite-size crystal displaying ballistic behavior,\nwhereas the classical scenario exhibits sub-diffusion governed by the\nKardar-Parisi-Zhang universality class. On two-dimensional square lattices, we\nshow that in the quantum domain, crystals remain intact against most defects,\nwhereas classically the initial crystal structure is washed out completely. We\nlink this peculiar quantum behavior to the presence of quantum many-body scars,\nbreaking conventional expectations of ergodicity. Our study highlights the\npotential of constrained two-dimensional quantum matter to display unique\ndynamical behaviors.",
            "author": [
                "Vighnesh Dattatraya Naik",
                "Fabian Ballar Trigueros",
                "Markus Heyl"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16240v1",
                "http://arxiv.org/pdf/2311.16240v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cond-mat.stat-mech"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16231v1",
            "title": "Ultraviolet Quasi-periodic Eruptions from Star-Disk Collisions in\n  Galactic Nuclei",
            "updated": "2023-11-27T19:00:01Z",
            "published": "2023-11-27T19:00:01Z",
            "summary": "``Quasi-periodic eruptions'' (QPE) are recurrent nuclear transients with\nperiods of several hours to almost a day, which thus far have been detected\nexclusively in the X-ray band. We have shown that many of the key properties of\nQPE flares (period, luminosity, duration, emission temperature, alternating\nlong-short recurrence time behavior, source rates) are naturally reproduced by\na scenario involving twice-per-orbit collisions between a solar-type star on a\nmildly eccentric orbit, likely brought into the nucleus as an extreme\nmass-ratio inspiral (EMRI), and the gaseous accretion disk of a supermassive\nblack hole (SMBH). The flare is generated by the hot shocked debris expanding\noutwards from either side of the disk midplane, akin to dual miniature\nsupernovae. Here, we consider the conditions necessary for disk-star collisions\nto generate lower-temperature flares which peak in the ultraviolet (UV) instead\nof the X-ray band. We identify a region of parameter space at low SMBH mass\n$M_{\\bullet} \\sim 10^{5.5}M_{\\odot}$ and QPE periods $P \\gtrsim 10$ hr for\nwhich the predicted flares are sufficiently luminous $L_{\\rm UV} \\sim 10^{41}$\nerg s$^{-1}$ to outshine the quiescent disk emission at these wavelengths. The\nprospects to discover such ``UV QPEs'' with future satellite missions such as\nULTRASAT and UVEX depends on the prevalence of very low-mass SMBH and the\noccurrence rate of stellar EMRIs onto them. For gaseous disks produced by the\ntidal disruption of stars, we predict that X-ray QPEs will eventually shut off,\nonly to later reappear as UV-QPEs as the accretion rate continues to drop.",
            "author": [
                "Itai Linial",
                "Brian D. Metzger"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16231v1",
                "http://arxiv.org/pdf/2311.16231v1"
            ],
            "primary_category": "astro-ph.HE",
            "category": [
                "astro-ph.HE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16233v1",
            "title": "C I Traces the Disk Atmosphere in the IM Lup Protoplanetary Disk",
            "updated": "2023-11-27T19:00:01Z",
            "published": "2023-11-27T19:00:01Z",
            "summary": "The central star and its energetic radiation fields play a vital role in\nsetting the vertical and radial chemical structure of planet-forming disks. We\npresent observations that, for the first time, clearly reveal the UV-irradiated\nsurface of a protoplanetary disk. Specifically, we spatially resolve the\natomic-to-molecular (C I-to-CO) transition in the IM Lup disk with ALMA\narchival observations of [C I] $^3$P$_1$-$^3$P$_0$. We derive a C I emitting\nheight of z/r $\\gtrsim$ 0.5 with emission detected out to a radius of\n${\\approx}$600 au. Compared to other systems with C I heights inferred from\nunresolved observations or models, the C I layer in the IM Lup disk is at scale\nheights almost double that of other disks, confirming its highly flared nature.\nC I arises from a narrow, optically-thin layer that is substantially more\nelevated than that of $^{12}$CO (z/r $\\approx$ 0.3-0.4), which allows us to\ndirectly constrain the physical gas conditions across the C I-to-CO transition\nzone. We also compute a radially-resolved C I column density profile and find a\ndisk-averaged C I column density of 2$\\times10^{16}$ cm$^{-2}$, which is\n${\\approx}$3-20$\\times$ lower than that of other disks with spatially-resolved\nC I detections. We do not find evidence for vertical substructures or\nspatially-localized deviations in C I due, e.g., to either an embedded giant\nplanet or a photoevaporative wind that have been proposed in the IM Lup disk,\nbut emphasize that deeper observations are required for robust constraints.",
            "author": [
                "Charles J. Law",
                "Felipe Alarc\u00f3n",
                "L. Ilsedore Cleeves",
                "Karin I. \u00d6berg",
                "Teresa Paneque-Carre\u00f1o"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16233v1",
                "http://arxiv.org/pdf/2311.16233v1"
            ],
            "primary_category": "astro-ph.EP",
            "category": [
                "astro-ph.EP",
                "astro-ph.SR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16218v2",
            "title": "Partition function approach to non-Gaussian likelihoods: macrocanonical\n  partitions and replicating Markov-chains",
            "updated": "2023-11-29T13:57:49Z",
            "published": "2023-11-27T19:00:00Z",
            "summary": "Monte-Carlo techniques are standard numerical tools for exploring\nnon-Gaussian and multivariate likelihoods. Many variants of the original\nMetropolis-Hastings algorithm have been proposed to increase the sampling\nefficiency. Motivated by Ensemble Monte Carlo we allow the number of Markov\nchains to vary by exchanging particles with a reservoir, controlled by a\nparameter analogous to a chemical potential $\\mu$, which effectively\nestablishes a random process that samples microstates from a macrocanonical\ninstead of a canonical ensemble. In this paper, we develop the theory of\nmacrocanonical sampling for statistical inference on the basis of Bayesian\nmacrocanonical partition functions, thereby bringing to light the relations\nbetween information-theoretical quantities and thermodynamic properties.\nFurthermore, we propose an algorithm for macrocanonical sampling,\n$\\texttt{Avalanche Sampling}$, and apply it to various toy problems as well as\nthe likelihood on the cosmological parameters $\\Omega_m$ and $w$ on the basis\nof data from the supernova distance redshift relation.",
            "author": [
                "Maximilian Philipp Herzog",
                "Heinrich von Campe",
                "Rebecca Maria Kuntz",
                "Lennart R\u00f6ver",
                "Bj\u00f6rn Malte Sch\u00e4fer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16218v2",
                "http://arxiv.org/pdf/2311.16218v2"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO",
                "astro-ph.IM",
                "physics.data-an"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16219v1",
            "title": "Principal Landau Determinants",
            "updated": "2023-11-27T19:00:00Z",
            "published": "2023-11-27T19:00:00Z",
            "summary": "We reformulate the Landau analysis of Feynman integrals with the aim of\nadvancing the state of the art in modern particle-physics computations. We\ncontribute new algorithms for computing Landau singularities, using tools from\npolyhedral geometry and symbolic/numerical elimination. Inspired by the work of\nGelfand, Kapranov, and Zelevinsky (GKZ) on generalized Euler integrals, we\ndefine the principal Landau determinant of a Feynman diagram. We illustrate\nwith a number of examples that this algebraic formalism allows to compute many\ncomponents of the Landau singular locus. We adapt the GKZ framework by\ncarefully specializing Euler integrals to Feynman integrals. For instance,\nultraviolet and infrared singularities are detected as irreducible components\nof an incidence variety, which project dominantly to the kinematic space. We\ncompute principal Landau determinants for the infinite families of one-loop and\nbanana diagrams with different mass configurations, and for a range of\ncutting-edge Standard Model processes. Our algorithms build on the Julia\npackage Landau.jl and are implemented in the new open-source package PLD.jl\navailable at https://mathrepo.mis.mpg.de/PLD/.",
            "author": [
                "Claudia Fevola",
                "Sebastian Mizera",
                "Simon Telen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16219v1",
                "http://arxiv.org/pdf/2311.16219v1"
            ],
            "primary_category": "math-ph",
            "category": [
                "math-ph",
                "hep-th",
                "math.AG",
                "math.MP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16222v1",
            "title": "Finite Bubble Statistics Constrain Late Cosmological Phase Transitions",
            "updated": "2023-11-27T19:00:00Z",
            "published": "2023-11-27T19:00:00Z",
            "summary": "We consider first order cosmological phase transitions (PT) happening at late\ntimes, below Standard Model (SM) temperatures $T_{\\rm PT} \\lesssim$ GeV. The\ninherently stochastic nature of bubble nucleation and the finite number of\nbubbles associated with a late-time PT lead to superhorizon fluctuations in the\nPT completion time. We compute how such fluctuations eventually source\ncurvature fluctuations with universal properties, independent of the\nmicrophysics of the PT dynamics. Using Cosmic Microwave Background (CMB) and\nLarge Scale Structure (LSS) measurements, we constrain the energy released in a\ndark-sector PT. For 0.1 eV $\\lesssim T_{\\rm PT} \\lesssim$ keV this constraint\nis stronger than both the current bound from additional neutrino species\n$\\Delta N_{\\rm eff}$, and in some cases, even CMB-S4 projections. Future\nmeasurements of CMB spectral distortions and pulsar timing arrays will also\nprovide competitive sensitivity for keV $\\lesssim T_{\\rm PT} \\lesssim$ GeV.",
            "author": [
                "Gilly Elor",
                "Ryusuke Jinno",
                "Soubhik Kumar",
                "Robert McGehee",
                "Yuhsin Tsai"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16222v1",
                "http://arxiv.org/pdf/2311.16222v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "astro-ph.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16223v1",
            "title": "Mapping quantum circuits to shallow-depth measurement patterns based on\n  graph states",
            "updated": "2023-11-27T19:00:00Z",
            "published": "2023-11-27T19:00:00Z",
            "summary": "The paradigm of measurement-based quantum computing (MBQC) starts from a\nhighly entangled resource state on which unitary operations are executed\nthrough adaptive measurements and corrections ensuring determinism. This is set\nin contrast to the more common quantum circuit model, in which unitary\noperations are directly implemented through quantum gates prior to final\nmeasurements. In this work, we incorporate concepts from MBQC into the circuit\nmodel to create a hybrid simulation technique, permitting us to split any\nquantum circuit into a classically efficiently simulatable Clifford-part and a\nsecond part consisting of a stabilizer state and local (adaptive) measurement\ninstructions, a so-called standard form, which is executed on a quantum\ncomputer. We further process the stabilizer state with the graph state\nformalism, thus enabling a significant decrease in circuit depth for certain\napplications. We show that groups of fully commuting operators can be\nimplemented using fully-parallel, i.e., non-adaptive, measurements within our\nprotocol. In addition, we discuss how such circuits can be implemented in\nconstant quantum depths by employing quantum teleportation. Finally, we\ndemonstrate the utility of our technique on two examples of high practical\nrelevance: the Quantum Approximate Optimization Algorithm (QAOA) and the\nVariational Quantum Eigensolver (VQE).",
            "author": [
                "Thierry Nicolas Kaldenbach",
                "Matthias Heller"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16223v1",
                "http://arxiv.org/pdf/2311.16223v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17071v1",
            "title": "Globular Clusters Contribute to the Nuclear Star Cluster and Galaxy\n  Center Gamma-Ray Excess, Moderated by Galaxy Assembly History",
            "updated": "2023-11-27T19:00:00Z",
            "published": "2023-11-27T19:00:00Z",
            "summary": "Two unresolved questions at galaxy centers, namely the formation of the\nnuclear star cluster (NSC) and the origin of the gamma-ray excess in the Milky\nWay (MW) and Andromeda (M31), are both related to the formation and evolution\nof globular clusters (GCs). They migrate towards the galaxy center due to\ndynamical friction, and get tidally disrupted to release the stellar mass\ncontent including millisecond pulsars (MSPs), which contribute to the NSC and\ngamma-ray excess. In this study, we propose a semi-analytical model of GC\nformation and evolution that utilizes the Illustris cosmological simulation to\naccurately capture the formation epochs of GCs and simulate their subsequent\nevolution. Our analysis confirms that our GC properties at z=0 are consistent\nwith observations, and our model naturally explains the formation of a massive\nNSC in a galaxy similar to the MW and M31. We also find a remarkable similarity\nin our model prediction with the gamma-ray excess signal in the MW. However,\nour predictions fall short by approximately an order of magnitude in M31,\nindicating distinct origins for the two gamma-ray excesses. Meanwhile, we\nutilize the catalog of Illustris halos to investigate the influence of galaxy\nassembly history. We find that the earlier a galaxy is assembled, the heavier\nand spatially more concentrated its GC system behaves at z=0. This results in a\nlarger NSC mass and brighter gamma-ray emission from deposited MSPs",
            "author": [
                "Yuan Gao",
                "Hui Li",
                "Xiaojia Zhang",
                "Meng Su",
                "Stephen Chi Yung Ng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17071v1",
                "http://arxiv.org/pdf/2311.17071v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16103v2",
            "title": "Video-Bench: A Comprehensive Benchmark and Toolkit for Evaluating\n  Video-based Large Language Models",
            "updated": "2023-11-28T18:16:29Z",
            "published": "2023-11-27T18:59:58Z",
            "summary": "Video-based large language models (Video-LLMs) have been recently introduced,\ntargeting both fundamental improvements in perception and comprehension, and a\ndiverse range of user inquiries. In pursuit of the ultimate goal of achieving\nartificial general intelligence, a truly intelligent Video-LLM model should not\nonly see and understand the surroundings, but also possess human-level\ncommonsense, and make well-informed decisions for the users. To guide the\ndevelopment of such a model, the establishment of a robust and comprehensive\nevaluation system becomes crucial. To this end, this paper proposes\n\\textit{Video-Bench}, a new comprehensive benchmark along with a toolkit\nspecifically designed for evaluating Video-LLMs. The benchmark comprises 10\nmeticulously crafted tasks, evaluating the capabilities of Video-LLMs across\nthree distinct levels: Video-exclusive Understanding, Prior Knowledge-based\nQuestion-Answering, and Comprehension and Decision-making. In addition, we\nintroduce an automatic toolkit tailored to process model outputs for various\ntasks, facilitating the calculation of metrics and generating convenient final\nscores. We evaluate 8 representative Video-LLMs using \\textit{Video-Bench}. The\nfindings reveal that current Video-LLMs still fall considerably short of\nachieving human-like comprehension and analysis of real-world videos, offering\nvaluable insights for future research directions. The benchmark and toolkit are\navailable at: \\url{https://github.com/PKU-YuanGroup/Video-Bench}.",
            "author": [
                "Munan Ning",
                "Bin Zhu",
                "Yujia Xie",
                "Bin Lin",
                "Jiaxi Cui",
                "Lu Yuan",
                "Dongdong Chen",
                "Li Yuan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16103v2",
                "http://arxiv.org/pdf/2311.16103v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16101v1",
            "title": "How Many Unicorns Are in This Image? A Safety Evaluation Benchmark for\n  Vision LLMs",
            "updated": "2023-11-27T18:59:42Z",
            "published": "2023-11-27T18:59:42Z",
            "summary": "This work focuses on the potential of Vision LLMs (VLLMs) in visual\nreasoning. Different from prior studies, we shift our focus from evaluating\nstandard performance to introducing a comprehensive safety evaluation suite,\ncovering both out-of-distribution (OOD) generalization and adversarial\nrobustness. For the OOD evaluation, we present two novel VQA datasets, each\nwith one variant, designed to test model performance under challenging\nconditions. In exploring adversarial robustness, we propose a straightforward\nattack strategy for misleading VLLMs to produce visual-unrelated responses.\nMoreover, we assess the efficacy of two jailbreaking strategies, targeting\neither the vision or language component of VLLMs. Our evaluation of 21 diverse\nmodels, ranging from open-source VLLMs to GPT-4V, yields interesting\nobservations: 1) Current VLLMs struggle with OOD texts but not images, unless\nthe visual information is limited; and 2) These VLLMs can be easily misled by\ndeceiving vision encoders only, and their vision-language training often\ncompromise safety protocols. We release this safety evaluation suite at\nhttps://github.com/UCSC-VLAA/vllm-safety-benchmark.",
            "author": [
                "Haoqin Tu",
                "Chenhang Cui",
                "Zijun Wang",
                "Yiyang Zhou",
                "Bingchen Zhao",
                "Junlin Han",
                "Wangchunshu Zhou",
                "Huaxiu Yao",
                "Cihang Xie"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16101v1",
                "http://arxiv.org/pdf/2311.16101v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16100v1",
            "title": "Efficient high-resolution refinement in cryo-EM with stochastic gradient\n  descent",
            "updated": "2023-11-27T18:59:32Z",
            "published": "2023-11-27T18:59:32Z",
            "summary": "Electron cryomicroscopy (cryo-EM) is an imaging technique widely used in\nstructural biology to determine the three-dimensional structure of biological\nmolecules from noisy two-dimensional projections with unknown orientations. As\nthe typical pipeline involves processing large amounts of data, efficient\nalgorithms are crucial for fast and reliable results. The stochastic gradient\ndescent (SGD) algorithm has been used to improve the speed of ab initio\nreconstruction, which results in a first, low-resolution estimation of the\nvolume representing the molecule of interest, but has yet to be applied\nsuccessfully in the high-resolution regime, where expectation-maximization\nalgorithms achieve state-of-the-art results, at a high computational cost. In\nthis article, we investigate the conditioning of the optimization problem and\nshow that the large condition number prevents the successful application of\ngradient descent-based methods at high resolution. Our results include a\ntheoretical analysis of the condition number of the optimization problem in a\nsimplified setting where the individual projection directions are known, an\nalgorithm based on computing a diagonal preconditioner using Hutchinson's\ndiagonal estimator, and numerical experiments showing the improvement in the\nconvergence speed when using the estimated preconditioner with SGD. The\npreconditioned SGD approach can potentially enable a simple and unified\napproach to ab initio reconstruction and high-resolution refinement with faster\nconvergence speed and higher flexibility, and our results are a promising step\nin this direction.",
            "author": [
                "Bogdan Toader",
                "Marcus A. Brubaker",
                "Roy R. Lederman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16100v1",
                "http://arxiv.org/pdf/2311.16100v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA",
                "q-bio.BM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.03729v1",
            "title": "Cognitive Dissonance: Why Do Language Model Outputs Disagree with\n  Internal Representations of Truthfulness?",
            "updated": "2023-11-27T18:59:14Z",
            "published": "2023-11-27T18:59:14Z",
            "summary": "Neural language models (LMs) can be used to evaluate the truth of factual\nstatements in two ways: they can be either queried for statement probabilities,\nor probed for internal representations of truthfulness. Past work has found\nthat these two procedures sometimes disagree, and that probes tend to be more\naccurate than LM outputs. This has led some researchers to conclude that LMs\n\"lie\" or otherwise encode non-cooperative communicative intents. Is this an\naccurate description of today's LMs, or can query-probe disagreement arise in\nother ways? We identify three different classes of disagreement, which we term\nconfabulation, deception, and heterogeneity. In many cases, the superiority of\nprobes is simply attributable to better calibration on uncertain answers rather\nthan a greater fraction of correct, high-confidence answers. In some cases,\nqueries and probes perform better on different subsets of inputs, and accuracy\ncan further be improved by ensembling the two. Code is available at\ngithub.com/lingo-mit/lm-truthfulness.",
            "author": [
                "Kevin Liu",
                "Stephen Casper",
                "Dylan Hadfield-Menell",
                "Jacob Andreas"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03729v1",
                "http://arxiv.org/pdf/2312.03729v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16097v1",
            "title": "CG-HOI: Contact-Guided 3D Human-Object Interaction Generation",
            "updated": "2023-11-27T18:59:10Z",
            "published": "2023-11-27T18:59:10Z",
            "summary": "We propose CG-HOI, the first method to address the task of generating dynamic\n3D human-object interactions (HOIs) from text. We model the motion of both\nhuman and object in an interdependent fashion, as semantically rich human\nmotion rarely happens in isolation without any interactions. Our key insight is\nthat explicitly modeling contact between the human body surface and object\ngeometry can be used as strong proxy guidance, both during training and\ninference. Using this guidance to bridge human and object motion enables\ngenerating more realistic and physically plausible interaction sequences, where\nthe human body and corresponding object move in a coherent manner. Our method\nfirst learns to model human motion, object motion, and contact in a joint\ndiffusion process, inter-correlated through cross-attention. We then leverage\nthis learned contact for guidance during inference synthesis of realistic,\ncoherent HOIs. Extensive evaluation shows that our joint contact-based\nhuman-object interaction approach generates realistic and physically plausible\nsequences, and we show two applications highlighting the capabilities of our\nmethod. Conditioned on a given object trajectory, we can generate the\ncorresponding human motion without re-training, demonstrating strong\nhuman-object interdependency learning. Our approach is also flexible, and can\nbe applied to static real-world 3D scene scans.",
            "author": [
                "Christian Diller",
                "Angela Dai"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16097v1",
                "http://arxiv.org/pdf/2311.16097v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "I.2.10; I.4.8; I.5.1; I.5.4"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16093v1",
            "title": "Have we built machines that think like people?",
            "updated": "2023-11-27T18:58:34Z",
            "published": "2023-11-27T18:58:34Z",
            "summary": "A chief goal of artificial intelligence is to build machines that think like\npeople. Yet it has been argued that deep neural network architectures fail to\naccomplish this. Researchers have asserted these models' limitations in the\ndomains of causal reasoning, intuitive physics, and intuitive psychology. Yet\nrecent advancements, namely the rise of large language models, particularly\nthose designed for visual processing, have rekindled interest in the potential\nto emulate human-like cognitive abilities. This paper evaluates the current\nstate of vision-based large language models in the domains of intuitive\nphysics, causal reasoning, and intuitive psychology. Through a series of\ncontrolled experiments, we investigate the extent to which these modern models\ngrasp complex physical interactions, causal relationships, and intuitive\nunderstanding of others' preferences. Our findings reveal that, while these\nmodels demonstrate a notable proficiency in processing and interpreting visual\ndata, they still fall short of human capabilities in these areas. The models\nexhibit a rudimentary understanding of physical laws and causal relationships,\nbut their performance is hindered by a lack of deeper insights-a key aspect of\nhuman cognition. Furthermore, in tasks requiring an intuitive theory of mind,\nthe models fail altogether. Our results emphasize the need for integrating more\nrobust mechanisms for understanding causality, physical dynamics, and social\ncognition into modern-day, vision-based language models, and point out the\nimportance of cognitively-inspired benchmarks.",
            "author": [
                "Luca M. Schulze Buschoff",
                "Elif Akata",
                "Matthias Bethge",
                "Eric Schulz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16093v1",
                "http://arxiv.org/pdf/2311.16093v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16090v1",
            "title": "Self-correcting LLM-controlled Diffusion Models",
            "updated": "2023-11-27T18:56:37Z",
            "published": "2023-11-27T18:56:37Z",
            "summary": "Text-to-image generation has witnessed significant progress with the advent\nof diffusion models. Despite the ability to generate photorealistic images,\ncurrent text-to-image diffusion models still often struggle to accurately\ninterpret and follow complex input text prompts. In contrast to existing models\nthat aim to generate images only with their best effort, we introduce\nSelf-correcting LLM-controlled Diffusion (SLD). SLD is a framework that\ngenerates an image from the input prompt, assesses its alignment with the\nprompt, and performs self-corrections on the inaccuracies in the generated\nimage. Steered by an LLM controller, SLD turns text-to-image generation into an\niterative closed-loop process, ensuring correctness in the resulting image. SLD\nis not only training-free but can also be seamlessly integrated with diffusion\nmodels behind API access, such as DALL-E 3, to further boost the performance of\nstate-of-the-art diffusion models. Experimental results show that our approach\ncan rectify a majority of incorrect generations, particularly in generative\nnumeracy, attribute binding, and spatial relationships. Furthermore, by simply\nadjusting the instructions to the LLM, SLD can perform image editing tasks,\nbridging the gap between text-to-image generation and image editing pipelines.\nWe will make our code available for future research and applications.",
            "author": [
                "Tsung-Han Wu",
                "Long Lian",
                "Joseph E. Gonzalez",
                "Boyi Li",
                "Trevor Darrell"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16090v1",
                "http://arxiv.org/pdf/2311.16090v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16087v1",
            "title": "DUnE: Dataset for Unified Editing",
            "updated": "2023-11-27T18:56:14Z",
            "published": "2023-11-27T18:56:14Z",
            "summary": "Even the most advanced language models remain susceptible to errors\nnecessitating to modify these models without initiating a comprehensive\nretraining process. Model editing refers to the modification of a model's\nknowledge or representations in a manner that produces the desired outcomes.\nPrior research primarily centered around editing factual data e.g. \"Messi plays\nfor Inter Miami\" confining the definition of an edit to a knowledge triplet\ni.e. (subject, object, relation). However, as the applications of language\nmodels expand, so do the diverse ways in which we wish to edit and refine their\noutputs. In this study, we broaden the scope of the editing problem to include\nan array of editing cases such as debiasing and rectifying reasoning errors and\ndefine an edit as any natural language expression that solicits a change in the\nmodel's outputs. We are introducing DUnE-an editing benchmark where edits are\nnatural language sentences and propose that DUnE presents a challenging yet\nrelevant task. To substantiate this claim, we conduct an extensive series of\nexperiments testing various editing approaches to address DUnE, demonstrating\ntheir respective strengths and weaknesses. We show that retrieval-augmented\nlanguage modeling can outperform specialized editing techniques and neither set\nof approaches has fully solved the generalized editing problem covered by our\nbenchmark.",
            "author": [
                "Afra Feyza Aky\u00fcrek",
                "Eric Pan",
                "Garry Kuwanto",
                "Derry Wijaya"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16087v1",
                "http://arxiv.org/pdf/2311.16087v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16083v1",
            "title": "BERT Goes Off-Topic: Investigating the Domain Transfer Challenge using\n  Genre Classification",
            "updated": "2023-11-27T18:53:31Z",
            "published": "2023-11-27T18:53:31Z",
            "summary": "While performance of many text classification tasks has been recently\nimproved due to Pre-trained Language Models (PLMs), in this paper we show that\nthey still suffer from a performance gap when the underlying distribution of\ntopics changes. For example, a genre classifier trained on \\textit{political}\ntopics often fails when tested on documents about \\textit{sport} or\n\\textit{medicine}. In this work, we quantify this phenomenon empirically with a\nlarge corpus and a large set of topics. Consequently, we verify that domain\ntransfer remains challenging both for classic PLMs, such as BERT, and for\nmodern large models, such as GPT-3. We also suggest and successfully test a\npossible remedy: after augmenting the training dataset with\ntopically-controlled synthetic texts, the F1 score improves by up to 50\\% for\nsome topics, nearing on-topic training results, while others show little to no\nimprovement. While our empirical results focus on genre classification, our\nmethodology is applicable to other classification tasks such as gender,\nauthorship, or sentiment classification. The code and data to replicate the\nexperiments are available at https://github.com/dminus1/genre",
            "author": [
                "Dmitri Roussinov",
                "Serge Sharoff"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16083v1",
                "http://arxiv.org/pdf/2311.16083v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16081v1",
            "title": "ViT-Lens-2: Gateway to Omni-modal Intelligence",
            "updated": "2023-11-27T18:52:09Z",
            "published": "2023-11-27T18:52:09Z",
            "summary": "Aiming to advance AI agents, large foundation models significantly improve\nreasoning and instruction execution, yet the current focus on vision and\nlanguage neglects the potential of perceiving diverse modalities in open-world\nenvironments. However, the success of data-driven vision and language models is\ncostly or even infeasible to be reproduced for rare modalities. In this paper,\nwe present ViT-Lens-2 that facilitates efficient omni-modal representation\nlearning by perceiving novel modalities with a pretrained ViT and aligning them\nto a pre-defined space. Specifically, the modality-specific lens is tuned to\nproject any-modal signals to an intermediate embedding space, which are then\nprocessed by a strong ViT with pre-trained visual knowledge. The encoded\nrepresentations are optimized toward aligning with the modal-independent space,\npre-defined by off-the-shelf foundation models. ViT-Lens-2 provides a unified\nsolution for representation learning of increasing modalities with two\nappealing advantages: (i) Unlocking the great potential of pretrained ViTs to\nnovel modalities effectively with efficient data regime; (ii) Enabling emergent\ndownstream capabilities through modality alignment and shared ViT parameters.\nWe tailor ViT-Lens-2 to learn representations for 3D point cloud, depth, audio,\ntactile and EEG, and set new state-of-the-art results across various\nunderstanding tasks, such as zero-shot classification. By seamlessly\nintegrating ViT-Lens-2 into Multimodal Foundation Models, we enable\nAny-modality to Text and Image Generation in a zero-shot manner. Code and\nmodels are available at https://github.com/TencentARC/ViT-Lens.",
            "author": [
                "Weixian Lei",
                "Yixiao Ge",
                "Kun Yi",
                "Jianfeng Zhang",
                "Difei Gao",
                "Dylan Sun",
                "Yuying Ge",
                "Ying Shan",
                "Mike Zheng Shou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16081v1",
                "http://arxiv.org/pdf/2311.16081v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16079v1",
            "title": "MEDITRON-70B: Scaling Medical Pretraining for Large Language Models",
            "updated": "2023-11-27T18:49:43Z",
            "published": "2023-11-27T18:49:43Z",
            "summary": "Large language models (LLMs) can potentially democratize access to medical\nknowledge. While many efforts have been made to harness and improve LLMs'\nmedical knowledge and reasoning capacities, the resulting models are either\nclosed-source (e.g., PaLM, GPT-4) or limited in scale (<= 13B parameters),\nwhich restricts their abilities. In this work, we improve access to large-scale\nmedical LLMs by releasing MEDITRON: a suite of open-source LLMs with 7B and 70B\nparameters adapted to the medical domain. MEDITRON builds on Llama-2 (through\nour adaptation of Nvidia's Megatron-LM distributed trainer), and extends\npretraining on a comprehensively curated medical corpus, including selected\nPubMed articles, abstracts, and internationally-recognized medical guidelines.\nEvaluations using four major medical benchmarks show significant performance\ngains over several state-of-the-art baselines before and after task-specific\nfinetuning. Overall, MEDITRON achieves a 6% absolute performance gain over the\nbest public baseline in its parameter class and 3% over the strongest baseline\nwe finetuned from Llama-2. Compared to closed-source LLMs, MEDITRON-70B\noutperforms GPT-3.5 and Med-PaLM and is within 5% of GPT-4 and 10% of\nMed-PaLM-2. We release our code for curating the medical pretraining corpus and\nthe MEDITRON model weights to drive open-source development of more capable\nmedical LLMs.",
            "author": [
                "Zeming Chen",
                "Alejandro Hern\u00e1ndez Cano",
                "Angelika Romanou",
                "Antoine Bonnet",
                "Kyle Matoba",
                "Francesco Salvi",
                "Matteo Pagliardini",
                "Simin Fan",
                "Andreas K\u00f6pf",
                "Amirkeivan Mohtashami",
                "Alexandre Sallinen",
                "Alireza Sakhaeirad",
                "Vinitra Swamy",
                "Igor Krawczuk",
                "Deniz Bayazit",
                "Axel Marmet",
                "Syrielle Montariol",
                "Mary-Anne Hartley",
                "Martin Jaggi",
                "Antoine Bosselut"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16079v1",
                "http://arxiv.org/pdf/2311.16079v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16075v1",
            "title": "BioLORD-2023: Semantic Textual Representations Fusing LLM and Clinical\n  Knowledge Graph Insights",
            "updated": "2023-11-27T18:46:17Z",
            "published": "2023-11-27T18:46:17Z",
            "summary": "In this study, we investigate the potential of Large Language Models to\ncomplement biomedical knowledge graphs in the training of semantic models for\nthe biomedical and clinical domains. Drawing on the wealth of the UMLS\nknowledge graph and harnessing cutting-edge Large Language Models, we propose a\nnew state-of-the-art approach for obtaining high-fidelity representations of\nbiomedical concepts and sentences, consisting of three steps: an improved\ncontrastive learning phase, a novel self-distillation phase, and a weight\naveraging phase. Through rigorous evaluations via the extensive BioLORD testing\nsuite and diverse downstream tasks, we demonstrate consistent and substantial\nperformance improvements over the previous state of the art (e.g. +2pts on\nMedSTS, +2.5pts on MedNLI-S, +6.1pts on EHR-Rel-B). Besides our new\nstate-of-the-art biomedical model for English, we also distill and release a\nmultilingual model compatible with 50+ languages and finetuned on 7 European\nlanguages. Many clinical pipelines can benefit from our latest models. Our new\nmultilingual model enables a range of languages to benefit from our\nadvancements in biomedical semantic representation learning, opening a new\navenue for bioinformatics researchers around the world. As a result, we hope to\nsee BioLORD-2023 becoming a precious tool for future biomedical applications.",
            "author": [
                "Fran\u00e7ois Remy",
                "Kris Demuynck",
                "Thomas Demeester"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16075v1",
                "http://arxiv.org/pdf/2311.16075v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16071v1",
            "title": "Metal and dust evolution in ALMA REBELS galaxies: insights for future\n  JWST observations",
            "updated": "2023-11-27T18:43:09Z",
            "published": "2023-11-27T18:43:09Z",
            "summary": "ALMA observations revealed the presence of significant amounts of dust in the\nfirst Gyr of Cosmic time. However, the metal and dust buildup picture remains\nvery uncertain due to the lack of constraints on metallicity. JWST has started\nto reveal the metal content of high-redshift targets, which may lead to firmer\nconstraints on high-redshift dusty galaxies evolution. In this work, we use\ndetailed chemical and dust evolution models to explore the evolution of\ngalaxies within the ALMA REBELS survey, testing different metallicity scenarios\nthat could be inferred from JWST observations. In the models, we track the\nbuildup of stellar mass by using non-parametric SFHs for REBELS galaxies.\nDifferent scenarios for metal and dust evolution are simulated by allowing\ndifferent prescriptions for gas flows and dust processes. The model outputs are\ncompared with measured dust scaling relations, by employing\nmetallicity-dependent calibrations for the gas mass based on the [CII]158micron\nline. Independently of the galaxies metal content, we found no need for extreme\ndust prescriptions to explain the dust masses revealed by ALMA. However,\ndifferent levels of metal enrichment will lead to different dominant dust\nproduction mechanisms, with stardust production dominant over other ISM dust\nprocesses only in the metal-poor case. This points out how metallicity\nmeasurements from JWST will significantly improve our understanding of the dust\nbuildup in high-redshift galaxies. We also show that models struggle to\nreproduce observables such as dust-to-gas and dust-to-stellar ratios\nsimultaneously, possibly indicating an overestimation of the gas mass through\ncurrent calibrations, especially at high metallicities.",
            "author": [
                "Marco Palla",
                "Ilse De Looze",
                "Monica Rela\u00f1o",
                "Stefan van der Giessen",
                "Pratika Dayal",
                "Andrea Ferrara",
                "Raffaella Schneider",
                "Luca Graziani",
                "Hiddo S. B. Algera",
                "Manuel Aravena",
                "Rebecca A. A. Bowler",
                "Alexander P. S. Hygate",
                "Hanae Inami",
                "Ivana van Leeuwen",
                "Rychard Bouwens",
                "Jacqueline Hodge",
                "Renske Smit",
                "Mauro Stefanon",
                "Paul van der Werf"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16071v1",
                "http://arxiv.org/pdf/2311.16071v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16065v1",
            "title": "A Survey on Vulnerability of Federated Learning: A Learning Algorithm\n  Perspective",
            "updated": "2023-11-27T18:32:08Z",
            "published": "2023-11-27T18:32:08Z",
            "summary": "This review paper takes a comprehensive look at malicious attacks against FL,\ncategorizing them from new perspectives on attack origins and targets, and\nproviding insights into their methodology and impact. In this survey, we focus\non threat models targeting the learning process of FL systems. Based on the\nsource and target of the attack, we categorize existing threat models into four\ntypes, Data to Model (D2M), Model to Data (M2D), Model to Model (M2M) and\ncomposite attacks. For each attack type, we discuss the defense strategies\nproposed, highlighting their effectiveness, assumptions and potential areas for\nimprovement. Defense strategies have evolved from using a singular metric to\nexcluding malicious clients, to employing a multifaceted approach examining\nclient models at various phases. In this survey paper, our research indicates\nthat the to-learn data, the learning gradients, and the learned model at\ndifferent stages all can be manipulated to initiate malicious attacks that\nrange from undermining model performance, reconstructing private local data,\nand to inserting backdoors. We have also seen these threat are becoming more\ninsidious. While earlier studies typically amplified malicious gradients,\nrecent endeavors subtly alter the least significant weights in local models to\nbypass defense measures. This literature review provides a holistic\nunderstanding of the current FL threat landscape and highlights the importance\nof developing robust, efficient, and privacy-preserving defenses to ensure the\nsafe and trusted adoption of FL in real-world applications.",
            "author": [
                "Xianghua Xie",
                "Chen Hu",
                "Hanchi Ren",
                "Jingjing Deng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16065v1",
                "http://arxiv.org/pdf/2311.16065v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16064v1",
            "title": "Heat content for Gaussian processes: small-time asymptotic analysis",
            "updated": "2023-11-27T18:28:56Z",
            "published": "2023-11-27T18:28:56Z",
            "summary": "This paper establishes the small-time asymptotic behaviors of the regular\nheat content and spectral heat content for general Gaussian processes in both\none-dimensional and multi-dimensional settings, where the boundary of the\nunderlying domain satisfies some smoothness condition. For the amount of heat\nloss associated with the spectral heat content, the exact asymptotic behavior\nwith rate function being the expected supremum process is obtained, whereas for\nthe regular heat content, the exact asymptotic behavior is described in terms\nof the standard deviation function.",
            "author": [
                "Kei Kobayashi",
                "Hyunchul Park"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16064v1",
                "http://arxiv.org/pdf/2311.16064v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16062v1",
            "title": "Local Differentially Private Heavy Hitter Detection in Data Streams with\n  Bounded Memory",
            "updated": "2023-11-27T18:28:15Z",
            "published": "2023-11-27T18:28:15Z",
            "summary": "Top-$k$ frequent items detection is a fundamental task in data stream mining.\nMany promising solutions are proposed to improve memory efficiency while still\nmaintaining high accuracy for detecting the Top-$k$ items. Despite the memory\nefficiency concern, the users could suffer from privacy loss if participating\nin the task without proper protection, since their contributed local data\nstreams may continually leak sensitive individual information. However, most\nexisting works solely focus on addressing either the memory-efficiency problem\nor the privacy concerns but seldom jointly, which cannot achieve a satisfactory\ntradeoff between memory efficiency, privacy protection, and detection accuracy.\n  In this paper, we present a novel framework HG-LDP to achieve accurate\nTop-$k$ item detection at bounded memory expense, while providing rigorous\nlocal differential privacy (LDP) protection. Specifically, we identify two key\nchallenges naturally arising in the task, which reveal that directly applying\nexisting LDP techniques will lead to an inferior ``accuracy-privacy-memory\nefficiency'' tradeoff. Therefore, we instantiate three advanced schemes under\nthe framework by designing novel LDP randomization methods, which address the\nhurdles caused by the large size of the item domain and by the limited space of\nthe memory. We conduct comprehensive experiments on both synthetic and\nreal-world datasets to show that the proposed advanced schemes achieve a\nsuperior ``accuracy-privacy-memory efficiency'' tradeoff, saving $2300\\times$\nmemory over baseline methods when the item domain size is $41,270$. Our code is\nopen-sourced via the link.",
            "author": [
                "Xiaochen Li",
                "Weiran Liu",
                "Jian Lou",
                "Yuan Hong",
                "Lei Zhang",
                "Zhan Qin",
                "Kui Ren"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16062v1",
                "http://arxiv.org/pdf/2311.16062v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16060v1",
            "title": "DiffSLVA: Harnessing Diffusion Models for Sign Language Video\n  Anonymization",
            "updated": "2023-11-27T18:26:19Z",
            "published": "2023-11-27T18:26:19Z",
            "summary": "Since American Sign Language (ASL) has no standard written form, Deaf signers\nfrequently share videos in order to communicate in their native language.\nHowever, since both hands and face convey critical linguistic information in\nsigned languages, sign language videos cannot preserve signer privacy. While\nsigners have expressed interest, for a variety of applications, in sign\nlanguage video anonymization that would effectively preserve linguistic\ncontent, attempts to develop such technology have had limited success, given\nthe complexity of hand movements and facial expressions. Existing approaches\nrely predominantly on precise pose estimations of the signer in video footage\nand often require sign language video datasets for training. These requirements\nprevent them from processing videos 'in the wild,' in part because of the\nlimited diversity present in current sign language video datasets. To address\nthese limitations, our research introduces DiffSLVA, a novel methodology that\nutilizes pre-trained large-scale diffusion models for zero-shot text-guided\nsign language video anonymization. We incorporate ControlNet, which leverages\nlow-level image features such as HED (Holistically-Nested Edge Detection)\nedges, to circumvent the need for pose estimation. Additionally, we develop a\nspecialized module dedicated to capturing facial expressions, which are\ncritical for conveying essential linguistic information in signed languages. We\nthen combine the above methods to achieve anonymization that better preserves\nthe essential linguistic content of the original signer. This innovative\nmethodology makes possible, for the first time, sign language video\nanonymization that could be used for real-world applications, which would offer\nsignificant benefits to the Deaf and Hard-of-Hearing communities. We\ndemonstrate the effectiveness of our approach with a series of signer\nanonymization experiments.",
            "author": [
                "Zhaoyang Xia",
                "Carol Neidle",
                "Dimitris N. Metaxas"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16060v1",
                "http://arxiv.org/pdf/2311.16060v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16214v1",
            "title": "DGR: Tackling Drifted and Correlated Noise in Quantum Error Correction\n  via Decoding Graph Re-weighting",
            "updated": "2023-11-27T18:26:16Z",
            "published": "2023-11-27T18:26:16Z",
            "summary": "Quantum hardware suffers from high error rates and noise, which makes\ndirectly running applications on them ineffective. Quantum Error Correction\n(QEC) is a critical technique towards fault tolerance which encodes the quantum\ninformation distributively in multiple data qubits and uses syndrome qubits to\ncheck parity. Minimum-Weight-Perfect-Matching (MWPM) is a popular QEC decoder\nthat takes the syndromes as input and finds the matchings between syndromes\nthat infer the errors. However, there are two paramount challenges for MWPM\ndecoders. First, as noise in real quantum systems can drift over time, there is\na potential misalignment with the decoding graph's initial weights, leading to\na severe performance degradation in the logical error rates. Second, while the\nMWPM decoder addresses independent errors, it falls short when encountering\ncorrelated errors typical on real hardware, such as those in the 2Q\ndepolarizing channel.\n  We propose DGR, an efficient decoding graph edge re-weighting strategy with\nno quantum overhead. It leverages the insight that the statistics of matchings\nacross decoding iterations offer rich information about errors on real quantum\nhardware. By counting the occurrences of edges and edge pairs in decoded\nmatchings, we can statistically estimate the up-to-date probabilities of each\nedge and the correlations between them. The reweighting process includes two\nvital steps: alignment re-weighting and correlation re-weighting. The former\nupdates the MWPM weights based on statistics to align with actual noise, and\nthe latter adjusts the weight considering edge correlations.\n  Extensive evaluations on surface code and honeycomb code under various\nsettings show that DGR reduces the logical error rate by 3.6x on average-case\nnoise mismatch with exceeding 5000x improvement under worst-case mismatch.",
            "author": [
                "Hanrui Wang",
                "Pengyu Liu",
                "Yilian Liu",
                "Jiaqi Gu",
                "Jonathan Baker",
                "Frederic T. Chong",
                "Song Han"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16214v1",
                "http://arxiv.org/pdf/2311.16214v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.AR",
                "cs.ET",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16059v3",
            "title": "Narrow absorption line Outflow in Seyfert 1 galaxy J1429+4518: Outflow's\n  distance from the central source and its energetics",
            "updated": "2023-11-29T16:16:02Z",
            "published": "2023-11-27T18:22:45Z",
            "summary": "In the HST/COS spectrum of the Seyfert 1 galaxy 2MASX J14292507+4518318, we\nhave identified a narrow absorption line (NAL) outflow system with a velocity\nof -151 km s$^{-1}$ This outflow exhibits absorption troughs from the resonance\nstates of ions like CIV, NV, SiIV, and SiII, as well as excited states from\nCII*, and SiII*. Our investigation of the outflow involved measuring ionic\ncolumn densities and conducting photoionization analysis. These yield the total\ncolumn density of the outflow to be estimated as $\\log N_{H}$=19.84\n[cm$^{-2}]$, its ionization parameter to be $\\log U_{H}$=$-$2.0 and its\nelectron number density equal to $\\log n_{e}$= 2.75[cm$^{-3}$]. These\nmeasurements enabled us to determine the mass-loss rate and the kinetic\nluminosity of the outflow system to be $Mdot$=0.22[$M_{Sun}$$yr^{-1}$] and\n$\\log Edot_{K}$=39.3 [erg s$^{-1}$], respectively. We have also measured the\nlocation of the outflow system to be at $\\sim$275 pc from the central source.\nThis outflow does not contribute to the AGN feedback processes due to the low\nratio of the outflow's kinetic luminosity to the AGN's Eddington luminosity\n($Edot_{K}/L_{Edd}\\approx 0.00025 \\%$). This outflow is remarkably similar to\nthe two bipolar lobe outflows observed in the Milky Way by XMM-Newton and\nChandra.",
            "author": [
                "Maryam Dehghanian",
                "Nahum Arav",
                "Doyee Byun",
                "Gwen Walker",
                "Mayank Sharma"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16059v3",
                "http://arxiv.org/pdf/2311.16059v3"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16213v1",
            "title": "Seeing Beyond Cancer: Multi-Institutional Validation of Object\n  Localization and 3D Semantic Segmentation using Deep Learning for Breast MRI",
            "updated": "2023-11-27T18:22:07Z",
            "published": "2023-11-27T18:22:07Z",
            "summary": "The clinical management of breast cancer depends on an accurate understanding\nof the tumor and its anatomical context to adjacent tissues and landmark\nstructures. This context may be provided by semantic segmentation methods;\nhowever, previous works have been largely limited to a singular focus on the\ntumor alone and rarely other tissue types. In contrast, we present a method\nthat exploits tissue-tissue interactions to accurately segment every major\ntissue type in the breast including: chest wall, skin, adipose tissue,\nfibroglandular tissue, vasculature and tumor via standard-of-care Dynamic\nContrast Enhanced MRI. Comparing our method to prior state-of-the-art, we\nachieved a superior Dice score on tumor segmentation while maintaining\ncompetitive performance on other studied tissues across multiple institutions.\nBriefly, our method proceeds by localizing the tumor using 2D object detectors,\nthen segmenting the tumor and surrounding tissues independently using two 3D\nU-nets, and finally integrating these results while mitigating false positives\nby checking for anatomically plausible tissue-tissue contacts. The object\ndetection models were pre-trained on ImageNet and COCO, and operated on MIP\n(maximum intensity projection) images in the axial and sagittal planes,\nestablishing a 3D tumor bounding box. By integrating multiple relevant\nperi-tumoral tissues, our work enables clinical applications in breast cancer\nstaging, prognosis and surgical planning.",
            "author": [
                "Arda Pekis",
                "Vignesh Kannan",
                "Evandros Kaklamanos",
                "Anu Antony",
                "Snehal Patel",
                "Tyler Earnest"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16213v1",
                "http://arxiv.org/pdf/2311.16213v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG",
                "I.4.6; J.3"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16056v1",
            "title": "A Holographic Entanglement Entropy at Spi",
            "updated": "2023-11-27T18:21:26Z",
            "published": "2023-11-27T18:21:26Z",
            "summary": "Defining finite entanglement entropy for a subregion in quantum field theory\nrequires the introduction of two logically independent scales: an IR scale that\ncontrols the size of the subregion, and a UV cut-off. In AdS/CFT, the IR scale\nis the AdS lengthscale, the UV cut-off is the bulk radial cut-off, and the\nsubregion is specified by dimensionless angles. This is the data that\ndetermines Ryu-Takayanagi surfaces and their areas in AdS/CFT. We argue that in\nasymptotically flat space there exists the notion of a \"spi-subregion\" that one\ncan associate to spatial infinity (spi). Even though geometrically quite\ndifferent from an AdS subregion, this angle data has the crucial feature that\nit allows an interpretation as a bi-partitioning of spi. Therefore, the area of\nthe RT surface associated to the spi-subregion can be interpreted as the\nentanglement entropy of the reduced density matrix of the bulk state under this\nbi-partition, as in AdS/CFT. For symmetric spi-subregions, these RT surfaces\nare the waists of Asymptotic Causal Diamonds. In empty flat space they reduce\nto Rindler horizons, and are analogues of the AdS-Rindler horizons of Casini,\nHuerta \\& Myers. We connect these definitions to previous work on minimal\nsurfaces anchored to screens in empty space, but also generalize the discussion\nto the case where there are black holes in the bulk. The phases of black hole\nRT surfaces as the spi-subregion is varied, naturally connect with those of\nblack holes (small and large) in AdS. A key observation is that the radial\ncut-off is associated to an IR scale in flat space -- and in fact there are no\nUV divergences. We argue that this is consistent with previous suggestions that\nin sub-AdS scales the holographic duality is an IR/IR correspondence and that\nthe degrees of freedom are {\\em not} those of a local QFT, but those of long\nstrings. Strings are of course, famously UV finite.",
            "author": [
                "Abir Ghosh",
                "Chethan Krishnan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16056v1",
                "http://arxiv.org/pdf/2311.16056v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th",
                "gr-qc",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16051v1",
            "title": "Evaluating the Impact of Personalized Value Alignment in Human-Robot\n  Interaction: Insights into Trust and Team Performance Outcomes",
            "updated": "2023-11-27T18:14:03Z",
            "published": "2023-11-27T18:14:03Z",
            "summary": "This paper examines the effect of real-time, personalized alignment of a\nrobot's reward function to the human's values on trust and team performance. We\npresent and compare three distinct robot interaction strategies: a non-learner\nstrategy where the robot presumes the human's reward function mirrors its own,\na non-adaptive-learner strategy in which the robot learns the human's reward\nfunction for trust estimation and human behavior modeling, but still optimizes\nits own reward function, and an adaptive-learner strategy in which the robot\nlearns the human's reward function and adopts it as its own. Two human-subject\nexperiments with a total number of 54 participants were conducted. In both\nexperiments, the human-robot team searches for potential threats in a town. The\nteam sequentially goes through search sites to look for threats. We model the\ninteraction between the human and the robot as a trust-aware Markov Decision\nProcess (trust-aware MDP) and use Bayesian Inverse Reinforcement Learning (IRL)\nto estimate the reward weights of the human as they interact with the robot. In\nExperiment 1, we start our learning algorithm with an informed prior of the\nhuman's values/goals. In Experiment 2, we start the learning algorithm with an\nuninformed prior. Results indicate that when starting with a good informed\nprior, personalized value alignment does not seem to benefit trust or team\nperformance. On the other hand, when an informed prior is unavailable,\nalignment to the human's values leads to high trust and higher perceived\nperformance while maintaining the same objective team performance.",
            "author": [
                "Shreyas Bhat",
                "Joseph B. Lyons",
                "Cong Shi",
                "X. Jessie Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16051v1",
                "http://arxiv.org/pdf/2311.16051v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16052v1",
            "title": "Exploring Attribute Variations in Style-based GANs using Diffusion\n  Models",
            "updated": "2023-11-27T18:14:03Z",
            "published": "2023-11-27T18:14:03Z",
            "summary": "Existing attribute editing methods treat semantic attributes as binary,\nresulting in a single edit per attribute. However, attributes such as\neyeglasses, smiles, or hairstyles exhibit a vast range of diversity. In this\nwork, we formulate the task of \\textit{diverse attribute editing} by modeling\nthe multidimensional nature of attribute edits. This enables users to generate\nmultiple plausible edits per attribute. We capitalize on disentangled latent\nspaces of pretrained GANs and train a Denoising Diffusion Probabilistic Model\n(DDPM) to learn the latent distribution for diverse edits. Specifically, we\ntrain DDPM over a dataset of edit latent directions obtained by embedding image\npairs with a single attribute change. This leads to latent subspaces that\nenable diverse attribute editing. Applying diffusion in the highly compressed\nlatent space allows us to model rich distributions of edits within limited\ncomputational resources. Through extensive qualitative and quantitative\nexperiments conducted across a range of datasets, we demonstrate the\neffectiveness of our approach for diverse attribute editing. We also showcase\nthe results of our method applied for 3D editing of various face attributes.",
            "author": [
                "Rishubh Parihar",
                "Prasanna Balaji",
                "Raghav Magazine",
                "Sarthak Vora",
                "Tejan Karmali",
                "Varun Jampani",
                "R. Venkatesh Babu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16052v1",
                "http://arxiv.org/pdf/2311.16052v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16048v1",
            "title": "Top-philic ALP phenomenology at the LHC: the elusive mass-window",
            "updated": "2023-11-27T18:13:15Z",
            "published": "2023-11-27T18:13:15Z",
            "summary": "We study the LHC phenomenology of an Axion Like Particle (ALP) that couples\nonly derivatively with the top quark at tree level. We inspect the radiatively\ninduced couplings with the SM fermions and (gauge) bosons and the associated\nproduction and decay mechanisms of the ALP. We focus on the most challenging\nmass window that remains open for a top-philic ALP, i.e., the range between\ntens and hundreds of GeV. Not only ALP production processes but also virtual\nALP contributions to final states with top quarks are considered in detail. We\nshow how searches through resonant production, such as ALP production in\nassociation with a $t\\bar t$ pair, are complementary to precision measurements\nof $t \\bar t$ and $t\\bar t t \\bar t$ final states, the latter being competitive\nor even more powerful for a top-philic ALP in this mass window. Finally, we\nexplore the scenario where the top-philic ALP acts as a mediator to a\ndark-matter sector, resulting in missing energy signatures at the LHC. We find\nthat the LHC constraints from $t \\bar t$, $t\\bar t t \\bar t$ and ALP + jet\nproduction, together with those from $t \\bar t$ + ALP production, can already\nexclude a large fraction of the parameter space leading to the correct relic\nabundance.",
            "author": [
                "Simone Blasi",
                "Fabio Maltoni",
                "Alberto Mariotti",
                "Ken Mimasu",
                "Davide Pagani",
                "Simone Tentori"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16048v1",
                "http://arxiv.org/pdf/2311.16048v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16047v2",
            "title": "Observer study-based evaluation of TGAN architecture used to generate\n  oncological PET images",
            "updated": "2023-11-28T03:13:52Z",
            "published": "2023-11-27T18:12:36Z",
            "summary": "The application of computer-vision algorithms in medical imaging has\nincreased rapidly in recent years. However, algorithm training is challenging\ndue to limited sample sizes, lack of labeled samples, as well as privacy\nconcerns regarding data sharing. To address these issues, we previously\ndeveloped (Bergen et al. 2022) a synthetic PET dataset for Head and Neck (H and\nN) cancer using the temporal generative adversarial network (TGAN) architecture\nand evaluated its performance segmenting lesions and identifying radiomics\nfeatures in synthesized images. In this work, a two-alternative forced-choice\n(2AFC) observer study was performed to quantitatively evaluate the ability of\nhuman observers to distinguish between real and synthesized oncological PET\nimages. In the study eight trained readers, including two board-certified\nnuclear medicine physicians, read 170 real/synthetic image pairs presented as\n2D-transaxial using a dedicated web app. For each image pair, the observer was\nasked to identify the real image and input their confidence level with a\n5-point Likert scale. P-values were computed using the binomial test and\nWilcoxon signed-rank test. A heat map was used to compare the response accuracy\ndistribution for the signed-rank test. Response accuracy for all observers\nranged from 36.2% [27.9-44.4] to 63.1% [54.8-71.3]. Six out of eight observers\ndid not identify the real image with statistical significance, indicating that\nthe synthetic dataset was reasonably representative of oncological PET images.\nOverall, this study adds validity to the realism of our simulated H&N cancer\ndataset, which may be implemented in the future to train AI algorithms while\nfavoring patient confidentiality and privacy protection.",
            "author": [
                "Roberto Fedrigo",
                "Fereshteh Yousefirizi",
                "Ziping Liu",
                "Abhinav K. Jha",
                "Robert V. Bergen",
                "Jean-Francois Rajotte",
                "Raymond T. Ng",
                "Ingrid Bloise",
                "Sara Harsini",
                "Dan J. Kadrmas",
                "Carlos Uribe",
                "Arman Rahmim"
            ],
            "link": [
                "http://dx.doi.org/10.1117/12.2652661",
                "http://arxiv.org/abs/2311.16047v2",
                "http://arxiv.org/pdf/2311.16047v2"
            ],
            "primary_category": "physics.med-ph",
            "category": [
                "physics.med-ph",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16046v1",
            "title": "Energy Dissipation of Fast Electrons in Polymethylmetacrylate (PMMA):\n  Towards a Universal Curve for Electron Beam Attenuation in Solids for\n  Energies between ~0 eV and 100 keV",
            "updated": "2023-11-27T18:11:31Z",
            "published": "2023-11-27T18:11:31Z",
            "summary": "Wolfgang S.M. Werner, Florian Simperl, Felix Bloedorn, Julian Brunner,\nJohannes Kero, Alessandra Bellissimo and Olga Ridzel\n  Spectroscopy of correlated electron pairs was employed to investigate the\nenergy dissipation process as well as the transport and the emission of low\nenergy electrons on a polymethylmetracylate (PMMA) surface, providing secondary\nelectron (SE) spectra causally related to the energy loss of the primary\nelectron. Two groups of electrons are identified in the cascade of slow\nelectrons, corresponding to different stages in the energy dissipation process.\nFor both groups, the characteristic lengths for attenuation due to collective\nexcitations and momentum relaxation are quantified and are found to be\ndistinctly different: l1=(12.0+/-2) Angstroem and l2=(61.5+/-11) Angstroem. The\nresults strongly contradict the commonly employed model of exponential\nattenuation with the electron inelastic mean free path (IMFP) as characteristic\nlength, but essentially agree with a theory used for decades in astrophysics\nand neutron transport, albeit with characteristic lengths expressed in units of\nAngstroems rather than lightyears.",
            "author": [
                "Wolfgang S. M. Werner",
                "Florian Simperl",
                "Felix Bloedorn",
                "Julian Brunner",
                "Johannes Kero",
                "Alessandra Bellissimo",
                "Olga Ridzel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16046v1",
                "http://arxiv.org/pdf/2311.16046v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "physics.app-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16518v1",
            "title": "SeeSR: Towards Semantics-Aware Real-World Image Super-Resolution",
            "updated": "2023-11-27T18:11:19Z",
            "published": "2023-11-27T18:11:19Z",
            "summary": "Owe to the powerful generative priors, the pre-trained text-to-image (T2I)\ndiffusion models have become increasingly popular in solving the real-world\nimage super-resolution problem. However, as a consequence of the heavy quality\ndegradation of input low-resolution (LR) images, the destruction of local\nstructures can lead to ambiguous image semantics. As a result, the content of\nreproduced high-resolution image may have semantic errors, deteriorating the\nsuper-resolution performance. To address this issue, we present a\nsemantics-aware approach to better preserve the semantic fidelity of generative\nreal-world image super-resolution. First, we train a degradation-aware prompt\nextractor, which can generate accurate soft and hard semantic prompts even\nunder strong degradation. The hard semantic prompts refer to the image tags,\naiming to enhance the local perception ability of the T2I model, while the soft\nsemantic prompts compensate for the hard ones to provide additional\nrepresentation information. These semantic prompts can encourage the T2I model\nto generate detailed and semantically accurate results. Furthermore, during the\ninference process, we integrate the LR images into the initial sampling noise\nto mitigate the diffusion model's tendency to generate excessive random\ndetails. The experiments show that our method can reproduce more realistic\nimage details and hold better the semantics.",
            "author": [
                "Rongyuan Wu",
                "Tao Yang",
                "Lingchen Sun",
                "Zhengqiang Zhang",
                "Shuai Li",
                "Lei Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16518v1",
                "http://arxiv.org/pdf/2311.16518v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16041v1",
            "title": "Low-lying geodesics on the modular surface and necklaces",
            "updated": "2023-11-27T18:04:53Z",
            "published": "2023-11-27T18:04:53Z",
            "summary": "The m-thick part of the modular surface X is the smallest compact subsurface\nof X with horocycle boundary containing all the closed geodesics which wind\naround the cusp at most m times. The m-thick parts form a compact exhaustion of\nX. We are interested in the geodesics that lie in the m-thick part (so called m\nlow-lying geodesics). We produce a complete asymptotic expansion for the number\nof m low-lying geodesics of length equal to 2n in the modular surface. In\nparticular, we obtain the asymptotic growth rate of the m low-lying geodesics\nin terms of their word length using the natural generators of the modular\ngroup. After establishing a correspondence between this counting problem and\nthe problem of counting necklaces with n beads, we perform a careful\nsingularity analysis on the associated generating function of the sequence.",
            "author": [
                "Ara Basmajian",
                "Mingkun Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16041v1",
                "http://arxiv.org/pdf/2311.16041v1"
            ],
            "primary_category": "math.GT",
            "category": [
                "math.GT",
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16040v1",
            "title": "Searching for New Physics in Hadronic Final States with Run 2\n  Proton-Proton Collision Data at the LHC",
            "updated": "2023-11-27T18:01:27Z",
            "published": "2023-11-27T18:01:27Z",
            "summary": "The symmetries of the Standard Model give rise to the forces that act on\nparticles, and the corresponding force mediators. While the Standard Model is\nan excellent description of particle interactions, it has known limitations; it\nis therefore important to search for new physics beyond the Standard Model,\npotentially indicating as-of-yet unknown symmetries of nature. The ATLAS and\nCMS collaborations have detailed physics programmes, involving a large number\nof searches for new physics in hadronic final states. As the start of Run 3 of\nthe LHC is imminent, now is a good time to review the progress made and the\nstatus of hadronic searches during Run 2 at a centre-of-mass collision energy\nof 13 TeV. This review provides an overview of the motivations and challenges\nof hadronic final states at the LHC, followed by an introduction to jet\nreconstruction, calibration, and tagging. Three classes of searches for new\nphysics in hadronic final states are discussed: di-jet searches, searches for\nmissing transverse momentum in association with another object, and searches\nfor hadronic di-boson resonances. The complementarity of these different\nanalysis strategies is discussed, emphasising the importance of a varied\nhadronic physics programme in the search for new physics.",
            "author": [
                "Steven Schramm"
            ],
            "link": [
                "http://dx.doi.org/10.3390/sym14061173",
                "http://arxiv.org/abs/2311.16040v1",
                "http://arxiv.org/pdf/2311.16040v1"
            ],
            "primary_category": "hep-ex",
            "category": [
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16037v1",
            "title": "GaussianEditor: Editing 3D Gaussians Delicately with Text Instructions",
            "updated": "2023-11-27T17:58:21Z",
            "published": "2023-11-27T17:58:21Z",
            "summary": "Recently, impressive results have been achieved in 3D scene editing with text\ninstructions based on a 2D diffusion model. However, current diffusion models\nprimarily generate images by predicting noise in the latent space, and the\nediting is usually applied to the whole image, which makes it challenging to\nperform delicate, especially localized, editing for 3D scenes. Inspired by\nrecent 3D Gaussian splatting, we propose a systematic framework, named\nGaussianEditor, to edit 3D scenes delicately via 3D Gaussians with text\ninstructions. Benefiting from the explicit property of 3D Gaussians, we design\na series of techniques to achieve delicate editing. Specifically, we first\nextract the region of interest (RoI) corresponding to the text instruction,\naligning it to 3D Gaussians. The Gaussian RoI is further used to control the\nediting process. Our framework can achieve more delicate and precise editing of\n3D scenes than previous methods while enjoying much faster training speed, i.e.\nwithin 20 minutes on a single V100 GPU, more than twice as fast as\nInstruct-NeRF2NeRF (45 minutes -- 2 hours).",
            "author": [
                "Jiemin Fang",
                "Junjie Wang",
                "Xiaopeng Zhang",
                "Lingxi Xie",
                "Qi Tian"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16037v1",
                "http://arxiv.org/pdf/2311.16037v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16029v1",
            "title": "Deep Learning Voigt Profiles I. Single-Cloud Doublets",
            "updated": "2023-11-27T17:49:18Z",
            "published": "2023-11-27T17:49:18Z",
            "summary": "Voigt profile (VP) decomposition of quasar absorption lines is key to\nstudying intergalactic gas and the baryon cycle governing the formation and\nevolution of galaxies. The VP velocities, column densities, and Doppler $b$\nparameters inform us of the kinematic, chemical, and ionization conditions of\nthese astrophysical environments. A drawback of traditional VP fitting is that\nit can be human-time intensive. With the coming next generation of large\nall-sky survey telescopes with multi-object high-resolution spectrographs, the\ntime demands will significantly outstrip our resources. Deep learning pipelines\nhold the promise to keep pace and deliver science digestible data products. We\nexplore the application of deep learning convolutional neural networks (CNNs)\nfor predicting VP fitted parameters directly from the normalized pixel flux\nvalues in quasar absorption line profiles. A CNN was applied to 56\nsingle-component MgII2796, 2803 doublet absorption line systems observed with\nHIRES and UVES ($R=45,000$). The CNN predictions were statistically indistinct\nfrom a traditional VP fitter. The advantage is that once trained, the CNN\nprocesses systems $\\sim\\!10^5$ times faster than a human expert VP fitting\nprofiles by hand. Our pilot study shows that CNNs hold promise to perform bulk\nanalysis of quasar absorption line systems in the future.",
            "author": [
                "Bryson Stemock",
                "Christopher W. Churchill",
                "Avery Lee",
                "Sultan Hassan",
                "Caitlin Doughty",
                "Rogelio Ochoa"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16029v1",
                "http://arxiv.org/pdf/2311.16029v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16028v1",
            "title": "Machine-to-Machine Transfer Function in Deep Learning-Based Quantitative\n  Ultrasound",
            "updated": "2023-11-27T17:46:08Z",
            "published": "2023-11-27T17:46:08Z",
            "summary": "A Transfer Function approach was recently demonstrated to mitigate data\nmismatches at the acquisition level for a single ultrasound scanner in deep\nlearning (DL) based quantitative ultrasound (QUS). As a natural progression, we\nfurther investigate the transfer function approach and introduce a\nMachine-to-Machine (M2M) Transfer Function, which possesses the ability to\nmitigate data mismatches at a machine level, i.e., mismatches between two\nscanners over the same frequency band. This ability opens the door to\nunprecedented opportunities for reducing DL model development costs, enabling\nthe combination of data from multiple sources or scanners, or facilitating the\ntransfer of DL models between machines with ease. We tested the proposed method\nutilizing a SonixOne machine and a Verasonics machine. In the experiments, we\nused a L9-4 array and conducted two types of acquisitions to obtain calibration\ndata: stable and free-hand, using two different calibration phantoms. Without\nthe proposed calibration method, the mean classification accuracy when applying\na model on data acquired from one system to data acquired from another system\nwas approximately 50%, and the mean AUC was about 0.40. With the proposed\nmethod, mean accuracy increased to approximately 90%, and the AUC rose to the\n0.99. Additional observations include that shifts in statistics for the z-score\nnormalization had a significant impact on performance. Furthermore, the choice\nof the calibration phantom played an important role in the proposed method.\nAdditionally, robust implementation inspired by Wiener filtering provided an\neffective method for transferring the domain from one machine to another\nmachine, and it can succeed using just a single calibration view without the\nneed for multiple independent calibration frames.",
            "author": [
                "Ufuk Soylu",
                "Michael L. Oelze"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16028v1",
                "http://arxiv.org/pdf/2311.16028v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16027v3",
            "title": "An HCAI Methodological Framework: Putting It Into Action to Enable\n  Human-Centered AI",
            "updated": "2023-11-30T23:30:38Z",
            "published": "2023-11-27T17:40:49Z",
            "summary": "Human-centered AI (HCAI), as a design philosophy, advocates prioritizing\nhumans in designing, developing, and deploying intelligent systems, aiming to\nmaximize the benefits of AI technology to humans and avoid its potential\nadverse effects. While HCAI has gained momentum, the lack of guidance on\nmethodology in its implementation makes its adoption challenging. After\nassessing the needs for a methodological framework for HCAI, this paper first\nproposes a comprehensive and interdisciplinary HCAI methodological framework\nintegrated with seven components, including design goals, design principles,\nimplementation approaches, design paradigms, interdisciplinary teams, methods,\nand processes. THe implications of the framework are also discussed. This paper\nalso presents a \"three-layer\" approach to facilitate the implementation of the\nframework. We believe the proposed framework is systematic and executable,\nwhich can overcome the weaknesses in current frameworks and the challenges\ncurrently faced in implementing HCAI. Thus, the framework can help put it into\naction to develop, transfer, and implement HCAI in practice, eventually\nenabling the design, development, and deployment of HCAI-based intelligent\nsystems.",
            "author": [
                "Wei Xu",
                "Zaifeng Gao",
                "Marvin Dainoff"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16027v3",
                "http://arxiv.org/pdf/2311.16027v3"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16024v1",
            "title": "MadRadar: A Black-Box Physical Layer Attack Framework on mmWave\n  Automotive FMCW Radars",
            "updated": "2023-11-27T17:38:14Z",
            "published": "2023-11-27T17:38:14Z",
            "summary": "Frequency modulated continuous wave (FMCW) millimeter-wave (mmWave) radars\nplay a critical role in many of the advanced driver assistance systems (ADAS)\nfeatured on today's vehicles. While previous works have demonstrated (only)\nsuccessful false-positive spoofing attacks against these sensors, all but one\nassumed that an attacker had the runtime knowledge of the victim radar's\nconfiguration. In this work, we introduce MadRadar, a general black-box radar\nattack framework for automotive mmWave FMCW radars capable of estimating the\nvictim radar's configuration in real-time, and then executing an attack based\non the estimates. We evaluate the impact of such attacks maliciously\nmanipulating a victim radar's point cloud, and show the novel ability to\neffectively `add' (i.e., false positive attacks), `remove' (i.e., false\nnegative attacks), or `move' (i.e., translation attacks) object detections from\na victim vehicle's scene. Finally, we experimentally demonstrate the\nfeasibility of our attacks on real-world case studies performed using a\nreal-time physical prototype on a software-defined radio platform.",
            "author": [
                "David Hunt",
                "Kristen Angell",
                "Zhenzhou Qi",
                "Tingjun Chen",
                "Miroslav Pajic"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16024v1",
                "http://arxiv.org/pdf/2311.16024v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16019v1",
            "title": "Sketched and Truncated Polynomial Krylov Subspace Methods: Matrix\n  Equations",
            "updated": "2023-11-27T17:33:26Z",
            "published": "2023-11-27T17:33:26Z",
            "summary": "Thanks to its great potential in reducing both computational cost and memory\nrequirements, combining sketching and Krylov subspace techniques has attracted\na lot of attention in the recent literature on projection methods for linear\nsystems, matrix function approximations, and eigenvalue problems. Applying this\nappealing strategy in the context of linear matrix equations turns out to be\nfar more involved than a straightforward generalization. These difficulties\ninclude establishing well-posedness of the projected problem and deriving\npossible error estimates depending on the sketching properties. Further\ncomputational complications include the lack of a natural residual norm\nestimate and of an explicit basis for the generated subspace. In this paper we\npropose a new sketched-and-truncated polynomial Krylov subspace method for\nSylvester equations that aims to address all these issues. The potential of our\nnovel approach, in terms of both computational time and storage demand, is\nillustrated with numerical experiments. Comparisons with a state-of-the-art\nprojection scheme based on rational Krylov subspaces are also included.",
            "author": [
                "Davide Palitta",
                "Marcel Schweitzer",
                "Valeria Simoncini"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16019v1",
                "http://arxiv.org/pdf/2311.16019v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA",
                "65F45, 68W20, 65F25, 65F50"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16502v1",
            "title": "MMMU: A Massive Multi-discipline Multimodal Understanding and Reasoning\n  Benchmark for Expert AGI",
            "updated": "2023-11-27T17:33:21Z",
            "published": "2023-11-27T17:33:21Z",
            "summary": "We introduce MMMU: a new benchmark designed to evaluate multimodal models on\nmassive multi-discipline tasks demanding college-level subject knowledge and\ndeliberate reasoning. MMMU includes 11.5K meticulously collected multimodal\nquestions from college exams, quizzes, and textbooks, covering six core\ndisciplines: Art & Design, Business, Science, Health & Medicine, Humanities &\nSocial Science, and Tech & Engineering. These questions span 30 subjects and\n183 subfields, comprising 30 highly heterogeneous image types, such as charts,\ndiagrams, maps, tables, music sheets, and chemical structures. Unlike existing\nbenchmarks, MMMU focuses on advanced perception and reasoning with\ndomain-specific knowledge, challenging models to perform tasks akin to those\nfaced by experts. Our evaluation of 14 open-source LMMs and the proprietary\nGPT-4V(ision) highlights the substantial challenges posed by MMMU. Even the\nadvanced GPT-4V only achieves a 56% accuracy, indicating significant room for\nimprovement. We believe MMMU will stimulate the community to build\nnext-generation multimodal foundation models towards expert artificial general\nintelligence.",
            "author": [
                "Xiang Yue",
                "Yuansheng Ni",
                "Kai Zhang",
                "Tianyu Zheng",
                "Ruoqi Liu",
                "Ge Zhang",
                "Samuel Stevens",
                "Dongfu Jiang",
                "Weiming Ren",
                "Yuxuan Sun",
                "Cong Wei",
                "Botao Yu",
                "Ruibin Yuan",
                "Renliang Sun",
                "Ming Yin",
                "Boyuan Zheng",
                "Zhenzhu Yang",
                "Yibo Liu",
                "Wenhao Huang",
                "Huan Sun",
                "Yu Su",
                "Wenhu Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16502v1",
                "http://arxiv.org/pdf/2311.16502v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16017v1",
            "title": "Decoding Logic Errors: A Comparative Study on Bug Detection by Students\n  and Large Language Models",
            "updated": "2023-11-27T17:28:33Z",
            "published": "2023-11-27T17:28:33Z",
            "summary": "Identifying and resolving logic errors can be one of the most frustrating\nchallenges for novices programmers. Unlike syntax errors, for which a compiler\nor interpreter can issue a message, logic errors can be subtle. In certain\nconditions, buggy code may even exhibit correct behavior -- in other cases, the\nissue might be about how a problem statement has been interpreted. Such errors\ncan be hard to spot when reading the code, and they can also at times be missed\nby automated tests. There is great educational potential in automatically\ndetecting logic errors, especially when paired with suitable feedback for\nnovices. Large language models (LLMs) have recently demonstrated surprising\nperformance for a range of computing tasks, including generating and explaining\ncode. These capabilities are closely linked to code syntax, which aligns with\nthe next token prediction behavior of LLMs. On the other hand, logic errors\nrelate to the runtime performance of code and thus may not be as well suited to\nanalysis by LLMs. To explore this, we investigate the performance of two\npopular LLMs, GPT-3 and GPT-4, for detecting and providing a novice-friendly\nexplanation of logic errors. We compare LLM performance with a large cohort of\nintroductory computing students $(n=964)$ solving the same error detection\ntask. Through a mixed-methods analysis of student and model responses, we\nobserve significant improvement in logic error identification between the\nprevious and current generation of LLMs, and find that both LLM generations\nsignificantly outperform students. We outline how such models could be\nintegrated into computing education tools, and discuss their potential for\nsupporting students when learning programming.",
            "author": [
                "Stephen MacNeil",
                "Paul Denny",
                "Andrew Tran",
                "Juho Leinonen",
                "Seth Bernstein",
                "Arto Hellas",
                "Sami Sarsa",
                "Joanne Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16017v1",
                "http://arxiv.org/pdf/2311.16017v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16012v1",
            "title": "Acceleration of Solvation Free Energy Calculation via Thermodynamic\n  Integration Coupled with Gaussian Process Regression and Improved\n  Gelman-Rubin Convergence Diagnostics",
            "updated": "2023-11-27T17:12:12Z",
            "published": "2023-11-27T17:12:12Z",
            "summary": "The determination of the solvation free energy of ions and molecules holds\nprofound importance across a spectrum of applications spanning chemistry,\nbiology, energy storage, and the environment. Molecular dynamics simulations\nare a powerful tool for computing this critical parameter. Nevertheless, the\naccurate and efficient calculation of solvation free energy becomes a\nformidable endeavor when dealing with complex systems characterized by potent\nCoulombic interactions and sluggish ion dynamics and, consequently, slow\ntransition across various metastable states. In the present study, we expose\nlimitations stemming from the conventional calculation of the statistical\ninefficiency g in the thermodynamic integration method, a factor that can\nhinder the determination of convergence of the solvation free energy and its\nassociated uncertainty. Instead, we propose a robust scheme based on\nGelman-Rubin convergence diagnostics. We leverage this improved estimation of\nuncertainties to introduce an innovative accelerated thermodynamic integration\nmethod based on Gaussian Process regression. This methodology is applied to the\ncalculation of the solvation free energy of trivalent rare earth elements\nimmersed in ionic liquids, a scenario where the aforementioned challenges\nrender standard approaches ineffective. The proposed method proves effective in\ncomputing solvation free energy in situations where traditional thermodynamic\nintegration methods fall short.",
            "author": [
                "Zhou Yu",
                "Enrique R. Batista",
                "Ping Yang",
                "Danny Perez"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16012v1",
                "http://arxiv.org/pdf/2311.16012v1"
            ],
            "primary_category": "cond-mat.mes-hall",
            "category": [
                "cond-mat.mes-hall",
                "physics.atom-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16011v1",
            "title": "Wannier charge center, spin resolved bulk polarization and corner modes\n  in a strained quantum spin Hall insulator",
            "updated": "2023-11-27T17:10:03Z",
            "published": "2023-11-27T17:10:03Z",
            "summary": "Topological invariants are a significant ingredient in the study of\ntopological phases of matter that intertwines the supposedly contradicting\nconcepts of bulk and boundary. The nature of the invariants differ depending on\nthe dimension of the boundary at which the topological states manifest\nthemselves. The primary motivation of this work is to study two distinct\nscenarios of topological phase, differing in the dimensionality of their\nboundary states and study the associated bulk topological invariants that\ncharacterize them. In this regard, we study the band engineered Kane Mele model\nwhich originally is a prototypical example of a system that hosts quantum spin\nHall effect on a honeycomb lattice. Under a smooth band deformation caused by\nvarying one of the nearest neighbor hopping amplitudes (say $t_1$) as compared\nto the other two (say $t$), we observe that the system transits from its first\norder topological insulating state (or quantum spin Hall state) to a second\norder topological insulating (SOTI) state via a gap closing transition. This\ntransition occurs when the system crosses a particular threshold of the\ndeformation parameter $t_1\\mathbin{/}t$ (namely $t_1\\mathbin{/}t=2$). We show\nthe presence of edge and corner modes as a signature of first and second order\ntopology respectively. Further, we observe the evolution of the Wannier charge\ncenter (WCC), a bulk property as a function of the deformation parameter\n${t_1}\\mathbin{/}{t}$. We also find that, while the $\\mathbb{Z}_2$ invariant\nsuccessfully characterizes the QSH state, it cannot characterize higher order\ntopology (second order here). The model being mirror invariant, we also\ncalculate mirror winding number to show that it is rendered trivial in the SOTI\nphase as well, while being non-trivial in the QSH phase. Finally, spin resolved\nbulk polarization establishes the SOTI phase as obstructed atomic insulator.",
            "author": [
                "Srijata Lahiri",
                "Saurabh Basu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16011v1",
                "http://arxiv.org/pdf/2311.16011v1"
            ],
            "primary_category": "cond-mat.mes-hall",
            "category": [
                "cond-mat.mes-hall"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16009v1",
            "title": "On Split-State Quantum Tamper Detection and Non-Malleability",
            "updated": "2023-11-27T17:09:02Z",
            "published": "2023-11-27T17:09:02Z",
            "summary": "Tamper-detection codes (TDCs) and non-malleable codes (NMCs) are now\nfundamental objects at the intersection of cryptography and coding theory. Both\nof these primitives represent natural relaxations of error-correcting codes and\noffer related security guarantees in adversarial settings where error\ncorrection is impossible. While in a TDC, the decoder is tasked with either\nrecovering the original message or rejecting it, in an NMC, the decoder is\nadditionally allowed to output a completely unrelated message.\n  In this work, we study quantum analogs of one of the most well-studied\nadversarial tampering models: the so-called split-state tampering model. In the\n$t$-split-state model, the codeword (or code-state) is divided into $t$ shares,\nand each share is tampered with \"locally\". Previous research has primarily\nfocused on settings where the adversaries' local quantum operations are\nassisted by an unbounded amount of pre-shared entanglement, while the code\nremains unentangled, either classical or separable.\n  We construct quantum TDCs and NMCs in several $\\textit{resource-restricted}$\nanalogs of the split-state model, which are provably impossible using just\nclassical codes. In particular, against split-state adversaries restricted to\nlocal (unentangled) operations, local operations and classical communication,\nas well as a \"bounded storage model\" where they are limited to a finite amount\nof pre-shared entanglement. We complement our code constructions in two\ndirections. First, we present applications to designing secret sharing schemes,\nwhich inherit similar non-malleable and tamper-detection guarantees. Second, we\ndiscuss connections between our codes and quantum encryption schemes, which we\nleverage to prove singleton-type bounds on the capacity of certain families of\nquantum NMCs in the split-state model.",
            "author": [
                "Thiago Bergamaschi",
                "Naresh Goud Boddu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16009v1",
                "http://arxiv.org/pdf/2311.16009v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16492v1",
            "title": "VLPrompt: Vision-Language Prompting for Panoptic Scene Graph Generation",
            "updated": "2023-11-27T17:05:25Z",
            "published": "2023-11-27T17:05:25Z",
            "summary": "Panoptic Scene Graph Generation (PSG) aims at achieving a comprehensive image\nunderstanding by simultaneously segmenting objects and predicting relations\namong objects. However, the long-tail problem among relations leads to\nunsatisfactory results in real-world applications. Prior methods predominantly\nrely on vision information or utilize limited language information, such as\nobject or relation names, thereby overlooking the utility of language\ninformation. Leveraging the recent progress in Large Language Models (LLMs), we\npropose to use language information to assist relation prediction, particularly\nfor rare relations. To this end, we propose the Vision-Language Prompting\n(VLPrompt) model, which acquires vision information from images and language\ninformation from LLMs. Then, through a prompter network based on attention\nmechanism, it achieves precise relation prediction. Our extensive experiments\nshow that VLPrompt significantly outperforms previous state-of-the-art methods\non the PSG dataset, proving the effectiveness of incorporating language\ninformation and alleviating the long-tail problem of relations.",
            "author": [
                "Zijian Zhou",
                "Miaojing Shi",
                "Holger Caesar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16492v1",
                "http://arxiv.org/pdf/2311.16492v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16004v1",
            "title": "Improved Data Generation for Enhanced Asset Allocation: A Synthetic\n  Dataset Approach for the Fixed Income Universe",
            "updated": "2023-11-27T16:55:04Z",
            "published": "2023-11-27T16:55:04Z",
            "summary": "We present a novel process for generating synthetic datasets tailored to\nassess asset allocation methods and construct portfolios within the fixed\nincome universe. Our approach begins by enhancing the CorrGAN model to generate\nsynthetic correlation matrices. Subsequently, we propose an Encoder-Decoder\nmodel that samples additional data conditioned on a given correlation matrix.\nThe resulting synthetic dataset facilitates in-depth analyses of asset\nallocation methods across diverse asset universes. Additionally, we provide a\ncase study that exemplifies the use of the synthetic dataset to improve\nportfolios constructed within a simulation-based asset allocation process.",
            "author": [
                "Szymon Kubiak",
                "Tillman Weyde",
                "Oleksandr Galkin",
                "Dan Philps",
                "Ram Gopal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16004v1",
                "http://arxiv.org/pdf/2311.16004v1"
            ],
            "primary_category": "q-fin.ST",
            "category": [
                "q-fin.ST",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16208v1",
            "title": "InstructMol: Multi-Modal Integration for Building a Versatile and\n  Reliable Molecular Assistant in Drug Discovery",
            "updated": "2023-11-27T16:47:51Z",
            "published": "2023-11-27T16:47:51Z",
            "summary": "The rapid evolution of artificial intelligence in drug discovery encounters\nchallenges with generalization and extensive training, yet Large Language\nModels (LLMs) offer promise in reshaping interactions with complex molecular\ndata. Our novel contribution, InstructMol, a multi-modal LLM, effectively\naligns molecular structures with natural language via an instruction-tuning\napproach, utilizing a two-stage training strategy that adeptly combines limited\ndomain-specific data with molecular and textual information. InstructMol\nshowcases substantial performance improvements in drug discovery-related\nmolecular tasks, surpassing leading LLMs and significantly reducing the gap\nwith specialized models, thereby establishing a robust foundation for a\nversatile and dependable drug discovery assistant.",
            "author": [
                "He Cao",
                "Zijing Liu",
                "Xingyu Lu",
                "Yuan Yao",
                "Yu Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16208v1",
                "http://arxiv.org/pdf/2311.16208v1"
            ],
            "primary_category": "q-bio.BM",
            "category": [
                "q-bio.BM",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16001v1",
            "title": "Automated Measurement of Vascular Calcification in Femoral\n  Endarterectomy Patients Using Deep Learning",
            "updated": "2023-11-27T16:47:09Z",
            "published": "2023-11-27T16:47:09Z",
            "summary": "Atherosclerosis, a chronic inflammatory disease affecting the large arteries,\npresents a global health risk. Accurate analysis of diagnostic images, like\ncomputed tomographic angiograms (CTAs), is essential for staging and monitoring\nthe progression of atherosclerosis-related conditions, including peripheral\narterial disease (PAD). However, manual analysis of CTA images is\ntime-consuming and tedious. To address this limitation, we employed a deep\nlearning model to segment the vascular system in CTA images of PAD patients\nundergoing femoral endarterectomy surgery and to measure vascular calcification\nfrom the left renal artery to the patella. Utilizing proprietary CTA images of\n27 patients undergoing femoral endarterectomy surgery provided by Prisma Health\nMidlands, we developed a Deep Neural Network (DNN) model to first segment the\narterial system, starting from the descending aorta to the patella, and second,\nto provide a metric of arterial calcification. Our designed DNN achieved 83.4%\naverage Dice accuracy in segmenting arteries from aorta to patella, advancing\nthe state-of-the-art by 0.8%. Furthermore, our work is the first to present a\nrobust statistical analysis of automated calcification measurement in the lower\nextremities using deep learning, attaining a Mean Absolute Percentage Error\n(MAPE) of 9.5% and a correlation coefficient of 0.978 between automated and\nmanual calcification scores. These findings underscore the potential of deep\nlearning techniques as a rapid and accurate tool for medical professionals to\nassess calcification in the abdominal aorta and its branches above the patella.\nThe developed DNN model and related documentation in this project are available\nat GitHub page at https://github.com/pip-alireza/DeepCalcScoring.",
            "author": [
                "Alireza Bagheri Rajeoni",
                "Breanna Pederson",
                "Daniel G. Clair",
                "Susan M. Lessner",
                "Homayoun Valafar"
            ],
            "link": [
                "http://dx.doi.org/10.3390/diagnostics13213363",
                "http://arxiv.org/abs/2311.16001v1",
                "http://arxiv.org/pdf/2311.16001v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG",
                "I.4.6; I.4.8; I.4.0; I.2.1"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16000v1",
            "title": "Bifurcation diagrams for spacetime singularities and black holes",
            "updated": "2023-11-27T16:46:36Z",
            "published": "2023-11-27T16:46:36Z",
            "summary": "We reexamine the focusing effect crucial to the theorems that predict the\nemergence of spacetime singularities and various results in the general theory\nof black holes in general relativity. Our investigation incorporates the fully\nnonlinear and dispersive nature of the underlying equations. We introduce and\nthoroughly explore the concept of versal unfolding (topological normal form)\nwithin the framework of the Newman-Penrose-Raychaudhuri system, the\nconvergence-vorticity equations (notably the first and third Sachs optical\nequations), and the Oppenheimer-Snyder equation governing exactly spherical\ncollapse. The findings lead to a novel dynamical depiction of spacetime\nsingularities and black holes, exposing their continuous transformations into\nnew topological configurations guided by the bifurcation diagrams associated\nwith these problems.",
            "author": [
                "Spiros Cotsakis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16000v1",
                "http://arxiv.org/pdf/2311.16000v1"
            ],
            "primary_category": "gr-qc",
            "category": [
                "gr-qc",
                "hep-th"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15999v1",
            "title": "Microarchitectural Security of AWS Firecracker VMM for Serverless Cloud\n  Platforms",
            "updated": "2023-11-27T16:46:03Z",
            "published": "2023-11-27T16:46:03Z",
            "summary": "Firecracker is a virtual machine manager (VMM) built by Amazon Web Services\n(AWS) for serverless cloud platforms, services that run code for end users on a\nper-task basis, automatically managing server infrastructure. Firecracker\nprovides fast and lightweight VMs and promises a combination of the speed of\ncontainers, typically used to isolate small tasks, and the security of VMs,\nwhich tend to provide greater isolation at the cost of performance. This\ncombination of security and efficiency, AWS claims, makes it not only possible\nbut safe to run thousands of user tasks from different users on the same\nhardware, with the host system frequently switching between active tasks.\nThough AWS states that microarchitectural attacks are included in their threat\nmodel, this class of attacks directly relies on shared hardware, just as the\nscalability of serverless computing relies on sharing hardware between\nunprecedented numbers of users. In this work, we investigate how secure\nFirecracker is against microarchitectural attacks. First, we review\nFirecracker's stated isolation model and recommended best practices for\ndeployment, identify potential threat models for serverless platforms, and\nanalyze potential weak points. Then, we use microarchitectural attack\nproof-of-concepts to test the isolation provided by Firecracker and find that\nit offers little protection against Spectre or MDS attacks. We discover two\nparticularly concerning cases: 1) a Medusa variant that threatens Firecracker\nVMs but not processes running outside them, and is not mitigated by defenses\nrecommended by AWS, and 2) a Spectre-PHT variant that remains exploitable even\nif recommended countermeasures are in place and SMT is disabled in the system.\nIn summary, we show that AWS overstates the security inherent to the\nFirecracker VMM and provides incomplete guidance for properly securing cloud\nsystems that use Firecracker.",
            "author": [
                "Zane Weissman",
                "Thore Tiemann",
                "Thomas Eisenbarth",
                "Berk Sunar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15999v1",
                "http://arxiv.org/pdf/2311.15999v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15995v1",
            "title": "Sensitivity-Based Layer Insertion for Residual and Feedforward Neural\n  Networks",
            "updated": "2023-11-27T16:44:13Z",
            "published": "2023-11-27T16:44:13Z",
            "summary": "The training of neural networks requires tedious and often manual tuning of\nthe network architecture. We propose a systematic method to insert new layers\nduring the training process, which eliminates the need to choose a fixed\nnetwork size before training. Our technique borrows techniques from constrained\noptimization and is based on first-order sensitivity information of the\nobjective with respect to the virtual parameters that additional layers, if\ninserted, would offer. We consider fully connected feedforward networks with\nselected activation functions as well as residual neural networks. In numerical\nexperiments, the proposed sensitivity-based layer insertion technique exhibits\nimproved training decay, compared to not inserting the layer. Furthermore, the\ncomputational effort is reduced in comparison to inserting the layer from the\nbeginning. The code is available at\n\\url{https://github.com/LeonieKreis/layer_insertion_sensitivity_based}.",
            "author": [
                "Evelyn Herberg",
                "Roland Herzog",
                "Frederik K\u00f6hne",
                "Leonie Kreis",
                "Anton Schiela"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15995v1",
                "http://arxiv.org/pdf/2311.15995v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16512v3",
            "title": "CoSeR: Bridging Image and Language for Cognitive Super-Resolution",
            "updated": "2023-12-02T05:12:04Z",
            "published": "2023-11-27T16:33:29Z",
            "summary": "Existing super-resolution (SR) models primarily focus on restoring local\ntexture details, often neglecting the global semantic information within the\nscene. This oversight can lead to the omission of crucial semantic details or\nthe introduction of inaccurate textures during the recovery process. In our\nwork, we introduce the Cognitive Super-Resolution (CoSeR) framework, empowering\nSR models with the capacity to comprehend low-resolution images. We achieve\nthis by marrying image appearance and language understanding to generate a\ncognitive embedding, which not only activates prior information from large\ntext-to-image diffusion models but also facilitates the generation of\nhigh-quality reference images to optimize the SR process. To further improve\nimage fidelity, we propose a novel condition injection scheme called\n\"All-in-Attention\", consolidating all conditional information into a single\nmodule. Consequently, our method successfully restores semantically correct and\nphotorealistic details, demonstrating state-of-the-art performance across\nmultiple benchmarks. Code: https://github.com/VINHYU/CoSeR",
            "author": [
                "Haoze Sun",
                "Wenbo Li",
                "Jianzhuang Liu",
                "Haoyu Chen",
                "Renjing Pei",
                "Xueyi Zou",
                "Youliang Yan",
                "Yujiu Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16512v3",
                "http://arxiv.org/pdf/2311.16512v3"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15985v1",
            "title": "Value-Based Reinforcement Learning for Digital Twins in Cloud Computing",
            "updated": "2023-11-27T16:29:34Z",
            "published": "2023-11-27T16:29:34Z",
            "summary": "The setup considered in the paper consists of sensors in a Networked Control\nSystem that are used to build a digital twin (DT) model of the system dynamics.\nThe focus is on control, scheduling, and resource allocation for sensory\nobservation to ensure timely delivery to the DT model deployed in the cloud.\nLow latency and communication timeliness are instrumental in ensuring that the\nDT model can accurately estimate and predict system states. However, acquiring\ndata for efficient state estimation and control computing poses a non-trivial\nproblem given the limited network resources, partial state vector information,\nand measurement errors encountered at distributed sensors. We propose the\nREinforcement learning and Variational Extended Kalman filter with Robust\nBelief (REVERB), which leverages a reinforcement learning solution combined\nwith a Value of Information-based algorithm for performing optimal control and\nselecting the most informative sensors to satisfy the prediction accuracy of\nDT. Numerical results demonstrate that the DT platform can offer satisfactory\nperformance while reducing the communication overhead up to five times.",
            "author": [
                "Van-Phuc Bui",
                "Shashi Raj Pandey",
                "Pedro M. de Sant Ana",
                "Petar Popovski"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15985v1",
                "http://arxiv.org/pdf/2311.15985v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15983v1",
            "title": "Sparsify-then-Classify: From Internal Neurons of Large Language Models\n  To Efficient Text Classifiers",
            "updated": "2023-11-27T16:28:20Z",
            "published": "2023-11-27T16:28:20Z",
            "summary": "Among the many tasks that Large Language Models (LLMs) have revolutionized is\ntext classification. However, existing approaches for applying pretrained LLMs\nto text classification predominantly rely on using single token outputs from\nonly the last layer of hidden states. As a result, they suffer from limitations\nin efficiency, task-specificity, and interpretability. In our work, we\ncontribute an approach that uses all internal representations by employing\nmultiple pooling strategies on all activation and hidden states. Our novel\nlightweight strategy, Sparsify-then-Classify (STC) first sparsifies\ntask-specific features layer-by-layer, then aggregates across layers for text\nclassification. STC can be applied as a seamless plug-and-play module on top of\nexisting LLMs. Our experiments on a comprehensive set of models and datasets\ndemonstrate that STC not only consistently improves the classification\nperformance of pretrained and fine-tuned models, but is also more efficient for\nboth training and inference, and is more intrinsically interpretable.",
            "author": [
                "Yilun Liu",
                "Difan Jiao",
                "Ashton Anderson"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15983v1",
                "http://arxiv.org/pdf/2311.15983v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15980v1",
            "title": "Direct2.5: Diverse Text-to-3D Generation via Multi-view 2.5D Diffusion",
            "updated": "2023-11-27T16:26:54Z",
            "published": "2023-11-27T16:26:54Z",
            "summary": "Recent advances in generative AI have unveiled significant potential for the\ncreation of 3D content. However, current methods either apply a pre-trained 2D\ndiffusion model with the time-consuming score distillation sampling (SDS), or a\ndirect 3D diffusion model trained on limited 3D data losing generation\ndiversity. In this work, we approach the problem by employing a multi-view 2.5D\ndiffusion fine-tuned from a pre-trained 2D diffusion model. The multi-view 2.5D\ndiffusion directly models the structural distribution of 3D data, while still\nmaintaining the strong generalization ability of the original 2D diffusion\nmodel, filling the gap between 2D diffusion-based and direct 3D diffusion-based\nmethods for 3D content generation. During inference, multi-view normal maps are\ngenerated using the 2.5D diffusion, and a novel differentiable rasterization\nscheme is introduced to fuse the almost consistent multi-view normal maps into\na consistent 3D model. We further design a normal-conditioned multi-view image\ngeneration module for fast appearance generation given the 3D geometry. Our\nmethod is a one-pass diffusion process and does not require any SDS\noptimization as post-processing. We demonstrate through extensive experiments\nthat, our direct 2.5D generation with the specially-designed fusion scheme can\nachieve diverse, mode-seeking-free, and high-fidelity 3D content generation in\nonly 10 seconds. Project page: https://nju-3dv.github.io/projects/direct25.",
            "author": [
                "Yuanxun Lu",
                "Jingyang Zhang",
                "Shiwei Li",
                "Tian Fang",
                "David McKinnon",
                "Yanghai Tsin",
                "Long Quan",
                "Xun Cao",
                "Yao Yao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15980v1",
                "http://arxiv.org/pdf/2311.15980v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15977v1",
            "title": "Text2Loc: 3D Point Cloud Localization from Natural Language",
            "updated": "2023-11-27T16:23:01Z",
            "published": "2023-11-27T16:23:01Z",
            "summary": "We tackle the problem of 3D point cloud localization based on a few natural\nlinguistic descriptions and introduce a novel neural network, Text2Loc, that\nfully interprets the semantic relationship between points and text. Text2Loc\nfollows a coarse-to-fine localization pipeline: text-submap global place\nrecognition, followed by fine localization. In global place recognition,\nrelational dynamics among each textual hint are captured in a hierarchical\ntransformer with max-pooling (HTM), whereas a balance between positive and\nnegative pairs is maintained using text-submap contrastive learning. Moreover,\nwe propose a novel matching-free fine localization method to further refine the\nlocation predictions, which completely removes the need for complicated\ntext-instance matching and is lighter, faster, and more accurate than previous\nmethods. Extensive experiments show that Text2Loc improves the localization\naccuracy by up to $2\\times$ over the state-of-the-art on the KITTI360Pose\ndataset. We will make the code publicly available.",
            "author": [
                "Yan Xia",
                "Letian Shi",
                "Zifeng Ding",
                "Jo\u00e3o F. Henriques",
                "Daniel Cremers"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15977v1",
                "http://arxiv.org/pdf/2311.15977v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15974v1",
            "title": "Adaptive Agents and Data Quality in Agent-Based Financial Markets",
            "updated": "2023-11-27T16:18:30Z",
            "published": "2023-11-27T16:18:30Z",
            "summary": "We present our Agent-Based Market Microstructure Simulation (ABMMS), an\nAgent-Based Financial Market (ABFM) that captures much of the complexity\npresent in the US National Market System for equities (NMS). Agent-Based models\nare a natural choice for understanding financial markets. Financial markets\nfeature a constrained action space that should simplify model creation, produce\na wealth of data that should aid model validation, and a successful ABFM could\nstrongly impact system design and policy development processes. Despite these\nadvantages, ABFMs have largely remained an academic novelty. We hypothesize\nthat two factors limit the usefulness of ABFMs. First, many ABFMs fail to\ncapture relevant microstructure mechanisms, leading to differences in the\nmechanics of trading. Second, the simple agents that commonly populate ABFMs do\nnot display the breadth of behaviors observed in human traders or the trading\nsystems that they create. We investigate these issues through the development\nof ABMMS, which features a fragmented market structure, communication\ninfrastructure with propagation delays, realistic auction mechanisms, and more.\nAs a baseline, we populate ABMMS with simple trading agents and investigate\nproperties of the generated data. We then compare the baseline with\nexperimental conditions that explore the impacts of market topology or\nmeta-reinforcement learning agents. The combination of detailed market\nmechanisms and adaptive agents leads to models whose generated data more\naccurately reproduce stylized facts observed in actual markets. These\nimprovements increase the utility of ABFMs as tools to inform design and policy\ndecisions.",
            "author": [
                "Colin M. Van Oort",
                "Ethan Ratliff-Crain",
                "Brian F. Tivnan",
                "Safwan Wshah"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15974v1",
                "http://arxiv.org/pdf/2311.15974v1"
            ],
            "primary_category": "q-fin.TR",
            "category": [
                "q-fin.TR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15973v1",
            "title": "Quantum simulation of entanglement dynamics in a quantum processor",
            "updated": "2023-11-27T16:15:05Z",
            "published": "2023-11-27T16:15:05Z",
            "summary": "We implement a five-qubit protocol in IBM quantum processors to get\nentanglement dynamics in a two qubit system in the presence of an environment.\nSpecifically, two qubits represent the main system, another two qubits the\nenvironment, and an additional qubit is used as an auxiliary qubit to perform\nthe quantum entanglement estimation. We focus on measuring, in this\nsuperconducting quantum processor, the sudden death and sudden birth of\nentanglement. We obtain the quantum entanglement evolution of the main system\nqubits and the environment qubits as the average of $N=10$ independent\nexperiments in the same quantum device, observing that the noisy nature of\ncurrent quantum processors produce a shift on times signaling sudden death o\nsudden birth of entanglement. This work takes relevance showing the usefulness\nof current noisy quantum devices to test fundamental concepts in quantum\ninformation.",
            "author": [
                "C. Inzulza",
                "S. Saavedra-Pino",
                "F. Albarr\u00e1n-Arriagada",
                "P. Roman",
                "J. C. Retamal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15973v1",
                "http://arxiv.org/pdf/2311.15973v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15966v1",
            "title": "Towards Transfer Learning for Large-Scale Image Classification Using\n  Annealing-based Quantum Boltzmann Machines",
            "updated": "2023-11-27T16:07:49Z",
            "published": "2023-11-27T16:07:49Z",
            "summary": "Quantum Transfer Learning (QTL) recently gained popularity as a hybrid\nquantum-classical approach for image classification tasks by efficiently\ncombining the feature extraction capabilities of large Convolutional Neural\nNetworks with the potential benefits of Quantum Machine Learning (QML).\nExisting approaches, however, only utilize gate-based Variational Quantum\nCircuits for the quantum part of these procedures. In this work we present an\napproach to employ Quantum Annealing (QA) in QTL-based image classification.\nSpecifically, we propose using annealing-based Quantum Boltzmann Machines as\npart of a hybrid quantum-classical pipeline to learn the classification of\nreal-world, large-scale data such as medical images through supervised\ntraining. We demonstrate our approach by applying it to the three-class\nCOVID-CT-MD dataset, a collection of lung Computed Tomography (CT) scan slices.\nUsing Simulated Annealing as a stand-in for actual QA, we compare our method to\nclassical transfer learning, using a neural network of the same order of\nmagnitude, to display its improved classification performance. We find that our\napproach consistently outperforms its classical baseline in terms of test\naccuracy and AUC-ROC-Score and needs less training epochs to do this.",
            "author": [
                "Dani\u00eblle Schuman",
                "Leo S\u00fcnkel",
                "Philipp Altmann",
                "Jonas Stein",
                "Christoph Roch",
                "Thomas Gabor",
                "Claudia Linnhoff-Popien"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15966v1",
                "http://arxiv.org/pdf/2311.15966v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.ET",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15964v1",
            "title": "Efficient Pre-training for Localized Instruction Generation of Videos",
            "updated": "2023-11-27T16:07:37Z",
            "published": "2023-11-27T16:07:37Z",
            "summary": "Procedural videos show step-by-step demonstrations of tasks like recipe\npreparation. Understanding such videos is challenging, involving the precise\nlocalization of steps and the generation of textual instructions. Manually\nannotating steps and writing instructions is costly, which limits the size of\ncurrent datasets and hinders effective learning. Leveraging large but noisy\nvideo-transcript datasets for pre-training can boost performance, but demands\nsignificant computational resources. Furthermore, transcripts contain\nirrelevant content and exhibit style variation compared to instructions written\nby human annotators. To mitigate both issues, we propose a technique,\nSieve-&-Swap, to automatically curate a smaller dataset: (i) Sieve filters\nirrelevant transcripts and (ii) Swap enhances the quality of the text\ninstruction by automatically replacing the transcripts with human-written\ninstructions from a text-only recipe dataset. The curated dataset, three orders\nof magnitude smaller than current web-scale datasets, enables efficient\ntraining of large-scale models with competitive performance. We complement our\nSieve-\\&-Swap approach with a Procedure Transformer (ProcX) for end-to-end step\nlocalization and instruction generation for procedural videos. When this model\nis pre-trained on our curated dataset, it achieves state-of-the-art performance\nin zero-shot and finetuning settings on YouCook2 and Tasty, while using a\nfraction of the computational resources.",
            "author": [
                "Anil Batra",
                "Davide Moltisanti",
                "Laura Sevilla-Lara",
                "Marcus Rohrbach",
                "Frank Keller"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15964v1",
                "http://arxiv.org/pdf/2311.15964v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15960v1",
            "title": "Addressing Long-Horizon Tasks by Integrating Program Synthesis and State\n  Machines",
            "updated": "2023-11-27T16:06:39Z",
            "published": "2023-11-27T16:06:39Z",
            "summary": "Deep reinforcement learning excels in various domains but lacks\ngeneralizability and interoperability. Programmatic RL methods (Trivedi et al.,\n2021; Liu et al., 2023) reformulate solving RL tasks as synthesizing\ninterpretable programs that can be executed in the environments. Despite\nencouraging results, these methods are limited to short-horizon tasks. On the\nother hand, representing RL policies using state machines (Inala et al., 2020)\ncan inductively generalize to long-horizon tasks; however, it struggles to\nscale up to acquire diverse and complex behaviors. This work proposes Program\nMachine Policies (POMPs), which bridge the advantages of programmatic RL and\nstate machine policies, allowing for the representation of complex behaviors\nand the address of long-term tasks. Specifically, we introduce a method that\ncan retrieve a set of effective, diverse, compatible programs. Then, we use\nthese programs as modes of a state machine and learn a transition function to\ntransition among mode programs, allowing for capturing long-horizon repetitive\nbehaviors. Our proposed framework outperforms programmatic RL and deep RL\nbaselines on various tasks and demonstrates the ability to generalize to even\nlonger horizons without any fine-tuning inductively. Ablation studies justify\nthe effectiveness of our proposed search algorithm for retrieving a set of\nprograms as modes.",
            "author": [
                "Yu-An Lin",
                "Chen-Tao Lee",
                "Guan-Ting Liu",
                "Pu-Jen Cheng",
                "Shao-Hua Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15960v1",
                "http://arxiv.org/pdf/2311.15960v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.PL",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15959v1",
            "title": "CheapNET: Improving Light-weight speech enhancement network by projected\n  loss function",
            "updated": "2023-11-27T16:03:42Z",
            "published": "2023-11-27T16:03:42Z",
            "summary": "Noise suppression and echo cancellation are critical in speech enhancement\nand essential for smart devices and real-time communication. Deployed in voice\nprocessing front-ends and edge devices, these algorithms must ensure efficient\nreal-time inference with low computational demands. Traditional edge-based\nnoise suppression often uses MSE-based amplitude spectrum mask training, but\nthis approach has limitations. We introduce a novel projection loss function,\ndiverging from MSE, to enhance noise suppression. This method uses projection\ntechniques to isolate key audio components from noise, significantly improving\nmodel performance. For echo cancellation, the function enables direct\npredictions on LAEC pre-processed outputs, substantially enhancing performance.\nOur noise suppression model achieves near state-of-the-art results with only\n3.1M parameters and 0.4GFlops/s computational load. Moreover, our echo\ncancellation model outperforms replicated industry-leading models, introducing\na new perspective in speech enhancement.",
            "author": [
                "Kaijun Tan",
                "Benzhe Dai",
                "Jiakui Li",
                "Wenyu Mao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15959v1",
                "http://arxiv.org/pdf/2311.15959v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.AI",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15955v1",
            "title": "NN bundle method applied to cosmology: an improvement in computational\n  times",
            "updated": "2023-11-27T15:58:37Z",
            "published": "2023-11-27T15:58:37Z",
            "summary": "In the last few years, there has been significant progress in the development\nof machine learning methods tailored to astrophysics and cosmology. Among the\nvarious methods that have been developed, there is one that allows to obtain a\nbundle of solutions of differential systems without the need of using\ntraditional numerical solvers. We have recently applied this to the\ncosmological scenario and showed that in some cases the computational times of\nthe inference process can be reduced. In this paper, we present an improvement\nto the neural network bundle method that results in a significant reduction of\nthe computational times of the statistical analysis. The novelty of the method\nconsists in the use of the neural network bundle method to calculate the\nluminosity distance of type Ia supernovae, which is usually computed through an\nintegral with numerical methods. In this work, we have applied this improvement\nto the Starobinsky $f(R)$ model, which is more difficult to integrate than the\n$f(R)$ models analyzed in our previous work. We performed a statistical\nanalysis with data from type Ia supernovae of the Pantheon+ compilation and\ncosmic chronometers to estimate the values of the free parameters of the\nStarobinsky model. We show that the statistical analyses carried out with our\nnew method require lower computational times than the ones performed with both\nthe numerical and the neural network method from our previous work. This\nreduction in time is more significant in the case of a difficult computational\nproblem such as the one we address in this work.",
            "author": [
                "Augusto T. Chantada",
                "Susana J. Landau",
                "Pavlos Protopapas",
                "Claudia G. Sc\u00f3ccola",
                "Cecilia Garraffo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15955v1",
                "http://arxiv.org/pdf/2311.15955v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO",
                "gr-qc",
                "hep-th"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15954v1",
            "title": "A Quantitative Approach to Understand Self-Supervised Models as\n  Cross-lingual Feature Extractors",
            "updated": "2023-11-27T15:58:28Z",
            "published": "2023-11-27T15:58:28Z",
            "summary": "In this work, we study the features extracted by English self-supervised\nlearning (SSL) models in cross-lingual contexts and propose a new metric to\npredict the quality of feature representations. Using automatic speech\nrecognition (ASR) as a downstream task, we analyze the effect of model size,\ntraining objectives, and model architecture on the models' performance as a\nfeature extractor for a set of topologically diverse corpora. We develop a\nnovel metric, the Phonetic-Syntax Ratio (PSR), to measure the phonetic and\nsynthetic information in the extracted representations using deep generalized\ncanonical correlation analysis. Results show the contrastive loss in the\nwav2vec2.0 objective facilitates more effective cross-lingual feature\nextraction. There is a positive correlation between PSR scores and ASR\nperformance, suggesting that phonetic information extracted by monolingual SSL\nmodels can be used for downstream tasks in cross-lingual settings. The proposed\nmetric is an effective indicator of the quality of the representations and can\nbe useful for model selection.",
            "author": [
                "Shuyue Stella Li",
                "Beining Xu",
                "Xiangyu Zhang",
                "Hexin Liu",
                "Wenhan Chao",
                "Leibny Paola Garcia"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15954v1",
                "http://arxiv.org/pdf/2311.15954v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15951v2",
            "title": "Replay across Experiments: A Natural Extension of Off-Policy RL",
            "updated": "2023-11-28T15:18:43Z",
            "published": "2023-11-27T15:57:11Z",
            "summary": "Replaying data is a principal mechanism underlying the stability and data\nefficiency of off-policy reinforcement learning (RL). We present an effective\nyet simple framework to extend the use of replays across multiple experiments,\nminimally adapting the RL workflow for sizeable improvements in controller\nperformance and research iteration times. At its core, Replay Across\nExperiments (RaE) involves reusing experience from previous experiments to\nimprove exploration and bootstrap learning while reducing required changes to a\nminimum in comparison to prior work. We empirically show benefits across a\nnumber of RL algorithms and challenging control domains spanning both\nlocomotion and manipulation, including hard exploration tasks from egocentric\nvision. Through comprehensive ablations, we demonstrate robustness to the\nquality and amount of data available and various hyperparameter choices.\nFinally, we discuss how our approach can be applied more broadly across\nresearch life cycles and can increase resilience by reloading data across\nrandom seeds or hyperparameter variations.",
            "author": [
                "Dhruva Tirumala",
                "Thomas Lampe",
                "Jose Enrique Chen",
                "Tuomas Haarnoja",
                "Sandy Huang",
                "Guy Lever",
                "Ben Moran",
                "Tim Hertweck",
                "Leonard Hasenclever",
                "Martin Riedmiller",
                "Nicolas Heess",
                "Markus Wulfmeier"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15951v2",
                "http://arxiv.org/pdf/2311.15951v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15950v1",
            "title": "Auto-CsiNet: Scenario-customized Automatic Neural Network Architecture\n  Generation for Massive MIMO CSI Feedback",
            "updated": "2023-11-27T15:56:58Z",
            "published": "2023-11-27T15:56:58Z",
            "summary": "Deep learning has revolutionized the design of the channel state information\n(CSI) feedback module in wireless communications. However, designing the\noptimal neural network (NN) architecture for CSI feedback can be a laborious\nand time-consuming process. Manual design can be prohibitively expensive for\ncustomizing NNs to different scenarios. This paper proposes using neural\narchitecture search (NAS) to automate the generation of scenario-customized CSI\nfeedback NN architectures, thereby maximizing the potential of deep learning in\nexclusive environments. By employing automated machine learning and\ngradient-descent-based NAS, an efficient and cost-effective architecture design\nprocess is achieved. The proposed approach leverages implicit scene knowledge,\nintegrating it into the scenario customization process in a data-driven manner,\nand fully exploits the potential of deep learning for each specific scenario.\nTo address the issue of excessive search, early stopping and elastic selection\nmechanisms are employed, enhancing the efficiency of the proposed scheme. The\nexperimental results demonstrate that the automatically generated architecture,\nknown as Auto-CsiNet, outperforms manually-designed models in both\nreconstruction performance (achieving approximately a 14% improvement) and\ncomplexity (reducing it by approximately 50%). Furthermore, the paper analyzes\nthe impact of the scenario on the NN architecture and its capacity.",
            "author": [
                "Xiangyi Li",
                "Jiajia Guo",
                "Chao-Kai Wen",
                "Shi Jin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15950v1",
                "http://arxiv.org/pdf/2311.15950v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "cs.AI",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15949v2",
            "title": "Improving the Time Resolution of Large-Area LaBr3:Ce Detectors with SiPM\n  Array Readout",
            "updated": "2023-11-28T16:19:49Z",
            "published": "2023-11-27T15:56:51Z",
            "summary": "LaBr3:Ce crystals have good scintillation properties for X-ray spectroscopy.\nInitially, they were introduced for radiation imaging in medical physics with\neither a photomultiplier or SiPM readout, and they found extensive applications\nin homeland security and gamma-ray astronomy. We used 1 inch round LaBr3:Ce\ncrystals to realize compact detectors with the SiPM array readout. The aim was\na good energy resolution and a fast time response to detect low-energy X-rays\naround 100 keV. A natural application was found inside the FAMU experiment, at\nRIKEN RAL. Its aim is a precise measurement of the proton Zemach radius with\nimpinging muons, to contribute to the solution to the so-called proton radius\npuzzle. Signals to be detected are characteristic X-rays around 130 KeV. A\nlimit for this type of detector, as compared to the ones with a photomultiplier\nreadout, is its poorer timing characteristics due to the large capacity of the\nSiPM arrays used. In particular, long signal falltimes are a problem in\nexperiments such as FAMU, where a prompt background component must be separated\nfrom a delayed one (after 600 ns) in the signal X-rays to be detected.\nDedicated studies were pursued to improve the timing characteristics of the\nused detectors, starting from hybrid ganging of SiPM cells; then developing a\nsuitable zero pole circuit with a parallel ganging, where an increased\novervoltage for the SiPM array was used to compensate for the signal decrease;\nand finally designing ad hoc electronics to split the 1 inch detector SiPM\narray into four quadrants, thus reducing the involved capacitances. The aim was\nto improve the detectors timing characteristics, especially falltime, while\nkeeping a good FWHM energy resolution for low-energy X-ray detection.",
            "author": [
                "M. Bonesini",
                "R. Bertoni",
                "A. Abba",
                "F. Caponio",
                "M. C. Prata",
                "M. Rossella"
            ],
            "link": [
                "http://dx.doi.org/10.3390/condmat8040099",
                "http://arxiv.org/abs/2311.15949v2",
                "http://arxiv.org/pdf/2311.15949v2"
            ],
            "primary_category": "physics.ins-det",
            "category": [
                "physics.ins-det"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15946v1",
            "title": "Leveraging deep active learning to identify low-resource mobility\n  functioning information in public clinical notes",
            "updated": "2023-11-27T15:53:11Z",
            "published": "2023-11-27T15:53:11Z",
            "summary": "Function is increasingly recognized as an important indicator of whole-person\nhealth, although it receives little attention in clinical natural language\nprocessing research. We introduce the first public annotated dataset\nspecifically on the Mobility domain of the International Classification of\nFunctioning, Disability and Health (ICF), aiming to facilitate automatic\nextraction and analysis of functioning information from free-text clinical\nnotes. We utilize the National NLP Clinical Challenges (n2c2) research dataset\nto construct a pool of candidate sentences using keyword expansion. Our active\nlearning approach, using query-by-committee sampling weighted by density\nrepresentativeness, selects informative sentences for human annotation. We\ntrain BERT and CRF models, and use predictions from these models to guide the\nselection of new sentences for subsequent annotation iterations. Our final\ndataset consists of 4,265 sentences with a total of 11,784 entities, including\n5,511 Action entities, 5,328 Mobility entities, 306 Assistance entities, and\n639 Quantification entities. The inter-annotator agreement (IAA), averaged over\nall entity types, is 0.72 for exact matching and 0.91 for partial matching. We\nalso train and evaluate common BERT models and state-of-the-art Nested NER\nmodels. The best F1 scores are 0.84 for Action, 0.7 for Mobility, 0.62 for\nAssistance, and 0.71 for Quantification. Empirical results demonstrate\npromising potential of NER models to accurately extract mobility functioning\ninformation from clinical text. The public availability of our annotated\ndataset will facilitate further research to comprehensively capture functioning\ninformation in electronic health records (EHRs).",
            "author": [
                "Tuan-Dung Le",
                "Zhuqi Miao",
                "Samuel Alvarado",
                "Brittany Smith",
                "William Paiva",
                "Thanh Thieu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15946v1",
                "http://arxiv.org/pdf/2311.15946v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16499v1",
            "title": "Deceptive-Human: Prompt-to-NeRF 3D Human Generation with 3D-Consistent\n  Synthetic Images",
            "updated": "2023-11-27T15:49:41Z",
            "published": "2023-11-27T15:49:41Z",
            "summary": "This paper presents Deceptive-Human, a novel Prompt-to-NeRF framework\ncapitalizing state-of-the-art control diffusion models (e.g., ControlNet) to\ngenerate a high-quality controllable 3D human NeRF. Different from direct 3D\ngenerative approaches, e.g., DreamFusion and DreamHuman, Deceptive-Human\nemploys a progressive refinement technique to elevate the reconstruction\nquality. This is achieved by utilizing high-quality synthetic human images\ngenerated through the ControlNet with view-consistent loss. Our method is\nversatile and readily extensible, accommodating multimodal inputs, including a\ntext prompt and additional data such as 3D mesh, poses, and seed images. The\nresulting 3D human NeRF model empowers the synthesis of highly photorealistic\nnovel views from 360-degree perspectives. The key to our Deceptive-Human for\nhallucinating multi-view consistent synthetic human images lies in our\nprogressive finetuning strategy. This strategy involves iteratively enhancing\nviews using the provided multimodal inputs at each intermediate step to improve\nthe human NeRF model. Within this iterative refinement process, view-dependent\nappearances are systematically eliminated to prevent interference with the\nunderlying density estimation. Extensive qualitative and quantitative\nexperimental comparison shows that our deceptive human models achieve\nstate-of-the-art application quality.",
            "author": [
                "Shiu-hong Kao",
                "Xinhang Liu",
                "Yu-Wing Tai",
                "Chi-Keung Tang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16499v1",
                "http://arxiv.org/pdf/2311.16499v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15941v1",
            "title": "Tell2Design: A Dataset for Language-Guided Floor Plan Generation",
            "updated": "2023-11-27T15:49:29Z",
            "published": "2023-11-27T15:49:29Z",
            "summary": "We consider the task of generating designs directly from natural language\ndescriptions, and consider floor plan generation as the initial research area.\nLanguage conditional generative models have recently been very successful in\ngenerating high-quality artistic images. However, designs must satisfy\ndifferent constraints that are not present in generating artistic images,\nparticularly spatial and relational constraints. We make multiple contributions\nto initiate research on this task. First, we introduce a novel dataset,\n\\textit{Tell2Design} (T2D), which contains more than $80k$ floor plan designs\nassociated with natural language instructions. Second, we propose a\nSequence-to-Sequence model that can serve as a strong baseline for future\nresearch. Third, we benchmark this task with several text-conditional image\ngeneration models. We conclude by conducting human evaluations on the generated\nsamples and providing an analysis of human performance. We hope our\ncontributions will propel the research on language-guided design generation\nforward.",
            "author": [
                "Sicong Leng",
                "Yang Zhou",
                "Mohammed Haroon Dupty",
                "Wee Sun Lee",
                "Sam Conrad Joyce",
                "Wei Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15941v1",
                "http://arxiv.org/pdf/2311.15941v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15939v1",
            "title": "Unleashing the Power of Prompt-driven Nucleus Instance Segmentation",
            "updated": "2023-11-27T15:46:47Z",
            "published": "2023-11-27T15:46:47Z",
            "summary": "Nuclear instance segmentation in histology images is crucial for a broad\nspectrum of clinical applications. Current prevailing nuclear instance\nsegmentation algorithms rely on regression of nuclei contours, distance maps,\nwatershed markers or a proxy nuclear representation of star-convex polygons.\nConsequently, these methods necessitate sophisticated post-processing\noperations to distinguish nuclei instances, which are commonly acknowledged to\nbe error-prone and parameter-sensitive. Recently, the segment anything model\n(SAM) has earned attracted huge attention within the domain of medical image\nsegmentation due to its impressive generalization ability and promptable\nproperty. Nevertheless, its potential on nuclear instance segmentation remains\nlargely underexplored. In this paper, we present a novel prompt-driven\nframework that consists of a point prompter and a SAM for automatic nuclei\ninstance segmentation. Specifically, the prompter learns to generate a unique\npoint prompt for each nucleus while the SAM is fine tuned to output the\ncorresponding mask of the cued nucleus. Furthermore, we propose to add adjacent\nnuclei as negative prompts to promote the model's ability to recognize\noverlapping nuclei. Without bells and whistles, our proposed method sets a new\nstate-of-the-art performance on three challenging benchmarks. Our code is\navailable at\n\\textcolor{magenta}{\\url{https://github.com/windygoo/PromptNucSeg}} .",
            "author": [
                "Zhongyi Shui",
                "Yunlong Zhang",
                "Kai Yao",
                "Chenglu Zhu",
                "Yuxuan Sun",
                "Lin Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15939v1",
                "http://arxiv.org/pdf/2311.15939v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.03728v1",
            "title": "Real Customization or Just Marketing: Are Customized Versions of Chat\n  GPT Useful?",
            "updated": "2023-11-27T15:46:15Z",
            "published": "2023-11-27T15:46:15Z",
            "summary": "Large Language Models (LLMs), as the case of OpenAI ChatGPT-4 Turbo, are\nrevolutionizing several industries, including higher education. In this\ncontext, LLMs can be personalized through a fine-tuning process to meet the\nstudent demands on every particular subject, like statistics. Recently, OpenAI\nhas launched the possibility to fine-tune their model with a natural language\nweb interface, enabling the possibility to create customized GPT version\ndeliberately conditioned to meet the demands of a specific task. The objective\nof this research is to assess the potential of the customized GPTs that have\nrecently been launched by OpenAI. After developing a Business Statistics\nVirtual Professor (BSVP), tailored for students at the Universidad Pontificia\nComillas, its behavior was evaluated and compared with that of ChatGPT-4 Turbo.\nThe results lead to several conclusions. Firstly, a substantial modification in\nthe style of communication was observed. Following the instructions it was\ntrained with, BSVP provided responses in a more relatable and friendly tone,\neven incorporating a few minor jokes. Secondly, and this is a matter of\nrelevance, when explicitly asked for something like, \"I would like to practice\na programming exercise similar to those in R practice 4,\" BSVP was capable of\nproviding a far superior response: having access to contextual documentation,\nit could fulfill the request, something beyond ChatGPT-4 Turbo's capabilities.\nOn the downside, the response times were generally higher. Lastly, regarding\noverall performance, quality, depth, and alignment with the specific content of\nthe course, no statistically significant differences were observed in the\nresponses between BSVP and ChatGPT-4 Turbo. It appears that customized\nassistants trained with prompts present advantages as virtual aids for\nstudents, yet they do not constitute a substantial improvement over ChatGPT-4\nTurbo.",
            "author": [
                "Eduardo C. Garrido-Merch\u00e1n",
                "Jose L. Arroyo-Barrig\u00fcete",
                "Francisco Borr\u00e1s-Pala",
                "Leandro Escobar-Torres",
                "Carlos Mart\u00ednez de Ibarreta",
                "Jose Mar\u00eda Ortiz-Lozano",
                "Antonio Rua-Vieites"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03728v1",
                "http://arxiv.org/pdf/2312.03728v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15936v3",
            "title": "Towards Responsible Governance of Biological Design Tools",
            "updated": "2023-11-30T11:54:38Z",
            "published": "2023-11-27T15:45:02Z",
            "summary": "Recent advancements in generative machine learning have enabled rapid\nprogress in biological design tools (BDTs) such as protein structure and\nsequence prediction models. The unprecedented predictive accuracy and novel\ndesign capabilities of BDTs present new and significant dual-use risks. For\nexample, their predictive accuracy allows biological agents, whether vaccines\nor pathogens, to be developed more quickly, while the design capabilities could\nbe used to discover drugs or evade DNA screening techniques. Similar to other\ndual-use AI systems, BDTs present a wicked problem: how can regulators uphold\npublic safety without stifling innovation? We highlight how current regulatory\nproposals that are primarily tailored toward large language models may be less\neffective for BDTs, which require fewer computational resources to train and\nare often developed in an open-source manner. We propose a range of measures to\nmitigate the risk that BDTs are misused, across the areas of responsible\ndevelopment, risk assessment, transparency, access management, cybersecurity,\nand investing in resilience. Implementing such measures will require close\ncoordination between developers and governments.",
            "author": [
                "Richard Moulange",
                "Max Langenkamp",
                "Tessa Alexanian",
                "Samuel Curtis",
                "Morgan Livingston"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15936v3",
                "http://arxiv.org/pdf/2311.15936v3"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15934v1",
            "title": "Descent with algebraic structures for symplectic cohomology",
            "updated": "2023-11-27T15:42:15Z",
            "published": "2023-11-27T15:42:15Z",
            "summary": "We formulate and prove a chain level descent property of symplectic\ncohomology for involutive covers by compact subsets that take into account the\nnatural algebraic structures that are present. The notion of an involutive\ncover is reviewed. We indicate the role that the statement plays in mirror\nsymmetry.",
            "author": [
                "Umut Varolgunes"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15934v1",
                "http://arxiv.org/pdf/2311.15934v1"
            ],
            "primary_category": "math.SG",
            "category": [
                "math.SG",
                "53D40"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15930v1",
            "title": "WorldSense: A Synthetic Benchmark for Grounded Reasoning in Large\n  Language Models",
            "updated": "2023-11-27T15:38:17Z",
            "published": "2023-11-27T15:38:17Z",
            "summary": "We propose WorldSense, a benchmark designed to assess the extent to which\nLLMs are consistently able to sustain tacit world models, by testing how they\ndraw simple inferences from descriptions of simple arrangements of entities.\nWorldsense is a synthetic benchmark with three problem types, each with their\nown trivial control, which explicitly avoids bias by decorrelating the abstract\nstructure of problems from the vocabulary and expressions, and by decorrelating\nall problem subparts with the correct response. We run our benchmark on three\nstate-of-the-art chat-LLMs (GPT3.5, GPT4 and Llama2-chat) and show that these\nmodels make errors even with as few as three objects. Furthermore, they have\nquite heavy response biases, preferring certain responses irrespective of the\nquestion. Errors persist even with chain-of-thought prompting and in-context\nlearning. Lastly, we show that while finetuning on similar problems does result\nin substantial improvements -- within- and out-of-distribution -- the finetuned\nmodels do not generalise beyond a constraint problem space.",
            "author": [
                "Youssef Benchekroun",
                "Megi Dervishi",
                "Mark Ibrahim",
                "Jean-Baptiste Gaya",
                "Xavier Martinet",
                "Gr\u00e9goire Mialon",
                "Thomas Scialom",
                "Emmanuel Dupoux",
                "Dieuwke Hupkes",
                "Pascal Vincent"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15930v1",
                "http://arxiv.org/pdf/2311.15930v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15928v1",
            "title": "A novel approach to muscle functional recovery monitoring by its free\n  vibration measurement",
            "updated": "2023-11-27T15:37:49Z",
            "published": "2023-11-27T15:37:49Z",
            "summary": "The study shows a potential to monitor functional recovery of a muscle by its\nnatural frequency measurement. A novel approach is presented, in which\nvibrations of the muscle of interest are measured in a contactless manner using\nlaser displacement sensor and the measured vibration signals are analyzed by an\nadvanced technique of experimental modal analysis to extract fundamental\nnatural frequency of the muscle with high accuracy. A case study of functional\nstatus recovery monitoring of a rectus femoris muscle, which become anthropic\nafter ACL reconstruction, is presented.",
            "author": [
                "Agnieszka Tomaszewska",
                "Milena Drozdowska",
                "Piotr Aschenbrenner"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15928v1",
                "http://arxiv.org/pdf/2311.15928v1"
            ],
            "primary_category": "physics.med-ph",
            "category": [
                "physics.med-ph",
                "q-bio.TO",
                "74H99"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.03727v1",
            "title": "Content-Localization based System for Analyzing Sentiment and Hate\n  Behaviors in Low-Resource Dialectal Arabic: English to Levantine and Gulf",
            "updated": "2023-11-27T15:37:33Z",
            "published": "2023-11-27T15:37:33Z",
            "summary": "Even though online social movements can quickly become viral on social media,\nlanguages can be a barrier to timely monitoring and analyzing the underlying\nonline social behaviors (OSB). This is especially true for under-resourced\nlanguages on social media like dialectal Arabic; the primary language used by\nArabs on social media. Therefore, it is crucial to provide solutions to\nefficiently exploit resources from high-resourced languages to solve\nlanguage-dependent OSB analysis in under-resourced languages. This paper\nproposes to localize content of resources in high-resourced languages into\nunder-resourced Arabic dialects. Content localization goes beyond content\ntranslation that converts text from one language to another; content\nlocalization adapts culture, language nuances and regional preferences from one\nlanguage to a specific language/dialect. Automating understanding of the\nnatural and familiar day-to-day expressions in different regions, is the key to\nachieve a wider analysis of OSB especially for smart cities. In this paper, we\nutilize content-localization based neural machine translation to develop\nsentiment and hate classifiers for two low-resourced Arabic dialects: Levantine\nand Gulf. Not only this but we also leverage unsupervised learning to\nfacilitate the analysis of sentiment and hate predictions by inferring hidden\ntopics from the corresponding data and providing coherent interpretations of\nthose topics in their native language/dialects. The experimental evaluations\nand proof-of-concept COVID-19 case study on real data have validated the\neffectiveness of our proposed system in precisely distinguishing sentiments and\naccurately identifying hate content in both Levantine and Gulf Arabic dialects.\nOur findings shed light on the importance of considering the unique nature of\ndialects within the same language and ignoring the dialectal aspect would lead\nto misleading analysis.",
            "author": [
                "Fatimah Alzamzami",
                "Abdulmotaleb El Saddik"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03727v1",
                "http://arxiv.org/pdf/2312.03727v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15916v1",
            "title": "ADM-Loc: Actionness Distribution Modeling for Point-supervised Temporal\n  Action Localization",
            "updated": "2023-11-27T15:24:54Z",
            "published": "2023-11-27T15:24:54Z",
            "summary": "This paper addresses the challenge of point-supervised temporal action\ndetection, in which only one frame per action instance is annotated in the\ntraining set. Self-training aims to provide supplementary supervision for the\ntraining process by generating pseudo-labels (action proposals) from a base\nmodel. However, most current methods generate action proposals by applying\nmanually designed thresholds to action classification probabilities and\ntreating adjacent snippets as independent entities. As a result, these methods\nstruggle to generate complete action proposals, exhibit sensitivity to\nfluctuations in action classification scores, and generate redundant and\noverlapping action proposals. This paper proposes a novel framework termed\nADM-Loc, which stands for Actionness Distribution Modeling for point-supervised\naction Localization. ADM-Loc generates action proposals by fitting a composite\ndistribution, comprising both Gaussian and uniform distributions, to the action\nclassification signals. This fitting process is tailored to each action class\npresent in the video and is applied separately for each action instance,\nensuring the distinctiveness of their distributions. ADM-Loc significantly\nenhances the alignment between the generated action proposals and ground-truth\naction instances and offers high-quality pseudo-labels for self-training.\nMoreover, to model action boundary snippets, it enforces consistency in action\nclassification scores during training by employing Gaussian kernels, supervised\nwith the proposed loss functions. ADM-Loc outperforms the state-of-the-art\npoint-supervised methods on THUMOS14 and ActivityNet-v1.2 datasets.",
            "author": [
                "Elahe Vahdani",
                "Yingli Tian"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15916v1",
                "http://arxiv.org/pdf/2311.15916v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15914v1",
            "title": "Computer Vision for Carriers: PATRIOT",
            "updated": "2023-11-27T15:23:25Z",
            "published": "2023-11-27T15:23:25Z",
            "summary": "Deck tracking performed on carriers currently involves a team of sailors\nmanually identifying aircraft and updating a digital user interface called the\nOuija Board. Improvements to the deck tracking process would result in\nincreased Sortie Generation Rates, and therefore applying automation is seen as\na critical method to improve deck tracking. However, the requirements on a\ncarrier ship do not allow for the installation of hardware-based location\nsensing technologies like Global Positioning System (GPS) sensors. PATRIOT\n(Panoramic Asset Tracking of Real-Time Information for the Ouija Tabletop) is a\nresearch effort and proposed solution to performing deck tracking with passive\nsensing and without the need for GPS sensors. PATRIOT is a prototype system\nwhich takes existing camera feeds, calculates aircraft poses, and updates a\nvirtual Ouija board interface with the current status of the assets. PATRIOT\nwould allow for faster, more accurate, and less laborious asset tracking for\naircraft, people, and support equipment. PATRIOT is anticipated to benefit the\nwarfighter by reducing cognitive workload, reducing manning requirements,\ncollecting data to improve logistics, and enabling an automation gateway for\nfuture efforts to improve efficiency and safety. The authors have developed and\ntested algorithms to perform pose estimations of assets in real-time including\nOpenPifPaf, High-Resolution Network (HRNet), HigherHRNet (HHRNet), Faster\nR-CNN, and in-house developed encoder-decoder network. The software was tested\nwith synthetic and real-world data and was able to accurately extract the pose\nof assets. Fusion, tracking, and real-world generality are planned to be\nimproved to ensure a successful transition to the fleet.",
            "author": [
                "Ari Goodman",
                "Gurpreet Singh",
                "James Hing",
                "Ryan O'Shea"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15914v1",
                "http://arxiv.org/pdf/2311.15914v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16483v1",
            "title": "ChartLlama: A Multimodal LLM for Chart Understanding and Generation",
            "updated": "2023-11-27T15:20:23Z",
            "published": "2023-11-27T15:20:23Z",
            "summary": "Multi-modal large language models have demonstrated impressive performances\non most vision-language tasks. However, the model generally lacks the\nunderstanding capabilities for specific domain data, particularly when it comes\nto interpreting chart figures. This is mainly due to the lack of relevant\nmulti-modal instruction tuning datasets. In this article, we create a\nhigh-quality instruction-tuning dataset leveraging GPT-4. We develop a\nmulti-step data generation process in which different steps are responsible for\ngenerating tabular data, creating chart figures, and designing instruction\ntuning data separately. Our method's flexibility enables us to generate\ndiverse, high-quality instruction-tuning data consistently and efficiently\nwhile maintaining a low resource expenditure. Additionally, it allows us to\nincorporate a wider variety of chart and task types not yet featured in\nexisting datasets. Next, we introduce ChartLlama, a multi-modal large language\nmodel that we've trained using our created dataset. ChartLlama outperforms all\nprior methods in ChartQA, Chart-to-text, and Chart-extraction evaluation\nbenchmarks. Additionally, ChartLlama significantly improves upon the baseline\nin our specially compiled chart dataset, which includes new chart and task\ntypes. The results of ChartLlama confirm the value and huge potential of our\nproposed data generation method in enhancing chart comprehension.",
            "author": [
                "Yucheng Han",
                "Chi Zhang",
                "Xin Chen",
                "Xu Yang",
                "Zhibin Wang",
                "Gang Yu",
                "Bin Fu",
                "Hanwang Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16483v1",
                "http://arxiv.org/pdf/2311.16483v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15908v1",
            "title": "Enhancing Perceptual Quality in Video Super-Resolution through\n  Temporally-Consistent Detail Synthesis using Diffusion Models",
            "updated": "2023-11-27T15:14:38Z",
            "published": "2023-11-27T15:14:38Z",
            "summary": "In this paper, we address the problem of video super-resolution (VSR) using\nDiffusion Models (DM), and present StableVSR. Our method significantly enhances\nthe perceptual quality of upscaled videos by synthesizing realistic and\ntemporally-consistent details. We turn a pre-trained DM for single image\nsuper-resolution into a VSR method by introducing the Temporal Conditioning\nModule (TCM). TCM uses Temporal Texture Guidance, which provides\nspatially-aligned and detail-rich texture information synthesized in adjacent\nframes. This guides the generative process of the current frame toward\nhigh-quality and temporally-consistent results. We introduce a Frame-wise\nBidirectional Sampling strategy to encourage the use of information from past\nto future and vice-versa. This strategy improves the perceptual quality of the\nresults and the temporal consistency across frames. We demonstrate the\neffectiveness of StableVSR in enhancing the perceptual quality of upscaled\nvideos compared to existing state-of-the-art methods for VSR. The code is\navailable at https://github.com/claudiom4sir/StableVSR.",
            "author": [
                "Claudio Rota",
                "Marco Buzzelli",
                "Joost van de Weijer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15908v1",
                "http://arxiv.org/pdf/2311.15908v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15905v1",
            "title": "Prolongement analytique de fonctions $\u03b6$ et de fonctions $L$",
            "updated": "2023-11-27T15:12:02Z",
            "published": "2023-11-27T15:12:02Z",
            "summary": "Wiles' work on Fermat's last Theorem highlighted the power of $p$-adic\nmethods to prove the existence of analytic continuations of $\\zeta$ and $L$\nfunctions. These methods have become considerably more sophisticated in recent\nyears, and have produced a wealth of beautiful results: Hasse--Weil conjecture\nfor genus $2$ curves, holomorphy of $L$-functions of symmetric powers of\nmodular forms, etc. We present some of these advances.",
            "author": [
                "Pierre Colmez"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15905v1",
                "http://arxiv.org/pdf/2311.15905v1"
            ],
            "primary_category": "math.NT",
            "category": [
                "math.NT",
                "math.HO",
                "math.RT",
                "11Fxx"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15904v1",
            "title": "Off-lattice Monte-Carlo approach for studying nucleation and evaporation\n  phenomena at the molecular scale",
            "updated": "2023-11-27T15:08:41Z",
            "published": "2023-11-27T15:08:41Z",
            "summary": "Droplet nucleation and evaporation are ubiquitous in nature and many\ntechnological applications, such as phase-change cooling and boiling heat\ntransfer. So far, the description of these phenomena at the molecular scale has\nposed challenges for modelling with most of the models being implemented on a\nlattice. Here, we propose an {off-lattice} Monte-Carlo approach combined with a\ngrid that can be used for the investigation of droplet formation and\nevaporation. We provide the details of the model, its implementation as Python\ncode, and results illustrating its dependence on various parameters. The method\ncan be easily extended for any force-field ({e.g.,} coarse-grained, all-atom\nmodels, and external fields, such as gravity and electric field). Thus, we\nanticipate that the proposed model will offer opportunities for a wide range of\nstudies in various research areas involving droplet formation and evaporation\nand will also form the basis for further method developments for the molecular\nmodelling of such phenomena.",
            "author": [
                "Panagiotis E. Theodorakis",
                "Y. Wang",
                "A. Chen",
                "B. Liu"
            ],
            "link": [
                "http://dx.doi.org/10.3390/ma14092092",
                "http://arxiv.org/abs/2311.15904v1",
                "http://arxiv.org/pdf/2311.15904v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15902v1",
            "title": "Simple Lattice Basis Computation -- The Generalization of the Euclidean\n  Algorithm",
            "updated": "2023-11-27T15:05:34Z",
            "published": "2023-11-27T15:05:34Z",
            "summary": "The Euclidean algorithm is one of the oldest algorithms known to mankind.\nGiven two integral numbers $a_1$ and $a_2$, it computes the greatest common\ndivisor (gcd) of $a_1$ and $a_2$ in a very elegant way. From a lattice\nperspective, it computes a basis of the sum of two one-dimensional lattices\n$a_1 \\mathbb{Z}$ and $a_2 \\mathbb{Z}$ as $\\gcd(a_1,a_2) \\mathbb{Z} = a_1\n\\mathbb{Z} + a_2 \\mathbb{Z}$. In this paper, we show that the classical\nEuclidean algorithm can be adapted in a very natural way to compute a basis of\na general lattice $L(a_1, \\ldots , a_m)$ given vectors $a_1, \\ldots , a_m \\in\n\\mathbb{Z}^n$ with $m> \\mathrm{rank}(a_1, \\ldots ,a_m)$. Similar to the\nEuclidean algorithm, our algorithm is very easy to describe and implement and\ncan be written within 12 lines of pseudocode.\n  While the Euclidean algorithm halves the largest number in every iteration,\nour generalized algorithm halves the determinant of a full rank subsystem\nleading to at most $\\log (\\det B)$ many iterations, for some initial subsystem\n$B$. Therefore, we can compute a basis of the lattice using at most\n$\\tilde{O}((m-n)n\\log(\\det B) + mn^{\\omega-1}\\log(||A||_\\infty))$ arithmetic\noperations, where $\\omega$ is the matrix multiplication exponent and $A = (a_1,\n\\ldots, a_m)$. Even using the worst case Hadamard bound for the determinant,\nour algorithm improves upon existing algorithm.\n  Another major advantage of our algorithm is that we can bound the entries of\nthe resulting lattice basis by $\\tilde{O}(n^2\\cdot ||A||_{\\infty})$ using a\nsimple pivoting rule. This is in contrast to the typical approach for computing\nlattice basis, where the Hermite normal form (HNF) is used. In the HNF, entries\ncan be as large as the determinant and hence can only be bounded by an\nexponential term.",
            "author": [
                "Kim-Manuel Klein",
                "Janina Reuter"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15902v1",
                "http://arxiv.org/pdf/2311.15902v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.DM",
                "math.NT",
                "F.2.2; G.2.1"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16206v1",
            "title": "Continual Instruction Tuning for Large Multimodal Models",
            "updated": "2023-11-27T15:04:48Z",
            "published": "2023-11-27T15:04:48Z",
            "summary": "Instruction tuning is now a widely adopted approach to aligning large\nmultimodal models (LMMs) to follow human intent. It unifies the data format of\nvision-language tasks, enabling multi-task joint training. However,\nvision-language tasks are constantly being created in practice. Instead of\nalways re-training LMMs when new tasks arrive, continual learning offers\nflexibility for models to continually and efficiently exploit the evolving\ndata. This work aims to explore the following two questions: 1) Do LMMs still\nsuffer from catastrophic forgetting in continual instruction tuning? 2) Are the\nexisting three classes of continual learning methods still applicable to the\ncontinual instruction tuning of LMMs? An extensive study is conducted to\naddress the above questions. First, we establish the first benchmark in this\nsetting and reveal that catastrophic forgetting is still observed when\ncontinually instruction-tuning LMMs. However, the multi-task joint instruction\ntuning can facilitate the model's continual learning ability and mitigate\nforgetting. Second, we integrate and adapt classic continual learning methods\nto our context, demonstrating the efficacy of data replay and model expansion\nstrategies across diverse scenarios. In contrast, regularization-based methods\nonly perform well on models that have been jointly instruction-tuned on\nmultiple tasks. Third, we delve into the correlation and forgetting dynamics\nbetween vision-language task pairs and propose task-similarity-informed\nregularization and model expansion methods for continual instruction tuning of\nLMMs. Experimental results show that our approach consistently boosts the\nmodel's performance.",
            "author": [
                "Jinghan He",
                "Haiyun Guo",
                "Ming Tang",
                "Jinqiao Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16206v1",
                "http://arxiv.org/pdf/2311.16206v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15896v1",
            "title": "Data Generation for Post-OCR correction of Cyrillic handwriting",
            "updated": "2023-11-27T15:01:26Z",
            "published": "2023-11-27T15:01:26Z",
            "summary": "This paper introduces a novel approach to post-Optical Character Recognition\nCorrection (POC) for handwritten Cyrillic text, addressing a significant gap in\ncurrent research methodologies. This gap is due to the lack of large text\ncorporas that provide OCR errors for further training of language-based POC\nmodels, which are demanding in terms of corpora size. Our study primarily\nfocuses on the development and application of a synthetic handwriting\ngeneration engine based on B\\'ezier curves. Such an engine generates highly\nrealistic handwritten text in any amounts, which we utilize to create a\nsubstantial dataset by transforming Russian text corpora sourced from the\ninternet. We apply a Handwritten Text Recognition (HTR) model to this dataset\nto identify OCR errors, forming the basis for our POC model training. The\ncorrection model is trained on a 90-symbol input context, utilizing a\npre-trained T5 architecture with a seq2seq correction task. We evaluate our\napproach on HWR200 and School_notebooks_RU datasets as they provide significant\nchallenges in the HTR domain. Furthermore, POC can be used to highlight errors\nfor teachers, evaluating student performance. This can be done simply by\ncomparing sentences before and after correction, displaying differences in\ntext. Our primary contribution lies in the innovative use of B\\'ezier curves\nfor Cyrillic text generation and subsequent error correction using a\nspecialized POC model. We validate our approach by presenting Word Accuracy\nRate (WAR) and Character Accuracy Rate (CAR) results, both with and without\npost-OCR correction, using real open corporas of handwritten Cyrillic text.\nThese results, coupled with our methodology, are designed to be reproducible,\npaving the way for further advancements in the field of OCR and handwritten\ntext analysis. Paper contributions can be found in\nhttps://github.com/dbrainio/CyrillicHandwritingPOC",
            "author": [
                "Evgenii Davydkin",
                "Aleksandr Markelov",
                "Egor Iuldashev",
                "Anton Dudkin",
                "Ivan Krivorotov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15896v1",
                "http://arxiv.org/pdf/2311.15896v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15891v1",
            "title": "Sampling a rare protein transition with a hybrid classical-quantum\n  computing algorithm",
            "updated": "2023-11-27T14:58:29Z",
            "published": "2023-11-27T14:58:29Z",
            "summary": "Simulating spontaneous structural rearrangements in macromolecules with\nclassical Molecular Dynamics (MD) is an outstanding challenge. Conventional\nsupercomputers can access time intervals up to tens of $\\mu$s, while many key\nevents occur on exponentially longer time scales. Transition path sampling\ntechniques have the advantage of focusing the computational power on\nbarrier-crossing trajectories, but generating uncorrelated transition paths\nthat explore diverse conformational regions remains an unsolved problem. We\nemploy a path-sampling paradigm combining machine learning (ML) with quantum\ncomputing (QC) to address this issue. We use ML on a classical computer to\nperform a preliminary uncharted exploration of the conformational space. The\ndata set generated in this exploration is then post-processed to obtain a\nnetwork representation of the reactive kinetics.\n  Quantum annealing machines can exploit quantum superposition to encode all\nthe transition pathways in this network in the initial quantum state and ensure\nthe generation of completely uncorrelated transition paths. In particular, we\nresort to the DWAVE quantum computer to perform an all-atom simulation of a\nprotein conformational transition that occurs on the ms timescale. Our results\nmatch those of a special purpose supercomputer designed to perform MD\nsimulations. These results highlight the role of biomolecular simulation as a\nground for applying, testing, and advancing quantum technologies.",
            "author": [
                "Danial Ghamari",
                "Roberto Covino",
                "Pietro Faccioli"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15891v1",
                "http://arxiv.org/pdf/2311.15891v1"
            ],
            "primary_category": "physics.bio-ph",
            "category": [
                "physics.bio-ph",
                "cond-mat.stat-mech",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15887v1",
            "title": "FLASC: A Flare-Sensitive Clustering Algorithm: Extending HDBSCAN* for\n  Detecting Branches in Clusters",
            "updated": "2023-11-27T14:55:16Z",
            "published": "2023-11-27T14:55:16Z",
            "summary": "We present FLASC, an algorithm for flare-sensitive clustering. Our algorithm\nbuilds upon HDBSCAN* -- which provides high-quality density-based clustering\nperformance -- through a post-processing step that differentiates branches\nwithin the detected clusters' manifold, adding a type of pattern that can be\ndiscovered. Two variants of the algorithm are presented, which trade\ncomputational cost for noise robustness. We show that both variants scale\nsimilarly to HDBSCAN* in terms of computational cost and provide stable outputs\nusing synthetic data sets, resulting in an efficient flare-sensitive clustering\nalgorithm. In addition, we demonstrate the algorithm's benefit in data\nexploration over HDBSCAN* clustering on two real-world data sets.",
            "author": [
                "D. M. Bot",
                "J. Peeters",
                "J. Liesenborgs",
                "J. Aerts"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15887v1",
                "http://arxiv.org/pdf/2311.15887v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DB",
                "I.5.3; H.3.3"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15884v1",
            "title": "Elementary Quantum Recursion Schemes That Capture Quantum\n  Polylogarithmic Time Computability of Quantum Functions",
            "updated": "2023-11-27T14:53:45Z",
            "published": "2023-11-27T14:53:45Z",
            "summary": "Quantum computing has been studied over the past four decades based on two\ncomputational models of quantum circuits and quantum Turing machines. To\ncapture quantum polynomial-time computability, a new recursion-theoretic\napproach was taken lately by Yamakami [J. Symb. Logic 80, pp. 1546--1587, 2020]\nby way of recursion schematic definitions, which constitute six initial quantum\nfunctions and three construction schemes of composition, branching, and\nmulti-qubit quantum recursion. By taking a similar approach, we look into\nquantum logarithmic-time computability and further explore the expressing power\nof elementary schemes designed for such quantum computation. In particular, we\nintroduce an elementary form of the quantum recursion, called the fast quantum\nrecursion and formulate EQS (elementary quantum schemes) of \"elementary\"\nquantum functions. This class EQS captures exactly quantum logarithmic-time\ncomputability, represented by BQPOLYLOGTIME. We also demonstrate the separation\nof BQPOLYLOGTIME from NLOGTIME and PPOLYLOGTIME. As a natural extension of EQS,\nwe further consider an algorithmic procedural scheme that implements the\nwell-known divide-and-conquer strategy. This divide-and-conquer scheme helps\ncompute the parity function but the scheme cannot be realized within our system\nEQS.",
            "author": [
                "Tomoyuki Yamakami"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15884v1",
                "http://arxiv.org/pdf/2311.15884v1"
            ],
            "primary_category": "cs.CC",
            "category": [
                "cs.CC",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15883v1",
            "title": "Characterising and Verifying the Core in Concurrent Multi-Player\n  Mean-Payoff Games (Full Version)",
            "updated": "2023-11-27T14:53:26Z",
            "published": "2023-11-27T14:53:26Z",
            "summary": "Concurrent multi-player mean-payoff games are important models for systems of\nagents with individual, non-dichotomous preferences. Whilst these games have\nbeen extensively studied in terms of their equilibria in non-cooperative\nsettings, this paper explores an alternative solution concept: the core from\ncooperative game theory. This concept is particularly relevant for cooperative\nAI systems, as it enables the modelling of cooperation among agents, even when\ntheir goals are not fully aligned. Our contribution is twofold. First, we\nprovide a characterisation of the core using discrete geometry techniques and\nestablish a necessary and sufficient condition for its non-emptiness. We then\nuse the characterisation to prove the existence of polynomial witnesses in the\ncore. Second, we use the existence of such witnesses to solve key decision\nproblems in rational verification and provide tight complexity bounds for the\nproblem of checking whether some/every equilibrium in a game satisfies a given\nLTL or GR(1) specification. Our approach is general and can be adapted to\nhandle other specifications expressed in various fragments of LTL without\nincurring additional computational costs.",
            "author": [
                "Julian Gutierrez",
                "Anthony W. Lin",
                "Muhammad Najib",
                "Thomas Steeples",
                "Michael Wooldridge"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15883v1",
                "http://arxiv.org/pdf/2311.15883v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT",
                "cs.FL",
                "cs.LO",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15882v1",
            "title": "Droplet control based on pinning and substrate wettability",
            "updated": "2023-11-27T14:52:29Z",
            "published": "2023-11-27T14:52:29Z",
            "summary": "Pinning of liquid droplets on solid substrates is ubiquitous and plays an\nessential role in many applications, especially in various areas, such as\nmicrofluidics and biology. Although pinning can often reduce the efficiency of\nvarious applications, a deeper understanding of this phenomenon can actually\noffer possibilities for technological exploitation. Here, by means of molecular\ndynamics simulation, we identify the conditions that lead to droplet pinning or\ndepinning and discuss the effects of key parameters in detail, such as the\nheight of the physical pinning-barrier and the wettability of the substrates.\nMoreover, we describe the mechanism of the barrier crossing by the droplet upon\ndepinning, identify the driving force of this process, and, also, elucidate the\ndynamics of the droplet. Not only does our work provide a detailed description\nof the pinning and depinning processes, but it also explicitly highlights how\nboth processes can be exploited in nanotechnology applications to control\ndroplet motion. Hence, we anticipate that our study will have significant\nimplications for the nanoscale design of substrates in micro and nano-scale\nsystems and will assist with assessing pinning effects in various applications.",
            "author": [
                "Panagiotis E. Theodorakis",
                "Alidad Amirfazli",
                "Bin Hu",
                "Zhizhao Che"
            ],
            "link": [
                "http://dx.doi.org/10.1021/acs.langmuir.1c00215",
                "http://arxiv.org/abs/2311.15882v1",
                "http://arxiv.org/pdf/2311.15882v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn",
                "cond-mat.soft"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15879v1",
            "title": "EVCap: Retrieval-Augmented Image Captioning with External Visual-Name\n  Memory for Open-World Comprehension",
            "updated": "2023-11-27T14:51:37Z",
            "published": "2023-11-27T14:51:37Z",
            "summary": "Large language models (LLMs)-based image captioning has the capability of\ndescribing objects not explicitly observed in training data; yet novel objects\noccur frequently, necessitating the requirement of sustaining up-to-date object\nknowledge for open-world comprehension. Instead of relying on large amounts of\ndata and scaling up network parameters, we introduce a highly effective\nretrieval-augmented image captioning method that prompts LLMs with object names\nretrieved from External Visual--name memory (EVCap). We build ever-changing\nobject knowledge memory using objects' visuals and names, enabling us to (i)\nupdate the memory at a minimal cost and (ii) effortlessly augment LLMs with\nretrieved object names utilizing a lightweight and fast-to-train model. Our\nmodel, which was trained only on the COCO dataset, can be adapted to out-domain\ndata without additional fine-tuning or retraining. Our comprehensive\nexperiments conducted on various benchmarks and synthetic commonsense-violating\ndata demonstrate that EVCap, comprising solely 3.97M trainable parameters,\nexhibits superior performance compared to other methods of equivalent model\nsize scale. Notably, it achieves competitive performance against specialist\nSOTAs with an enormous number of parameters. Our code is available at\nhttps://jiaxuan-li.github.io/EVCap.",
            "author": [
                "Jiaxuan Li",
                "Duc Minh Vo",
                "Akihiro Sugimoto",
                "Hideki Nakayama"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15879v1",
                "http://arxiv.org/pdf/2311.15879v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15876v1",
            "title": "RO-LLaMA: Generalist LLM for Radiation Oncology via Noise Augmentation\n  and Consistency Regularization",
            "updated": "2023-11-27T14:49:06Z",
            "published": "2023-11-27T14:49:06Z",
            "summary": "Recent advancements in Artificial Intelligence (AI) have profoundly\ninfluenced medical fields, by providing tools to reduce clinical workloads.\nHowever, most AI models are constrained to execute uni-modal tasks, in stark\ncontrast to the comprehensive approaches utilized by medical professionals. To\naddress this, here we present RO-LLaMA, a versatile generalist large language\nmodel (LLM) tailored for the field of radiation oncology. This model seamlessly\ncovers a wide range of the workflow of radiation oncologists, adept at various\ntasks such as clinical report summarization, radiation therapy plan suggestion,\nand plan-guided therapy target volume segmentation. In particular, to maximize\nthe end-to-end performance, we further present a novel Consistency Embedding\nFine-Tuning (CEFTune) technique, which boosts LLM's robustness to additional\nerrors at the intermediates while preserving the capability of handling clean\ninputs, and creatively transform this concept into LLM-driven segmentation\nframework as Consistency Embedding Segmentation (CESEG). Experimental results\non multi-centre cohort sets demonstrate our proposed RO-LLaMA's promising\nperformance for diverse tasks with generalization capabilities.",
            "author": [
                "Kwanyoung Kim",
                "Yujin Oh",
                "Sangjoon Park",
                "Hwa Kyung Byun",
                "Jin Sung Kim",
                "Yong Bae Kim",
                "Jong Chul Ye"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15876v1",
                "http://arxiv.org/pdf/2311.15876v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15873v1",
            "title": "Taming Quantum Time Complexity",
            "updated": "2023-11-27T14:45:19Z",
            "published": "2023-11-27T14:45:19Z",
            "summary": "Quantum query complexity has several nice properties with respect to\ncomposition. First, bounded-error quantum query algorithms can be composed\nwithout incurring log factors through error reduction (exactness). Second,\nthrough careful accounting (thriftiness), the total query complexity is smaller\nif subroutines are mostly run on cheaper inputs -- a property that is much less\nobvious in quantum algorithms than in their classical counterparts. While these\nproperties were previously seen through the model of span programs\n(alternatively, the dual adversary bound), a recent work by two of the authors\n(Belovs, Yolcu 2023) showed how to achieve these benefits without converting to\nspan programs, by defining quantum Las Vegas query complexity. Independently,\nrecent works, including by one of the authors (Jeffery 2022), have worked\ntowards bringing thriftiness to the more practically significant setting of\nquantum time complexity.\n  In this work, we show how to achieve both exactness and thriftiness in the\nsetting of time complexity. We generalize the quantum subroutine composition\nresults of Jeffery 2022 so that, in particular, no error reduction is needed.\nWe give a time complexity version of the well-known result in quantum query\ncomplexity, $Q(f\\circ g)=O(Q(f)\\cdot Q(g))$, without log factors.\n  We achieve this by employing a novel approach to the design of quantum\nalgorithms based on what we call transducers, and which we think is of large\nindependent interest. While a span program is a completely different\ncomputational model, a transducer is a direct generalisation of a quantum\nalgorithm, which allows for much greater transparency and control. Transducers\nnaturally characterize general state conversion, rather than only decision\nproblems; provide a very simple treatment of other quantum primitives such as\nquantum walks; and lend themselves well to time complexity analysis.",
            "author": [
                "Aleksandrs Belovs",
                "Stacey Jeffery",
                "Duyal Yolcu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15873v1",
                "http://arxiv.org/pdf/2311.15873v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15865v1",
            "title": "A precise symbolic emulator of the linear matter power spectrum",
            "updated": "2023-11-27T14:33:21Z",
            "published": "2023-11-27T14:33:21Z",
            "summary": "Computing the matter power spectrum, $P(k)$, as a function of cosmological\nparameters can be prohibitively slow in cosmological analyses, hence emulating\nthis calculation is desirable. Previous analytic approximations are\ninsufficiently accurate for modern applications, so black-box, uninterpretable\nemulators are often used. We utilise an efficient genetic programming based\nsymbolic regression framework to explore the space of potential mathematical\nexpressions which can approximate the power spectrum and $\\sigma_8$. We learn\nthe ratio between an existing low-accuracy fitting function for $P(k)$ and that\nobtained by solving the Boltzmann equations and thus still incorporate the\nphysics which motivated this earlier approximation. We obtain an analytic\napproximation to the linear power spectrum with a root mean squared fractional\nerror of 0.2% between $k = 9\\times10^{-3} - 9 \\, h{\\rm \\, Mpc^{-1}}$ and across\na wide range of cosmological parameters, and we provide physical\ninterpretations for various terms in the expression. We also provide a simple\nanalytic approximation for $\\sigma_8$ with a similar accuracy, with a root mean\nsquared fractional error of just 0.4% when evaluated across the same range of\ncosmologies. This function is easily invertible to obtain $A_{\\rm s}$ as a\nfunction of $\\sigma_8$ and the other cosmological parameters, if preferred. It\nis possible to obtain symbolic approximations to a seemingly complex function\nat a precision required for current and future cosmological analyses without\nresorting to deep-learning techniques, thus avoiding their black-box nature and\nlarge number of parameters. Our emulator will be usable long after the codes on\nwhich numerical approximations are built become outdated.",
            "author": [
                "Deaglan J. Bartlett",
                "Lukas Kammerer",
                "Gabriel Kronberger",
                "Harry Desmond",
                "Pedro G. Ferreira",
                "Benjamin D. Wandelt",
                "Bogdan Burlacu",
                "David Alonso",
                "Matteo Zennaro"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15865v1",
                "http://arxiv.org/pdf/2311.15865v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO",
                "astro-ph.IM",
                "cs.LG",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15864v1",
            "title": "InterControl: Generate Human Motion Interactions by Controlling Every\n  Joint",
            "updated": "2023-11-27T14:32:33Z",
            "published": "2023-11-27T14:32:33Z",
            "summary": "Text-conditioned human motion generation model has achieved great progress by\nintroducing diffusion models and corresponding control signals. However, the\ninteraction between humans are still under explored. To model interactions of\narbitrary number of humans, we define interactions as human joint pairs that\nare either in contact or separated, and leverage {\\em Large Language Model\n(LLM) Planner} to translate interaction descriptions into contact plans. Based\non the contact plans, interaction generation could be achieved by spatially\ncontrollable motion generation methods by taking joint contacts as spatial\nconditions. We present a novel approach named InterControl for flexible spatial\ncontrol of every joint in every person at any time by leveraging motion\ndiffusion model only trained on single-person data. We incorporate a motion\ncontrolnet to generate coherent and realistic motions given sparse spatial\ncontrol signals and a loss guidance module to precisely align any joint to the\ndesired position in a classifier guidance manner via Inverse Kinematics (IK).\nExtensive experiments on HumanML3D and KIT-ML dataset demonstrate its\neffectiveness in versatile joint control. We also collect data of joint contact\npairs by LLMs to show InterControl's ability in human interaction generation.",
            "author": [
                "Zhenzhi Wang",
                "Jingbo Wang",
                "Dahua Lin",
                "Bo Dai"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15864v1",
                "http://arxiv.org/pdf/2311.15864v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15859v1",
            "title": "Efficient solution of the non-unitary time-dependent Schrodinger\n  equation on a quantum computer with complex absorbing potential",
            "updated": "2023-11-27T14:25:41Z",
            "published": "2023-11-27T14:25:41Z",
            "summary": "We explore the possibility of adding complex absorbing potential at the\nboundaries when solving the one-dimensional real-time Schr\\\"odinger evolution\non a grid using a quantum computer with a fully quantum algorithm described on\na $n$ qubit register. Due to the complex potential, the evolution mixes real-\nand imaginary-time propagation and the wave function can potentially be\ncontinuously absorbed during the time propagation. We use the dilation quantum\nalgorithm to treat the imaginary-time evolution in parallel to the real-time\npropagation. This method has the advantage of using only one reservoir qubit at\na time, that is measured with a certain success probability to implement the\ndesired imaginary-time evolution. We propose a specific prescription for the\ndilation method where the success probability is directly linked to the\nphysical norm of the continuously absorbed state evolving on the mesh. We\nexpect that the proposed prescription will have the advantage of keeping a high\nprobability of success in most physical situations. Applications of the method\nare made on one-dimensional wave functions evolving on a mesh. Results obtained\non a quantum computer identify with those obtained on a classical computer. We\nfinally give a detailed discussion on the complexity of implementing the\ndilation matrix. Due to the local nature of the potential, for $n$ qubits, the\ndilation matrix only requires $2^n$ CNOT and $2^n$ unitary rotation for each\ntime step, whereas it would require of the order of $4^{n+1}$ C-NOT gates to\nimplement it using the best-known algorithm for general unitary matrices.",
            "author": [
                "Mariane Mangin-Brinet",
                "Jing Zhang",
                "Denis Lacroix",
                "Edgar Andres Ruiz Guzman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15859v1",
                "http://arxiv.org/pdf/2311.15859v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15858v1",
            "title": "Multi-Agent Reinforcement Learning for Power Control in Wireless\n  Networks via Adaptive Graphs",
            "updated": "2023-11-27T14:25:40Z",
            "published": "2023-11-27T14:25:40Z",
            "summary": "The ever-increasing demand for high-quality and heterogeneous wireless\ncommunication services has driven extensive research on dynamic optimization\nstrategies in wireless networks. Among several possible approaches, multi-agent\ndeep reinforcement learning (MADRL) has emerged as a promising method to\naddress a wide range of complex optimization problems like power control.\nHowever, the seamless application of MADRL to a variety of network optimization\nproblems faces several challenges related to convergence. In this paper, we\npresent the use of graphs as communication-inducing structures among\ndistributed agents as an effective means to mitigate these challenges.\nSpecifically, we harness graph neural networks (GNNs) as neural architectures\nfor policy parameterization to introduce a relational inductive bias in the\ncollective decision-making process. Most importantly, we focus on modeling the\ndynamic interactions among sets of neighboring agents through the introduction\nof innovative methods for defining a graph-induced framework for integrated\ncommunication and learning. Finally, the superior generalization capabilities\nof the proposed methodology to larger networks and to networks with different\nuser categories is verified through simulations.",
            "author": [
                "Lorenzo Mario Amorosa",
                "Marco Skocaj",
                "Roberto Verdone",
                "Deniz G\u00fcnd\u00fcz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15858v1",
                "http://arxiv.org/pdf/2311.15858v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "cs.LG",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15857v1",
            "title": "A generalization of Markov's approach to the continuity problem for Type\n  1 computable functions",
            "updated": "2023-11-27T14:25:25Z",
            "published": "2023-11-27T14:25:25Z",
            "summary": "We axiomatize and generalize Markov's approach to the continuity problem for\nType 1 computable functions, i.e. the problem of finding sufficient conditions\non a computable topological space to obtain a theorem of the form \"computable\nfunctions are (effectively) continuous\". In a computable topological space, a\npoint $x$ is called effectively adherent to a set $A$ if there is an algorithm\nthat on input a neighborhood of $x$ produces a point of $A$ in that\nneighborhood. We say that a space $X$ satisfies a Markov condition if, whenever\na point $x$ of $X$ is effectively adherent to a subset $A$ of $X$, the\nsingleton $\\{x\\}$ is not a semi-decidable subset of $A\\cup\\{x\\}$. We show that\nthis condition prevents functions whose domain is $X$ from having effective\ndiscontinuities, provided that their codomain is a space where points have\nneighborhood bases of co-semi-decidable sets. We then show that results that\nforbid effective discontinuities can be turned into (abstract) continuity\nresults on spaces where the closure and effective closure of semi-decidable\nsets naturally agree -this happens for instance on spaces which admit a dense\nand computable sequence. This work is motivated by the study of the space of\nmarked groups, for which the author has shown that most known continuity\nresults (of Ceitin, Moschovakis, Spreen) do not apply.",
            "author": [
                "Emmanuel Rauzy"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15857v1",
                "http://arxiv.org/pdf/2311.15857v1"
            ],
            "primary_category": "math.LO",
            "category": [
                "math.LO",
                "03D45, 03D78"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15856v1",
            "title": "JSSL: Joint Supervised and Self-supervised Learning for MRI\n  Reconstruction",
            "updated": "2023-11-27T14:23:36Z",
            "published": "2023-11-27T14:23:36Z",
            "summary": "Magnetic Resonance Imaging represents an important diagnostic modality;\nhowever, its inherently slow acquisition process poses challenges in obtaining\nfully sampled k-space data under motion in clinical scenarios such as\nabdominal, cardiac, and prostate imaging. In the absence of fully sampled\nacquisitions, which can serve as ground truth data, training deep learning\nalgorithms in a supervised manner to predict the underlying ground truth image\nbecomes an impossible task. To address this limitation, self-supervised methods\nhave emerged as a viable alternative, leveraging available subsampled k-space\ndata to train deep learning networks for MRI reconstruction. Nevertheless,\nthese self-supervised approaches often fall short when compared to supervised\nmethodologies. In this paper, we introduce JSSL (Joint Supervised and\nSelf-supervised Learning), a novel training approach for deep learning-based\nMRI reconstruction algorithms aimed at enhancing reconstruction quality in\nscenarios where target dataset(s) containing fully sampled k-space measurements\nare unavailable. Our proposed method operates by simultaneously training a\nmodel in a self-supervised learning setting, using subsampled data from the\ntarget dataset(s), and in a supervised learning manner, utilizing data from\nother datasets, referred to as proxy datasets, where fully sampled k-space data\nis accessible. To demonstrate the efficacy of JSSL, we utilized subsampled\nprostate parallel MRI measurements as the target dataset, while employing fully\nsampled brain and knee k-space acquisitions as proxy datasets. Our results\nshowcase a substantial improvement over conventional self-supervised training\nmethods, thereby underscoring the effectiveness of our joint approach. We\nprovide a theoretical motivation for JSSL and establish a practical\n\"rule-of-thumb\" for selecting the most appropriate training approach for deep\nMRI reconstruction.",
            "author": [
                "George Yiasemis",
                "Nikita Moriakov",
                "Clara I. S\u00e1nchez",
                "Jan-Jakob Sonke",
                "Jonas Teuwen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15856v1",
                "http://arxiv.org/pdf/2311.15856v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "physics.med-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15849v1",
            "title": "Empirical instability strip for classical Cepheids: I. The LMC galaxy",
            "updated": "2023-11-27T14:16:11Z",
            "published": "2023-11-27T14:16:11Z",
            "summary": "The instability strip (IS) of classical Cepheids has been extensively studied\ntheoretically. Comparison of the theoretical IS edges with those obtained\nempirically, using the most recent Cepheids catalogs available, can provide us\nwith insights into the physical processes that determine the position of the IS\nboundaries. In this study, we investigate the empirical positions of the IS of\nthe classical Cepheids in the Large Magellanic Cloud (LMC), considering any\neffect that increases its width, to obtain intrinsic edges that can be compared\nwith theoretical models. We use data of classical fundamental-mode (F) and\nfirst-overtone (1O) LMC Cepheids from the OGLE-IV variable star catalog,\ntogether with a recent high-resolution reddening map from the literature. Our\nfinal sample includes 2058 F and 1387 1O Cepheids. We studied their position on\nthe Hertzsprung-Russell diagram and determined the IS borders by tracing the\nedges of the color distribution along the strip. We obtain the blue and red\nedges of the IS in V- and I-photometric bands, in addition to $\\log T_{\\rm\neff}$ and $\\log L$. The results obtained show a break located at the Cepheids'\nperiod of about 3 days, which was not reported before. We compare our empirical\nborders with theoretical ones published in the literature obtaining a good\nagreement for specific parameter sets. The break in the IS borders is most\nlikely explained by the depopulation of second and third crossing classical\nCepheids in the faint part of the IS, since blue loops of evolutionary tracks\nin this mass range do not extend blueward enough to cross the IS at the LMC\nmetallicity. Results from the comparison of our empirical borders with\ntheoretical ones prove that our empirical IS is a useful tool for constraining\ntheoretical models.",
            "author": [
                "F. Espinoza-Arancibia",
                "B. Pilecki",
                "G. Pietrzy\u0144ski",
                "R. Smolec",
                "P. Kervella"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15849v1",
                "http://arxiv.org/pdf/2311.15849v1"
            ],
            "primary_category": "astro-ph.SR",
            "category": [
                "astro-ph.SR",
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15847v1",
            "title": "Cell Maps Representation For Lung Adenocarcinoma Growth Patterns\n  Classification In Whole Slide Images",
            "updated": "2023-11-27T14:12:51Z",
            "published": "2023-11-27T14:12:51Z",
            "summary": "Lung adenocarcinoma is a morphologically heterogeneous disease, characterized\nby five primary histologic growth patterns. The quantity of these patterns can\nbe related to tumor behavior and has a significant impact on patient prognosis.\nIn this work, we propose a novel machine learning pipeline capable of\nclassifying tissue tiles into one of the five patterns or as non-tumor, with an\nArea Under the Receiver Operating Characteristic Curve (AUCROC) score of 0.97.\nOur model's strength lies in its comprehensive consideration of cellular\nspatial patterns, where it first generates cell maps from Hematoxylin and Eosin\n(H&E) whole slide images (WSIs), which are then fed into a convolutional neural\nnetwork classification model. Exploiting these cell maps provides the model\nwith robust generalizability to new data, achieving approximately 30% higher\naccuracy on unseen test-sets compared to current state of the art approaches.\nThe insights derived from our model can be used to predict prognosis, enhancing\npatient outcomes.",
            "author": [
                "Arwa Al-Rubaian",
                "Gozde N. Gunesli",
                "Wajd A. Althakfi",
                "Ayesha Azam",
                "Nasir Rajpoot",
                "Shan E Ahmed Raza"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15847v1",
                "http://arxiv.org/pdf/2311.15847v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15846v1",
            "title": "Learning with Noisy Low-Cost MOS for Image Quality Assessment via\n  Dual-Bias Calibration",
            "updated": "2023-11-27T14:11:54Z",
            "published": "2023-11-27T14:11:54Z",
            "summary": "Learning based image quality assessment (IQA) models have obtained impressive\nperformance with the help of reliable subjective quality labels, where mean\nopinion score (MOS) is the most popular choice. However, in view of the\nsubjective bias of individual annotators, the labor-abundant MOS (LA-MOS)\ntypically requires a large collection of opinion scores from multiple\nannotators for each image, which significantly increases the learning cost. In\nthis paper, we aim to learn robust IQA models from low-cost MOS (LC-MOS), which\nonly requires very few opinion scores or even a single opinion score for each\nimage. More specifically, we consider the LC-MOS as the noisy observation of\nLA-MOS and enforce the IQA model learned from LC-MOS to approach the unbiased\nestimation of LA-MOS. In this way, we represent the subjective bias between\nLC-MOS and LA-MOS, and the model bias between IQA predictions learned from\nLC-MOS and LA-MOS (i.e., dual-bias) as two latent variables with unknown\nparameters. By means of the expectation-maximization based alternating\noptimization, we can jointly estimate the parameters of the dual-bias, which\nsuppresses the misleading of LC-MOS via a gated dual-bias calibration (GDBC)\nmodule. To the best of our knowledge, this is the first exploration of robust\nIQA model learning from noisy low-cost labels. Theoretical analysis and\nextensive experiments on four popular IQA datasets show that the proposed\nmethod is robust toward different bias rates and annotation numbers and\nsignificantly outperforms the other learning based IQA models when only LC-MOS\nis available. Furthermore, we also achieve comparable performance with respect\nto the other models learned with LA-MOS.",
            "author": [
                "Lei Wang",
                "Qingbo Wu",
                "Desen Yuan",
                "King Ngi Ngan",
                "Hongliang Li",
                "Fanman Meng",
                "Linfeng Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15846v1",
                "http://arxiv.org/pdf/2311.15846v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15842v1",
            "title": "IPv6 Bitcoin-Certified Addresses",
            "updated": "2023-11-27T14:08:31Z",
            "published": "2023-11-27T14:08:31Z",
            "summary": "A pivotal feature of IPv6 is its plug-and-play capability that enables hosts\nto integrate seamlessly into networks. In the absence of a trusted authority or\nsecurity infrastructure, the challenge for hosts is generating their own\naddress and verifying ownership of others. Cryptographically Generated\nAddresses (CGA) solves this problem by binding IPv6 addresses to hosts' public\nkeys to prove address ownership. CGA generation involves solving a\ncryptographic puzzle similar to Bitcoin's Proof-of-Work (PoW) to deter address\nspoofing. Unfortunately, solving the puzzle often causes undesirable address\ngeneration delays, which has hindered the adoption of CGA. In this paper, we\npresent Bitcoin-Certified Addresses (BCA), a new technique to bind IPv6\naddresses to hosts' public keys. BCA reduces the computational cost of\ngenerating addresses by using the PoW computed by Bitcoin nodes to secure the\nbinding. Compared to CGA, BCA provides better protection against spoofing\nattacks and improves the privacy of hosts. Due to the decentralized nature of\nthe Bitcoin network, BCA avoids reliance on a trusted authority, similar to\nCGA. BCA shows how the PoW computed by Bitcoin nodes can be reused, which saves\ncosts for hosts and makes Bitcoin mining more efficient.",
            "author": [
                "Mathieu Ducroux"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15842v1",
                "http://arxiv.org/pdf/2311.15842v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15840v1",
            "title": "turbo-RANS: Straightforward and Efficient Bayesian Optimization of\n  Turbulence Model Coefficients",
            "updated": "2023-11-27T14:05:29Z",
            "published": "2023-11-27T14:05:29Z",
            "summary": "Industrial simulations of turbulent flows often rely on Reynolds-averaged\nNavier-Stokes (RANS) turbulence models, which contain numerous closure\ncoefficients that need to be calibrated. Although tuning these coefficients can\nproduce significantly improved predictive accuracy, their default values are\noften used. We believe users do not calibrate RANS models for several reasons:\nthere is no clearly recommended framework to optimize these coefficients; the\naverage user does not have the expertise to implement such a framework; and,\nthe optimization of the values of these coefficients can be a computationally\nexpensive process. In this work, we address these issues by proposing a\nsemi-automated calibration of these coefficients using a new framework based on\nBayesian optimization. We introduce the generalized error and default\ncoefficient preference (GEDCP) objective function, which can be used with\nintegral, sparse, or dense reference data. We demonstrate the computationally\nefficient performance of turbo-RANS for three example cases: predicting the\nlift coefficient of an airfoil; predicting the velocity and turbulent kinetic\nenergy fields for a separated flow; and, predicting the wall pressure\ncoefficient distribution for flow through a converging-diverging channel. In\nthe first two examples, we calibrate the $k$-$\\omega$ shear stress transport\n(SST) turbulence model and, in the last example, we calibrate user-specified\ncoefficients for the Generalized $k$-$\\omega$ (GEKO) model in Ansys Fluent. An\nin-depth hyperparameter tuning study is conducted to recommend efficient\nsettings for the turbo-RANS optimization procedure. Towards the goal of\nfacilitating RANS turbulence closure model calibration, we provide an\nopen-source implementation of the turbo-RANS framework that includes OpenFOAM,\nAnsys Fluent, and solver-agnostic templates for user application.",
            "author": [
                "Ryley McConkey",
                "Nikhila Kalia",
                "Eugene Yee",
                "Fue-Sang Lien"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15840v1",
                "http://arxiv.org/pdf/2311.15840v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15839v1",
            "title": "Ontologising Trustworthy in the Telecommunications Domain",
            "updated": "2023-11-27T14:04:46Z",
            "published": "2023-11-27T14:04:46Z",
            "summary": "Based upon trusted and confidential computing platforms, telecommunications\nsystems must provide guaranteed security for the processes and data running\natop them. This in turn requires us to provide trustworthy systems. The term\ntrustworthy is poorly defined with corresponding misunderstanding and\nmisapplication. We present a definition of this term, as well as others,\ndemonstrate its application against certain telecommunications use cases and\naddress how the learnings from ontologising these structures contribute to\nstandardisation and the necessity for FAIR ontologies across telecommunications\nstandards and hosting organisations.",
            "author": [
                "Ian Oliver",
                "Pekka Kuure",
                "Wiktor Sedkowski",
                "Thore Sommer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15839v1",
                "http://arxiv.org/pdf/2311.15839v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.SE",
                "D.2.1"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15838v1",
            "title": "Utilizing Explainability Techniques for Reinforcement Learning Model\n  Assurance",
            "updated": "2023-11-27T14:02:47Z",
            "published": "2023-11-27T14:02:47Z",
            "summary": "Explainable Reinforcement Learning (XRL) can provide transparency into the\ndecision-making process of a Deep Reinforcement Learning (DRL) model and\nincrease user trust and adoption in real-world use cases. By utilizing XRL\ntechniques, researchers can identify potential vulnerabilities within a trained\nDRL model prior to deployment, therefore limiting the potential for mission\nfailure or mistakes by the system. This paper introduces the ARLIN (Assured RL\nModel Interrogation) Toolkit, an open-source Python library that identifies\npotential vulnerabilities and critical points within trained DRL models through\ndetailed, human-interpretable explainability outputs. To illustrate ARLIN's\neffectiveness, we provide explainability visualizations and vulnerability\nanalysis for a publicly available DRL model. The open-source code repository is\navailable for download at https://github.com/mitre/arlin.",
            "author": [
                "Alexander Tapley",
                "Kyle Gatesman",
                "Luis Robaina",
                "Brett Bissey",
                "Joseph Weissman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15838v1",
                "http://arxiv.org/pdf/2311.15838v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15835v1",
            "title": "Surface skyrmions and dual topological Hall effect in antiferromagnetic\n  topological insulator EuCd$_2$As$_2$",
            "updated": "2023-11-27T13:59:53Z",
            "published": "2023-11-27T13:59:53Z",
            "summary": "In this work, we synthesized single crystal of EuCd$_2$As$_2$, which exhibits\nA-type antiferromagnetic (AFM) order with in-plane spin orientation below $T_N$\n= 9.5~K.Optical spectroscopy and transport measurements suggest its topological\ninsulator (TI) nature with an insulating gap around 0.1eV. Remarkably, a dual\ntopological Hall resistivity that exhibits same magnitude but opposite signs in\nthe positive to negative and negative to positive magnetic field hysteresis\nbranches emerges below 20~K. With magnetic force microscopy (MFM) images and\nnumerical simulations, we attribute the dual topological Hall effect to the\nN\\'{e}el-type skyrmions stabilized by the interactions between topological\nsurface states and magnetism, and the sign reversal in different hysteresis\nbranches indicates potential coexistence of skyrmions and antiskyrmions. Our\nwork uncovers a unique two-dimensional (2D) magnetism on the surface of\nintrinsic AFM TI, providing a promising platform for novel topological quantum\nstates and AFM spintronic applications.",
            "author": [
                "Min Wu",
                "R. Yang",
                "Xiangde Zhu",
                "Yixiong Ren",
                "Ang Qian",
                "Yongjie Xie",
                "Changming Yue",
                "Yong Nie",
                "Xiang Yuan",
                "Ning Wang",
                "Daifeng Tu",
                "Ding Li",
                "Yuyan Han",
                "Zhaosheng Wang",
                "Yaomin Dai",
                "Guolin Zheng",
                "Jianhui Zhou",
                "Wei Ning",
                "Xianggang Qiu",
                "Mingliang Tian"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15835v1",
                "http://arxiv.org/pdf/2311.15835v1"
            ],
            "primary_category": "cond-mat.supr-con",
            "category": [
                "cond-mat.supr-con",
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15831v1",
            "title": "Temporal Action Localization for Inertial-based Human Activity\n  Recognition",
            "updated": "2023-11-27T13:55:21Z",
            "published": "2023-11-27T13:55:21Z",
            "summary": "A persistent trend in Deep Learning has been the applicability of machine\nlearning concepts to other areas than originally introduced for. As of today,\nstate-of-the-art activity recognition from wearable sensors relies on\nclassifiers being trained on fixed windows of data. Contrarily, video-based\nHuman Activity Recognition has followed a segment-based prediction approach,\nlocalizing activity occurrences from start to end. This paper is the first to\nsystematically demonstrate the applicability of state-of-the-art TAL models for\nwearable Human Activity Recongition (HAR) using raw inertial data as input. Our\nresults show that state-of-the-art TAL models are able to outperform popular\ninertial models on 4 out of 6 wearable activity recognition benchmark datasets,\nwith improvements ranging as much as 25% in F1-score. Introducing the TAL\ncommunity's most popular metric to inertial-based HAR, namely mean Average\nPrecision, our analysis shows that TAL models are able to produce more coherent\nsegments along with an overall higher NULL-class accuracy across all datasets.\nBeing the first to provide such an analysis, the TAL community offers an\ninteresting new perspective to inertial-based HAR with yet to be explored\ndesign choices and training concepts, which could be of significant value for\nthe inertial-based HAR community.",
            "author": [
                "Marius Bock",
                "Michael Moeller",
                "Kristof Van Laerhoven"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15831v1",
                "http://arxiv.org/pdf/2311.15831v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.HC",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15830v2",
            "title": "A-JEPA: Joint-Embedding Predictive Architecture Can Listen",
            "updated": "2023-11-28T03:15:50Z",
            "published": "2023-11-27T13:53:53Z",
            "summary": "This paper presents that the masked-modeling principle driving the success of\nlarge foundational vision models can be effectively applied to audio by making\npredictions in a latent space. We introduce Audio-based Joint-Embedding\nPredictive Architecture (A-JEPA), a simple extension method for self-supervised\nlearning from the audio spectrum. Following the design of I-JEPA, our A-JEPA\nencodes visible audio spectrogram patches with a curriculum masking strategy\nvia context encoder, and predicts the representations of regions sampled at\nwell-designed locations. The target representations of those regions are\nextracted by the exponential moving average of context encoder, \\emph{i.e.},\ntarget encoder, on the whole spectrogram. We find it beneficial to transfer\nrandom block masking into time-frequency aware masking in a curriculum manner,\nconsidering the complexity of highly correlated in local time and frequency in\naudio spectrograms. To enhance contextual semantic understanding and\nrobustness, we fine-tune the encoder with a regularized masking on target\ndatasets, instead of input dropping or zero. Empirically, when built with\nVision Transformers structure, we find A-JEPA to be highly scalable and sets\nnew state-of-the-art performance on multiple audio and speech classification\ntasks, outperforming other recent models that use externally supervised\npre-training.",
            "author": [
                "Zhengcong Fei",
                "Mingyuan Fan",
                "Junshi Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15830v2",
                "http://arxiv.org/pdf/2311.15830v2"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.CV",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15828v1",
            "title": "A New Polar-Domain Dictionary Design for the Near-field Region of\n  Extremely Large Aperture Arrays",
            "updated": "2023-11-27T13:51:34Z",
            "published": "2023-11-27T13:51:34Z",
            "summary": "A grid of orthogonal beams with zero column coherence can be easily\nconstructed to cover all prospective user equipments (UEs) in the far-field\nregion of a multiple-antenna base station (BS). However, when the BS is\nequipped with an extremely large aperture array, the Fraunhofer distance is\nhuge, causing the UEs to be located in the radiative near-field region. This\ncalls for designing a grid of beams based on a near-field dictionary. In the\nprevious work, a polar-domain grid design was proposed to maintain control over\nthe column coherence. A limitation of this approach is identified in this\npaper, and we propose an enhanced methodology for the design of a polar-domain\ndictionary specifically tailored for the near-field of an extremely large\naperture uniform planar array. Through simulation results, it is demonstrated\nthat the proposed dictionary, employing a non-uniform distance sampling\napproach, achieves lower column coherence than the benchmark and significantly\nimproves the localization of UEs compared to uniform distance sampling.",
            "author": [
                "\u00d6zlem Tu\u011ffe Demir",
                "Emil Bj\u00f6rnson"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15828v1",
                "http://arxiv.org/pdf/2311.15828v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15824v2",
            "title": "Photoevaporation obfuscates the distinction between wind and viscous\n  angular momentum transport in protoplanetary discs",
            "updated": "2023-12-07T12:15:47Z",
            "published": "2023-11-27T13:49:23Z",
            "summary": "How protoplanetary discs evolve remains an unanswered question. Competing\ntheories of viscosity and magnetohydrodynamic disc winds have been put forward\nas the drivers of angular momentum transport in protoplanetary discs. These two\nmodels predict distinct differences in the disc mass, radius and accretion\nrates over time, that could be used to distinguish them. However that\nexpectation is built on models that do not include another important process -\nphotoevaporation, both internally by the host star and externally by\nneighbouring stars. In this work we produce numerical models of protoplanetary\ndiscs including viscosity, magnetohydrodynamic disc winds, and internal and\nexternal photoevaporation. We find that even weak levels of external\nphotoevaporation can significantly affect the evolution of protoplanetary\ndiscs, influencing the observable features such as disc radii, that might\notherwise distinguish between viscous and wind driven discs. Including internal\nphotoevaporation further suppresses differences in evolution between viscous\nand wind driven discs. This makes it much more difficult than previously\nanticipated, to use observations of nearby star forming regions to determine\nwhether discs are viscous or wind driven. Interestingly we find that evolved\nprotoplanetary discs in intermediate FUV environments may be the best cases for\ndifferentiating whether they evolve through viscosity or magnetohydrodynamic\ndisc winds. Ultimately this work demonstrates the importance of understanding\nwhat are the key evolutionary processes and including as many of those as\npossible when exploring the evolution of protoplanetary discs.",
            "author": [
                "Gavin A. L. Coleman",
                "Joseph K. Mroueh",
                "Thomas J. Haworth"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15824v2",
                "http://arxiv.org/pdf/2311.15824v2"
            ],
            "primary_category": "astro-ph.EP",
            "category": [
                "astro-ph.EP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15819v1",
            "title": "Coating-free Underwater Breathing via Biomimicry",
            "updated": "2023-11-27T13:45:19Z",
            "published": "2023-11-27T13:45:19Z",
            "summary": "Numerous natural and engineering scenarios necessitate entrapment of air\npockets or bubbles on submerged surfaces, e.g., aquatic insects, smartphones,\nand membranes for separation and purification. Current technologies for bubble\nentrapment rely heavily on perfluorocarbon coatings, which limits their\nsustainability and applications. Here, we investigate doubly reentrant\ncavities, a biomimetic microtexture capable of entrapping air under wetting\nliquids, under static and dynamic pressure cycling. The effects of positive,\nnegative, and positive-negative cycles are studied across a range of pressure\namplitudes, ramp rates, intercycle intervals, and water column heights.\nRemarkably, the fate of the trapped air under pressure cycling falls into the\nfollowing three distinct regimes: the bubble (i) monotonically depletes, (ii)\nremains indefinitely stable, or (iii) starts growing. This hitherto unrealized\nrichness of underwater bubble dynamics will guide the development of\ncoating-free underwater technologies and provide clues into the curious lives\nof air-breather aquatic/marine insects.",
            "author": [
                "Sankara Narayana Moorthi Arunachalam",
                "Muhammad Subkhi Sadullah",
                "Himanshu Mishra"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15819v1",
                "http://arxiv.org/pdf/2311.15819v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15818v1",
            "title": "A study on various generalizations of Generalized centers $\\bm{(GC)}$ in\n  Banach spaces",
            "updated": "2023-11-27T13:43:23Z",
            "published": "2023-11-27T13:43:23Z",
            "summary": "In [{\\em Generalized centers of finite sets in Banach spaces}, Acta Math.\nUniv. Comenian. (N.S.) {\\bf 66}(1) (1997), 83--115], Vesel\\'{y} developed the\nidea of generalized centers for finite sets in Banach spaces. In this work, we\nexplore the concept of {\\it restricted $\\mathscr{F}$-center property} for a\ntriplet $(X,Y,\\mathcal{F}(X))$, where $Y$ is a subspace of a Banach space $X$\nand $\\mathcal{F}(X)$ is the family of finite subsets of $X$. In addition, we\ngeneralize the analysis to include all closed, bounded subsets of $X$. Similar\nto how Lindenstrauss characterized $n.2.I.P.$, we characterize $n.X.I.P.$. So,\nit is possible to figure out that $Y$ has $n.X.I.P.$ in $X$ for all natural\nnumbers $n$ if and only if $\\textrm{rad}_Y(F)=\\textrm{rad}_X(F)$ for all finite\nsubsets $F$ of $Y$. It then turns out that, for all continuous monotone\nfunctions $f$, the $f$-radii viz. $\\textrm{rad}_Y^f(F),\\textrm{rad}_X^f(F)$ are\nsame whenever the generalised radii viz. $\\textrm{rad}_Y(F), \\textrm{rad}_X(F)$\nare same, for all finite subsets $F$ of $Y$. We establish a variety of\ncharacterizations of central subspaces of Banach spaces. With reference to an\nappropriate subfamily of closed and bounded subsets, it appears that a number\nof function spaces and subspaces exhibit the restricted weighted Chebyshev\ncenter property.",
            "author": [
                "Syamantak Das",
                "Tanmoy Paul"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15818v1",
                "http://arxiv.org/pdf/2311.15818v1"
            ],
            "primary_category": "math.FA",
            "category": [
                "math.FA",
                "math.OC",
                "41A28, 41A65, 46B20, 41A50"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15813v1",
            "title": "FlowZero: Zero-Shot Text-to-Video Synthesis with LLM-Driven Dynamic\n  Scene Syntax",
            "updated": "2023-11-27T13:39:44Z",
            "published": "2023-11-27T13:39:44Z",
            "summary": "Text-to-video (T2V) generation is a rapidly growing research area that aims\nto translate the scenes, objects, and actions within complex video text into a\nsequence of coherent visual frames. We present FlowZero, a novel framework that\ncombines Large Language Models (LLMs) with image diffusion models to generate\ntemporally-coherent videos. FlowZero uses LLMs to understand complex\nspatio-temporal dynamics from text, where LLMs can generate a comprehensive\ndynamic scene syntax (DSS) containing scene descriptions, object layouts, and\nbackground motion patterns. These elements in DSS are then used to guide the\nimage diffusion model for video generation with smooth object motions and\nframe-to-frame coherence. Moreover, FlowZero incorporates an iterative\nself-refinement process, enhancing the alignment between the spatio-temporal\nlayouts and the textual prompts for the videos. To enhance global coherence, we\npropose enriching the initial noise of each frame with motion dynamics to\ncontrol the background movement and camera motion adaptively. By using\nspatio-temporal syntaxes to guide the diffusion process, FlowZero achieves\nimprovement in zero-shot video synthesis, generating coherent videos with vivid\nmotion.",
            "author": [
                "Yu Lu",
                "Linchao Zhu",
                "Hehe Fan",
                "Yi Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15813v1",
                "http://arxiv.org/pdf/2311.15813v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16500v1",
            "title": "LLMGA: Multimodal Large Language Model based Generation Assistant",
            "updated": "2023-11-27T13:37:26Z",
            "published": "2023-11-27T13:37:26Z",
            "summary": "In this paper, we introduce a Multimodal Large Language Model-based\nGeneration Assistant (LLMGA), leveraging the vast reservoir of knowledge and\nproficiency in reasoning, comprehension, and response inherent in Large\nLanguage Models (LLMs) to assist users in image generation and editing.\nDiverging from existing approaches where Multimodal Large Language Models\n(MLLMs) generate fixed-size embeddings to control Stable Diffusion (SD), our\nLLMGA provides a detailed language generation prompt for precise control over\nSD. This not only augments LLM context understanding but also reduces noise in\ngeneration prompts, yields images with more intricate and precise content, and\nelevates the interpretability of the network. To this end, we curate a\ncomprehensive dataset comprising prompt refinement, similar image generation,\ninpainting $\\&$ outpainting, and visual question answering. Moreover, we\npropose a two-stage training scheme. In the first stage, we train the MLLM to\ngrasp the properties of image generation and editing, enabling it to generate\ndetailed prompts. In the second stage, we optimize SD to align with the MLLM's\ngeneration prompts. Additionally, we propose a reference-based restoration\nnetwork to alleviate texture, brightness, and contrast disparities between\ngenerated and preserved regions during image editing. Extensive results show\nthat LLMGA has promising generative capabilities and can enable wider\napplications in an interactive manner.",
            "author": [
                "Bin Xia",
                "Shiyin Wang",
                "Yingfan Tao",
                "Yitong Wang",
                "Jiaya Jia"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16500v1",
                "http://arxiv.org/pdf/2311.16500v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15812v1",
            "title": "C-SAW: Self-Supervised Prompt Learning for Image Generalization in\n  Remote Sensing",
            "updated": "2023-11-27T13:35:20Z",
            "published": "2023-11-27T13:35:20Z",
            "summary": "We focus on domain and class generalization problems in analyzing optical\nremote sensing images, using the large-scale pre-trained vision-language model\n(VLM), CLIP. While contrastively trained VLMs show impressive zero-shot\ngeneralization performance, their effectiveness is limited when dealing with\ndiverse domains during training and testing. Existing prompt learning\ntechniques overlook the importance of incorporating domain and content\ninformation into the prompts, which results in a drop in performance while\ndealing with such multi-domain data. To address these challenges, we propose a\nsolution that ensures domain-invariant prompt learning while enhancing the\nexpressiveness of visual features. We observe that CLIP's vision encoder\nstruggles to identify contextual image information, particularly when image\npatches are jumbled up. This issue is especially severe in optical remote\nsensing images, where land-cover classes exhibit well-defined contextual\nappearances. To this end, we introduce C-SAW, a method that complements CLIP\nwith a self-supervised loss in the visual space and a novel prompt learning\ntechnique that emphasizes both visual domain and content-specific features. We\nkeep the CLIP backbone frozen and introduce a small set of projectors for both\nthe CLIP encoders to train C-SAW contrastively. Experimental results\ndemonstrate the superiority of C-SAW across multiple remote sensing benchmarks\nand different generalization tasks.",
            "author": [
                "Avigyan Bhattacharya",
                "Mainak Singha",
                "Ankit Jha",
                "Biplab Banerjee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15812v1",
                "http://arxiv.org/pdf/2311.15812v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15810v1",
            "title": "Tascade: Hardware Support for Atomic-free, Asynchronous and Efficient\n  Reduction Trees",
            "updated": "2023-11-27T13:32:33Z",
            "published": "2023-11-27T13:32:33Z",
            "summary": "As system parallelism at chip- and server-level increases, challenges that\narose with network-level systems a decade ago, are now being encountered with\nthese massively parallel systems that have become an important workhorse for\nMachine Learning workloads as well as Graph and Sparse workloads. To tackle the\ncommunication bottlenecks, recent works have introduced task-based\nparallelization schemes to accelerate graph search and sparse data-structure\ntraversal, where some solutions scale up to thousands of processing units (PUs)\non a single chip. However, existing communication schemes do not scale to\nlarger than thousands of processing tiles. To address these challenges we\npropose Tascade, a system that offers hardware-supported, efficient and\nbalanced reduction trees to reduce communication overheads in task-based\nparallelization schemes and scales up to a million PUs. Tascade achieves this\nby implementing an execution model utilizing proxy regions and cascading\nupdates, along with a supporting hardware design that enables the execution of\nthe reduction tree at the chip level. The Tascade approach reduces overall\ncommunication and improves load balancing. We evaluate six applications and\nfour datasets to provide a detailed analysis of Tascade's performance, power,\nand traffic-reduction gains over prior work. Our parallelization of\nBreadth-First-Search with RMAT-26 across a million PUs, the largest of the\nliterature, reaches 5305 GTEPS.",
            "author": [
                "Marcelo Orenes-Vera",
                "Esin Tureci",
                "David Wentzlaff",
                "Margaret Martonosi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15810v1",
                "http://arxiv.org/pdf/2311.15810v1"
            ],
            "primary_category": "cs.AR",
            "category": [
                "cs.AR",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15806v1",
            "title": "PIPE : Parallelized Inference Through Post-Training Quantization\n  Ensembling of Residual Expansions",
            "updated": "2023-11-27T13:29:34Z",
            "published": "2023-11-27T13:29:34Z",
            "summary": "Deep neural networks (DNNs) are ubiquitous in computer vision and natural\nlanguage processing, but suffer from high inference cost. This problem can be\naddressed by quantization, which consists in converting floating point\nperations into a lower bit-width format. With the growing concerns on privacy\nrights, we focus our efforts on data-free methods. However, such techniques\nsuffer from their lack of adaptability to the target devices, as a hardware\ntypically only support specific bit widths. Thus, to adapt to a variety of\ndevices, a quantization method shall be flexible enough to find good accuracy\nv.s. speed trade-offs for every bit width and target device. To achieve this,\nwe propose PIPE, a quantization method that leverages residual error expansion,\nalong with group sparsity and an ensemble approximation for better\nparallelization. PIPE is backed off by strong theoretical guarantees and\nachieves superior performance on every benchmarked application (from vision to\nNLP tasks), architecture (ConvNets, transformers) and bit-width (from int8 to\nternary quantization).",
            "author": [
                "Edouard Yvinec",
                "Arnaud Dapogny",
                "Kevin Bailly"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15806v1",
                "http://arxiv.org/pdf/2311.15806v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15804v1",
            "title": "Voice Anonymization for All -- Bias Evaluation of the Voice Privacy\n  Challenge Baseline System",
            "updated": "2023-11-27T13:26:49Z",
            "published": "2023-11-27T13:26:49Z",
            "summary": "In an age of voice-enabled technology, voice anonymization offers a solution\nto protect people's privacy, provided these systems work equally well across\nsubgroups. This study investigates bias in voice anonymization systems within\nthe context of the Voice Privacy Challenge. We curate a novel benchmark dataset\nto assess performance disparities among speaker subgroups based on sex and\ndialect. We analyze the impact of three anonymization systems and attack models\non speaker subgroup bias and reveal significant performance variations.\nNotably, subgroup bias intensifies with advanced attacker capabilities,\nemphasizing the challenge of achieving equal performance across all subgroups.\nOur study highlights the need for inclusive benchmark datasets and\ncomprehensive evaluation strategies that address subgroup bias in voice\nanonymization.",
            "author": [
                "Anna Leschanowsky",
                "\u00dcnal Ege Gaznepoglu",
                "Nils Peters"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15804v1",
                "http://arxiv.org/pdf/2311.15804v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16204v1",
            "title": "Planning for the Efficient Updating of Mutual Fund Portfolios",
            "updated": "2023-11-27T13:09:56Z",
            "published": "2023-11-27T13:09:56Z",
            "summary": "Once there is a decision of rebalancing or updating a portfolio of funds, the\nprocess of changing the current portfolio to the target one, involves a set of\ntransactions that are susceptible of being optimized. This is particularly\nrelevant when managers have to handle the implications of different types of\ninstruments. In this work we present linear programming and heuristic search\napproaches that produce plans for executing the update. The evaluation of our\nproposals shows cost improvements over the compared based strategy. The models\ncan be easily extended to other realistic scenarios in which a holistic\nportfolio management is required",
            "author": [
                "Tom\u00e1s de la Rosa"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16204v1",
                "http://arxiv.org/pdf/2311.16204v1"
            ],
            "primary_category": "q-fin.PM",
            "category": [
                "q-fin.PM",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15790v1",
            "title": "A Social-aware Gaussian Pre-trained Model for Effective Cold-start\n  Recommendation",
            "updated": "2023-11-27T13:04:33Z",
            "published": "2023-11-27T13:04:33Z",
            "summary": "The use of pre-training is an emerging technique to enhance a neural model's\nperformance, which has been shown to be effective for many neural language\nmodels such as BERT. This technique has also been used to enhance the\nperformance of recommender systems. In such recommender systems, pre-training\nmodels are used to learn a better initialisation for both users and items.\nHowever, recent existing pre-trained recommender systems tend to only\nincorporate the user interaction data at the pre-training stage, making it\ndifficult to deliver good recommendations, especially when the interaction data\nis sparse. To alleviate this common data sparsity issue, we propose to\npre-train the recommendation model not only with the interaction data but also\nwith other available information such as the social relations among users,\nthereby providing the recommender system with a better initialisation compared\nwith solely relying on the user interaction data. We propose a novel\nrecommendation model, the Social-aware Gaussian Pre-trained model (SGP), which\nencodes the user social relations and interaction data at the pre-training\nstage in a Graph Neural Network (GNN). Afterwards, in the subsequent\nfine-tuning stage, our SGP model adopts a Gaussian Mixture Model (GMM) to\nfactorise these pre-trained embeddings for further training, thereby benefiting\nthe cold-start users from these pre-built social relations. Our extensive\nexperiments on three public datasets show that, in comparison to 16 competitive\nbaselines, our SGP model significantly outperforms the best baseline by upto\n7.7% in terms of NDCG@10. In addition, we show that SGP permits to effectively\nalleviate the cold-start problem, especially when users newly register to the\nsystem through their friends' suggestions.",
            "author": [
                "Siwei Liu",
                "Xi Wang",
                "Craig Macdonald",
                "Iadh Ounis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15790v1",
                "http://arxiv.org/pdf/2311.15790v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI",
                "68P20",
                "H.3.3"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15786v2",
            "title": "YUAN 2.0: A Large Language Model with Localized Filtering-based\n  Attention",
            "updated": "2023-12-04T10:20:57Z",
            "published": "2023-11-27T13:01:59Z",
            "summary": "In this work, we develop and release Yuan 2.0, a series of large language\nmodels with parameters ranging from 2.1 billion to 102.6 billion. The Localized\nFiltering-based Attention (LFA) is introduced to incorporate prior knowledge of\nlocal dependencies of natural language into Attention. A data filtering and\ngenerating system is presented to build pre-training and fine-tuning dataset in\nhigh quality. A distributed training method with non-uniform pipeline parallel,\ndata parallel, and optimizer parallel is proposed, which greatly reduces the\nbandwidth requirements of intra-node communication, and achieves good\nperformance in large-scale distributed training. Yuan 2.0 models display\nimpressive ability in code generation, math problem-solving, and chatting\ncompared with existing models. The latest version of YUAN 2.0, including model\nweights and source code, is accessible at Github.",
            "author": [
                "Shaohua Wu",
                "Xudong Zhao",
                "Shenling Wang",
                "Jiangang Luo",
                "Lingjun Li",
                "Xi Chen",
                "Bing Zhao",
                "Wei Wang",
                "Tong Yu",
                "Rongguo Zhang",
                "Jiahua Zhang",
                "Chao Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15786v2",
                "http://arxiv.org/pdf/2311.15786v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16510v1",
            "title": "Source-Free Domain Adaptation with Frozen Multimodal Foundation Model",
            "updated": "2023-11-27T12:58:02Z",
            "published": "2023-11-27T12:58:02Z",
            "summary": "Source-Free Domain Adaptation (SFDA) aims to adapt a source model for a\ntarget domain, with only access to unlabeled target training data and the\nsource model pre-trained on a supervised source domain. Relying on pseudo\nlabeling and/or auxiliary supervision, conventional methods are inevitably\nerror-prone. To mitigate this limitation, in this work we for the first time\nexplore the potentials of off-the-shelf vision-language (ViL) multimodal models\n(e.g.,CLIP) with rich whilst heterogeneous knowledge. We find that directly\napplying the ViL model to the target domain in a zero-shot fashion is\nunsatisfactory, as it is not specialized for this particular task but largely\ngeneric. To make it task specific, we propose a novel Distilling multimodal\nFoundation model(DIFO)approach. Specifically, DIFO alternates between two steps\nduring adaptation: (i) Customizing the ViL model by maximizing the mutual\ninformation with the target model in a prompt learning manner, (ii) Distilling\nthe knowledge of this customized ViL model to the target model. For more\nfine-grained and reliable distillation, we further introduce two effective\nregularization terms, namely most-likely category encouragement and predictive\nconsistency. Extensive experiments show that DIFO significantly outperforms the\nstate-of-the-art alternatives. Our source code will be released.",
            "author": [
                "Song Tang",
                "Wenxin Su",
                "Mao Ye",
                "Xiatian Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16510v1",
                "http://arxiv.org/pdf/2311.16510v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15781v1",
            "title": "Increasing Coverage and Precision of Textual Information in Multilingual\n  Knowledge Graphs",
            "updated": "2023-11-27T12:54:47Z",
            "published": "2023-11-27T12:54:47Z",
            "summary": "Recent work in Natural Language Processing and Computer Vision has been using\ntextual information -- e.g., entity names and descriptions -- available in\nknowledge graphs to ground neural models to high-quality structured data.\nHowever, when it comes to non-English languages, the quantity and quality of\ntextual information are comparatively scarce. To address this issue, we\nintroduce the novel task of automatic Knowledge Graph Enhancement (KGE) and\nperform a thorough investigation on bridging the gap in both the quantity and\nquality of textual information between English and non-English languages. More\nspecifically, we: i) bring to light the problem of increasing multilingual\ncoverage and precision of entity names and descriptions in Wikidata; ii)\ndemonstrate that state-of-the-art methods, namely, Machine Translation (MT),\nWeb Search (WS), and Large Language Models (LLMs), struggle with this task;\niii) present M-NTA, a novel unsupervised approach that combines MT, WS, and\nLLMs to generate high-quality textual information; and, iv) study the impact of\nincreasing multilingual coverage and precision of non-English textual\ninformation in Entity Linking, Knowledge Graph Completion, and Question\nAnswering. As part of our effort towards better multilingual knowledge graphs,\nwe also introduce WikiKGE-10, the first human-curated benchmark to evaluate KGE\napproaches in 10 languages across 7 language families.",
            "author": [
                "Simone Conia",
                "Min Li",
                "Daniel Lee",
                "Umar Farooq Minhas",
                "Ihab Ilyas",
                "Yunyao Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15781v1",
                "http://arxiv.org/pdf/2311.15781v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15780v1",
            "title": "Modular Customizable ROS-Based Framework for Rapid Development of Social\n  Robots",
            "updated": "2023-11-27T12:54:20Z",
            "published": "2023-11-27T12:54:20Z",
            "summary": "Developing socially competent robots requires tight integration of robotics,\ncomputer vision, speech processing, and web technologies. We present the\nSocially-interactive Robot Software platform (SROS), an open-source framework\naddressing this need through a modular layered architecture. SROS bridges the\nRobot Operating System (ROS) layer for mobility with web and Android interface\nlayers using standard messaging and APIs. Specialized perceptual and\ninteractive skills are implemented as ROS services for reusable deployment on\nany robot. This facilitates rapid prototyping of collaborative behaviors that\nsynchronize perception with physical actuation. We experimentally validated\ncore SROS technologies including computer vision, speech processing, and GPT2\nautocomplete speech implemented as plug-and-play ROS services. Modularity is\ndemonstrated through the successful integration of an additional ROS package,\nwithout changes to hardware or software platforms. The capabilities enabled\nconfirm SROS's effectiveness in developing socially interactive robots through\nsynchronized cross-domain interaction. Through demonstrations showing\nsynchronized multimodal behaviors on an example platform, we illustrate how the\nSROS architectural approach addresses shortcomings of previous work by lowering\nbarriers for researchers to advance the state-of-the-art in adaptive,\ncollaborative customizable human-robot systems through novel applications\nintegrating perceptual and social abilities.",
            "author": [
                "Mahta Akhyani",
                "Hadi Moradi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15780v1",
                "http://arxiv.org/pdf/2311.15780v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.SE",
                "cs.SY",
                "eess.IV",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15778v1",
            "title": "Stellar Black Holes and Compact Stellar Remnants",
            "updated": "2023-11-27T12:52:26Z",
            "published": "2023-11-27T12:52:26Z",
            "summary": "The recent observations of gravitational waves (GWs) by the LIGO-Virgo-KAGRA\ncollaboration (LVK) have provided a new opportunity for studying our Universe.\nBy detecting several merging events of black holes (BHs), LVK has spurred the\nastronomical community to improve theoretical models of single, binary, and\nmultiple star evolution in order to better understand the formation of binary\nblack hole (BBH) systems and interpret their observed properties. The final BBH\nsystem configuration before the merger depends on several processes, including\nthose related to the evolution of the inner stellar structure and those due to\nthe interaction with the companion and the environment (such as in stellar\nclusters). This chapter provides a summary of the formation scenarios of\nstellar BHs in single, binary, and multiple systems. We review all the\nimportant physical processes that affect the formation of BHs and discuss the\nmethodologies used to detect these elusive objects and constrain their\nproperties.",
            "author": [
                "Guglielmo Costa",
                "Martyna Chru\u015bli\u0144ska",
                "Jakub Klencki",
                "Floor S. Broekgaarden",
                "Carl L. Rodriguez",
                "Tana D. Joseph",
                "Sara Saracino"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15778v1",
                "http://arxiv.org/pdf/2311.15778v1"
            ],
            "primary_category": "astro-ph.SR",
            "category": [
                "astro-ph.SR",
                "astro-ph.GA",
                "astro-ph.HE",
                "gr-qc"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15777v1",
            "title": "Size-constrained Weighted Ancestors with Applications",
            "updated": "2023-11-27T12:51:59Z",
            "published": "2023-11-27T12:51:59Z",
            "summary": "The weighted ancestor problem on a rooted node-weighted tree $T$ is a\ngeneralization of the classic predecessor problem: construct a data structure\nfor a set of integers that supports fast predecessor queries. Both problems are\nknown to require $\\Omega(\\log\\log n)$ time for queries provided\n$\\mathcal{O}(n\\text{ poly} \\log n)$ space is available, where $n$ is the input\nsize. The weighted ancestor problem has attracted a lot of attention by the\ncombinatorial pattern matching community due to its direct application to\nsuffix trees. In this formulation of the problem, the nodes are weighted by\nstring depth. This attention has culminated in a data structure for weighted\nancestors in suffix trees with $\\mathcal{O}(1)$ query time and an\n$\\mathcal{O}(n)$-time construction algorithm [Belazzougui et al., CPM 2021]. In\nthis paper, we consider a different version of the weighted ancestor problem,\nwhere the nodes are weighted by any function $\\textsf{weight}$ that maps the\nnodes of $T$ to positive integers, such that $\\textsf{weight}(u)\\le\n\\textsf{size}(u)$ for any node $u$ and $\\textsf{weight}(u_1)\\le\n\\textsf{weight}(u_2)$ if node $u_1$ is a descendant of node $u_2$, where\n$\\textsf{size}(u)$ is the number of nodes in the subtree rooted at $u$. In the\nsize-constrained weighted ancestor (SWAQ) problem, for any node $u$ of $T$ and\nany integer $k$, we are asked to return the lowest ancestor $w$ of $u$ with\nweight at least $k$. We show that for any rooted tree with $n$ nodes, we can\nlocate node $w$ in $\\mathcal{O}(1)$ time after $\\mathcal{O}(n)$-time\npreprocessing. In particular, this implies a data structure for the SWAQ\nproblem in suffix trees with $\\mathcal{O}(1)$ query time and\n$\\mathcal{O}(n)$-time preprocessing, when the nodes are weighted by\n$\\textsf{weight}$. We also show several string-processing applications of this\nresult.",
            "author": [
                "Philip Bille",
                "Yakov Nekrich",
                "Solon P. Pissis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15777v1",
                "http://arxiv.org/pdf/2311.15777v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15773v2",
            "title": "Check, Locate, Rectify: A Training-Free Layout Calibration System for\n  Text-to-Image Generation",
            "updated": "2023-11-30T13:14:28Z",
            "published": "2023-11-27T12:48:33Z",
            "summary": "Diffusion models have recently achieved remarkable progress in generating\nrealistic images. However, challenges remain in accurately understanding and\nsynthesizing the layout requirements in the textual prompts. To align the\ngenerated image with layout instructions, we present a training-free layout\ncalibration system SimM that intervenes in the generative process on the fly\nduring inference time. Specifically, following a \"check-locate-rectify\"\npipeline, the system first analyses the prompt to generate the target layout\nand compares it with the intermediate outputs to automatically detect errors.\nThen, by moving the located activations and making intra- and inter-map\nadjustments, the rectification process can be performed with negligible\ncomputational overhead. To evaluate SimM over a range of layout requirements,\nwe present a benchmark SimMBench that compensates for the lack of superlative\nspatial relations in existing datasets. And both quantitative and qualitative\nresults demonstrate the effectiveness of the proposed SimM in calibrating the\nlayout inconsistencies. Our project page is at https://simm-t2i.github.io/SimM.",
            "author": [
                "Biao Gong",
                "Siteng Huang",
                "Yutong Feng",
                "Shiwei Zhang",
                "Yuyuan Li",
                "Yu Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15773v2",
                "http://arxiv.org/pdf/2311.15773v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15772v1",
            "title": "Attend Who is Weak: Enhancing Graph Condensation via Cross-Free\n  Adversarial Training",
            "updated": "2023-11-27T12:44:42Z",
            "published": "2023-11-27T12:44:42Z",
            "summary": "In this paper, we study the \\textit{graph condensation} problem by\ncompressing the large, complex graph into a concise, synthetic representation\nthat preserves the most essential and discriminative information of structure\nand features. We seminally propose the concept of Shock Absorber (a type of\nperturbation) that enhances the robustness and stability of the original graphs\nagainst changes in an adversarial training fashion. Concretely, (I) we forcibly\nmatch the gradients between pre-selected graph neural networks (GNNs) trained\non a synthetic, simplified graph and the original training graph at regularly\nspaced intervals. (II) Before each update synthetic graph point, a Shock\nAbsorber serves as a gradient attacker to maximize the distance between the\nsynthetic dataset and the original graph by selectively perturbing the parts\nthat are underrepresented or insufficiently informative. We iteratively repeat\nthe above two processes (I and II) in an adversarial training fashion to\nmaintain the highly-informative context without losing correlation with the\noriginal dataset. More importantly, our shock absorber and the synthesized\ngraph parallelly share the backward process in a free training manner. Compared\nto the original adversarial training, it introduces almost no additional time\noverhead.\n  We validate our framework across 8 datasets (3 graph and 5 node\nclassification datasets) and achieve prominent results: for example, on Cora,\nCiteseer and Ogbn-Arxiv, we can gain nearly 1.13% to 5.03% improvements compare\nwith SOTA models. Moreover, our algorithm adds only about 0.2% to 2.2%\nadditional time overhead over Flicker, Citeseer and Ogbn-Arxiv. Compared to the\ngeneral adversarial training, our approach improves time efficiency by nearly\n4-fold.",
            "author": [
                "Xinglin Li",
                "Kun Wang",
                "Hanhui Deng",
                "Yuxuan Liang",
                "Di Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15772v1",
                "http://arxiv.org/pdf/2311.15772v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15766v1",
            "title": "Knowledge Unlearning for LLMs: Tasks, Methods, and Challenges",
            "updated": "2023-11-27T12:37:51Z",
            "published": "2023-11-27T12:37:51Z",
            "summary": "In recent years, large language models (LLMs) have spurred a new research\nparadigm in natural language processing. Despite their excellent capability in\nknowledge-based question answering and reasoning, their potential to retain\nfaulty or even harmful knowledge poses risks of malicious application. The\nchallenge of mitigating this issue and transforming these models into purer\nassistants is crucial for their widespread applicability. Unfortunately,\nRetraining LLMs repeatedly to eliminate undesirable knowledge is impractical\ndue to their immense parameters. Knowledge unlearning, derived from analogous\nstudies on machine unlearning, presents a promising avenue to address this\nconcern and is notably advantageous in the context of LLMs. It allows for the\nremoval of harmful knowledge in an efficient manner, without affecting\nunrelated knowledge in the model. To this end, we provide a survey of knowledge\nunlearning in the era of LLMs. Firstly, we formally define the knowledge\nunlearning problem and distinguish it from related works. Subsequently, we\ncategorize existing knowledge unlearning methods into three classes: those\nbased on parameter optimization, parameter merging, and in-context learning,\nand introduce details of these unlearning methods. We further present\nevaluation datasets used in existing methods, and finally conclude this survey\nby presenting the ongoing challenges and future directions.",
            "author": [
                "Nianwen Si",
                "Hao Zhang",
                "Heyu Chang",
                "Wenlin Zhang",
                "Dan Qu",
                "Weiqiang Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15766v1",
                "http://arxiv.org/pdf/2311.15766v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15762v1",
            "title": "Universal fidelity-dissipation relations in quantum gates",
            "updated": "2023-11-27T12:31:52Z",
            "published": "2023-11-27T12:31:52Z",
            "summary": "Accurate quantum computing relies on the precision of quantum gates. However,\nquantum gates in practice are generally affected by dissipative environments,\nwhich can significantly reduce their fidelity. In this Letter, we elucidate\nuniversal relations between the average fidelity of generic quantum gates and\nthe dissipation that occurs during the computing processes. Considering\nscenarios in which a quantum gate is subject to Markovian environments, we\nrigorously derive fidelity-dissipation relations that universally hold for\narbitrary operational times. Intriguingly, when the quantum gate undergoes\nthermal relaxation, the result can be used as a valuable tool for estimating\ndissipation through experimentally measurable fidelity, without requiring\ndetailed knowledge of the dissipative structure. For the case of arbitrary\nenvironments, we uncover a tradeoff relation between the average fidelity and\nenergy dissipation, implying that these quantities cannot be large\nsimultaneously. Our results unveil the computational limitations imposed by\nthermodynamics, shedding light on the profound connection between\nthermodynamics and quantum computing.",
            "author": [
                "Tan Van Vu",
                "Tomotaka Kuwahara",
                "Keiji Saito"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15762v1",
                "http://arxiv.org/pdf/2311.15762v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cond-mat.stat-mech"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15759v1",
            "title": "Towards Vision Enhancing LLMs: Empowering Multimodal Knowledge Storage\n  and Sharing in LLMs",
            "updated": "2023-11-27T12:29:20Z",
            "published": "2023-11-27T12:29:20Z",
            "summary": "Recent advancements in multimodal large language models (MLLMs) have achieved\nsignificant multimodal generation capabilities, akin to GPT-4. These models\npredominantly map visual information into language representation space,\nleveraging the vast knowledge and powerful text generation abilities of LLMs to\nproduce multimodal instruction-following responses. We could term this method\nas LLMs for Vision because of its employing LLMs for visual-language\nunderstanding, yet observe that these MLLMs neglect the potential of harnessing\nvisual knowledge to enhance overall capabilities of LLMs, which could be\nregraded as Vision Enhancing LLMs. In this paper, we propose an approach called\nMKS2, aimed at enhancing LLMs through empowering Multimodal Knowledge Storage\nand Sharing in LLMs. Specifically, we introduce the Modular Visual Memory, a\ncomponent integrated into the internal blocks of LLMs, designed to store\nopen-world visual information efficiently. Additionally, we present a soft\nMixtures-of-Multimodal Experts architecture in LLMs to invoke multimodal\nknowledge collaboration during generation. Our comprehensive experiments\ndemonstrate that MKS2 substantially augments the reasoning capabilities of LLMs\nin contexts necessitating physical or commonsense knowledge. It also delivers\ncompetitive results on multimodal benchmarks.",
            "author": [
                "Yunxin Li",
                "Baotian Hu",
                "Wei Wang",
                "Xiaochun Cao",
                "Min Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15759v1",
                "http://arxiv.org/pdf/2311.15759v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15756v1",
            "title": "Learning Multi-Frequency Partial Correlation Graphs",
            "updated": "2023-11-27T12:22:44Z",
            "published": "2023-11-27T12:22:44Z",
            "summary": "Despite the large research effort devoted to learning dependencies between\ntime series, the state of the art still faces a major limitation: existing\nmethods learn partial correlations but fail to discriminate across distinct\nfrequency bands. Motivated by many applications in which this differentiation\nis pivotal, we overcome this limitation by learning a block-sparse,\nfrequency-dependent, partial correlation graph, in which layers correspond to\ndifferent frequency bands, and partial correlations can occur over just a few\nlayers. To this aim, we formulate and solve two nonconvex learning problems:\nthe first has a closed-form solution and is suitable when there is prior\nknowledge about the number of partial correlations; the second hinges on an\niterative solution based on successive convex approximation, and is effective\nfor the general case where no prior knowledge is available. Numerical results\non synthetic data show that the proposed methods outperform the current state\nof the art. Finally, the analysis of financial time series confirms that\npartial correlations exist only within a few frequency bands, underscoring how\nour methods enable the gaining of valuable insights that would be undetected\nwithout discriminating along the frequency domain.",
            "author": [
                "Gabriele D'Acunto",
                "Paolo Di Lorenzo",
                "Francesco Bonchi",
                "Stefania Sardellitti",
                "Sergio Barbarossa"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15756v1",
                "http://arxiv.org/pdf/2311.15756v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "eess.SP",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15755v2",
            "title": "Persistent hypergraph homology and its applications",
            "updated": "2023-12-02T13:37:01Z",
            "published": "2023-11-27T12:22:00Z",
            "summary": "Persistent homology theory is a relatively new but powerful method in data\nanalysis. Using simplicial complexes, classical persistent homology is able to\nreveal high dimensional geometric structures of datasets, and represent them as\npersistent barcodes. However, many datasets contain complex systems of\nmulti-way interactions, making these datasets more naturally and faithfully\nmodeled by hypergraphs. In this article, we investigate the persistent\nhypergraph model, an important generalization of the classical persistent\nhomology on simplicial complexes. We introduce a new homology, $\\hat{H}$, on\nhypergraphs and an efficient algorithm to compute both persistent barcodes and\n$\\hat{H}$ barcodes. As example, our theory is demonstrated by analyzing\nface-to-face interactions of different populations. The datasets that we select\nconsist of baboons in primate center, people from rural Malawi, scientific\nconference, workplace and high school.",
            "author": [
                "Yaru Gao",
                "Yan Xu",
                "Fengchun Lei"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15755v2",
                "http://arxiv.org/pdf/2311.15755v2"
            ],
            "primary_category": "math.AT",
            "category": [
                "math.AT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15754v1",
            "title": "Graded Jet Geometry",
            "updated": "2023-11-27T12:17:48Z",
            "published": "2023-11-27T12:17:48Z",
            "summary": "Jet manifolds and vector bundles allow one to employ tools of differential\ngeometry to study differential equations, for example those arising as\nequations of motions in physics. They are necessary for a geometrical\nformulation of Lagrangian mechanics and the calculus of variations. It is thus\nonly natural to require their generalization in geometry of $\\mathbb{Z}$-graded\nmanifolds and vector bundles.\n  Our aim is to construct the $k$-th order jet bundle\n$\\mathfrak{J}^{k}_{\\mathcal{E}}$ of an arbitrary $\\mathbb{Z}$-graded vector\nbundle $\\mathcal{E}$ over an arbitrary $\\mathbb{Z}$-graded manifold\n$\\mathcal{M}$. We do so by directly constructing its sheaf of sections, which\nallows one to quickly prove all its usual properties. It turns out that it is\nconvenient to start with the construction of the graded vector bundle of $k$-th\norder (linear) differential operators $\\mathfrak{D}^{k}_{\\mathcal{E}}$ on\n$\\mathcal{E}$. In the process, we discuss (principal) symbol maps and a\nsubclass of differential operators whose symbols correspond to completely\nsymmetric $k$-vector fields, thus finding a graded version of Atiyah Lie\nalgebroid. Necessary rudiments of geometry of $\\mathbb{Z}$-graded vector\nbundles over $\\mathbb{Z}$-graded manifolds are recalled.",
            "author": [
                "Jan Vysoky"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15754v1",
                "http://arxiv.org/pdf/2311.15754v1"
            ],
            "primary_category": "math.DG",
            "category": [
                "math.DG",
                "math-ph",
                "math.MP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15752v1",
            "title": "Insights into Age-Related Functional Brain Changes during Audiovisual\n  Integration Tasks: A Comprehensive EEG Source-Based Analysis",
            "updated": "2023-11-27T12:16:16Z",
            "published": "2023-11-27T12:16:16Z",
            "summary": "The seamless integration of visual and auditory information is a fundamental\naspect of human cognition. Although age-related functional changes in\nAudio-Visual Integration (AVI) have been extensively explored in the past,\nthorough studies across various age groups remain insufficient. Previous\nstudies have provided valuable insights into agerelated AVI using EEG-based\nsensor data. However, these studies have been limited in their ability to\ncapture spatial information related to brain source activation and their\nconnectivity. To address these gaps, our study conducted a comprehensive\naudiovisual integration task with a specific focus on assessing the aging\neffects in various age groups, particularly middle-aged individuals. We\npresented visual, auditory, and audio-visual stimuli and recorded EEG data from\nYoung (18-25 years), Transition (26- 33 years), and Middle (34-42 years) age\ncohort healthy participants. We aimed to understand how aging affects brain\nactivation and functional connectivity among hubs during audio-visual tasks.\nOur findings revealed delayed brain activation in middleaged individuals,\nespecially for bimodal stimuli. The superior temporal cortex and superior\nfrontal gyrus showed significant changes in neuronal activation with aging.\nLower frequency bands (theta and alpha) showed substantial changes with\nincreasing age during AVI. Our findings also revealed that the AVI-associated\nbrain regions can be clustered into five different brain networks using the\nk-means algorithm. Additionally, we observed increased functional connectivity\nin middle age, particularly in the frontal, temporal, and occipital regions.\nThese results highlight the compensatory neural mechanisms involved in aging\nduring cognitive tasks.",
            "author": [
                "Prerna Singh",
                "Ayush Tripathi",
                "Lalan Kumar",
                "Tapan Kumar Gandhi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15752v1",
                "http://arxiv.org/pdf/2311.15752v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15751v1",
            "title": "PyNanospacing: TEM image processing tool for strain analysis and\n  visualization",
            "updated": "2023-11-27T12:08:46Z",
            "published": "2023-11-27T12:08:46Z",
            "summary": "The diverse spectrum of material characteristics including band gap,\nmechanical moduli, color, phonon and electronic density of states, along with\ncatalytic and surface properties are intricately intertwined with the atomic\nstructure and the corresponding interatomic bond-lengths. This interconnection\nextends to the manifestation of interplanar spacings within a crystalline\nlattice. Analysis of these interplanar spacings and the comprehension of any\ndeviations, whether it be lattice compression or expansion, commonly referred\nto as strain, hold paramount significance in unraveling various unknowns within\nthe field. Transmission Electron Microscopy (TEM) is widely used to capture\natomic-scale ordering, facilitating direct investigation of interplanar\nspacings. However, creating critical contour maps for visualizing and\ninterpreting lattice stresses in TEM images remains a challenging task. Here we\ndeveloped a Python code for TEM image processing that can handle a wide range\nof materials including nanoparticles, 2D materials, pure crystals and solid\nsolutions. This algorithm converts local differences in interplanar spacings\ninto contour maps allowing for a visual representation of lattice expansion and\ncompression. The tool is very generic and can significantly aid in analyzing\nmaterial properties using TEM images, allowing for a more in-depth exploration\nof the underlying science behind strain engineering via strain contour maps at\nthe atomic level.",
            "author": [
                "Mehmet Ali Sarsil",
                "Mubashir Mansoor",
                "Mert Saracoglu",
                "Servet Timur",
                "Mustafa Urgen",
                "Onur Ergen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15751v1",
                "http://arxiv.org/pdf/2311.15751v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15747v1",
            "title": "Chaotic Type I Migration in Turbulent Discs",
            "updated": "2023-11-27T12:05:55Z",
            "published": "2023-11-27T12:05:55Z",
            "summary": "By performing global hydrodynamical simulations of accretion discs with\ndriven turbulence models, we demonstrate that elevated levels of turbulence\ninduce highly stochastic migration torques on low-mass companions embedded in\nthese discs. This scenario applies to planets migrating within\ngravito-turbulent regions of protoplanetary discs as well as stars and black\nholes embedded in the outskirts of active galactic nuclei (AGN) accretion\ndiscs. When the turbulence level is low, linear Lindblad torques persists in\nthe background of stochastic forces and its accumulative effect can still\ndominate over relatively long timescales. However, in the presence of very\nstronger turbulence, classical flow patterns around the companion embedded in\nthe disc are disrupted, leading to significant deviations from the expectations\nof classical Type I migration theory over arbitrarily long timescales. Our\nfindings suggest that the stochastic nature of turbulent migration can prevent\nlow-mass companions from monotonically settling into universal migration traps\nwithin the traditional laminar disc framework, thus reducing the frequency of\nthree-body interactions and hierarchical mergers compared to previously\nexpected. We propose a scaling for the transition mass ratio from classical to\nchaotic migration $q\\propto \\alpha_R$, where $\\alpha_R$ is the Reynolds\nviscosity stress parameter, which can be further tested and refined by\nconducting extensive simulations over the relevant parameter space.",
            "author": [
                "Yinhao Wu",
                "Yi-Xian Chen",
                "Douglas N. C. Lin"
            ],
            "link": [
                "http://dx.doi.org/10.1093/mnrasl/slad183",
                "http://arxiv.org/abs/2311.15747v1",
                "http://arxiv.org/pdf/2311.15747v1"
            ],
            "primary_category": "astro-ph.EP",
            "category": [
                "astro-ph.EP",
                "astro-ph.GA",
                "astro-ph.HE",
                "astro-ph.SR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16490v1",
            "title": "SIRAN: Sinkhorn Distance Regularized Adversarial Network for DEM\n  Super-resolution using Discriminative Spatial Self-attention",
            "updated": "2023-11-27T12:03:22Z",
            "published": "2023-11-27T12:03:22Z",
            "summary": "Digital Elevation Model (DEM) is an essential aspect in the remote sensing\ndomain to analyze and explore different applications related to surface\nelevation information. In this study, we intend to address the generation of\nhigh-resolution DEMs using high-resolution multi-spectral (MX) satellite\nimagery by incorporating adversarial learning. To promptly regulate this\nprocess, we utilize the notion of polarized self-attention of discriminator\nspatial maps as well as introduce a Densely connected Multi-Residual Block\n(DMRB) module to assist in efficient gradient flow. Further, we present an\nobjective function related to optimizing Sinkhorn distance with traditional GAN\nto improve the stability of adversarial learning. In this regard, we provide\nboth theoretical and empirical substantiation of better performance in terms of\nvanishing gradient issues and numerical convergence. We demonstrate both\nqualitative and quantitative outcomes with available state-of-the-art methods.\nBased on our experiments on DEM datasets of Shuttle Radar Topographic Mission\n(SRTM) and Cartosat-1, we show that the proposed model performs preferably\nagainst other learning-based state-of-the-art methods. We also generate and\nvisualize several high-resolution DEMs covering terrains with diverse\nsignatures to show the performance of our model.",
            "author": [
                "Subhajit Paul",
                "Ashutosh Gupta"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16490v1",
                "http://arxiv.org/pdf/2311.16490v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15742v1",
            "title": "Testing theories of accretion and gravity with super-extremal Kerr discs",
            "updated": "2023-11-27T11:56:48Z",
            "published": "2023-11-27T11:56:48Z",
            "summary": "Fitting the thermal continuum emission of accreting black holes observed\nacross X-ray bands represents one of the principle means of constraining the\nproperties (mass and spin) of astrophysical black holes. Recent ''continuum\nfitting'' studies of Galactic X-ray binaries in the soft state have found best\nfitting dimensionless spin values which run into the prior bounds placed on\ntraditional models ($a_\\star = 0.9999$). It is of critical importance that\nthese results are robust, and not a result solely of the presence of these\nprior bounds and deficiencies in conventional models of accretion. Motivated by\nthese results we derive and present superkerr, an XSPEC model comprising of a\nthin accretion disc solution valid in the Kerr geometry for arbitrary spin\nparameter $a_\\star$, extending previous models valid only for black holes\n($|a_\\star| < 1$). This extension into ''superextremal'' spacetimes with\n$|a_\\star| > 1$ includes solutions which describe discs evolving around naked\nsingularities, not black holes. While being valid solutions of Einstein's field\nequations these naked singularities are not expected to be present in nature.\nWe discuss how the ''measurement'' of a Kerr spin parameter $1 < a_\\star < 5/3$\nwould present compelling evidence for the requirement of a rethink in either\nstandard accretion theory, or our theories of gravity.",
            "author": [
                "Andrew Mummery",
                "Steven Balbus",
                "Adam Ingram"
            ],
            "link": [
                "http://dx.doi.org/10.1093/mnras/stad3532",
                "http://arxiv.org/abs/2311.15742v1",
                "http://arxiv.org/pdf/2311.15742v1"
            ],
            "primary_category": "gr-qc",
            "category": [
                "gr-qc",
                "astro-ph.HE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15741v1",
            "title": "Machine Learning-Based Jamun Leaf Disease Detection: A Comprehensive\n  Review",
            "updated": "2023-11-27T11:46:30Z",
            "published": "2023-11-27T11:46:30Z",
            "summary": "Jamun leaf diseases pose a significant threat to agricultural productivity,\nnegatively impacting both yield and quality in the jamun industry. The advent\nof machine learning has opened up new avenues for tackling these diseases\neffectively. Early detection and diagnosis are essential for successful crop\nmanagement. While no automated systems have yet been developed specifically for\njamun leaf disease detection, various automated systems have been implemented\nfor similar types of disease detection using image processing techniques. This\npaper presents a comprehensive review of machine learning methodologies\nemployed for diagnosing plant leaf diseases through image classification, which\ncan be adapted for jamun leaf disease detection. It meticulously assesses the\nstrengths and limitations of various Vision Transformer models, including\nTransfer learning model and vision transformer (TLMViT), SLViT, SE-ViT,\nIterationViT, Tiny-LeViT, IEM-ViT, GreenViT, and PMViT. Additionally, the paper\nreviews models such as Dense Convolutional Network (DenseNet), Residual Neural\nNetwork (ResNet)-50V2, EfficientNet, Ensemble model, Convolutional Neural\nNetwork (CNN), and Locally Reversible Transformer. These machine-learning\nmodels have been evaluated on various datasets, demonstrating their real-world\napplicability. This review not only sheds light on current advancements in the\nfield but also provides valuable insights for future research directions in\nmachine learning-based jamun leaf disease detection and classification.",
            "author": [
                "Auvick Chandra Bhowmik",
                "Dr. Md. Taimur Ahad",
                "Yousuf Rayhan Emon"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15741v1",
                "http://arxiv.org/pdf/2311.15741v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15740v1",
            "title": "Optimization of Image Processing Algorithms for Character Recognition in\n  Cultural Typewritten Documents",
            "updated": "2023-11-27T11:44:46Z",
            "published": "2023-11-27T11:44:46Z",
            "summary": "Linked Data is used in various fields as a new way of structuring and\nconnecting data. Cultural heritage institutions have been using linked data to\nimprove archival descriptions and facilitate the discovery of information. Most\narchival records have digital representations of physical artifacts in the form\nof scanned images that are non-machine-readable. Optical Character Recognition\n(OCR) recognizes text in images and translates it into machine-encoded text.\nThis paper evaluates the impact of image processing methods and parameter\ntuning in OCR applied to typewritten cultural heritage documents. The approach\nuses a multi-objective problem formulation to minimize Levenshtein edit\ndistance and maximize the number of words correctly identified with a\nnon-dominated sorting genetic algorithm (NSGA-II) to tune the methods'\nparameters. Evaluation results show that parameterization by digital\nrepresentation typology benefits the performance of image pre-processing\nalgorithms in OCR. Furthermore, our findings suggest that employing image\npre-processing algorithms in OCR might be more suitable for typologies where\nthe text recognition task without pre-processing does not produce good results.\nIn particular, Adaptive Thresholding, Bilateral Filter, and Opening are the\nbest-performing algorithms for the theatre plays' covers, letters, and overall\ndataset, respectively, and should be applied before OCR to improve its\nperformance.",
            "author": [
                "Mariana Dias",
                "Carla Teixeira Lopes"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3606705",
                "http://arxiv.org/abs/2311.15740v1",
                "http://arxiv.org/pdf/2311.15740v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.DL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15737v1",
            "title": "Quasi-optimal Discontinuous Galerkin discretisations of the\n  $p$-Dirichlet problem",
            "updated": "2023-11-27T11:39:43Z",
            "published": "2023-11-27T11:39:43Z",
            "summary": "The classical arguments employed when obtaining error estimates of Finite\nElement (FE) discretisations of elliptic problems lead to more restrictive\nassumptions on the regularity of the exact solution when applied to\nnon-conforming methods. The so-called minimal regularity estimates available in\nthe literature relax some of these assumptions, but are not truly of -minimal\nregularity-, since a data oscillation term appears in the error estimate.\nEmploying an approach based on a smoothing operator, we derive for the first\ntime error estimates for Discontinuous Galerkin (DG) type discretisations of\nnon-linear problems with $(p,\\delta)$-structure that only assume the natural\n$W^{1,p}$-regularity of the exact solution, and which do not contain any\noscillation terms.",
            "author": [
                "J. Blechta",
                "P. A. Gazca-Orozco",
                "A. Kaltenbach",
                "M. R\u016f\u017ei\u010dka"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15737v1",
                "http://arxiv.org/pdf/2311.15737v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA",
                "35J66, 35J92, 65N12, 65N30"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15736v1",
            "title": "SceneDM: Scene-level Multi-agent Trajectory Generation with Consistent\n  Diffusion Models",
            "updated": "2023-11-27T11:39:27Z",
            "published": "2023-11-27T11:39:27Z",
            "summary": "Realistic scene-level multi-agent motion simulations are crucial for\ndeveloping and evaluating self-driving algorithms. However, most existing works\nfocus on generating trajectories for a certain single agent type, and typically\nignore the consistency of generated trajectories. In this paper, we propose a\nnovel framework based on diffusion models, called SceneDM, to generate joint\nand consistent future motions of all the agents, including vehicles, bicycles,\npedestrians, etc., in a scene. To enhance the consistency of the generated\ntrajectories, we resort to a new Transformer-based network to effectively\nhandle agent-agent interactions in the inverse process of motion diffusion. In\nconsideration of the smoothness of agent trajectories, we further design a\nsimple yet effective consistent diffusion approach, to improve the model in\nexploiting short-term temporal dependencies. Furthermore, a scene-level scoring\nfunction is attached to evaluate the safety and road-adherence of the generated\nagent's motions and help filter out unrealistic simulations. Finally, SceneDM\nachieves state-of-the-art results on the Waymo Sim Agents Benchmark. Project\nwebpage is available at https://alperen-hub.github.io/SceneDM.",
            "author": [
                "Zhiming Guo",
                "Xing Gao",
                "Jianlan Zhou",
                "Xinyu Cai",
                "Botian Shi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15736v1",
                "http://arxiv.org/pdf/2311.15736v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15735v1",
            "title": "Model-based reconstructions for quantitative imaging in photoacoustic\n  tomography",
            "updated": "2023-11-27T11:37:27Z",
            "published": "2023-11-27T11:37:27Z",
            "summary": "The reconstruction task in photoacoustic tomography can vary a lot depending\non measured targets, geometry, and especially the quantity we want to recover.\nSpecifically, as the signal is generated due to the coupling of light and sound\nby the photoacoustic effect, we have the possibility to recover acoustic as\nwell as optical tissue parameters. This is referred to as quantitative imaging,\ni.e, correct recovery of physical parameters and not just a qualitative image.\nIn this chapter, we aim to give an overview on established reconstruction\ntechniques in photoacoustic tomography. We start with modelling of the optical\nand acoustic phenomena, necessary for a reliable recovery of quantitative\nvalues. Furthermore, we give an overview of approaches for the tomographic\nreconstruction problem with an emphasis on the recovery of quantitative values,\nfrom direct and fast analytic approaches to computationally involved\noptimisation based techniques and recent data-driven approaches.",
            "author": [
                "Andreas Hauptmann",
                "Tanja Tarvainen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15735v1",
                "http://arxiv.org/pdf/2311.15735v1"
            ],
            "primary_category": "physics.med-ph",
            "category": [
                "physics.med-ph",
                "cs.NA",
                "eess.IV",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15734v2",
            "title": "A Variational Construction of Hamiltonian Stationary Surfaces with\n  Isolated Schoen-Wolfson Conical Singularities",
            "updated": "2023-12-07T16:43:03Z",
            "published": "2023-11-27T11:31:47Z",
            "summary": "We construct using variational methods Hamiltonian Stationary Surfaces with\nIsolated Schoen-Wolfson Conical Singularities. We obtain these surfaces through\na convergence process reminiscent to the Ginzburg-Landau asymptotic analysis in\nthe strongly repulsive regime. We describe in particular how the prescription\nof Schoen Wolfson conical singularities is related to optimal Wente constants.",
            "author": [
                "Filippo Gaia",
                "Gerard Orriols",
                "Tristan Rivi\u00e8re"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15734v2",
                "http://arxiv.org/pdf/2311.15734v2"
            ],
            "primary_category": "math.DG",
            "category": [
                "math.DG",
                "math.AP",
                "53D12, 49Q05, 58E12, 49Q10, 35J50, 35J25, 35J65, 53C42"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15730v1",
            "title": "Analytical Queries: A Comprehensive Survey",
            "updated": "2023-11-27T11:27:38Z",
            "published": "2023-11-27T11:27:38Z",
            "summary": "Modern hardware heterogeneity brings efficiency and performance opportunities\nfor analytical query processing. In the presence of continuous data volume and\ncomplexity growth, bridging the gap between recent hardware advancements and\nthe data processing tools ecosystem is paramount for improving the speed of ETL\nand model development. In this paper, we present a comprehensive overview of\nexisting analytical query processing approaches as well as the use and design\nof systems that use heterogeneous hardware for the task. We then analyze\nstate-of-the-art solutions and identify missing pieces. The last two chapters\ndiscuss the identified problems and present our view on how the ecosystem\nshould evolve.",
            "author": [
                "Petr Kurapov",
                "Areg Melik-Adamyan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15730v1",
                "http://arxiv.org/pdf/2311.15730v1"
            ],
            "primary_category": "cs.DB",
            "category": [
                "cs.DB",
                "cs.DC",
                "cs.PF"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15727v1",
            "title": "MARIS: Referring Image Segmentation via Mutual-Aware Attention Features",
            "updated": "2023-11-27T11:24:25Z",
            "published": "2023-11-27T11:24:25Z",
            "summary": "Referring image segmentation (RIS) aims to segment a particular region based\non a language expression prompt. Existing methods incorporate linguistic\nfeatures into visual features and obtain multi-modal features for mask\ndecoding. However, these methods may segment the visually salient entity\ninstead of the correct referring region, as the multi-modal features are\ndominated by the abundant visual context. In this paper, we propose MARIS, a\nreferring image segmentation method that leverages the Segment Anything Model\n(SAM) and introduces a mutual-aware attention mechanism to enhance the\ncross-modal fusion via two parallel branches. Specifically, our mutual-aware\nattention mechanism consists of Vision-Guided Attention and Language-Guided\nAttention, which bidirectionally model the relationship between visual and\nlinguistic features. Correspondingly, we design a Mask Decoder to enable\nexplicit linguistic guidance for more consistent segmentation with the language\nexpression. To this end, a multi-modal query token is proposed to integrate\nlinguistic information and interact with visual information simultaneously.\nExtensive experiments on three benchmark datasets show that our method\noutperforms the state-of-the-art RIS methods. Our code will be publicly\navailable.",
            "author": [
                "Mengxi Zhang",
                "Yiming Liu",
                "Xiangjun Yin",
                "Huanjing Yue",
                "Jingyu Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15727v1",
                "http://arxiv.org/pdf/2311.15727v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15726v1",
            "title": "Electron correlation mediated site-selective charge compensation in\n  polar/non-polar heterointerface",
            "updated": "2023-11-27T11:20:16Z",
            "published": "2023-11-27T11:20:16Z",
            "summary": "One of the boundary conditions of the classical electromagnetic theory\ndemands continuous electric potential across any boundary, which may not be\nnaturally satisfied in atomically engineered heterostructures. Such polarity\nmismatch in oxide heterointerfaces is compensated through some\n(electronic/chemical/structural) reconstructions, leading to a myriad of\nemergent phenomena. The question we are posing is whether conventional\nsemiconductor band bending framework is sufficient to comprehend compensation\nmechanisms in oxide heterostructures since, unlike semiconductors, complex\noxides host strong electron correlations whose effects are indispensable. To\naddress this, we investigate the interface between a prototypical insulating\ndouble perovskite Nd$_2$NiMnO$_6$ and a wide-bandgap insulator SrTiO$_3$. This\npolar/non-polar interface offers a similar scenario as the famous\nLaAlO$_3$/SrTiO$_3$ system but with an exception - two transition metal sites\nwith two individual correlated energy scales. By combining several experimental\ntechniques and density functional theory, we establish a site-selective charge\ncompensation process that occurs explicitly at the Mn site of the film, leaving\nthe Ni sites inert. This surprising selectivity, which cannot be accounted by\nexisting polar compensation mechanisms, is directly attributed to the TM\ncations' relative correlation energy scales. This discovery presents that\nsite-specific charge compensation can be a designers tool for tailoring\nemergent phenomena in oxide heterostructures.",
            "author": [
                "Nandana Bhattacharya",
                "Arpita Sen",
                "Jianwei Zhang",
                "Ranjan Kumar Patel",
                "Siddharth Kumar",
                "Prithwijit Mandal",
                "Shashank Kumar Ojha",
                "Jyotirmay Maity",
                "Zhan Zhang",
                "Hua Zhou",
                "Fanny Rodolakis",
                "Padraic Shafer",
                "Christoph Klewe",
                "John William Freeland",
                "Zhenzhong Yang",
                "Umesh Waghmare",
                "Srimanta Middey"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15726v1",
                "http://arxiv.org/pdf/2311.15726v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "cond-mat.mes-hall",
                "cond-mat.str-el"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15723v1",
            "title": "Italian Crossword Generator: Enhancing Education through Interactive\n  Word Puzzles",
            "updated": "2023-11-27T11:17:29Z",
            "published": "2023-11-27T11:17:29Z",
            "summary": "Educational crosswords offer numerous benefits for students, including\nincreased engagement, improved understanding, critical thinking, and memory\nretention. Creating high-quality educational crosswords can be challenging, but\nrecent advances in natural language processing and machine learning have made\nit possible to use language models to generate nice wordplays. The exploitation\nof cutting-edge language models like GPT3-DaVinci, GPT3-Curie, GPT3-Babbage,\nGPT3-Ada, and BERT-uncased has led to the development of a comprehensive system\nfor generating and verifying crossword clues. A large dataset of clue-answer\npairs was compiled to fine-tune the models in a supervised manner to generate\noriginal and challenging clues from a given keyword. On the other hand, for\ngenerating crossword clues from a given text, Zero/Few-shot learning techniques\nwere used to extract clues from the input text, adding variety and creativity\nto the puzzles. We employed the fine-tuned model to generate data and labeled\nthe acceptability of clue-answer parts with human supervision. To ensure\nquality, we developed a classifier by fine-tuning existing language models on\nthe labeled dataset. Conversely, to assess the quality of clues generated from\nthe given text using zero/few-shot learning, we employed a zero-shot learning\napproach to check the quality of generated clues. The results of the evaluation\nhave been very promising, demonstrating the effectiveness of the approach in\ncreating high-standard educational crosswords that offer students engaging and\nrewarding learning experiences.",
            "author": [
                "Kamyar Zeinalipour",
                "Tommaso laquinta",
                "Asya Zanollo",
                "Giovanni Angelini",
                "Leonardo Rigutini",
                "Marco Maggini",
                "Marco Gori"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15723v1",
                "http://arxiv.org/pdf/2311.15723v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15716v1",
            "title": "Justifiable Artificial Intelligence: Engineering Large Language Models\n  for Legal Applications",
            "updated": "2023-11-27T10:59:16Z",
            "published": "2023-11-27T10:59:16Z",
            "summary": "In this work, I discuss how Large Language Models can be applied in the legal\ndomain, circumventing their current drawbacks. Despite their large success and\nacceptance, their lack of explainability hinders legal experts to trust in\ntheir output, and this happens rightfully so. However, in this paper, I argue\nin favor of a new view, Justifiable Artificial Intelligence, instead of\nfocusing on Explainable Artificial Intelligence. I discuss in this paper how\ngaining evidence for and against a Large Language Model's output may make their\ngenerated texts more trustworthy - or hold them accountable for misinformation.",
            "author": [
                "Sabine Wehnert"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15716v1",
                "http://arxiv.org/pdf/2311.15716v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.HC",
                "cs.IR",
                "H.4.2; H.3.3; H.5.2"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15711v2",
            "title": "Standard analysis",
            "updated": "2023-12-04T09:17:06Z",
            "published": "2023-11-27T10:57:03Z",
            "summary": "Let $\\mathcal{L}$ be a first-order two-sorted language. Let $S$ be some fixed\nstructure. A standard structure is an $\\mathcal{L}$-structure of the form\n$(M,S)$, where $M$ is arbitrary. When $S$ is a compact topological space (and\n$\\mathcal{L}$ meets a few additional requirements) it is possible to adapt a\nsignificant part of model theory to the restricted class of standard\nstructures. This has been shown by Henson and Iovino for normed spaces and has\nbeen generalized to a larger class of structures in [AAVV]. We further\ngeneralize their approach to a significantly larger class.\n  The starting point is to prove that every standard structure has a positive\nelementary extension that is standard and realizes all positive types that are\nfinitely consistent. A second important step is to prove that (in a\nsufficiently saturated structure) the negation of a positive formula is\nequivalent to to an infinite (but small) disjunction of positive formulas. The\nmain tool is the notion of approximation of a positive formula and of its\nnegation that have been introduced by Henson and Iovino.\n  We review and elaborate on the properties of positive formulas and their\napproximations. In parallel, we introduce continuous formulas which provide a\nbetter counterpart to Henson and Iovino theory of normed spaces and to the\nreal-valued model theory of metric spaces [BBHU]. To demonstrate this setting\nin action we discuss countable categoricity and local stability.",
            "author": [
                "Domenico Zambella"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15711v2",
                "http://arxiv.org/pdf/2311.15711v2"
            ],
            "primary_category": "math.LO",
            "category": [
                "math.LO",
                "03C68, 03C66"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15710v1",
            "title": "A Spectral Method to Compute the Tides of Laterally-Heterogeneous Bodies",
            "updated": "2023-11-27T10:56:52Z",
            "published": "2023-11-27T10:56:52Z",
            "summary": "Body tides reveal information about planetary interiors and affect their\nevolution. Most models to compute body tides rely on the assumption of a\nspherically-symmetric interior. However, several processes can lead to lateral\nvariations of interior properties. We present a new spectral method to compute\nthe tidal response of laterally-heterogeneous bodies. Compared to previous\nspectral methods, our approach is not limited to small-amplitude lateral\nvariations; compared to finite element codes, the approach is more\ncomputationally-efficient. While the tidal response of a spherically-symmetric\nbody has the same wave-length as the tidal force; lateral heterogeneities\nproduce an additional tidal response with an spectra that depends on the\nspatial pattern of such variations. For Mercury, the Moon and Io the amplitude\nof this signal is as high as $1\\%-10\\%$ the main tidal response for\nlong-wavelength shear modulus variations higher than $\\sim 10\\%$ the mean shear\nmodulus. For Europa, Ganymede and Enceladus, shell-thickness variations of\n$50\\%$ the mean shell thickness can cause an additional signal of $\\sim 1\\%$\nand $\\sim 10\\%$ for the Jovian moons and Encelaudus, respectively. Future\nmissions, such as $ \\textit{BepiColombo}$ and $\\textit{JUICE}$, might measure\nthese signals. Lateral variations of viscosity affect the distribution of tidal\nheating. This can drive the thermal evolution of tidally-active bodies and\naffect the distribution of active regions.",
            "author": [
                "Marc Rovira-Navarro",
                "Isamu Matsuyama",
                "Alexander Berne"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15710v1",
                "http://arxiv.org/pdf/2311.15710v1"
            ],
            "primary_category": "astro-ph.EP",
            "category": [
                "astro-ph.EP",
                "physics.geo-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15707v1",
            "title": "SAM-6D: Segment Anything Model Meets Zero-Shot 6D Object Pose Estimation",
            "updated": "2023-11-27T10:50:47Z",
            "published": "2023-11-27T10:50:47Z",
            "summary": "Zero-shot 6D object pose estimation involves the detection of novel objects\nwith their 6D poses in cluttered scenes, presenting significant challenges for\nmodel generalizability. Fortunately, the recent Segment Anything Model (SAM)\nhas showcased remarkable zero-shot transfer performance, which provides a\npromising solution to tackle this task. Motivated by this, we introduce SAM-6D,\na novel framework designed to realize the task through two steps, including\ninstance segmentation and pose estimation. Given the target objects, SAM-6D\nemploys two dedicated sub-networks, namely Instance Segmentation Model (ISM)\nand Pose Estimation Model (PEM), to perform these steps on cluttered RGB-D\nimages. ISM takes SAM as an advanced starting point to generate all possible\nobject proposals and selectively preserves valid ones through meticulously\ncrafted object matching scores in terms of semantics, appearance and geometry.\nBy treating pose estimation as a partial-to-partial point matching problem, PEM\nperforms a two-stage point matching process featuring a novel design of\nbackground tokens to construct dense 3D-3D correspondence, ultimately yielding\nthe pose estimates. Without bells and whistles, SAM-6D outperforms the existing\nmethods on the seven core datasets of the BOP Benchmark for both instance\nsegmentation and pose estimation of novel objects.",
            "author": [
                "Jiehong Lin",
                "Lihua Liu",
                "Dekun Lu",
                "Kui Jia"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15707v1",
                "http://arxiv.org/pdf/2311.15707v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15705v1",
            "title": "On quantum channels that destroy negative conditional entropy",
            "updated": "2023-11-27T10:48:15Z",
            "published": "2023-11-27T10:48:15Z",
            "summary": "Counter-intuitive to classical notions, quantum conditional entropy can be\nnegative, playing a pivotal role in information-processing tasks. This article\ndelves deeply into quantum channels, emphasizing negative conditional entropy\nbreaking channels (NCEB) and introducing negative conditional entropy\nannihilating channels (NCEA). We characterize these channels from both\ntopological and information-theoretic perspectives, examining their properties\nwhen combined serially and in parallel. Our exploration extends to\ncomplimentary channels associated with NCEB, leading to the introduction of\ninformation-leaking channels. Utilizing the parameters of the standard\ndepolarizing channel, we provide tangible examples and further\ncharacterization. We demonstrate the relationship of NCEB and NCEA with newly\nintroduced channels like coherent information breaking (CIB) and mutual\ninformation breaking (MIB), along with standard channels like zero capacity\nchannels. Preservation of quantum resources is an integral constituent of\nquantum information theory. Recognizing this, we lay prescriptions to detect\nchannels that do not break the negativity of conditional entropy, ensuring the\nconservation of this quantum resource.",
            "author": [
                "PV Srinidhi",
                "Indranil Chakrabarty",
                "Samyadeb Bhattacharya",
                "Nirman Ganguly"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15705v1",
                "http://arxiv.org/pdf/2311.15705v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15704v1",
            "title": "Tropical Mathematics and the Lambda Calculus I: Metric and Differential\n  Analysis of Effectful Programs",
            "updated": "2023-11-27T10:43:15Z",
            "published": "2023-11-27T10:43:15Z",
            "summary": "We study the interpretation of the lambda-calculus in a framework based on\ntropical mathematics, and we show that it provides a unifying framework for two\nwell-developed quantitative approaches to program semantics: on the one hand\nprogram metrics, based on the analysis of program sensitivity via Lipschitz\nconditions, on the other hand resource analysis, based on linear logic and\nhigher-order program differentiation. To do that we focus on the semantic\narising from the relational model weighted over the tropical semiring, and we\ndiscuss its application to the study of \"best case\" program behavior for\nlanguages with probabilistic and non-deterministic effects. Finally, we show\nthat a general foundation for this approach is provided by an abstract\ncorrespondence between tropical algebra and Lawvere's theory of generalized\nmetric spaces.",
            "author": [
                "Davide Barbarossa",
                "Paolo Pistone"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15704v1",
                "http://arxiv.org/pdf/2311.15704v1"
            ],
            "primary_category": "cs.LO",
            "category": [
                "cs.LO",
                "cs.PL",
                "math.LO",
                "F.3.2; F.4.1"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15702v1",
            "title": "Retrieving planet formation parameters of WASP-77Ab using SimAb",
            "updated": "2023-11-27T10:41:22Z",
            "published": "2023-11-27T10:41:22Z",
            "summary": "The atmospheric compositions of planets offer a unique view into their\nrespective formation processes. State-of-the-art observatories and techniques\nare finally able to provide high-precision data on atmospheric composition that\ncan be used to constrain planet formation. In this context, we focus on the\nformation of WASP-77Ab based on previous observations of its atmosphere, which\nhave provided precise C/O and metallicity measurements. We use the SimAb planet\nformation simulation to model the formation of WASP-77Ab. We assume two\ncompositions for the disk WASP-77Ab was formed within: one of a solar\ncomposition and one that represents the composition of WASP-77A. In addition,\nwe considered two different scenarios regarding the migration of the planet and\nwe study the possible planet formation paths that reproduce the composition of\nWASP-77Ab. This work shows that the planet is expected to have formed in a disk\nwhere not many planetesimals could be accreted. Moreover, we demonstrate that\nthe most likely migration scenario is disk-free migration, whereby the planet\ninitiates its Type II migration within the CO ice line and ends it beyond the\nwater ice line.",
            "author": [
                "N. Khorshid",
                "M. Min",
                "J. M. D\u00e9sert"
            ],
            "link": [
                "http://dx.doi.org/10.1051/0004-6361/202245469",
                "http://arxiv.org/abs/2311.15702v1",
                "http://arxiv.org/pdf/2311.15702v1"
            ],
            "primary_category": "astro-ph.EP",
            "category": [
                "astro-ph.EP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15701v1",
            "title": "Cyber risk modeling using a two-phase Hawkes process with external\n  excitation",
            "updated": "2023-11-27T10:38:45Z",
            "published": "2023-11-27T10:38:45Z",
            "summary": "With the growing digital transformation of the worldwide economy, cyber risk\nhas become a major issue. As 1 % of the world's GDP (around $1,000 billion) is\nallegedly lost to cybercrime every year, IT systems continue to get\nincreasingly interconnected, making them vulnerable to accumulation phenomena\nthat undermine the pooling mechanism of insurance. As highlighted in the\nliterature, Hawkes processes appear to be suitable models to capture contagion\nphenomena and clustering features of cyber events. This paper extends the\nstandard Hawkes modeling of cyber risk frequency by adding external shocks,\nmodelled by the publication of cyber vulnerabilities that are deemed to\nincrease the likelihood of attacks in the short term. The aim of the proposed\nmodel is to provide a better quantification of contagion effects since, while\nthe standard Hawkes model allocates all the clustering phenomena to\nself-excitation, our model allows to capture the external common factors that\nmay explain part of the systemic pattern. We propose a Hawkes model with two\nkernels, one for the endogenous factor (the contagion from other cyber events)\nand one for the exogenous component (cyber vulnerability publications). We use\nparametric exponential specifications for both the internal and exogenous\nintensity kernels, and we compare different methods to tackle the inference\nproblem based on public datasets containing features of cyber attacks found in\nthe Hackmageddon database and cyber vulnerabilities from the Known Exploited\nVulnerability database and the National Vulnerability Dataset. By refining the\nexternal excitation database selection, the degree of endogeneity of the model\nis nearly halved. We illustrate our model with simulations and discuss the\nimpact of taking into account the external factor driven by vulnerabilities.\nOnce an attack has occurred, response measures are implemented to limit the\neffects of an attack. These measures include patching vulnerabilities and\nreducing the attack's contagion. We use an augmented version of the model by\nadding a second phase modeling a reduction in the contagion pattern from the\nremediation measures. Based on this model, we explore various scenarios and\nquantify the effect of mitigation measures of an insurance company that aims to\nmitigate the effects of a cyber pandemic in its insured portfolio.",
            "author": [
                "Alexandre Boumezoued",
                "Yousra Cherkaoui",
                "Caroline Hillairet"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15701v1",
                "http://arxiv.org/pdf/2311.15701v1"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15698v1",
            "title": "Cerbero-7B: A Leap Forward in Language-Specific LLMs Through Enhanced\n  Chat Corpus Generation and Evaluation",
            "updated": "2023-11-27T10:34:55Z",
            "published": "2023-11-27T10:34:55Z",
            "summary": "This study introduces a novel approach for generating high-quality,\nlanguage-specific chat corpora using a self-chat mechanism. We combine a\ngenerator LLM for creating new samples and an embedder LLM to ensure diversity.\nA new Masked Language Modelling (MLM) model-based quality assessment metric is\nproposed for evaluating and filtering the corpora. Utilizing the llama2-70b as\nthe generator and a multilingual sentence transformer as embedder, we generate\nan Italian chat corpus and refine the Fauno corpus, which is based on\ntranslated English ChatGPT self-chat data. The refinement uses structural\nassertions and Natural Language Processing techniques. Both corpora undergo a\ncomprehensive quality evaluation using the proposed MLM model-based quality\nmetric. The Italian LLM fine-tuned with these corpora demonstrates\nsignificantly enhanced language comprehension and question-answering skills.\nThe resultant model, cerbero-7b, establishes a new state-of-the-art for Italian\nLLMs. This approach marks a substantial advancement in the development of\nlanguage-specific LLMs, with a special emphasis on augmenting corpora for\nunderrepresented languages like Italian.",
            "author": [
                "Federico A. Galatolo",
                "Mario G. C. A. Cimino"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15698v1",
                "http://arxiv.org/pdf/2311.15698v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16494v1",
            "title": "ArGue: Attribute-Guided Prompt Tuning for Vision-Language Models",
            "updated": "2023-11-27T10:34:44Z",
            "published": "2023-11-27T10:34:44Z",
            "summary": "Although soft prompt tuning is effective in efficiently adapting\nVision-Language (V&L) models for downstream tasks, it shows limitations in\ndealing with distribution shifts. We address this issue with Attribute-Guided\nPrompt Tuning (ArGue), making three key contributions. 1) In contrast to the\nconventional approach of directly appending soft prompts preceding class names,\nwe align the model with primitive visual attributes generated by Large Language\nModels (LLMs). We posit that a model's ability to express high confidence in\nthese attributes signifies its capacity to discern the correct class\nrationales. 2) We introduce attribute sampling to eliminate disadvantageous\nattributes, thus only semantically meaningful attributes are preserved. 3) We\npropose negative prompting, explicitly enumerating class-agnostic attributes to\nactivate spurious correlations and encourage the model to generate highly\northogonal probability distributions in relation to these negative features. In\nexperiments, our method significantly outperforms current state-of-the-art\nprompt tuning methods on both novel class prediction and out-of-distribution\ngeneralization tasks.",
            "author": [
                "Xinyu Tian",
                "Shu Zou",
                "Zhaoyuan Yang",
                "Jing Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16494v1",
                "http://arxiv.org/pdf/2311.16494v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15691v1",
            "title": "Automated discovery of trade-off between utility, privacy and fairness\n  in machine learning models",
            "updated": "2023-11-27T10:28:44Z",
            "published": "2023-11-27T10:28:44Z",
            "summary": "Machine learning models are deployed as a central component in decision\nmaking and policy operations with direct impact on individuals' lives. In order\nto act ethically and comply with government regulations, these models need to\nmake fair decisions and protect the users' privacy. However, such requirements\ncan come with decrease in models' performance compared to their potentially\nbiased, privacy-leaking counterparts. Thus the trade-off between fairness,\nprivacy and performance of ML models emerges, and practitioners need a way of\nquantifying this trade-off to enable deployment decisions. In this work we\ninterpret this trade-off as a multi-objective optimization problem, and propose\nPFairDP, a pipeline that uses Bayesian optimization for discovery of\nPareto-optimal points between fairness, privacy and utility of ML models. We\nshow how PFairDP can be used to replicate known results that were achieved\nthrough manual constraint setting process. We further demonstrate effectiveness\nof PFairDP with experiments on multiple models and datasets.",
            "author": [
                "Bogdan Ficiu",
                "Neil D. Lawrence",
                "Andrei Paleyes"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15691v1",
                "http://arxiv.org/pdf/2311.15691v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15689v1",
            "title": "Two Approaches to the Identity of Processes in BFO",
            "updated": "2023-11-27T10:28:06Z",
            "published": "2023-11-27T10:28:06Z",
            "summary": "This paper aims to explore processes and their identity with a focus on the\nupper ontology Basic Formal Ontology (BFO). We begin with a classification\nbased on two basic classes of changes of independent continuants: changes with\nrespect to a single specifically dependent continuant thereof or with respect\nto the spatial region that its parts occupy. We accordingly distinguish two\nkinds of simple processes: specifically dependent continuant changes and\nspatial changes. Next, we investigate a compositional approach to the identity\nof processes: the identity of any process is determined by the identity of the\nsimple processes that compose them. Then, we consider a causal approach to the\nidentity of processes with recourse to a dispositional view of processes\naccording to which any process is a realization of some disposition. We also\nexamine assumptions on which these two approaches to the identity of processes\nare based.",
            "author": [
                "Fumiaki Toyoshima",
                "Adrien Barton"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15689v1",
                "http://arxiv.org/pdf/2311.15689v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15688v1",
            "title": "A Knowledge Graph Approach for Exploratory Search in Research\n  Institutions",
            "updated": "2023-11-27T10:27:26Z",
            "published": "2023-11-27T10:27:26Z",
            "summary": "Over the past decades, research institutions have grown increasingly and\nconsequently also their research output. This poses a significant challenge for\nresearchers seeking to understand the research landscape of an institution. The\nprocess of exploring the research landscape of institutions has a vague\ninformation need, no precise goal, and is open-ended. Current applications are\nnot designed to fulfill the requirements for exploratory search in research\ninstitutions. In this paper, we analyze exploratory search in research\ninstitutions and propose a knowledge graph-based approach to enhance this\nprocess.",
            "author": [
                "Tim Schopf",
                "Nektrios Machner",
                "Florian Matthes"
            ],
            "link": [
                "http://dx.doi.org/10.5220/0012223800003598",
                "http://arxiv.org/abs/2311.15688v1",
                "http://arxiv.org/pdf/2311.15688v1"
            ],
            "primary_category": "cs.DL",
            "category": [
                "cs.DL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15687v1",
            "title": "Auditory cortex and beyond: Deficits in congenital amusia",
            "updated": "2023-11-27T10:27:09Z",
            "published": "2023-11-27T10:27:09Z",
            "summary": "Congenital amusia is a neuro-developmental disorder of music perception and\nproduction, with the observed deficits contrasting with the sophisticated music\nprocessing reported for the general population. Musical deficits within amusia\nhave been hypothesized to arise from altered pitch processing, with impairments\nin pitch discrimination and, notably, short-term memory. We here review\nresearch investigating its behavioral and neural correlates, in particular the\nimpairments at encoding, retention, and recollection of pitch information, as\nwell as how these impairments extend to the processing of pitch cues in speech\nand emotion. The impairments have been related to altered brain responses in a\ndistributed fronto-temporal network, which can be observed also at rest.\nNeuroimaging studies revealed changes in connectivity patterns within this\nnetwork and beyond, shedding light on the brain dynamics underlying auditory\ncognition. Interestingly, some studies revealed spared implicit pitch\nprocessing in congenital amusia, showing the power of implicit cognition in the\nmusic domain. Building on these findings, together with audiovisual integration\nand other beneficial mechanisms, we outline perspectives for training and\nrehabilitation and the future directions of this research domain.",
            "author": [
                "Barbara Tillmann",
                "Jackson Graves",
                "Francesca Talamini",
                "Yohana L\u00e9v\u00eaque",
                "Lesly Fornoni",
                "Caliani Hoarau",
                "Agathe Pralus",
                "J\u00e9r\u00e9mie Ginzburg",
                "Philippe Albouy",
                "Anne Caclin"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.heares.2023.108855",
                "http://arxiv.org/abs/2311.15687v1",
                "http://arxiv.org/pdf/2311.15687v1"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15685v1",
            "title": "The Battleship Approach to the Low Resource Entity Matching Problem",
            "updated": "2023-11-27T10:18:17Z",
            "published": "2023-11-27T10:18:17Z",
            "summary": "Entity matching, a core data integration problem, is the task of deciding\nwhether two data tuples refer to the same real-world entity. Recent advances in\ndeep learning methods, using pre-trained language models, were proposed for\nresolving entity matching. Although demonstrating unprecedented results, these\nsolutions suffer from a major drawback as they require large amounts of labeled\ndata for training, and, as such, are inadequate to be applied to low resource\nentity matching problems. To overcome the challenge of obtaining sufficient\nlabeled data we offer a new active learning approach, focusing on a selection\nmechanism that exploits unique properties of entity matching. We argue that a\ndistributed representation of a tuple pair indicates its informativeness when\nconsidered among other pairs. This is used consequently in our approach that\niteratively utilizes space-aware considerations. Bringing it all together, we\ntreat the low resource entity matching problem as a Battleship game, hunting\nindicative samples, focusing on positive ones, through awareness of the latent\nspace along with careful planning of next sampling iterations. An extensive\nexperimental analysis shows that the proposed algorithm outperforms\nstate-of-the-art active learning solutions to low resource entity matching, and\nalthough using less samples, can be as successful as state-of-the-art fully\ntrained known algorithms.",
            "author": [
                "Bar Genossar",
                "Avigdor Gal",
                "Roee Shraga"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3626711",
                "http://arxiv.org/abs/2311.15685v1",
                "http://arxiv.org/pdf/2311.15685v1"
            ],
            "primary_category": "cs.DB",
            "category": [
                "cs.DB",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15684v1",
            "title": "Current and shot noise in a spin dependent driven normal metal -- BCS\n  superconductor junction",
            "updated": "2023-11-27T10:17:17Z",
            "published": "2023-11-27T10:17:17Z",
            "summary": "Andreev reflection is a fundamental transport process occurring at the\njunction between a normal metal and a superconductor (a N-S junction), when an\nincident electron from the normal side can only be transmitted in the\nsuperconductor as a Cooper pair, with the reflection of a hole in the normal\nmetal. As a consequence of the spin singlet nature of the BCS Cooper pairs, the\ncurrent due to Andreev reflection at a N-S junction is always symmetric in\nspin. Using a Keldysh Nambu Floquet approach, combining analytical and\nnumerical calculations, we study in details the AC transport at a N-S junction,\nwhen the two spin components in the normal metal are driven by different\nperiodic drives. We show that, in the Andreev regime, i.e. when the\nsuperconducting gap is much larger than the frequency of the drives, the\nspin-resolved photo-assisted currents are always equal even if the two drives\nare different. In addition, we show that in this regime the excess noise\ndepends only on the sum of the periodic drives, and we consider in particular\nthe case of Lorentzian pulses (Levitons). We also show how these properties get\nmodified when going beyond the Andreev regime. Finally we give a simple\nanalytical proof of the special properties of the Andreev regime using an exact\nmapping to a particular N-N junction.",
            "author": [
                "Bruno Bertin-Johannet",
                "Beno\u00eet Gr\u00e9maud",
                "Flavio Ronneti",
                "Laurent Raymond",
                "J\u00e9r\u00f4me Rech",
                "Thibaut Jonckheere",
                "Thierry Martin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15684v1",
                "http://arxiv.org/pdf/2311.15684v1"
            ],
            "primary_category": "cond-mat.supr-con",
            "category": [
                "cond-mat.supr-con",
                "cond-mat.mes-hall",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15683v2",
            "title": "Ultrasensitive Textile Strain Sensors Redefine Wearable Silent Speech\n  Interfaces with High Machine Learning Efficiency",
            "updated": "2023-12-07T09:16:20Z",
            "published": "2023-11-27T10:17:00Z",
            "summary": "Our research presents a wearable Silent Speech Interface (SSI) technology\nthat excels in device comfort, time-energy efficiency, and speech decoding\naccuracy for real-world use. We developed a biocompatible, durable textile\nchoker with an embedded graphene-based strain sensor, capable of accurately\ndetecting subtle throat movements. This sensor, surpassing other strain sensors\nin sensitivity by 420%, simplifies signal processing compared to traditional\nvoice recognition methods. Our system uses a computationally efficient neural\nnetwork, specifically a one-dimensional convolutional neural network with\nresidual structures, to decode speech signals. This network is energy and\ntime-efficient, reducing computational load by 90% while achieving 95.25%\naccuracy for a 20-word lexicon and swiftly adapting to new users and words with\nminimal samples. This innovation demonstrates a practical, sensitive, and\nprecise wearable SSI suitable for daily communication applications.",
            "author": [
                "Chenyu Tang",
                "Muzi Xu",
                "Wentian Yi",
                "Zibo Zhang",
                "Edoardo Occhipinti",
                "Chaoqun Dong",
                "Dafydd Ravenscroft",
                "Sung-Min Jung",
                "Sanghyo Lee",
                "Shuo Gao",
                "Jong Min Kim",
                "Luigi G. Occhipinti"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15683v2",
                "http://arxiv.org/pdf/2311.15683v2"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.SD",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15681v1",
            "title": "Bounds on ALP-Mediated Dark Matter Models from Celestial Objects",
            "updated": "2023-11-27T10:14:54Z",
            "published": "2023-11-27T10:14:54Z",
            "summary": "We have studied the signals from axion-like particles (ALPs) as dark matter\nmediators from celestial objects such as neutron stars or brown dwarfs. We\nconsider the accumulation of dark matter inside the celestial objects using the\nmultiscatter capturing process. The production of ALP from the dark matter\nannihilation can escape the celestial object and decay into gamma-ray and\nneutrinos before reaching the Earth. We investigate our model using gamma-ray\nobservations from Fermi and H.E.S.S and neutrino observations from IceCube and\nANTARES. The effective Lagrangian approach allows us to place constraints on\nthe ALP-photon and ALP-fermion couplings. In the gamma-ray channel, our results\nimprove the existing bounds on ALPs by 1-2 orders of magnitude. Although the\nconstraints from neutrino fluxes rule out a significant portion of the\nparameter space, the remaining part of the parameter space is accessible by\nfuture experiments.",
            "author": [
                "Tanech Klangburam",
                "Chakrit Pongkitivanichkul"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15681v1",
                "http://arxiv.org/pdf/2311.15681v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "astro-ph.HE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15676v1",
            "title": "Mixing model of Phobos' bulk elemental composition for the determination\n  of its origin: Multivariate analysis of MMX/MEGANE data",
            "updated": "2023-11-27T10:04:01Z",
            "published": "2023-11-27T10:04:01Z",
            "summary": "The formation process of the two Martian moons, Phobos and Deimos, is still\ndebated with two main competing hypotheses: the capture of an asteroid or a\ngiant impact onto Mars. In order to reveal their origin, the Martian Moons\neXploration (MMX) mission by Japan Aerospace Exploration Agency (JAXA) plans to\nmeasure Phobos' elemental composition by a gamma-ray and neutron spectrometer\ncalled MEGANE. This study provides a model of Phobos' bulk elemental\ncomposition, assuming the two formation hypotheses. Using the mixing model, we\nestablished a MEGANE data analysis flow to discriminate between the formation\nhypotheses by multivariate analysis. The mixing model expresses the composition\nof Phobos in 6 key lithophile elements that will be measured by MEGANE (Fe, Si,\nO, Ca, Mg, and Th) as a linear mixing of two mixing components: material from\nMars and material from an asteroid as represented by primitive meteorite\ncompositions. The inversion calculation includes consideration of MEGANE's\nmeasurement errors ($E_P$) and derives the mixing ratio for a given Phobos\ncomposition, based on which the formation hypotheses are judged. For at least\n65\\% of the modeled compositions, MEGANE measurements will determine the origin\nuniquely ($E_P$ = 30\\%), and this increases from 74 to 87\\% as $E_P$ decreases\nfrom 20 to 10\\%. Although the discrimination performance depends on $E_P$, the\ncurrent operation plan for MEGANE predicts an instrument performance for $E_P$\nof 20--30\\%, resulting in ~70\\% discrimination between the original hypotheses.\nMEGANE observations can also enable the determination of the asteroid type of\nthe captured body or the impactor. The addition of other measurements, such as\nMEGANE's measurements of the volatile element K, as well as observations by\nother MMX remote sensing instruments, will also contribute to the MMX mission's\ngoal to constrain the origin of Phobos.",
            "author": [
                "Kaori Hirata",
                "Tomohiro Usui",
                "Ryuki Hyodo",
                "Hidenori Genda",
                "Ryota Fukai",
                "David J. Lawrence",
                "Nancy L. Chabot",
                "Patrick N. Peplowski",
                "Hiroki Kusano"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.icarus.2023.115891",
                "http://arxiv.org/abs/2311.15676v1",
                "http://arxiv.org/pdf/2311.15676v1"
            ],
            "primary_category": "astro-ph.EP",
            "category": [
                "astro-ph.EP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15675v1",
            "title": "The Complexity of Second-order HyperLTL",
            "updated": "2023-11-27T10:03:40Z",
            "published": "2023-11-27T10:03:40Z",
            "summary": "We determine the complexity of second-order HyperLTL satisfiability and\nmodel-checking: Both are as hard as truth in third-order arithmetic.",
            "author": [
                "Martin Zimmermann"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15675v1",
                "http://arxiv.org/pdf/2311.15675v1"
            ],
            "primary_category": "cs.LO",
            "category": [
                "cs.LO",
                "cs.FL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15674v1",
            "title": "MOT-DETR: 3D Single Shot Detection and Tracking with Transformers to\n  build 3D representations for Agro-Food Robots",
            "updated": "2023-11-27T10:03:01Z",
            "published": "2023-11-27T10:03:01Z",
            "summary": "In the current demand for automation in the agro-food industry, accurately\ndetecting and localizing relevant objects in 3D is essential for successful\nrobotic operations. However, this is a challenge due the presence of\nocclusions. Multi-view perception approaches allow robots to overcome\nocclusions, but a tracking component is needed to associate the objects\ndetected by the robot over multiple viewpoints. Most multi-object tracking\n(MOT) algorithms are designed for high frame rate sequences and struggle with\nthe occlusions generated by robots' motions and 3D environments. In this paper,\nwe introduce MOT-DETR, a novel approach to detect and track objects in 3D over\ntime using a combination of convolutional networks and transformers. Our method\nprocesses 2D and 3D data, and employs a transformer architecture to perform\ndata fusion. We show that MOT-DETR outperforms state-of-the-art multi-object\ntracking methods. Furthermore, we prove that MOT-DETR can leverage 3D data to\ndeal with long-term occlusions and large frame-to-frame distances better than\nstate-of-the-art methods. Finally, we show how our method is resilient to\ncamera pose noise that can affect the accuracy of point clouds. The\nimplementation of MOT-DETR can be found here:\nhttps://github.com/drapado/mot-detr",
            "author": [
                "David Rapado-Rincon",
                "Henk Nap",
                "Katarina Smolenova",
                "Eldert J. van Henten",
                "Gert Kootstra"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15674v1",
                "http://arxiv.org/pdf/2311.15674v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15671v1",
            "title": "The generalized Vaidya spacetime with polytropic equation of state",
            "updated": "2023-11-27T10:01:00Z",
            "published": "2023-11-27T10:01:00Z",
            "summary": "The process of the gravitational collapse might lead not only to a black hole\nbut also to naked singularity formation. In this paper, we consider the\ngeneralized Vaidya spacetime with polytropic and generalized polytropic\nequations of state. We solve the Einstein and Einstein-Maxwell equations to\nobtain the explicit form of a mass function. The process of the gravitational\ncollapse has been then considered. We have found out that the conditions of the\nnaked singularity formation don't depend on the polytropic index.",
            "author": [
                "Vitalii Vertogradov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15671v1",
                "http://arxiv.org/pdf/2311.15671v1"
            ],
            "primary_category": "gr-qc",
            "category": [
                "gr-qc"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15662v1",
            "title": "The basement membrane in epidermal polarity, stemness, and regeneration",
            "updated": "2023-11-27T09:48:24Z",
            "published": "2023-11-27T09:48:24Z",
            "summary": "The epidermis is a specialized epithelium that constitutes the outermost\nlayer of the skin, and it provides a protective barrier against environmental\nassaults. Primarily consisting of multilayered keratinocytes, the epidermis is\ncontinuously renewed by proliferation of stem cells and the differentiation of\ntheir progeny, which undergo terminal differentiation as they leave the basal\nlayer and move upward toward the surface, where they die and slough off. Basal\nkeratinocytes rest on a basement membrane at the dermal-epidermal junction that\nis composed of specific extracellular matrix proteins organized into\ninteractive and mechanically supportive networks. Firm attachment of basal\nkeratinocytes, and their dynamic regulation via focal adhesions and\nhemidesmosomes, is essential for maintaining major skin processes, such as\nself-renewal, barrier function, and resistance to physical and chemical\nstresses. The adhesive integrin receptors expressed by epidermal cells serve\nstructural, signaling, and mechanosensory roles that are critical for epidermal\ncell anchorage and tissue homeostasis. More specifically, the basement membrane\ncomponents play key roles in preserving the stem cell pool, and establishing\ncell polarity cues enabling asymmetric cell divisions, which result in the\ntransition from a proliferative basal cell layer to suprabasal cells committed\nto terminal differentiation. Finally, through a well-regulated sequence of\nsynthesis and remodeling, the components of the dermal-epidermal junction play\nan essential role in regeneration of the epidermis during skin healing. Here\ntoo, they provide biological and mechanical signals that are essential to the\nrestoration of barrier function.",
            "author": [
                "Patricia Rousselle",
                "Chlo\u00e9 Laigle",
                "Gaelle Rousselet"
            ],
            "link": [
                "http://dx.doi.org/10.1152/ajpcell.00069.2022",
                "http://arxiv.org/abs/2311.15662v1",
                "http://arxiv.org/pdf/2311.15662v1"
            ],
            "primary_category": "q-bio.BM",
            "category": [
                "q-bio.BM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15658v1",
            "title": "Regularization by Texts for Latent Diffusion Inverse Solvers",
            "updated": "2023-11-27T09:40:14Z",
            "published": "2023-11-27T09:40:14Z",
            "summary": "The recent advent of diffusion models has led to significant progress in\nsolving inverse problems, leveraging these models as effective generative\npriors. Nonetheless, challenges related to the ill-posed nature of such\nproblems remain, often due to inherent ambiguities in measurements. Drawing\ninspiration from the human ability to resolve visual ambiguities through\nperceptual biases, here we introduce a novel latent diffusion inverse solver by\nincorporating regularization by texts (TReg). Specifically, TReg applies the\ntextual description of the preconception of the solution during the reverse\nsampling phase, of which description isndynamically reinforced through\nnull-text optimization for adaptive negation. Our comprehensive experimental\nresults demonstrate that TReg successfully mitigates ambiguity in latent\ndiffusion inverse solvers, enhancing their effectiveness and accuracy.",
            "author": [
                "Jeongsol Kim",
                "Geon Yeong Park",
                "Hyungjin Chung",
                "Jong Chul Ye"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15658v1",
                "http://arxiv.org/pdf/2311.15658v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15653v1",
            "title": "MoDS: Model-oriented Data Selection for Instruction Tuning",
            "updated": "2023-11-27T09:33:13Z",
            "published": "2023-11-27T09:33:13Z",
            "summary": "Instruction tuning has become the de facto method to equip large language\nmodels (LLMs) with the ability of following user instructions. Usually,\nhundreds of thousands or millions of instruction-following pairs are employed\nto fine-tune the foundation LLMs. Recently, some studies show that a small\nnumber of high-quality instruction data is enough. However, how to select\nappropriate instruction data for a given LLM is still an open problem. To\naddress this problem, in this paper we present a model-oriented data selection\n(MoDS) approach, which selects instruction data based on a new criteria\nconsidering three aspects: quality, coverage and necessity. First, our approach\nutilizes a quality evaluation model to filter out the high-quality subset from\nthe original instruction dataset, and then designs an algorithm to further\nselect from the high-quality subset a seed instruction dataset with good\ncoverage. The seed dataset is applied to fine-tune the foundation LLM to obtain\nan initial instruction-following LLM. Finally, we develop a necessity\nevaluation model to find out the instruction data which are performed badly in\nthe initial instruction-following LLM and consider them necessary instructions\nto further improve the LLMs. In this way, we can get a small high-quality,\nbroad-coverage and high-necessity subset from the original instruction\ndatasets. Experimental results show that, the model fine-tuned with 4,000\ninstruction pairs selected by our approach could perform better than the model\nfine-tuned with the full original dataset which includes 214k instruction data.",
            "author": [
                "Qianlong Du",
                "Chengqing Zong",
                "Jiajun Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15653v1",
                "http://arxiv.org/pdf/2311.15653v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16479v1",
            "title": "Mitigating Hallucination in Visual Language Models with Visual\n  Supervision",
            "updated": "2023-11-27T09:30:02Z",
            "published": "2023-11-27T09:30:02Z",
            "summary": "Large vision-language models (LVLMs) suffer from hallucination a lot,\ngenerating responses that apparently contradict to the image content\noccasionally. The key problem lies in its weak ability to comprehend detailed\ncontent in a multi-modal context, which can be mainly attributed to two factors\nin training data and loss function. The vision instruction dataset primarily\nfocuses on global description, and the auto-regressive loss function favors\ntext modeling rather than image understanding. In this paper, we bring more\ndetailed vision annotations and more discriminative vision models to facilitate\nthe training of LVLMs, so that they can generate more precise responses without\nencounter hallucination. On one hand, we generate image-text pairs with\ndetailed relationship annotations in panoptic scene graph dataset (PSG). These\nconversations pay more attention on detailed facts in the image, encouraging\nthe model to answer questions based on multi-modal contexts. On the other hand,\nwe integrate SAM and mask prediction loss as auxiliary supervision, forcing the\nLVLMs to have the capacity to identify context-related objects, so that they\ncan generate more accurate responses, mitigating hallucination. Moreover, to\nprovide a deeper evaluation on the hallucination in LVLMs, we propose a new\nbenchmark, RAH-Bench. It divides vision hallucination into three different\ntypes that contradicts the image with wrong categories, attributes or\nrelations, and introduces False Positive Rate as detailed sub-metric for each\ntype. In this benchmark, our approach demonstrates an +8.4% enhancement\ncompared to original LLaVA and achieves widespread performance improvements\nacross other models.",
            "author": [
                "Zhiyang Chen",
                "Yousong Zhu",
                "Yufei Zhan",
                "Zhaowen Li",
                "Chaoyang Zhao",
                "Jinqiao Wang",
                "Ming Tang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16479v1",
                "http://arxiv.org/pdf/2311.16479v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15651v2",
            "title": "Propagating front solutions in a time-fractional Fisher-KPP equation",
            "updated": "2023-12-07T01:49:48Z",
            "published": "2023-11-27T09:26:07Z",
            "summary": "In this paper, we treat the Fisher-KPP equation with a Caputo-type time\nfractional derivative and discuss the propagation speed of the solution. The\nequation is a mathematical model that describes the processes of sub-diffusion,\nproliferation, and saturation. First, the behavior of the solution is analyzed\nby numerical simulations, and it is discussed what kind of solution is\nappropriate to characterize the propagation of the solution. Based on the\ninsights, we introduce the notion of a traveling wave-like solution, the\nso-called asymptotic traveling wave solution. Finally, the existence of the\nasymptotic traveling wave solution is discussed using a monotone iteration\nmethod.",
            "author": [
                "Hiroshi Ishii"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15651v2",
                "http://arxiv.org/pdf/2311.15651v2"
            ],
            "primary_category": "math.AP",
            "category": [
                "math.AP",
                "35R11, 35B40, 35C07"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15650v1",
            "title": "SimSIMS: Simulation-based Supernova Ia Model Selection with thousands of\n  latent variables",
            "updated": "2023-11-27T09:22:39Z",
            "published": "2023-11-27T09:22:39Z",
            "summary": "We present principled Bayesian model comparison through simulation-based\nneural classification applied to SN Ia analysis. We validate our approach on\nrealistically simulated SN Ia light curve data, demonstrating its ability to\nrecover posterior model probabilities while marginalizing over >4000 latent\nvariables. The amortized nature of our technique allows us to explore the\ndependence of Bayes factors on the true parameters of simulated data,\ndemonstrating Occam's razor for nested models. When applied to a sample of 86\nlow-redshift SNae Ia from the Carnegie Supernova Project, our method prefers a\nmodel with a single dust law and no magnitude step with host mass, disfavouring\ndifferent dust laws for low- and high-mass hosts with odds in excess of 100:1.",
            "author": [
                "Konstantin Karchev",
                "Roberto Trotta",
                "Christoph Weniger"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15650v1",
                "http://arxiv.org/pdf/2311.15650v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO",
                "astro-ph.IM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15649v1",
            "title": "RoboGPT: an intelligent agent of making embodied long-term decisions for\n  daily instruction tasks",
            "updated": "2023-11-27T09:20:23Z",
            "published": "2023-11-27T09:20:23Z",
            "summary": "Robotic agents must master common sense and long-term sequential decisions to\nsolve daily tasks through natural language instruction. The developments in\nLarge Language Models (LLMs) in natural language processing have inspired\nefforts to use LLMs in complex robot planning. Despite LLMs' great\ngeneralization and comprehension of instruction tasks, LLMs-generated task\nplans sometimes lack feasibility and correctness. To address the problem, we\npropose a RoboGPT agent\\footnote{our code and dataset will be released soon}\nfor making embodied long-term decisions for daily tasks, with two modules: 1)\nLLMs-based planning with re-plan to break the task into multiple sub-goals; 2)\nRoboSkill individually designed for sub-goals to learn better navigation and\nmanipulation skills. The LLMs-based planning is enhanced with a new robotic\ndataset and re-plan, called RoboGPT. The new robotic dataset of 67k daily\ninstruction tasks is gathered for fine-tuning the Llama model and obtaining\nRoboGPT. RoboGPT planner with strong generalization can plan hundreds of daily\ninstruction tasks. Additionally, a low-computational Re-Plan module is designed\nto allow plans to flexibly adapt to the environment, thereby addressing the\nnomenclature diversity challenge. The proposed RoboGPT agent outperforms SOTA\nmethods on the ALFRED daily tasks. Moreover, RoboGPT planner exceeds SOTA\nLLM-based planners like ChatGPT in task-planning rationality for hundreds of\nunseen daily tasks, and even other domain tasks, while keeping the large\nmodel's original broad application and generality.",
            "author": [
                "Yaran Chen",
                "Wenbo Cui",
                "Yuanwen Chen",
                "Mining Tan",
                "Xinyao Zhang",
                "Dongbin Zhao",
                "He Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15649v1",
                "http://arxiv.org/pdf/2311.15649v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15648v1",
            "title": "Reinforcement Learning from Diffusion Feedback: Q* for Image Search",
            "updated": "2023-11-27T09:20:12Z",
            "published": "2023-11-27T09:20:12Z",
            "summary": "Large vision-language models are steadily gaining personalization\ncapabilities at the cost of fine-tuning or data augmentation. We present two\nmodels for image generation using model-agnostic learning that align semantic\npriors with generative capabilities. RLDF, or Reinforcement Learning from\nDiffusion Feedback, is a singular approach for visual imitation through\nprior-preserving reward function guidance. This employs Q-learning (with\nstandard Q*) for generation and follows a semantic-rewarded trajectory for\nimage search through finite encoding-tailored actions. The second proposed\nmethod, noisy diffusion gradient, is optimization driven. At the root of both\nmethods is a special CFG encoding that we propose for continual semantic\nguidance. Using only a single input image and no text input, RLDF generates\nhigh-quality images over varied domains including retail, sports and\nagriculture showcasing class-consistency and strong visual diversity. Project\nwebsite is available at https://infernolia.github.io/RLDF.",
            "author": [
                "Aboli Marathe"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15648v1",
                "http://arxiv.org/pdf/2311.15648v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL",
                "cs.LG",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15642v1",
            "title": "InfoPattern: Unveiling Information Propagation Patterns in Social Media",
            "updated": "2023-11-27T09:12:35Z",
            "published": "2023-11-27T09:12:35Z",
            "summary": "Social media play a significant role in shaping public opinion and\ninfluencing ideological communities through information propagation. Our demo\nInfoPattern centers on the interplay between language and human ideology. The\ndemo (Code: https://github.com/blender-nlp/InfoPattern ) is capable of: (1) red\nteaming to simulate adversary responses from opposite ideology communities; (2)\nstance detection to identify the underlying political sentiments in each\nmessage; (3) information propagation graph discovery to reveal the evolution of\nclaims across various communities over time. (Live Demo:\nhttps://incas.csl.illinois.edu/blender/About )",
            "author": [
                "Chi Han",
                "Jialiang Xu",
                "Manling Li",
                "Hanning Zhang",
                "Tarek Abdelzaher",
                "Heng Ji"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15642v1",
                "http://arxiv.org/pdf/2311.15642v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15641v1",
            "title": "A generalized nonstandard finite difference method for a class of\n  autonomous dynamical systems and its applications",
            "updated": "2023-11-27T09:10:59Z",
            "published": "2023-11-27T09:10:59Z",
            "summary": "In this work, a class of continuous-time autonomous dynamical systems\ndescribing many important phenomena and processes arising in real-world\napplications is considered. We apply the nonstandard finite difference (NSFD)\nmethodology proposed by Mickens to design a generalized NSFD method for the\ndynamical system models under consideration. This method is constructed based\non a novel non-local approximation for the right-side functions of the\ndynamical systems. It is proved by rigorous mathematical analyses that the NSFD\nmethod is dynamically consistent with respect to positivity, asymptotic\nstability and three classes of conservation laws, including direct\nconservation, generalized conservation and sub-conservation laws. Furthermore,\nthe NSFD method is easy to be implemented and can be applied to solve a broad\nrange of mathematical models arising in real-life. Finally, a set of numerical\nexperiments is performed to illustrate the theoretical findings and to show\nadvantages of the proposed NSFD method.",
            "author": [
                "Manh Tuan Hoang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15641v1",
                "http://arxiv.org/pdf/2311.15641v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA",
                "math.CA",
                "math.DS",
                "34A45, 65L05"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15639v1",
            "title": "Almost Logarithmic Approximation for Cutwidth and Pathwidth",
            "updated": "2023-11-27T09:09:53Z",
            "published": "2023-11-27T09:09:53Z",
            "summary": "We study several graph layout problems with a min max objective. Here, given\na graph we wish to find a linear ordering of the vertices that minimizes some\nworst case objective over the natural cuts in the ordering; which separate an\ninitial segment of the vertices from the rest. A prototypical problem here is\ncutwidth, where we want to minimize the maximum number of edges crossing a cut.\nThe only known algorithm here is by [Leighton-Rao J.ACM 99] based on\nrecursively partitioning the graph using balanced cuts. This achieves an\n$O(\\log^{3/2}{n})$ approximation using the $ O(\\log^{1/2}{n})$ approximation of\n[Arora-Rao-Vazirani J.ACM 09] for balanced cuts.\n  We depart from the above approach and give an improved $ O(\\log^{1+o(1)}{n})$\napproximation for cutwidth. Our approach also gives a similarly improved $\nO(\\log^{1+o(1)}{n})$ approximation for finding the pathwidth of a graph.\nPreviously, the best known approximation for pathwidth was $O(\\log^{3/2}{n})$.",
            "author": [
                "Nikhil Bansal",
                "Dor Katzelnick",
                "Roy Schwartz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15639v1",
                "http://arxiv.org/pdf/2311.15639v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.00048v1",
            "title": "Tokenized Model: A Blockchain-Empowered Decentralized Model Ownership\n  Verification Platform",
            "updated": "2023-11-27T09:02:57Z",
            "published": "2023-11-27T09:02:57Z",
            "summary": "With the development of practical deep learning models like generative AI,\ntheir excellent performance has brought huge economic value. For instance,\nChatGPT has attracted more than 100 million users in three months. Since the\nmodel training requires a lot of data and computing power, a well-performing\ndeep learning model is behind a huge effort and cost. Facing various model\nattacks, unauthorized use and abuse from the network that threaten the\ninterests of model owners, in addition to considering legal and other\nadministrative measures, it is equally important to protect the model's\ncopyright from the technical means. By using the model watermarking technology,\nwe point out the possibility of building a unified platform for model ownership\nverification. Given the application history of blockchain in copyright\nverification and the drawbacks of a centralized third-party, this paper\nconsiders combining model watermarking technology and blockchain to build a\nunified model copyright protection platform. By a new solution we called\nTokenized Model, it protects the model's copyright by reliable ownership record\nand verification mechanism. It also promotes the financial value of model by\nconstructing the model's transaction process and contribution shares of a\nmodel. In the typical case study, we also study the various performance under\nusual scenario to verify the effectiveness of this platform.",
            "author": [
                "Yihao Li",
                "Yanyi Lai",
                "Tianchi Liao",
                "Chuan Chen",
                "Zibin Zheng"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00048v1",
                "http://arxiv.org/pdf/2312.00048v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15637v1",
            "title": "PaintNeSF: Artistic Creation of Stylized Scenes with Vectorized 3D\n  Strokes",
            "updated": "2023-11-27T09:02:21Z",
            "published": "2023-11-27T09:02:21Z",
            "summary": "We present Paint Neural Stroke Field (PaintNeSF), a novel technique to\ngenerate stylized images of a 3D scene at arbitrary novel views from multi-view\n2D images. Different from existing methods which apply stylization to trained\nneural radiance fields at the voxel level, our approach draws inspiration from\nimage-to-painting methods, simulating the progressive painting process of human\nartwork with vector strokes. We develop a palette of stylized 3D strokes from\nbasic primitives and splines, and consider the 3D scene stylization task as a\nmulti-view reconstruction process based on these 3D stroke primitives. Instead\nof directly searching for the parameters of these 3D strokes, which would be\ntoo costly, we introduce a differentiable renderer that allows optimizing\nstroke parameters using gradient descent, and propose a training scheme to\nalleviate the vanishing gradient issue. The extensive evaluation demonstrates\nthat our approach effectively synthesizes 3D scenes with significant geometric\nand aesthetic stylization while maintaining a consistent appearance across\ndifferent views. Our method can be further integrated with style loss and\nimage-text contrastive models to extend its applications, including color\ntransfer and text-driven 3D scene drawing.",
            "author": [
                "Hao-Bin Duan",
                "Miao Wang",
                "Yan-Xun Li",
                "Yong-Liang Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15637v1",
                "http://arxiv.org/pdf/2311.15637v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15633v1",
            "title": "Toward a real-time TCP SYN Flood DDoS mitigation using Adaptive\n  Neuro-Fuzzy classifier and SDN Assistance in Fog Computing",
            "updated": "2023-11-27T08:54:00Z",
            "published": "2023-11-27T08:54:00Z",
            "summary": "The growth of the Internet of Things (IoT) has recently impacted our daily\nlives in many ways. As a result, a massive volume of data is generated and\nneeds to be processed in a short period of time. Therefore, the combination of\ncomputing models such as cloud computing is necessary. The main disadvantage of\nthe cloud platform is its high latency due to the centralized mainframe.\nFortunately, a distributed paradigm known as fog computing has emerged to\novercome this problem, offering cloud services with low latency and high-access\nbandwidth to support many IoT application scenarios. However, Attacks against\nfog servers can take many forms, such as Distributed Denial of Service (DDoS)\nattacks that severely affect the reliability and availability of fog services.\nTo address these challenges, we propose mitigation of Fog computing-based SYN\nFlood DDoS attacks using an Adaptive Neuro-Fuzzy Inference System (ANFIS) and\nSoftware Defined Networking (SDN) Assistance (FASA). The simulation results\nshow that FASA system outperforms other algorithms in terms of accuracy,\nprecision, recall, and F1-score. This shows how crucial our system is for\ndetecting and mitigating TCP SYN floods DDoS attacks.",
            "author": [
                "Radjaa Bensaid",
                "Nabila Labraoui",
                "Ado Adamou Abba Ari",
                "Leandros Maglaras",
                "Hafida Saidi",
                "Ahmed Mahmoud Abdu Lwahhab",
                "Sihem Benfriha"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15633v1",
                "http://arxiv.org/pdf/2311.15633v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15630v1",
            "title": "Generalized $\\varphi$-pullback attractors for evolution processes and\n  application to a nonautonomous wave equation",
            "updated": "2023-11-27T08:53:11Z",
            "published": "2023-11-27T08:53:11Z",
            "summary": "In this work we define the generalized $\\varphi$-pullback attractors for\nevolution processes in complete metric spaces, which are compact and positively\ninvariant families, such that they pullback attract bounded sets with a rate\ndetermined by a decreasing function $\\varphi$ that vanishes at infinity. We\nfind conditions under which a given evolution process has a generalized\n$\\varphi$-pullback attractor, both in the discrete and in the continuous cases.\nWe present a result for the special case of generalized polynomial pullback\nattractors, and apply it to obtain such an object for a nonautonomous wave\nequation.",
            "author": [
                "Matheus C. Bortolan",
                "Tomas Caraballo",
                "Carlos Pecorari Neto"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15630v1",
                "http://arxiv.org/pdf/2311.15630v1"
            ],
            "primary_category": "math.DS",
            "category": [
                "math.DS",
                "35B41, 35L20, 37L25"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16203v2",
            "title": "ChatTraffic: Text-to-Traffic Generation via Diffusion Model",
            "updated": "2023-11-29T01:53:46Z",
            "published": "2023-11-27T08:52:10Z",
            "summary": "Traffic prediction is one of the most significant foundations in Intelligent\nTransportation Systems (ITS). Traditional traffic prediction methods rely only\non historical traffic data to predict traffic trends and face two main\nchallenges. 1) insensitivity to unusual events. 2) poor performance in\nlong-term prediction. In this work, we explore how generative models combined\nwith text describing the traffic system can be applied for traffic generation\nand name the task Text-to-Traffic Generation (TTG). The key challenge of the\nTTG task is how to associate text with the spatial structure of the road\nnetwork and traffic data for generating traffic situations. To this end, we\npropose ChatTraffic, the first diffusion model for text-to-traffic generation.\nTo guarantee the consistency between synthetic and real data, we augment a\ndiffusion model with the Graph Convolutional Network (GCN) to extract spatial\ncorrelations of traffic data. In addition, we construct a large dataset\ncontaining text-traffic pairs for the TTG task. We benchmarked our model\nqualitatively and quantitatively on the released dataset. The experimental\nresults indicate that ChatTraffic can generate realistic traffic situations\nfrom the text. Our code and dataset are available at\nhttps://github.com/ChyaZhang/ChatTraffic.",
            "author": [
                "Chengyang Zhang",
                "Yong Zhang",
                "Qitan Shao",
                "Bo Li",
                "Yisheng Lv",
                "Xinglin Piao",
                "Baocai Yin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16203v2",
                "http://arxiv.org/pdf/2311.16203v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16496v1",
            "title": "Leveraging Out-of-Domain Data for Domain-Specific Prompt Tuning in\n  Multi-Modal Fake News Detection",
            "updated": "2023-11-27T08:49:26Z",
            "published": "2023-11-27T08:49:26Z",
            "summary": "The spread of fake news using out-of-context images has become widespread and\nis a challenging task in this era of information overload. Since annotating\nhuge amounts of such data requires significant time of domain experts, it is\nimperative to develop methods which can work in limited annotated data\nscenarios. In this work, we explore whether out-of-domain data can help to\nimprove out-of-context misinformation detection (termed here as multi-modal\nfake news detection) of a desired domain, eg. politics, healthcare, etc.\nTowards this goal, we propose a novel framework termed DPOD (Domain-specific\nPrompt-tuning using Out-of-Domain data). First, to compute generalizable\nfeatures, we modify the Vision-Language Model, CLIP to extract features that\nhelps to align the representations of the images and corresponding text\ncaptions of both the in-domain and out-of-domain data in a label-aware manner.\nFurther, we propose a domain-specific prompt learning technique which leverages\nthe training samples of all the available domains based on the the extent they\ncan be useful to the desired domain. Extensive experiments on a large-scale\nbenchmark dataset, namely NewsClippings demonstrate that the proposed framework\nachieves state of-the-art performance, significantly surpassing the existing\napproaches for this challenging task.",
            "author": [
                "Debarshi Brahma",
                "Amartya Bhattacharya",
                "Suraj Nagaje Mahadev",
                "Anmol Asati",
                "Vikas Verma",
                "Soma Biswas"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16496v1",
                "http://arxiv.org/pdf/2311.16496v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15629v1",
            "title": "How water binds to microcline feldspar (001)",
            "updated": "2023-11-27T08:49:13Z",
            "published": "2023-11-27T08:49:13Z",
            "summary": "Microcline feldspar (KAlSi$_3$O$_8$) is a common mineral with important roles\nfor Earth's ecological balance. It participates in the carbon, potassium, and\nwater cycles, contributing to CO$_2$ sequestration, soil formation, and\natmospheric ice nucleation. To understand the fundamentals of these processes,\nit is essential to establish microcline's surface atomic structure and its\ninteraction with the omnipresent water molecules. This work presents\natomic-scale results on microcline's lowest-energy surface and its interaction\nwith water, combining ultrahigh vacuum investigations by non-contact atomic\nforce microscopy and X-ray photoelectron spectroscopy with density functional\ntheory calculations. An ordered array of hydroxyls bonded to silicon or\naluminum readily forms on the cleaved surface at room temperature. The distinct\nproton affinities of these hydroxyls influence the arrangement and orientation\nof the first water molecules binding to the surface, holding potential\nimplications for the subsequent condensation of water.",
            "author": [
                "Giada Franceschi",
                "Andrea Conti",
                "Luca Lezuo",
                "Rainer Abart",
                "Florian Mittendorfer",
                "Michael Schmid",
                "Ulrike Diebold"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15629v1",
                "http://arxiv.org/pdf/2311.15629v1"
            ],
            "primary_category": "cond-mat.mes-hall",
            "category": [
                "cond-mat.mes-hall"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15627v1",
            "title": "Phonetic-aware speaker embedding for far-field speaker verification",
            "updated": "2023-11-27T08:45:35Z",
            "published": "2023-11-27T08:45:35Z",
            "summary": "When a speaker verification (SV) system operates far from the sound sourced,\nsignificant challenges arise due to the interference of noise and\nreverberation. Studies have shown that incorporating phonetic information into\nspeaker embedding can improve the performance of text-independent SV. Inspired\nby this observation, we propose a joint-training speech recognition and speaker\nrecognition (JTSS) framework to exploit phonetic content for far-field SV. The\nframework encourages speaker embeddings to preserve phonetic information by\nmatching the frame-based feature maps of a speaker embedding network with\nwav2vec's vectors. The intuition is that phonetic information can preserve\nlow-level acoustic dynamics with speaker information and thus partly compensate\nfor the degradation due to noise and reverberation. Results show that the\nproposed framework outperforms the standard speaker embedding on the VOiCES\nChallenge 2019 evaluation set and the VoxCeleb1 test set. This indicates that\nleveraging phonetic information under far-field conditions is effective for\nlearning robust speaker representations.",
            "author": [
                "Zezhong Jin",
                "Youzhi Tu",
                "Man-Wai Mak"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15627v1",
                "http://arxiv.org/pdf/2311.15627v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.AI",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15626v1",
            "title": "The WebCrow French Crossword Solver",
            "updated": "2023-11-27T08:45:31Z",
            "published": "2023-11-27T08:45:31Z",
            "summary": "Crossword puzzles are one of the most popular word games, played in different\nlanguages all across the world, where riddle style can vary significantly from\none country to another. Automated crossword resolution is challenging, and\ntypical solvers rely on large databases of previously solved crosswords. In\nthis work, we extend WebCrow 2.0, an automatic crossword solver, to French,\nmaking it the first program for crossword solving in the French language. To\ncope with the lack of a large repository of clue-answer crossword data, WebCrow\n2.0 exploits multiple modules, called experts, that retrieve candidate answers\nfrom heterogeneous resources, such as the web, knowledge graphs, and linguistic\nrules. We compared WebCrow's performance against humans in two different\nchallenges. Despite the limited amount of past crosswords, French WebCrow was\ncompetitive, actually outperforming humans in terms of speed and accuracy, thus\nproving its capabilities to generalize to new languages.",
            "author": [
                "Giovanni Angelini",
                "Marco Ernandes",
                "Tommaso laquinta",
                "Caroline Stehl\u00e9",
                "Fanny Sim\u00f5es",
                "Kamyar Zeinalipour",
                "Andrea Zugarini",
                "Marco Gori"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15626v1",
                "http://arxiv.org/pdf/2311.15626v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15625v1",
            "title": "Only Positive Cases: 5-fold High-order Attention Interaction Model for\n  Skin Segmentation Derived Classification",
            "updated": "2023-11-27T08:44:00Z",
            "published": "2023-11-27T08:44:00Z",
            "summary": "Computer-aided diagnosis of skin diseases is an important tool. However, the\ninterpretability of computer-aided diagnosis is currently poor. Dermatologists\nand patients cannot intuitively understand the learning and prediction process\nof neural networks, which will lead to a decrease in the credibility of\ncomputer-aided diagnosis. In addition, traditional methods need to be trained\nusing negative samples in order to predict the presence or absence of a lesion,\nbut medical data is often in short supply. In this paper, we propose a multiple\nhigh-order attention interaction model (MHA-UNet) for use in a highly\nexplainable skin lesion segmentation task. MHA-UNet is able to obtain the\npresence or absence of a lesion by explainable reasoning without the need for\ntraining on negative samples. Specifically, we propose a high-order attention\ninteraction mechanism that introduces squeeze attention to a higher level for\nfeature attention. In addition, a multiple high-order attention interaction\n(MHAblock) module is proposed by combining the different features of different\norders. For classifying the presence or absence of lesions, we conducted\nclassification experiments on several publicly available datasets in the\nabsence of negative samples, based on explainable reasoning about the\ninteraction of 5 attention orders of MHAblock. The highest positive detection\nrate obtained from the experiments was 81.0% and the highest negative detection\nrate was 83.5%. For segmentation experiments, comparison experiments of the\nproposed method with 13 medical segmentation models and external validation\nexperiments with 8 state-of-the-art models in three public datasets and our\nclinical dataset demonstrate the state-of-the-art performance of our model. The\ncode is available from https://github.com/wurenkai/MHA-UNet.",
            "author": [
                "Renkai Wu",
                "Yinghao Liu",
                "Pengchen Liang",
                "Qing Chang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15625v1",
                "http://arxiv.org/pdf/2311.15625v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15624v1",
            "title": "The star formation histories of galaxies in different stages of\n  pre-processing in the Fornax A group",
            "updated": "2023-11-27T08:39:34Z",
            "published": "2023-11-27T08:39:34Z",
            "summary": "We study the recent star formation histories of ten galaxies in the Fornax A\ngalaxy group, on the outskirts of the Fornax cluster. The group galaxies are\ngas-rich, and their neutral atomic hydrogen (HI) was studied in detail with\nobservations from the MeerKAT telescope. This allowed them to be classified\ninto different stages of pre-processing (early, ongoing, advanced). We use\nlong-slit spectra obtained with the South African Large Telescope (SALT) to\nanalyse stellar population indicators to constrain quenching timescales and to\ncompare these to the HI gas content of the galaxies. The H$\\alpha$ equivalent\nwidth, EW(H$\\alpha$), suggest that the pre-processing stage is closely related\nto the recent (< 10 Myr) specific Star Formation Rate (sSFR). The early-stage\ngalaxy (NGC 1326B) is not yet quenched in its outer parts, while the\nongoing-stage galaxies mostly have a distributed population of very young\nstars, though less so in their outer parts. The galaxies in the advanced stage\nof pre-processing show very low recent sSFR in the outer parts. Our results\nsuggest that NGC 1326B, FCC 35 and FCC 46 underwent significantly different\nhistories from secular evolution during the last Gyr. The fact that most\ngalaxies are on the secular evolution sequence implies that pre-processing has\na negligible effect on these galaxies compared to secular evolution. We find\nEW(H$\\alpha$) to be a useful tool for classifying the stage of pre-processing\nin group galaxies. The recent sSFR and HI morphology show that galaxies in the\nFornax A vicinity are pre-processing from the outside in.",
            "author": [
                "S. I. Loubser",
                "K. Mosia",
                "P. Serra",
                "D. Kleiner",
                "R. F. Peletier",
                "R. C. Kraan-Korteweg",
                "E. Iodice",
                "A. Loni",
                "P. Kamphuis",
                "N. Zabel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15624v1",
                "http://arxiv.org/pdf/2311.15624v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15623v1",
            "title": "Injecting linguistic knowledge into BERT for Dialogue State Tracking",
            "updated": "2023-11-27T08:38:42Z",
            "published": "2023-11-27T08:38:42Z",
            "summary": "Dialogue State Tracking (DST) models often employ intricate neural network\narchitectures, necessitating substantial training data, and their inference\nprocesses lack transparency. This paper proposes a method that extracts\nlinguistic knowledge via an unsupervised framework and subsequently utilizes\nthis knowledge to augment BERT's performance and interpretability in DST tasks.\nThe knowledge extraction procedure is computationally economical and does not\nnecessitate annotations or additional training data. The injection of the\nextracted knowledge necessitates the addition of only simple neural modules. We\nemploy the Convex Polytopic Model (CPM) as a feature extraction tool for DST\ntasks and illustrate that the acquired features correlate with the syntactic\nand semantic patterns in the dialogues. This correlation facilitates a\ncomprehensive understanding of the linguistic features influencing the DST\nmodel's decision-making process. We benchmark this framework on various DST\ntasks and observe a notable improvement in accuracy.",
            "author": [
                "Xiaohan Feng",
                "Xixin Wu",
                "Helen Meng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15623v1",
                "http://arxiv.org/pdf/2311.15623v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15619v1",
            "title": "Align before Adapt: Leveraging Entity-to-Region Alignments for\n  Generalizable Video Action Recognition",
            "updated": "2023-11-27T08:32:28Z",
            "published": "2023-11-27T08:32:28Z",
            "summary": "Large-scale visual-language pre-trained models have achieved significant\nsuccess in various video tasks. However, most existing methods follow an \"adapt\nthen align\" paradigm, which adapts pre-trained image encoders to model\nvideo-level representations and utilizes one-hot or text embedding of the\naction labels for supervision. This paradigm overlooks the challenge of mapping\nfrom static images to complicated activity concepts. In this paper, we propose\na novel \"Align before Adapt\" (ALT) paradigm. Prior to adapting to video\nrepresentation learning, we exploit the entity-to-region alignments for each\nframe. The alignments are fulfilled by matching the region-aware image\nembeddings to an offline-constructed text corpus. With the aligned entities, we\nfeed their text embeddings to a transformer-based video adapter as the queries,\nwhich can help extract the semantics of the most important entities from a\nvideo to a vector. This paradigm reuses the visual-language alignment of VLP\nduring adaptation and tries to explain an action by the underlying entities.\nThis helps understand actions by bridging the gap with complex activity\nsemantics, particularly when facing unfamiliar or unseen categories. ALT\nachieves competitive performance and superior generalizability while requiring\nsignificantly low computational costs. In fully supervised scenarios, it\nachieves 88.1% top-1 accuracy on Kinetics-400 with only 4947 GFLOPs. In 2-shot\nexperiments, ALT outperforms the previous state-of-the-art by 7.1% and 9.2% on\nHMDB-51 and UCF-101, respectively.",
            "author": [
                "Yifei Chen",
                "Dapeng Chen",
                "Ruijin Liu",
                "Sai Zhou",
                "Wenyuan Xue",
                "Wei Peng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15619v1",
                "http://arxiv.org/pdf/2311.15619v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15614v1",
            "title": "FreeAL: Towards Human-Free Active Learning in the Era of Large Language\n  Models",
            "updated": "2023-11-27T08:23:08Z",
            "published": "2023-11-27T08:23:08Z",
            "summary": "Collecting high-quality labeled data for model training is notoriously\ntime-consuming and labor-intensive for various NLP tasks. While copious\nsolutions, such as active learning for small language models (SLMs) and\nprevalent in-context learning in the era of large language models (LLMs), have\nbeen proposed and alleviate the labeling burden to some extent, their\nperformances are still subject to human intervention. It is still underexplored\nhow to reduce the annotation cost in the LLMs era. To bridge this, we\nrevolutionize traditional active learning and propose an innovative\ncollaborative learning framework FreeAL to interactively distill and filter the\ntask-specific knowledge from LLMs. During collaborative training, an LLM serves\nas an active annotator inculcating its coarse-grained knowledge, while a\ndownstream SLM is incurred as a student to filter out high-quality in-context\nsamples to feedback LLM for the subsequent label refinery. Extensive\nexperiments on eight benchmark datasets demonstrate that FreeAL largely\nenhances the zero-shot performances for both SLM and LLM without any human\nsupervision. The code is available at https://github.com/Justherozen/FreeAL .",
            "author": [
                "Ruixuan Xiao",
                "Yiwen Dong",
                "Junbo Zhao",
                "Runze Wu",
                "Minmin Lin",
                "Gang Chen",
                "Haobo Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15614v1",
                "http://arxiv.org/pdf/2311.15614v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16478v1",
            "title": "RetouchUAA: Unconstrained Adversarial Attack via Image Retouching",
            "updated": "2023-11-27T08:21:25Z",
            "published": "2023-11-27T08:21:25Z",
            "summary": "Deep Neural Networks (DNNs) are susceptible to adversarial examples.\nConventional attacks generate controlled noise-like perturbations that fail to\nreflect real-world scenarios and hard to interpretable. In contrast, recent\nunconstrained attacks mimic natural image transformations occurring in the real\nworld for perceptible but inconspicuous attacks, yet compromise realism due to\nneglect of image post-processing and uncontrolled attack direction. In this\npaper, we propose RetouchUAA, an unconstrained attack that exploits a real-life\nperturbation: image retouching styles, highlighting its potential threat to\nDNNs. Compared to existing attacks, RetouchUAA offers several notable\nadvantages. Firstly, RetouchUAA excels in generating interpretable and\nrealistic perturbations through two key designs: the image retouching attack\nframework and the retouching style guidance module. The former custom-designed\nhuman-interpretability retouching framework for adversarial attack by\nlinearizing images while modelling the local processing and retouching\ndecision-making in human retouching behaviour, provides an explicit and\nreasonable pipeline for understanding the robustness of DNNs against\nretouching. The latter guides the adversarial image towards standard retouching\nstyles, thereby ensuring its realism. Secondly, attributed to the design of the\nretouching decision regularization and the persistent attack strategy,\nRetouchUAA also exhibits outstanding attack capability and defense robustness,\nposing a heavy threat to DNNs. Experiments on ImageNet and Place365 reveal that\nRetouchUAA achieves nearly 100\\% white-box attack success against three DNNs,\nwhile achieving a better trade-off between image naturalness, transferability\nand defense robustness than baseline attacks.",
            "author": [
                "Mengda Xie",
                "Yiling He",
                "Meie Fang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16478v1",
                "http://arxiv.org/pdf/2311.16478v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15612v1",
            "title": "Galactic magnetic fields I. Theoretical model and scaling relations",
            "updated": "2023-11-27T08:11:32Z",
            "published": "2023-11-27T08:11:32Z",
            "summary": "Galactic dynamo models have generally relied on input parameters that are\nvery challenging to constrain. We address this problem by developing a model\nthat uses observable quantities as input: the galaxy rotation curve, the\nsurface densities of the gas, stars and star formation rate, and the gas\ntemperature. The model can be used to estimate parameters of the random and\nmean components of the magnetic field, as well as the gas scale height,\nroot-mean-square velocity and the correlation length and time of the\ninterstellar turbulence, in terms of the observables. We use our model to\nderive theoretical scaling relations for the quantities of interest, finding\nreasonable agreement with empirical scaling relations inferred from\nobservation. We assess the dependence of the results on different assumptions\nabout turbulence driving, finding that agreement with observations is improved\nby explicitly modeling the expansion and energetics of supernova remnants. The\nmodel is flexible enough to include alternative prescriptions for the physical\nprocesses involved, and we provide links to two open-source PYTHON programs\nthat implement it.",
            "author": [
                "Luke Chamandy",
                "Rion Glenn Nazareth",
                "Gayathri Santhosh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15612v1",
                "http://arxiv.org/pdf/2311.15612v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15609v1",
            "title": "A manometric feature descriptor with linear-SVM to distinguish\n  esophageal contraction vigor",
            "updated": "2023-11-27T08:06:56Z",
            "published": "2023-11-27T08:06:56Z",
            "summary": "n clinical, if a patient presents with nonmechanical obstructive dysphagia,\nesophageal chest pain, and gastro esophageal reflux symptoms, the physician\nwill usually assess the esophageal dynamic function. High-resolution manometry\n(HRM) is a clinically commonly used technique for detection of esophageal\ndynamic function comprehensively and objectively. However, after the results of\nHRM are obtained, doctors still need to evaluate by a variety of parameters.\nThis work is burdensome, and the process is complex. We conducted image\nprocessing of HRM to predict the esophageal contraction vigor for assisting the\nevaluation of esophageal dynamic function. Firstly, we used Feature-Extraction\nand Histogram of Gradients (FE-HOG) to analyses feature of proposal of swallow\n(PoS) to further extract higher-order features. Then we determine the\nclassification of esophageal contraction vigor normal, weak and failed by using\nlinear-SVM according to these features. Our data set includes 3000 training\nsets, 500 validation sets and 411 test sets. After verification our accuracy\nreaches 86.83%, which is higher than other common machine learning methods.",
            "author": [
                "Jialin Liu",
                "Lu Yan",
                "Xiaowei Liu",
                "Yuzhuo Dai",
                "Fanggen Lu",
                "Yuanting Ma",
                "Muzhou Hou",
                "Zheng Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15609v1",
                "http://arxiv.org/pdf/2311.15609v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15607v1",
            "title": "Spatially Covariant Image Registration with Text Prompts",
            "updated": "2023-11-27T08:00:53Z",
            "published": "2023-11-27T08:00:53Z",
            "summary": "Medical images are often characterized by their structured anatomical\nrepresentations and spatially inhomogeneous contrasts. Leveraging anatomical\npriors in neural networks can greatly enhance their utility in\nresource-constrained clinical settings. Prior research has harnessed such\ninformation for image segmentation, yet progress in deformable image\nregistration has been modest. Our work introduces textSCF, a novel method that\nintegrates spatially covariant filters and textual anatomical prompts encoded\nby visual-language models, to fill this gap. This approach optimizes an\nimplicit function that correlates text embeddings of anatomical regions to\nfilter weights, relaxing the typical translation-invariance constraint of\nconvolutional operations. TextSCF not only boosts computational efficiency but\ncan also retain or improve registration accuracy. By capturing the contextual\ninterplay between anatomical regions, it offers impressive inter-regional\ntransferability and the ability to preserve structural discontinuities during\nregistration. TextSCF's performance has been rigorously tested on inter-subject\nbrain MRI and abdominal CT registration tasks, outperforming existing\nstate-of-the-art models in the MICCAI Learn2Reg 2021 challenge and leading the\nleaderboard. In abdominal registrations, textSCF's larger model variant\nimproved the Dice score by 11.3% over the second-best model, while its smaller\nvariant maintained similar accuracy but with an 89.13% reduction in network\nparameters and a 98.34\\% decrease in computational operations.",
            "author": [
                "Hang Zhang",
                "Xiang Chen",
                "Rongguang Wang",
                "Renjiu Hu",
                "Dongdong Liu",
                "Gaolei Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15607v1",
                "http://arxiv.org/pdf/2311.15607v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15606v1",
            "title": "Selective active resonance tuning for multi-mode nonlinear photonic\n  cavities",
            "updated": "2023-11-27T08:00:01Z",
            "published": "2023-11-27T08:00:01Z",
            "summary": "Resonant enhancement of nonlinear photonic processes is critical for the\nscalability of applications such as long-distance entanglement generation. To\nimplement nonlinear resonant enhancement, multiple resonator modes must be\nindividually tuned onto a precise set of process wavelengths, which requires\nmultiple linearly-independent tuning methods. Using coupled auxiliary\nresonators to indirectly tune modes in a multi-resonant nonlinear cavity is\nparticularly attractive because it allows the extension of a single physical\ntuning mechanism, such as thermal tuning, to provide the required independent\ncontrols. Here we model and simulate the performance and tradeoffs of a\ncoupled-resonator tuning scheme which uses auxiliary resonators to tune\nspecific modes of a multi-resonant nonlinear process. Our analysis determines\nthe tuning bandwidth for steady-state mode field intensity can significantly\nexceed the inter-cavity coupling rate if the total quality factor of the\nauxiliary resonator is higher than the multi-mode main resonator. Consequently,\nover-coupling a nonlinear resonator mode to improve the maximum efficiency of a\nfrequency conversion process will simultaneously expand the auxiliary resonator\ntuning bandwidth for that mode, indicating a natural compatibility with this\ntuning scheme. We apply the model to an existing small-diameter triply-resonant\nring resonator design and find that a tuning bandwidth of 136 GHz ~ 1.1 nm can\nbe attained for a mode in the telecom band while limiting excess scattering\nlosses to a quality factor of 10^6. Such range would span the distribution of\ninhomogeneously broadened quantum emitter ensembles as well as resonator\nfabrication variations, indicating the potential for the auxiliary resonators\nto enable not only low-loss telecom conversion but also the generation of\nindistinguishable photons in a quantum network.",
            "author": [
                "Alan D. Logan",
                "Nicholas S. Yama",
                "Kai-Mei C. Fu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15606v1",
                "http://arxiv.org/pdf/2311.15606v1"
            ],
            "primary_category": "physics.optics",
            "category": [
                "physics.optics"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15603v1",
            "title": "QuickDrop: Efficient Federated Unlearning by Integrated Dataset\n  Distillation",
            "updated": "2023-11-27T07:53:44Z",
            "published": "2023-11-27T07:53:44Z",
            "summary": "Federated Unlearning (FU) aims to delete specific training data from an ML\nmodel trained using Federated Learning (FL). We introduce QuickDrop, an\nefficient and original FU method that utilizes dataset distillation (DD) to\naccelerate unlearning and drastically reduces computational overhead compared\nto existing approaches. In QuickDrop, each client uses DD to generate a compact\ndataset representative of the original training dataset, called a distilled\ndataset, and uses this compact dataset during unlearning. To unlearn specific\nknowledge from the global model, QuickDrop has clients execute Stochastic\nGradient Ascent with samples from the distilled datasets, thus significantly\nreducing computational overhead compared to conventional FU methods. We further\nincrease the efficiency of QuickDrop by ingeniously integrating DD into the FL\ntraining process. By reusing the gradient updates produced during FL training\nfor DD, the overhead of creating distilled datasets becomes close to\nnegligible. Evaluations on three standard datasets show that, with comparable\naccuracy guarantees, QuickDrop reduces the duration of unlearning by 463.8x\ncompared to model retraining from scratch and 65.1x compared to existing FU\napproaches. We also demonstrate the scalability of QuickDrop with 100 clients\nand show its effectiveness while handling multiple unlearning operations.",
            "author": [
                "Akash Dhasade",
                "Yaohong Ding",
                "Song Guo",
                "Anne-marie Kermarrec",
                "Martijn De Vos",
                "Leijie Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15603v1",
                "http://arxiv.org/pdf/2311.15603v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.03726v1",
            "title": "Interpretation modeling: Social grounding of sentences by reasoning over\n  their implicit moral judgments",
            "updated": "2023-11-27T07:50:55Z",
            "published": "2023-11-27T07:50:55Z",
            "summary": "The social and implicit nature of human communication ramifies readers'\nunderstandings of written sentences. Single gold-standard interpretations\nrarely exist, challenging conventional assumptions in natural language\nprocessing. This work introduces the interpretation modeling (IM) task which\ninvolves modeling several interpretations of a sentence's underlying semantics\nto unearth layers of implicit meaning. To obtain these, IM is guided by\nmultiple annotations of social relation and common ground - in this work\napproximated by reader attitudes towards the author and their understanding of\nmoral judgments subtly embedded in the sentence. We propose a number of\nmodeling strategies that rely on one-to-one and one-to-many generation methods\nthat take inspiration from the philosophical study of interpretation. A\nfirst-of-its-kind IM dataset is curated to support experiments and analyses.\nThe modeling results, coupled with scrutiny of the dataset, underline the\nchallenges of IM as conflicting and complex interpretations are socially\nplausible. This interplay of diverse readings is affirmed by automated and\nhuman evaluations on the generated interpretations. Finally, toxicity analyses\nin the generated interpretations demonstrate the importance of IM for refining\nfilters of content and assisting content moderators in safeguarding the safety\nin online discourse.",
            "author": [
                "Liesbeth Allein",
                "Maria Mihaela Tru\u015fc\u01ce",
                "Marie-Francine Moens"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03726v1",
                "http://arxiv.org/pdf/2312.03726v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15597v1",
            "title": "Spatial Diarization for Meeting Transcription with Ad-Hoc Acoustic\n  Sensor Networks",
            "updated": "2023-11-27T07:46:48Z",
            "published": "2023-11-27T07:46:48Z",
            "summary": "We propose a diarization system, that estimates \"who spoke when\" based on\nspatial information, to be used as a front-end of a meeting transcription\nsystem running on the signals gathered from an acoustic sensor network (ASN).\nAlthough the spatial distribution of the microphones is advantageous,\nexploiting the spatial diversity for diarization and signal enhancement is\nchallenging, because the microphones' positions are typically unknown, and the\nrecorded signals are initially unsynchronized in general. Here, we approach\nthese issues by first blindly synchronizing the signals and then estimating\ntime differences of arrival (TDOAs). The TDOA information is exploited to\nestimate the speakers' activity, even in the presence of multiple speakers\nbeing simultaneously active. This speaker activity information serves as a\nguide for a spatial mixture model, on which basis the individual speaker's\nsignals are extracted via beamforming. Finally, the extracted signals are\nforwarded to a speech recognizer. Additionally, a novel initialization scheme\nfor spatial mixture models based on the TDOA estimates is proposed. Experiments\nconducted on real recordings from the LibriWASN data set have shown that our\nproposed system is advantageous compared to a system using a spatial mixture\nmodel, which does not make use of external diarization information.",
            "author": [
                "Tobias Gburrek",
                "Joerg Schmalenstroeer",
                "Reinhold Haeb-Umbach"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15597v1",
                "http://arxiv.org/pdf/2311.15597v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15596v1",
            "title": "Can Vision-Language Models Think from a First-Person Perspective?",
            "updated": "2023-11-27T07:44:25Z",
            "published": "2023-11-27T07:44:25Z",
            "summary": "Vision-language models (VLMs) have recently shown promising results in\ntraditional downstream tasks. Evaluation studies have emerged to assess their\nabilities, with the majority focusing on the third-person perspective, and only\na few addressing specific tasks from the first-person perspective. However, the\ncapability of VLMs to \"think\" from a first-person perspective, a crucial\nattribute for advancing autonomous agents and robotics, remains largely\nunexplored. To bridge this research gap, we introduce EgoThink, a novel visual\nquestion-answering benchmark that encompasses six core capabilities with twelve\ndetailed dimensions. The benchmark is constructed using selected clips from\negocentric videos, with manually annotated question-answer pairs containing\nfirst-person information. To comprehensively assess VLMs, we evaluate eighteen\npopular VLMs on EgoThink. Moreover, given the open-ended format of the answers,\nwe use GPT-4 as the automatic judge to compute single-answer grading.\nExperimental results indicate that although GPT-4V leads in numerous\ndimensions, all evaluated VLMs still possess considerable potential for\nimprovement in first-person perspective tasks. Meanwhile, enlarging the number\nof trainable parameters has the most significant impact on model performance on\nEgoThink. In conclusion, EgoThink serves as a valuable addition to existing\nevaluation benchmarks for VLMs, providing an indispensable resource for future\nresearch in the realm of embodied artificial intelligence and robotics.",
            "author": [
                "Sijie Cheng",
                "Zhicheng Guo",
                "Jingwen Wu",
                "Kechen Fang",
                "Peng Li",
                "Huaping Liu",
                "Yang Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15596v1",
                "http://arxiv.org/pdf/2311.15596v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15595v1",
            "title": "Error Performance of Coded AFDM Systems in Doubly Selective Channels",
            "updated": "2023-11-27T07:42:36Z",
            "published": "2023-11-27T07:42:36Z",
            "summary": "Affine frequency division multiplexing (AFDM) is a strong candidate for the\nsixth-generation wireless network thanks to its strong resilience to\ndelay-Doppler spreads. In this letter, we investigate the error performance of\ncoded AFDM systems in doubly selective channels. We first study the conditional\npairwise-error probability (PEP) of AFDM system and derive its conditional\ncoding gain. Then, we show that there is a fundamental trade-off between the\ndiversity gain and the coding gain of AFDM system, namely the coding gain\ndeclines with a descending speed with respect to the number of separable paths,\nwhile the diversity gain increases linearly. Moreover, we propose a\nnear-optimal turbo decoder based on the sum-product algorithm for coded AFDM\nsystems to improve its error performance. Simulation results verify our\nanalyses and the effectiveness of the proposed turbo decoder, showing that AFDM\noutperforms orthogonal frequency division multiplexing (OFDM) and orthogonal\ntime frequency space (OTFS) in both coded and uncoded cases over high-mobility\nchannels.",
            "author": [
                "Haoran Yin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15595v1",
                "http://arxiv.org/pdf/2311.15595v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15594v1",
            "title": "Networked Multiagent Safe Reinforcement Learning for Low-carbon Demand\n  Management in Distribution Network",
            "updated": "2023-11-27T07:41:28Z",
            "published": "2023-11-27T07:41:28Z",
            "summary": "This paper proposes a multiagent based bi-level operation framework for the\nlow-carbon demand management in distribution networks considering the carbon\nemission allowance on the demand side. In the upper level, the aggregate load\nagents optimize the control signals for various types of loads to maximize the\nprofits; in the lower level, the distribution network operator makes optimal\ndispatching decisions to minimize the operational costs and calculates the\ndistribution locational marginal price and carbon intensity. The distributed\nflexible load agent has only incomplete information of the distribution network\nand cooperates with other agents using networked communication. Finally, the\nproblem is formulated into a networked multi-agent constrained Markov decision\nprocess, which is solved using a safe reinforcement learning algorithm called\nconsensus multi-agent constrained policy optimization considering the carbon\nemission allowance for each agent. Case studies with the IEEE 33-bus and\n123-bus distribution network systems demonstrate the effectiveness of the\nproposed approach, in terms of satisfying the carbon emission constraint on\ndemand side, ensuring the safe operation of the distribution network and\npreserving privacy of both sides.",
            "author": [
                "Jichen Zhang",
                "Linwei Sang",
                "Yinliang Xu",
                "Hongbin Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15594v1",
                "http://arxiv.org/pdf/2311.15594v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.AI",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15593v1",
            "title": "Performance Analysis of MDMA-Based Cooperative MRC Networks with Relays\n  in Dissimilar Rayleigh Fading Channels",
            "updated": "2023-11-27T07:37:56Z",
            "published": "2023-11-27T07:37:56Z",
            "summary": "Multiple access technology is a key technology in various generations of\nwireless communication systems. As a potential multiple access technology for\nthe next generation wireless communication systems, model division multiple\naccess (MDMA) technology improves spectrum efficiency and feasibility regions.\nThis implies that the MDMA scheme can achieve greater performance gains\ncompared to traditional schemes. Relayassisted cooperative networks, as a\ninfrastructure of wireless communication, can effectively utilize resources and\nimprove performance when MDMA is applied. In this paper, a communication relay\ncooperative network based on MDMA in dissimilar rayleigh fading channels is\nproposed, which consists of two source nodes, any number of decode-and-forward\n(DF) relay nodes, and one destination node, as well as using the maximal ratio\ncombining (MRC) at the destination to combine the signals received from the\nsource and relays. By applying the state transition matrix (STM) and moment\ngenerating function (MGF), closed-form analytical solutions for outage\nprobability and resource utilization efficiency are derived. Theoretical and\nsimulation results are conducted to verify the validity of the theoretical\nanalysis.",
            "author": [
                "Lei Teng",
                "Wannian An",
                "Chen Dong",
                "Xiaoqi Qin",
                "Xiaodong Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15593v1",
                "http://arxiv.org/pdf/2311.15593v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "cs.PF",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16517v1",
            "title": "LFSRDiff: Light Field Image Super-Resolution via Diffusion Models",
            "updated": "2023-11-27T07:31:12Z",
            "published": "2023-11-27T07:31:12Z",
            "summary": "Light field (LF) image super-resolution (SR) is a challenging problem due to\nits inherent ill-posed nature, where a single low-resolution (LR) input LF\nimage can correspond to multiple potential super-resolved outcomes. Despite\nthis complexity, mainstream LF image SR methods typically adopt a deterministic\napproach, generating only a single output supervised by pixel-wise loss\nfunctions. This tendency often results in blurry and unrealistic results.\nAlthough diffusion models can capture the distribution of potential SR results\nby iteratively predicting Gaussian noise during the denoising process, they are\nprimarily designed for general images and struggle to effectively handle the\nunique characteristics and information present in LF images. To address these\nlimitations, we introduce LFSRDiff, the first diffusion-based LF image SR\nmodel, by incorporating the LF disentanglement mechanism. Our novel\ncontribution includes the introduction of a disentangled U-Net for diffusion\nmodels, enabling more effective extraction and fusion of both spatial and\nangular information within LF images. Through comprehensive experimental\nevaluations and comparisons with the state-of-the-art LF image SR methods, the\nproposed approach consistently produces diverse and realistic SR results. It\nachieves the highest perceptual metric in terms of LPIPS. It also demonstrates\nthe ability to effectively control the trade-off between perception and\ndistortion. The code is available at\n\\url{https://github.com/chaowentao/LFSRDiff}.",
            "author": [
                "Wentao Chao",
                "Fuqing Duan",
                "Xuechun Wang",
                "Yingqian Wang",
                "Guanghui Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16517v1",
                "http://arxiv.org/pdf/2311.16517v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15589v1",
            "title": "Versatile non-diffracting beams generator based on free lens modulation",
            "updated": "2023-11-27T07:26:10Z",
            "published": "2023-11-27T07:26:10Z",
            "summary": "Non-diffracting beams, notable for their self-healing properties,\nhigh-localized intensity profiles over extended propagation distances, and\nresistance to diffraction, present significant utility across various fields.\nIn this letter, we present a versatile and highly efficient non-diffracting\nbeams (NDBs) generator predicated on the Fourier transformation of the focal\nplane fields produced through the free lens modulation. We demonstrate the\nexperimental generation of high-quality Bessel beams, polymorphic generalized\nNDBs, tilted NDBs, asymmetric NDBs, and specially structured beams formed by\nthe superposition of co-propagating beams. The versatile generalized NDBs\ngenerator is anticipated to find applications in laser processing, optical\nmanipulation, and other fields.",
            "author": [
                "Xue Yun",
                "Yansheng Liang",
                "Minru He",
                "Lingquan Guo",
                "Xinyu Zhang",
                "Tianyu Zhao1",
                "Ming Lei"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15589v1",
                "http://arxiv.org/pdf/2311.15589v1"
            ],
            "primary_category": "physics.optics",
            "category": [
                "physics.optics"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15586v1",
            "title": "An Ensemble of 2.5D ResUnet Based Models for Segmentation for Kidney and\n  Masses",
            "updated": "2023-11-27T07:24:50Z",
            "published": "2023-11-27T07:24:50Z",
            "summary": "The automatic segmentation of kidney, kidney tumor and kidney cyst on\nComputed Tomography (CT) scans is a challenging task due to the indistinct\nlesion boundaries and fuzzy texture. Considering the large range and unbalanced\ndistribution of CT scans' thickness, 2.5D ResUnet are adopted to build an\nefficient coarse-to-fine semantic segmentation framework in this work. A set of\n489 CT scans are used for training and validation, and an independent\nnever-before-used CT scans for testing. Finally, we demonstrate the\neffectiveness of our proposed method. The dice values on test set are 0.954,\n0.792, 0.691, the surface dice values are 0.897, 0.591, 0.541 for kidney, tumor\nand cyst, respectively. The average inference time of each CT scan is 20.65s\nand the max GPU memory is 3525MB. The results suggest that a better trade-off\nbetween model performance and efficiency.",
            "author": [
                "Cancan Chen",
                "RongguoZhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15586v1",
                "http://arxiv.org/pdf/2311.15586v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15585v1",
            "title": "Dawning of a New Era in Gravitational Wave Data Analysis: Unveiling\n  Cosmic Mysteries via Artificial Intelligence -- A Systematic Review",
            "updated": "2023-11-27T07:21:24Z",
            "published": "2023-11-27T07:21:24Z",
            "summary": "Background: Artificial intelligence (AI), with its vast capabilities, has\nbecome an integral part of our daily interactions, particularly with the rise\nof sophisticated models like Large Language Models. These advancements have not\nonly transformed human-machine interactions but have also paved the way for\nsignificant breakthroughs in various scientific domains. Aim of review: This\nreview is centered on elucidating the profound impact of AI, especially deep\nlearning, in the field of gravitational wave data analysis (GWDA). We aim to\nhighlight the challenges faced by traditional GWDA methodologies and how AI\nemerges as a beacon of hope, promising enhanced accuracy, real-time processing,\nand adaptability. Key scientific concepts of review: Gravitational wave (GW)\nwaveform modeling stands as a cornerstone in the realm of GW research, serving\nas a sophisticated method to simulate and interpret the intricate patterns and\nsignatures of these cosmic phenomena. This modeling provides a deep\nunderstanding of the astrophysical events that produce gravitational waves.\nNext in line is GW signal detection, a refined technique that meticulously\ncombs through extensive datasets, distinguishing genuine gravitational wave\nsignals from the cacophony of background noise. This detection process is\npivotal in ensuring the authenticity of observed events. Complementing this is\nthe GW parameter estimation, a method intricately designed to decode the\ndetected signals, extracting crucial parameters that offer insights into the\nproperties and origins of the waves. Lastly, the integration of AI for GW\nscience has emerged as a transformative force. AI methodologies harness vast\ncomputational power and advanced algorithms to enhance the efficiency,\naccuracy, and adaptability of data analysis in GW research, heralding a new era\nof innovation and discovery in the field.",
            "author": [
                "Tianyu Zhao",
                "Ruijun Shi",
                "Yue Zhou",
                "Zhoujian Cao",
                "Zhixiang Ren"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15585v1",
                "http://arxiv.org/pdf/2311.15585v1"
            ],
            "primary_category": "gr-qc",
            "category": [
                "gr-qc",
                "astro-ph.HE",
                "astro-ph.IM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15584v1",
            "title": "A deep learning approach for marine snow synthesis and removal",
            "updated": "2023-11-27T07:19:41Z",
            "published": "2023-11-27T07:19:41Z",
            "summary": "Marine snow, the floating particles in underwater images, severely degrades\nthe visibility and performance of human and machine vision systems. This paper\nproposes a novel method to reduce the marine snow interference using deep\nlearning techniques. We first synthesize realistic marine snow samples by\ntraining a Generative Adversarial Network (GAN) model and combine them with\nnatural underwater images to create a paired dataset. We then train a U-Net\nmodel to perform marine snow removal as an image to image translation task. Our\nexperiments show that the U-Net model can effectively remove both synthetic and\nnatural marine snow with high accuracy, outperforming state-of-the-art methods\nsuch as the Median filter and its adaptive variant. We also demonstrate the\nrobustness of our method by testing it on the MSRB dataset, which contains\nsynthetic artifacts that our model has not seen during training. Our method is\na practical and efficient solution for enhancing underwater images affected by\nmarine snow.",
            "author": [
                "Fernando Galetto",
                "Guang Deng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15584v1",
                "http://arxiv.org/pdf/2311.15584v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16201v1",
            "title": "Pre-trained Language Models Do Not Help Auto-regressive Text-to-Image\n  Generation",
            "updated": "2023-11-27T07:19:26Z",
            "published": "2023-11-27T07:19:26Z",
            "summary": "Recent advances in image tokenizers, such as VQ-VAE, have enabled\ntext-to-image generation using auto-regressive methods, similar to language\nmodeling. However, these methods have yet to leverage pre-trained language\nmodels, despite their adaptability to various downstream tasks. In this work,\nwe explore this gap by adapting a pre-trained language model for\nauto-regressive text-to-image generation, and find that pre-trained language\nmodels offer limited help. We provide a two-fold explanation by analyzing\ntokens from each modality. First, we demonstrate that image tokens possess\nsignificantly different semantics compared to text tokens, rendering\npre-trained language models no more effective in modeling them than randomly\ninitialized ones. Second, the text tokens in the image-text datasets are too\nsimple compared to normal language model pre-training data, which causes the\ncatastrophic degradation of language models' capability.",
            "author": [
                "Yuhui Zhang",
                "Brandon McKinzie",
                "Zhe Gan",
                "Vaishaal Shankar",
                "Alexander Toshev"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16201v1",
                "http://arxiv.org/pdf/2311.16201v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15583v1",
            "title": "A Simple Geometric-Aware Indoor Positioning Interpolation Algorithm\n  Based on Manifold Learning",
            "updated": "2023-11-27T07:19:23Z",
            "published": "2023-11-27T07:19:23Z",
            "summary": "Interpolation methodologies have been widely used within the domain of indoor\npositioning systems. However, existing indoor positioning interpolation\nalgorithms exhibit several inherent limitations, including reliance on complex\nmathematical models, limited flexibility, and relatively low precision. To\nenhance the accuracy and efficiency of indoor positioning interpolation\ntechniques, this paper proposes a simple yet powerful geometric-aware\ninterpolation algorithm for indoor positioning tasks. The key to our algorithm\nis to exploit the geometric attributes of the local topological manifold using\nmanifold learning principles. Therefore, instead of constructing complicated\nmathematical models, the proposed algorithm facilitates the more precise and\nefficient estimation of points grounded in the local topological manifold.\nMoreover, our proposed method can be effortlessly integrated into any indoor\npositioning system, thereby bolstering its adaptability. Through a systematic\narray of experiments and comprehensive performance analyses conducted on both\nsimulated and real-world datasets, we demonstrate that the proposed algorithm\nconsistently outperforms the most commonly used and representative\ninterpolation approaches regarding interpolation accuracy and efficiency.\nFurthermore, the experimental results also underscore the substantial practical\nutility of our method and its potential applicability in real-time indoor\npositioning scenarios.",
            "author": [
                "Suorong Yang",
                "Geng Zhang",
                "Jian Zhao",
                "Furao Shen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15583v1",
                "http://arxiv.org/pdf/2311.15583v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15582v1",
            "title": "Lightly Weighted Automatic Audio Parameter Extraction for the Quality\n  Assessment of Consensus Auditory-Perceptual Evaluation of Voice",
            "updated": "2023-11-27T07:19:22Z",
            "published": "2023-11-27T07:19:22Z",
            "summary": "The Consensus Auditory-Perceptual Evaluation of Voice is a widely employed\ntool in clinical voice quality assessment that is significant for streaming\ncommunication among clinical professionals and benchmarking for the\ndetermination of further treatment. Currently, because the assessment relies on\nexperienced clinicians, it tends to be inconsistent, and thus, difficult to\nstandardize. To address this problem, we propose to leverage lightly weighted\nautomatic audio parameter extraction, to increase the clinical relevance,\nreduce the complexity, and enhance the interpretability of voice quality\nassessment. The proposed method utilizes age, sex, and five audio parameters:\njitter, absolute jitter, shimmer, harmonic-to-noise ratio (HNR), and zero\ncrossing. A classical machine learning approach is employed. The result reveals\nthat our approach performs similar to state-of-the-art (SOTA) methods, and\noutperforms the latent representation obtained by using popular audio\npre-trained models. This approach provide insights into the feasibility of\ndifferent feature extraction approaches for voice evaluation. Audio parameters\nsuch as jitter and the HNR are proven to be suitable for characterizing voice\nquality attributes, such as roughness and strain. Conversely, pre-trained\nmodels exhibit limitations in effectively addressing noise-related scorings.\nThis study contributes toward more comprehensive and precise voice quality\nevaluations, achieved by a comprehensively exploring diverse assessment\nmethodologies.",
            "author": [
                "Yi-Heng Lin",
                "Wen-Hsuan Tseng",
                "Li-Chin Chen",
                "Ching-Ting Tan",
                "Yu Tsao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15582v1",
                "http://arxiv.org/pdf/2311.15582v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.LG",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15581v1",
            "title": "Real Time GAZED: Online Shot Selection and Editing of Virtual Cameras\n  from Wide-Angle Monocular Video Recordings",
            "updated": "2023-11-27T07:19:10Z",
            "published": "2023-11-27T07:19:10Z",
            "summary": "Eliminating time-consuming post-production processes and delivering\nhigh-quality videos in today's fast-paced digital landscape are the key\nadvantages of real-time approaches. To address these needs, we present Real\nTime GAZED: a real-time adaptation of the GAZED framework integrated with\nCineFilter, a novel real-time camera trajectory stabilization approach. It\nenables users to create professionally edited videos in real-time. Comparative\nevaluations against baseline methods, including the non-real-time GAZED,\ndemonstrate that Real Time GAZED achieves similar editing results, ensuring\nhigh-quality video output. Furthermore, a user study confirms the aesthetic\nquality of the video edits produced by the Real Time GAZED approach. With these\nadvancements in real-time camera trajectory optimization and video editing\npresented, the demand for immediate and dynamic content creation in industries\nsuch as live broadcasting, sports coverage, news reporting, and social media\ncontent creation can be met more efficiently.",
            "author": [
                "Sudheer Achary",
                "Rohit Girmaji",
                "Adhiraj Anil Deshmukh",
                "Vineet Gandhi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15581v1",
                "http://arxiv.org/pdf/2311.15581v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR",
                "cs.HC",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16200v1",
            "title": "Streaming Lossless Volumetric Compression of Medical Images Using Gated\n  Recurrent Convolutional Neural Network",
            "updated": "2023-11-27T07:19:09Z",
            "published": "2023-11-27T07:19:09Z",
            "summary": "Deep learning-based lossless compression methods offer substantial advantages\nin compressing medical volumetric images. Nevertheless, many learning-based\nalgorithms encounter a trade-off between practicality and compression\nperformance. This paper introduces a hardware-friendly streaming lossless\nvolumetric compression framework, utilizing merely one-thousandth of the model\nweights compared to other learning-based compression frameworks. We propose a\ngated recurrent convolutional neural network that combines diverse\nconvolutional structures and fusion gate mechanisms to capture the inter-slice\ndependencies in volumetric images. Based on such contextual information, we can\npredict the pixel-by-pixel distribution for entropy coding. Guided by\nhardware/software co-design principles, we implement the proposed framework on\nField Programmable Gate Array to achieve enhanced real-time performance.\nExtensive experimental results indicate that our method outperforms traditional\nlossless volumetric compressors and state-of-the-art learning-based lossless\ncompression methods across various medical image benchmarks. Additionally, our\nmethod exhibits robust generalization ability and competitive compression speed",
            "author": [
                "Qianhao Chen",
                "Jietao Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16200v1",
                "http://arxiv.org/pdf/2311.16200v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.AR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15580v1",
            "title": "Erasure-cooling, control, and hyper-entanglement of motion in optical\n  tweezers",
            "updated": "2023-11-27T07:17:56Z",
            "published": "2023-11-27T07:17:56Z",
            "summary": "We demonstrate how motional degrees of freedom in optical tweezers can be\nused as quantum information carriers. To this end, we first implement a\nspecies-agnostic cooling mechanism via conversion of motional excitations into\nerasures - errors with a known location - reminiscent of Maxwell's demon\nthought experiment. We find that this cooling mechanism fundamentally\noutperforms idealized traditional sideband cooling, which we experimentally\ndemonstrate in specific scenarios. By coherently manipulating the motional\nstate, we perform mid-circuit readout and mid-circuit erasure detection of an\noptical qubit via local shelving into motional superposition states. We finally\nentangle the motion of two atoms in separate tweezers, and utilize this to\ngenerate hyper-entanglement by preparing a simultaneous Bell state of motional\nand optical qubits. This work shows how controlling motion enriches the toolbox\nof quantum information processing with neutral atoms, and opens unique\nprospects for metrology enhanced by mid-circuit readout and a large class of\nquantum operations enabled via hyper-entanglement.",
            "author": [
                "Pascal Scholl",
                "Adam L. Shaw",
                "Ran Finkelstein",
                "Richard Bing-Shiun Tsai",
                "Joonhee Choi",
                "Manuel Endres"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15580v1",
                "http://arxiv.org/pdf/2311.15580v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cond-mat.quant-gas",
                "physics.atom-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15574v1",
            "title": "Unconventional superconductivity and paramagnetic Meissner response\n  triggered by nonlocal pairing interaction in proximitized heterostructures",
            "updated": "2023-11-27T06:59:48Z",
            "published": "2023-11-27T06:59:48Z",
            "summary": "Proximity phenomena and induced superconducting correlations in\nheterostructures are shown to be strongly affected by the nonlocal nature of\nthe electronic attraction. The latter can trigger the formation of Cooper pairs\nconsisting of electrons localized in neighbouring layers even in the absence of\ndirect quasiparticle transfer between the layers. We investigate the\nmanifestations of such nonlocal pairing and resulting unconventional induced\nsuperconductivity in an exemplary two-dimensional (2D) electronic system\ncoupled to a conventional superconductor. The interplay between the\nquasiparticle tunneling and spin-triplet interlayer pairing is shown to\ngenerate the odd-frequency superconducting correlations in the 2D material\nwhich give rise to the paramagnetic contribution to the Meissner response and\naffect the energy resolved quasiparticle density of states. Experimental\nevidence for the above nonlocal interface pairing would provide new\nperspectives in engineering the unconventional superconducting correlations in\nheterostructures.",
            "author": [
                "A. A. Kopasov",
                "A. S. Mel'nikov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15574v1",
                "http://arxiv.org/pdf/2311.15574v1"
            ],
            "primary_category": "cond-mat.supr-con",
            "category": [
                "cond-mat.supr-con",
                "cond-mat.mes-hall"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15573v1",
            "title": "EucliDreamer: Fast and High-Quality Texturing for 3D Models with Stable\n  Diffusion Depth",
            "updated": "2023-11-27T06:55:53Z",
            "published": "2023-11-27T06:55:53Z",
            "summary": "This paper presents a novel method to generate textures for 3D models given\ntext prompts and 3D meshes. Additional depth information is taken into account\nto perform the Score Distillation Sampling (SDS) process [28] with depth\nconditional Stable Diffusion [34]. We ran our model over the open-source\ndataset Objaverse [7] and conducted a user study to compare the results with\nthose of various 3D texturing methods. We have shown that our model can\ngenerate more satisfactory results and produce various art styles for the same\nobject. In addition, we achieved faster time when generating textures of\ncomparable quality. We also conduct thorough ablation studies of how different\nfactors may affect generation quality, including sampling steps, guidance\nscale, negative prompts, data augmentation, elevation range, and alternatives\nto SDS.",
            "author": [
                "Cindy Le",
                "Congrui Hetang",
                "Ang Cao",
                "Yihui He"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15573v1",
                "http://arxiv.org/pdf/2311.15573v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15572v1",
            "title": "Shaping dynamical neural computations using spatiotemporal constraints",
            "updated": "2023-11-27T06:45:31Z",
            "published": "2023-11-27T06:45:31Z",
            "summary": "Dynamics play a critical role in computation. The principled evolution of\nstates over time enables both biological and artificial networks to represent\nand integrate information to make decisions. In the past few decades,\nsignificant multidisciplinary progress has been made in bridging the gap\nbetween how we understand biological versus artificial computation, including\nhow insights gained from one can translate to the other. Research has revealed\nthat neurobiology is a key determinant of brain network architecture, which\ngives rise to spatiotemporally constrained patterns of activity that underlie\ncomputation. Here, we discuss how neural systems use dynamics for computation,\nand claim that the biological constraints that shape brain networks may be\nleveraged to improve the implementation of artificial neural networks. To\nformalize this discussion, we consider a natural artificial analog of the brain\nthat has been used extensively to model neural computation: the recurrent\nneural network (RNN). In both the brain and the RNN, we emphasize the common\ncomputational substrate atop which dynamics occur -- the connectivity between\nneurons -- and we explore the unique computational advantages offered by\nbiophysical constraints such as resource efficiency, spatial embedding, and\nneurodevelopment.",
            "author": [
                "Jason Z. Kim",
                "Bart Larsen",
                "Linden Parkes"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15572v1",
                "http://arxiv.org/pdf/2311.15572v1"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15569v1",
            "title": "Improving Adaptability and Generalizability of Efficient Transfer\n  Learning for Vision-Language Models",
            "updated": "2023-11-27T06:37:05Z",
            "published": "2023-11-27T06:37:05Z",
            "summary": "Vision-Language Models (VLMs) like CLIP have demonstrated remarkable\napplicability across a variety of downstream tasks, including zero-shot image\nclassification. Recently, the use of prompts or adapters for efficient transfer\nlearning has gained significant attention for effectively adapting to\ndownstream tasks. However, the roles of vision and text prompts, as well as\nadapters in terms of generalization and transfer difficulty, have been\noverlooked, limiting performance on unseen tasks. In this paper, we empirically\nanalyze how VLMs behave when using vision and text prompts, adapters, and a\ncombination of these components, marking a novel exploration by our study. Our\nobservations find that utilizing vision prompts for class separability and text\nadapters for task adaptation is crucial for adaptability and generalizability.\nMoreover, to improve generalization across every domain, we propose an adaptive\nensemble method that effectively combines the general knowledge of VLMs with\ntask-specific knowledge according to transfer difficulty. Upon experimenting\nwith extensive benchmarks, our method consistently outperforms all baselines,\nparticularly on unseen tasks, demonstrating the effectiveness of our proposed\napproach.",
            "author": [
                "Yongjin Yang",
                "Jongwoo Ko",
                "Se-Young Yun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15569v1",
                "http://arxiv.org/pdf/2311.15569v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15566v1",
            "title": "SpotServe: Serving Generative Large Language Models on Preemptible\n  Instances",
            "updated": "2023-11-27T06:31:17Z",
            "published": "2023-11-27T06:31:17Z",
            "summary": "The high computational and memory requirements of generative large language\nmodels (LLMs) make it challenging to serve them cheaply. This paper aims to\nreduce the monetary cost for serving LLMs by leveraging preemptible GPU\ninstances on modern clouds, which offer accesses to spare GPUs at a much\ncheaper price than regular instances but may be preempted by the cloud at any\ntime. Serving LLMs on preemptible instances requires addressing challenges\ninduced by frequent instance preemptions and the necessity of migrating\ninstances to handle these preemptions.\n  This paper presents SpotServe, the first distributed LLM serving system on\npreemptible instances. Several key techniques in SpotServe realize fast and\nreliable serving of generative LLMs on cheap preemptible instances. First,\nSpotServe dynamically adapts the LLM parallelization configuration for dynamic\ninstance availability and fluctuating workload, while balancing the trade-off\namong the overall throughput, inference latency and monetary costs. Second, to\nminimize the cost of migrating instances for dynamic reparallelization, the\ntask of migrating instances is formulated as a bipartite graph matching\nproblem, which uses the Kuhn-Munkres algorithm to identify an optimal migration\nplan that minimizes communications. Finally, to take advantage of the grace\nperiod offered by modern clouds, we introduce stateful inference recovery, a\nnew inference mechanism that commits inference progress at a much finer\ngranularity and allows SpotServe to cheaply resume inference upon preemption.\nWe evaluate on real spot instance preemption traces and various popular LLMs\nand show that SpotServe can reduce the P99 tail latency by 2.4 - 9.1x compared\nwith the best existing LLM serving systems. We also show that SpotServe can\nleverage the price advantage of preemptive instances, saving 54% monetary cost\ncompared with only using on-demand instances.",
            "author": [
                "Xupeng Miao",
                "Chunan Shi",
                "Jiangfei Duan",
                "Xiaoli Xi",
                "Dahua Lin",
                "Bin Cui",
                "Zhihao Jia"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15566v1",
                "http://arxiv.org/pdf/2311.15566v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15565v2",
            "title": "Evaluating the Efficacy of Hybrid Deep Learning Models in Distinguishing\n  AI-Generated Text",
            "updated": "2023-12-02T21:06:50Z",
            "published": "2023-11-27T06:26:53Z",
            "summary": "My research investigates the use of cutting-edge hybrid deep learning models\nto accurately differentiate between AI-generated text and human writing. I\napplied a robust methodology, utilising a carefully selected dataset comprising\nAI and human texts from various sources, each tagged with instructions.\nAdvanced natural language processing techniques facilitated the analysis of\ntextual features. Combining sophisticated neural networks, the custom model\nenabled it to detect nuanced differences between AI and human content.",
            "author": [
                "Finbarrs Oketunji"
            ],
            "link": [
                "http://dx.doi.org/10.5281/zenodo.10251778",
                "http://arxiv.org/abs/2311.15565v2",
                "http://arxiv.org/pdf/2311.15565v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG",
                "I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15564v1",
            "title": "Boot and Switch: Alternating Distillation for Zero-Shot Dense Retrieval",
            "updated": "2023-11-27T06:22:57Z",
            "published": "2023-11-27T06:22:57Z",
            "summary": "Neural 'dense' retrieval models are state of the art for many datasets,\nhowever these models often exhibit limited domain transfer ability. Existing\napproaches to adaptation are unwieldy, such as requiring explicit supervision,\ncomplex model architectures, or massive external models. We present\n$\\texttt{ABEL}$, a simple but effective unsupervised method to enhance passage\nretrieval in zero-shot settings. Our technique follows a straightforward loop:\na dense retriever learns from supervision signals provided by a reranker, and\nsubsequently, the reranker is updated based on feedback from the improved\nretriever. By iterating this loop, the two components mutually enhance one\nanother's performance. Experimental results demonstrate that our unsupervised\n$\\texttt{ABEL}$ model outperforms both leading supervised and unsupervised\nretrievers on the BEIR benchmark. Meanwhile, it exhibits strong adaptation\nabilities to tasks and domains that were unseen during training. By either\nfine-tuning $\\texttt{ABEL}$ on labelled data or integrating it with existing\nsupervised dense retrievers, we achieve state-of-the-art\nresults.\\footnote{Source code is available at\n\\url{https://github.com/Fantabulous-J/BootSwitch}.}",
            "author": [
                "Fan Jiang",
                "Qiongkai Xu",
                "Tom Drummond",
                "Trevor Cohn"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15564v1",
                "http://arxiv.org/pdf/2311.15564v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15563v1",
            "title": "Noisy Self-Training with Synthetic Queries for Dense Retrieval",
            "updated": "2023-11-27T06:19:50Z",
            "published": "2023-11-27T06:19:50Z",
            "summary": "Although existing neural retrieval models reveal promising results when\ntraining data is abundant and the performance keeps improving as training data\nincreases, collecting high-quality annotated data is prohibitively costly. To\nthis end, we introduce a novel noisy self-training framework combined with\nsynthetic queries, showing that neural retrievers can be improved in a\nself-evolution manner with no reliance on any external models. Experimental\nresults show that our method improves consistently over existing methods on\nboth general-domain (e.g., MS-MARCO) and out-of-domain (i.e., BEIR) retrieval\nbenchmarks. Extra analysis on low-resource settings reveals that our method is\ndata efficient and outperforms competitive baselines, with as little as 30% of\nlabelled training data. Further extending the framework for reranker training\ndemonstrates that the proposed method is general and yields additional gains on\ntasks of diverse domains.\\footnote{Source code is available at\n\\url{https://github.com/Fantabulous-J/Self-Training-DPR}}",
            "author": [
                "Fan Jiang",
                "Tom Drummond",
                "Trevor Cohn"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15563v1",
                "http://arxiv.org/pdf/2311.15563v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15562v1",
            "title": "Fully Authentic Visual Question Answering Dataset from Online\n  Communities",
            "updated": "2023-11-27T06:19:00Z",
            "published": "2023-11-27T06:19:00Z",
            "summary": "Visual Question Answering (VQA) entails answering questions about images. We\nintroduce the first VQA dataset in which all contents originate from an\nauthentic use case. Sourced from online question answering community forums, we\ncall it VQAonline. We then characterize our dataset and how it relates to eight\nother VQA datasets. Observing that answers in our dataset tend to be much\nlonger (e.g., with a mean of 173 words) and thus incompatible with standard VQA\nevaluation metrics, we next analyze which of the six popular metrics for longer\ntext evaluation align best with human judgments. We then use the best-suited\nmetrics to evaluate six state-of-the-art vision and language foundation models\non VQAonline and reveal where they struggle most. We will release the dataset\nsoon to facilitate future extensions.",
            "author": [
                "Chongyan Chen",
                "Mengchen Liu",
                "Noel Codella",
                "Yunsheng Li",
                "Lu Yuan",
                "Danna Gurari"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15562v1",
                "http://arxiv.org/pdf/2311.15562v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15560v1",
            "title": "The influence of pinholes and weak-points in aluminium-oxide Josephson\n  junctions",
            "updated": "2023-11-27T06:13:39Z",
            "published": "2023-11-27T06:13:39Z",
            "summary": "Josephson junctions are the key components used in superconducting qubits for\nquantum computing. The advancement of quantum computing is limited by a lack of\nstability and reproducibility of qubits which ultimately originates in the\namorphous tunnel barrier of the Josephson junctions and other material\nimperfections. Pinholes in the junction have been suggested as one of the\npossible contributors to these instabilities, but evidence of their existence\nand the effect they might have on transport is unclear. We use molecular\ndynamics to create three-dimensional atomistic models to describe Al-AlOx-Al\ntunnel junctions, showing that pinholes form when oxidation of the barrier is\nincomplete. Following this we use the atomistic model and simulate the\nelectronic transport properties for tunnel junctions with different barrier\nthicknesses using the non-equilibrium Green's function formalism. We observe\nthat pinholes may contribute to excess quasiparticle current flow in Al-AlOx-Al\ntunnel junctions with thinner barriers, and in thicker barriers we observe\nweak-points which facilitate leakage currents even when the oxide is\ncontinuous. We find that the disordered nature of the amorphous barrier results\nin significant variations in the transport properties. Additionally, we\ndetermine the current-phase relationship for our atomistic structures,\nconfirming that devices with pinholes and weak-points cause a deviation from\nthe ideal sinusoidal Josephson relationship.",
            "author": [
                "K. Bayros",
                "M. J. Cyster",
                "J. S. Smith",
                "J. H. Cole"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15560v1",
                "http://arxiv.org/pdf/2311.15560v1"
            ],
            "primary_category": "cond-mat.mes-hall",
            "category": [
                "cond-mat.mes-hall",
                "cond-mat.supr-con",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15556v2",
            "title": "PKU-I2IQA: An Image-to-Image Quality Assessment Database for AI\n  Generated Images",
            "updated": "2023-11-29T14:16:08Z",
            "published": "2023-11-27T05:53:03Z",
            "summary": "As image generation technology advances, AI-based image generation has been\napplied in various fields and Artificial Intelligence Generated Content (AIGC)\nhas garnered widespread attention. However, the development of AI-based image\ngenerative models also brings new problems and challenges. A significant\nchallenge is that AI-generated images (AIGI) may exhibit unique distortions\ncompared to natural images, and not all generated images meet the requirements\nof the real world. Therefore, it is of great significance to evaluate AIGIs\nmore comprehensively. Although previous work has established several human\nperception-based AIGC image quality assessment (AIGCIQA) databases for\ntext-generated images, the AI image generation technology includes scenarios\nlike text-to-image and image-to-image, and assessing only the images generated\nby text-to-image models is insufficient. To address this issue, we establish a\nhuman perception-based image-to-image AIGCIQA database, named PKU-I2IQA. We\nconduct a well-organized subjective experiment to collect quality labels for\nAIGIs and then conduct a comprehensive analysis of the PKU-I2IQA database.\nFurthermore, we have proposed two benchmark models: NR-AIGCIQA based on the\nno-reference image quality assessment method and FR-AIGCIQA based on the\nfull-reference image quality assessment method. Finally, leveraging this\ndatabase, we conduct benchmark experiments and compare the performance of the\nproposed benchmark models. The PKU-I2IQA database and benchmarks will be\nreleased to facilitate future research on\n\\url{https://github.com/jiquan123/I2IQA}.",
            "author": [
                "Jiquan Yuan",
                "Xinyan Cao",
                "Changjin Li",
                "Fanyi Yang",
                "Jinlong Lin",
                "Xixin Cao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15556v2",
                "http://arxiv.org/pdf/2311.15556v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15555v1",
            "title": "One-dimensional moire chains with partially-filled flat bands in\n  two-dimensional twisted bilayer WSe2",
            "updated": "2023-11-27T05:44:39Z",
            "published": "2023-11-27T05:44:39Z",
            "summary": "Two-dimensional (2D) moire systems based on twisted bilayer graphene and\ntransition metal dichalcogenides provide a promising platform to investigate\nemergent phenomena driven by strong electron-electron interactions in\npartially-filled flat bands1-11. A natural question arises: is it possible to\nexpand the 2D correlated moire physics to one-dimensional (1D)? This requires\nselectively doping of 1D moire chain embedded in the 2D moire systems, which is\nan outstanding challenge in experiment and seems to be not within the grasp of\ntoday's technology. Therefore, an experimental demonstration of the 1D moire\nchain with partially-filled flat bands remains absent. Here we show that we can\nintroduce 1D boundaries, separating two regions with different twist angles, in\ntwisted bilayer WSe2 (tWSe2) by using scanning tunneling microscopy (STM), and\ndemonstrate that the flat bands of moire sites along the 1D boundaries can be\nselectively filled. The charge and discharge states of correlated moire\nelectrons in the 1D moire chain can be directly imaged and manipulated by\ncombining a back-gate voltage with the STM bias. Our results open the door for\nrealizing new correlated electronic states of the 1D moire chain in 2D systems.",
            "author": [
                "Ya-Ning Ren",
                "Hui-Ying Ren",
                "Kenji Watanabe",
                "Takashi Taniguchi",
                "Lin He"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15555v1",
                "http://arxiv.org/pdf/2311.15555v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "cond-mat.mes-hall"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15551v1",
            "title": "Instruct2Attack: Language-Guided Semantic Adversarial Attacks",
            "updated": "2023-11-27T05:35:49Z",
            "published": "2023-11-27T05:35:49Z",
            "summary": "We propose Instruct2Attack (I2A), a language-guided semantic attack that\ngenerates semantically meaningful perturbations according to free-form language\ninstructions. We make use of state-of-the-art latent diffusion models, where we\nadversarially guide the reverse diffusion process to search for an adversarial\nlatent code conditioned on the input image and text instruction. Compared to\nexisting noise-based and semantic attacks, I2A generates more natural and\ndiverse adversarial examples while providing better controllability and\ninterpretability. We further automate the attack process with GPT-4 to generate\ndiverse image-specific text instructions. We show that I2A can successfully\nbreak state-of-the-art deep neural networks even under strong adversarial\ndefenses, and demonstrate great transferability among a variety of network\narchitectures.",
            "author": [
                "Jiang Liu",
                "Chen Wei",
                "Yuxiang Guo",
                "Heng Yu",
                "Alan Yuille",
                "Soheil Feizi",
                "Chun Pong Lau",
                "Rama Chellappa"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15551v1",
                "http://arxiv.org/pdf/2311.15551v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CR",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15549v2",
            "title": "From Prediction to Action: Critical Role of Performance Estimation for\n  Machine-Learning-Driven Materials Discovery",
            "updated": "2023-12-07T02:08:13Z",
            "published": "2023-11-27T05:29:43Z",
            "summary": "Materials discovery driven by statistical property models is an iterative\ndecision process, during which an initial data collection is extended with new\ndata proposed by a model-informed acquisition function--with the goal to\nmaximize a certain \"reward\" over time, such as the maximum property value\ndiscovered so far. While the materials science community achieved much progress\nin developing property models that predict well on average with respect to the\ntraining distribution, this form of in-distribution performance measurement is\nnot directly coupled with the discovery reward. This is because an iterative\ndiscovery process has a shifting reward distribution that is\nover-proportionally determined by the model performance for exceptional\nmaterials. We demonstrate this problem using the example of bulk modulus\nmaximization among double perovskite oxides. We find that the in-distribution\npredictive performance suggests random forests as superior to Gaussian process\nregression, while the results are inverse in terms of the discovery rewards. We\nargue that the lack of proper performance estimation methods from pre-computed\ndata collections is a fundamental problem for improving data-driven materials\ndiscovery, and we propose a novel such estimator that, in contrast to na\\\"ive\nreward estimation, successfully predicts Gaussian processes with the \"expected\nimprovement\" acquisition function as the best out of four options in our\ndemonstrational study for double perovskites. Importantly, it does so without\nrequiring the over thousand ab initio computations that were needed to confirm\nthis prediction.",
            "author": [
                "Mario Boley",
                "Felix Luong",
                "Simon Teshuva",
                "Daniel F Schmidt",
                "Lucas Foppa",
                "Matthias Scheffler"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15549v2",
                "http://arxiv.org/pdf/2311.15549v2"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15548v1",
            "title": "Deficiency of Large Language Models in Finance: An Empirical Examination\n  of Hallucination",
            "updated": "2023-11-27T05:27:13Z",
            "published": "2023-11-27T05:27:13Z",
            "summary": "The hallucination issue is recognized as a fundamental deficiency of large\nlanguage models (LLMs), especially when applied to fields such as finance,\neducation, and law. Despite the growing concerns, there has been a lack of\nempirical investigation. In this paper, we provide an empirical examination of\nLLMs' hallucination behaviors in financial tasks. First, we empirically\ninvestigate LLM model's ability of explaining financial concepts and\nterminologies. Second, we assess LLM models' capacity of querying historical\nstock prices. Third, to alleviate the hallucination issue, we evaluate the\nefficacy of four practical methods, including few-shot learning, Decoding by\nContrasting Layers (DoLa), the Retrieval Augmentation Generation (RAG) method\nand the prompt-based tool learning method for a function to generate a query\ncommand. Finally, our major finding is that off-the-shelf LLMs experience\nserious hallucination behaviors in financial tasks. Therefore, there is an\nurgent need to call for research efforts in mitigating LLMs' hallucination.",
            "author": [
                "Haoqiang Kang",
                "Xiao-Yang Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15548v1",
                "http://arxiv.org/pdf/2311.15548v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG",
                "q-fin.ST"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15547v1",
            "title": "Dataset Distillation in Latent Space",
            "updated": "2023-11-27T05:23:01Z",
            "published": "2023-11-27T05:23:01Z",
            "summary": "Dataset distillation (DD) is a newly emerging research area aiming at\nalleviating the heavy computational load in training models on large datasets.\nIt tries to distill a large dataset into a small and condensed one so that\nmodels trained on the distilled dataset can perform comparably with those\ntrained on the full dataset when performing downstream tasks. Among the\nprevious works in this area, there are three key problems that hinder the\nperformance and availability of the existing DD methods: high time complexity,\nhigh space complexity, and low info-compactness. In this work, we\nsimultaneously attempt to settle these three problems by moving the DD\nprocesses from conventionally used pixel space to latent space. Encoded by a\npretrained generic autoencoder, latent codes in the latent space are naturally\ninfo-compact representations of the original images in much smaller sizes.\nAfter transferring three mainstream DD algorithms to latent space, we\nsignificantly reduce time and space consumption while achieving similar\nperformance, allowing us to distill high-resolution datasets or target at\ngreater data ratio that previous methods have failed. Besides, within the same\nstorage budget, we can also quantitatively deliver more latent codes than\npixel-level images, which further boosts the performance of our methods.",
            "author": [
                "Yuxuan Duan",
                "Jianfu Zhang",
                "Liqing Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15547v1",
                "http://arxiv.org/pdf/2311.15547v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15544v2",
            "title": "The effect of source disclosure on evaluation of AI-generated messages:\n  A two-part study",
            "updated": "2023-11-28T02:04:58Z",
            "published": "2023-11-27T05:20:47Z",
            "summary": "Advancements in artificial intelligence (AI) over the last decade demonstrate\nthat machines can exhibit communicative behavior and influence how humans\nthink, feel, and behave. In fact, the recent development of ChatGPT has shown\nthat large language models (LLMs) can be leveraged to generate high-quality\ncommunication content at scale and across domains, suggesting that they will be\nincreasingly used in practice. However, many questions remain about how knowing\nthe source of the messages influences recipients' evaluation of and preference\nfor AI-generated messages compared to human-generated messages. This paper\ninvestigated this topic in the context of vaping prevention messaging. In Study\n1, which was pre-registered, we examined the influence of source disclosure on\npeople's evaluation of AI-generated health prevention messages compared to\nhuman-generated messages. We found that source disclosure (i.e., labeling the\nsource of a message as AI vs. human) significantly impacted the evaluation of\nthe messages but did not significantly alter message rankings. In a follow-up\nstudy (Study 2), we examined how the influence of source disclosure may vary by\nthe participants' negative attitudes towards AI. We found a significant\nmoderating effect of negative attitudes towards AI on message evaluation, but\nnot for message selection. However, for those with moderate levels of negative\nattitudes towards AI, source disclosure decreased the preference for\nAI-generated messages. Overall, the results of this series of studies showed a\nslight bias against AI-generated messages once the source was disclosed, adding\nto the emerging area of study that lies at the intersection of AI and\ncommunication.",
            "author": [
                "Sue Lim",
                "Ralf Schm\u00e4lzle"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15544v2",
                "http://arxiv.org/pdf/2311.15544v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15543v1",
            "title": "Beyond Pixels: Exploring Human-Readable SVG Generation for Simple Images\n  with Vision Language Models",
            "updated": "2023-11-27T05:20:11Z",
            "published": "2023-11-27T05:20:11Z",
            "summary": "In the field of computer graphics, the use of vector graphics, particularly\nScalable Vector Graphics (SVG), represents a notable development from\ntraditional pixel-based imagery. SVGs, with their XML-based format, are\ndistinct in their ability to directly and explicitly represent visual elements\nsuch as shape, color, and path. This direct representation facilitates a more\naccurate and logical depiction of graphical elements, enhancing reasoning and\ninterpretability. Recognizing the potential of SVGs, the machine learning\ncommunity has introduced multiple methods for image vectorization. However,\ntransforming images into SVG format while retaining the relational properties\nand context of the original scene remains a key challenge. Most vectorization\nmethods often yield SVGs that are overly complex and not easily interpretable.\nIn response to this challenge, we introduce our method, Simple-SVG-Generation\n(S\\textsuperscript{2}VG\\textsuperscript{2}). Our method focuses on producing\nSVGs that are both accurate and simple, aligning with human readability and\nunderstanding. With simple images, we evaluate our method with reasoning tasks\ntogether with advanced language models, the results show a clear improvement\nover previous SVG generation methods. We also conducted surveys for human\nevaluation on the readability of our generated SVGs, the results also favor our\nmethods.",
            "author": [
                "Tong Zhang",
                "Haoyang Liu",
                "Peiyan Zhang",
                "Yuxuan Cheng",
                "Haohan Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15543v1",
                "http://arxiv.org/pdf/2311.15543v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15540v1",
            "title": "EAFP-Med: An Efficient Adaptive Feature Processing Module Based on\n  Prompts for Medical Image Detection",
            "updated": "2023-11-27T05:10:15Z",
            "published": "2023-11-27T05:10:15Z",
            "summary": "In the face of rapid advances in medical imaging, cross-domain adaptive\nmedical image detection is challenging due to the differences in lesion\nrepresentations across various medical imaging technologies. To address this\nissue, we draw inspiration from large language models to propose EAFP-Med, an\nefficient adaptive feature processing module based on prompts for medical image\ndetection. EAFP-Med can efficiently extract lesion features of different scales\nfrom a diverse range of medical images based on prompts while being flexible\nand not limited by specific imaging techniques. Furthermore, it serves as a\nfeature preprocessing module that can be connected to any model front-end to\nenhance the lesion features in input images. Moreover, we propose a novel\nadaptive disease detection model named EAFP-Med ST, which utilizes the Swin\nTransformer V2 - Tiny (SwinV2-T) as its backbone and connects it to EAFP-Med.\nWe have compared our method to nine state-of-the-art methods. Experimental\nresults demonstrate that EAFP-Med ST achieves the best performance on all three\ndatasets (chest X-ray images, cranial magnetic resonance imaging images, and\nskin images). EAFP-Med can efficiently extract lesion features from various\nmedical images based on prompts, enhancing the model's performance. This holds\nsignificant potential for improving medical image analysis and diagnosis.",
            "author": [
                "Xiang Li",
                "Long Lan",
                "Husam Lahza",
                "Shaowu Yang",
                "Shuihua Wang",
                "Wenjing Yang",
                "Hengzhu Liu",
                "Yudong Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15540v1",
                "http://arxiv.org/pdf/2311.15540v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16480v1",
            "title": "MI-Gen: Multiple Instance Generation of Pathology Reports for Gigapixel\n  Whole-Slide Images",
            "updated": "2023-11-27T05:05:41Z",
            "published": "2023-11-27T05:05:41Z",
            "summary": "Whole slide images are the foundation of digital pathology for the diagnosis\nand treatment of carcinomas. Writing pathology reports is laborious and\nerror-prone for inexperienced pathologists. To reduce the workload and improve\nclinical automation, we investigate how to generate pathology reports given\nwhole slide images. On the data end, we curated the largest WSI-text dataset\n(TCGA-PathoText). In specific, we collected nearly 10000 high-quality WSI-text\npairs for visual-language models by recognizing and cleaning pathology reports\nwhich narrate diagnostic slides in TCGA. On the model end, we propose the\nmultiple instance generative model (MI-Gen) which can produce pathology reports\nfor gigapixel WSIs. We benchmark our model on the largest subset of\nTCGA-PathoText. Experimental results show our model can generate pathology\nreports which contain multiple clinical clues. Furthermore, WSI-text prediction\ncan be seen as an approach of visual-language pre-training, which enables our\nmodel to be transferred to downstream diagnostic tasks like carcinoma grading\nand phenotyping. We observe that simple semantic extraction from the pathology\nreports can achieve the best performance (0.838 of F1 score) on BRCA subtyping\nwithout adding extra parameters or tricky fine-tuning. Our collected dataset\nand related code will all be publicly available.",
            "author": [
                "Pingyi Chen",
                "Honglin Li",
                "Chenglu Zhu",
                "Sunyi Zheng",
                "Lin Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16480v1",
                "http://arxiv.org/pdf/2311.16480v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15539v1",
            "title": "A Novel Human-Based Meta-Heuristic Algorithm: Dragon Boat Optimization",
            "updated": "2023-11-27T05:04:38Z",
            "published": "2023-11-27T05:04:38Z",
            "summary": "(Aim) Dragon Boat Racing, a popular aquatic folklore team sport, is\ntraditionally held during the Dragon Boat Festival. Inspired by this event, we\npropose a novel human-based meta-heuristic algorithm called dragon boat\noptimization (DBO) in this paper. (Method) It models the unique behaviors of\neach crew member on the dragon boat during the race by introducing social\npsychology mechanisms (social loafing, social incentive). Throughout this\nprocess, the focus is on the interaction and collaboration among the crew\nmembers, as well as their decision-making in different situations. During each\niteration, DBO implements different state updating strategies. By modelling the\ncrew's behavior and adjusting the state updating strategies, DBO is able to\nmaintain high-performance efficiency. (Results) We have tested the DBO\nalgorithm with 29 mathematical optimization problems and 2 structural design\nproblems. (Conclusion) The experimental results demonstrate that DBO is\ncompetitive with state-of-the-art meta-heuristic algorithms as well as\nconventional methods.",
            "author": [
                "Xiang Li",
                "Long Lan",
                "Husam Lahza",
                "Shaowu Yang",
                "Shuihua Wang",
                "Wenjing Yang",
                "Hengzhu Liu",
                "Yudong Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15539v1",
                "http://arxiv.org/pdf/2311.15539v1"
            ],
            "primary_category": "stat.CO",
            "category": [
                "stat.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15537v1",
            "title": "SED: A Simple Encoder-Decoder for Open-Vocabulary Semantic Segmentation",
            "updated": "2023-11-27T05:00:38Z",
            "published": "2023-11-27T05:00:38Z",
            "summary": "Open-vocabulary semantic segmentation strives to distinguish pixels into\ndifferent semantic groups from an open set of categories. Most existing methods\nexplore utilizing pre-trained vision-language models, in which the key is to\nadopt the image-level model for pixel-level segmentation task. In this paper,\nwe propose a simple encoder-decoder, named SED, for open-vocabulary semantic\nsegmentation, which comprises a hierarchical encoder-based cost map generation\nand a gradual fusion decoder with category early rejection. The hierarchical\nencoder-based cost map generation employs hierarchical backbone, instead of\nplain transformer, to predict pixel-level image-text cost map. Compared to\nplain transformer, hierarchical backbone better captures local spatial\ninformation and has linear computational complexity with respect to input size.\nOur gradual fusion decoder employs a top-down structure to combine cost map and\nthe feature maps of different backbone levels for segmentation. To accelerate\ninference speed, we introduce a category early rejection scheme in the decoder\nthat rejects many no-existing categories at the early layer of decoder,\nresulting in at most 4.7 times acceleration without accuracy degradation.\nExperiments are performed on multiple open-vocabulary semantic segmentation\ndatasets, which demonstrates the efficacy of our SED method. When using\nConvNeXt-B, our SED method achieves mIoU score of 31.6\\% on ADE20K with 150\ncategories at 82 millisecond ($ms$) per image on a single A6000. We will\nrelease it at \\url{https://github.com/xb534/SED.git}.",
            "author": [
                "Bin Xie",
                "Jiale Cao",
                "Jin Xie",
                "Fahad Shahbaz Khan",
                "Yanwei Pang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15537v1",
                "http://arxiv.org/pdf/2311.15537v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.03725v1",
            "title": "SCStory: Self-supervised and Continual Online Story Discovery",
            "updated": "2023-11-27T04:50:01Z",
            "published": "2023-11-27T04:50:01Z",
            "summary": "We present a framework SCStory for online story discovery, that helps people\ndigest rapidly published news article streams in real-time without human\nannotations. To organize news article streams into stories, existing approaches\ndirectly encode the articles and cluster them based on representation\nsimilarity. However, these methods yield noisy and inaccurate story discovery\nresults because the generic article embeddings do not effectively reflect the\nstory-indicative semantics in an article and cannot adapt to the rapidly\nevolving news article streams. SCStory employs self-supervised and continual\nlearning with a novel idea of story-indicative adaptive modeling of news\narticle streams. With a lightweight hierarchical embedding module that first\nlearns sentence representations and then article representations, SCStory\nidentifies story-relevant information of news articles and uses them to\ndiscover stories. The embedding module is continuously updated to adapt to\nevolving news streams with a contrastive learning objective, backed up by two\nunique techniques, confidence-aware memory replay and prioritized-augmentation,\nemployed for label absence and data scarcity problems. Thorough experiments on\nreal and the latest news data sets demonstrate that SCStory outperforms\nexisting state-of-the-art algorithms for unsupervised online story discovery.",
            "author": [
                "Susik Yoon",
                "Yu Meng",
                "Dongha Lee",
                "Jiawei Han"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03725v1",
                "http://arxiv.org/pdf/2312.03725v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15532v1",
            "title": "Detecting the tidal heating with the generic extreme-mass-ratio\n  inspirals",
            "updated": "2023-11-27T04:29:41Z",
            "published": "2023-11-27T04:29:41Z",
            "summary": "The horizon of a classical black hole, functioning as a one-way membrane,\nplays a vital role in the dynamic evolution of binary objects, capable of\nabsorbing fluxes entirely. Tidal heating, stemming from this phenomenon, exerts\na notable influence on the production of gravitational waves (GWs).This impact\ncan be utilized for model-independent investigations into the nature of massive\nobjects. In this paper, assuming that the extreme-mass-ratio inspiral (EMRI)\ncontains a stellar-mass compact object orbiting around a massive exotic compact\nobject (ECO) with a reflective surface, we compute the GWs from the generic\nEMRI orbits. Using the accurate and analytic flux formulas in the black hole\nspacetime, we adapted these formulas in the vicinity of the ECO surface by\nincorporating a reflectivity parameter. Under the adiabatic approximation, we\ncan evolve the orbital parameters and compute the EMRI waveforms. The effect of\ntidal heating for the spinning and non-spinning objects can be used to\nconstrain the reflectivity of the surface at the level of O(10^-4) by computing\nthe mismatch and Fisher information matrix.",
            "author": [
                "Tieguang Zi",
                "Chang-Qing Ye",
                "Peng-Cheng Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15532v1",
                "http://arxiv.org/pdf/2311.15532v1"
            ],
            "primary_category": "gr-qc",
            "category": [
                "gr-qc",
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15530v1",
            "title": "SSIN: Self-Supervised Learning for Rainfall Spatial Interpolation",
            "updated": "2023-11-27T04:23:47Z",
            "published": "2023-11-27T04:23:47Z",
            "summary": "The acquisition of accurate rainfall distribution in space is an important\ntask in hydrological analysis and natural disaster pre-warning. However, it is\nimpossible to install rain gauges on every corner. Spatial interpolation is a\ncommon way to infer rainfall distribution based on available raingauge data.\nHowever, the existing works rely on some unrealistic pre-settings to capture\nspatial correlations, which limits their performance in real scenarios. To\ntackle this issue, we propose the SSIN, which is a novel data-driven\nself-supervised learning framework for rainfall spatial interpolation by mining\nlatent spatial patterns from historical observation data. Inspired by the Cloze\ntask and BERT, we fully consider the characteristics of spatial interpolation\nand design the SpaFormer model based on the Transformer architecture as the\ncore of SSIN. Our main idea is: by constructing rich self-supervision signals\nvia random masking, SpaFormer can learn informative embeddings for raw data and\nthen adaptively model spatial correlations based on rainfall spatial context.\nExtensive experiments on two real-world raingauge datasets show that our method\noutperforms the state-of-the-art solutions. In addition, we take traffic\nspatial interpolation as another use case to further explore the performance of\nour method, and SpaFormer achieves the best performance on one large real-world\ntraffic dataset, which further confirms the effectiveness and generality of our\nmethod.",
            "author": [
                "Jia Li",
                "Yanyan Shen",
                "Lei Chen",
                "Charles Wang Wai NG"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3589321",
                "http://arxiv.org/abs/2311.15530v1",
                "http://arxiv.org/pdf/2311.15530v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "physics.ao-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15529v1",
            "title": "Efficient Dataset Distillation via Minimax Diffusion",
            "updated": "2023-11-27T04:22:48Z",
            "published": "2023-11-27T04:22:48Z",
            "summary": "Dataset distillation reduces the storage and computational consumption of\ntraining a network by generating a small surrogate dataset that encapsulates\nrich information of the original large-scale one. However, previous\ndistillation methods heavily rely on the sample-wise iterative optimization\nscheme. As the images-per-class (IPC) setting or image resolution grows larger,\nthe necessary computation will demand overwhelming time and resources. In this\nwork, we intend to incorporate generative diffusion techniques for computing\nthe surrogate dataset. Observing that key factors for constructing an effective\nsurrogate dataset are representativeness and diversity, we design additional\nminimax criteria in the generative training to enhance these facets for the\ngenerated images of diffusion models. We present a theoretical model of the\nprocess as hierarchical diffusion control demonstrating the flexibility of the\ndiffusion process to target these criteria without jeopardizing the\nfaithfulness of the sample to the desired distribution. The proposed method\nachieves state-of-the-art validation performance while demanding much less\ncomputational resources. Under the 100-IPC setting on ImageWoof, our method\nrequires less than one-twentieth the distillation time of previous methods, yet\nyields even better performance. Source code available in\nhttps://github.com/vimar-gu/MinimaxDiffusion.",
            "author": [
                "Jianyang Gu",
                "Saeed Vahidian",
                "Vyacheslav Kungurtsev",
                "Haonan Wang",
                "Wei Jiang",
                "Yang You",
                "Yiran Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15529v1",
                "http://arxiv.org/pdf/2311.15529v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15525v1",
            "title": "Overview of the VLSP 2022 -- Abmusu Shared Task: A Data Challenge for\n  Vietnamese Abstractive Multi-document Summarization",
            "updated": "2023-11-27T04:01:13Z",
            "published": "2023-11-27T04:01:13Z",
            "summary": "This paper reports the overview of the VLSP 2022 - Vietnamese abstractive\nmulti-document summarization (Abmusu) shared task for Vietnamese News. This\ntask is hosted at the 9$^{th}$ annual workshop on Vietnamese Language and\nSpeech Processing (VLSP 2022). The goal of Abmusu shared task is to develop\nsummarization systems that could create abstractive summaries automatically for\na set of documents on a topic. The model input is multiple news documents on\nthe same topic, and the corresponding output is a related abstractive summary.\nIn the scope of Abmusu shared task, we only focus on Vietnamese news\nsummarization and build a human-annotated dataset of 1,839 documents in 600\nclusters, collected from Vietnamese news in 8 categories. Participated models\nare evaluated and ranked in terms of \\texttt{ROUGE2-F1} score, the most typical\nevaluation metric for document summarization problem.",
            "author": [
                "Mai-Vu Tran",
                "Hoang-Quynh Le",
                "Duy-Cat Can",
                "Quoc-An Nguyen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15525v1",
                "http://arxiv.org/pdf/2311.15525v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16513v1",
            "title": "Fine-grained Appearance Transfer with Diffusion Models",
            "updated": "2023-11-27T04:00:04Z",
            "published": "2023-11-27T04:00:04Z",
            "summary": "Image-to-image translation (I2I), and particularly its subfield of appearance\ntransfer, which seeks to alter the visual appearance between images while\nmaintaining structural coherence, presents formidable challenges. Despite\nsignificant advancements brought by diffusion models, achieving fine-grained\ntransfer remains complex, particularly in terms of retaining detailed\nstructural elements and ensuring information fidelity. This paper proposes an\ninnovative framework designed to surmount these challenges by integrating\nvarious aspects of semantic matching, appearance transfer, and latent\ndeviation. A pivotal aspect of our approach is the strategic use of the\npredicted $x_0$ space by diffusion models within the latent space of diffusion\nprocesses. This is identified as a crucial element for the precise and natural\ntransfer of fine-grained details. Our framework exploits this space to\naccomplish semantic alignment between source and target images, facilitating\nmask-wise appearance transfer for improved feature acquisition. A significant\nadvancement of our method is the seamless integration of these features into\nthe latent space, enabling more nuanced latent deviations without necessitating\nextensive model retraining or fine-tuning. The effectiveness of our approach is\ndemonstrated through extensive experiments, which showcase its ability to\nadeptly handle fine-grained appearance transfers across a wide range of\ncategories and domains. We provide our code at\nhttps://github.com/babahui/Fine-grained-Appearance-Transfer",
            "author": [
                "Yuteng Ye",
                "Guanwen Li",
                "Hang Zhou",
                "Cai Jiale",
                "Junqing Yu",
                "Yawei Luo",
                "Zikai Song",
                "Qilong Xing",
                "Youjia Zhang",
                "Wei Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16513v1",
                "http://arxiv.org/pdf/2311.16513v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16197v1",
            "title": "Generation of patient specific cardiac chamber models using generative\n  neural networks under a Bayesian framework for electroanatomical mapping",
            "updated": "2023-11-27T03:47:33Z",
            "published": "2023-11-27T03:47:33Z",
            "summary": "Electroanatomical mapping is a technique used in cardiology to create a\ndetailed 3D map of the electrical activity in the heart. It is useful for\ndiagnosis, treatment planning and real time guidance in cardiac ablation\nprocedures to treat arrhythmias like atrial fibrillation. A probabilistic\nmachine learning model trained on a library of CT/MRI scans of the heart can be\nused during electroanatomical mapping to generate a patient-specific 3D model\nof the chamber being mapped. The use of probabilistic machine learning models\nunder a Bayesian framework provides a way to quantify uncertainty in results\nand provide a natural framework of interpretability of the model. Here we\nintroduce a Bayesian approach to surface reconstruction of cardiac chamber\nmodels from a sparse 3D point cloud data acquired during electroanatomical\nmapping. We show how probabilistic graphical models trained on segmented CT/MRI\ndata can be used to generate cardiac chamber models from few acquired locations\nthereby reducing procedure time and x-ray exposure. We show how they provide\ninsight into what the neural network learns from the segmented CT/MRI images\nused to train the network, which provides explainability to the resulting\ncardiac chamber models generated by the model.",
            "author": [
                "Sunil Mathew",
                "Jasbir Sra",
                "Daniel B. Rowe"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16197v1",
                "http://arxiv.org/pdf/2311.16197v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15519v1",
            "title": "Chemo-dynamical Nature of the Anticenter Stream and Monoceros Ring",
            "updated": "2023-11-27T03:45:44Z",
            "published": "2023-11-27T03:45:44Z",
            "summary": "In the epoch of deep photometric surveys, a large number of substructures,\ne.g., over-densities, streams, were identified. With the help of astrometry and\nspectroscopy, the community revealed a complex picture of our Milky Way (MW)\nafter investigating their origins. Off-plane substructures Anticenter Stream\n(ACS) and Monoceros Ring (MNC), once considered as dissolving dwarf galaxies,\nwere later found to share similar kinematics and metallicity with the Galactic\nouter thin disk. In this work, we aim to chemically tag ACS and MNC with\nhigh-accuracy abundances from the APOGEE survey. By extrapolating chemical\nabundance trends in the outer thin disk region (10 < Rgc < 18 kpc, 0 < |Zgc| <\n3kpc), we found that ACS and MNC stars show consistent chemical abundances as\nthe extrapolating values for 12 elements, including C, N, O, Mg, Al, Si, K, Ca,\nCr, Mn, Co and Ni. The similar chemical patterns indicate that ACS and MNC have\nsimilar star formation history as the MW outer thin disk, meanwhile, we also\nexcluded their dwarf galaxy association, as they are distinctive in multiple\nchemical spaces. The ages of ACS and MNC stars are consistent with the time of\nthe first Sgr dSph passage, indicating their possible connection.",
            "author": [
                "Yi Qiao",
                "Baitian Tang",
                "Jianhui Lian",
                "Jing Li",
                "Cheng Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15519v1",
                "http://arxiv.org/pdf/2311.15519v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA",
                "astro-ph.SR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15516v1",
            "title": "Active Foundational Models for Fault Diagnosis of Electrical Motors",
            "updated": "2023-11-27T03:25:12Z",
            "published": "2023-11-27T03:25:12Z",
            "summary": "Fault detection and diagnosis of electrical motors are of utmost importance\nin ensuring the safe and reliable operation of several industrial systems.\nDetection and diagnosis of faults at the incipient stage allows corrective\nactions to be taken in order to reduce the severity of faults. The existing\ndata-driven deep learning approaches for machine fault diagnosis rely\nextensively on huge amounts of labeled samples, where annotations are expensive\nand time-consuming. However, a major portion of unlabeled condition monitoring\ndata is not exploited in the training process. To overcome this limitation, we\npropose a foundational model-based Active Learning framework that utilizes less\namount of labeled samples, which are most informative and harnesses a large\namount of available unlabeled data by effectively combining Active Learning and\nContrastive Self-Supervised Learning techniques. It consists of a transformer\nnetwork-based backbone model trained using an advanced nearest-neighbor\ncontrastive self-supervised learning method. This approach empowers the\nbackbone to learn improved representations of samples derived from raw,\nunlabeled vibration data. Subsequently, the backbone can undergo fine-tuning to\naddress a range of downstream tasks, both within the same machines and across\ndifferent machines. The effectiveness of the proposed methodology has been\nassessed through the fine-tuning of the backbone for multiple target tasks\nusing three distinct machine-bearing fault datasets. The experimental\nevaluation demonstrates a superior performance as compared to existing\nstate-of-the-art fault diagnosis methods with less amount of labeled data.",
            "author": [
                "Sriram Anbalagan",
                "Sai Shashank GP",
                "Deepesh Agarwal",
                "Balasubramaniam Natarajan",
                "Babji Srinivasan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15516v1",
                "http://arxiv.org/pdf/2311.15516v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.AI",
                "cs.LG",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15515v1",
            "title": "On Oda's problem and special loci",
            "updated": "2023-11-27T03:23:16Z",
            "published": "2023-11-27T03:23:16Z",
            "summary": "Oda's problem, which deals with the fixed field of the universal monodromy\nrepresentation of moduli spaces of curves and its independence with respect to\nthe topological data, is a central question of anabelian arithmetic geometry.\nThis paper emphasizes the stack nature of this problem by establishing the\nindependence of monodromy fields with respect to finer special loci data of\ncurves with symmetries, which we show provides a new proof of Oda's prediction.",
            "author": [
                "Benjamin Collas",
                "S\u00e9verin Philip"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15515v1",
                "http://arxiv.org/pdf/2311.15515v1"
            ],
            "primary_category": "math.AG",
            "category": [
                "math.AG",
                "14H30, 11G30 (Primary) 14H10, 14H25, 14G32 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15513v1",
            "title": "A Comparative and Experimental Study on Automatic Question Answering\n  Systems and its Robustness against Word Jumbling",
            "updated": "2023-11-27T03:17:09Z",
            "published": "2023-11-27T03:17:09Z",
            "summary": "Question answer generation using Natural Language Processing models is\nubiquitous in the world around us. It is used in many use cases such as the\nbuilding of chat bots, suggestive prompts in google search and also as a way of\nnavigating information in banking mobile applications etc. It is highly\nrelevant because a frequently asked questions (FAQ) list can only have a finite\namount of questions but a model which can perform question answer generation\ncould be able to answer completely new questions that are within the scope of\nthe data. This helps us to be able to answer new questions accurately as long\nas it is a relevant question. In commercial applications, it can be used to\nincrease customer satisfaction and ease of usage. However a lot of data is\ngenerated by humans so it is susceptible to human error and this can adversely\naffect the model's performance and we are investigating this through our work",
            "author": [
                "Shashidhar Reddy Javaji",
                "Haoran Hu",
                "Sai Sameer Vennam",
                "Vijaya Gajanan Buddhavarapu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15513v1",
                "http://arxiv.org/pdf/2311.15513v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15510v1",
            "title": "CaesarNeRF: Calibrated Semantic Representation for Few-shot\n  Generalizable Neural Rendering",
            "updated": "2023-11-27T03:09:58Z",
            "published": "2023-11-27T03:09:58Z",
            "summary": "Generalizability and few-shot learning are key challenges in Neural Radiance\nFields (NeRF), often due to the lack of a holistic understanding in pixel-level\nrendering. We introduce CaesarNeRF, an end-to-end approach that leverages\nscene-level CAlibratEd SemAntic Representation along with pixel-level\nrepresentations to advance few-shot, generalizable neural rendering,\nfacilitating a holistic understanding without compromising high-quality\ndetails. CaesarNeRF explicitly models pose differences of reference views to\ncombine scene-level semantic representations, providing a calibrated holistic\nunderstanding. This calibration process aligns various viewpoints with precise\nlocation and is further enhanced by sequential refinement to capture varying\ndetails. Extensive experiments on public datasets, including LLFF, Shiny,\nmip-NeRF 360, and MVImgNet, show that CaesarNeRF delivers state-of-the-art\nperformance across varying numbers of reference views, proving effective even\nwith a single reference image. The project page of this work can be found at\nhttps://haidongz-usc.github.io/project/caesarnerf.",
            "author": [
                "Haidong Zhu",
                "Tianyu Ding",
                "Tianyi Chen",
                "Ilya Zharkov",
                "Ram Nevatia",
                "Luming Liang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15510v1",
                "http://arxiv.org/pdf/2311.15510v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15509v1",
            "title": "A Corpus for Named Entity Recognition in Chinese Novels with\n  Multi-genres",
            "updated": "2023-11-27T03:08:41Z",
            "published": "2023-11-27T03:08:41Z",
            "summary": "Entities like person, location, organization are important for literary text\nanalysis. The lack of annotated data hinders the progress of named entity\nrecognition (NER) in literary domain. To promote the research of literary NER,\nwe build the largest multi-genre literary NER corpus containing 263,135\nentities in 105,851 sentences from 260 online Chinese novels spanning 13\ndifferent genres. Based on the corpus, we investigate characteristics of\nentities from different genres. We propose several baseline NER models and\nconduct cross-genre and cross-domain experiments. Experimental results show\nthat genre difference significantly impact NER performance though not as much\nas domain difference like literary domain and news domain. Compared with NER in\nnews domain, literary NER still needs much improvement and the\nOut-of-Vocabulary (OOV) problem is more challenging due to the high variety of\nentities in literary works.",
            "author": [
                "Hanjie Zhao",
                "Jinge Xie",
                "Yuchen Yan",
                "Yuxiang Jia",
                "Yawen Ye",
                "Hongying Zan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15509v1",
                "http://arxiv.org/pdf/2311.15509v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15508v1",
            "title": "Surface mapping class group actions on 3-manifolds",
            "updated": "2023-11-27T03:08:08Z",
            "published": "2023-11-27T03:08:08Z",
            "summary": "For each circle bundle $S^1\\to X\\to\\Sigma_g$ over a surface with genus\n$g\\ge2$, there is a natural surjection $\\pi:Homeo^+(X)\\to Mod(\\Sigma_g)$. When\n$X$ is the unit tangent bundle $U\\Sigma_g$, it is well-known that $\\pi$ splits.\nOn the other hand $\\pi$ does not split when the Euler number $e(X)$ is not\ndivisible by the Euler characteristic $\\chi(\\Sigma_g)$ by work of the second\ntwo authors. In this paper we show that this homomorphism does not split in\nmany cases where $\\chi(\\Sigma_g)$ divides $e(X)$.",
            "author": [
                "Alina Al Beaini",
                "Lei Chen",
                "Bena Tshishiku"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15508v1",
                "http://arxiv.org/pdf/2311.15508v1"
            ],
            "primary_category": "math.GT",
            "category": [
                "math.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15507v1",
            "title": "Improving Word Sense Disambiguation in Neural Machine Translation with\n  Salient Document Context",
            "updated": "2023-11-27T03:05:48Z",
            "published": "2023-11-27T03:05:48Z",
            "summary": "Lexical ambiguity is a challenging and pervasive problem in machine\ntranslation (\\mt). We introduce a simple and scalable approach to resolve\ntranslation ambiguity by incorporating a small amount of extra-sentential\ncontext in neural \\mt. Our approach requires no sense annotation and no change\nto standard model architectures. Since actual document context is not available\nfor the vast majority of \\mt training data, we collect related sentences for\neach input to construct pseudo-documents. Salient words from pseudo-documents\nare then encoded as a prefix to each source sentence to condition the\ngeneration of the translation. To evaluate, we release \\docmucow, a challenge\nset for translation disambiguation based on the English-German \\mucow\n\\cite{raganato-etal-2020-evaluation} augmented with document IDs. Extensive\nexperiments show that our method translates ambiguous source words better than\nstrong sentence-level baselines and comparable document-level baselines while\nreducing training costs.",
            "author": [
                "Elijah Rippeth",
                "Marine Carpuat",
                "Kevin Duh",
                "Matt Post"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15507v1",
                "http://arxiv.org/pdf/2311.15507v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15500v2",
            "title": "Function-constrained Program Synthesis",
            "updated": "2023-12-04T06:24:02Z",
            "published": "2023-11-27T02:55:34Z",
            "summary": "This work introduces (1) a technique that allows large language models (LLMs)\nto leverage user-provided code when solving programming tasks and (2) a method\nto iteratively generate modular sub-functions that can aid future code\ngeneration attempts when the initial code generated by the LLM is inadequate.\nGenerating computer programs in general-purpose programming languages like\nPython poses a challenge for LLMs when instructed to use code provided in the\nprompt. Code-specific LLMs (e.g., GitHub Copilot, CodeLlama2) can generate code\ncompletions in real-time by drawing on all code available in a development\nenvironment. However, restricting code-specific LLMs to use only in-context\ncode is not straightforward, as the model is not explicitly instructed to use\nthe user-provided code and users cannot highlight precisely which snippets of\ncode the model should incorporate into its context. Moreover, current systems\nlack effective recovery methods, forcing users to iteratively re-prompt the\nmodel with modified prompts until a sufficient solution is reached. Our method\ndiffers from traditional LLM-powered code-generation by constraining\ncode-generation to an explicit function set and enabling recovery from failed\nattempts through automatically generated sub-functions. When the LLM cannot\nproduce working code, we generate modular sub-functions to aid subsequent\nattempts at generating functional code. A by-product of our method is a library\nof reusable sub-functions that can solve related tasks, imitating a software\nteam where efficiency scales with experience. We also introduce a new\n\"half-shot\" evaluation paradigm that provides tighter estimates of LLMs' coding\nabilities compared to traditional zero-shot evaluation. Our proposed evaluation\nmethod encourages models to output solutions in a structured format, decreasing\nsyntax errors that can be mistaken for poor coding ability.",
            "author": [
                "Patrick Hajali",
                "Ignas Budvytis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15500v2",
                "http://arxiv.org/pdf/2311.15500v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL",
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15494v1",
            "title": "Enhancement of non-Stabilizerness within Indefinite Causal Order",
            "updated": "2023-11-27T02:35:48Z",
            "published": "2023-11-27T02:35:48Z",
            "summary": "In the field of quantum computation, the non-stabilizerness of a quantum\ncircuit is crucial for understanding and quantifying quantum speed-up. In this\nwork, we explore some intriguing phenomena regarding the non-stabilizerness of\na circuit when a Quantum SWITCH structure is employed. This structure is a\nnovel quantum construct that enables quantum states to pass through operations\nin a superposition of different orders and has shown superiority in numerous\ntasks over circuits with a definite causal order. Firstly, we discover that the\ncompletely stabilizer-preserving operations, which cannot generate magic states\nunder standard conditions, can be transformed into a resourceful operation\ncapable of generating magic states when processed by the Quantum SWITCH.\nSecondly, when considering the effects of noisy channels on operations, we\nobserve that while the non-stabilizerness of each path may be annihilated,\ntheir superposition could still preserve the non-stabilizerness of the\noperation. These findings reveal unique properties brought by the Quantum\nSWITCH and open further avenues in future research on magic resources of\ngeneral quantum architecture.",
            "author": [
                "Yin Mo",
                "Chengkai Zhu",
                "Zhiping Liu",
                "Mingrui Jing",
                "Xin Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15494v1",
                "http://arxiv.org/pdf/2311.15494v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15493v1",
            "title": "UFIN: Universal Feature Interaction Network for Multi-Domain\n  Click-Through Rate Prediction",
            "updated": "2023-11-27T02:30:39Z",
            "published": "2023-11-27T02:30:39Z",
            "summary": "Click-Through Rate (CTR) prediction, which aims to estimate the probability\nof a user clicking on an item, is a key task in online advertising. Numerous\nexisting CTR models concentrate on modeling the feature interactions within a\nsolitary domain, thereby rendering them inadequate for fulfilling the\nrequisites of multi-domain recommendations in real industrial scenarios. Some\nrecent approaches propose intricate architectures to enhance knowledge sharing\nand augment model training across multiple domains. However, these approaches\nencounter difficulties when being transferred to new recommendation domains,\nowing to their reliance on the modeling of ID features (e.g., item id). To\naddress the above issue, we propose the Universal Feature Interaction Network\n(UFIN) approach for CTR prediction. UFIN exploits textual data to learn\nuniversal feature interactions that can be effectively transferred across\ndiverse domains. For learning universal feature representations, we regard the\ntext and feature as two different modalities and propose an encoder-decoder\nnetwork founded on a Large Language Model (LLM) to enforce the transfer of data\nfrom the text modality to the feature modality. Building upon the above\nfoundation, we further develop a mixtureof-experts (MoE) enhanced adaptive\nfeature interaction model to learn transferable collaborative patterns across\nmultiple domains. Furthermore, we propose a multi-domain knowledge distillation\nframework to enhance feature interaction learning. Based on the above methods,\nUFIN can effectively bridge the semantic gap to learn common knowledge across\nvarious domains, surpassing the constraints of ID-based models. Extensive\nexperiments conducted on eight datasets show the effectiveness of UFIN, in both\nmultidomain and cross-platform settings. Our code is available at\nhttps://github.com/RUCAIBox/UFIN.",
            "author": [
                "Zhen Tian",
                "Changwang Zhang",
                "Wayne Xin Zhao",
                "Xin Zhao",
                "Ji-Rong Wen",
                "Zhao Cao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15493v1",
                "http://arxiv.org/pdf/2311.15493v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16485v1",
            "title": "Class-Adaptive Sampling Policy for Efficient Continual Learning",
            "updated": "2023-11-27T02:17:14Z",
            "published": "2023-11-27T02:17:14Z",
            "summary": "Continual learning (CL) aims to acquire new knowledge while preserving\ninformation from previous experiences without forgetting. Though buffer-based\nmethods (i.e., retaining samples from previous tasks) have achieved acceptable\nperformance, determining how to allocate the buffer remains a critical\nchallenge. Most recent research focuses on refining these methods but often\nfails to sufficiently consider the varying influence of samples on the learning\nprocess, and frequently overlooks the complexity of the classes/concepts being\nlearned. Generally, these methods do not directly take into account the\ncontribution of individual classes. However, our investigation indicates that\nmore challenging classes necessitate preserving a larger number of samples\ncompared to less challenging ones. To address this issue, we propose a novel\nmethod and policy named 'Class-Adaptive Sampling Policy' (CASP), which\ndynamically allocates storage space within the buffer. By utilizing concepts of\nclass contribution and difficulty, CASP adaptively manages buffer space,\nallowing certain classes to occupy a larger portion of the buffer while\nreducing storage for others. This approach significantly improves the\nefficiency of knowledge retention and utilization. CASP provides a versatile\nsolution to boost the performance and efficiency of CL. It meets the demand for\ndynamic buffer allocation, accommodating the varying contributions of different\nclasses and their learning complexities over time.",
            "author": [
                "Hossein Rezaei",
                "Mohammad Sabokrou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16485v1",
                "http://arxiv.org/pdf/2311.16485v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15490v1",
            "title": "Optimizing and Fine-tuning Large Language Model for Urban Renewal",
            "updated": "2023-11-27T02:17:11Z",
            "published": "2023-11-27T02:17:11Z",
            "summary": "This study aims to innovatively explore adaptive applications of large\nlanguage models (LLM) in urban renewal. It also aims to improve its performance\nand text generation quality for knowledge question-answering (QA) tasks. Based\non the ChatGLM, we automatically generate QA datasets using urban renewal\nscientific literature corpora in a self-instruct manner and then conduct joint\nfine-tuning training on the model using the Prefix and LoRA fine-tuning methods\nto create an LLM for urban renewal. By guiding the LLM to automatically\ngenerate QA data based on prompt words and given text, it is possible to\nquickly obtain datasets in the urban renewal field and provide data support for\nthe fine-tuning training of LLMs. The experimental results show that the joint\nfine-tuning training method proposed in this study can significantly improve\nthe performance of LLM on the QA tasks. Compared with LoRA fine-tuning, the\nmethod improves the Bleu and Rouge metrics on the test by about 5%; compared\nwith the model before fine-tuning, the method improves the Bleu and Rouge\nmetrics by about 15%-20%. This study demonstrates the effectiveness and\nsuperiority of the joint fine-tuning method using Prefix and LoRA for ChatGLM\nin the urban renewal knowledge QA tasks. It provides a new approach for\nfine-tuning LLMs on urban renewal-related tasks.",
            "author": [
                "Xi Wang",
                "Xianyao Ling",
                "Tom Zhang",
                "Xuecao Li",
                "Shaolan Wang",
                "Zhixing Li",
                "Liang Zhang",
                "Peng Gong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15490v1",
                "http://arxiv.org/pdf/2311.15490v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15487v1",
            "title": "Global $\\mathcal{L}^2$ minimization with certainty via geometrically\n  adapted gradient descent in Deep Learning",
            "updated": "2023-11-27T02:12:02Z",
            "published": "2023-11-27T02:12:02Z",
            "summary": "We consider the gradient descent flow widely used for the minimization of the\n$\\mathcal{L}^2$ cost function in Deep Learning networks, and introduce two\nmodified versions; one adapted for the overparametrized setting, and the other\nfor the underparametrized setting. Both have a clear and natural invariant\ngeometric meaning, taking into account the pullback vector bundle structure in\nthe overparametrized, and the pushforward vector bundle structure in the\nunderparametrized setting. In the overparametrized case, we prove that,\nprovided that a rank condition holds, all orbits of the modified gradient\ndescent drive the $\\mathcal{L}^2$ cost to its global minimum at a uniform\nexponential convergence rate. We point out relations of the latter to\nsub-Riemannian geometry.",
            "author": [
                "Thomas Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15487v1",
                "http://arxiv.org/pdf/2311.15487v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "math-ph",
                "math.MP",
                "math.OC",
                "stat.ML",
                "57R70, 62M45"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15485v1",
            "title": "Calibrated Generalized Bayesian Inference",
            "updated": "2023-11-27T02:05:07Z",
            "published": "2023-11-27T02:05:07Z",
            "summary": "We provide a simple and general solution to the fundamental open problem of\ninaccurate uncertainty quantification of Bayesian inference in misspecified or\napproximate models, and of generalized Bayesian posteriors more generally.\nWhile existing solutions are based on explicit Gaussian posterior\napproximations, or computationally onerous post-processing procedures, we\ndemonstrate that correct uncertainty quantification can be achieved by\nsubstituting the usual posterior with an alternative posterior that conveys the\nsame information. This solution applies to both likelihood-based and loss-based\nposteriors, and we formally demonstrate the reliable uncertainty quantification\nof this approach. The new approach is demonstrated through a range of examples,\nincluding generalized linear models, and doubly intractable models.",
            "author": [
                "David T. Frazier",
                "Christopher Drovandi",
                "Robert Kohn"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15485v1",
                "http://arxiv.org/pdf/2311.15485v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.03724v1",
            "title": "DP-OPT: Make Large Language Model Your Privacy-Preserving Prompt\n  Engineer",
            "updated": "2023-11-27T02:01:10Z",
            "published": "2023-11-27T02:01:10Z",
            "summary": "Large Language Models (LLMs) have emerged as dominant tools for various\ntasks, particularly when tailored for a specific target by prompt tuning.\nNevertheless, concerns surrounding data privacy present obstacles due to the\ntuned prompts' dependency on sensitive private information. A practical\nsolution is to host a local LLM and optimize a soft prompt privately using\ndata. Yet, hosting a local model becomes problematic when model ownership is\nprotected. Alternative methods, like sending data to the model's provider for\ntraining, intensify these privacy issues facing an untrusted provider. In this\npaper, we present a novel solution called Differentially-Private Offsite Prompt\nTuning (DP-OPT) to address this challenge. Our approach involves tuning a\ndiscrete prompt on the client side and then applying it to the desired cloud\nmodels. We demonstrate that prompts suggested by LLMs themselves can be\ntransferred without compromising performance significantly. To ensure that the\nprompts do not leak private information, we introduce the first private prompt\ngeneration mechanism, by a differentially-private (DP) ensemble of in-context\nlearning with private demonstrations. With DP-OPT, generating\nprivacy-preserving prompts by Vicuna-7b can yield competitive performance\ncompared to non-private in-context learning on GPT3.5 or local private prompt\ntuning. Codes are available at https://github.com/VITA-Group/DP-OPT .",
            "author": [
                "Junyuan Hong",
                "Jiachen T. Wang",
                "Chenhui Zhang",
                "Zhangheng Li",
                "Bo Li",
                "Zhangyang Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03724v1",
                "http://arxiv.org/pdf/2312.03724v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15480v1",
            "title": "Automatic Time Signature Determination for New Scores Using Lyrics for\n  Latent Rhythmic Structure",
            "updated": "2023-11-27T01:44:02Z",
            "published": "2023-11-27T01:44:02Z",
            "summary": "There has recently been a sharp increase in interest in Artificial\nIntelligence-Generated Content (AIGC). Despite this, musical components such as\ntime signatures have not been studied sufficiently to form an algorithmic\ndetermination approach for new compositions, especially lyrical songs. This is\nlikely because of the neglect of musical details, which is critical for\nconstructing a robust framework. Specifically, time signatures establish the\nfundamental rhythmic structure for almost all aspects of a song, including the\nphrases and notes. In this paper, we propose a novel approach that only uses\nlyrics as input to automatically generate a fitting time signature for lyrical\nsongs and uncover the latent rhythmic structure utilizing explainable machine\nlearning models. In particular, we devise multiple methods that are associated\nwith discovering lyrical patterns and creating new features that simultaneously\ncontain lyrical, rhythmic, and statistical information. In this approach, the\nbest of our experimental results reveal a 97.6% F1 score and a 0.996 Area Under\nthe Curve (AUC) of the Receiver Operating Characteristic (ROC) score. In\nconclusion, our research directly generates time signatures from lyrics\nautomatically for new scores utilizing machine learning, which is an innovative\nidea that approaches an understudied component of musicology and therefore\ncontributes significantly to the future of Artificial Intelligence (AI) music\ngeneration.",
            "author": [
                "Callie C. Liao",
                "Duoduo Liao",
                "Jesse Guessford"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15480v1",
                "http://arxiv.org/pdf/2311.15480v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL",
                "cs.MM",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15478v1",
            "title": "AerialBooth: Mutual Information Guidance for Text Controlled Aerial View\n  Synthesis from a Single Image",
            "updated": "2023-11-27T01:41:25Z",
            "published": "2023-11-27T01:41:25Z",
            "summary": "We present a novel method, AerialBooth, for synthesizing the aerial view from\na single input image using its text description. We leverage the pretrained\ntext-to-2D image stable diffusion model as prior knowledge of the 3D world. The\nmodel is finetuned in two steps to optimize for the text embedding and the UNet\nthat reconstruct the input image and its inverse perspective mapping\nrespectively. The inverse perspective mapping creates variance within the\ntext-image space of the diffusion model, while providing weak guidance for\naerial view synthesis. At inference, we steer the contents of the generated\nimage towards the input image using novel mutual information guidance that\nmaximizes the information content between the probability distributions of the\ntwo images. We evaluate our approach on a wide spectrum of real and synthetic\ndata, including natural scenes, indoor scenes, human action, etc. Through\nextensive experiments and ablation studies, we demonstrate the effectiveness of\nAerialBooth and also its generalizability to other text-controlled views. We\nalso show that AerialBooth achieves the best viewpoint-fidelity trade-off\nthough quantitative evaluation on 7 metrics analyzing viewpoint and fidelity\nw.r.t. input image. Code and data is available at\nhttps://github.com/divyakraman/AerialBooth2023.",
            "author": [
                "Divya Kothandaraman",
                "Tianyi Zhou",
                "Ming Lin",
                "Dinesh Manocha"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15478v1",
                "http://arxiv.org/pdf/2311.15478v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15476v1",
            "title": "FRET$-$Calc: A Free Software and Web Server for F\u00f6rster Resonance\n  Energy Transfer Calculation",
            "updated": "2023-11-27T01:24:00Z",
            "published": "2023-11-27T01:24:00Z",
            "summary": "F\\\"{o}rster Resonance Energy Transfer Calculator (FRET$-$Calc) is a program\nand web server that analyzes molar extinction coefficient of the acceptor,\nemission spectrum of the donor, and the refractive index spectrum of the\ndonor/acceptor blend. Its main function is to obtain important parameters of\nthe FRET process from experimental data, such as: (i) effective refractive\nindex, (ii) overlap integral, (iii) F\\\"{o}rster radius, (iii) FRET efficiency\nand (iv) FRET rate. FRET$-$Calc is license free software that can be run via\ndedicated web server (nanocalc.org) or downloading the program executables (for\nUnix, Windows, and macOS) from the FRET$-$Calc repository on GitHub. The\nprogram features a user$-$friendly interface, making it suitable for materials\nresearch and teaching purposes. In addition, the program is optimized to run on\nnormal computers and is lightweight. An example will be given with the step by\nstep of its use and results obtained.",
            "author": [
                "Leandro Benatto",
                "Omar Mesquita",
                "Jo\u00e3o L. B. Rosa",
                "Lucimara S. Roman",
                "Marlus Koehler",
                "Rodrigo B. Capaz",
                "Grazi\u00e2ni Candiotto"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.cpc.2023.108715",
                "http://arxiv.org/abs/2311.15476v1",
                "http://arxiv.org/pdf/2311.15476v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "cond-mat.mes-hall"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15475v1",
            "title": "MeshGPT: Generating Triangle Meshes with Decoder-Only Transformers",
            "updated": "2023-11-27T01:20:11Z",
            "published": "2023-11-27T01:20:11Z",
            "summary": "We introduce MeshGPT, a new approach for generating triangle meshes that\nreflects the compactness typical of artist-created meshes, in contrast to dense\ntriangle meshes extracted by iso-surfacing methods from neural fields. Inspired\nby recent advances in powerful large language models, we adopt a sequence-based\napproach to autoregressively generate triangle meshes as sequences of\ntriangles. We first learn a vocabulary of latent quantized embeddings, using\ngraph convolutions, which inform these embeddings of the local mesh geometry\nand topology. These embeddings are sequenced and decoded into triangles by a\ndecoder, ensuring that they can effectively reconstruct the mesh. A transformer\nis then trained on this learned vocabulary to predict the index of the next\nembedding given previous embeddings. Once trained, our model can be\nautoregressively sampled to generate new triangle meshes, directly generating\ncompact meshes with sharp edges, more closely imitating the efficient\ntriangulation patterns of human-crafted meshes. MeshGPT demonstrates a notable\nimprovement over state of the art mesh generation methods, with a 9% increase\nin shape coverage and a 30-point enhancement in FID scores across various\ncategories.",
            "author": [
                "Yawar Siddiqui",
                "Antonio Alliegro",
                "Alexey Artemov",
                "Tatiana Tommasi",
                "Daniele Sirigatti",
                "Vladislav Rosov",
                "Angela Dai",
                "Matthias Nie\u00dfner"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15475v1",
                "http://arxiv.org/pdf/2311.15475v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15472v1",
            "title": "Unexpected Field Evaporation Sequence in $\u03b3$-TiAl",
            "updated": "2023-11-27T01:07:23Z",
            "published": "2023-11-27T01:07:23Z",
            "summary": "In atom probe tomography (APT), atoms from the surface of a needle shape\nspecimen are evaporated under a high electric field and analyzed via time of\nflight mass spectrometry and position sensitive detection. 3D reconstruction of\nthe atom positions follows a simple projection law, which can sometimes lead to\nartifacts due to deviation from an assumed ideal evaporation sequence. Here, we\nrevisit the evaporation behavior of [001]-oriented $\\gamma$-TiAl using a\nfull-dynamics simulation approach empowered by molecular dynamics. Without any\nknowledge of charge states or assumptions about evaporation fields, we\nsuccessfully reproduced the lack of distinct Al and Ti layers observed in\nreconstructions of experimental data which is traditionally attributed to the\nretention of Al on the evaporating surface. We further showed that a step-wise\nbond breaking process of Ti in contrast to the simultaneous bond breaking of Al\nexplains the seemingly counterintuitive preferential evaporation of the\nstrongly bonded Ti atoms.",
            "author": [
                "Jiayuwen Qi",
                "Fei Xue",
                "Emmanuelle Marquis",
                "Wolfgang Windl"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15472v1",
                "http://arxiv.org/pdf/2311.15472v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15471v1",
            "title": "PLQ-Sim: A Computational Tool for Simulating Photoluminescence Quenching\n  Dynamics in Organic Donor/Acceptor Blends",
            "updated": "2023-11-27T01:06:07Z",
            "published": "2023-11-27T01:06:07Z",
            "summary": "Photoluminescence Quenching Simulator (PLQ-Sim) is a user-friendly software\nto study the photoexcited state dynamics at the interface between two organic\nsemiconductors forming a blend: an electron donor (D), and an electron acceptor\n(A). Its main function is to provide substantial information on the\nphotophysical processes relevant to organic photovoltaic and photothermal\ndevices, such as charge transfer state formation and subsequent free charge\ngeneration or exciton recombination. From input parameters provided by the\nuser, the program calculates the transfer rates of the D/A blend and employs a\nkinetic model that provides the photoluminescence quenching efficiency for\ninitial excitation in the donor or acceptor. When calculating the rates, the\nuser can choose to use disorder parameters to better describe the system. In\naddition, the program was developed to address energy transfer phenomena that\nare commonly present in organic blends. The time evolution of state populations\nis also calculated providing relevant information for the user. In this\narticle, we present the theory behind the kinetic model, along with suggestions\nfor methods to obtain the input parameters. A detailed demonstration of the\nprogram, its applicability, and an analysis of the outputs are also presented.\nPLQ-Sim is license free software that can be run via dedicated webserver\nnanocalc.org or downloading the program executables (for Unix, Windows, and\nmacOS) from the PLQ-Sim repository on GitHub.",
            "author": [
                "Leandro Benatto",
                "Omar Mesquita",
                "Lucimara S. Roman",
                "Rodrigo B. Capaz",
                "Grazi\u00e2ni Candiotto",
                "Marlus Koehler"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.cpc.2023.109015",
                "http://arxiv.org/abs/2311.15471v1",
                "http://arxiv.org/pdf/2311.15471v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15469v1",
            "title": "New evidence of multiple channels for the origin of gamma-ray bursts\n  with extended emission",
            "updated": "2023-11-27T00:55:28Z",
            "published": "2023-11-27T00:55:28Z",
            "summary": "Gamma-ray bursts (GRBs) are the most intense explosions in the universe. GRBs\nwith extended emission (GRB EE) constitute a small subclass of GRBs. GRB EE are\ndivided into EE-I GRBs and EE-II GRBs, according to the Amati empirical\nrelationship rather than duration. We test here if these two types of GRB have\ndifferent origins based on their luminosity function (and formation rate).\nTherefore, we use Lynden-Bell's c^- method to investigate the LF and FR of GRBs\nwith EE without any assumption. We calculate the formation rate of two types of\nGRBs. For EE-I GRBs, the fitting function can be written as \\rho (z) \\propto\n{(1 + z)^{ - 0.34 \\pm 0.04} for z < 2.39 and \\rho (z) \\propto {(1 + z)^{ - 2.34\n\\pm 0.24}} for z>2.39. The formation rate of EE-II can describe as \\rho (z)\n\\propto {(1 + z)^{ - 1.05 \\pm 1.10}} for z<0.43 and \\rho (z) \\propto {(1 + z)^{\n- 8.44 \\pm 1.10}} for z>0.43. The local formation rate are \\rho (0) = 0.03\nGpc^{-3}yr^{-1} for some EE-I GRBs and \\rho (0) = 0.32 Gpc^{-3}yr^{-1} for\nEE-II GRBs. Based on these results, we provide a new evidence that the origins\nof EE-I GRBs are different from EE-II GRBs from the perspective of event rate.\nThe EE-I GRB could be produced from the death of the massive star, but EE-II\nGRB bursts may come from other processes that are unrelated to the SFR. Our\nfindings indicate that the GRB with EE could have multiple production channels.",
            "author": [
                "Q. M. Li",
                "Q. B. Sun",
                "K. J. Zhang",
                ". Lon"
            ],
            "link": [
                "http://dx.doi.org/10.1093/mnras/stad3619",
                "http://arxiv.org/abs/2311.15469v1",
                "http://arxiv.org/pdf/2311.15469v1"
            ],
            "primary_category": "astro-ph.HE",
            "category": [
                "astro-ph.HE",
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15466v1",
            "title": "Intersections of Dual $SL_3$-Webs",
            "updated": "2023-11-27T00:37:28Z",
            "published": "2023-11-27T00:37:28Z",
            "summary": "We introduce a topological intersection number for an ordered pair of\n$\\operatorname{SL}_3$-webs on a decorated surface. Using this intersection\npairing between reduced $(\\operatorname{SL}_3,\\mathcal{A})$-webs and a\ncollection of $(\\operatorname{SL}_3,\\mathcal{X})$-webs associated with the\nFock--Goncharov cluster coordinates, we provide a natural combinatorial\ninterpretation of the bijection from the set of reduced\n$(\\operatorname{SL}_3,\\mathcal{A})$-webs to the tropical set\n$\\mathcal{A}^+_{\\operatorname{PGL}_3,\\hat{S}}(\\mathbb{Z}^t)$, as established by\nDouglas and Sun in \\cite{DS20a, DS20b}. We provide a new proof of the flip\nequivariance of the above bijection, which is crucial for proving the\nFock--Goncharov duality conjecture of higher Teichm\\\"uller spaces for\n$\\operatorname{SL}_3$.",
            "author": [
                "Linhui Shen",
                "Zhe Sun",
                "Daping Weng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15466v1",
                "http://arxiv.org/pdf/2311.15466v1"
            ],
            "primary_category": "math.GT",
            "category": [
                "math.GT",
                "math.CO",
                "math.QA",
                "math.RT",
                "57K31, 57K20, 57M15, 13F60, 32G15"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15465v1",
            "title": "Quantum Carnot thermal machines revisited: Definition of efficiency and\n  the effects of strong coupling",
            "updated": "2023-11-27T00:35:05Z",
            "published": "2023-11-27T00:35:05Z",
            "summary": "Whether the strong coupling to thermal baths can improve the performance of\nquantum thermal machines remains an open issue under active debate. Here, we\nrevisit quantum thermal machines operating with the quasi-static Carnot cycle\nand aim to unveil the role of strong coupling in maximum efficiency. Our\nanalysis builds upon definitions of excess work and heat derived from an exact\nformulation of the first law of thermodynamics for the working substance, which\ncaptures the non-Gibbsian thermal equilibrium state that emerges at strong\ncouplings during quasi-static isothermal processes. These excess definitions\ndiffer from conventional ones by an energetic cost for maintaining the\nnon-Gibbsian characteristics. With this distinction, we point out that one can\nintroduce two different yet thermodynamically allowed definitions for\nefficiency of both the heat engine and refrigerator modes. We dub them inside\nand outside definitions which differ in the way of defining the gain for the\nthermal machines at strong couplings by either just analyzing the energetics of\nthe working substance or instead evaluating the performance from an external\nsystem upon which the thermal machine acts, respectively. We analytically\ndemonstrate that the inside definition predicts that the Carnot limit remains\nthe upper bound for both operation modes at strong couplings, whereas the\noutside one reveals that strong coupling can suppress the maximum efficiency\nrendering the Carnot limit unattainable. These seemingly incompatible\npredictions thus indicate that it is imperative to first gauge the definition\nfor efficiency before elucidating the exact role of strong coupling, thereby\nshedding light on the on-going investigation on strong-coupling quantum thermal\nmachines.",
            "author": [
                "Junjie Liu",
                "Kenneth A. Jung"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15465v1",
                "http://arxiv.org/pdf/2311.15465v1"
            ],
            "primary_category": "cond-mat.stat-mech",
            "category": [
                "cond-mat.stat-mech"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15463v1",
            "title": "Where to Begin? From Random to Foundation Model Instructed\n  Initialization in Federated Learning for Medical Image Segmentation",
            "updated": "2023-11-27T00:29:10Z",
            "published": "2023-11-27T00:29:10Z",
            "summary": "In medical image analysis, Federated Learning (FL) stands out as a key\ntechnology that enables privacy-preserved, decentralized data processing,\ncrucial for handling sensitive medical data. Currently, most FL models employ\nrandom initialization, which has been proven effective in various instances.\nHowever, given the unique challenges posed by non-IID (independently and\nidentically distributed) data in FL, we propose a novel perspective: exploring\nthe impact of using the foundation model with enormous pre-trained knowledge,\nsuch as the Segment Anything Model (SAM), as an instructive teacher for FL\nmodel initialization in medical image segmentation task. This work for the\nfirst time attempts to utilize the foundation model as an instructive teacher\nfor initialization in FL, assessing its impact on the performance of FL models,\nespecially in non-IID data scenarios. Our empirical evaluation on chest x-ray\nlung segmentation showcases that FL with foundation model instructed\ninitialization not only achieves faster convergence but also improves\nperformance in complex data contexts. These findings offer a new perspective\nfor model initialization in FL.",
            "author": [
                "Ming Li",
                "Guang Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15463v1",
                "http://arxiv.org/pdf/2311.15463v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15459v1",
            "title": "HyperKon: A Self-Supervised Contrastive Network for Hyperspectral Image\n  Analysis",
            "updated": "2023-11-26T23:50:05Z",
            "published": "2023-11-26T23:50:05Z",
            "summary": "The exceptional spectral resolution of hyperspectral imagery enables material\ninsights that are not possible with RGB or multispectral images. Yet, the full\npotential of this data is often underutilized by deep learning techniques due\nto the scarcity of hyperspectral-native CNN backbones. To bridge this gap, we\nintroduce HyperKon, a self-supervised contrastive learning network designed and\ntrained on hyperspectral data from the EnMAP Hyperspectral\nSatellite\\cite{kaufmann2012environmental}. HyperKon uniquely leverages the high\nspectral continuity, range, and resolution of hyperspectral data through a\nspectral attention mechanism and specialized convolutional layers. We also\nperform a thorough ablation study on different kinds of layers, showing their\nperformance in understanding hyperspectral layers. It achieves an outstanding\n98% Top-1 retrieval accuracy and outperforms traditional RGB-trained backbones\nin hyperspectral pan-sharpening tasks. Additionally, in hyperspectral image\nclassification, HyperKon surpasses state-of-the-art methods, indicating a\nparadigm shift in hyperspectral image analysis and underscoring the importance\nof hyperspectral-native backbones.",
            "author": [
                "Daniel L Ayuba",
                "Belen Marti-Cardona",
                "Jean-Yves Guillemaut",
                "Oscar Mendez Maldonado"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15459v1",
                "http://arxiv.org/pdf/2311.15459v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15457v1",
            "title": "Fonctions d'une variable $p$-adique et repr\u00e9sentations de ${\\rm\n  GL}_2(\\mathbf{Q}_p)$",
            "updated": "2023-11-26T23:31:26Z",
            "published": "2023-11-26T23:31:26Z",
            "summary": "We extend the dictionary between Fontaine rings and $p$-adic functionnal\nanalysis, and we give a refinement of the $p$-adic local Langlands\ncorrespondence for principal series representations of ${\\rm\nGL}_2(\\mathbf{Q}_p)$.",
            "author": [
                "Pierre Colmez",
                "Shanwen Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15457v1",
                "http://arxiv.org/pdf/2311.15457v1"
            ],
            "primary_category": "math.NT",
            "category": [
                "math.NT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.03723v1",
            "title": "ChatGPT Application In Summarizing An Evolution Of Deep Learning\n  Techniques In Imaging: A Qualitative Study",
            "updated": "2023-11-26T23:22:37Z",
            "published": "2023-11-26T23:22:37Z",
            "summary": "The pursuit of article or text summarization has captured the attention of\nnatural language processing (NLP) practitioners, presenting itself as a\nformidable challenge. ChatGPT 3.5 exhibits the capacity to condense the content\nof up to 3000 tokens into a single page, aiming to retain pivotal information\nfrom a given text across diverse themes. In a conducted qualitative research\nendeavor, we selected seven scientific articles and employed the publicly\navailable ChatGPT service to generate summaries of these articles.\nSubsequently, we engaged six co-authors of the articles in a survey, presenting\nfive questions to evaluate the quality of the summaries compared to the\noriginal content. The findings revealed that the summaries produced by ChatGPT\neffectively encapsulated the crucial information present in the articles,\npreserving the principal message of each manuscript. Nonetheless, there was a\nslight diminishment in the technical depth of the summaries as opposed to the\noriginal articles. As a result, our conclusion underscores ChatGPT's text\nsummarization capability as a potent tool for extracting essential insights in\na manner more aligned with reporting than purely scientific discourse.",
            "author": [
                "Arman Sarraf",
                "Amirabbas Abbaspour"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03723v1",
                "http://arxiv.org/pdf/2312.03723v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15454v1",
            "title": "Simulation study of intra-beam scattering effect in the HALF storage\n  ring with Piwinski model",
            "updated": "2023-11-26T23:15:16Z",
            "published": "2023-11-26T23:15:16Z",
            "summary": "The Hefei Advanced Light Facility (HALF) will be a VUV and soft X-ray\ndiffraction-limited storage ring (DLSR), and its high density of electron\nbunches makes the intra-beam scattering (IBS) effect very serious. In this\npaper, an IBS module used in the IMPACT code is developed, where the scattering\nprocess of IBS is described by the Piwinski model in Monte Carlo sampling. For\nbenchmarking, the IMPACT code with IBS module is compared with the ELEGANT code\nand a semi-analytic code using Bane's model. Then, the results of IBS effect in\nthe HALF storage ring studied by this new code are presented. With various\ncountermeasures, the IBS impact can be controlled to a certain extent, and the\nexpected beam emittance is approximately 59 pm.rad.",
            "author": [
                "C. W. Luo",
                "P. H. Yang",
                "G. W. Liu",
                "W. W. Li",
                "N. Hu",
                "W. M. Li",
                "Z. H. Bai",
                "L. Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15454v1",
                "http://arxiv.org/pdf/2311.15454v1"
            ],
            "primary_category": "physics.acc-ph",
            "category": [
                "physics.acc-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15453v1",
            "title": "DISYRE: Diffusion-Inspired SYnthetic REstoration for Unsupervised\n  Anomaly Detection",
            "updated": "2023-11-26T23:07:19Z",
            "published": "2023-11-26T23:07:19Z",
            "summary": "Unsupervised Anomaly Detection (UAD) techniques aim to identify and localize\nanomalies without relying on annotations, only leveraging a model trained on a\ndataset known to be free of anomalies. Diffusion models learn to modify inputs\n$x$ to increase the probability of it belonging to a desired distribution,\ni.e., they model the score function $\\nabla_x \\log p(x)$. Such a score function\nis potentially relevant for UAD, since $\\nabla_x \\log p(x)$ is itself a\npixel-wise anomaly score. However, diffusion models are trained to invert a\ncorruption process based on Gaussian noise and the learned score function is\nunlikely to generalize to medical anomalies. This work addresses the problem of\nhow to learn a score function relevant for UAD and proposes DISYRE:\nDiffusion-Inspired SYnthetic REstoration. We retain the diffusion-like pipeline\nbut replace the Gaussian noise corruption with a gradual, synthetic anomaly\ncorruption so the learned score function generalizes to medical, naturally\noccurring anomalies. We evaluate DISYRE on three common Brain MRI UAD\nbenchmarks and substantially outperform other methods in two out of the three\ntasks.",
            "author": [
                "Sergio Naval Marimont",
                "Matthew Baugh",
                "Vasilis Siomos",
                "Christos Tzelepis",
                "Bernhard Kainz",
                "Giacomo Tarroni"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15453v1",
                "http://arxiv.org/pdf/2311.15453v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16196v1",
            "title": "Variational Exploration Module VEM: A Cloud-Native Optimization and\n  Validation Tool for Geospatial Modeling and AI Workflows",
            "updated": "2023-11-26T23:07:00Z",
            "published": "2023-11-26T23:07:00Z",
            "summary": "Geospatial observations combined with computational models have become key to\nunderstanding the physical systems of our environment and enable the design of\nbest practices to reduce societal harm. Cloud-based deployments help to scale\nup these modeling and AI workflows. Yet, for practitioners to make robust\nconclusions, model tuning and testing is crucial, a resource intensive process\nwhich involves the variation of model input variables. We have developed the\nVariational Exploration Module which facilitates the optimization and\nvalidation of modeling workflows deployed in the cloud by orchestrating\nworkflow executions and using Bayesian and machine learning-based methods to\nanalyze model behavior. User configurations allow the combination of diverse\nsampling strategies in multi-agent environments. The flexibility and robustness\nof the model-agnostic module is demonstrated using real-world applications.",
            "author": [
                "Julian Kuehnert",
                "Hiwot Tadesse",
                "Chris Dearden",
                "Rosie Lickorish",
                "Paolo Fraccaro",
                "Anne Jones",
                "Blair Edwards",
                "Sekou L. Remy",
                "Peter Melling",
                "Tim Culmer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16196v1",
                "http://arxiv.org/pdf/2311.16196v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.03722v1",
            "title": "Leveraging AI-derived Data for Carbon Accounting: Information Extraction\n  from Alternative Sources",
            "updated": "2023-11-26T22:49:41Z",
            "published": "2023-11-26T22:49:41Z",
            "summary": "Carbon accounting is a fundamental building block in our global path to\nemissions reduction and decarbonization, yet many challenges exist in achieving\nreliable and trusted carbon accounting measures. We motivate that carbon\naccounting not only needs to be more data-driven, but also more\nmethodologically sound. We discuss the need for alternative, more diverse data\nsources that can play a significant role on our path to trusted carbon\naccounting procedures and elaborate on not only why, but how Artificial\nIntelligence (AI) in general and Natural Language Processing (NLP) in\nparticular can unlock reasonable access to a treasure trove of alternative data\nsets in light of the recent advances in the field that better enable the\nutilization of unstructured data in this process. We present a case study of\nthe recent developments on real-world data via an NLP-powered analysis using\nOpenAI's GPT API on financial and shipping data. We conclude the paper with a\ndiscussion on how these methods and approaches can be integrated into a broader\nframework for AI-enabled integrative carbon accounting.",
            "author": [
                "Olamide Oladeji",
                "Seyed Shahabeddin Mousavi"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03722v1",
                "http://arxiv.org/pdf/2312.03722v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15451v1",
            "title": "Uncertainty-aware Language Modeling for Selective Question Answering",
            "updated": "2023-11-26T22:47:54Z",
            "published": "2023-11-26T22:47:54Z",
            "summary": "We present an automatic large language model (LLM) conversion approach that\nproduces uncertainty-aware LLMs capable of estimating uncertainty with every\nprediction. Our approach is model- and data-agnostic, is\ncomputationally-efficient, and does not rely on external models or systems. We\nevaluate converted models on the selective question answering setting -- to\nanswer as many questions as possible while maintaining a given accuracy,\nforgoing providing predictions when necessary. As part of our results, we test\nBERT and Llama 2 model variants on the SQuAD extractive QA task and the\nTruthfulQA generative QA task. We show that using the uncertainty estimates\nprovided by our approach to selectively answer questions leads to significantly\nhigher accuracy over directly using model probabilities.",
            "author": [
                "Qi Yang",
                "Shreya Ravikumar",
                "Fynn Schmitt-Ulms",
                "Satvik Lolla",
                "Ege Demir",
                "Iaroslav Elistratov",
                "Alex Lavaee",
                "Sadhana Lolla",
                "Elaheh Ahmadi",
                "Daniela Rus",
                "Alexander Amini",
                "Alejandro Perez"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15451v1",
                "http://arxiv.org/pdf/2311.15451v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15445v1",
            "title": "FLAIR: A Conditional Diffusion Framework with Applications to Face Video\n  Restoration",
            "updated": "2023-11-26T22:09:18Z",
            "published": "2023-11-26T22:09:18Z",
            "summary": "Face video restoration (FVR) is a challenging but important problem where one\nseeks to recover a perceptually realistic face videos from a low-quality input.\nWhile diffusion probabilistic models (DPMs) have been shown to achieve\nremarkable performance for face image restoration, they often fail to preserve\ntemporally coherent, high-quality videos, compromising the fidelity of\nreconstructed faces. We present a new conditional diffusion framework called\nFLAIR for FVR. FLAIR ensures temporal consistency across frames in a\ncomputationally efficient fashion by converting a traditional image DPM into a\nvideo DPM. The proposed conversion uses a recurrent video refinement layer and\na temporal self-attention at different scales. FLAIR also uses a conditional\niterative refinement process to balance the perceptual and distortion quality\nduring inference. This process consists of two key components: a\ndata-consistency module that analytically ensures that the generated video\nprecisely matches its degraded observation and a coarse-to-fine image\nenhancement module specifically for facial regions. Our extensive experiments\nshow superiority of FLAIR over the current state-of-the-art (SOTA) for video\nsuper-resolution, deblurring, JPEG restoration, and space-time frame\ninterpolation on two high-quality face video datasets.",
            "author": [
                "Zihao Zou",
                "Jiaming Liu",
                "Shirin Shoushtari",
                "Yubo Wang",
                "Weijie Gan",
                "Ulugbek S. Kamilov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15445v1",
                "http://arxiv.org/pdf/2311.15445v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15443v1",
            "title": "DCRA: A Distributed Chiplet-based Reconfigurable Architecture for\n  Irregular Applications",
            "updated": "2023-11-26T22:02:04Z",
            "published": "2023-11-26T22:02:04Z",
            "summary": "In recent years, the growing demand to process large graphs and sparse\ndatasets has led to increased research efforts to develop hardware- and\nsoftware-based architectural solutions to accelerate them. While some of these\napproaches achieve scalable parallelization with up to thousands of cores,\nadaptation of these proposals by the industry remained slow. To help solve this\ndissonance, we identified a set of questions and considerations that current\nresearch has not considered deeply. Starting from a tile-based architecture, we\nput forward a Distributed Chiplet-based Reconfigurable Architecture (DCRA) for\nirregular applications that carefully consider fabrication constraints that\nmade prior work either hard or costly to implement or too rigid to be applied.\nWe identify and study pre-silicon, package-time and compile-time configurations\nthat help optimize DCRA for different deployments and target metrics. To enable\nthat, we propose a practical path for manufacturing chip packages by composing\nvariable numbers of DCRA and memory dies, with a software-configurable Torus\nnetwork to connect them. We evaluate six applications and four datasets, with\nseveral configurations and memory technologies, to provide a detailed analysis\nof the performance, power, and cost of DCRA as a compute node for scale-out\nsparse data processing. Finally, we present our findings and discuss how DCRA,\ntogether with our framework for design exploration, can help guide architects\nto build scalable and cost-efficient systems for irregular applications.",
            "author": [
                "Marcelo Orenes-Vera",
                "Esin Tureci",
                "Margaret Martonosi",
                "David Wentzlaff"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15443v1",
                "http://arxiv.org/pdf/2311.15443v1"
            ],
            "primary_category": "cs.AR",
            "category": [
                "cs.AR",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15438v1",
            "title": "ProtoArgNet: Interpretable Image Classification with Super-Prototypes\n  and Argumentation [Technical Report]",
            "updated": "2023-11-26T21:52:47Z",
            "published": "2023-11-26T21:52:47Z",
            "summary": "We propose ProtoArgNet, a novel interpretable deep neural architecture for\nimage classification in the spirit of prototypical-part-learning as found, e.g.\nin ProtoPNet. While earlier approaches associate every class with multiple\nprototypical-parts, ProtoArgNet uses super-prototypes that combine\nprototypical-parts into single prototypical class representations. Furthermore,\nwhile earlier approaches use interpretable classification layers, e.g. logistic\nregression in ProtoPNet, ProtoArgNet improves accuracy with multi-layer\nperceptrons while relying upon an interpretable reading thereof based on a form\nof argumentation. ProtoArgNet is customisable to user cognitive requirements by\na process of sparsification of the multi-layer perceptron/argumentation\ncomponent. Also, as opposed to other prototypical-part-learning approaches,\nProtoArgNet can recognise spatial relations between different\nprototypical-parts that are from different regions in images, similar to how\nCNNs capture relations between patterns recognized in earlier layers.",
            "author": [
                "Hamed Ayoobi",
                "Nico Potyka",
                "Francesca Toni"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15438v1",
                "http://arxiv.org/pdf/2311.15438v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15437v1",
            "title": "Quality Modeling Under A Relaxed Natural Scene Statistics Model",
            "updated": "2023-11-26T21:48:58Z",
            "published": "2023-11-26T21:48:58Z",
            "summary": "Information-theoretic image quality assessment (IQA) models such as Visual\nInformation Fidelity (VIF) and Spatio-temporal Reduced Reference Entropic\nDifferences (ST-RRED) have enjoyed great success by seamlessly integrating\nnatural scene statistics (NSS) with information theory. The Gaussian Scale\nMixture (GSM) model that governs the wavelet subband coefficients of natural\nimages forms the foundation for these algorithms. However, the explosion of\nuser-generated content on social media, which is typically distorted by one or\nmore of many possible unknown impairments, has revealed the limitations of\nNSS-based IQA models that rely on the simple GSM model. Here, we seek to\nelaborate the VIF index by deriving useful properties of the Multivariate\nGeneralized Gaussian Distribution (MGGD), and using them to study the behavior\nof VIF under a Generalized GSM (GGSM) model.",
            "author": [
                "Abhinau K. Venkataramanan",
                "Alan C. Bovik"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15437v1",
                "http://arxiv.org/pdf/2311.15437v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "math.ST",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15436v1",
            "title": "Learning to Skip for Language Modeling",
            "updated": "2023-11-26T21:45:53Z",
            "published": "2023-11-26T21:45:53Z",
            "summary": "Overparameterized large-scale language models have impressive generalization\nperformance of in-context few-shot learning. However, most language models\nallocate the same amount of parameters or computation to each token,\ndisregarding the complexity or importance of the input data. We argue that in\nlanguage model pretraining, a variable amount of computation should be assigned\nto different tokens, and this can be efficiently achieved via a simple routing\nmechanism. Different from conventional early stopping techniques where tokens\ncan early exit at only early layers, we propose a more general method that\ndynamically skips the execution of a layer (or module) for any input token with\na binary router. In our extensive evaluation across 24 NLP tasks, we\ndemonstrate that the proposed method can significantly improve the 1-shot\nperformance compared to other competitive baselines only at mild extra cost for\ninference.",
            "author": [
                "Dewen Zeng",
                "Nan Du",
                "Tao Wang",
                "Yuanzhong Xu",
                "Tao Lei",
                "Zhifeng Chen",
                "Claire Cui"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15436v1",
                "http://arxiv.org/pdf/2311.15436v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15431v1",
            "title": "On the piecewise complexity of words and periodic words",
            "updated": "2023-11-26T21:23:48Z",
            "published": "2023-11-26T21:23:48Z",
            "summary": "The piecewise complexity $h(u)$ of a word is the minimal length of subwords\nneeded to exactly characterise $u$. Its piecewise minimality index $\\rho(u)$ is\nthe smallest length $k$ such that $u$ is minimal among its order-$k$ class\n$[u]_k$ in Simon's congruence.\n  We study these two measures and provide efficient algorithms for computing\n$h(u)$ and $\\rho(u)$. We also provide efficient algorithms for the case where\n$u$ is a periodic word, of the form $u=v^n$",
            "author": [
                "M. Praveen",
                "Philippe Schnoebelen",
                "Isa Vialard",
                "Julien Veron"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15431v1",
                "http://arxiv.org/pdf/2311.15431v1"
            ],
            "primary_category": "cs.FL",
            "category": [
                "cs.FL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15430v1",
            "title": "Application of batch learning for boosting high-throughput ab initio\n  success rates and reducing computational effort required using data-driven\n  processes",
            "updated": "2023-11-26T21:22:17Z",
            "published": "2023-11-26T21:22:17Z",
            "summary": "The increased availability of computing time, in recent years, allows for\nsystematic high-throughput studies of material classes with the purpose of both\nscreening for materials with remarkable properties and understanding how\nstructural configuration and material composition affect macroscopic attributes\nmanifestation. However, when conducting systematic high-throughput studies, the\nindividual ab initio calculations' success depends on the quality of the chosen\ninput quantities. On a large scale, improving input parameters by trial and\nerror is neither efficient nor systematic. We present a systematic,\nhigh-throughput compatible, and machine learning-based approach to improve the\ninput parameters optimized during a DFT computation or workflow. This approach\nof integrating machine learning into a typical high-throughput workflow\ndemonstrates the advantages and necessary considerations for a systematic study\nof magnetic multilayers of 3$d$ transition metal layers on FCC noble metal\nsubstrates. For 6660 film systems, we were able to improve the overall success\nrate of our high-throughput FLAPW-based structural relaxations from $64.8 \\%$\nto $94.3\\ \\%$ while at the same time requiring $17\\ \\%$ less computational time\nfor each successful relaxation.",
            "author": [
                "Robin Hilgers",
                "Daniel Wortmann",
                "Stefan Bl\u00fcgel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15430v1",
                "http://arxiv.org/pdf/2311.15430v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15425v1",
            "title": "Machine-Generated Text Detection using Deep Learning",
            "updated": "2023-11-26T21:16:01Z",
            "published": "2023-11-26T21:16:01Z",
            "summary": "Our research focuses on the crucial challenge of discerning text produced by\nLarge Language Models (LLMs) from human-generated text, which holds\nsignificance for various applications. With ongoing discussions about attaining\na model with such functionality, we present supporting evidence regarding the\nfeasibility of such models. We evaluated our models on multiple datasets,\nincluding Twitter Sentiment, Football Commentary, Project Gutenberg, PubMedQA,\nand SQuAD, confirming the efficacy of the enhanced detection approaches. These\ndatasets were sampled with intricate constraints encompassing every\npossibility, laying the foundation for future research. We evaluate\nGPT-3.5-Turbo against various detectors such as SVM, RoBERTa-base, and\nRoBERTa-large. Based on the research findings, the results predominantly relied\non the sequence length of the sentence.",
            "author": [
                "Raghav Gaggar",
                "Ashish Bhagchandani",
                "Harsh Oza"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15425v1",
                "http://arxiv.org/pdf/2311.15425v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "I.2.7; I.5.4; I.2.6"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15423v1",
            "title": "Machine Learning-based estimation and explainable artificial\n  intelligence-supported interpretation of the critical temperature from\n  magnetic ab initio Heusler alloys data",
            "updated": "2023-11-26T21:11:12Z",
            "published": "2023-11-26T21:11:12Z",
            "summary": "Machine Learning (ML) has impacted numerous areas of materials science, most\nprominently improving molecular simulations, where force fields were trained on\npreviously relaxed structures. One natural next step is to predict material\nproperties beyond structure. In this work, we investigate the applicability and\nexplainability of ML methods in the use case of estimating the critical\ntemperature for magnetic Heusler alloys calculated using ab initio methods\ndetermined materials-specific magnetic interactions and a subsequent Monte\nCarlo (MC) approach. We compare the performance of regression and\nclassification models to predict the range of the critical temperature of given\ncompounds without performing the MC calculations. Since the MC calculation\nrequires computational resources in the same order of magnitude as the\ndensity-functional theory (DFT) calculation, it would be advantageous to\nreplace either step with a less computationally intensive method such as ML. We\ndiscuss the necessity to generate the magnetic ab initio results to make a\nquantitative prediction of the critical temperature. We used state-of-the-art\nexplainable artificial intelligence (XAI) methods to extract physical relations\nand deepen our understanding of patterns learned by our models from the\nexamined data.",
            "author": [
                "Robin Hilgers",
                "Daniel Wortmann",
                "Stefan Bl\u00fcgel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15423v1",
                "http://arxiv.org/pdf/2311.15423v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15418v1",
            "title": "Atomic models of dense plasmas, applications and current challenges",
            "updated": "2023-11-26T20:56:33Z",
            "published": "2023-11-26T20:56:33Z",
            "summary": "Modeling plasmas in terms of atoms or ions is theoretically appealing for\nseveral reasons. When it is relevant, the notion of atom or ion in a plasma\nprovides us with an interpretation scheme of the plasma's internal functioning.\nFrom the standpoint of quantitative estimation of plasma properties, atomic\nmodels of plasma allow to extend many theoretical tools of atomic physics to\nplasmas. This notably includes the statistical approaches to the detailed\naccounting for excited states, or the collisional-radiative modeling of\nnon-equilibrium plasmas, which is based on the notion of atomic processes. In\nthis paper, we focus on the challenges raised by the atomic modeling of dense,\nnon-ideal plasmas.\n  First we make a brief, non-exhaustive review of atomic models of plasmas,\nfrom ideal plasmas to strongly-coupled and pressure-ionized plasmas. We discuss\nthe limitations of these models and pinpoint some open problems in the field of\natomic modeling of plasmas.\n  We then address the peculiarities of atomic processes in dense plasmas and\npoint out some specific issues relative to the calculation of their\ncross-sections. In particular, we discuss the modeling of fluctuations, the\naccounting for channel mixing and collective phenomena in the photoabsorption,\nor the impact of pressure ionization on collisional processes.",
            "author": [
                "R. Piron"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15418v1",
                "http://arxiv.org/pdf/2311.15418v1"
            ],
            "primary_category": "physics.plasm-ph",
            "category": [
                "physics.plasm-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15415v1",
            "title": "GAN-Based LiDAR Intensity Simulation",
            "updated": "2023-11-26T20:44:09Z",
            "published": "2023-11-26T20:44:09Z",
            "summary": "Realistic vehicle sensor simulation is an important element in developing\nautonomous driving. As physics-based implementations of visual sensors like\nLiDAR are complex in practice, data-based approaches promise solutions. Using\npairs of camera images and LiDAR scans from real test drives, GANs can be\ntrained to translate between them. For this process, we contribute two\nadditions. First, we exploit the camera images, acquiring segmentation data and\ndense depth maps as additional input for training. Second, we test the\nperformance of the LiDAR simulation by testing how well an object detection\nnetwork generalizes between real and synthetic point clouds to enable\nevaluation without ground truth point clouds. Combining both, we simulate LiDAR\npoint clouds and demonstrate their realism.",
            "author": [
                "Richard Marcus",
                "Felix Gabel",
                "Niklas Knoop",
                "Marc Stamminger"
            ],
            "link": [
                "http://dx.doi.org/10.1007/978-3-031-39059-3_28",
                "http://arxiv.org/abs/2311.15415v1",
                "http://arxiv.org/pdf/2311.15415v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15414v2",
            "title": "KOPPA: Improving Prompt-based Continual Learning with Key-Query\n  Orthogonal Projection and Prototype-based One-Versus-All",
            "updated": "2023-11-30T15:26:20Z",
            "published": "2023-11-26T20:35:19Z",
            "summary": "Drawing inspiration from prompt tuning techniques applied to Large Language\nModels, recent methods based on pre-trained ViT networks have achieved\nremarkable results in the field of Continual Learning. Specifically, these\napproaches propose to maintain a set of prompts and allocate a subset of them\nto learn each task using a key-query matching strategy. However, they may\nencounter limitations when lacking control over the correlations between old\ntask queries and keys of future tasks, the shift of features in the latent\nspace, and the relative separation of latent vectors learned in independent\ntasks. In this work, we introduce a novel key-query learning strategy based on\northogonal projection, inspired by model-agnostic meta-learning, to enhance\nprompt matching efficiency and address the challenge of shifting features.\nFurthermore, we introduce a One-Versus-All (OVA) prototype-based component that\nenhances the classification head distinction. Experimental results on benchmark\ndatasets demonstrate that our method empowers the model to achieve results\nsurpassing those of current state-of-the-art approaches by a large margin of up\nto 20%.",
            "author": [
                "Quyen Tran",
                "Lam Tran",
                "Khoat Than",
                "Toan Tran",
                "Dinh Phung",
                "Trung Le"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15414v2",
                "http://arxiv.org/pdf/2311.15414v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15412v1",
            "title": "Joint Antenna Selection and Power Allocation in Massive MIMO Systems\n  with Cell Division Technique for MRT and ZF Precoding Schemes",
            "updated": "2023-11-26T20:29:36Z",
            "published": "2023-11-26T20:29:36Z",
            "summary": "One of the most important challenges in the fifth generation (5G) of\ntelecommunication systems is the efficiency of energy and spectrum. Massive\nmultiple-input multiple-output (MIMO) systems have been proposed by researchers\nto resolve existing challenges. In the proposed system model of this paper,\nthere is a base station (BS) around which several users and an eavesdropper\n(EVA) are evenly distributed. The information transmitted between BS and users\nis disrupted by an EVA, which highlights the importance of secure transfer.\nThis paper analyzes secure energy efficiency (EE) of a massive MIMO system, and\nits purpose is to maximize the secure EE of the system. Several scenarios are\nconsidered to evaluate achieving the desired goal. To maximize the secure EE,\nselecting optimal number of antennas and cell division methods are employed.\nEach of these two methods is applied in a system with the maximum ratio\ntransmission (MRT) and the zero forcing (ZF) precodings, and then the problem\nis solved. Maximum transmission power and minimum secure rate for users insert\nlimitations to the optimization problem. Channel state information (CSI) is\ngenerally imperfect for users in any method, while CSI of the EVA is considered\nperfect as the worst case. Four iterative algorithms are designed to provide\nnumerical assessments. The first algorithm calculates the optimal power of\nusers without utilizing existing methods, the second one is related to the cell\ndivision method, the third one is based on the strategy of selecting optimal\nnumber of antennas, and forth one is based on a hybrid strategy.",
            "author": [
                "Abdolrasoul Sakhaei Gharagezlou",
                "Nima Imani",
                "Mahdi Nangir"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15412v1",
                "http://arxiv.org/pdf/2311.15412v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15411v1",
            "title": "On long-term fatigue damage estimation for a floating offshore wind\n  turbine using a surrogate model",
            "updated": "2023-11-26T20:28:48Z",
            "published": "2023-11-26T20:28:48Z",
            "summary": "This study is concerned with the estimation of fatigue damage for a 5-MW\noffshore wind turbine supported by a semi-submersible floating platform. The\nfore-aft bending moment at the turbine tower base and the fairlead tension in\nthe windward mooring line are selected for evaluation. The selected wind\nturbine is sited in 200 meters of water. Metocean data provide information on\njoint statistics of the wind speed, wave height, and wave period along with\ntheir relative likelihoods for the installation site in the Mediterranean Sea,\nnear the coast of Sicily. A frequency-domain (FD) model provides needed power\nspectra for the desired response processes. With the ultimate goal of efficient\nevaluation of fatigue limit states for such floating offshore wind turbine\nsystems, a detailed computational framework is introduced and used to develop a\nsurrogate model using Gaussian process regression. The surrogate model, at\nfirst, relies only on a small subset of representative sea states and, then, is\nsupplemented by the evaluation of additional sea states that lead to efficient\nconvergence and accurate prediction of fatigue damage. The proposed approach\noffers an efficient and accurate alternative to exhaustive evaluation of a\nlarger number of sea states and, as such, avoids excessive response\nsimulations.",
            "author": [
                "Ding Peng Liu",
                "Giulio Ferri",
                "Taemin Heo",
                "Enzo Marino",
                "Lance Manuel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15411v1",
                "http://arxiv.org/pdf/2311.15411v1"
            ],
            "primary_category": "stat.AP",
            "category": [
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15406v2",
            "title": "How to Optimize the Environmental Impact of Transformed NoSQL Schemas\n  through a Multidimensional Cost Model?",
            "updated": "2023-11-28T19:02:00Z",
            "published": "2023-11-26T20:05:27Z",
            "summary": "The complexity of database systems has increased significantly along with the\ncontinuous growth of data, resulting in NoSQL systems and forcing Information\nSystems (IS) architects to constantly adapt their data models (i.e., the data\nstructure of information stored in the database) and carefully choose the best\noption(s) for storing and managing data. In this context, we propose %in this\npaper an automatic global approach for leading data models' transformation\nprocess. This approach starts with the generation of all possible solutions. It\nthen relies on a cost model that helps to compare these generated data models\nin a logical level to finally choose the best one for the given use case. This\ncost model integrates both data model and queries cost. It also takes into\nconsideration the environmental impact of a data model as well as its financial\nand its time costs. This work presents for the first time a multidimensional\ncost model encompassing time, environmental and financial constraints, which\ncompares data models leading to the choice of the optimal one for a given use\ncase. In addition, a simulation for data model's transformation and cost\ncomputation has been developed based on our approach.",
            "author": [
                "Jihane Mali",
                "Faten Atigui",
                "Ahmed Azough",
                "Nicolas Travers",
                "Shohreh Ahvar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15406v2",
                "http://arxiv.org/pdf/2311.15406v2"
            ],
            "primary_category": "cs.DB",
            "category": [
                "cs.DB"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15405v1",
            "title": "Charged Higgs decay to $W^{\\pm}$ and heavy neutral Higgs decaying into\n  $\u03c4^+\u03c4^-$ in Georgi Machacek Model at LHC",
            "updated": "2023-11-26T20:05:23Z",
            "published": "2023-11-26T20:05:23Z",
            "summary": "The CMS collaboration at the Large Hadron Collider (LHC) searched for a\ncharged Higgs boson, in the mass range of $300$ to $700$ GeV, decaying into a\n$W^{\\pm}$ boson and a heavy neutral Higgs boson of mass $200$ GeV, which\nsuccessively decays into a pair of tau leptons, in proton-proton collisions at\n$\\sqrt{s} = 13$ TeV. In this letter, focussing on the Georgi-Machacek (GM)\nmodel, I discuss the parameter space, allowed by the theoretical and\nexperimental constraints, for which the limits on this process obtained by the\nCMS can be accommodated. The study in this letter also shows that, for the\nchoice of the parameters, the decay of the charged Higgs boson $H_3^{\\pm}$ to\n$W^{\\pm}$ and a heavy neutral Higgs boson H is preferred over the decay to any\ngauge boson and any other neutral or charged Higgs bosons.",
            "author": [
                "Swagata Ghosh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15405v1",
                "http://arxiv.org/pdf/2311.15405v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15402v1",
            "title": "Learning Section Weights for Multi-Label Document Classification",
            "updated": "2023-11-26T19:56:19Z",
            "published": "2023-11-26T19:56:19Z",
            "summary": "Multi-label document classification is a traditional task in NLP. Compared to\nsingle-label classification, each document can be assigned multiple classes.\nThis problem is crucially important in various domains, such as tagging\nscientific articles. Documents are often structured into several sections such\nas abstract and title. Current approaches treat different sections equally for\nmulti-label classification. We argue that this is not a realistic assumption,\nleading to sub-optimal results. Instead, we propose a new method called\nLearning Section Weights (LSW), leveraging the contribution of each distinct\nsection for multi-label classification. Via multiple feed-forward layers, LSW\nlearns to assign weights to each section of, and incorporate the weights in the\nprediction. We demonstrate our approach on scientific articles. Experimental\nresults on public (arXiv) and private (Elsevier) datasets confirm the\nsuperiority of LSW, compared to state-of-the-art multi-label document\nclassification methods. In particular, LSW achieves a 1.3% improvement in terms\nof macro averaged F1-score while it achieves 1.3% in terms of macro averaged\nrecall on the publicly available arXiv dataset.",
            "author": [
                "Maziar Moradi Fard",
                "Paula Sorrolla Bayod",
                "Kiomars Motarjem",
                "Mohammad Alian Nejadi",
                "Saber Akhondi",
                "Camilo Thorne"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15402v1",
                "http://arxiv.org/pdf/2311.15402v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15394v1",
            "title": "Natural Aging and Vacancy Trapping in Al-6xxx",
            "updated": "2023-11-26T19:29:58Z",
            "published": "2023-11-26T19:29:58Z",
            "summary": "Undesirable natural aging (NA) in Al-6xxx delays subsequent artificial aging\n(AA) but the size, composition, and evolution of clustering are challenging to\nmeasure. Here, atomistic details of early-stage clustering in Al-1\\%Mg-0.6\\%Si\nduring NA are studied computationally using a chemically-accurate\nneural-network potential. Feasible growth paths for the preferred $\\beta''$\nprecipitates identify: dominant clusters differing from $\\beta''$ motifs;\nspontaneous vacancy-interstitial formation creating 14-18 solute atom\n$\\beta''$-like motifs; and lower-energy clusters requiring chemical\nre-arrangement to form $\\beta''$ nuclei. Quasi-on-lattice kinetic Monte Carlo\nsimulations reveal that 8-14 solute atom clusters form within 1000 s but that\ngrowth slows considerably due to vacancy trapping inside clusters, with\ntrapping energies of 0.3-0.5 eV. These findings rationalize why cluster growth\nand alloy hardness saturate during NA, confirm the concept of ''vacancy\nprisons\", and suggest why clusters must be dissolved during AA before formation\nof $\\beta''$. This atomistic understanding of NA may enable design of\nstrategies to mitigate negative effects of NA.",
            "author": [
                "Abhinav C. P. Jain",
                "M. Ceriotti",
                "W. A. Curtin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15394v1",
                "http://arxiv.org/pdf/2311.15394v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15390v1",
            "title": "Local Convergence of Approximate Newton Method for Two Layer Nonlinear\n  Regression",
            "updated": "2023-11-26T19:19:02Z",
            "published": "2023-11-26T19:19:02Z",
            "summary": "There have been significant advancements made by large language models (LLMs)\nin various aspects of our daily lives. LLMs serve as a transformative force in\nnatural language processing, finding applications in text generation,\ntranslation, sentiment analysis, and question-answering. The accomplishments of\nLLMs have led to a substantial increase in research efforts in this domain. One\nspecific two-layer regression problem has been well-studied in prior works,\nwhere the first layer is activated by a ReLU unit, and the second layer is\nactivated by a softmax unit. While previous works provide a solid analysis of\nbuilding a two-layer regression, there is still a gap in the analysis of\nconstructing regression problems with more than two layers.\n  In this paper, we take a crucial step toward addressing this problem: we\nprovide an analysis of a two-layer regression problem. In contrast to previous\nworks, our first layer is activated by a softmax unit. This sets the stage for\nfuture analyses of creating more activation functions based on the softmax\nfunction. Rearranging the softmax function leads to significantly different\nanalyses. Our main results involve analyzing the convergence properties of an\napproximate Newton method used to minimize the regularized training loss. We\nprove that the loss function for the Hessian matrix is positive definite and\nLipschitz continuous under certain assumptions. This enables us to establish\nlocal convergence guarantees for the proposed training algorithm. Specifically,\nwith an appropriate initialization and after $O(\\log(1/\\epsilon))$ iterations,\nour algorithm can find an $\\epsilon$-approximate minimizer of the training loss\nwith high probability. Each iteration requires approximately $O(\\mathrm{nnz}(C)\n+ d^\\omega)$ time, where $d$ is the model size, $C$ is the input matrix, and\n$\\omega < 2.374$ is the matrix multiplication exponent.",
            "author": [
                "Zhihang Li",
                "Zhao Song",
                "Zifan Wang",
                "Junze Yin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15390v1",
                "http://arxiv.org/pdf/2311.15390v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15389v3",
            "title": "High-brightness and high-flux cold neutron source utilizing high-aspect\n  ratio rectangular para-hydrogen moderators",
            "updated": "2023-12-07T17:04:21Z",
            "published": "2023-11-26T19:14:59Z",
            "summary": "A novel cold neutron source employing chess-board or staircase assemblies of\nhigh-aspect ratio rectangular \\hpara moderators is proposed. It is demonstrated\nthat this design can generate neutron beams with higher intensity and\nbrightness, up to approximately 2.5 times more than any \\hpara-based cold\nneutron source with an equal cold neutron beam cross-section made of a single\nmoderator (flat or voluminous). Two limiting factors for this gain are\nidentified: the limited volume of the high-density thermal neutron region\nsurrounding the reactor core or spallation target, which imposes constraints on\nthe total length of the moderator assembly, and the finite width of moderator\nwalls.\n  An analytic approach for calculating the brightness of \\hpara moderators is\nintroduced. Because brightness gain originates from a near-the-surface effect\nresulting from the prevailing single collision process during thermal-to-cold\nneutron conversion, high-aspect ratio rectangular cold moderators offer a\nsignificant increase, up to a factor of 10, in cold neutron brightness. The\nobtained results are in excellent agreement with MCNP calculations.\n  The concept of 'low-dimensionality' in moderators is explored, demonstrating\nthat achieving a substantial increase in brightness necessitates moderators to\nbe low-dimensional both geometrically, implying a high aspect ratio, and\nphysically, requiring the moderator's smallest dimension to be smaller than the\ncharacteristic scale of moderator medium (about the mean free path for thermal\nneutrons). This explains why additional compression of the moderator along the\nlongest direction, effectively giving it a tube-like shape, does not result in\na significant brightness increase comparable to the flattening of moderator.",
            "author": [
                "Alexander Ioffe",
                "Petr Konik",
                "Konstantin Batkov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15389v3",
                "http://arxiv.org/pdf/2311.15389v3"
            ],
            "primary_category": "physics.ins-det",
            "category": [
                "physics.ins-det"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15386v1",
            "title": "Spectro-ViT: A Vision Transformer Model for GABA-edited MRS\n  Reconstruction Using Spectrograms",
            "updated": "2023-11-26T19:09:28Z",
            "published": "2023-11-26T19:09:28Z",
            "summary": "Purpose: To investigate the use of a Vision Transformer (ViT) to\nreconstruct/denoise GABA-edited magnetic resonance spectroscopy (MRS) from a\nquarter of the typically acquired number of transients using spectrograms.\n  Theory and Methods: A quarter of the typically acquired number of transients\ncollected in GABA-edited MRS scans are pre-processed and converted to a\nspectrogram image representation using the Short-Time Fourier Transform (STFT).\nThe image representation of the data allows the adaptation of a pre-trained ViT\nfor reconstructing GABA-edited MRS spectra (Spectro-ViT). The Spectro-ViT is\nfine-tuned and then tested using \\textit{in vivo} GABA-edited MRS data. The\nSpectro-ViT performance is compared against other models in the literature\nusing spectral quality metrics and estimated metabolite concentration values.\n  Results: The Spectro-ViT model significantly outperformed all other models in\nfour out of five quantitative metrics (mean squared error, shape score,\nGABA+/water fit error, and full width at half maximum). The metabolite\nconcentrations estimated (GABA+/water, GABA+/Cr, and Glx/water) were consistent\nwith the metabolite concentrations estimated using typical GABA-edited MRS\nscans reconstructed with the full amount of typically collected transients.\n  Conclusion: The proposed Spectro-ViT model achieved state-of-the-art results\nin reconstructing GABA-edited MRS, and the results indicate these scans could\nbe up to four times faster.",
            "author": [
                "Gabriel Dias",
                "Rodrigo Pommot Berto",
                "Mateus Oliveira",
                "Lucas Ueda",
                "Sergio Dertkigil",
                "Paula D. P. Costa",
                "Amirmohammad Shamaei",
                "Roberto Souza",
                "Ashley Harris",
                "Leticia Rittner"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15386v1",
                "http://arxiv.org/pdf/2311.15386v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.LG",
                "physics.med-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15384v1",
            "title": "Robust and Automatic Data Clustering: Dirichlet Process meets\n  Median-of-Means",
            "updated": "2023-11-26T19:01:15Z",
            "published": "2023-11-26T19:01:15Z",
            "summary": "Clustering stands as one of the most prominent challenges within the realm of\nunsupervised machine learning. Among the array of centroid-based clustering\nalgorithms, the classic $k$-means algorithm, rooted in Lloyd's heuristic, takes\ncenter stage as one of the extensively employed techniques in the literature.\nNonetheless, both $k$-means and its variants grapple with noteworthy\nlimitations. These encompass a heavy reliance on initial cluster centroids,\nsusceptibility to converging into local minima of the objective function, and\nsensitivity to outliers and noise in the data. When confronted with data\ncontaining noisy or outlier-laden observations, the Median-of-Means (MoM)\nestimator emerges as a stabilizing force for any centroid-based clustering\nframework. On a different note, a prevalent constraint among existing\nclustering methodologies resides in the prerequisite knowledge of the number of\nclusters prior to analysis. Utilizing model-based methodologies, such as\nBayesian nonparametric models, offers the advantage of infinite mixture models,\nthereby circumventing the need for such requirements. Motivated by these facts,\nin this article, we present an efficient and automatic clustering technique by\nintegrating the principles of model-based and centroid-based methodologies that\nmitigates the effect of noise on the quality of clustering while ensuring that\nthe number of clusters need not be specified in advance. Statistical guarantees\non the upper bound of clustering error, and rigorous assessment through\nsimulated and real datasets suggest the advantages of our proposed method over\nexisting state-of-the-art clustering algorithms.",
            "author": [
                "Supratik Basu",
                "Jyotishka Ray Choudhury",
                "Debolina Paul",
                "Swagatam Das"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15384v1",
                "http://arxiv.org/pdf/2311.15384v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15383v1",
            "title": "Visual Programming for Zero-shot Open-Vocabulary 3D Visual Grounding",
            "updated": "2023-11-26T19:01:14Z",
            "published": "2023-11-26T19:01:14Z",
            "summary": "3D Visual Grounding (3DVG) aims at localizing 3D object based on textual\ndescriptions. Conventional supervised methods for 3DVG often necessitate\nextensive annotations and a predefined vocabulary, which can be restrictive. To\naddress this issue, we propose a novel visual programming approach for\nzero-shot open-vocabulary 3DVG, leveraging the capabilities of large language\nmodels (LLMs). Our approach begins with a unique dialog-based method, engaging\nwith LLMs to establish a foundational understanding of zero-shot 3DVG. Building\non this, we design a visual program that consists of three types of modules,\ni.e., view-independent, view-dependent, and functional modules. These modules,\nspecifically tailored for 3D scenarios, work collaboratively to perform complex\nreasoning and inference. Furthermore, we develop an innovative language-object\ncorrelation module to extend the scope of existing 3D object detectors into\nopen-vocabulary scenarios. Extensive experiments demonstrate that our zero-shot\napproach can outperform some supervised baselines, marking a significant stride\ntowards effective 3DVG.",
            "author": [
                "Zhihao Yuan",
                "Jinke Ren",
                "Chun-Mei Feng",
                "Hengshuang Zhao",
                "Shuguang Cui",
                "Zhen Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15383v1",
                "http://arxiv.org/pdf/2311.15383v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15381v1",
            "title": "On universality of regular realizability problems",
            "updated": "2023-11-26T18:53:33Z",
            "published": "2023-11-26T18:53:33Z",
            "summary": "We prove universality of the regular realizability problems for several\nclasses of filters. The filters are descriptions of finite relations on the set\nof non-negative integers in the format proposed by P. Wolf and H. Fernau. The\nuniversality has proven up to reductions using NP-oracles. It corresponds to\nthe results of P. Wolf and H. Fernau about decidability of regular\nrealizability problems for many graph-theoretic properties.",
            "author": [
                "Alexander Rubtsov",
                "Michael Vyalyi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15381v1",
                "http://arxiv.org/pdf/2311.15381v1"
            ],
            "primary_category": "cs.FL",
            "category": [
                "cs.FL",
                "68Q45",
                "F.4.3"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15376v2",
            "title": "Constructive validity of a generalized Kreisel-Putnam rule",
            "updated": "2023-11-28T13:04:28Z",
            "published": "2023-11-26T18:35:32Z",
            "summary": "In this paper, we propose a computational interpretation of the generalized\nKreisel-Putnam rule, also known as the generalized Harrop rule or simply the\nSplit rule, in the style of BHK semantics. We will achieve this by exploiting\nthe Curry-Howard correspondence between formulas and types. First, we inspect\nthe inferential behavior of the Split rule in the setting of a natural\ndeduction system for the intuitionistic propositional logic. This will guide\nour process of formulating an appropriate program that would capture the\ncorresponding computational content of the typed Split rule. In other words, we\nwant to find an appropriate selector function for the Split rule by considering\nits typed variant. Our investigation can also be reframed as an effort to\nanswer the following questions: is the Split rule constructively valid in the\nsense of BHK semantics? Our answer is positive for the Split rule as well as\nfor its newly proposed generalized version called the S rule.",
            "author": [
                "Ivo Pezlar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15376v2",
                "http://arxiv.org/pdf/2311.15376v2"
            ],
            "primary_category": "cs.LO",
            "category": [
                "cs.LO",
                "math.LO",
                "03F03, 03A05, 03F10"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15372v1",
            "title": "Exploring Mid-Air Hand Interaction in Data Visualization",
            "updated": "2023-11-26T18:05:07Z",
            "published": "2023-11-26T18:05:07Z",
            "summary": "Interacting with data visualizations without an instrument or touch surface\nis typically characterized by the use of mid-air hand gestures. While mid-air\nexpressions can be quite intuitive for interacting with digital content at a\ndistance, they frequently lack precision and necessitate a different way of\nexpressing users' data-related intentions. In this work, we aim to identify new\ndesigns for mid-air hand gesture manipulations that can facilitate\ninstrument-free, touch-free, and embedded interactions with visualizations,\nwhile utilizing the three-dimensional (3D) interaction space that mid-air\ngestures afford. We explore mid-air hand gestures for data visualization by\nsearching for natural means to interact with content. We employ three studies -\nan Elicitation Study, a User Study, and an Expert Study, to provide insight\ninto the users' mental models, explore the design space, and suggest\nconsiderations for future mid-air hand gesture design. In addition to forming\nstrong associations with physical manipulations, we discovered that mid-air\nhand gestures can: promote space-multiplexed interaction, which allows for a\ngreater degree of expression; play a functional role in visual cognition and\ncomprehension; and enhance creativity and engagement. We further highlight the\nchallenges that designers in this field may face to help set the stage for\ndeveloping effective gestures for a wide range of touchless interactions with\nvisualizations.",
            "author": [
                "Zona Kostic",
                "Catherine Dumas",
                "Sarah Pratt",
                "Johanna Beyer"
            ],
            "link": [
                "http://dx.doi.org/10.1109/TVCG.2023.3332647",
                "http://arxiv.org/abs/2311.15372v1",
                "http://arxiv.org/pdf/2311.15372v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15371v1",
            "title": "From nonreciprocal to charge-4e supercurrents in Ge-based Josephson\n  devices with tunable harmonic content",
            "updated": "2023-11-26T17:57:12Z",
            "published": "2023-11-26T17:57:12Z",
            "summary": "Hybrid superconductor(S)-semiconductor(Sm) devices bring a range of new\nfunctionalities into superconducting circuits. In particular, hybrid\nparity-protected qubits and Josephson diodes were recently proposed and\nexperimentally demonstrated. Such devices leverage the non-sinusoidal character\nof the Josephson current-phase relation (CPR) in highly transparent S-Sm-S\njunctions. Here we report an experimental study of superconducting\nquantum-interference devices (SQUIDs) embedding Josephson field-effect\ntransistors fabricated from a SiGe/Ge/SiGe heterostructure grown on a 200-mm\nsilicon wafer. The single-junction CPR shows up to three harmonics with gate\ntunable amplitude. In the presence of microwave irradiation, the ratio of the\nfirst two dominant harmonics, corresponding to single and double Cooper-pair\ntransport processes, is consistently reflected in relative weight of integer\nand half-integer Shapiro steps. A combination of magnetic-flux and gate-voltage\ncontrol enables tuning the SQUID functionality from a nonreciprocal\nJosephson-diode regime with 27% asymmetry to a $\\pi$-periodic Josephson regime\nsuitable for the implementation of parity-protected superconducting qubits.\nThese results illustrate the potential of Ge-based hybrid devices as versatile\nand scalable building blocks of novel superconducting quantum circuits.",
            "author": [
                "Axel Leblanc",
                "Chotivut Tangchingchai",
                "Zahra Sadre Momtaz",
                "Elyjah Kiyooka",
                "Jean-Michel Hartmann",
                "Gonzalo Troncoso Fernandez-Bada",
                "Boris Brun-Barriere",
                "Vivien Schmitt",
                "Simon Zihlmann",
                "Romain Maurand",
                "\u00c9tienne Dumur",
                "Silvano De Franceschi",
                "Fran\u00e7ois Lefloch"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15371v1",
                "http://arxiv.org/pdf/2311.15371v1"
            ],
            "primary_category": "cond-mat.mes-hall",
            "category": [
                "cond-mat.mes-hall",
                "cond-mat.supr-con"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15369v1",
            "title": "TD-Net: A Tri-domain network for sparse-view CT reconstruction",
            "updated": "2023-11-26T17:48:53Z",
            "published": "2023-11-26T17:48:53Z",
            "summary": "Sparse-view CT reconstruction, aimed at reducing X-ray radiation risks,\nfrequently suffers from image quality degradation, manifested as noise and\nartifacts. Existing post-processing and dual-domain techniques, although\neffective in radiation reduction, often lead to over-smoothed results,\ncompromising diagnostic clarity. Addressing this, we introduce TD-Net, a\npioneering tri-domain approach that unifies sinogram, image, and frequency\ndomain optimizations. By incorporating Frequency Supervision Module(FSM),\nTD-Net adeptly preserves intricate details, overcoming the prevalent\nover-smoothing issue. Extensive evaluations demonstrate TD-Net's superior\nperformance in reconstructing high-quality CT images from sparse views,\nefficiently balancing radiation safety and image fidelity. The enhanced\ncapabilities of TD-Net in varied noise scenarios highlight its potential as a\nbreakthrough in medical imaging.",
            "author": [
                "Xinyuan Wang",
                "Changqing Su",
                "Bo Xiong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15369v1",
                "http://arxiv.org/pdf/2311.15369v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.AI",
                "cs.CV",
                "cs.LG",
                "physics.med-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15366v1",
            "title": "Untargeted Code Authorship Evasion with Seq2Seq Transformation",
            "updated": "2023-11-26T17:45:57Z",
            "published": "2023-11-26T17:45:57Z",
            "summary": "Code authorship attribution is the problem of identifying authors of\nprogramming language codes through the stylistic features in their codes, a\ntopic that recently witnessed significant interest with outstanding\nperformance. In this work, we present SCAE, a code authorship obfuscation\ntechnique that leverages a Seq2Seq code transformer called StructCoder. SCAE\ncustomizes StructCoder, a system designed initially for function-level code\ntranslation from one language to another (e.g., Java to C#), using transfer\nlearning. SCAE improved the efficiency at a slight accuracy degradation\ncompared to existing work. We also reduced the processing time by about 68%\nwhile maintaining an 85% transformation success rate and up to 95.77% evasion\nsuccess rate in the untargeted setting.",
            "author": [
                "Soohyeon Choi",
                "Rhongho Jang",
                "DaeHun Nyang",
                "David Mohaisen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15366v1",
                "http://arxiv.org/pdf/2311.15366v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15365v1",
            "title": "A Convergence result of a continuous model of deep learning via\n  \u0141ojasiewicz--Simon inequality",
            "updated": "2023-11-26T17:44:29Z",
            "published": "2023-11-26T17:44:29Z",
            "summary": "This study focuses on a Wasserstein-type gradient flow, which represents an\noptimization process of a continuous model of a Deep Neural Network (DNN).\nFirst, we establish the existence of a minimizer for an average loss of the\nmodel under $L^2$-regularization. Subsequently, we show the existence of a\ncurve of maximal slope of the loss. Our main result is the convergence of flow\nto a critical point of the loss as time goes to infinity. An essential aspect\nof proving this result involves the establishment of the \\L{}ojasiewicz--Simon\ngradient inequality for the loss. We derive this inequality by assuming the\nanalyticity of NNs and loss functions. Our proofs offer a new approach for\nanalyzing the asymptotic behavior of Wasserstein-type gradient flows for\nnonconvex functionals.",
            "author": [
                "Noboru Isobe"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15365v1",
                "http://arxiv.org/pdf/2311.15365v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.AP",
                "math.FA",
                "math.PR",
                "35B40, 49J20, 49Q22, 68T07"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15362v1",
            "title": "Application of Process Mining and Sequence Clustering in Recognizing an\n  Industrial Issue",
            "updated": "2023-11-26T17:31:55Z",
            "published": "2023-11-26T17:31:55Z",
            "summary": "Process mining has become one of the best programs that can outline the event\nlogs of production processes in visualized detail. We have addressed the\nimportant problem that easily occurs in the industrial process called\nBottleneck. The analysis process was focused on extracting the bottlenecks in\nthe production line to improve the flow of production. Given enough stored\nhistory logs, the field of process mining can provide a suitable answer to\noptimize production flow by mitigating bottlenecks in the production stream.\nProcess mining diagnoses the productivity processes by mining event logs, this\ncan help to expose the opportunities to optimize critical production processes.\nWe found that there is a considerable bottleneck in the process because of the\nweaving activities. Through discussions with specialists, it was agreed that\nthe main problem in the weaving processes, especially machines that were\nexhausted in overloading processes. The improvement in the system has measured\nby teamwork; the cycle time for process has improved to 91%, the worker's\nperformance has improved to 96%,product quality has improved by 85%, and lead\ntime has optimized from days and weeks to hours.",
            "author": [
                "Hamza Saad"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15362v1",
                "http://arxiv.org/pdf/2311.15362v1"
            ],
            "primary_category": "econ.GN",
            "category": [
                "econ.GN",
                "q-fin.EC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15358v1",
            "title": "An optimised cuckoo-based discrete symbiotic organisms search strategy\n  for tasks scheduling in cloud computing environment",
            "updated": "2023-11-26T17:20:21Z",
            "published": "2023-11-26T17:20:21Z",
            "summary": "Currently, the cloud computing paradigm is experiencing rapid growth as there\nis a shift from other distributed computing methods and traditional IT\ninfrastructure towards it. Consequently, optimised task scheduling techniques\nhave become crucial in managing the expanding cloud computing environment. In\ncloud computing, numerous tasks need to be scheduled on a limited number of\ndiverse virtual machines to minimise the imbalance between the local and global\nsearch space; and optimise system utilisation. Task scheduling is a challenging\nproblem known as NP-complete, which means that there is no exact solution, and\nwe can only achieve near-optimal results, particularly when using large-scale\ntasks in the context of cloud computing. This paper proposes an optimised\nstrategy, Cuckoo-based Discrete Symbiotic Organisms Search (C-DSOS) that\nincorporated with Levy-Flight for optimal task scheduling in the cloud\ncomputing environment to minimise degree of imbalance. The strategy is based on\nthe Standard Symbiotic Organism Search (SOS), which is a nature-inspired\nmetaheuristic optimisation algorithm designed for numerical optimisation\nproblems. SOS simulates the symbiotic relationships observed in ecosystems,\nsuch as mutualism, commensalism, and parasitism. To evaluate the proposed\ntechnique, the CloudSim toolkit simulator was used to conduct experiments. The\nresults demonstrated that C-DSOS outperforms the Simulated Annealing Symbiotic\nOrganism Search (SASOS) algorithm, which is a benchmarked algorithm commonly\nused in task scheduling problems. C-DSOS exhibits a favourable convergence\nrate, especially when using larger search spaces, making it suitable for task\nscheduling problems in the cloud. For the analysis, a t-test was employed,\nreveals that C-DSOS is statistically significant compared to the benchmarked\nSASOS algorithm, particularly for scenarios involving a large search space.",
            "author": [
                "Suleiman Sa'ad",
                "Abdullah Muhammed",
                "Mohammed Abdullahi",
                "Azizol Abdullah"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15358v1",
                "http://arxiv.org/pdf/2311.15358v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15357v1",
            "title": "Controlling Atom-Surface Scattering with Laser Assisted Quantum\n  Reflection",
            "updated": "2023-11-26T17:18:08Z",
            "published": "2023-11-26T17:18:08Z",
            "summary": "In low energy atom-surface scattering, it is possible for the atom to be\nreflected in a region of attractive potential with no classical turning point.\nThis phenomenon has come to be known as quantum reflection and it can reduce\nthe sticking probability of atoms to surfaces, as well be used for atom\ntrapping. We simulate the quantum reflection process in a one-dimensional model\nwith a slow-moving atom moving in a Morse potential in the presence of an\napplied laser field. We show that in the case of laser-assisted quantum\nreflection, the laser field imparts additional momentum and kinetic energy to\nthe atom. This results in a decreased distance of closest approach between the\natom and surface. Our results show that the distance of closest approach and\ncan be controlled through the timing and intensity of the laser pulse, which\nmay result in enhanced sticking probability and/or reduced quantum reflection\nprobability.",
            "author": [
                "A. L. Harris"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15357v1",
                "http://arxiv.org/pdf/2311.15357v1"
            ],
            "primary_category": "physics.atom-ph",
            "category": [
                "physics.atom-ph",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15356v1",
            "title": "Having Second Thoughts? Let's hear it",
            "updated": "2023-11-26T17:17:28Z",
            "published": "2023-11-26T17:17:28Z",
            "summary": "Deep learning models loosely mimic bottom-up signal pathways from low-order\nsensory areas to high-order cognitive areas. After training, DL models can\noutperform humans on some domain-specific tasks, but their decision-making\nprocess has been known to be easily disrupted. Since the human brain consists\nof multiple functional areas highly connected to one another and relies on\nintricate interplays between bottom-up and top-down (from high-order to\nlow-order areas) processing, we hypothesize that incorporating top-down signal\nprocessing may make DL models more robust. To address this hypothesis, we\npropose a certification process mimicking selective attention and test if it\ncould make DL models more robust. Our empirical evaluations suggest that this\nnewly proposed certification can improve DL models' accuracy and help us build\nsafety measures to alleviate their vulnerabilities with both artificial and\nnatural adversarial examples.",
            "author": [
                "Jung H. Lee",
                "Sujith Vijayan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15356v1",
                "http://arxiv.org/pdf/2311.15356v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.03721v1",
            "title": "Exploring the Robustness of Model-Graded Evaluations and Automated\n  Interpretability",
            "updated": "2023-11-26T17:11:55Z",
            "published": "2023-11-26T17:11:55Z",
            "summary": "There has been increasing interest in evaluations of language models for a\nvariety of risks and characteristics. Evaluations relying on natural language\nunderstanding for grading can often be performed at scale by using other\nlanguage models. We test the robustness of these model-graded evaluations to\ninjections on different datasets including a new Deception Eval. These\ninjections resemble direct communication between the testee and the evaluator\nto change their grading. We extrapolate that future, more intelligent models\nmight manipulate or cooperate with their evaluation model. We find significant\nsusceptibility to these injections in state-of-the-art commercial models on all\nexamined evaluations. Furthermore, similar injections can be used on automated\ninterpretability frameworks to produce misleading model-written explanations.\nThe results inspire future work and should caution against unqualified trust in\nevaluations and automated interpretability.",
            "author": [
                "Simon Lermen",
                "Ond\u0159ej Kvapil"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03721v1",
                "http://arxiv.org/pdf/2312.03721v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15354v1",
            "title": "Web-Based Dynamic Paintings: Real-Time Interactive Artworks in Web Using\n  a 2.5D Pipeline",
            "updated": "2023-11-26T17:09:37Z",
            "published": "2023-11-26T17:09:37Z",
            "summary": "In this work, we present a 2.5D pipeline approach to creating dynamic\npaintings that can be re-rendered interactively in real-time on the Web. Using\nthis 2.5D approach, any existing simple painting such as portraits can be\nturned into an interactive dynamic web-based artwork. Our interactive system\nprovides most global illumination effects such as reflection, refraction,\nshadow, and subsurface scattering by processing images. In our system, the\nscene is defined only by a set of images. These include (1) a shape image, (2)\ntwo diffuse images, (3) a background image, (4) one foreground image, and (5)\none transparency image. A shape image is either a normal map or a height. Two\ndiffuse images are usually hand-painted. They are interpolated using\nillumination information. The transparency image is used to define the\ntransparent and reflective regions that can reflect the foreground image and\nrefract the background image, both of which are also hand-drawn. This\nframework, which mainly uses hand-drawn images, provides qualitatively\nconvincing painterly global illumination effects such as reflection and\nrefraction. We also include parameters to provide additional artistic controls.\nFor instance, using our piecewise linear Fresnel function, it is possible to\ncontrol the ratio of reflection and refraction. This system is the result of a\nlong line of research contributions. On the other hand, the art-directed\nFresnel function that provides physically plausible compositing of reflection\nand refraction with artistic control is completely new. Art-directed warping\nequations that provide qualitatively convincing refraction and reflection\neffects with linearized artistic control are also new. You can try our\nweb-based system for interactive dynamic real-time paintings at\nhttp://mock3d.tamu.edu/.",
            "author": [
                "Ergun Akleman",
                "Youyou wang",
                "Yinan Xiong",
                "Anusha Shanker",
                "Fermi Perumal",
                "Ozgur Gonen",
                "Motahareh Fard"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15354v1",
                "http://arxiv.org/pdf/2311.15354v1"
            ],
            "primary_category": "cs.GR",
            "category": [
                "cs.GR",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15342v1",
            "title": "Frobenius and commutative pseudomonoids in the bicategory of spans",
            "updated": "2023-11-26T16:03:49Z",
            "published": "2023-11-26T16:03:49Z",
            "summary": "In previous work by the first two authors, Frobenius and commutative algebra\nobjects in the category of spans of sets were characterized in terms of\nsimplicial sets satisfying certain properties. In this paper, we find a similar\ncharacterization for the analogous coherent structures in the bicategory of\nspans of sets. We show that commutative and Frobenius pseudomonoids in\n$\\operatorname{Span}$ correspond, respectively, to paracyclic sets and\n$\\Gamma$-sets satisfying the $2$-Segal conditions. These results connect\nclosely with work of the third author on $A_\\infty$ algebras in\n$\\infty$-categories of spans, as well as the growing body of work on higher\nSegal objects. Because our motivation comes from symplectic geometry and\ntopological field theory, we emphasize the direct and computational nature of\nthe classifications and their proofs.",
            "author": [
                "Ivan Contreras",
                "Rajan Amit Mehta",
                "Walker H. Stern"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15342v1",
                "http://arxiv.org/pdf/2311.15342v1"
            ],
            "primary_category": "math.CT",
            "category": [
                "math.CT",
                "18B10"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15341v1",
            "title": "Generative Modelling of Stochastic Actions with Arbitrary Constraints in\n  Reinforcement Learning",
            "updated": "2023-11-26T15:57:20Z",
            "published": "2023-11-26T15:57:20Z",
            "summary": "Many problems in Reinforcement Learning (RL) seek an optimal policy with\nlarge discrete multidimensional yet unordered action spaces; these include\nproblems in randomized allocation of resources such as placements of multiple\nsecurity resources and emergency response units, etc. A challenge in this\nsetting is that the underlying action space is categorical (discrete and\nunordered) and large, for which existing RL methods do not perform well.\nMoreover, these problems require validity of the realized action (allocation);\nthis validity constraint is often difficult to express compactly in a closed\nmathematical form. The allocation nature of the problem also prefers stochastic\noptimal policies, if one exists. In this work, we address these challenges by\n(1) applying a (state) conditional normalizing flow to compactly represent the\nstochastic policy -- the compactness arises due to the network only producing\none sampled action and the corresponding log probability of the action, which\nis then used by an actor-critic method; and (2) employing an invalid action\nrejection method (via a valid action oracle) to update the base policy. The\naction rejection is enabled by a modified policy gradient that we derive.\nFinally, we conduct extensive experiments to show the scalability of our\napproach compared to prior methods and the ability to enforce arbitrary\nstate-conditional constraints on the support of the distribution of actions in\nany state.",
            "author": [
                "Changyu Chen",
                "Ramesha Karunasena",
                "Thanh Hong Nguyen",
                "Arunesh Sinha",
                "Pradeep Varakantham"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15341v1",
                "http://arxiv.org/pdf/2311.15341v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15339v1",
            "title": "Adversarial Purification of Information Masking",
            "updated": "2023-11-26T15:50:19Z",
            "published": "2023-11-26T15:50:19Z",
            "summary": "Adversarial attacks meticulously generate minuscule, imperceptible\nperturbations to images to deceive neural networks. Counteracting these,\nadversarial purification methods seek to transform adversarial input samples\ninto clean output images to defend against adversarial attacks. Nonetheless,\nextent generative models fail to effectively eliminate adversarial\nperturbations, yielding less-than-ideal purification results. We emphasize the\npotential threat of residual adversarial perturbations to target models,\nquantitatively establishing a relationship between perturbation scale and\nattack capability. Notably, the residual perturbations on the purified image\nprimarily stem from the same-position patch and similar patches of the\nadversarial sample. We propose a novel adversarial purification approach named\nInformation Mask Purification (IMPure), aims to extensively eliminate\nadversarial perturbations. To obtain an adversarial sample, we first mask part\nof the patches information, then reconstruct the patches to resist adversarial\nperturbations from the patches. We reconstruct all patches in parallel to\nobtain a cohesive image. Then, in order to protect the purified samples against\npotential similar regional perturbations, we simulate this risk by randomly\nmixing the purified samples with the input samples before inputting them into\nthe feature extraction network. Finally, we establish a combined constraint of\npixel loss and perceptual loss to augment the model's reconstruction\nadaptability. Extensive experiments on the ImageNet dataset with three\nclassifier models demonstrate that our approach achieves state-of-the-art\nresults against nine adversarial attack methods. Implementation code and\npre-trained weights can be accessed at\n\\textcolor{blue}{https://github.com/NoWindButRain/IMPure}.",
            "author": [
                "Sitong Liu",
                "Zhichao Lian",
                "Shuangquan Zhang",
                "Liang Xiao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15339v1",
                "http://arxiv.org/pdf/2311.15339v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CR",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15335v1",
            "title": "Token Recycling for Efficient Sequential Inference with Vision\n  Transformers",
            "updated": "2023-11-26T15:39:57Z",
            "published": "2023-11-26T15:39:57Z",
            "summary": "Vision Transformers (ViTs) overpass Convolutional Neural Networks in\nprocessing incomplete inputs because they do not require the imputation of\nmissing values. Therefore, ViTs are well suited for sequential decision-making,\ne.g. in the Active Visual Exploration problem. However, they are\ncomputationally inefficient because they perform a full forward pass each time\na piece of new sequential information arrives.\n  To reduce this computational inefficiency, we introduce the TOken REcycling\n(TORE) modification for the ViT inference, which can be used with any\narchitecture. TORE divides ViT into two parts, iterator and aggregator. An\niterator processes sequential information separately into midway tokens, which\nare cached. The aggregator processes midway tokens jointly to obtain the\nprediction. This way, we can reuse the results of computations made by\niterator.\n  Except for efficient sequential inference, we propose a complementary\ntraining policy, which significantly reduces the computational burden\nassociated with sequential decision-making while achieving state-of-the-art\naccuracy.",
            "author": [
                "Jan Olszewski",
                "Dawid Rymarczyk",
                "Piotr W\u00f3jcik",
                "Mateusz Pach",
                "Bartosz Zieli\u0144ski"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15335v1",
                "http://arxiv.org/pdf/2311.15335v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15331v1",
            "title": "How much data do I need? A case study on medical data",
            "updated": "2023-11-26T15:31:51Z",
            "published": "2023-11-26T15:31:51Z",
            "summary": "The collection of data to train a Deep Learning network is costly in terms of\neffort and resources. In many cases, especially in a medical context, it may\nhave detrimental impacts. Such as requiring invasive medical procedures or\nprocesses which could in themselves cause medical harm. However, Deep Learning\nis seen as a data hungry method. Here, we look at two commonly held adages i)\nmore data gives better results and ii) transfer learning will aid you when you\ndon't have enough data. These are widely assumed to be true and used as\nevidence for choosing how to solve a problem when Deep Learning is involved. We\nevaluate six medical datasets and six general datasets. Training a ResNet18\nnetwork on varying subsets of these datasets to evaluate `more data gives\nbetter results'. We take eleven of these datasets as the sources for Transfer\nLearning on subsets of the twelfth dataset -- Chest -- in order to determine\nwhether Transfer Learning is universally beneficial. We go further to see\nwhether multi-stage Transfer Learning provides a consistent benefit. Our\nanalysis shows that the real situation is more complex than these simple adages\n-- more data could lead to a case of diminishing returns and an incorrect\nchoice of dataset for transfer learning can lead to worse performance, with\ndatasets which we would consider highly similar to the Chest dataset giving\nworse results than datasets which are more dissimilar. Multi-stage transfer\nlearning likewise reveals complex relationships between datasets.",
            "author": [
                "Ayse Betul Cengiz",
                "A. Stephen McGough"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15331v1",
                "http://arxiv.org/pdf/2311.15331v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15330v1",
            "title": "Multi-Agent Combinatorial Path Finding with Heterogeneous Task Duration",
            "updated": "2023-11-26T15:28:53Z",
            "published": "2023-11-26T15:28:53Z",
            "summary": "Multi-Agent Combinatorial Path Finding (MCPF) seeks collision-free paths for\nmultiple agents from their initial locations to destinations, visiting a set of\nintermediate target locations in the middle of the paths, while minimizing the\nsum of arrival times. While a few approaches have been developed to handle\nMCPF, most of them simply direct the agent to visit the targets without\nconsidering the task duration, i.e., the amount of time needed for an agent to\nexecute the task (such as picking an item) at a target location. MCPF is\nNP-hard to solve to optimality, and the inclusion of task duration further\ncomplicates the problem. This paper investigates heterogeneous task duration,\nwhere the duration can be different with respect to both the agents and\ntargets. We develop two methods, where the first method post-processes the\npaths planned by any MCPF planner to include the task duration and has no\nsolution optimality guarantee; and the second method considers task duration\nduring planning and is able to ensure solution optimality. The numerical and\nsimulation results show that our methods can handle up to 20 agents and 50\ntargets in the presence of task duration, and can execute the paths subject to\nrobot motion disturbance.",
            "author": [
                "Yuanhang Zhang",
                "Hesheng Wang",
                "Zhongqiang Ren"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15330v1",
                "http://arxiv.org/pdf/2311.15330v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15328v1",
            "title": "BS-Diff: Effective Bone Suppression Using Conditional Diffusion Models\n  from Chest X-Ray Images",
            "updated": "2023-11-26T15:13:13Z",
            "published": "2023-11-26T15:13:13Z",
            "summary": "Chest X-rays (CXRs) are commonly utilized as a low-dose modality for lung\nscreening. Nonetheless, the efficacy of CXRs is somewhat impeded, given that\napproximately 75% of the lung area overlaps with bone, which in turn hampers\nthe detection and diagnosis of diseases. As a remedial measure, bone\nsuppression techniques have been introduced. The current dual-energy\nsubtraction imaging technique in the clinic requires costly equipment and\nsubjects being exposed to high radiation. To circumvent these issues, deep\nlearning-based image generation algorithms have been proposed. However,\nexisting methods fall short in terms of producing high-quality images and\ncapturing texture details, particularly with pulmonary vessels. To address\nthese issues, this paper proposes a new bone suppression framework, termed\nBS-Diff, that comprises a conditional diffusion model equipped with a U-Net\narchitecture and a simple enhancement module to incorporate an autoencoder. Our\nproposed network cannot only generate soft tissue images with a high bone\nsuppression rate but also possesses the capability to capture fine image\ndetails. Additionally, we compiled the largest dataset since 2010, including\ndata from 120 patients with high-definition, high-resolution paired CXRs and\nsoft tissue images collected by our affiliated hospital. Extensive experiments,\ncomparative analyses, ablation studies, and clinical evaluations indicate that\nthe proposed BS-Diff outperforms several bone-suppression models across\nmultiple metrics.",
            "author": [
                "Zhanghao Chen",
                "Yifei Sun",
                "Wenjian Qin",
                "Ruiquan Ge",
                "Cheng Pan",
                "Wenming Deng",
                "Zhou Liu",
                "Wenwen Min",
                "Ahmed Elazab",
                "Xiang Wan",
                "Changmiao Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15328v1",
                "http://arxiv.org/pdf/2311.15328v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15327v2",
            "title": "FRAC-Q-Learning: A Reinforcement Learning with Boredom Avoidance\n  Processes for Social Robots",
            "updated": "2023-12-07T03:21:06Z",
            "published": "2023-11-26T15:11:17Z",
            "summary": "The reinforcement learning algorithms have often been applied to social\nrobots. However, most reinforcement learning algorithms were not optimized for\nthe use of social robots, and consequently they may bore users. We proposed a\nnew reinforcement learning method specialized for the social robot, the\nFRAC-Q-learning, that can avoid user boredom. The proposed algorithm consists\nof a forgetting process in addition to randomizing and categorizing processes.\nThis study evaluated interest and boredom hardness scores of the\nFRAC-Q-learning by a comparison with the traditional Q-learning. The\nFRAC-Q-learning showed significantly higher trend of interest score, and\nindicated significantly harder to bore users compared to the traditional\nQ-learning. Therefore, the FRAC-Q-learning can contribute to develop a social\nrobot that will not bore users. The proposed algorithm can also find\napplications in Web-based communication and educational systems. This paper\npresents the entire process, detailed implementation and a detailed evaluation\nmethod of the of the FRAC-Q-learning for the first time.",
            "author": [
                "Akinari Onishi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15327v2",
                "http://arxiv.org/pdf/2311.15327v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.HC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16195v1",
            "title": "A Foundational Framework and Methodology for Personalized Early and\n  Timely Diagnosis",
            "updated": "2023-11-26T14:42:31Z",
            "published": "2023-11-26T14:42:31Z",
            "summary": "Early diagnosis of diseases holds the potential for deep transformation in\nhealthcare by enabling better treatment options, improving long-term survival\nand quality of life, and reducing overall cost. With the advent of medical big\ndata, advances in diagnostic tests as well as in machine learning and\nstatistics, early or timely diagnosis seems within reach. Early diagnosis\nresearch often neglects the potential for optimizing individual diagnostic\npaths. To enable personalized early diagnosis, a foundational framework is\nneeded that delineates the diagnosis process and systematically identifies the\ntime-dependent value of various diagnostic tests for an individual patient\ngiven their unique characteristics. Here, we propose the first foundational\nframework for early and timely diagnosis. It builds on decision-theoretic\napproaches to outline the diagnosis process and integrates machine learning and\nstatistical methodology for estimating the optimal personalized diagnostic\npath. To describe the proposed framework as well as possibly other frameworks,\nwe provide essential definitions.\n  The development of a foundational framework is necessary for several reasons:\n1) formalism provides clarity for the development of decision support tools; 2)\nobserved information can be complemented with estimates of the future patient\ntrajectory; 3) the net benefit of counterfactual diagnostic paths and\nassociated uncertainties can be modeled for individuals 4) 'early' and 'timely'\ndiagnosis can be clearly defined; 5) a mechanism emerges for assessing the\nvalue of technologies in terms of their impact on personalized early diagnosis,\nresulting health outcomes and incurred costs.\n  Finally, we hope that this foundational framework will unlock the\nlong-awaited potential of timely diagnosis and intervention, leading to\nimproved outcomes for patients and higher cost-effectiveness for healthcare\nsystems.",
            "author": [
                "Tim Schubert",
                "Richard W Peck",
                "Alexander Gimson",
                "Camelia Davtyan",
                "Mihaela van der Schaar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16195v1",
                "http://arxiv.org/pdf/2311.16195v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15318v1",
            "title": "Perspective in Opinion Dynamics on Complex Convex Domains of Time\n  Networks for Addiction, Forgetting",
            "updated": "2023-11-26T14:36:32Z",
            "published": "2023-11-26T14:36:32Z",
            "summary": "This paper revises previous work and introduces changes in spatio-temporal\nscales. The paper presents a model that includes layers A and B with varying\ndegrees of forgetting and dependence over time. We also model changes in\ndependence and forgetting in layers A, A', B, and B' under certain conditions.\nIn addition, to discuss the formation of opinion clusters that have reinforcing\nor obstructive behaviors of forgetting and dependence and are conservative or\nbrainwashing or detoxifying and less prone to filter bubbling, new clusters C\nand D that recommend, obstruct, block, or incite forgetting and dependence over\ntime are Introduction. This introduction allows us to test hypotheses regarding\nthe expansion of opinions in two dimensions over time and space, the state of\ndevelopment of opinion space, and the expansion of public opinion. Challenges\nin consensus building will be highlighted, emphasizing the dynamic nature of\nopinions and the need to consider factors such as dissent, distrust, and media\ninfluence. The paper proposes an extended framework that incorporates trust,\ndistrust, and media influence into the consensus building model. We introduce\nnetwork analysis using dimerizing as a method to gain deeper insights. In this\ncontext, we discuss network clustering, media influence, and consensus\nbuilding. The location and distribution of dimers will be analyzed to gain\ninsight into the structure and dynamics of the network. Dimertiling has been\napplied in various fields other than network analysis, such as physics and\nsociology. The paper concludes by emphasizing the importance of diverse\nperspectives, network analysis, and influential entities in consensus building.\nIt also introduces torus-based visualizations that aid in understanding complex\nnetwork structures.",
            "author": [
                "Yasuko Kawahata"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15318v1",
                "http://arxiv.org/pdf/2311.15318v1"
            ],
            "primary_category": "physics.soc-ph",
            "category": [
                "physics.soc-ph",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15316v1",
            "title": "Enhancing Empathetic and Emotion Support Dialogue Generation with\n  Prophetic Commonsense Inference",
            "updated": "2023-11-26T14:35:23Z",
            "published": "2023-11-26T14:35:23Z",
            "summary": "The interest in Empathetic and Emotional Support conversations among the\npublic has significantly increased. To offer more sensitive and understanding\nresponses, leveraging commonsense knowledge has become a common strategy to\nbetter understand psychological aspects and causality. However, such\ncommonsense inferences can be out of context and unable to predict upcoming\ndialogue themes, resulting in responses that lack coherence and empathy. To\nremedy this issue, we present Prophetic Commonsense Inference, an innovative\nparadigm for inferring commonsense knowledge. By harnessing the capabilities of\nLarge Language Models in understanding dialogue and making commonsense\ndeductions, we train tunable models to bridge the gap between past and\npotential future dialogues. Extensive experiments conducted on\nEmpatheticDialogues and Emotion Support Conversation show that equipping\ndialogue agents with our proposed prophetic commonsense inference significantly\nenhances the quality of their responses.",
            "author": [
                "Lanrui Wang",
                "Jiangnan Li",
                "Chenxu Yang",
                "Zheng Lin",
                "Weiping Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15316v1",
                "http://arxiv.org/pdf/2311.15316v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15313v1",
            "title": "Low-Complexity Joint Beamforming for RIS-Assisted MU-MISO Systems Based\n  on Model-Driven Deep Learning",
            "updated": "2023-11-26T14:24:26Z",
            "published": "2023-11-26T14:24:26Z",
            "summary": "Reconfigurable intelligent surfaces (RIS) can improve signal propagation\nenvironments by adjusting the phase of the incident signal. However, optimizing\nthe phase shifts jointly with the beamforming vector at the access point is\nchallenging due to the non-convex objective function and constraints. In this\nstudy, we propose an algorithm based on weighted minimum mean square error\noptimization and power iteration to maximize the weighted sum rate (WSR) of a\nRIS-assisted downlink multi-user multiple-input single-output system. To\nfurther improve performance, a model-driven deep learning (DL) approach is\ndesigned, where trainable variables and graph neural networks are introduced to\naccelerate the convergence of the proposed algorithm. We also extend the\nproposed method to include beamforming with imperfect channel state information\nand derive a two-timescale stochastic optimization algorithm. Simulation\nresults show that the proposed algorithm outperforms state-of-the-art\nalgorithms in terms of complexity and WSR. Specifically, the model-driven DL\napproach has a runtime that is approximately 3% of the state-of-the-art\nalgorithm to achieve the same performance. Additionally, the proposed algorithm\nwith 2-bit phase shifters outperforms the compared algorithm with continuous\nphase shift.",
            "author": [
                "Weijie Jin",
                "Jing Zhang",
                "Chao-Kai Wen",
                "Shi Jin",
                "Xiao Li",
                "Shuangfeng Han"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15313v1",
                "http://arxiv.org/pdf/2311.15313v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16194v1",
            "title": "BadCLIP: Trigger-Aware Prompt Learning for Backdoor Attacks on CLIP",
            "updated": "2023-11-26T14:24:13Z",
            "published": "2023-11-26T14:24:13Z",
            "summary": "Contrastive Vision-Language Pre-training, known as CLIP, has shown promising\neffectiveness in addressing downstream image recognition tasks. However, recent\nworks revealed that the CLIP model can be implanted with a downstream-oriented\nbackdoor. On downstream tasks, one victim model performs well on clean samples\nbut predicts a specific target class whenever a specific trigger is present.\nFor injecting a backdoor, existing attacks depend on a large amount of\nadditional data to maliciously fine-tune the entire pre-trained CLIP model,\nwhich makes them inapplicable to data-limited scenarios. In this work,\nmotivated by the recent success of learnable prompts, we address this problem\nby injecting a backdoor into the CLIP model in the prompt learning stage. Our\nmethod named BadCLIP is built on a novel and effective mechanism in backdoor\nattacks on CLIP, i.e., influencing both the image and text encoders with the\ntrigger. It consists of a learnable trigger applied to images and a\ntrigger-aware context generator, such that the trigger can change text features\nvia trigger-aware prompts, resulting in a powerful and generalizable attack.\nExtensive experiments conducted on 11 datasets verify that the clean accuracy\nof BadCLIP is similar to those of advanced prompt learning methods and the\nattack success rate is higher than 99% in most cases. BadCLIP is also\ngeneralizable to unseen classes, and shows a strong generalization capability\nunder cross-dataset and cross-domain settings.",
            "author": [
                "Jiawang Bai",
                "Kuofeng Gao",
                "Shaobo Min",
                "Shu-Tao Xia",
                "Zhifeng Li",
                "Wei Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16194v1",
                "http://arxiv.org/pdf/2311.16194v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15312v1",
            "title": "A Low-cost and Portable Active Noise Control Unit",
            "updated": "2023-11-26T14:20:58Z",
            "published": "2023-11-26T14:20:58Z",
            "summary": "The objective of this research is to employ cutting-edge active noise control\nmethodologies in order to mitigate the noise emissions produced by electrical\nappliances, such as a coffee machine. The algorithm utilized in this study is\nthe modified Filtered-X Least Mean Square (FXLMS) algorithm. This algorithm\naims to generate an anti-noise waveform by utilizing measurements from both the\nreference microphone and the error microphone. The desired outcome of this\napproach is to achieve a residual noise level of zero. The primary difficulty\nlies in conducting the experiment in an open space setting, as conventional\nactive noise control systems are designed to function within enclosed\nenvironments, such as closed rooms or relatively confined spaces like the\nvolume inside headphones. A validation test bench is established, employing the\nSigma Studio software to oversee the entire system, with the ADAU1452 digital\nsignal processor being chosen. This study presents an introduction to different\nActive Noise Control systems and algorithms, followed by the execution of\nsimulations for representative techniques. Subsequently, this section provides\na comprehensive account of the procedures involved in executing the\nexperiments, followed by an exploration of potential avenues for further\nresearch.",
            "author": [
                "Wang Zhaohan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15312v1",
                "http://arxiv.org/pdf/2311.15312v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15309v1",
            "title": "Deep Refinement-Based Joint Source Channel Coding over Time-Varying\n  Channels",
            "updated": "2023-11-26T14:18:50Z",
            "published": "2023-11-26T14:18:50Z",
            "summary": "In recent developments, deep learning (DL)-based joint source-channel coding\n(JSCC) for wireless image transmission has made significant strides in\nperformance enhancement. Nonetheless, the majority of existing DL-based JSCC\nmethods are tailored for scenarios featuring stable channel conditions, notably\na fixed signal-to-noise ratio (SNR). This specialization poses a limitation, as\ntheir performance tends to wane in practical scenarios marked by highly dynamic\nchannels, given that a fixed SNR inadequately represents the dynamic nature of\nsuch channels. In response to this challenge, we introduce a novel solution,\nnamely deep refinement-based JSCC (DRJSCC). This innovative method is designed\nto seamlessly adapt to channels exhibiting temporal variations. By leveraging\ninstantaneous channel state information (CSI), we dynamically optimize the\nencoding strategy through re-encoding the channel symbols. This dynamic\nadjustment ensures that the encoding strategy consistently aligns with the\nvarying channel conditions during the transmission process. Specifically, our\napproach begins with the division of encoded symbols into multiple blocks,\nwhich are transmitted progressively to the receiver. In the event of changing\nchannel conditions, we propose a mechanism to re-encode the remaining blocks,\nallowing them to adapt to the current channel conditions. Experimental results\nshow that the DRJSCC scheme achieves comparable performance to the other\nmainstream DL-based JSCC models in stable channel conditions, and also exhibits\ngreat robustness against time-varying channels.",
            "author": [
                "Junyu Pan",
                "Hanlei Li",
                "Guangyi Zhang",
                "Yunlong Cai",
                "Guanding Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15309v1",
                "http://arxiv.org/pdf/2311.15309v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15308v1",
            "title": "AV-Deepfake1M: A Large-Scale LLM-Driven Audio-Visual Deepfake Dataset",
            "updated": "2023-11-26T14:17:51Z",
            "published": "2023-11-26T14:17:51Z",
            "summary": "The detection and localization of highly realistic deepfake audio-visual\ncontent are challenging even for the most advanced state-of-the-art methods.\nWhile most of the research efforts in this domain are focused on detecting\nhigh-quality deepfake images and videos, only a few works address the problem\nof the localization of small segments of audio-visual manipulations embedded in\nreal videos. In this research, we emulate the process of such content\ngeneration and propose the AV-Deepfake1M dataset. The dataset contains\ncontent-driven (i) video manipulations, (ii) audio manipulations, and (iii)\naudio-visual manipulations for more than 2K subjects resulting in a total of\nmore than 1M videos. The paper provides a thorough description of the proposed\ndata generation pipeline accompanied by a rigorous analysis of the quality of\nthe generated data. The comprehensive benchmark of the proposed dataset\nutilizing state-of-the-art deepfake detection and localization methods\nindicates a significant drop in performance compared to previous datasets. The\nproposed dataset will play a vital role in building the next-generation\ndeepfake localization methods. The dataset and associated code are available at\nhttps://github.com/ControlNet/AV-Deepfake1M .",
            "author": [
                "Zhixi Cai",
                "Shreya Ghosh",
                "Aman Pankaj Adatia",
                "Munawar Hayat",
                "Abhinav Dhall",
                "Kalin Stefanov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15308v1",
                "http://arxiv.org/pdf/2311.15308v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15307v1",
            "title": "Toward More Realistic Mass Functions For Ultradense Dark Matter Halos",
            "updated": "2023-11-26T14:15:11Z",
            "published": "2023-11-26T14:15:11Z",
            "summary": "Ultradense dark matter halos (UDMHs) are high concentrations of dark matter\nwhich are assumed to have formed from amplified primordial perturbations,\nalongside the primordial black holes (PBHs). In this work we calculate the\nabundance of UDMHs and improve the previous works by elaborating on the\nformation process of these halos through including various physical and\ngeometrical modifications in the analysis. In particular, we investigate the\nimpact of angular momentum, dynamical friction and triaxial collapse on the\npredicted mass functions for UDMHs. We perform the calculations for four\nprimordial power spectra with different amplified features that allow for (PBH\nand) UDHM formation in a wide mass range. We find that the abundance of UDMHs\nis prominently enhanced in the presence of these more realistic physical\nmodifications. Comparison of the results with the current observational bounds\non PBHs also implies that the UDMHs are expected to significantly outnumber\nPBHs in broad mass intervals, with the details depending on the primordial\npower spectrum.",
            "author": [
                "Saeed Fakhry",
                "Marzieh Farhang",
                "Antonino Del Popolo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15307v1",
                "http://arxiv.org/pdf/2311.15307v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO",
                "gr-qc"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15306v1",
            "title": "Sketch Video Synthesis",
            "updated": "2023-11-26T14:14:04Z",
            "published": "2023-11-26T14:14:04Z",
            "summary": "Understanding semantic intricacies and high-level concepts is essential in\nimage sketch generation, and this challenge becomes even more formidable when\napplied to the domain of videos. To address this, we propose a novel\noptimization-based framework for sketching videos represented by the frame-wise\nB\\'ezier curve. In detail, we first propose a cross-frame stroke initialization\napproach to warm up the location and the width of each curve. Then, we optimize\nthe locations of these curves by utilizing a semantic loss based on CLIP\nfeatures and a newly designed consistency loss using the self-decomposed 2D\natlas network. Built upon these design elements, the resulting sketch video\nshowcases impressive visual abstraction and temporal coherence. Furthermore, by\ntransforming a video into SVG lines through the sketching process, our method\nunlocks applications in sketch-based video editing and video doodling, enabled\nthrough video composition, as exemplified in the teaser.",
            "author": [
                "Yudian Zheng",
                "Xiaodong Cun",
                "Menghan Xia",
                "Chi-Man Pun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15306v1",
                "http://arxiv.org/pdf/2311.15306v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15302v1",
            "title": "A Quick Response Algorithm for Dynamic Autonomous Mobile Robot Routing\n  Problem with Time Windows",
            "updated": "2023-11-26T13:57:09Z",
            "published": "2023-11-26T13:57:09Z",
            "summary": "This paper investigates the optimization problem of scheduling autonomous\nmobile robots (AMRs) in hospital settings, considering dynamic requests with\ndifferent priorities. The primary objective is to minimize the daily service\ncost by dynamically planning routes for the limited number of available AMRs.\nThe total cost consists of AMR's purchase cost, transportation cost, delay\npenalty cost, and loss of denial of service. To address this problem, we have\nestablished a two-stage mathematical programming model. In the first stage, a\ntabu search algorithm is employed to plan prior routes for all known medical\nrequests. The second stage involves planning for real-time received dynamic\nrequests using the efficient insertion algorithm with decision rules, which\nenables quick response based on the time window and demand constraints of the\ndynamic requests. One of the main contributions of this study is to make\nresource allocation decisions based on the present number of service AMRs for\ndynamic requests with different priorities. Computational experiments using\nLackner instances demonstrate the efficient insertion algorithm with decision\nrules is very fast and robust in solving the dynamic AMR routing problem with\ntime windows and request priority. Additionally, we provide managerial insights\nconcerning the AMR's safety stock settings, which can aid in decision-making\nprocesses.",
            "author": [
                "Lulu Cheng",
                "Ning Zhao",
                "Mengge Yuan",
                "Kan Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15302v1",
                "http://arxiv.org/pdf/2311.15302v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15301v1",
            "title": "Eye Disease Prediction using Ensemble Learning and Attention on OCT\n  Scans",
            "updated": "2023-11-26T13:55:24Z",
            "published": "2023-11-26T13:55:24Z",
            "summary": "Eye diseases have posed significant challenges for decades, but advancements\nin technology have opened new avenues for their detection and treatment.\nMachine learning and deep learning algorithms have become instrumental in this\ndomain, particularly when combined with Optical Coherent Technology (OCT)\nimaging. We propose a novel method for efficient detection of eye diseases from\nOCT images. Our technique enables the classification of patients into disease\nfree (normal eyes) or affected by specific conditions such as Choroidal\nNeovascularization (CNV), Diabetic Macular Edema (DME), or Drusen. In this\nwork, we introduce an end to end web application that utilizes machine learning\nand deep learning techniques for efficient eye disease prediction. The\napplication allows patients to submit their raw OCT scanned images, which\nundergo segmentation using a trained custom UNet model. The segmented images\nare then fed into an ensemble model, comprising InceptionV3 and Xception\nnetworks, enhanced with a self attention layer. This self attention approach\nleverages the feature maps of individual models to achieve improved\nclassification accuracy. The ensemble model's output is aggregated to predict\nand classify various eye diseases. Extensive experimentation and optimization\nhave been conducted to ensure the application's efficiency and optimal\nperformance. Our results demonstrate the effectiveness of the proposed approach\nin accurate eye disease prediction. The developed web application holds\nsignificant potential for early detection and timely intervention, thereby\ncontributing to improved eye healthcare outcomes.",
            "author": [
                "Gauri Naik",
                "Nandini Narvekar",
                "Dimple Agarwal",
                "Nishita Nandanwar",
                "Himangi Pande"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15301v1",
                "http://arxiv.org/pdf/2311.15301v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15299v1",
            "title": "Covariance-Based Activity Detection in Cooperative Multi-Cell Massive\n  MIMO: Scaling Law and Efficient Algorithms",
            "updated": "2023-11-26T13:49:13Z",
            "published": "2023-11-26T13:49:13Z",
            "summary": "This paper focuses on the covariance-based activity detection problem in a\nmulti-cell massive multiple-input multiple-output (MIMO) system. In this\nsystem, active devices transmit their signature sequences to multiple base\nstations (BSs), and the BSs cooperatively detect the active devices based on\nthe received signals. While the scaling law for the covariance-based activity\ndetection in the single-cell scenario has been extensively analyzed in the\nliterature, this paper aims to analyze the scaling law for the covariance-based\nactivity detection in the multi-cell massive MIMO system. Specifically, this\npaper demonstrates a quadratic scaling law in the multi-cell system, under the\nassumption that the exponent in the classical path-loss model is greater than\n2. This finding shows that, in the multi-cell MIMO system, the maximum number\nof active devices that can be detected correctly in each cell increases\nquadratically with the length of the signature sequence and decreases\nlogarithmically with the number of cells (as the number of antennas tends to\ninfinity). Moreover, in addition to analyzing the scaling law for the signature\nsequences randomly and uniformly distributed on a sphere, the paper also\nestablishes the scaling law for signature sequences generated from a finite\nalphabet, which are easier to generate and store. Moreover, this paper proposes\ntwo efficient accelerated coordinate descent (CD) algorithms with a convergence\nguarantee for solving the device activity detection problem. The first\nalgorithm reduces the complexity of CD by using an inexact coordinate update\nstrategy. The second algorithm avoids unnecessary computations of CD by using\nan active set selection strategy. Simulation results show that the proposed\nalgorithms exhibit excellent performance in terms of computational efficiency\nand detection error probability.",
            "author": [
                "Ziyue Wang",
                "Ya-Feng Liu",
                "Zhaorui Wang",
                "Wei Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15299v1",
                "http://arxiv.org/pdf/2311.15299v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "eess.SP",
                "math.IT",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15297v1",
            "title": "Controllable Expensive Multi-objective Optimization with Warm-starting\n  Gaussian Processes",
            "updated": "2023-11-26T13:45:21Z",
            "published": "2023-11-26T13:45:21Z",
            "summary": "Pareto Set Learning (PSL) is a promising approach for approximating the\nentire Pareto front in multi-objective optimization (MOO) problems. However,\nexisting derivative-free PSL methods are often unstable and inefficient,\nespecially for expensive black-box MOO problems where objective function\nevaluations are costly. In this work, we propose to address the instability and\ninefficiency of existing PSL methods with a novel controllable PSL method,\ncalled Co-PSL. Particularly, Co-PSL consists of two stages: (1) warm-starting\nBayesian optimization to obtain quality Gaussian Processes priors and (2)\ncontrollable Pareto set learning to accurately acquire a parametric mapping\nfrom preferences to the corresponding Pareto solutions. The former is to help\nstabilize the PSL process and reduce the number of expensive function\nevaluations. The latter is to support real-time trade-off control between\nconflicting objectives. Performances across synthesis and real-world MOO\nproblems showcase the effectiveness of our Co-PSL for expensive multi-objective\noptimization tasks.",
            "author": [
                "Quang-Huy Nguyen",
                "Long P. Hoang",
                "Hoang V. Viet",
                "Dung D. Le"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15297v1",
                "http://arxiv.org/pdf/2311.15297v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15296v1",
            "title": "UHGEval: Benchmarking the Hallucination of Chinese Large Language Models\n  via Unconstrained Generation",
            "updated": "2023-11-26T13:42:56Z",
            "published": "2023-11-26T13:42:56Z",
            "summary": "Large language models (LLMs) have emerged as pivotal contributors in\ncontemporary natural language processing and are increasingly being applied\nacross a diverse range of industries. However, these large-scale probabilistic\nstatistical models cannot currently ensure the requisite quality in\nprofessional content generation. These models often produce hallucinated text,\ncompromising their practical utility in professional contexts. To assess the\nauthentic reliability of LLMs in text generation, numerous initiatives have\ndeveloped benchmark evaluations for hallucination phenomena. Nevertheless,\nthese benchmarks frequently utilize constrained generation techniques due to\ncost and temporal constraints. These techniques encompass the use of directed\nhallucination induction and strategies that deliberately alter authentic text\nto produce hallucinations. These approaches are not congruent with the\nunrestricted text generation demanded by real-world applications. Furthermore,\na well-established Chinese-language dataset dedicated to the evaluation of\nhallucinations in text generation is presently lacking. Consequently, we have\ndeveloped an Unconstrained Hallucination Generation Evaluation (UHGEval)\nbenchmark, designed to compile outputs produced with minimal restrictions by\nLLMs. Concurrently, we have established a comprehensive benchmark evaluation\nframework to aid subsequent researchers in undertaking scalable and\nreproducible experiments. We have also executed extensive experiments,\nevaluating prominent Chinese language models and the GPT series models to\nderive professional performance insights regarding hallucination challenges.",
            "author": [
                "Xun Liang",
                "Shichao Song",
                "Simin Niu",
                "Zhiyu Li",
                "Feiyu Xiong",
                "Bo Tang",
                "Zhaohui Wy",
                "Dawei He",
                "Peng Cheng",
                "Zhonghao Wang",
                "Haiying Deng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15296v1",
                "http://arxiv.org/pdf/2311.15296v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15292v1",
            "title": "Active-Sensing-Based Beam Alignment for Near Field MIMO Communications",
            "updated": "2023-11-26T13:23:27Z",
            "published": "2023-11-26T13:23:27Z",
            "summary": "An active-sensing-based learning algorithm is proposed to solve the\nnear-field beam alignment problem with the aid of wavenumber-domain transform\nmatrices (WTMs). Specifically, WTMs can transform the antenna-domain channel\ninto a sparse representation in the wavenumber domain. The dimensions of WTMs\ncan be further reduced by exploiting the dominance of line-of-sight (LoS)\nlinks. By employing these lower-dimensional WTMs as mapping functions, the\nactive-sensing-based algorithm is executed in the wavenumber domain, resulting\nin an acceleration of convergence. Compared with the codebook-based beam\nalignment methods, the proposed method finds the optimal beam pair in a\nping-pong fashion, thus avoiding high training overheads caused by beam\nsweeping. Finally, the numerical results validate the effectiveness of the\nproposed method.",
            "author": [
                "Hao Jiang",
                "Zhaolin Wang",
                "Yuanwei Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15292v1",
                "http://arxiv.org/pdf/2311.15292v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15289v1",
            "title": "Counting cliques without generalized theta graphs",
            "updated": "2023-11-26T13:09:04Z",
            "published": "2023-11-26T13:09:04Z",
            "summary": "The \\textit{generalized Tur\\'an number} $\\mathrm{ex}(n, T, F)$ is the maximum\npossible number of copies of $T$ in an $F$-free graph on $n$ vertices for any\ntwo graphs $T$ and $F$. For the book graph $B_t$, there is a close connection\nbetween $\\ex(n,K_3,B_t)$ and the Ruzsa-Szemer\\'edi triangle removal lemma.\nMotivated by this, in this paper, we study the generalized Tur\\'an problem for\ngeneralized theta graphs, a natural extension of book graphs. Our main result\nprovides a complete characterization of the magnitude of $\\ex(n,K_3,H)$ when\n$H$ is a generalized theta graph, indicating when it is quadratic, when it is\nnearly quadratic, and when it is subquadratic. Furthermore, as an application,\nwe obtain the exact value of $\\ex(n, K_r, kF)$, where $F$ is an edge-critical\ngeneralized theta graph, and $3\\le r\\le k+1$, extending several recent results.",
            "author": [
                "Jun Gao",
                "Zhuo Wu",
                "Yisai Xue"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15289v1",
                "http://arxiv.org/pdf/2311.15289v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15286v1",
            "title": "Macroscopic fluctuation theory of local time in lattice gases",
            "updated": "2023-11-26T12:57:35Z",
            "published": "2023-11-26T12:57:35Z",
            "summary": "The local time in an ensemble of particles measures the amount of time the\nparticles spend in the vicinity of a given point in space. Here we study\nfluctuations of this quantity, that is of the empirical time average\n$R=\\int_{0}^{T}\\rho\\left(x=0,t\\right)\\,dt$ of the density\n$\\rho\\left(x=0,t\\right)$ at the origin for an initially uniform one-dimensional\ndiffusive lattice gas. We consider both the quenched and annealed initial\nconditions and employ the Macroscopic Fluctuation Theory (MFT). For a gas of\nnon-interacting random walkers (RWs) the MFT yields exact large-deviation\nfunctions of $R$, which are closely related to the ones recently obtained by\nBurenev \\textit{et al.} (2023) using microscopic calculations for\nnon-interacting Brownian particles. Our MFT calculations, however, additionally\nyield the most likely history of the gas density $\\rho(x,t)$ conditioned on a\ngiven value of $R$. Furthermore, we calculate the variance of the local time\nfluctuations for arbitrary particle- or energy-conserving diffusive lattice\ngases. Better known examples of such systems include the simple symmetric\nexclusion process, the Kipnis-Marchioro-Presutti model and the symmetric\nzero-range process. Our results for the non-interacting RWs can be readily\nextended to a step-like initial condition for the density.",
            "author": [
                "Naftali R. Smith",
                "Baruch Meerson"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15286v1",
                "http://arxiv.org/pdf/2311.15286v1"
            ],
            "primary_category": "cond-mat.stat-mech",
            "category": [
                "cond-mat.stat-mech",
                "math.PR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15285v1",
            "title": "Hole probabilities and balayage of measures for planar Coulomb gases",
            "updated": "2023-11-26T12:57:25Z",
            "published": "2023-11-26T12:57:25Z",
            "summary": "We study hole probabilities of two-dimensional Coulomb gases with general\npotentials and arbitrary temperature. The hole region $U$ is assumed to satisfy\n$\\partial U\\subset S$, where $S$ is the support of the equilibrium measure\n$\\mu$. Let $n$ be the number of points. As $n \\to \\infty$, we prove that the\nprobability that no points lie in $U$ behaves like $\\exp(-Cn^{2}+o(n^{2}))$. We\ndetermine $C$ in terms of $\\mu$ and the balayage measure $\\nu =\n\\mathrm{Bal}(\\mu|_{U},\\partial U)$. If $U$ is unbounded, then $C$ also involves\nthe Green function of $\\Omega$ with pole at $\\infty$, where $\\Omega$ is the\nunbounded component of $U$. We also provide several examples where $\\nu$ and\n$C$ admit explicit expressions: we consider several point processes, such as\nthe elliptic Ginibre, Mittag-Leffler, and spherical point processes, and\nvarious hole regions, such as circular sectors, ellipses, rectangles, and the\ncomplement of an ellipse. This work generalizes previous results of Adhikari\nand Reddy in several directions.",
            "author": [
                "Christophe Charlier"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15285v1",
                "http://arxiv.org/pdf/2311.15285v1"
            ],
            "primary_category": "math.CA",
            "category": [
                "math.CA",
                "math-ph",
                "math.MP",
                "math.PR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15280v1",
            "title": "Optimize the event selection strategy the study the anomalous quartic\n  gauge couplings at muon colliders using the support vector machine",
            "updated": "2023-11-26T12:48:15Z",
            "published": "2023-11-26T12:48:15Z",
            "summary": "The search of the new physics~(NP) beyond the Standard Model is one of the\nmost important topics in current high energy physics research. With the\nincreasing luminosities at the colliders, the search for NP signals requires\nthe analysis of more and more data, and the efficiency in data processing\nbecomes particularly important. As a machine learning algorithm, the support\nvector machine~(SVM) is expected to be useful in the search of NP, meanwhile,\nhas the potential to be accelerated with the help of quantum computing. How to\nuse the SVM to optimize an event selection strategy to search for NP signals is\nstudied in this paper. Taking the tri-photon process at a muon collider as an\nexample, it can be shown that the event selection strategy optimized by the SVM\nis effective in the search of the dimension-8 operators contributing to the\nanomalous quartic gauge couplings.",
            "author": [
                "Shuai Zhang",
                "Yu-Chen Guo",
                "Ji-Chong Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15280v1",
                "http://arxiv.org/pdf/2311.15280v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15279v1",
            "title": "A reduced model for particle calcination for use in DEM/CFD simulations",
            "updated": "2023-11-26T12:47:47Z",
            "published": "2023-11-26T12:47:47Z",
            "summary": "We treat the accurate simulation of the calcination reaction in particles,\nwhere the particles are large and, thus, the inner-particle processes must be\nresolved. Because these processes need to be described with coupled partial\ndifferential equations that must be solved numerically, the computation times\nfor a single particle are too high for use in simulations that involve many\nparticles. Simulations of this type arise when the Discrete Element Method\n(DEM) is combined with Computational Fluid Dynamics (CFD) to investigate\nindustrial systems such as quick lime production in lime shaft kilns. We show\nthat, based on proper orthogonal de-composition and Galerkin projection,\nreduced models can be derived for single particles that provide the same\nspatial and temporal resolution as the original PDE models at a considerably\nreduced computational cost. Replacing the finite-volume particle models with\nthe reduced models results in an overall reduction of the reactor simulation\ntime by about 60% for the simple example treated here.",
            "author": [
                "Lucas Reineking",
                "Torben Bergold",
                "Enric Illana",
                "Viktor Scherer",
                "Martin M\u00f6nnigmann"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15279v1",
                "http://arxiv.org/pdf/2311.15279v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15277v1",
            "title": "Universal relations in compact stars with exotic degrees of freedom",
            "updated": "2023-11-26T12:36:35Z",
            "published": "2023-11-26T12:36:35Z",
            "summary": "The nature of the highly dense matter inside the supernova remnant compact\nstar is not constrained by terrestrial experiment and hence is modeled\nphenomenologically to accommodate the astrophysical observations from compact\nstars as the observable properties of the compact stars are highly sensitive to\nthe microscopic model of highly dense matter. However, there exists some\nuniversal relations between some macroscopic properties of compact stars\nindependent of the matter model. We examine the universal relations for\nquantities moment of inertia - tidal love number - quadrupole moment. We also\nstudy some already established universal relations in non-radial oscillation\nfrequencies with star compactness for the baryonic star with core composed of\nheavier baryons and for the hybrid star with core composed of strange quark\nmatter in CFL phase surrounded by nucleonic matter. We find the hybrid star\nwith core of quark matter in the CFL phase obeys the same universal relation as\nthe hybrid star with normal quark matter. However, the baryonic star with\nstrange and non-strange heavier baryons at the inner core fails to satisfy the\nuniversal relations.",
            "author": [
                "Manoj Kumar Ghosh",
                "Anil Kumar",
                "Pratik Thakur",
                "Vivek Baruah Thapa",
                "Monika Sinha"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15277v1",
                "http://arxiv.org/pdf/2311.15277v1"
            ],
            "primary_category": "astro-ph.HE",
            "category": [
                "astro-ph.HE",
                "hep-ph",
                "nucl-th"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15274v1",
            "title": "Transient vortex dynamics and evolution of Bose metal from a 2D\n  superconductor on MoS$_2$",
            "updated": "2023-11-26T12:03:11Z",
            "published": "2023-11-26T12:03:11Z",
            "summary": "The true character of physical phenomena is thought to be reinforced as the\nsystem becomes disorder-free. In contrast, the two-dimensional (2D)\nsuperconductor is predicted to turn fragile and resistive away from the limit I\n-> 0, B -> 0, in the pinning-free regime. It is intriguing to note that the\nvery vortices responsible for achieving superconductivity by pairing,\ncondensation, and, thereby reducing the classical dissipation, render the state\nresistive driven by quantum fluctuations in the T -> 0. While cleaner systems\nare being explored for technological improvements, the 2D superconductor\nturning resistive when influenced by weak electric and magnetic fields has\nprofound consequences for quantum technologies. A metallic ground state in 2D\nis beyond the consensus of both Bosonic and Fermionic systems, and its origin\nand nature warrant a comprehensive theoretical understanding supplemented by\nin-depth experiments. A real-time observation of the influence of vortex\ndynamics on transport properties so far has been elusive. We explore the nature\nand fate of a low-viscous, clean, 2D superconducting state formed on an\nionic-liquid gated few-layered MoS$_2$ sample. The vortex-core being\ndissipative, the elastic depinning, intervortex interaction, and the subsequent\ndynamics of the vortex-lattice cause the system to behave like an overdamped\nharmonic oscillator, leaving transient signatures in the transport\ncharacteristics. The temperature and magnetic field dependence of the transient\nnature and the noise characteristics of the magnetoresistance confirm that\nquantum fluctuations are solely responsible for the Bose metal state and the\nfragility of the superconducting state.",
            "author": [
                "Sreevidya Narayanan",
                "Anoop Kamalasanan",
                "Annu Anns Sunny",
                "Madhu Thalakulam"
            ],
            "link": [
                "http://dx.doi.org/10.1088/2053-1583/ad0b87",
                "http://arxiv.org/abs/2311.15274v1",
                "http://arxiv.org/pdf/2311.15274v1"
            ],
            "primary_category": "cond-mat.mes-hall",
            "category": [
                "cond-mat.mes-hall"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15271v1",
            "title": "Synthesizing mixed-integer linear programming models from natural\n  language descriptions",
            "updated": "2023-11-26T11:50:56Z",
            "published": "2023-11-26T11:50:56Z",
            "summary": "Numerous real-world decision-making problems can be formulated and solved\nusing Mixed-Integer Linear Programming (MILP) models. However, the\ntransformation of these problems into MILP models heavily relies on expertise\nin operations research and mathematical optimization, which restricts\nnon-experts' accessibility to MILP. To address this challenge, we propose a\nframework for automatically formulating MILP models from unstructured natural\nlanguage descriptions of decision problems, which integrates Large Language\nModels (LLMs) and mathematical modeling techniques. This framework consists of\nthree phases: i) identification of decision variables, ii) classification of\nobjective and constraints, and iii) finally, generation of MILP models.\n  In this study, we present a constraint classification scheme and a set of\nconstraint templates that can guide the LLMs in synthesizing a complete MILP\nmodel. After fine-tuning LLMs, our approach can identify and synthesize logic\nconstraints in addition to classic demand and resource constraints. The logic\nconstraints have not been studied in existing work.\n  To evaluate the performance of the proposed framework, we extend the NL4Opt\ndataset with more problem descriptions and constraint types, and with the new\ndataset, we compare our framework with one-step model generation methods\noffered by LLMs. The experimental results reveal that with respect to the\naccuracies of generating the correct model, objective, and constraints, our\nmethod which integrates constraint classification and templates with LLMs\nsignificantly outperforms the others. The prototype system that we developed\nhas a great potential to capture more constraints for more complex MILPs. It\nopens up opportunities for developing training tools for operations research\npractitioners and has the potential to be a powerful tool for automatic\ndecision problem modeling and solving in practice.",
            "author": [
                "Qingyang Li",
                "Lele Zhang",
                "Vicky Mak-Hau"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15271v1",
                "http://arxiv.org/pdf/2311.15271v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15270v1",
            "title": "Exploring the impact of a rapidly decelerating bar on transforming bulge\n  orbits into disc-like orbits",
            "updated": "2023-11-26T11:47:35Z",
            "published": "2023-11-26T11:47:35Z",
            "summary": "The most metal-poor tail of the Milky Way ([Fe/H] $\\leq$ $-$2.5) contains a\npopulation of stars with very prograde planar orbits, which is puzzling in both\ntheir origin and evolution. A possible scenario is that they are shepherded by\nthe bar from the inner Galaxy, where many of the old and low-metallicity stars\nin the Galaxy are located. To investigate this scenario, we use test-particle\nsimulations with an axisymmetric background potential plus a central bar model.\nThe test particles are generated by an extended distribution function (EDF)\nmodel based on the observational constraints of bulge stars. According to the\nsimulation results, a bar with constant pattern speed cannot help bring stars\nfrom the bulge to the solar vicinity. In contrast, when the model includes a\nrapidly decelerating bar, some bulge stars can gain rotation and move outwards\nas they are trapped in the co-rotation regions of the bar. The resulting\ndistribution of shepherded stars heavily depends on the present-day azimuthal\nangle between the bar and the Sun. The majority of the low-metallicity bulge\nstars driven outwards are distributed in the fourth quadrant of the Galaxy with\nrespect to the Sun, and about 10$\\%$ of them are within 6 kpc from us. Our\nexperiments indicate that the decelerating bar perturbation can be a\ncontributing process to explain part of the most metal-poor stars with prograde\nplanar orbits seen in the Solar neighborhood but is unlikely to be the dominant\none.",
            "author": [
                "Chengdong Li",
                "Zhen Yuan",
                "Giacomo Monari",
                "Nicolas F. Martin",
                "Arnaud Siebert",
                "Benoit Famaey",
                "Georges Kordopatis",
                "Rodrigo A. Ibata",
                "Vanessa Hill"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15270v1",
                "http://arxiv.org/pdf/2311.15270v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15266v1",
            "title": "Unified construction of relativistic Hamiltonians",
            "updated": "2023-11-26T10:57:25Z",
            "published": "2023-11-26T10:57:25Z",
            "summary": "It is shown that four-component (4C), quasi-four-component (Q4C), and exact\ntwo-component (X2C) relativistic Hartree-Fock (HF) equations can be implemented\nin an unified manner, by making use of the atomic nature of the small\ncomponents of molecular 4-spinors. A model density matrix approximation can\nfirst be invoked for the small-component charge/current density functions,\nwhich gives rise to a static, pre-molecular mean field (pmf) to be combined\nwith the one-electron term. As a result, only the nonrelativistic-like\ntwo-electron term of the 4C/Q4C/X2C Fock matrix needs to be updated during the\niterations. A `one-center small-component' approximation can then be invoked in\nthe evaluation of relativistic integrals. That is, all atom-centered\nsmall-component basis functions are regarded as extremely localized nearby the\nposition of the atom to which they belong, such that they have vanishing\noverlaps with all small- or large-component functions centered at other nuclei.\nUnder these approximations, the 4C, Q4C, and X2C mean-field and many-electron\nHamiltonians share precisely the same structure and accuracy. Beyond these is\nthe effective quantum electrodynamics Hamiltonian that can be constructed in\nthe same way. Such approximations lead to errors that are orders of magnitude\nsmaller than other sources of errors (e.g., truncation errors in the one- and\nmany-particle bases as well as uncertainties of experimental measurements) and\nare hence safe to use for whatever purposes. The quaternion forms of the 4C,\nQ4C, and X2C equations are also presented in the most general way, based on\nwhich the corresponding Kramers-restricted open-shell (RKOHF) variants are\nformulated for `high-spin' open-shell systems.",
            "author": [
                "Wenjian Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15266v1",
                "http://arxiv.org/pdf/2311.15266v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15263v1",
            "title": "Strong limit theorems for step-reinforced random walks",
            "updated": "2023-11-26T10:37:18Z",
            "published": "2023-11-26T10:37:18Z",
            "summary": "A step-reinforced random walk is a discrete-time non-Markovian process with\nlong range memory. At each step, with a fixed probability p, the positively\nstep-reinforced random walk repeats one of its preceding steps chosen uniformly\nat random, and with complementary probability 1-p, it has an independent\nincrement. The negatively step-reinforced random walk follows the same\nreinforcement algorithm but when a step is repeated its sign is also changed.\nStrong laws of large numbers and strong invariance principles are established\nfor positively and negatively step-reinforced random walks in this work. Our\napproach relies on two general theorems on invariance principle for martingale\ndifference sequences and a truncation argument. As by-products of our main\nresults, the law of iterated logarithm and the functional central limit theorem\nare also obtained for step-reinforced random walks.",
            "author": [
                "Zhishui Hu",
                "Yiting Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15263v1",
                "http://arxiv.org/pdf/2311.15263v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17930v1",
            "title": "Pragmatic Nonsense",
            "updated": "2023-11-26T10:04:38Z",
            "published": "2023-11-26T10:04:38Z",
            "summary": "Inspired by the early Wittgenstein's concept of nonsense (meaning that which\nlies beyond the limits of language), we define two different, yet\ncomplementary, types of nonsense: formal nonsense and pragmatic nonsense. The\nsimpler notion of formal nonsense is initially defined within Tarski's semantic\ntheory of truth; the notion of pragmatic nonsense, by its turn, is formulated\nwithin the context of the theory of pragmatic truth, also known as quasi-truth,\nas formalized by da Costa and his collaborators. While an expression will be\nconsidered formally nonsensical if the formal criteria required for the\nassignment of any truth-value (whether true, false, pragmatically true, or\npragmatically false) to such sentence are not met, a (well-formed) formula will\nbe considered pragmatically nonsensical if the pragmatic criteria (inscribed\nwithin the context of scientific practice) required for the assignment of any\ntruth-value to such sentence are not met. Thus, in the context of the theory of\npragmatic truth, any (well-formed) formula of a formal language interpreted on\na simple pragmatic structure will be considered pragmatically nonsensical if\nthe set of primary sentences of such structure is not well-built, that is, if\nit does not include the relevant observational data and/or theoretical results,\nor if it does include sentences that are inconsistent with such data.",
            "author": [
                "Ricardo P. Cavassane",
                "Felipe S. Abrah\u00e3o",
                "Itala M. L. D'Ottaviano"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17930v1",
                "http://arxiv.org/pdf/2311.17930v1"
            ],
            "primary_category": "math.LO",
            "category": [
                "math.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16192v1",
            "title": "Utilizing Multiple Inputs Autoregressive Models for Bearing Remaining\n  Useful Life Prediction",
            "updated": "2023-11-26T09:50:32Z",
            "published": "2023-11-26T09:50:32Z",
            "summary": "Accurate prediction of the Remaining Useful Life (RUL) of rolling bearings is\ncrucial in industrial production, yet existing models often struggle with\nlimited generalization capabilities due to their inability to fully process all\nvibration signal patterns. We introduce a novel multi-input autoregressive\nmodel to address this challenge in RUL prediction for bearings. Our approach\nuniquely integrates vibration signals with previously predicted Health\nIndicator (HI) values, employing feature fusion to output current window HI\nvalues. Through autoregressive iterations, the model attains a global receptive\nfield, effectively overcoming the limitations in generalization. Furthermore,\nwe innovatively incorporate a segmentation method and multiple training\niterations to mitigate error accumulation in autoregressive models. Empirical\nevaluation on the PMH2012 dataset demonstrates that our model, compared to\nother backbone networks using similar autoregressive approaches, achieves\nsignificantly lower Root Mean Square Error (RMSE) and Score. Notably, it\noutperforms traditional autoregressive models that use label values as inputs\nand non-autoregressive networks, showing superior generalization abilities with\na marked lead in RMSE and Score metrics.",
            "author": [
                "Junliang Wang",
                "Qinghua Zhang",
                "Guanhua Zhu",
                "Guoxi Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16192v1",
                "http://arxiv.org/pdf/2311.16192v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15250v1",
            "title": "Rely/Guarantee, Refinement and the ABA Problem: Part 1",
            "updated": "2023-11-26T09:39:04Z",
            "published": "2023-11-26T09:39:04Z",
            "summary": "Rely/guarantee reasoning provides a compositional way of reasoning about\nconcurrency. The ABA problem occurs in many non-blocking concurrent data\nstructures, where a change made by a concurrent process may be undetected by\nother processes. Guarantee conditions provide a useful mechanism for reasoning\nabout such changes, as is demonstrated by two non-blocking examples, the\nTreiber stack and the Herlihy-Wing queue. The ABA problem can be identified by\nthe program making a step where the before and after states do not correspond\nto a valid step at the sequential level. Therefore, such invalid behaviour\nrelates to a failure of the guarantee condition. As such behaviour is\nnon-linearisable, this suggests a strong relationship between refinement with\nrely/guarantee and linearisability.",
            "author": [
                "Nisansala P. Yatapanage"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15250v1",
                "http://arxiv.org/pdf/2311.15250v1"
            ],
            "primary_category": "cs.LO",
            "category": [
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15249v1",
            "title": "Algorithm Evolution Using Large Language Model",
            "updated": "2023-11-26T09:38:44Z",
            "published": "2023-11-26T09:38:44Z",
            "summary": "Optimization can be found in many real-life applications. Designing an\neffective algorithm for a specific optimization problem typically requires a\ntedious amount of effort from human experts with domain knowledge and algorithm\ndesign skills. In this paper, we propose a novel approach called Algorithm\nEvolution using Large Language Model (AEL). It utilizes a large language model\n(LLM) to automatically generate optimization algorithms via an evolutionary\nframework. AEL does algorithm-level evolution without model training. Human\neffort and requirements for domain knowledge can be significantly reduced. We\ntake constructive methods for the salesman traveling problem as a test example,\nwe show that the constructive algorithm obtained by AEL outperforms simple\nhand-crafted and LLM-generated heuristics. Compared with other domain deep\nlearning model-based algorithms, these methods exhibit excellent scalability\nacross different problem sizes. AEL is also very different from previous\nattempts that utilize LLMs as search operators in algorithms.",
            "author": [
                "Fei Liu",
                "Xialiang Tong",
                "Mingxuan Yuan",
                "Qingfu Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15249v1",
                "http://arxiv.org/pdf/2311.15249v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16475v1",
            "title": "Generating Human-Centric Visual Cues for Human-Object Interaction\n  Detection via Large Vision-Language Models",
            "updated": "2023-11-26T09:11:32Z",
            "published": "2023-11-26T09:11:32Z",
            "summary": "Human-object interaction (HOI) detection aims at detecting human-object pairs\nand predicting their interactions. However, the complexity of human behavior\nand the diverse contexts in which these interactions occur make it challenging.\nIntuitively, human-centric visual cues, such as the involved participants, the\nbody language, and the surrounding environment, play crucial roles in shaping\nthese interactions. These cues are particularly vital in interpreting unseen\ninteractions. In this paper, we propose three prompts with VLM to generate\nhuman-centric visual cues within an image from multiple perspectives of humans.\nTo capitalize on these rich Human-Centric Visual Cues, we propose a novel\napproach named HCVC for HOI detection. Particularly, we develop a\ntransformer-based multimodal fusion module with multitower architecture to\nintegrate visual cue features into the instance and interaction decoders. Our\nextensive experiments and analysis validate the efficacy of leveraging the\ngenerated human-centric visual cues for HOI detection. Notably, the\nexperimental results indicate the superiority of the proposed model over the\nexisting state-of-the-art methods on two widely used datasets.",
            "author": [
                "Yu-Wei Zhan",
                "Fan Liu",
                "Xin Luo",
                "Liqiang Nie",
                "Xin-Shun Xu",
                "Mohan Kankanhalli"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16475v1",
                "http://arxiv.org/pdf/2311.16475v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.03720v1",
            "title": "Negotiating with LLMS: Prompt Hacks, Skill Gaps, and Reasoning Deficits",
            "updated": "2023-11-26T08:44:58Z",
            "published": "2023-11-26T08:44:58Z",
            "summary": "Large language models LLMs like ChatGPT have reached the 100 Mio user barrier\nin record time and might increasingly enter all areas of our life leading to a\ndiverse set of interactions between those Artificial Intelligence models and\nhumans. While many studies have discussed governance and regulations\ndeductively from first-order principles, few studies provide an inductive,\ndata-driven lens based on observing dialogues between humans and LLMs\nespecially when it comes to non-collaborative, competitive situations that have\nthe potential to pose a serious threat to people. In this work, we conduct a\nuser study engaging over 40 individuals across all age groups in price\nnegotiations with an LLM. We explore how people interact with an LLM,\ninvestigating differences in negotiation outcomes and strategies. Furthermore,\nwe highlight shortcomings of LLMs with respect to their reasoning capabilities\nand, in turn, susceptiveness to prompt hacking, which intends to manipulate the\nLLM to make agreements that are against its instructions or beyond any\nrationality. We also show that the negotiated prices humans manage to achieve\nspan a broad range, which points to a literacy gap in effectively interacting\nwith LLMs.",
            "author": [
                "Johannes Schneider",
                "Steffi Haag",
                "Leona Chandra Kruse"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03720v1",
                "http://arxiv.org/pdf/2312.03720v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15235v1",
            "title": "Limited bisimulations for nondeterministic fuzzy transition systems",
            "updated": "2023-11-26T08:23:56Z",
            "published": "2023-11-26T08:23:56Z",
            "summary": "The limited version of bisimulation, called limited approximate bisimulation,\nhas recently been introduced to fuzzy transition systems (NFTSs). This article\nextends limited approximate bisimulation to NFTSs, which are more general\nstructures than FTSs, to introduce a notion of $k$-limited\n$\\alpha$-bisimulation by using an approach of relational lifting, where $k$ is\na natural number and $\\alpha\\in[0,1]$. To give the algorithmic\ncharacterization, a fixed point characterization of $k$-limited\n$\\alpha$-bisimilarity is first provided. Then $k$-limited $\\alpha$-bisimulation\nvector with $i$-th element being a $(k-i+1)$-limited $\\alpha$-bisimulation is\nintroduced to investigate conditions for two states to be $k$-limited\n$\\alpha$-bisimilar, where $1\\leq i\\leq k+1$. Using these results, an\n$O(2k^2|V|^6\\cdot\\left|\\lra\\right|^2)$ algorithm is designed for computing the\ndegree of similarity between two states, where $|V|$ is the number of states of\nthe NFTS and $\\left|\\lra\\right|$ is the greatest number of transitions from\nstates. Finally, the relationship between $k$-limited $\\alpha$-bisimilar and\n$\\alpha$-bisimulation under $\\widetilde{S}$ is showed, and by which, a logical\ncharacterization of $k$-limited $\\alpha$-bisimilarity is provided.",
            "author": [
                "Sha Qiao",
                "Jun e Feng",
                "Ping Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15235v1",
                "http://arxiv.org/pdf/2311.15235v1"
            ],
            "primary_category": "math.DS",
            "category": [
                "math.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15231v1",
            "title": "Double Reverse Regularization Network Based on Self-Knowledge\n  Distillation for SAR Object Classification",
            "updated": "2023-11-26T08:09:43Z",
            "published": "2023-11-26T08:09:43Z",
            "summary": "In current synthetic aperture radar (SAR) object classification, one of the\nmajor challenges is the severe overfitting issue due to the limited dataset\n(few-shot) and noisy data. Considering the advantages of knowledge distillation\nas a learned label smoothing regularization, this paper proposes a novel Double\nReverse Regularization Network based on Self-Knowledge Distillation\n(DRRNet-SKD). Specifically, through exploring the effect of distillation weight\non the process of distillation, we are inspired to adopt the double reverse\nthought to implement an effective regularization network by combining offline\nand online distillation in a complementary way. Then, the Adaptive Weight\nAssignment (AWA) module is designed to adaptively assign two reverse-changing\nweights based on the network performance, allowing the student network to\nbetter benefit from both teachers. The experimental results on OpenSARShip and\nFUSAR-Ship demonstrate that DRRNet-SKD exhibits remarkable performance\nimprovement on classical CNNs, outperforming state-of-the-art self-knowledge\ndistillation methods.",
            "author": [
                "Bo Xu",
                "Hao Zheng",
                "Zhigang Hu",
                "Liu Yang",
                "Meiguang Zheng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15231v1",
                "http://arxiv.org/pdf/2311.15231v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15230v1",
            "title": "GAIA: Zero-shot Talking Avatar Generation",
            "updated": "2023-11-26T08:04:43Z",
            "published": "2023-11-26T08:04:43Z",
            "summary": "Zero-shot talking avatar generation aims at synthesizing natural talking\nvideos from speech and a single portrait image. Previous methods have relied on\ndomain-specific heuristics such as warping-based motion representation and 3D\nMorphable Models, which limit the naturalness and diversity of the generated\navatars. In this work, we introduce GAIA (Generative AI for Avatar), which\neliminates the domain priors in talking avatar generation. In light of the\nobservation that the speech only drives the motion of the avatar while the\nappearance of the avatar and the background typically remain the same\nthroughout the entire video, we divide our approach into two stages: 1)\ndisentangling each frame into motion and appearance representations; 2)\ngenerating motion sequences conditioned on the speech and reference portrait\nimage. We collect a large-scale high-quality talking avatar dataset and train\nthe model on it with different scales (up to 2B parameters). Experimental\nresults verify the superiority, scalability, and flexibility of GAIA as 1) the\nresulting model beats previous baseline models in terms of naturalness,\ndiversity, lip-sync quality, and visual quality; 2) the framework is scalable\nsince larger models yield better results; 3) it is general and enables\ndifferent applications like controllable talking avatar generation and\ntext-instructed avatar generation.",
            "author": [
                "Tianyu He",
                "Junliang Guo",
                "Runyi Yu",
                "Yuchi Wang",
                "Jialiang Zhu",
                "Kaikai An",
                "Leyi Li",
                "Xu Tan",
                "Chunyu Wang",
                "Han Hu",
                "HsiangTao Wu",
                "Sheng Zhao",
                "Jiang Bian"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15230v1",
                "http://arxiv.org/pdf/2311.15230v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15227v1",
            "title": "Epidemic modeling and flattening the infection curve in social networks",
            "updated": "2023-11-26T07:49:49Z",
            "published": "2023-11-26T07:49:49Z",
            "summary": "The main goal of this paper is to model the epidemic and flattening the\ninfection curve of the social networks. Flattening the infection curve implies\nslowing down the spread of the disease and reducing the infection rate via\nsocial-distancing, isolation (quarantine) and vaccination. The\nnan-pharmaceutical methods are a much simpler and efficient way to control the\nspread of epidemic and infection rate. By specifying a target group with high\ncentrality for isolation and quarantine one can reach a much flatter infection\ncurve (related to Corona for example) without adding extra costs to health\nservices. The aim of this research is, first, modeling the epidemic and, then,\ngiving strategies and structural algorithms for targeted vaccination or\ntargeted non-pharmaceutical methods for reducing the peak of the viral disease\nand flattening the infection curve. These methods are more efficient for\nnan-pharmaceutical interventions as finding the target quarantine group\nflattens the infection curve much easier. For this purpose, a few number of\nparticular nodes with high centrality are isolated and the infection curve is\nanalyzed. Our research shows meaningful results for flattening the infection\ncurve only by isolating a few number of targeted nodes in the social network.\nThe proposed methods are independent of the type of the disease and are\neffective for any viral disease, e.g., Covid-19.",
            "author": [
                "Mohammadreza Doostmohammadian",
                "Soraya Doustmohamadian",
                "Najmeh Doostmohammadian",
                "Azam Doustmohammadian",
                "Houman Zarrabi",
                "Hamid R. Rabiee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15227v1",
                "http://arxiv.org/pdf/2311.15227v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "physics.soc-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14742v1",
            "title": "Query-LIFE: Query-aware Language Image Fusion Embedding for E-Commerce\n  Relevance",
            "updated": "2023-11-26T07:34:18Z",
            "published": "2023-11-26T07:34:18Z",
            "summary": "Relevance module plays a fundamental role in e-commerce search as they are\nresponsible for selecting relevant products from thousands of items based on\nuser queries, thereby enhancing users experience and efficiency. The\ntraditional approach models the relevance based product titles and queries, but\nthe information in titles alone maybe insufficient to describe the products\ncompletely. A more general optimization approach is to further leverage product\nimage information. In recent years, vision-language pre-training models have\nachieved impressive results in many scenarios, which leverage contrastive\nlearning to map both textual and visual features into a joint embedding space.\nIn e-commerce, a common practice is to fine-tune on the pre-trained model based\non e-commerce data. However, the performance is sub-optimal because the\nvision-language pre-training models lack of alignment specifically designed for\nqueries. In this paper, we propose a method called Query-LIFE (Query-aware\nLanguage Image Fusion Embedding) to address these challenges. Query-LIFE\nutilizes a query-based multimodal fusion to effectively incorporate the image\nand title based on the product types. Additionally, it employs query-aware\nmodal alignment to enhance the accuracy of the comprehensive representation of\nproducts. Furthermore, we design GenFilt, which utilizes the generation\ncapability of large models to filter out false negative samples and further\nimprove the overall performance of the contrastive learning task in the model.\nExperiments have demonstrated that Query-LIFE outperforms existing baselines.\nWe have conducted ablation studies and human evaluations to validate the\neffectiveness of each module within Query-LIFE. Moreover, Query-LIFE has been\ndeployed on Miravia Search, resulting in improved both relevance and conversion\nefficiency.",
            "author": [
                "Hai Zhu",
                "Yuankai Guo",
                "Ronggang Dou",
                "Kai Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14742v1",
                "http://arxiv.org/pdf/2311.14742v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15222v2",
            "title": "Decision Tree Psychological Risk Assessment in Currency Trading",
            "updated": "2023-12-01T08:43:14Z",
            "published": "2023-11-26T07:23:37Z",
            "summary": "This research paper focuses on the integration of Artificial Intelligence\n(AI) into the currency trading landscape, positing the development of\npersonalized AI models, essentially functioning as intelligent personal\nassistants tailored to the idiosyncrasies of individual traders. The paper\nposits that AI models are capable of identifying nuanced patterns within the\ntrader's historical data, facilitating a more accurate and insightful\nassessment of psychological risk dynamics in currency trading. The PRI is a\ndynamic metric that experiences fluctuations in response to market conditions\nthat foster psychological fragility among traders. By employing sophisticated\ntechniques, a classifying decision tree is crafted, enabling clearer\ndecision-making boundaries within the tree structure. By incorporating the\nuser's chronological trade entries, the model becomes adept at identifying\ncritical junctures when psychological risks are heightened. The real-time\nnature of the calculations enhances the model's utility as a proactive tool,\noffering timely alerts to traders about impending moments of psychological\nrisks. The implications of this research extend beyond the confines of currency\ntrading, reaching into the realms of other industries where the judicious\napplication of personalized modeling emerges as an efficient and strategic\napproach. This paper positions itself at the intersection of cutting-edge\ntechnology and the intricate nuances of human psychology, offering a\ntransformative paradigm for decision making support in dynamic and\nhigh-pressure environments.",
            "author": [
                "Jai Pal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15222v2",
                "http://arxiv.org/pdf/2311.15222v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CE",
                "q-fin.GN"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15221v1",
            "title": "The Local Landscape of Phase Retrieval Under Limited Samples",
            "updated": "2023-11-26T07:22:35Z",
            "published": "2023-11-26T07:22:35Z",
            "summary": "In this paper, we provide a fine-grained analysis of the local landscape of\nphase retrieval under the regime with limited samples. Our aim is to ascertain\nthe minimal sample size necessary to guarantee a benign local landscape\nsurrounding global minima in high dimensions. Let $n$ and $d$ denote the sample\nsize and input dimension, respectively. We first explore the local convexity\nand establish that when $n=o(d\\log d)$, for almost every fixed point in the\nlocal ball, the Hessian matrix must have negative eigenvalues as long as $d$ is\nsufficiently large. Consequently, the local landscape is highly non-convex. We\nnext consider the one-point strong convexity and show that as long as\n$n=\\omega(d)$, with high probability, the landscape is one-point strongly\nconvex in the local annulus: $\\{w\\in\\mathbb{R}^d: o_d(1)\\leqslant\n\\|w-w^*\\|\\leqslant c\\}$, where $w^*$ is the ground truth and $c$ is an absolute\nconstant. This implies that gradient descent initialized from any point in this\ndomain can converge to an $o_d(1)$-loss solution exponentially fast.\nFurthermore, we show that when $n=o(d\\log d)$, there is a radius of\n$\\widetilde\\Theta\\left(\\sqrt{1/d}\\right)$ such that one-point convexity breaks\nin the corresponding smaller local ball. This indicates an impossibility to\nestablish a convergence to exact $w^*$ for gradient descent under limited\nsamples by relying solely on one-point convexity.",
            "author": [
                "Kaizhao Liu",
                "Zihao Wang",
                "Lei Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15221v1",
                "http://arxiv.org/pdf/2311.15221v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "cs.LG",
                "eess.SP",
                "math.IT",
                "math.OC",
                "math.ST",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15218v2",
            "title": "Real-Time Online Stock Forecasting Utilizing Integrated Quantitative and\n  Qualitative Analysis",
            "updated": "2023-12-05T14:49:36Z",
            "published": "2023-11-26T07:19:10Z",
            "summary": "The application of Machine learning to finance has become a familiar\napproach, even more so in stock market forecasting. The stock market is highly\nvolatile and huge amounts of data are generated every minute globally. The\nextraction of effective intelligence from this data is of critical importance.\nHowever, a collaboration of numerical stock data with qualitative text data can\nbe a challenging task. In this work, we accomplish this and provide an\nunprecedented, publicly available dataset with technical and fundamental data,\nsentiment that we gathered from News Archives, TV news captions, Radio\nTranscripts, Tweets, Daily financial newspapers, etc. The text data entries\nused for sentiment extraction total more than 1.4 Million. The dataset consists\nof daily entries from January 2018 to December 2022 for 8 companies\nrepresenting diverse industrial sectors and the Dow Jones Industrial Average\n(DJIA) as a whole. Holistic Fundamental and Technical data is provided training\nready for Model learning and deployment. The data generated could be used for\nIncremental online learning with real-time data points retrieved daily, since\nthere was no stagnant data utilized, all the data was retired from APIs or\nself-designed scripts. Moreover, the utilization of Spearman's rank correlation\nover real-time data, linking stock returns with sentiment analysis has produced\nnoteworthy results for the DJIA achieving accuracy levels surpassing 60\\%. The\ndataset is made available at https://github.com/batking24/Huge-Stock-Dataset",
            "author": [
                "Sai Akash Bathini",
                "Dagli Cihan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15218v2",
                "http://arxiv.org/pdf/2311.15218v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CE",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15215v1",
            "title": "From OTFS to DD-ISAC: Integrating Sensing and Communications in the\n  Delay Doppler Domain",
            "updated": "2023-11-26T07:13:01Z",
            "published": "2023-11-26T07:13:01Z",
            "summary": "Next-generation vehicular networks are expected to provide the capability of\nrobust environmental sensing in addition to reliable communications to meet\nintelligence requirements. A promising solution is the integrated sensing and\ncommunication (ISAC) technology, which performs both functionalities using the\nsame spectrum and hardware resources. Most existing works on ISAC consider the\nOrthogonal Frequency Division Multiplexing (OFDM) waveform. Nevertheless,\nvehicle motion introduces Doppler shift, which breaks the subcarrier\northogonality and leads to performance degradation. The recently proposed\nOrthogonal Time Frequency Space (OTFS) modulation, which exploits various\nadvantages of Delay Doppler (DD) channels, has been shown to support reliable\ncommunication in high-mobility scenarios. Moreover, the DD waveform can\ndirectly interact with radar sensing parameters, which are actually delay and\nDoppler shifts. This paper investigates the advantages of applying the DD\ncommunication waveform to ISAC. Specifically, we first provide a comprehensive\noverview of implementing DD communications, based on which several advantages\nof DD-ISAC over OFDM-based ISAC are revealed, including transceiver designs and\nthe ambiguity function. Furthermore, a detailed performance comparison are\npresented, where the target detection probability and the mean squared error\n(MSE) performance are also studied. Finally, some challenges and opportunities\nof DD-ISAC are also provided.",
            "author": [
                "Weijie Yuan",
                "Lin Zhou",
                "Saeid K. Dehkordi",
                "Shuangyang Li",
                "Pingzhi Fan",
                "Giuseppe Caire",
                "H. Vincent Poor"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15215v1",
                "http://arxiv.org/pdf/2311.15215v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15213v1",
            "title": "Leveraging Anatomical Constraints with Uncertainty for Pneumothorax\n  Segmentation",
            "updated": "2023-11-26T07:03:17Z",
            "published": "2023-11-26T07:03:17Z",
            "summary": "Pneumothorax is a medical emergency caused by abnormal accumulation of air in\nthe pleural space - the potential space between the lungs and chest wall. On 2D\nchest radiographs, pneumothorax occurs within the thoracic cavity and outside\nof the mediastinum and we refer to this area as \"lung+ space\". While deep\nlearning (DL) has increasingly been utilized to segment pneumothorax lesions in\nchest radiographs, many existing DL models employ an end-to-end approach. These\nmodels directly map chest radiographs to clinician-annotated lesion areas,\noften neglecting the vital domain knowledge that pneumothorax is inherently\nlocation-sensitive.\n  We propose a novel approach that incorporates the lung+ space as a constraint\nduring DL model training for pneumothorax segmentation on 2D chest radiographs.\nTo circumvent the need for additional annotations and to prevent potential\nlabel leakage on the target task, our method utilizes external datasets and an\nauxiliary task of lung segmentation. This approach generates a specific\nconstraint of lung+ space for each chest radiograph. Furthermore, we have\nincorporated a discriminator to eliminate unreliable constraints caused by the\ndomain shift between the auxiliary and target datasets.\n  Our results demonstrated significant improvements, with average performance\ngains of 4.6%, 3.6%, and 3.3% regarding Intersection over Union (IoU), Dice\nSimilarity Coefficient (DSC), and Hausdorff Distance (HD). Our research\nunderscores the significance of incorporating medical domain knowledge about\nthe location-specific nature of pneumothorax to enhance DL-based lesion\nsegmentation.",
            "author": [
                "Han Yuan",
                "Chuan Hong",
                "Nguyen Tuan Anh Tran",
                "Xinxing Xu",
                "Nan Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15213v1",
                "http://arxiv.org/pdf/2311.15213v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15212v1",
            "title": "OpenPerf: A Benchmarking Framework for the Sustainable Development of\n  the Open-Source Ecosystem",
            "updated": "2023-11-26T07:01:36Z",
            "published": "2023-11-26T07:01:36Z",
            "summary": "Benchmarking involves designing scientific test methods, tools, and\nframeworks to quantitatively and comparably assess specific performance\nindicators of certain test subjects. With the development of artificial\nintelligence, AI benchmarking datasets such as ImageNet and DataPerf have\ngradually become consensus standards in both academic and industrial fields.\nHowever, constructing a benchmarking framework remains a significant challenge\nin the open-source domain due to the diverse range of data types, the wide\narray of research issues, and the intricate nature of collaboration networks.\nThis paper introduces OpenPerf, a benchmarking framework designed for the\nsustainable development of the open-source ecosystem. This framework defines 9\ntask benchmarking tasks in the open-source research, encompassing 3 data types:\ntime series, text, and graphics, and addresses 6 research problems including\nregression, classification, recommendation, ranking, network building, and\nanomaly detection. Based on the above tasks, we implemented 3 data science task\nbenchmarks, 2 index-based benchmarks, and 1 standard benchmark. Notably, the\nindex-based benchmarks have been adopted by the China Electronics\nStandardization Institute as evaluation criteria for open-source community\ngovernance. Additionally, we have developed a comprehensive toolkit for\nOpenPerf, which not only offers robust data management, tool integration, and\nuser interface capabilities but also adopts a Benchmarking-as-a-Service (BaaS)\nmodel to serve academic institutions, industries, and foundations. Through its\napplication in renowned companies and institutions such as Alibaba, Ant Group,\nand East China Normal University, we have validated OpenPerf's pivotal role in\nthe healthy evolution of the open-source ecosystem.",
            "author": [
                "Fenglin Bi",
                "Fanyu Han",
                "Shengyu Zhao",
                "Jinlu Li",
                "Yanbin Zhang",
                "Wei Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15212v1",
                "http://arxiv.org/pdf/2311.15212v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15211v1",
            "title": "Probabilistic Transformer: A Probabilistic Dependency Model for\n  Contextual Word Representation",
            "updated": "2023-11-26T06:56:02Z",
            "published": "2023-11-26T06:56:02Z",
            "summary": "Syntactic structures used to play a vital role in natural language processing\n(NLP), but since the deep learning revolution, NLP has been gradually dominated\nby neural models that do not consider syntactic structures in their design. One\nvastly successful class of neural models is transformers. When used as an\nencoder, a transformer produces contextual representation of words in the input\nsentence. In this work, we propose a new model of contextual word\nrepresentation, not from a neural perspective, but from a purely syntactic and\nprobabilistic perspective. Specifically, we design a conditional random field\nthat models discrete latent representations of all words in a sentence as well\nas dependency arcs between them; and we use mean field variational inference\nfor approximate inference. Strikingly, we find that the computation graph of\nour model resembles transformers, with correspondences between dependencies and\nself-attention and between distributions over latent representations and\ncontextual embeddings of words. Experiments show that our model performs\ncompetitively to transformers on small to medium sized datasets. We hope that\nour work could help bridge the gap between traditional syntactic and\nprobabilistic approaches and cutting-edge neural approaches to NLP, and inspire\nmore linguistically-principled neural approaches in the future.",
            "author": [
                "Haoyi Wu",
                "Kewei Tu"
            ],
            "link": [
                "http://dx.doi.org/10.18653/v1/2023.findings-acl.482",
                "http://arxiv.org/abs/2311.15211v1",
                "http://arxiv.org/pdf/2311.15211v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15210v1",
            "title": "Topology combined machine learning for consonant recognition",
            "updated": "2023-11-26T06:53:56Z",
            "published": "2023-11-26T06:53:56Z",
            "summary": "In artificial-intelligence-aided signal processing, existing deep learning\nmodels often exhibit a black-box structure, and their validity and\ncomprehensibility remain elusive. The integration of topological methods,\ndespite its relatively nascent application, serves a dual purpose of making\nmodels more interpretable as well as extracting structural information from\ntime-dependent data for smarter learning. Here, we provide a transparent and\nbroadly applicable methodology, TopCap, to capture the most salient topological\nfeatures inherent in time series for machine learning. Rooted in\nhigh-dimensional ambient spaces, TopCap is capable of capturing features rarely\ndetected in datasets with low intrinsic dimensionality. Applying time-delay\nembedding and persistent homology, we obtain descriptors which encapsulate\ninformation such as the vibration of a time series, in terms of its variability\nof frequency, amplitude, and average line, demonstrated with simulated data.\nThis information is then vectorised and fed into multiple machine learning\nalgorithms such as k-nearest neighbours and support vector machine. Notably, in\nclassifying voiced and voiceless consonants, TopCap achieves an accuracy\nexceeding 96% and is geared towards designing topological convolutional layers\nfor deep learning of speech and audio signals.",
            "author": [
                "Pingyao Feng",
                "Siheng Yi",
                "Qingrui Qu",
                "Zhiwang Yu",
                "Yifei Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15210v1",
                "http://arxiv.org/pdf/2311.15210v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.ST",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16501v1",
            "title": "PISA: Point-cloud-based Instructed Scene Augmentation",
            "updated": "2023-11-26T06:40:16Z",
            "published": "2023-11-26T06:40:16Z",
            "summary": "Indoor scene augmentation has become an emerging topic in the field of\ncomputer vision with applications in augmented and virtual reality. However,\nexisting scene augmentation methods mostly require a pre-built object database\nwith a given position as the desired location. In this paper, we propose the\nfirst end-to-end multi-modal deep neural network that can generate point cloud\nobjects consistent with their surroundings, conditioned on text instructions.\nOur model generates a seemly object in the appropriate position based on the\ninputs of a query and point clouds, thereby enabling the creation of new\nscenarios involving previously unseen layouts of objects. Database of\npre-stored CAD models is no longer needed. We use Point-E as our generative\nmodel and introduce methods including quantified position prediction and Top-K\nestimation to mitigate the false negative problems caused by ambiguous language\ndescription. Moreover, we evaluate the ability of our model by demonstrating\nthe diversity of generated objects, the effectiveness of instruction, and\nquantitative metric results, which collectively indicate that our model is\ncapable of generating realistic in-door objects. For a more thorough\nevaluation, we also incorporate visual grounding as a metric to assess the\nquality of the scenes generated by our model.",
            "author": [
                "Yiyang Luo",
                "Ke Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16501v1",
                "http://arxiv.org/pdf/2311.16501v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15209v2",
            "title": "See and Think: Embodied Agent in Virtual Environment",
            "updated": "2023-12-03T00:58:47Z",
            "published": "2023-11-26T06:38:16Z",
            "summary": "Large language models (LLMs) have achieved impressive progress on several\nopen-world tasks. Recently, using LLMs to build embodied agents has been a\nhotspot. In this paper, we propose STEVE, a comprehensive and visionary\nembodied agent in the Minecraft virtual environment. STEVE consists of three\nkey components: vision perception, language instruction, and code action.\nVision perception involves the interpretation of visual information in the\nenvironment, which is then integrated into the LLMs component with agent state\nand task instruction. Language instruction is responsible for iterative\nreasoning and decomposing complex tasks into manageable guidelines. Code action\ngenerates executable skill actions based on retrieval in skill database,\nenabling the agent to interact effectively within the Minecraft environment. We\nalso collect STEVE-21K dataset, which includes 600$+$ vision-environment pairs,\n20K knowledge question-answering pairs, and 200$+$ skill-code pairs. We conduct\ncontinuous block search, knowledge question and answering, and tech tree\nmastery to evaluate the performance. Extensive experiments show that STEVE\nachieves at most $1.5 \\times$ faster unlocking key tech trees and $2.5 \\times$\nquicker in block search tasks compared to previous state-of-the-art methods.",
            "author": [
                "Zhonghan Zhao",
                "Wenhao Chai",
                "Xuan Wang",
                "Li Boyi",
                "Shengyu Hao",
                "Shidong Cao",
                "Tian Ye",
                "Jenq-Neng Hwang",
                "Gaoang Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15209v2",
                "http://arxiv.org/pdf/2311.15209v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15208v1",
            "title": "LongStory: Coherent, Complete and Length Controlled Long story\n  Generation",
            "updated": "2023-11-26T06:24:25Z",
            "published": "2023-11-26T06:24:25Z",
            "summary": "A human author can write any length of story without losing coherence. Also,\nthey always bring the story to a proper ending, an ability that current\nlanguage models lack. In this work, we present the LongStory for coherent,\ncomplete, and length-controlled long story generation. LongStory introduces two\nnovel methodologies: (1) the long and short-term contexts weight calibrator\n(CWC) and (2) long story structural positions (LSP). The CWC adjusts weights\nfor long-term context Memory and short-term context Cheating, acknowledging\ntheir distinct roles. The LSP employs discourse tokens to convey the structural\npositions of a long story. Trained on three datasets with varied average story\nlengths, LongStory outperforms other baselines, including the strong story\ngenerator Plotmachine, in coherence, completeness, relevance, and\nrepetitiveness. We also perform zero-shot tests on each dataset to assess the\nmodel's ability to predict outcomes beyond its training data and validate our\nmethodology by comparing its performance with variants of our model.",
            "author": [
                "Kyeongman Park",
                "Nakyeong Yang",
                "Kyomin Jung"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15208v1",
                "http://arxiv.org/pdf/2311.15208v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15207v1",
            "title": "Efficient interpolation of molecular properties across chemical compound\n  space with low-dimensional descriptors",
            "updated": "2023-11-26T06:22:13Z",
            "published": "2023-11-26T06:22:13Z",
            "summary": "We demonstrate accurate data-starved models of molecular properties for\ninterpolation in chemical compound spaces with low-dimensional descriptors.\n  Our starting point is based on three-dimensional, universal, physical\ndescriptors derived from the properties of the distributions of the eigenvalues\nof Coulomb matrices. To account for the shape and composition of molecules, we\ncombine these descriptors with six-dimensional features informed by the\nGershgorin circle theorem. We use the nine-dimensional descriptors thus\nobtained for Gaussian process regression based on kernels with variable\nfunctional form, leading to extremely efficient, low-dimensional interpolation\nmodels. The resulting models trained with 100 molecules are able to predict the\nproduct of entropy and temperature ($S \\times T$) and zero point vibrational\nenergy (ZPVE) with the absolute error under 1 kcal mol$^{-1}$ for $> 78$ \\% and\nunder 1.3 kcal mol$^{-1}$ for $> 92$ \\% of molecules in the test data. The test\ndata comprises 20,000 molecules with complexity varying from three atoms to 29\natoms and the ranges of $S \\times T$ and ZPVE covering 36 kcal mol$^{-1}$ and\n161 kcal mol$^{-1}$, respectively. We also illustrate that the descriptors\nbased on the Gershgorin circle theorem yield more accurate models of molecular\nentropy than those based on graph neural networks that explicitly account for\nthe atomic connectivity of molecules.",
            "author": [
                "Yun-Wen Mao",
                "Roman V. Krems"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15207v1",
                "http://arxiv.org/pdf/2311.15207v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15205v1",
            "title": "Discrete stopping times in the lattice of continuous functions",
            "updated": "2023-11-26T06:08:33Z",
            "published": "2023-11-26T06:08:33Z",
            "summary": "A functional calculus for an order complete vector lattice $\\mathcal{E}$ was\ndeveloped by Grobler in 2014 using the Daniell integral. We show that if one\nrepresents the universal completion of $\\mathcal{E}$ as $C^\\infty(K)$, then the\nDaniell functional calculus for continuous functions is exactly the pointwise\ncomposition of functions in $C^\\infty(K)$. This representation allows an easy\ndeduction of the various properties of the functional calculus. Afterwards, we\nstudy discrete stopping times and stopped processes in $C^\\infty(K)$. We obtain\na representation that is analogous to what is expected in probability theory.",
            "author": [
                "Achintya Raya Polavarapu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15205v1",
                "http://arxiv.org/pdf/2311.15205v1"
            ],
            "primary_category": "math.FA",
            "category": [
                "math.FA",
                "46A40, 46E05, 60G20, 60G40"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15204v1",
            "title": "OpenDigger: Data Mining and Information Service System for Open\n  Collaboration Digital Ecosystem",
            "updated": "2023-11-26T05:56:40Z",
            "published": "2023-11-26T05:56:40Z",
            "summary": "The widespread development and adoption of open-source software have built an\necosystem for open development and collaboration. In this ecosystem,\nindividuals and organizations collaborate to create high-quality software that\ncan be used by everyone. Social collaboration platforms like GitHub have\nfurther facilitated large-scale, distributed, and fine-grained code\ncollaboration and technical interactions. Countless developers contribute code,\nreview code, report bugs, and propose new features on these platforms every\nday, generating a massive amount of valuable behavioral data from the open\ncollaboration process. This paper presents the design and implementation of\nOpenDigger, a comprehensive data mining and information service system for open\ncollaboration in the digital ecosystem. The goal is to build a data\ninfrastructure for the open-source domain and promote the continuous\ndevelopment of the open-source ecosystem. The metrics and analysis models in\nthe OpenDigger system can mine various knowledge from the macro to micro levels\nin the open-source digital ecosystem. Through a unified information service\ninterface, OpenDigger provides various open-source information services to\ndifferent user groups, including governments, enterprises, foundations, and\nindividuals. As a novel information service system in the open-source\necosystem, this paper demonstrates the effectiveness of the metrics and models\nin OpenDigger through several real-world scenarios, including products, tools,\napplications, and courses. It showcases the significant and diverse practical\napplications of the metrics and models in both algorithmic and business\naspects.",
            "author": [
                "Xiaoya Xia",
                "Shengyu Zhao",
                "Fanyu Han",
                "Fenglin Bi",
                "Wei Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15204v1",
                "http://arxiv.org/pdf/2311.15204v1"
            ],
            "primary_category": "cs.DL",
            "category": [
                "cs.DL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15198v1",
            "title": "ChatGPT and Beyond: The Generative AI Revolution in Education",
            "updated": "2023-11-26T05:34:22Z",
            "published": "2023-11-26T05:34:22Z",
            "summary": "The wide adoption and usage of generative artificial intelligence (AI)\nmodels, particularly ChatGPT, has sparked a surge in research exploring their\npotential applications in the educational landscape. This survey examines\nacademic literature published between November, 2022, and July, 2023,\nspecifically targeting high-impact research from Scopus-indexed Q1 and Q2\njournals. This survey delves into the practical applications and implications\nof generative AI models across a diverse range of educational contexts. Through\na comprehensive and rigorous evaluation of recent academic literature, this\nsurvey seeks to illuminate the evolving role of generative AI models,\nparticularly ChatGPT, in education. By shedding light on the potential\nbenefits, challenges, and emerging trends in this dynamic field, the survey\nendeavors to contribute to the understanding of the nexus between artificial\nintelligence and education. The findings of this review will empower educators,\nresearchers, and policymakers to make informed decisions about the integration\nof AI technologies into learning environments.",
            "author": [
                "Mohammad AL-Smadi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15198v1",
                "http://arxiv.org/pdf/2311.15198v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.03719v1",
            "title": "Assessing AI Chatbots Performance in Comprehensive Standardized Test\n  Preparation; A Case Study with GRE",
            "updated": "2023-11-26T05:27:35Z",
            "published": "2023-11-26T05:27:35Z",
            "summary": "This research paper presents a comprehensive evaluation of the performance of\nthree artificial 10 intelligence chatbots: Bing, ChatGPT, and GPT-4, in\naddressing standardized test questions. Graduate record examination, known as\nGRE, serves as a case study in this paper, encompassing both quantitative\nreasoning and verbal skills. A total of 137 quantitative reasoning questions,\nfeaturing diverse styles and 157 verbal questions categorized into varying\nlevels of difficulty (easy, medium, and hard) were administered to assess the\nchatbots' capabilities. This paper provides a detailed examination of the\nresults and their implications for the utilization of artificial intelligence\nin standardized test preparation by presenting the performance of each chatbot\nacross various skills and styles tested in the exam. Additionally, this paper\nexplores the proficiency of artificial intelligence in addressing image-based\nquestions and illustrates the uncertainty level of each chatbot. The results\nreveal varying degrees of success across the chatbots, demonstrating the\ninfluence of model sophistication and training data. GPT-4 emerged as the most\nproficient, especially in complex language understanding tasks, highlighting\nthe evolution of artificial intelligence in language comprehension and its\nability to pass the exam with a high score.",
            "author": [
                "Mohammad Abu-Haifa",
                "Bara'a Etawi",
                "Huthaifa Alkhatatbeh",
                "Ayman Ababneh"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03719v1",
                "http://arxiv.org/pdf/2312.03719v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15194v1",
            "title": "Neural Network Models of Becoming a Cardinal Principle Knower",
            "updated": "2023-11-26T05:17:45Z",
            "published": "2023-11-26T05:17:45Z",
            "summary": "As children enter elementary school, their understanding of the ordinal\nstructure of numbers transitions from a memorized count list of the first\n50-100 numbers to knowing the successor function and understanding the\ncountably infinite. We investigate this developmental change in two neural\nnetwork models that learn the successor function on the pairs (N, N+1) for N in\n(0, 98). The first uses a one-hot encoding of the input and output values and\ncorresponds to children memorizing a count list, while the second model uses a\nplace-value encoding and corresponds to children learning the language rules\nfor naming numbers. The place-value model showed a predicted drop in\nrepresentational similarity across tens boundaries. Counting across a tens\nboundary can be understood as a vector operation in 2D space, where the numbers\nwith the same tens place are organized in a linearly separable manner, whereas\nthose with the same ones place are grouped together. A curriculum learning\nsimulation shows that, in the expanding numerical environment of the developing\nchild, representations of smaller numbers continue to be sharpened even as\nlarger numbers begin to be learned. These models set the stage for future work\nusing recurrent architectures to move beyond learning the successor function to\nsimulating the counting process more generally, and point towards a deeper\nunderstanding of what it means to understand the countably infinite.",
            "author": [
                "Vima Gupta",
                "Sashank Varma"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15194v1",
                "http://arxiv.org/pdf/2311.15194v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15185v1",
            "title": "Contractibility of the solution sets for set optimization problems",
            "updated": "2023-11-26T04:23:21Z",
            "published": "2023-11-26T04:23:21Z",
            "summary": "This paper aims at investigating the contractibility of the solution sets for\nset optimization problems by utilizing strictly quasi cone-convexlikeness,\nwhich is an assumption weaker than strictly cone-convexity, strictly\ncone-quasiconvexity and strictly naturally quasi cone-convexity. We establish\nthe contractibility of l-minimal, l-weak minimal, u-minimal and u-weak minimal\nsolution sets for set optimization problems by using the star-shape sets and\nthe nonlinear scalarizing functions for sets. Moreover, we also discuss the\narcwise connectedness and the contractibility of p-minimal and p-weak minimal\nsolution sets for set optimization problems by using the scalarization\ntechnique. Finally, our main results are applied to the contractibility of the\nsolution sets for vector optimization problems.",
            "author": [
                "Bin Chen",
                "Yu Han"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15185v1",
                "http://arxiv.org/pdf/2311.15185v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15180v1",
            "title": "Benchmarking Large Language Model Volatility",
            "updated": "2023-11-26T03:54:03Z",
            "published": "2023-11-26T03:54:03Z",
            "summary": "The impact of non-deterministic outputs from Large Language Models (LLMs) is\nnot well examined for financial text understanding tasks. Through a compelling\ncase study on investing in the US equity market via news sentiment analysis, we\nuncover substantial variability in sentence-level sentiment classification\nresults, underscoring the innate volatility of LLM outputs. These uncertainties\ncascade downstream, leading to more significant variations in portfolio\nconstruction and return. While tweaking the temperature parameter in the\nlanguage model decoder presents a potential remedy, it comes at the expense of\nstifled creativity. Similarly, while ensembling multiple outputs mitigates the\neffect of volatile outputs, it demands a notable computational investment. This\nwork furnishes practitioners with invaluable insights for adeptly navigating\nuncertainty in the integration of LLMs into financial decision-making,\nparticularly in scenarios dictated by non-deterministic information.",
            "author": [
                "Boyang Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15180v1",
                "http://arxiv.org/pdf/2311.15180v1"
            ],
            "primary_category": "q-fin.TR",
            "category": [
                "q-fin.TR",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15167v1",
            "title": "Self-supervised OCT Image Denoising with Slice-to-Slice Registration and\n  Reconstruction",
            "updated": "2023-11-26T02:45:16Z",
            "published": "2023-11-26T02:45:16Z",
            "summary": "Strong speckle noise is inherent to optical coherence tomography (OCT)\nimaging and represents a significant obstacle for accurate quantitative\nanalysis of retinal structures which is key for advances in clinical diagnosis\nand monitoring of disease. Learning-based self-supervised methods for\nstructure-preserving noise reduction have demonstrated superior performance\nover traditional methods but face unique challenges in OCT imaging. The high\ncorrelation of voxels generated by coherent A-scan beams undermines the\nefficacy of self-supervised learning methods as it violates the assumption of\nindependent pixel noise. We conduct experiments demonstrating limitations of\nexisting models due to this independence assumption. We then introduce a new\nend-to-end self-supervised learning framework specifically tailored for OCT\nimage denoising, integrating slice-by-slice training and registration modules\ninto one network. An extensive ablation study is conducted for the proposed\napproach. Comparison to previously published self-supervised denoising models\ndemonstrates improved performance of the proposed framework, potentially\nserving as a preprocessing step towards superior segmentation performance and\nquantitative analysis.",
            "author": [
                "Shijie Li",
                "Palaiologos Alexopoulos",
                "Anse Vellappally",
                "Ronald Zambrano",
                "Wollstein Gadi",
                "Guido Gerig"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15167v1",
                "http://arxiv.org/pdf/2311.15167v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15166v1",
            "title": "CP violation in lepton-number-conserving processes through heavy\n  Majorana neutrinos at future lepton colliders",
            "updated": "2023-11-26T02:39:52Z",
            "published": "2023-11-26T02:39:52Z",
            "summary": "Small neutrino masses confirmed in the neutrino oscillation experiments\nindicate the need for new physics beyond the standard model. Seesaw mechanism\nis an interesting way to extend the standard model for explaining the neutrino\nmasses. In a low-scale type-I seesaw mechanism, the tiny masses of neutrinos\ncan be explained by heavy Majorana neutrino masses. Heavy Majorana neutrinos\ncan lead to lepton-number-violating processes and the induced CP violation can\ncontribute to the baryon asymmetry in the Universe. Heavy Majorana neutrinos\ncan also lead to lepton-number-conserving processes and in this paper, we study\nthe CP violation in lepton-number-conserving processes through heavy Majorana\nneutrinos at future lepton colliders. New possible observations of CP violation\ncan also be connected to evidences of new physics beyond the standard model.",
            "author": [
                "Zhe Wang",
                "Xing-Hua Yang",
                "Xin-Yi Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15166v1",
                "http://arxiv.org/pdf/2311.15166v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15164v1",
            "title": "Neural-Optic Co-Designed Polarization-Multiplexed Metalens for Compact\n  Computational Spectral Imaging",
            "updated": "2023-11-26T02:06:30Z",
            "published": "2023-11-26T02:06:30Z",
            "summary": "As the realm of spectral imaging applications extends its reach into the\ndomains of mobile technology and augmented reality, the demands for compact yet\nhigh-fidelity systems become increasingly pronounced. Conventional\nmethodologies, exemplified by coded aperture snapshot spectral imaging systems,\nare significantly limited by their cumbersome physical dimensions and form\nfactors. To address this inherent challenge, diffractive optical elements\n(DOEs) have been repeatedly employed as a means to mitigate issues related to\nthe bulky nature of these systems. Nonetheless, it's essential to note that the\ncapabilities of DOEs primarily revolve around the modulation of the phase of\nlight. Here, we introduce an end-to-end computational spectral imaging\nframework based on a polarization-multiplexed metalens. A distinguishing\nfeature of this approach lies in its capacity to simultaneously modulate\northogonal polarization channels. When harnessed in conjunction with a neural\nnetwork, it facilitates the attainment of high-fidelity spectral\nreconstruction. Importantly, the framework is intrinsically fully\ndifferentiable, a feature that permits the joint optimization of both the\nmetalens structure and the parameters governing the neural network. The\nexperimental results presented herein validate the exceptional spatial-spectral\nreconstruction performance, underscoring the efficacy of this system in\npractical, real-world scenarios. This innovative approach transcends the\ntraditional boundaries separating hardware and software in the realm of\ncomputational imaging and holds the promise of substantially propelling the\nminiaturization of spectral imaging systems.",
            "author": [
                "Qiangbo Zhang",
                "Peicheng Lin",
                "Chang Wang",
                "Yang Zhang",
                "Zeqing Yu",
                "Xinyu Liu",
                "Ting Xu",
                "Zhenrong Zheng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15164v1",
                "http://arxiv.org/pdf/2311.15164v1"
            ],
            "primary_category": "physics.optics",
            "category": [
                "physics.optics",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15163v1",
            "title": "Deep Learning-Based Approaches for Contactless Fingerprints Segmentation\n  and Extraction",
            "updated": "2023-11-26T01:56:10Z",
            "published": "2023-11-26T01:56:10Z",
            "summary": "Fingerprints are widely recognized as one of the most unique and reliable\ncharacteristics of human identity. Most modern fingerprint authentication\nsystems rely on contact-based fingerprints, which require the use of\nfingerprint scanners or fingerprint sensors for capturing fingerprints during\nthe authentication process. Various types of fingerprint sensors, such as\noptical, capacitive, and ultrasonic sensors, employ distinct techniques to\ngather and analyze fingerprint data. This dependency on specific hardware or\nsensors creates a barrier or challenge for the broader adoption of fingerprint\nbased biometric systems. This limitation hinders the widespread adoption of\nfingerprint authentication in various applications and scenarios. Border\ncontrol, healthcare systems, educational institutions, financial transactions,\nand airport security face challenges when fingerprint sensors are not\nuniversally available. To mitigate the dependence on additional hardware, the\nuse of contactless fingerprints has emerged as an alternative. Developing\nprecise fingerprint segmentation methods, accurate fingerprint extraction\ntools, and reliable fingerprint matchers are crucial for the successful\nimplementation of a robust contactless fingerprint authentication system. This\npaper focuses on the development of a deep learning-based segmentation tool for\ncontactless fingerprint localization and segmentation. Our system leverages\ndeep learning techniques to achieve high segmentation accuracy and reliable\nextraction of fingerprints from contactless fingerprint images. In our\nevaluation, our segmentation method demonstrated an average mean absolute error\n(MAE) of 30 pixels, an error in angle prediction (EAP) of 5.92 degrees, and a\nlabeling accuracy of 97.46%. These results demonstrate the effectiveness of our\nnovel contactless fingerprint segmentation and extraction tools.",
            "author": [
                "M. G. Sarwar Murshed",
                "Syed Konain Abbas",
                "Sandip Purnapatra",
                "Daqing Hou",
                "Faraz Hussain"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15163v1",
                "http://arxiv.org/pdf/2311.15163v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15162v1",
            "title": "Domain Knowledge Injection in Bayesian Search for New Materials",
            "updated": "2023-11-26T01:55:55Z",
            "published": "2023-11-26T01:55:55Z",
            "summary": "In this paper we propose DKIBO, a Bayesian optimization (BO) algorithm that\naccommodates domain knowledge to tune exploration in the search space. Bayesian\noptimization has recently emerged as a sample-efficient optimizer for many\nintractable scientific problems. While various existing BO frameworks allow the\ninput of prior beliefs to accelerate the search by narrowing down the space,\nincorporating such knowledge is not always straightforward and can often\nintroduce bias and lead to poor performance. Here we propose a simple approach\nto incorporate structural knowledge in the acquisition function by utilizing an\nadditional deterministic surrogate model to enrich the approximation power of\nthe Gaussian process. This is suitably chosen according to structural\ninformation of the problem at hand and acts a corrective term towards a\nbetter-informed sampling. We empirically demonstrate the practical utility of\nthe proposed method by successfully injecting domain knowledge in a materials\ndesign task. We further validate our method's performance on different\nexperimental settings and ablation analyses.",
            "author": [
                "Zikai Xie",
                "Xenophon Evangelopoulos",
                "Joseph Thacker",
                "Andrew Cooper"
            ],
            "link": [
                "http://dx.doi.org/10.3233/FAIA230587",
                "http://arxiv.org/abs/2311.15162v1",
                "http://arxiv.org/pdf/2311.15162v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "68W99",
                "I.2.8"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15158v1",
            "title": "Angular-Distance Based Channel Estimation for Holographic MIMO",
            "updated": "2023-11-26T01:28:55Z",
            "published": "2023-11-26T01:28:55Z",
            "summary": "This paper investigates the channel estimation for holographic MIMO systems\nby unmasking their distinctions from the conventional one. Specifically, we\nelucidate that the channel estimation, subject to holographic MIMO's\nelectromagnetically large antenna arrays, has to discriminate not only the\nangles of a user/scatterer but also its distance information, namely the\nthree-dimensional (3D) azimuth and elevation angles plus the distance (AED)\nparameters. As the angular-domain representation fails to characterize the\nsparsity inherent in holographic MIMO channels, the tightly coupled 3D AED\nparameters are firstly decomposed for independently constructing their own\ncovariance matrices. Then, the recovery of each individual parameter can be\nstructured as a compressive sensing (CS) problem by harnessing the covariance\nmatrix constructed. This pair of techniques contribute to a parametric\ndecomposition and compressed deconstruction (DeRe) framework, along with a\nformulation of the maximum likelihood estimation for each parameter. Then, an\nefficient algorithm, namely DeRe-based variational Bayesian inference and\nmessage passing (DeRe-VM), is proposed for the sharp detection of the 3D AED\nparameters and the robust recovery of sparse channels. Finally, the proposed\nchannel estimation regime is confirmed to be of great robustness in\naccommodating different channel conditions, regardless of the near-field and\nfar-field contexts of a holographic MIMO system, as well as an improved\nperformance in comparison to the state-of-the-art benchmarks.",
            "author": [
                "Yuanbin Chen",
                "Ying Wang",
                "Zhaocheng Wang",
                "Zhu Han"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15158v1",
                "http://arxiv.org/pdf/2311.15158v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15153v1",
            "title": "Self-Supervised Learning for SAR ATR with a Knowledge-Guided Predictive\n  Architecture",
            "updated": "2023-11-26T01:05:55Z",
            "published": "2023-11-26T01:05:55Z",
            "summary": "Recently, the emergence of a large number of Synthetic Aperture Radar (SAR)\nsensors and target datasets has made it possible to unify downstream tasks with\nself-supervised learning techniques, which can pave the way for building the\nfoundation model in the SAR target recognition field. The major challenge of\nself-supervised learning for SAR target recognition lies in the generalizable\nrepresentation learning in low data quality and noise.To address the\naforementioned problem, we propose a knowledge-guided predictive architecture\nthat uses local masked patches to predict the multiscale SAR feature\nrepresentations of unseen context. The core of the proposed architecture lies\nin combining traditional SAR domain feature extraction with state-of-the-art\nscalable self-supervised learning for accurate generalized feature\nrepresentations. The proposed framework is validated on various downstream\ndatasets (MSTAR, FUSAR-Ship, SAR-ACD and SSDD), and can bring consistent\nperformance improvement for SAR target recognition. The experimental results\nstrongly demonstrate the unified performance improvement of the self-supervised\nlearning technique for SAR target recognition across diverse targets, scenes\nand sensors.",
            "author": [
                "Weijie Li",
                "Yang Wei",
                "Tianpeng Liu",
                "Yuenan Hou",
                "Yongxiang Liu",
                "Li Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15153v1",
                "http://arxiv.org/pdf/2311.15153v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.03718v1",
            "title": "Large Language Models in Law: A Survey",
            "updated": "2023-11-26T00:48:12Z",
            "published": "2023-11-26T00:48:12Z",
            "summary": "The advent of artificial intelligence (AI) has significantly impacted the\ntraditional judicial industry. Moreover, recently, with the development of\nAI-generated content (AIGC), AI and law have found applications in various\ndomains, including image recognition, automatic text generation, and\ninteractive chat. With the rapid emergence and growing popularity of large\nmodels, it is evident that AI will drive transformation in the traditional\njudicial industry. However, the application of legal large language models\n(LLMs) is still in its nascent stage. Several challenges need to be addressed.\nIn this paper, we aim to provide a comprehensive survey of legal LLMs. We not\nonly conduct an extensive survey of LLMs, but also expose their applications in\nthe judicial system. We first provide an overview of AI technologies in the\nlegal field and showcase the recent research in LLMs. Then, we discuss the\npractical implementation presented by legal LLMs, such as providing legal\nadvice to users and assisting judges during trials. In addition, we explore the\nlimitations of legal LLMs, including data, algorithms, and judicial practice.\nFinally, we summarize practical recommendations and propose future development\ndirections to address these challenges.",
            "author": [
                "Jinqi Lai",
                "Wensheng Gan",
                "Jiayang Wu",
                "Zhenlian Qi",
                "Philip S. Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03718v1",
                "http://arxiv.org/pdf/2312.03718v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15150v1",
            "title": "Observation of the spectral bifurcation in the Fractional Nonlinear\n  Schr\u00f6dinger Equation",
            "updated": "2023-11-26T00:34:15Z",
            "published": "2023-11-26T00:34:15Z",
            "summary": "We report a comprehensive investigation and experimental realization of\nspectral bifurcations of ultrafast soliton pulses. These bifurcations are\ninduced by the interplay between fractional group-velocity dispersion and Kerr\nnonlinearity (self-phase modulation) within the framework of the fractional\nnonlinear Schr\\\"{o}dinger equation. To capture the dynamics of the pulses under\nthe action of the fractional dispersion and nonlinearity, we propose an\neffective `force' model based on the frequency chirp, which characterizes their\ninteractions as either `repulsion', `attraction', or `equilibration'. By\nleveraging the `force' model, we design segmented fractional dispersion\nprofiles that directly generate spectral bifurcations \\{1\\}$\\rightarrow$ \\{N\\}\nat relevant nonlinearity levels. These results extend beyond the traditional\nsequence of bifurcations \\{1\\}$\\rightarrow$ \\{2\\}$\\rightarrow$ \\{3\\} ...\n$\\rightarrow$ \\{N\\} associated with the growth of the nonlinearity. The\nexperimental validation involves a precisely tailored hologram within a pulse\nshaper setup, coupled to an alterable nonlinear medium. Notably, we achieve up\nto N=5 in \\{1\\}$\\rightarrow$ \\{N\\} bifurcations at a significantly lower\nstrength of nonlinearity than otherwise would be required in a sequential\ncascade. The proposal for engineering spectral bifurcation patterns holds\nsignificant potential for ultrafast signal processing applications. As a\npractical illustration, we employ these bifurcation modes to optical data\nsqueezing and transmitting it across a 100-km-long single-mode fiber.",
            "author": [
                "Shilong Liu",
                "Yingwen Zhang",
                "St\u00e9phane Virally",
                "Ebrahim Karimi",
                "Boris A. Malomed",
                "Denis V. Seletskiy"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15150v1",
                "http://arxiv.org/pdf/2311.15150v1"
            ],
            "primary_category": "physics.optics",
            "category": [
                "physics.optics",
                "math-ph",
                "math.MP",
                "nlin.PS",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15145v1",
            "title": "Choosing Wisely and Learning Deeply: Selective Cross-Modality\n  Distillation via CLIP for Domain Generalization",
            "updated": "2023-11-26T00:06:12Z",
            "published": "2023-11-26T00:06:12Z",
            "summary": "Domain Generalization (DG), a crucial research area, seeks to train models\nacross multiple domains and test them on unseen ones. In this paper, we\nintroduce a novel approach, namely, Selective Cross-Modality Distillation for\nDomain Generalization (SCMD). SCMD leverages the capabilities of large\nvision-language models, specifically the CLIP model, to train a more efficient\nmodel, ensuring it acquires robust generalization capabilities across unseen\ndomains. Our primary contribution is a unique selection framework strategically\ndesigned to identify hard-to-learn samples for distillation. In parallel, we\nintroduce a novel cross-modality module. This module seamlessly combines the\nprojected features of the student model with the text embeddings from CLIP,\nensuring the alignment of similarity distributions. We assess SCMD's\nperformance on various benchmarks, where it empowers a ResNet50 to deliver\nstate-of-the-art performance, surpassing existing domain generalization\nmethods. Furthermore, we provide a theoretical analysis of our selection\nstrategy, offering deeper insight into its effectiveness and potential in the\nfield of DG.",
            "author": [
                "Jixuan Leng",
                "Yijiang Li",
                "Haohan Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15145v1",
                "http://arxiv.org/pdf/2311.15145v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15143v1",
            "title": "Reduced Augmentation Implicit Low-rank (RAIL) integrators for\n  advection-diffusion and Fokker-Planck models",
            "updated": "2023-11-26T00:03:26Z",
            "published": "2023-11-26T00:03:26Z",
            "summary": "This paper introduces a novel computational approach termed the Reduced\nAugmentation Implicit Low-rank (RAIL) method by investigating two predominant\nresearch directions in low-rank solutions to time-dependent partial\ndifferential equations (PDEs): dynamical low-rank (DLR), and step and\ntruncation (SAT) tensor methods. The RAIL method, along with the development of\nthe SAT approach, is designed to enhance the efficiency of traditional\nfull-rank implicit solvers from method-of-lines discretizations of\ntime-dependent PDEs, while maintaining accuracy and stability. We consider\nspectral methods for spatial discretization, and diagonally implicit\nRunge-Kutta (DIRK) and implicit-explicit (IMEX) RK methods for time\ndiscretization. The efficiency gain is achieved by investigating low-rank\nstructures within solutions at each RK stage using a singular value\ndecomposition (SVD). In particular, we develop a reduced augmentation procedure\nto predict the basis functions to construct projection subspaces. This\nprocedure balances algorithm accuracy and efficiency by incorporating as many\nbases as possible from previous RK stages and predictions, and by optimizing\nthe basis representation through SVD truncation. As such, one can form implicit\nschemes for updating basis functions in a dimension-by-dimension manner,\nsimilar in spirit to the K-L step in the DLR framework. We also apply a\nglobally mass conservative post-processing step at the end of each RK stage. We\nvalidate the RAIL method through numerical simulations of advection-diffusion\nproblems and a Fokker-Planck model, showcasing its ability to efficiently\nhandle time-dependent PDEs while maintaining global mass conservation. Our\napproach generalizes and bridges the DLR and SAT approaches, offering a\ncomprehensive framework for efficiently and accurately solving time-dependent\nPDEs with implicit treatment.",
            "author": [
                "Joseph Nakao",
                "Jing-Mei Qiu",
                "Lukas Einkemmer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15143v1",
                "http://arxiv.org/pdf/2311.15143v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA",
                "65"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15141v1",
            "title": "OFDMA-F$^2$L: Federated Learning With Flexible Aggregation Over an OFDMA\n  Air Interface",
            "updated": "2023-11-25T23:47:56Z",
            "published": "2023-11-25T23:47:56Z",
            "summary": "Federated learning (FL) can suffer from a communication bottleneck when\ndeployed in mobile networks, limiting participating clients and deterring FL\nconvergence. The impact of practical air interfaces with discrete modulations\non FL has not previously been studied in depth. This paper proposes a new\nparadigm of flexible aggregation-based FL (F$^2$L) over orthogonal frequency\ndivision multiple-access (OFDMA) air interface, termed as ``OFDMA-F$^2$L'',\nallowing selected clients to train local models for various numbers of\niterations before uploading the models in each aggregation round. We optimize\nthe selections of clients, subchannels and modulations, adapting to channel\nconditions and computing powers. Specifically, we derive an upper bound on the\noptimality gap of OFDMA-F$^2$L capturing the impact of the selections, and show\nthat the upper bound is minimized by maximizing the weighted sum rate of the\nclients per aggregation round. A Lagrange-dual based method is developed to\nsolve this challenging mixed integer program of weighted sum rate maximization,\nrevealing that a ``winner-takes-all'' policy provides the almost surely optimal\nclient, subchannel, and modulation selections. Experiments on multilayer\nperceptrons and convolutional neural networks show that OFDMA-F$^2$L with\noptimal selections can significantly improve the training convergence and\naccuracy, e.g., by about 18\\% and 5\\%, compared to potential alternatives.",
            "author": [
                "Shuyan Hu",
                "Xin Yuan",
                "Wei Ni",
                "Xin Wang",
                "Ekram Hossain",
                "H. Vincent Poor"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15141v1",
                "http://arxiv.org/pdf/2311.15141v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15138v2",
            "title": "Can SAM recognize crops? Quantifying the zero-shot performance of a\n  semantic segmentation foundation model on generating crop-type maps using\n  satellite imagery for precision agriculture",
            "updated": "2023-12-04T21:02:05Z",
            "published": "2023-11-25T23:40:09Z",
            "summary": "Climate change is increasingly disrupting worldwide agriculture, making\nglobal food production less reliable. To tackle the growing challenges in\nfeeding the planet, cutting-edge management strategies, such as precision\nagriculture, empower farmers and decision-makers with rich and actionable\ninformation to increase the efficiency and sustainability of their farming\npractices. Crop-type maps are key information for decision-support tools but\nare challenging and costly to generate. We investigate the capabilities of Meta\nAI's Segment Anything Model (SAM) for crop-map prediction task, acknowledging\nits recent successes at zero-shot image segmentation. However, SAM being\nlimited to up-to 3 channel inputs and its zero-shot usage being class-agnostic\nin nature pose unique challenges in using it directly for crop-type mapping. We\npropose using clustering consensus metrics to assess SAM's zero-shot\nperformance in segmenting satellite imagery and producing crop-type maps.\nAlthough direct crop-type mapping is challenging using SAM in zero-shot\nsetting, experiments reveal SAM's potential for swiftly and accurately\noutlining fields in satellite images, serving as a foundation for subsequent\ncrop classification. This paper attempts to highlight a use-case of\nstate-of-the-art image segmentation models like SAM for crop-type mapping and\nrelated specific needs of the agriculture industry, offering a potential avenue\nfor automatic, efficient, and cost-effective data products for precision\nagriculture practices.",
            "author": [
                "Rutuja Gurav",
                "Het Patel",
                "Zhuocheng Shang",
                "Ahmed Eldawy",
                "Jia Chen",
                "Elia Scudiero",
                "Evangelos Papalexakis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15138v2",
                "http://arxiv.org/pdf/2311.15138v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15137v1",
            "title": "Multi-fidelity Constrained Optimization for Stochastic Black Box\n  Simulators",
            "updated": "2023-11-25T23:36:38Z",
            "published": "2023-11-25T23:36:38Z",
            "summary": "Constrained optimization of the parameters of a simulator plays a crucial\nrole in a design process. These problems become challenging when the simulator\nis stochastic, computationally expensive, and the parameter space is\nhigh-dimensional. One can efficiently perform optimization only by utilizing\nthe gradient with respect to the parameters, but these gradients are\nunavailable in many legacy, black-box codes. We introduce the algorithm\nScout-Nd (Stochastic Constrained Optimization for N dimensions) to tackle the\nissues mentioned earlier by efficiently estimating the gradient, reducing the\nnoise of the gradient estimator, and applying multi-fidelity schemes to further\nreduce computational effort. We validate our approach on standard benchmarks,\ndemonstrating its effectiveness in optimizing parameters highlighting better\nperformance compared to existing methods.",
            "author": [
                "Atul Agrawal",
                "Kislaya Ravi",
                "Phaedon-Stelios Koutsourelakis",
                "Hans-Joachim Bungartz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15137v1",
                "http://arxiv.org/pdf/2311.15137v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15132v1",
            "title": "Enhancement of Superconducting Properties of Polycrystalline CaKFe4As4\n  by High-Pressure Growth",
            "updated": "2023-11-25T22:44:38Z",
            "published": "2023-11-25T22:44:38Z",
            "summary": "High-pressure growth is a unique method to improve the sample quality and\nsize. Here, we have used the high gas pressure and high-temperature synthesis\n(HP-HTS) method to grow CaKFe4As4 (1144) bulks and investigated their\nsuperconducting properties using structural, microstructural, transport, and\nmagnetic studies. The microstructural analysis demonstrates that 1144 samples\nprepared by HP-HTS have improved the sample density and grain connectivity. The\ntransition temperature (Tconset) of 1144 bulks prepared by HP-HTS is increased\nup to 35.2 K with a transition width ({\\Delta}T) of 1 K, which is remarkably\ncomparable to the reported 1144 single crystal. Additionally, the critical\ncurrent density (Jc) is enhanced by almost one order of magnitude compared with\nthe parent compound prepared by the conventional synthesis process at ambient\npressure (CSP), which could be attributed to the improved sample density and\neffective pinning centers. Our study demonstrates that the sample quality and\nsuperconducting properties of various iron-based superconductors can be\nenhanced by applying the HP-HTS approach, and further research is demanded in\nthis direction.",
            "author": [
                "Manasa Manasa",
                "Mohammad Azam",
                "Tatiana Zajarniuk",
                "Ryszard Diduszko",
                "Tomasz Cetner",
                "Andrzej Morawski",
                "Andrzej Wisniewski",
                "Shiv J. Singh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15132v1",
                "http://arxiv.org/pdf/2311.15132v1"
            ],
            "primary_category": "cond-mat.supr-con",
            "category": [
                "cond-mat.supr-con",
                "cond-mat.mtrl-sci",
                "physics.app-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15131v1",
            "title": "Localizing Lying in Llama: Understanding Instructed Dishonesty on\n  True-False Questions Through Prompting, Probing, and Patching",
            "updated": "2023-11-25T22:41:23Z",
            "published": "2023-11-25T22:41:23Z",
            "summary": "Large language models (LLMs) demonstrate significant knowledge through their\noutputs, though it is often unclear whether false outputs are due to a lack of\nknowledge or dishonesty. In this paper, we investigate instructed dishonesty,\nwherein we explicitly prompt LLaMA-2-70b-chat to lie. We perform prompt\nengineering to find which prompts best induce lying behavior, and then use\nmechanistic interpretability approaches to localize where in the network this\nbehavior occurs. Using linear probing and activation patching, we localize five\nlayers that appear especially important for lying. We then find just 46\nattention heads within these layers that enable us to causally intervene such\nthat the lying model instead answers honestly. We show that these interventions\nwork robustly across many prompts and dataset splits. Overall, our work\ncontributes a greater understanding of dishonesty in LLMs so that we may hope\nto prevent it.",
            "author": [
                "James Campbell",
                "Richard Ren",
                "Phillip Guo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15131v1",
                "http://arxiv.org/pdf/2311.15131v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15128v1",
            "title": "Quickest Change Detection with Post-Change Density Estimation",
            "updated": "2023-11-25T22:29:05Z",
            "published": "2023-11-25T22:29:05Z",
            "summary": "The problem of quickest change detection in a sequence of independent\nobservations is considered. The pre-change distribution is assumed to be known,\nwhile the post-change distribution is unknown. Two tests based on post-change\ndensity estimation are developed for this problem, the window-limited\nnon-parametric generalized likelihood ratio (NGLR) CuSum test and the\nnon-parametric window-limited adaptive (NWLA) CuSum test. Both tests do not\nassume any knowledge of the post-change distribution, except that the\npost-change density satisfies certain smoothness conditions that allows for\nefficient non-parametric estimation. Also, they do not require any\npre-collected post-change training samples. Under certain convergence\nconditions on the density estimator, it is shown that both tests are\nfirst-order asymptotically optimal, as the false alarm rate goes to zero. The\nanalysis is validated through numerical results, where both tests are compared\nwith baseline tests that have distributional knowledge.",
            "author": [
                "Yuchen Liang",
                "Venugopal V. Veeravalli"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15128v1",
                "http://arxiv.org/pdf/2311.15128v1"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "eess.SP",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15127v1",
            "title": "Stable Video Diffusion: Scaling Latent Video Diffusion Models to Large\n  Datasets",
            "updated": "2023-11-25T22:28:38Z",
            "published": "2023-11-25T22:28:38Z",
            "summary": "We present Stable Video Diffusion - a latent video diffusion model for\nhigh-resolution, state-of-the-art text-to-video and image-to-video generation.\nRecently, latent diffusion models trained for 2D image synthesis have been\nturned into generative video models by inserting temporal layers and finetuning\nthem on small, high-quality video datasets. However, training methods in the\nliterature vary widely, and the field has yet to agree on a unified strategy\nfor curating video data. In this paper, we identify and evaluate three\ndifferent stages for successful training of video LDMs: text-to-image\npretraining, video pretraining, and high-quality video finetuning. Furthermore,\nwe demonstrate the necessity of a well-curated pretraining dataset for\ngenerating high-quality videos and present a systematic curation process to\ntrain a strong base model, including captioning and filtering strategies. We\nthen explore the impact of finetuning our base model on high-quality data and\ntrain a text-to-video model that is competitive with closed-source video\ngeneration. We also show that our base model provides a powerful motion\nrepresentation for downstream tasks such as image-to-video generation and\nadaptability to camera motion-specific LoRA modules. Finally, we demonstrate\nthat our model provides a strong multi-view 3D-prior and can serve as a base to\nfinetune a multi-view diffusion model that jointly generates multiple views of\nobjects in a feedforward fashion, outperforming image-based methods at a\nfraction of their compute budget. We release code and model weights at\nhttps://github.com/Stability-AI/generative-models .",
            "author": [
                "Andreas Blattmann",
                "Tim Dockhorn",
                "Sumith Kulal",
                "Daniel Mendelevitch",
                "Maciej Kilian",
                "Dominik Lorenz",
                "Yam Levi",
                "Zion English",
                "Vikram Voleti",
                "Adam Letts",
                "Varun Jampani",
                "Robin Rombach"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15127v1",
                "http://arxiv.org/pdf/2311.15127v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15120v1",
            "title": "The nature of very-faint X-ray binaries: Near-infrared spectroscopy of\n  1RXH J173523.7$-$354013 reveals a giant companion",
            "updated": "2023-11-25T21:43:51Z",
            "published": "2023-11-25T21:43:51Z",
            "summary": "Very-faint X-ray binaries (VFXBs) are a sub-class of black holes and neutron\nstars in binaries that appear to be accreting at a very low rate. In addition\nto providing interesting constraints on poorly understood forms of accretion,\nelucidating the nature of VFXBs is particularly interesting for binary\nevolution and population modeling. Through near-infrared (nIR) spectroscopy, we\nhere investigate the nature of the bursting neutron star and VFXB 1RXH\nJ173523.7$-$354013 (J1735), which persistently accretes at an X-ray luminosity\nof $L_X \\sim 10^{34} - 10^{35}~L_{\\odot}$. Our analysis shows that the nIR\nemission is dominated by that of the companion star, which we find to be a late\nG or early K-type giant, making this the second neutron star identified as a\nVFXB found to have a giant companion. We discuss how several of the system\nproperties are difficult to reconcile with a wind-fed symbiotic X-ray binary.\nWe therefore also propose an alternative scenario wherein J1735 is a wide\nbinary system (supported by the discovery of a 7.5 d modulation in the nIR\nlight curves) with a quiescent luminosity of $L_X \\sim 10^{34} -\n10^{35}~L_{\\odot}$, in which the donor star is overflowing its Roche lobe. This\nraises the possibility that J1735 may, every century or more, exhibit very long\nand very bright outbursts during which it reaches accretion rates around the\nEddington limit like the neutron star Z sources.",
            "author": [
                "A. W. Shaw",
                "N. Degenaar",
                "T. J. Maccarone",
                "C. O. Heinke",
                "R. Wijnands",
                "J. van den Eijnden"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15120v1",
                "http://arxiv.org/pdf/2311.15120v1"
            ],
            "primary_category": "astro-ph.HE",
            "category": [
                "astro-ph.HE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15117v1",
            "title": "Resilience-driven Planning of Electric Power Systems Against Extreme\n  Weather Events",
            "updated": "2023-11-25T21:01:08Z",
            "published": "2023-11-25T21:01:08Z",
            "summary": "With the increasing frequency of natural disasters, operators must prioritize\nimprovements in the existing electric power grid infrastructure to enhance the\nresilience of the grid. Resilience to extreme weather events necessitates\nlowering the impacts of high-impact, low-probability (HILP) events, which is\nonly possible when such events are considered during the planning stage. This\npaper proposes a two-stage stochastic planning model where the generation\ndispatch, line hardening, line capacity expansion, and distributed generation\nsizing and siting decisions are proactively decided to minimize the overall\nload shed and its risk for extreme weather scenarios, where the risk is modeled\nusing conditional value-at-risk. To alleviate computational complexity without\nsacrificing solution quality, a representative scenario sampling method is\nused. Finally, the overall framework is tested on a standard IEEE reliability\ntest system to evaluate the effectiveness of the proposed approach. Several\nplanning portfolios are presented that can help system planners identify\ntrade-offs between system resilience, planning budget, and risk aversion.",
            "author": [
                "Abodh Poudyal",
                "Shishir Lamichhane",
                "Anamika Dubey",
                "Josue Campos do Prado"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15117v1",
                "http://arxiv.org/pdf/2311.15117v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15114v1",
            "title": "Studies of the Inhomogeneous Cosmology in Higher Dimensional space-time\n  with a Cosmological Constant",
            "updated": "2023-11-25T20:38:25Z",
            "published": "2023-11-25T20:38:25Z",
            "summary": "We have studied the inhomogeneous cosmology in Kaluza-Klein spacetime with\npositive cosmological constant. Depending on the integration constant we have\nderived two types of solutions. The dimensional reduction is possible of extra\ndimensional scale factor depending on the curvature of the metric for positive\ncosmological constant for all solutions. The high value of entropy in present\nobservable universe and the possible matter leakage in $4D$ world due to\nreduction of extra dimension are also discussed. Our solutions show that early\ndeceleration and late accelerating nature of the universe. Findings are\nverified by the wellknown Raychaudhuri equation.",
            "author": [
                "D. Panigrahi",
                "S. Chatterjee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15114v1",
                "http://arxiv.org/pdf/2311.15114v1"
            ],
            "primary_category": "gr-qc",
            "category": [
                "gr-qc",
                "astro-ph.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15110v1",
            "title": "Relevance feedback strategies for recall-oriented neural information\n  retrieval",
            "updated": "2023-11-25T19:50:41Z",
            "published": "2023-11-25T19:50:41Z",
            "summary": "In a number of information retrieval applications (e.g., patent search,\nliterature review, due diligence, etc.), preventing false negatives is more\nimportant than preventing false positives. However, approaches designed to\nreduce review effort (like \"technology assisted review\") can create false\nnegatives, since they are often based on active learning systems that exclude\ndocuments automatically based on user feedback. Therefore, this research\nproposes a more recall-oriented approach to reducing review effort. More\nspecifically, through iteratively re-ranking the relevance rankings based on\nuser feedback, which is also referred to as relevance feedback. In our proposed\nmethod, the relevance rankings are produced by a BERT-based dense-vector search\nand the relevance feedback is based on cumulatively summing the queried and\nselected embeddings. Our results show that this method can reduce review effort\nbetween 17.85% and 59.04%, compared to a baseline approach (of no feedback),\ngiven a fixed recall target",
            "author": [
                "Timo Kats",
                "Peter van der Putten",
                "Jan Scholtes"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15110v1",
                "http://arxiv.org/pdf/2311.15110v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15108v1",
            "title": "Leveraging Diffusion Perturbations for Measuring Fairness in Computer\n  Vision",
            "updated": "2023-11-25T19:40:13Z",
            "published": "2023-11-25T19:40:13Z",
            "summary": "Computer vision models have been known to encode harmful biases, leading to\nthe potentially unfair treatment of historically marginalized groups, such as\npeople of color. However, there remains a lack of datasets balanced along\ndemographic traits that can be used to evaluate the downstream fairness of\nthese models. In this work, we demonstrate that diffusion models can be\nleveraged to create such a dataset. We first use a diffusion model to generate\na large set of images depicting various occupations. Subsequently, each image\nis edited using inpainting to generate multiple variants, where each variant\nrefers to a different perceived race. Using this dataset, we benchmark several\nvision-language models on a multi-class occupation classification task. We find\nthat images generated with non-Caucasian labels have a significantly higher\noccupation misclassification rate than images generated with Caucasian labels,\nand that several misclassifications are suggestive of racial biases. We measure\na model's downstream fairness by computing the standard deviation in the\nprobability of predicting the true occupation label across the different\nperceived identity groups. Using this fairness metric, we find significant\ndisparities between the evaluated vision-and-language models. We hope that our\nwork demonstrates the potential value of diffusion methods for fairness\nevaluations.",
            "author": [
                "Nicholas Lui",
                "Bryan Chia",
                "William Berrios",
                "Candace Ross",
                "Douwe Kiela"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15108v1",
                "http://arxiv.org/pdf/2311.15108v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15106v1",
            "title": "Solving the Right Problem is Key for Translational NLP: A Case Study in\n  UMLS Vocabulary Insertion",
            "updated": "2023-11-25T19:35:53Z",
            "published": "2023-11-25T19:35:53Z",
            "summary": "As the immense opportunities enabled by large language models become more\napparent, NLP systems will be increasingly expected to excel in real-world\nsettings. However, in many instances, powerful models alone will not yield\ntranslational NLP solutions, especially if the formulated problem is not well\naligned with the real-world task. In this work, we study the case of UMLS\nvocabulary insertion, an important real-world task in which hundreds of\nthousands of new terms, referred to as atoms, are added to the UMLS, one of the\nmost comprehensive open-source biomedical knowledge bases. Previous work aimed\nto develop an automated NLP system to make this time-consuming, costly, and\nerror-prone task more efficient. Nevertheless, practical progress in this\ndirection has been difficult to achieve due to a problem formulation and\nevaluation gap between research output and the real-world task. In order to\naddress this gap, we introduce a new formulation for UMLS vocabulary insertion\nwhich mirrors the real-world task, datasets which faithfully represent it and\nseveral strong baselines we developed through re-purposing existing solutions.\nAdditionally, we propose an effective rule-enhanced biomedical language model\nwhich enables important new model behavior, outperforms all strong baselines\nand provides measurable qualitative improvements to editors who carry out the\nUVI task. We hope this case study provides insight into the considerable\nimportance of problem formulation for the success of translational NLP\nsolutions.",
            "author": [
                "Bernal Jimenez Gutierrez",
                "Yuqing Mao",
                "Vinh Nguyen",
                "Kin Wah Fung",
                "Yu Su",
                "Olivier Bodenreider"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15106v1",
                "http://arxiv.org/pdf/2311.15106v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15105v1",
            "title": "Relative mixed multiplicities and mixed Buchsbaum-Rim multiplicities",
            "updated": "2023-11-25T19:30:44Z",
            "published": "2023-11-25T19:30:44Z",
            "summary": "We define and study the natural multigraded extension of the relative\nmultiplicities introduced by Simis, Ulrich and Vasconcelos. We call these new\ninvariants relative mixed multiplicities. We show that they have a stable value\nequal to the mixed Buchsbaum-Rim multiplicity of Kleiman and Thorup.\nFurthermore, we prove that integral dependence and birationality can be\ndetected via the vanishing of relative mixed multiplicities.",
            "author": [
                "Yairon Cid-Ruiz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15105v1",
                "http://arxiv.org/pdf/2311.15105v1"
            ],
            "primary_category": "math.AC",
            "category": [
                "math.AC",
                "math.AG",
                "13H15, 14C17, 13D40, 13A30, 13B22"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15097v1",
            "title": "AugmentTRAJ: A framework for point-based trajectory data augmentation",
            "updated": "2023-11-25T18:54:38Z",
            "published": "2023-11-25T18:54:38Z",
            "summary": "Data augmentation has emerged as a powerful technique in machine learning,\nstrengthening model robustness while mitigating overfitting and under-fitting\nissues by generating diverse synthetic data. Nevertheless, despite its success\nin other domains, data augmentation's potential remains largely untapped in\nmobility data analysis, primarily due to the intricate nature and unique format\nof trajectory data. Additionally, there is a lack of frameworks capable of\npoint-wise data augmentation, which can reliably generate synthetic\ntrajectories while preserving the inherent characteristics of the original\ndata. To address these challenges, this research introduces AugmenTRAJ, an\nopen-source Python3 framework designed explicitly for trajectory data\naugmentation. AugmenTRAJ offers a reliable and well-controlled approach for\ngenerating synthetic trajectories, thereby enabling the harnessing of data\naugmentation benefits in mobility analysis. This thesis presents a\ncomprehensive overview of the methodologies employed in developing AugmenTRAJ\nand showcases the various data augmentation techniques available within the\nframework. AugmenTRAJ opens new possibilities for enhancing mobility data\nanalysis models' performance and generalization capabilities by providing\nresearchers with a practical and versatile tool for augmenting trajectory data,\nIts user-friendly implementation in Python3 facilitates easy integration into\nexisting workflows, offering the community an accessible resource to leverage\nthe full potential of data augmentation in trajectory-based applications.",
            "author": [
                "Yaksh J Haranwala"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15097v1",
                "http://arxiv.org/pdf/2311.15097v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16185v1",
            "title": "Enhancing Sentiment Analysis Results through Outlier Detection\n  Optimization",
            "updated": "2023-11-25T18:20:43Z",
            "published": "2023-11-25T18:20:43Z",
            "summary": "When dealing with text data containing subjective labels like speaker\nemotions, inaccuracies or discrepancies among labelers are not uncommon. Such\ndiscrepancies can significantly affect the performance of machine learning\nalgorithms. This study investigates the potential of identifying and addressing\noutliers in text data with subjective labels, aiming to enhance classification\noutcomes. We utilized the Deep SVDD algorithm, a one-class classification\nmethod, to detect outliers in nine text-based emotion and sentiment analysis\ndatasets. By employing both a small-sized language model (DistilBERT base model\nwith 66 million parameters) and non-deep learning machine learning algorithms\n(decision tree, KNN, Logistic Regression, and LDA) as the classifier, our\nfindings suggest that the removal of outliers can lead to enhanced results in\nmost cases. Additionally, as outliers in such datasets are not necessarily\nunlearnable, we experienced utilizing a large language model -- DeBERTa v3\nlarge with 131 million parameters, which can capture very complex patterns in\ndata. We continued to observe performance enhancements across multiple\ndatasets.",
            "author": [
                "Yuetian Chen",
                "Mei Si"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16185v1",
                "http://arxiv.org/pdf/2311.16185v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15090v1",
            "title": "Fine-Grained Unsupervised Cross-Modality Domain Adaptation for\n  Vestibular Schwannoma Segmentation",
            "updated": "2023-11-25T18:08:59Z",
            "published": "2023-11-25T18:08:59Z",
            "summary": "The domain adaptation approach has gained significant acceptance in\ntransferring styles across various vendors and centers, along with filling the\ngaps in modalities. However, multi-center application faces the challenge of\nthe difficulty of domain adaptation due to their intra-domain differences. We\nfocus on introducing a fine-grained unsupervised framework for domain\nadaptation to facilitate cross-modality segmentation of vestibular schwannoma\n(VS) and cochlea. We propose to use a vector to control the generator to\nsynthesize a fake image with given features. And then, we can apply various\naugmentations to the dataset by searching the feature dictionary. The diversity\naugmentation can increase the performance and robustness of the segmentation\nmodel. On the CrossMoDA validation phase Leaderboard, our method received a\nmean Dice score of 0.765 and 0.836 on VS and cochlea, respectively.",
            "author": [
                "Luyi Han",
                "Tao Tan",
                "Ritse Mann"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15090v1",
                "http://arxiv.org/pdf/2311.15090v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15085v3",
            "title": "Corrections to Landau Fermi-liquid fixed-point approximation in\n  nonlinear bosonized theory: Application to $g_A^L$ in nuclei",
            "updated": "2023-11-29T17:25:55Z",
            "published": "2023-11-25T17:28:40Z",
            "summary": "We calculated in nonlinear bosonized theory $1/\\bar{N}$ corrections to the\nLandau Fermi-liquid fixed-point (FLFP) axial-vector coupling constant in\nnuclear matter $g_A^L\\approx 1$ to which the Landau parameter $F_1^\\omega$\npredominantly contributes. We obtain the correction to $F_1^\\omega$ to\ncalculate the correction $\\delta g_A^L$ to the axial-vector coupling constant\n$g_A^L$ at the nuclear saturation density. It comes out to be extremely small,\n$\\delta g_A^L\\sim O(10^{-4})$. We discuss how the \"dilaton-limit fixed-point\n(DLFP)\" result $g_A=1$ can be preserved from finite nuclei to high densities\nrelevant to massive neutron stars and its possible impact on $0\\nu\\beta\\beta$\ndecay processes involved in going beyond the Standard Model.",
            "author": [
                "Long-Qi Shao",
                "Mannque Rho"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15085v3",
                "http://arxiv.org/pdf/2311.15085v3"
            ],
            "primary_category": "nucl-th",
            "category": [
                "nucl-th",
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15084v1",
            "title": "Minimal Specialization: Coevolution of Network Structure and Dynamics",
            "updated": "2023-11-25T17:28:14Z",
            "published": "2023-11-25T17:28:14Z",
            "summary": "The changing topology of a network is driven by the need to maintain or\noptimize network function. As this function is often related to moving\nquantities such as traffic, information, etc. efficiently through the network\nthe structure of the network and the dynamics on the network directly depend on\nthe other. To model this interplay of network structure and dynamics we use the\ndynamics on the network, or the dynamical processes the network models, to\ninfluence the dynamics of the network structure, i.e., to determine where and\nwhen to modify the network structure. We model the dynamics on the network\nusing Jackson network dynamics and the dynamics of the network structure using\nminimal specialization, a variant of the more general network growth model\nknown as specialization. The resulting model, which we refer to as the\nintegrated specialization model, coevolves both the structure and the dynamics\nof the network. We show this model produces networks with real-world\nproperties, such as right-skewed degree distributions, sparsity, the\nsmall-world property, and non-trivial equitable partitions. Additionally, when\ncompared to other growth models, the integrated specialization model creates\nnetworks with small diameter, minimizing distances across the network. Along\nwith producing these structural features, this model also sequentially removes\nthe network's largest bottlenecks. The result are networks that have both\ndynamic and structural features that allow quantities to more efficiently move\nthrough the network.",
            "author": [
                "Annika King",
                "Dallas Smith",
                "Benjamin Webb"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15084v1",
                "http://arxiv.org/pdf/2311.15084v1"
            ],
            "primary_category": "physics.soc-ph",
            "category": [
                "physics.soc-ph",
                "math.DS",
                "90B10"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15082v3",
            "title": "Learning graph-Fourier spectra of textured surface images for defect\n  localization",
            "updated": "2023-12-02T03:33:56Z",
            "published": "2023-11-25T17:25:07Z",
            "summary": "In the realm of industrial manufacturing, product inspection remains a\nsignificant bottleneck, with only a small fraction of manufactured items\nundergoing inspection for surface defects. Advances in imaging systems and AI\ncan allow automated full inspection of manufactured surfaces. However, even the\nmost contemporary imaging and machine learning methods perform poorly for\ndetecting defects in images with highly textured backgrounds, that stem from\ndiverse manufacturing processes. This paper introduces an approach based on\ngraph Fourier analysis to automatically identify defective images, as well as\ncrucial graph Fourier coefficients that inform the defects in images amidst\nhighly textured backgrounds. The approach capitalizes on the ability of graph\nrepresentations to capture the complex dynamics inherent in high-dimensional\ndata, preserving crucial locality properties in a lower dimensional space. A\nconvolutional neural network model (1D-CNN) was trained with the coefficients\nof the graph Fourier transform of the images as the input to identify, with\nclassification accuracy of 99.4%, if the image contains a defect. An\nexplainable AI method using SHAP (SHapley Additive exPlanations) was used to\nfurther analyze the trained 1D-CNN model to discern important spectral\ncoefficients for each image. This approach sheds light on the crucial\ncontribution of low-frequency graph eigen waveforms to precisely localize\nsurface defects in images, thereby advancing the realization of zero-defect\nmanufacturing.",
            "author": [
                "Tapan Ganatma Nakkina",
                "Adithyaa Karthikeyan",
                "Yuhao Zhong",
                "Ceyhun Eksin",
                "Satish T. S. Bukkapatnam"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15082v3",
                "http://arxiv.org/pdf/2311.15082v3"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15080v1",
            "title": "Weakly-Supervised Audio-Visual Segmentation",
            "updated": "2023-11-25T17:18:35Z",
            "published": "2023-11-25T17:18:35Z",
            "summary": "Audio-visual segmentation is a challenging task that aims to predict\npixel-level masks for sound sources in a video. Previous work applied a\ncomprehensive manually designed architecture with countless pixel-wise accurate\nmasks as supervision. However, these pixel-level masks are expensive and not\navailable in all cases. In this work, we aim to simplify the supervision as the\ninstance-level annotation, i.e., weakly-supervised audio-visual segmentation.\nWe present a novel Weakly-Supervised Audio-Visual Segmentation framework,\nnamely WS-AVS, that can learn multi-scale audio-visual alignment with\nmulti-scale multiple-instance contrastive learning for audio-visual\nsegmentation. Extensive experiments on AVSBench demonstrate the effectiveness\nof our WS-AVS in the weakly-supervised audio-visual segmentation of\nsingle-source and multi-source scenarios.",
            "author": [
                "Shentong Mo",
                "Bhiksha Raj"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15080v1",
                "http://arxiv.org/pdf/2311.15080v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG",
                "cs.MM",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15077v1",
            "title": "Multilingual self-supervised speech representations improve the speech\n  recognition of low-resource African languages with codeswitching",
            "updated": "2023-11-25T17:05:21Z",
            "published": "2023-11-25T17:05:21Z",
            "summary": "While many speakers of low-resource languages regularly code-switch between\ntheir languages and other regional languages or English, datasets of\ncodeswitched speech are too small to train bespoke acoustic models from scratch\nor do language model rescoring. Here we propose finetuning self-supervised\nspeech representations such as wav2vec 2.0 XLSR to recognize code-switched\ndata. We find that finetuning self-supervised multilingual representations and\naugmenting them with n-gram language models trained from transcripts reduces\nabsolute word error rates by up to 20% compared to baselines of hybrid models\ntrained from scratch on code-switched data. Our findings suggest that in\ncircumstances with limited training data finetuning self-supervised\nrepresentations is a better performing and viable solution.",
            "author": [
                "Tol\u00falop\u00e9 \u00d2g\u00fanr\u00e8m\u00ed",
                "Christopher D. Manning",
                "Dan Jurafsky"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15077v1",
                "http://arxiv.org/pdf/2311.15077v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15075v1",
            "title": "Mug-STAN: Adapting Image-Language Pretrained Models for General Video\n  Understanding",
            "updated": "2023-11-25T17:01:38Z",
            "published": "2023-11-25T17:01:38Z",
            "summary": "Large-scale image-language pretrained models, e.g., CLIP, have demonstrated\nremarkable proficiency in acquiring general multi-modal knowledge through\nweb-scale image-text data. Despite the impressive performance of image-language\nmodels on various image tasks, how to effectively expand them on general video\nunderstanding remains an area of ongoing exploration. In this paper, we\ninvestigate the image-to-video transferring from the perspective of the model\nand the data, unveiling two key obstacles impeding the adaptation of\nimage-language models: non-generalizable temporal modeling and partially\nmisaligned video-text data. To address these challenges, we propose\nSpatial-Temporal Auxiliary Network with Mutual-guided alignment module\n(Mug-STAN), a simple yet effective framework extending image-text model to\ndiverse video tasks and video-text data.Specifically, STAN adopts a branch\nstructure with decomposed spatial-temporal modules to enable generalizable\ntemporal modeling, while Mug suppresses misalignment by introducing token-wise\nfeature aggregation of either modality from the other. Extensive experimental\nresults verify Mug-STAN significantly improves adaptation of language-image\npretrained models such as CLIP and CoCa at both video-text post-pretraining and\nfinetuning stages. With our solution, state-of-the-art zero-shot and finetuning\nresults on various downstream datasets, including MSR-VTT, DiDeMo, LSMDC,\nKinetics-400, Something-Something-2, HMDB-51, UCF- 101, and AVA, are achieved.\nMoreover, by integrating pretrained Mug-STAN with the emerging multimodal\ndialogue model, we can realize zero-shot video chatting. Codes are available at\nhttps://github.com/farewellthree/STAN",
            "author": [
                "Ruyang Liu",
                "Jingjia Huang",
                "Wei Gao",
                "Thomas H. Li",
                "Ge Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15075v1",
                "http://arxiv.org/pdf/2311.15075v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15074v1",
            "title": "Upconversion of infrared light by graphitic micro-particles due to\n  photo-induced structural modification",
            "updated": "2023-11-25T16:59:01Z",
            "published": "2023-11-25T16:59:01Z",
            "summary": "Recent reports of upconversion and white light emission from graphitic\nparticles warrant an explanation of the physics behind the process. We offer a\nmodel, wherein the upconversion is facilitated by photo-induced electronic\nstructure modification allowing for multi-photon processes. As per the\nprediction of the model, we experimentally show that graphite upconverts\ninfrared light centered around 1.31~$\\mu$m to broadband white light centered\naround 0.85 $\\mu$m. Our results suggest that upconversion from shortwave\ninfrared ($\\sim$3~$\\mu$m) to visible region may be possible. Our experiments\nshow that the population dynamics of the electronic states involved in this\nupconversion process occur in the timescale of milliseconds.",
            "author": [
                "Rohin Sharma",
                "Nishma Bhattarai",
                "Rijan Maharjan",
                "Lilia M. Woods",
                "Nirajan Ojha",
                "Ashim Dhakal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15074v1",
                "http://arxiv.org/pdf/2311.15074v1"
            ],
            "primary_category": "physics.optics",
            "category": [
                "physics.optics",
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15069v1",
            "title": "Multiuser Beamforming for Partially-Connected Millimeter Wave Massive\n  MIMO",
            "updated": "2023-11-25T16:41:54Z",
            "published": "2023-11-25T16:41:54Z",
            "summary": "Multiuser beamforming is considered for partially-connected millimeter wave\nmassive MIMO systems. Based on perfect channel state information (CSI), a\nlow-complexity hybrid beamforming scheme that decouples the analog beamformer\nand the digital beamformer is proposed to maximize the sum-rate. The analog\nbeamformer design is modeled as a phase alignment problem to harvest the array\ngain. Given the analog beamformer, the digital beamformer is designed by\nsolving a weighted minimum mean squared error problem. Then based on imperfect\nCSI, an analog-only beamformer design scheme is proposed, where the design\nproblem aims at maximizing the desired signal power on the current user and\nminimizing the power on the other users to mitigate the multiuser interference.\nThe original problem is then transformed into a series of independent beam\nnulling subproblems, where an efficient iterative algorithm using the\nmajorization-minimization framework is proposed to solve the subproblems.\nSimulation results show that, under perfect CSI, the proposed scheme achieves\nalmost the same sum-rate performance as the existing schemes but with lower\ncomputational complexity; and under imperfect CSI, the proposed analog-only\nbeamforming design scheme can effectively mitigate the multiuser interference.",
            "author": [
                "Chenhao Qi",
                "Jinlin Hu",
                "Yang Du",
                "Arumugam Nallanathan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15069v1",
                "http://arxiv.org/pdf/2311.15069v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15066v1",
            "title": "Beam Training and Tracking for Extremely Large-Scale MIMO Communications",
            "updated": "2023-11-25T16:25:28Z",
            "published": "2023-11-25T16:25:28Z",
            "summary": "In this paper, beam training and beam tracking are investigated for extremely\nlarge-scale multiple-input-multiple-output communication systems with\npartially-connected hybrid combining structures. Firstly, we propose a\ntwo-stage hybrid-field beam training scheme for both the near field and the far\nfield. In the first stage, each subarray independently uses multiple far-field\nchannel steering vectors to approximate near-field ones for analog combining.\nTo find the codeword best fitting for the channel, digital combiners in the\nsecond stage are designed to combine the outputs of the analog combiners from\nthe first stage. Then, based on the principle of stationary phase and the\ntime-frequency duality, the expressions of subarray signals after analog\ncombining are analytically derived and a beam refinement based on phase shifts\nof subarrays~(BRPSS) scheme with closed-form solutions is proposed for\nhigh-resolution channel parameter estimation. Moreover, a low-complexity\nnear-field beam tracking scheme is developed, where the kinematic model is\nadopted to characterize the channel variations and the extended Kalman filter\nis exploited for beam tracking. Simulation results verify the effectiveness of\nthe proposed schemes.",
            "author": [
                "Kangjian Chen",
                "Chenhao Qi",
                "Cheng-Xiang Wang",
                "Geoffrey Ye Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15066v1",
                "http://arxiv.org/pdf/2311.15066v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15062v1",
            "title": "Simultaneous Beam Training and Target Sensing in ISAC Systems with RIS",
            "updated": "2023-11-25T16:06:33Z",
            "published": "2023-11-25T16:06:33Z",
            "summary": "This paper investigates an integrated sensing and communication (ISAC) system\nwith reconfigurable intelligent surface (RIS). Our simultaneous beam training\nand target sensing (SBTTS) scheme enables the base station to perform beam\ntraining with the user terminals (UTs) and the RIS, and simultaneously to sense\nthe targets. Based on our findings, the energy of the echoes from the RIS is\naccumulated in the angle-delay domain while that from the targets is\naccumulated in the Doppler-delay domain. The SBTTS scheme can distinguish the\nRIS from the targets with the mixed echoes from the RIS and the targets. Then\nwe propose a positioning and array orientation estimation (PAOE) scheme for\nboth the line-of-sight channels and the non-line-of-sight channels based on the\nbeam training results of SBTTS by developing a low-complexity two-dimensional\nfast search algorithm. Based on the SBTTS and PAOE schemes, we further compute\nthe angle-of-arrival and angle-of-departure for the channels between the RIS\nand the UTs by exploiting the geometry relationship to accomplish the beam\nalignment of the ISAC system. Simulation results verify the effectiveness of\nthe proposed schemes.",
            "author": [
                "Kangjian Chen",
                "Chenhao Qi",
                "Octavia A. Dobre",
                "Geoffrey Ye Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15062v1",
                "http://arxiv.org/pdf/2311.15062v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15061v1",
            "title": "SenseAI: Real-Time Inpainting for Electron Microscopy",
            "updated": "2023-11-25T16:01:29Z",
            "published": "2023-11-25T16:01:29Z",
            "summary": "Despite their proven success and broad applicability to Electron Microscopy\n(EM) data, joint dictionary-learning and sparse-coding based inpainting\nalgorithms have so far remained impractical for real-time usage with an\nElectron Microscope. For many EM applications, the reconstruction time for a\nsingle frame is orders of magnitude longer than the data acquisition time,\nmaking it impossible to perform exclusively subsampled acquisition. This\nlimitation has led to the development of SenseAI, a C++/CUDA library capable of\nextremely efficient dictionary-based inpainting. SenseAI provides N-dimensional\ndictionary learning, live reconstructions, dictionary transfer and\nvisualization, as well as real-time plotting of statistics, parameters, and\nimage quality metrics.",
            "author": [
                "Jack Wells",
                "Amirafshar Moshtaghpour",
                "Daniel Nicholls",
                "Alex W. Robinson",
                "Yalin Zheng",
                "Jony Castagna",
                "Nigel D. Browning"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15061v1",
                "http://arxiv.org/pdf/2311.15061v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15060v1",
            "title": "Key Issues in Wireless Transmission for NTN-Assisted Internet of Things",
            "updated": "2023-11-25T15:55:33Z",
            "published": "2023-11-25T15:55:33Z",
            "summary": "Non-terrestrial networks (NTNs) have become appealing resolutions for\nseamless coverage in the next-generation wireless transmission, where a large\nnumber of Internet of Things (IoT) devices diversely distributed can be\nefficiently served. The explosively growing number of IoT devices brings a new\nchallenge for massive connection. The long-distance wireless signal propagation\nin NTNs leads to severe path loss and large latency, where the accurate\nacquisition of channel state information (CSI) is another challenge, especially\nfor fast-moving non-terrestrial base stations (NTBSs). Moreover, the scarcity\nof on-board resources of NTBSs is also a challenge for resource allocation. To\nthis end, we investigate three key issues, where the existing schemes and\nemerging resolutions for these three key issues have been comprehensively\npresented. The first issue is to enable the massive connection by designing\nrandom access to establish the wireless link and multiple access to transmit\ndata streams. The second issue is to accurately acquire CSI in various channel\nconditions by channel estimation and beam training, where orthogonal time\nfrequency space modulation and dynamic codebooks are on focus. The third issue\nis to efficiently allocate the wireless resources, including power allocation,\nspectrum sharing, beam hopping, and beamforming. At the end of this article,\nsome future research topics are identified.",
            "author": [
                "Chenhao Qi",
                "Jing Wang",
                "Leyi Lyu",
                "Lei Tan",
                "Jinming Zhang",
                "Geoffrey Ye Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15060v1",
                "http://arxiv.org/pdf/2311.15060v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15059v1",
            "title": "Beyond the aggregated paradigm: phenology and structure in mutualistic\n  networks",
            "updated": "2023-11-25T15:49:36Z",
            "published": "2023-11-25T15:49:36Z",
            "summary": "Mutualistic interactions, where species interact to obtain mutual benefits,\nconstitute an essential component of natural ecosystems. The use of ecological\nnetworks to represent the species and their ecological interactions allows the\nstudy of structural and dynamic patterns common to different ecosystems.\nHowever, by neglecting the temporal dimension of mutualistic communities,\nrelevant insights into the organization and functioning of natural ecosystems\ncan be lost. Therefore, it is crucial to incorporate empirical phenology -- the\ncycles of species' activity within a season -- to fully understand the effects\nof temporal variability on network architecture. In this paper, by using two\nempirical datasets together with a set of synthetic models, we propose a\nframework to characterize phenology on ecological networks and assess the\neffect of temporal variability. Analyses reveal that non-trivial information is\nmissed when portraying the network of interactions as static, which leads to\noverestimating the value of fundamental structural features. We discuss the\nimplications of our findings for mutualistic relationships and intra-guild\ncompetition for common resources. We show that recorded interactions and\nspecies' activity duration are pivotal factors in accurately replicating\nobserved patterns within mutualistic communities. Furthermore, our exploration\nof synthetic models underscores the system-specific character of the mechanisms\ndriving phenology, increasing our understanding of the complexities of natural\necosystems.",
            "author": [
                "Cl\u00e0udia Payrat\u00f3-Borr\u00e0s",
                "Carlos Gracia-L\u00e1zaro",
                "Laura Hern\u00e1ndez",
                "Yamir Moreno"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15059v1",
                "http://arxiv.org/pdf/2311.15059v1"
            ],
            "primary_category": "q-bio.PE",
            "category": [
                "q-bio.PE",
                "physics.soc-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15055v1",
            "title": "Automatically Finding and Categorizing Replication Studies",
            "updated": "2023-11-25T15:27:10Z",
            "published": "2023-11-25T15:27:10Z",
            "summary": "In many fields of experimental science, papers that failed to replicate\ncontinue to be cited as a result of the poor discoverability of replication\nstudies. As a first step to creating a system that automatically finds\nreplication studies for a given paper, 334 replication studies and 344\nreplicated studies were collected. Replication studies could be identified in\nthe dataset based on text content at a higher rate than chance (AUROC = 0.886).\n  Additionally, successful replication studies could be distinguished from\nfailed replication studies at a higher rate than chance (AUROC = 0.664).",
            "author": [
                "Bob de Ruiter"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15055v1",
                "http://arxiv.org/pdf/2311.15055v1"
            ],
            "primary_category": "cs.DL",
            "category": [
                "cs.DL",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15054v1",
            "title": "Detection of developmental language disorder in Cypriot Greek children\n  using a machine learning neural network algorithm",
            "updated": "2023-11-25T15:23:46Z",
            "published": "2023-11-25T15:23:46Z",
            "summary": "Children with developmental language disorder (DLD) encounter difficulties in\nacquiring various language structures. Early identification and intervention\nare crucial to prevent negative long-term outcomes impacting the academic,\nsocial, and emotional development of children. The study aims to develop an\nautomated method for the identification of DLD using artificial intelligence,\nspecifically a neural network machine learning algorithm. This protocol is\napplied for the first time in Cypriot Greek children, which is generally\nconsidered underresearched in the context of DLD. The neural network model was\ntrained using perceptual and production data elicited from children with DLD\nand healthy controls. The k-fold technique was used to crossvalidate the\nalgorithm. The performance of the model was evaluated using metrics such as\naccuracy, precision, recall, F1 score, and ROC/AUC curve to assess its ability\nto make accurate predictions on a set of unseen data. The results demonstrated\nhigh classification values for all metrics (between 0.92 and 0.98), indicating\nthe high accuracy of the neural model in classifying children with DLD.\nAdditionally, the variable importance analysis revealed that the language\nproduction skills of children had a more significant impact on the performance\nof the model compared to perception skills. Neural networks represent powerful\ntools for detecting DLD, providing early and quick assessments of the disorder,\nand having the potential to improve clinical outcomes.",
            "author": [
                "Georgios P. Georgiou",
                "Elena Theodorou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15054v1",
                "http://arxiv.org/pdf/2311.15054v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15050v1",
            "title": "Super Winds and Radio Emission in X-ray Binary Systems",
            "updated": "2023-11-25T15:07:54Z",
            "published": "2023-11-25T15:07:54Z",
            "summary": "We have recently proposed that supercritical colliding wind binaries (SCWBs)\nare suitable scenarios for particle acceleration and nonthermal radiation. In\nthese X-ray binary systems (XRBs), the wind from the companion star collides\nwith the wind ejected from the super-Eddington accretion disk of the stellar\nblack hole. Strong shocks are generated in this collision, leading to the\nacceleration of particles and subsequent broadband emission through different\nnonthermal radiative processes. In particular, we estimate luminosities of the\norder of $L\\approx 10^{34}\\,{\\rm erg\\,s^{-1}}$ in the radio band. One of the\nmajor components in these processes is the power provided by the super wind\nexpelled from the disk. Furthermore, some properties of the wind photosphere,\nsuch as its geometry or its temperature distribution, also contribute to the\nabsorption and reprocessing of the nonthermal radiation. In this work, we\nperform a more detailed description of the powerful wind launched from the\naccretion disk, in order to obtain a better understanding of the\nabove-mentioned processes.",
            "author": [
                "L. Abaroa",
                "G. E. Romero"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15050v1",
                "http://arxiv.org/pdf/2311.15050v1"
            ],
            "primary_category": "astro-ph.HE",
            "category": [
                "astro-ph.HE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15047v1",
            "title": "Training a Hopfield Variational Autoencoder with Equilibrium Propagation",
            "updated": "2023-11-25T14:50:37Z",
            "published": "2023-11-25T14:50:37Z",
            "summary": "On dedicated analog hardware, equilibrium propagation is an energy-efficient\nalternative to backpropagation. In spite of its theoretical guarantees, its\napplication in the AI domain remains limited to the discriminative setting.\nMeanwhile, despite its high computational demands, generative AI is on the\nrise. In this paper, we demonstrate the application of Equilibrium Propagation\nin training a variational autoencoder (VAE) for generative modeling. Leveraging\nthe symmetric nature of Hopfield networks, we propose using a single model to\nserve as both the encoder and decoder which could effectively halve the\nrequired chip size for VAE implementations, paving the way for more efficient\nanalog hardware configurations.",
            "author": [
                "Tom Van Der Meersch",
                "Johannes Deleu",
                "Thomas Demeester"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15047v1",
                "http://arxiv.org/pdf/2311.15047v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15041v1",
            "title": "MPCNN: A Novel Matrix Profile Approach for CNN-based Sleep Apnea\n  Classification",
            "updated": "2023-11-25T14:39:12Z",
            "published": "2023-11-25T14:39:12Z",
            "summary": "Sleep apnea (SA) is a significant respiratory condition that poses a major\nglobal health challenge. Previous studies have investigated several machine and\ndeep learning models for electrocardiogram (ECG)-based SA diagnoses. Despite\nthese advancements, conventional feature extractions derived from ECG signals,\nsuch as R-peaks and RR intervals, may fail to capture crucial information\nencompassed within the complete PQRST segments. In this study, we propose an\ninnovative approach to address this diagnostic gap by delving deeper into the\ncomprehensive segments of the ECG signal. The proposed methodology draws\ninspiration from Matrix Profile algorithms, which generate an Euclidean\ndistance profile from fixed-length signal subsequences. From this, we derived\nthe Min Distance Profile (MinDP), Max Distance Profile (MaxDP), and Mean\nDistance Profile (MeanDP) based on the minimum, maximum, and mean of the\nprofile distances, respectively. To validate the effectiveness of our approach,\nwe use the modified LeNet-5 architecture as the primary CNN model, along with\ntwo existing lightweight models, BAFNet and SE-MSCNN, for ECG classification\ntasks. Our extensive experimental results on the PhysioNet Apnea-ECG dataset\nrevealed that with the new feature extraction method, we achieved a per-segment\naccuracy up to 92.11 \\% and a per-recording accuracy of 100\\%. Moreover, it\nyielded the highest correlation compared to state-of-the-art methods, with a\ncorrelation coefficient of 0.989. By introducing a new feature extraction\nmethod based on distance relationships, we enhanced the performance of certain\nlightweight models, showing potential for home sleep apnea test (HSAT) and SA\ndetection in IoT devices. The source code for this work is made publicly\navailable in GitHub: https://github.com/vinuni-vishc/MPCNN-Sleep-Apnea.",
            "author": [
                "Hieu X. Nguyen",
                "Duong V. Nguyen",
                "Hieu H. Pham",
                "Cuong D. Do"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15041v1",
                "http://arxiv.org/pdf/2311.15041v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15038v1",
            "title": "Low-latency Visual Previews of Large Synchrotron Micro-CT Datasets",
            "updated": "2023-11-25T14:24:55Z",
            "published": "2023-11-25T14:24:55Z",
            "summary": "The unprecedented rate at which synchrotron radiation facilities are\nproducing micro-computed (micro-CT) datasets has resulted in an overwhelming\namount of data that scientists struggle to browse and interact with in\nreal-time. Thousands of arthropods are scanned into micro-CT within the NOVA\nproject, producing a large collection of gigabyte-sized datasets. In this work,\nwe present methods to reduce the size of this data, scaling it from gigabytes\nto megabytes, enabling the micro-CT dataset to be delivered in real-time. In\naddition, arthropods can be identified by scientists even after implementing\ndata reduction methodologies. Our initial step is to devise three distinct\nvisual previews that comply with the best practices of data exploration.\nSubsequently, each visual preview warrants its own design consideration,\nthereby necessitating an individual data processing pipeline for each. We aim\nto present data reduction algorithms applied across the data processing\npipelines. Particularly, we reduce size by using the multi-resolution\nslicemaps, the server-side rendering, and the histogram filtering approaches.\nIn the evaluation, we examine the disparities of each method to identify the\nmost favorable arrangement for our operation, which can then be adjusted for\nother experiments that have comparable necessities. Our demonstration proved\nthat reducing the dataset size to the megabyte range is achievable without\ncompromising the arthropod's geometry information.",
            "author": [
                "Nicholas Tan Jerome",
                "Suren Chilingaryan",
                "Thomas van de Kamp",
                "Andreas Kopmann"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15038v1",
                "http://arxiv.org/pdf/2311.15038v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16515v1",
            "title": "Word for Person: Zero-shot Composed Person Retrieval",
            "updated": "2023-11-25T14:24:49Z",
            "published": "2023-11-25T14:24:49Z",
            "summary": "Searching for specific person has great security value and social benefits,\nand it often involves a combination of visual and textual information.\nConventional person retrieval methods, whether image-based or text-based,\nusually fall short in effectively harnessing both types of information, leading\nto the loss of accuracy. In this paper, a whole new task called Composed Person\nRetrieval (CPR) is proposed to jointly utilize both image and text information\nfor target person retrieval. However, the supervised CPR must depend on very\ncostly manual annotation dataset, while there are currently no available\nresources. To mitigate this issue, we firstly introduce the Zero-shot Composed\nPerson Retrieval (ZS-CPR), which leverages existing domain-related data to\nresolve the CPR problem without reliance on expensive annotations. Secondly, to\nlearn ZS-CPR model, we propose a two-stage learning framework, Word4Per, where\na lightweight Textual Inversion Network (TINet) and a text-based person\nretrieval model based on fine-tuned Contrastive Language-Image Pre-training\n(CLIP) network are learned without utilizing any CPR data. Thirdly, a finely\nannotated Image-Text Composed Person Retrieval dataset (ITCPR) is built as the\nbenchmark to assess the performance of the proposed Word4Per framework.\nExtensive experiments under both Rank-1 and mAP demonstrate the effectiveness\nof Word4Per for the ZS-CPR task, surpassing the comparative methods by over\n10%. The code and ITCPR dataset will be publicly available at\nhttps://github.com/Delong-liu-bupt/Word4Per.",
            "author": [
                "Delong Liu",
                "Haiwen Li",
                "Zhicheng Zhao",
                "Fei Su",
                "Hongying Meng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16515v1",
                "http://arxiv.org/pdf/2311.16515v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15032v1",
            "title": "nlpBDpatriots at BLP-2023 Task 2: A Transfer Learning Approach to Bangla\n  Sentiment Analysis",
            "updated": "2023-11-25T13:58:58Z",
            "published": "2023-11-25T13:58:58Z",
            "summary": "In this paper, we discuss the nlpBDpatriots entry to the shared task on\nSentiment Analysis of Bangla Social Media Posts organized at the first workshop\non Bangla Language Processing (BLP) co-located with EMNLP. The main objective\nof this task is to identify the polarity of social media content using a Bangla\ndataset annotated with positive, neutral, and negative labels provided by the\nshared task organizers. Our best system for this task is a transfer learning\napproach with data augmentation which achieved a micro F1 score of 0.71. Our\nbest system ranked 12th among 30 teams that participated in the competition.",
            "author": [
                "Dhiman Goswami",
                "Md Nishat Raihan",
                "Sadiya Sayara Chowdhury Puspo",
                "Marcos Zampieri"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15032v1",
                "http://arxiv.org/pdf/2311.15032v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15030v1",
            "title": "Learning Task-adaptive Quasi-stiffness Control for A Powered\n  Transfemoral Prosthesis",
            "updated": "2023-11-25T13:51:14Z",
            "published": "2023-11-25T13:51:14Z",
            "summary": "While significant advancements have been made in the mechanical and\ntask-specific controller designs of powered transfemoral prostheses, developing\na task-adaptive control framework that generalizes across various locomotion\nmodes and terrain conditions remains an open problem. This study proposes a\ntask-adaptive learning quasi-stiffness control framework for powered prostheses\nthat generalizes across tasks, including the torque-angle relationship\nreconstruction part and the quasi-stiffness controller design part.\nQuasi-stiffness is defined as the slope of the human joint's torque-angle\nrelationship. To accurately obtain the torque-angle relationship in a new task,\na Gaussian Process Regression (GPR) model is introduced to predict the target\nfeatures of the human joint's angle and torque in the task. Then a Kernelized\nMovement Primitives (KMP) is employed to reconstruct the torque-angle\nrelationship of a new task from multiple human demonstrations and estimated\ntarget features. Based on the torque-angle relationship of the new task, a\nquasi-stiffness control approach is designed for a powered prosthesis. Finally,\nthe proposed framework is validated through practical examples, including\nvarying speed and incline walking tasks. The proposed framework has the\npotential to expand to variable walking tasks in daily life for the\ntransfemoral amputees.",
            "author": [
                "Teng Ma",
                "Shucong Yin",
                "Zhimin Hou",
                "Binxin Huang",
                "Chuheng Chen",
                "Haoyong Yu",
                "Chenglong Fu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15030v1",
                "http://arxiv.org/pdf/2311.15030v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15029v1",
            "title": "nlpBDpatriots at BLP-2023 Task 1: A Two-Step Classification for Violence\n  Inciting Text Detection in Bangla",
            "updated": "2023-11-25T13:47:34Z",
            "published": "2023-11-25T13:47:34Z",
            "summary": "In this paper, we discuss the nlpBDpatriots entry to the shared task on\nViolence Inciting Text Detection (VITD) organized as part of the first workshop\non Bangla Language Processing (BLP) co-located with EMNLP. The aim of this task\nis to identify and classify the violent threats, that provoke further unlawful\nviolent acts. Our best-performing approach for the task is two-step\nclassification using back translation and multilinguality which ranked 6th out\nof 27 teams with a macro F1 score of 0.74.",
            "author": [
                "Md Nishat Raihan",
                "Dhiman Goswami",
                "Sadiya Sayara Chowdhury Puspo",
                "Marcos Zampieri"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15029v1",
                "http://arxiv.org/pdf/2311.15029v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15027v1",
            "title": "Double-Flow-based Steganography without Embedding for Image-to-Image\n  Hiding",
            "updated": "2023-11-25T13:44:37Z",
            "published": "2023-11-25T13:44:37Z",
            "summary": "As an emerging concept, steganography without embedding (SWE) hides a secret\nmessage without directly embedding it into a cover. Thus, SWE has the unique\nadvantage of being immune to typical steganalysis methods and can better\nprotect the secret message from being exposed. However, existing SWE methods\nare generally criticized for their poor payload capacity and low fidelity of\nrecovered secret messages. In this paper, we propose a novel\nsteganography-without-embedding technique, named DF-SWE, which addresses the\naforementioned drawbacks and produces diverse and natural stego images.\nSpecifically, DF-SWE employs a reversible circulation of double flow to build a\nreversible bijective transformation between the secret image and the generated\nstego image. Hence, it provides a way to directly generate stego images from\nsecret images without a cover image. Besides leveraging the invertible\nproperty, DF-SWE can invert a secret image from a generated stego image in a\nnearly lossless manner and increases the fidelity of extracted secret images.\nTo the best of our knowledge, DF-SWE is the first SWE method that can hide\nlarge images and multiple images into one image with the same size,\nsignificantly enhancing the payload capacity. According to the experimental\nresults, the payload capacity of DF-SWE achieves 24-72 BPP is 8000-16000 times\ncompared to its competitors while producing diverse images to minimize the\nexposure risk. Importantly, DF-SWE can be applied in the steganography of\nsecret images in various domains without requiring training data from the\ncorresponding domains. This domain-agnostic property suggests that DF-SWE can\n1) be applied to hiding private data and 2) be deployed in resource-limited\nsystems.",
            "author": [
                "Bingbing Song",
                "Derui Wang",
                "Tianwei Zhang",
                "Renyang Liu",
                "Yu Lin",
                "Wei Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15027v1",
                "http://arxiv.org/pdf/2311.15027v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16184v1",
            "title": "Impact of overlapping signals on parameterized post-Newtonian\n  coefficients in tests of gravity",
            "updated": "2023-11-25T13:43:09Z",
            "published": "2023-11-25T13:43:09Z",
            "summary": "Gravitational waves have been instrumental in providing deep insights into\nthe nature of gravity. Next-generation detectors, such as the Einstein\nTelescope, are predicted to have a higher detection rate given the increased\nsensitivity and lower cut-off frequency. However, this increased sensitivity\nraises challenges concerning parameter estimation due to the foreseeable\noverlap of signals from multiple sources. Overlapping signals (OSs), if not\nproperly identified, may introduce biases in estimating post-Newtonian (PN)\ncoefficients in parameterized tests of general relativity (GR). We investigate\nhow OSs affect $-1$PN to 2PN terms in parameterized GR tests, examining their\npotential to falsely suggest GR deviations. We estimate the prevalence of such\nmisleading signals in next-generation detectors, and their collective influence\non GR tests. We compare the effects of OSs on coefficients at different PN\norders, concluding that overall the 1PN coefficient suffers the most. Our\nfindings also reveal that while a non-negligible portion of OSs exhibit biases\nin PN coefficients that might individually prefer to conclude deviations from\nGR, collectively, the direction to deviate is random and a statistical\ncombination will still be in favor of GR.",
            "author": [
                "Yixuan Dang",
                "Ziming Wang",
                "Dicong Liang",
                "Lijing Shao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16184v1",
                "http://arxiv.org/pdf/2311.16184v1"
            ],
            "primary_category": "astro-ph.IM",
            "category": [
                "astro-ph.IM",
                "gr-qc"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15026v1",
            "title": "Impact craters formed by spinning granular projectiles",
            "updated": "2023-11-25T13:36:57Z",
            "published": "2023-11-25T13:36:57Z",
            "summary": "Craters formed by the impact of agglomerated materials are commonly observed\nin nature, such as asteroids colliding with planets and moons. In this paper,\nwe investigate how the projectile spin and cohesion lead to different crater\nshapes. For that, we carried out DEM (discrete element method) computations of\nspinning granular projectiles impacting onto cohesionless grains, for different\nbonding stresses, initial spins and initial heights. We found that, as the\nbonding stresses decrease and the initial spin increases, the projectile's\ngrains spread farther from the collision point, and, in consequence, the crater\nshape becomes flatter, with peaks around the rim and in the center of craters.\nOur results shed light on the dispersion of the projectile's material and the\ndifferent shapes of craters found on Earth and other planetary environments.",
            "author": [
                "Douglas Daniel de Carvalho",
                "Nicolao Cerqueira Lima",
                "Erick de Moraes Franklin"
            ],
            "link": [
                "http://dx.doi.org/10.1103/PhysRevE.108.054904",
                "http://arxiv.org/abs/2311.15026v1",
                "http://arxiv.org/pdf/2311.15026v1"
            ],
            "primary_category": "astro-ph.EP",
            "category": [
                "astro-ph.EP",
                "physics.geo-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15023v1",
            "title": "Offensive Language Identification in Transliterated and Code-Mixed\n  Bangla",
            "updated": "2023-11-25T13:27:22Z",
            "published": "2023-11-25T13:27:22Z",
            "summary": "Identifying offensive content in social media is vital for creating safe\nonline communities. Several recent studies have addressed this problem by\ncreating datasets for various languages. In this paper, we explore offensive\nlanguage identification in texts with transliterations and code-mixing,\nlinguistic phenomena common in multilingual societies, and a known challenge\nfor NLP systems. We introduce TB-OLID, a transliterated Bangla offensive\nlanguage dataset containing 5,000 manually annotated comments. We train and\nfine-tune machine learning models on TB-OLID, and we evaluate their results on\nthis dataset. Our results show that English pre-trained transformer-based\nmodels, such as fBERT and HateBERT achieve the best performance on this\ndataset.",
            "author": [
                "Md Nishat Raihan",
                "Umma Hani Tanmoy",
                "Anika Binte Islam",
                "Kai North",
                "Tharindu Ranasinghe",
                "Antonios Anastasopoulos",
                "Marcos Zampieri"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15023v1",
                "http://arxiv.org/pdf/2311.15023v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15021v1",
            "title": "The Imprimitivity Fell Bundle",
            "updated": "2023-11-25T13:23:59Z",
            "published": "2023-11-25T13:23:59Z",
            "summary": "Given a full right-Hilbert C*-module $\\mathbf{X}$ over a C*-algebra $A$, the\nset $\\mathbb{K}_{A}(\\mathbf{X})$ of $A$-compact operators on $\\mathbf{X}$ is\nthe (up to isomorphism) unique C*-algebra that is strongly Morita equivalent to\nthe coefficient algebra $A$ via $\\mathbf{X}$. As bimodule,\n$\\mathbb{K}_{A}(\\mathbf{X})$ can also be thought of as the balanced tensor\nproduct $\\mathbf{X}\\otimes_{A} \\mathbf{X}^{\\mathrm{op}}$, and so the latter\nnaturally becomes a C*-algebra. We generalize both of these facts to the world\nof Fell bundles over groupoids: Suppose $\\mathscr{B}$ is a Fell bundle over a\ngroupoid $\\mathcal{H}$ and $\\mathscr{M}$ an upper semi-continuous Banach bundle\nover a principal right $\\mathcal{H}$-space $X$. If $\\mathscr{M}$ carries a\nright-action of $\\mathscr{B}$ and a sufficiently nice $\\mathscr{B}$-valued\ninner product, then its imprimitivity Fell bundle\n$\\mathbb{K}_{\\mathscr{B}}(\\mathscr{M})=\\mathscr{M}\\otimes_{\\mathscr{B}}\n\\mathscr{M}^{\\mathrm{op}}$ is a Fell bundle over the imprimitivity groupoid of\n$X$, and it is the unique Fell bundle that is equivalent to $\\mathscr{B}$ via\n$\\mathscr{M}$. We show that $\\mathbb{K}_{\\mathscr{B}}(\\mathscr{M})$ generalizes\nthe 'higher order' compact operators of Abadie and Ferraro in the case of\nsaturated bundles over groups, and that the theorem recovers results such as\nKumjian's Stabilization trick.",
            "author": [
                "Anna Duwenig"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15021v1",
                "http://arxiv.org/pdf/2311.15021v1"
            ],
            "primary_category": "math.OA",
            "category": [
                "math.OA",
                "46L55, 46L05, 22A22"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15020v1",
            "title": "Careful Synchronization of One-Cluster Automata",
            "updated": "2023-11-25T13:23:44Z",
            "published": "2023-11-25T13:23:44Z",
            "summary": "In this paper we investigate careful synchronization of one-cluster partial\nautomata. First we prove that in general case the shortest carefully\nsynchronizing word for such automata is of length $2^\\frac{n}{2} + 1$, where\n$n$ is the number of states of an automaton. Additionally we prove that\nchecking whether a given one-cluster partial automaton is carefully\nsynchronizing is NP-hard even in the case of binary alphabet.",
            "author": [
                "Jakub Ruszil"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15020v1",
                "http://arxiv.org/pdf/2311.15020v1"
            ],
            "primary_category": "cs.FL",
            "category": [
                "cs.FL",
                "cs.CC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15016v1",
            "title": "E-CORE: Emotion Correlation Enhanced Empathetic Dialogue Generation",
            "updated": "2023-11-25T12:47:39Z",
            "published": "2023-11-25T12:47:39Z",
            "summary": "Achieving empathy is a crucial step toward humanized dialogue systems.\nCurrent approaches for empathetic dialogue generation mainly perceive an\nemotional label to generate an empathetic response conditioned on it, which\nsimply treat emotions independently, but ignore the intrinsic emotion\ncorrelation in dialogues, resulting in inaccurate emotion perception and\nunsuitable response generation. In this paper, we propose a novel emotion\ncorrelation enhanced empathetic dialogue generation framework, which\ncomprehensively realizes emotion correlation learning, utilization, and\nsupervising. Specifically, a multi-resolution emotion graph is devised to\ncapture context-based emotion interactions from different resolutions, further\nmodeling emotion correlation. Then we propose an emotion correlation enhanced\ndecoder, with a novel correlation-aware aggregation and soft/hard strategy,\nrespectively improving the emotion perception and response generation.\nExperimental results on the benchmark dataset demonstrate the superiority of\nour model in both empathetic perception and expression.",
            "author": [
                "Fengyi Fu",
                "Lei Zhang",
                "Quan Wang",
                "Zhendong Mao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15016v1",
                "http://arxiv.org/pdf/2311.15016v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15010v2",
            "title": "Adapter is All You Need for Tuning Visual Tasks",
            "updated": "2023-11-30T14:57:30Z",
            "published": "2023-11-25T12:33:54Z",
            "summary": "Pre-training & fine-tuning can enhance the transferring efficiency and\nperformance in visual tasks. Recent delta-tuning methods provide more options\nfor visual classification tasks. Despite their success, existing visual\ndelta-tuning art fails to exceed the upper limit of full fine-tuning on\nchallenging tasks like instance segmentation and semantic segmentation. To find\na competitive alternative to full fine-tuning, we propose the Multi-cognitive\nVisual Adapter (Mona) tuning, a novel adapter-based tuning method. First, we\nintroduce multiple vision-friendly filters into the adapter to enhance its\nability to process visual signals, while previous methods mainly rely on\nlanguage-friendly linear filters. Second, we add the scaled normalization layer\nin the adapter to regulate the distribution of input features for visual\nfilters. To fully demonstrate the practicality and generality of Mona, we\nconduct experiments on multiple representative visual tasks, including instance\nsegmentation on COCO, semantic segmentation on ADE20K, object detection on\nPascal VOC, and image classification on several common datasets. Exciting\nresults illustrate that Mona surpasses full fine-tuning on all these tasks and\nis the only delta-tuning method outperforming full fine-tuning on instance\nsegmentation and semantic segmentation tasks. For example, Mona achieves a 1%\nperformance gain on the COCO dataset compared to full fine-tuning.\nComprehensive results suggest that Mona-tuning is more suitable for retaining\nand utilizing the capabilities of pre-trained models than full fine-tuning. The\ncode will be released at https://github.com/Leiyi-Hu/mona.",
            "author": [
                "Dongshuo Yin",
                "Leiyi Hu",
                "Bin Li",
                "Youqun Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15010v2",
                "http://arxiv.org/pdf/2311.15010v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15007v1",
            "title": "Guiding principles for the design of a chemical vapor deposition process\n  for highly crystalline transition metal dichalcogenides",
            "updated": "2023-11-25T12:23:47Z",
            "published": "2023-11-25T12:23:47Z",
            "summary": "Two-dimensional transition metal dichalcogenides (TMDs) for advanced logic\ntransistor technologies are deposited by various modifications of the chemical\nvapor deposition (CVD) method using a wide variety of precursors. Being a major\nelectrical performance limiter, the TMD crystal grain size strongly differs\nbetween the various CVD precursor chemistries from nano- to millimeter-sized\ncrystals. However, it remains unclear how the CVD precursor chemistry affects\nthe nucleation density and resulting TMD crystal grain size. This work\npostulates guiding principles to design a CVD process for highly crystalline\nTMD deposition using a quantitative analytical model benchmarked against\nliterature. The TMD nucleation density reduces favorably under low\nsupersaturation conditions, where the metal precursor sorption on the starting\nsurface is reversible and the corresponding metal precursor desorption rate\nexceeds the overall deposition rate. Such reversible precursor adsorption\nguarantees efficient long-range gas-phase lateral diffusion of precursor\nspecies in addition to short-range surface diffusion, which vitally increases\ncrystal grain size. As such, the proposed model explains the large spread in\nexperimentally observed TMD nucleation densities and crystal grain sizes for\nstate-of-the-art CVD chemistries. Ultimately, it empowers the reader to\ninterpret and modulate precursor adsorption and diffusion reactions through\ndesigning CVD precursor chemistries compatible with temperature sensitive\napplication schemes.",
            "author": [
                "Vladislav Voronenkov",
                "Benjamin Groven",
                "Henry Medina Silva",
                "Pierre Morin",
                "Stefan De Gendt"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15007v1",
                "http://arxiv.org/pdf/2311.15007v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15006v1",
            "title": "A Survey Examining Neuromorphic Architecture in Space and Challenges\n  from Radiation",
            "updated": "2023-11-25T12:21:40Z",
            "published": "2023-11-25T12:21:40Z",
            "summary": "Inspired by the human brain's structure and function, neuromorphic computing\nhas emerged as a promising approach for developing energy-efficient and\npowerful computing systems. Neuromorphic computing offers significant\nprocessing speed and power consumption advantages in aerospace applications.\nThese two factors are crucial for real-time data analysis and decision-making.\nHowever, the harsh space environment, particularly with the presence of\nradiation, poses significant challenges to the reliability and performance of\nthese computing systems. This paper comprehensively surveys the integration of\nradiation-resistant neuromorphic computing systems in aerospace applications.\nWe explore the challenges posed by space radiation, review existing solutions\nand developments, present case studies of neuromorphic computing systems used\nin space applications, discuss future directions, and discuss the potential\nbenefits of this technology in future space missions.",
            "author": [
                "Jonathan Naoukin",
                "Murat Isik",
                "Karn Tiwari"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15006v1",
                "http://arxiv.org/pdf/2311.15006v1"
            ],
            "primary_category": "cs.ET",
            "category": [
                "cs.ET"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15005v1",
            "title": "Spectrum Sharing between UAV-based Wireless Mesh Networks and Ground\n  Networks",
            "updated": "2023-11-25T12:04:33Z",
            "published": "2023-11-25T12:04:33Z",
            "summary": "The unmanned aerial vehicle (UAV)-based wireless mesh networks can\neconomically provide wireless services for the areas with disasters. However,\nthe capacity of air-to-air communications is limited due to the multi-hop\ntransmissions. In this paper, the spectrum sharing between UAV-based wireless\nmesh networks and ground networks is studied to improve the capacity of the UAV\nnetworks. Considering the distribution of UAVs as a three-dimensional (3D)\nhomogeneous Poisson point process (PPP) within a vertical range, the stochastic\ngeometry is applied to analyze the impact of the height of UAVs, the transmit\npower of UAVs, the density of UAVs and the vertical range, etc., on the\ncoverage probability of ground network user and UAV network user, respectively.\nThe optimal height of UAVs is numerically achieved in maximizing the capacity\nof UAV networks with the constraint of the coverage probability of ground\nnetwork user. This paper provides a basic guideline for the deployment of\nUAV-based wireless mesh networks.",
            "author": [
                "Zhiqing Wei",
                "Zijun Guo",
                "Zhiyong Feng",
                "Jialin Zhu",
                "Caijun Zhong",
                "Qihui Wu",
                "Huici Wu"
            ],
            "link": [
                "http://dx.doi.org/10.1109/WCSP.2018.8555855",
                "http://arxiv.org/abs/2311.15005v1",
                "http://arxiv.org/pdf/2311.15005v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.NA",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15003v1",
            "title": "Enumerating Error Bounded Polytime Algorithms Through Arithmetical\n  Theories",
            "updated": "2023-11-25T11:44:47Z",
            "published": "2023-11-25T11:44:47Z",
            "summary": "We consider a minimal extension of the language of arithmetic, such that the\nbounded formulas provably total in a suitably-defined theory \\`a la Buss\n(expressed in this new language) precisely capture polytime random functions.\nThen, we provide two new characterizations of the semantic class BPP obtained\nby internalizing the error-bound check within a logical system: the first\nrelies on measure-sensitive quantifiers, while the second is based on standard\nfirst-order quantification. This leads us to introduce a family of effectively\nenumerable subclasses of BPP, called BPP_T and consisting of languages captured\nby those probabilistic Turing machines whose underlying error can be proved\nbounded in the theory T. As a paradigmatic example of this approach, we\nestablish that polynomial identity testing is in BPP_T where\nT=$\\mathrm{I}\\Delta_0+\\mathrm{Exp}$ is a well-studied theory based on bounded\ninduction.",
            "author": [
                "Melissa Antonelli",
                "Ugo Dal Lago",
                "Davide Davoli",
                "Isabel Oitavem",
                "Paolo Pistone"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15003v1",
                "http://arxiv.org/pdf/2311.15003v1"
            ],
            "primary_category": "cs.LO",
            "category": [
                "cs.LO",
                "math.LO",
                "F.4.1; F.1.3"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14998v1",
            "title": "On the integration of Ito equations with a random or a W-symmetry",
            "updated": "2023-11-25T11:04:48Z",
            "published": "2023-11-25T11:04:48Z",
            "summary": "Symmetries can be used to integrate scalar Ito equation -- or reduce systems\nof such equations -- by the Kozlov substitution, i.e. passing to symmetry\nadapted coordinates. While the theory is well established for so called\ndeterministic standard symmetries (the class originally studied by Kozlov),\nsome points need clarification for so called random standard symmetries and\nW-symmetries. This paper is devoted to such clarification; in particular we\nnote that the theory naturally calls, for these classes of symmetries, to also\nconsider generalized Ito equations; and that while Kozlov theory is extended\nsubstantially unharmed for random standard symmetries, W-symmetries should be\nhandled with great care, and cannot be used towards integration of stochastic\nequations, albeit they have different uses.",
            "author": [
                "Giuseppe Gaeta"
            ],
            "link": [
                "http://dx.doi.org/10.1063/5.0141333",
                "http://arxiv.org/abs/2311.14998v1",
                "http://arxiv.org/pdf/2311.14998v1"
            ],
            "primary_category": "math-ph",
            "category": [
                "math-ph",
                "math.MP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16491v1",
            "title": "$Z^*$: Zero-shot Style Transfer via Attention Rearrangement",
            "updated": "2023-11-25T11:03:43Z",
            "published": "2023-11-25T11:03:43Z",
            "summary": "Despite the remarkable progress in image style transfer, formulating style in\nthe context of art is inherently subjective and challenging. In contrast to\nexisting learning/tuning methods, this study shows that vanilla diffusion\nmodels can directly extract style information and seamlessly integrate the\ngenerative prior into the content image without retraining. Specifically, we\nadopt dual denoising paths to represent content/style references in latent\nspace and then guide the content image denoising process with style latent\ncodes. We further reveal that the cross-attention mechanism in latent diffusion\nmodels tends to blend the content and style images, resulting in stylized\noutputs that deviate from the original content image. To overcome this\nlimitation, we introduce a cross-attention rearrangement strategy. Through\ntheoretical analysis and experiments, we demonstrate the effectiveness and\nsuperiority of the diffusion-based $\\underline{Z}$ero-shot $\\underline{S}$tyle\n$\\underline{T}$ransfer via $\\underline{A}$ttention $\\underline{R}$earrangement,\nZ-STAR.",
            "author": [
                "Yingying Deng",
                "Xiangyu He",
                "Fan Tang",
                "Weiming Dong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16491v1",
                "http://arxiv.org/pdf/2311.16491v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14995v1",
            "title": "Gohberg-Semencul Estimation of Toeplitz Structured Covariance Matrices\n  and Their Inverses",
            "updated": "2023-11-25T10:46:21Z",
            "published": "2023-11-25T10:46:21Z",
            "summary": "When only few data samples are accessible, utilizing structural prior\nknowledge is essential for estimating covariance matrices and their inverses.\nOne prominent example is knowing the covariance matrix to be Toeplitz\nstructured, which occurs when dealing with wide sense stationary (WSS)\nprocesses. This work introduces a novel class of positive definiteness ensuring\nlikelihood-based estimators for Toeplitz structured covariance matrices (CMs)\nand their inverses. In order to accomplish this, we derive positive\ndefiniteness enforcing constraint sets for the Gohberg-Semencul (GS)\nparameterization of inverse symmetric Toeplitz matrices. Motivated by the\nrelationship between the GS parameterization and autoregressive (AR) processes,\nwe propose hyperparameter tuning techniques, which enable our estimators to\ncombine advantages from state-of-the-art likelihood and non-parametric\nestimators. Moreover, we present a computationally cheap closed-form estimator,\nwhich is derived by maximizing an approximate likelihood. Due to the ensured\npositive definiteness, our estimators perform well for both the estimation of\nthe CM and the inverse covariance matrix (ICM). Extensive simulation results\nvalidate the proposed estimators' efficacy for several standard Toeplitz\nstructured CMs commonly employed in a wide range of applications.",
            "author": [
                "Benedikt B\u00f6ck",
                "Dominik Semmler",
                "Benedikt Fesl",
                "Michael Baur",
                "Wolfgang Utschick"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14995v1",
                "http://arxiv.org/pdf/2311.14995v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14994v1",
            "title": "Exploring Causal Learning through Graph Neural Networks: An In-depth\n  Review",
            "updated": "2023-11-25T10:46:06Z",
            "published": "2023-11-25T10:46:06Z",
            "summary": "In machine learning, exploring data correlations to predict outcomes is a\nfundamental task. Recognizing causal relationships embedded within data is\npivotal for a comprehensive understanding of system dynamics, the significance\nof which is paramount in data-driven decision-making processes. Beyond\ntraditional methods, there has been a surge in the use of graph neural networks\n(GNNs) for causal learning, given their capabilities as universal data\napproximators. Thus, a thorough review of the advancements in causal learning\nusing GNNs is both relevant and timely. To structure this review, we introduce\na novel taxonomy that encompasses various state-of-the-art GNN methods employed\nin studying causality. GNNs are further categorized based on their applications\nin the causality domain. We further provide an exhaustive compilation of\ndatasets integral to causal learning with GNNs to serve as a resource for\npractical study. This review also touches upon the application of causal\nlearning across diverse sectors. We conclude the review with insights into\npotential challenges and promising avenues for future exploration in this\nrapidly evolving field of machine learning.",
            "author": [
                "Simi Job",
                "Xiaohui Tao",
                "Taotao Cai",
                "Haoran Xie",
                "Lin Li",
                "Jianming Yong",
                "Qing Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14994v1",
                "http://arxiv.org/pdf/2311.14994v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14990v1",
            "title": "View it like a radiologist: Shifted windows for deep learning\n  augmentation of CT images",
            "updated": "2023-11-25T10:28:08Z",
            "published": "2023-11-25T10:28:08Z",
            "summary": "Deep learning has the potential to revolutionize medical practice by\nautomating and performing important tasks like detecting and delineating the\nsize and locations of cancers in medical images. However, most deep learning\nmodels rely on augmentation techniques that treat medical images as natural\nimages. For contrast-enhanced Computed Tomography (CT) images in particular,\nthe signals producing the voxel intensities have physical meaning, which is\nlost during preprocessing and augmentation when treating such images as natural\nimages. To address this, we propose a novel preprocessing and intensity\naugmentation scheme inspired by how radiologists leverage multiple viewing\nwindows when evaluating CT images. Our proposed method, window shifting,\nrandomly places the viewing windows around the region of interest during\ntraining. This approach improves liver lesion segmentation performance and\nrobustness on images with poorly timed contrast agent. Our method outperforms\nclassical intensity augmentations as well as the intensity augmentation\npipeline of the popular nn-UNet on multiple datasets.",
            "author": [
                "Eirik A. \u00d8stmo",
                "Kristoffer K. Wickstr\u00f8m",
                "Keyur Radiya",
                "Michael C. Kampffmeyer",
                "Robert Jenssen"
            ],
            "link": [
                "http://dx.doi.org/10.1109/MLSP55844.2023.10285978",
                "http://arxiv.org/abs/2311.14990v1",
                "http://arxiv.org/pdf/2311.14990v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14988v1",
            "title": "The Performance Analysis of Spectrum Sharing between UAV enabled\n  Wireless Mesh Networks and Ground Networks",
            "updated": "2023-11-25T10:18:36Z",
            "published": "2023-11-25T10:18:36Z",
            "summary": "Unmanned aerial vehicle (UAV) has the advantages of large coverage and\nflexibility, which could be applied in disaster management to provide wireless\nservices to the rescuers and victims. When UAVs forms an aerial mesh network,\nline-of-sight (LoS) air-to-air (A2A) communications have long transmission\ndistance, which extends the coverage of multiple UAVs. However, the capacity of\nUAV is constrained due to the multiple hop transmissions in aerial mesh\nnetworks. In this paper, spectrum sharing between UAV enabled wireless mesh\nnetworks and ground networks is studied to improve the capacity of UAV\nnetworks. Considering two-dimensional (2D) and three-dimensional (3D)\nhomogeneous Poisson point process (PPP) modeling for the distribution of UAVs\nwithin a vertical range {\\Delta}h, stochastic geometry is applied to analyze\nthe impact of the height of UAVs, the transmit power of UAVs, the density of\nUAVs and the vertical range, etc., on the coverage probability of ground\nnetwork user and UAV network user. Besides, performance improvement of spectrum\nsharing with directional antenna is verified. With the object function of\nmaximizing the transmission capacity, the optimal altitude of UAVs is obtained.\nThis paper provides a theoretical guideline for the spectrum sharing of UAV\nenabled wireless mesh networks, which may contribute significant value to the\nstudy of spectrum sharing mechanisms for UAV enabled wireless mesh networks.",
            "author": [
                "Zhiqing Wei",
                "Jialin Zhu",
                "Zijun Guo",
                "Fan Ning"
            ],
            "link": [
                "http://dx.doi.org/10.1109/JSEN.2020.3038774",
                "http://arxiv.org/abs/2311.14988v1",
                "http://arxiv.org/pdf/2311.14988v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.PF"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14987v1",
            "title": "Reconstruction of a Long-term spatially Contiguous Solar-Induced\n  Fluorescence (LCSIF) over 1982-2022",
            "updated": "2023-11-25T10:15:40Z",
            "published": "2023-11-25T10:15:40Z",
            "summary": "Satellite-observed solar-induced chlorophyll fluorescence (SIF) is a powerful\nproxy for diagnosing the photosynthetic characteristics of terrestrial\necosystems. Despite the increasing spatial and temporal resolutions of these\nsatellite retrievals, records of SIF are primarily limited to the recent\ndecade, impeding their application in detecting long-term dynamics of ecosystem\nfunction and structure. In this study, we leverage the two surface reflectance\nbands (red and near-infrared) available both from Advanced Very High-Resolution\nRadiometer (AVHRR, 1982-2022) and MODerate-resolution Imaging Spectroradiometer\n(MODIS, 2001-2022). Importantly, we calibrate and orbit-correct the AVHRR bands\nagainst their MODIS counterparts during their overlapping period. Using the\nlong-term bias-corrected reflectance data, a neural network is then built to\nreproduce the Orbiting Carbon Observatory-2 SIF using AVHRR and MODIS, and used\nto map SIF globally over the entire 1982-2022 period. Compared with the\nprevious MODIS-based CSIF product relying on four reflectance bands, our\ntwo-band-based product has similar skill but can be advantageously extended to\nthe bias-corrected AVHRR period. Further comparison with three widely used\nvegetation indices (NDVI, kNDVI, NIRv; all based empirically on red and\nnear-infrared bands) shows a higher or comparable correlation of LCSIF with\nsatellite SIF and site-level GPP estimates across vegetation types, ensuring a\ngreater capacity of LCSIF for representing terrestrial photosynthesis.\nGlobally, LCSIF-AVHRR shows an accelerating upward trend since 1982, with an\naverage rate of 0.0025 mW m-2 nm-1 sr-1 per decade during 1982-2000 and 0.0038\nmW m-2 nm-1 sr-1 per decade during 2001-2022. Our LCSIF data provide\nopportunities to better understand the long-term dynamics of ecosystem\nphotosynthesis and their underlying driving processes.",
            "author": [
                "Jianing Fang",
                "Xu Lian",
                "Youngryel Ryu",
                "Sungchan Jeong",
                "Chongya Jiang",
                "Pierre Gentine"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14987v1",
                "http://arxiv.org/pdf/2311.14987v1"
            ],
            "primary_category": "physics.geo-ph",
            "category": [
                "physics.geo-ph",
                "astro-ph.IM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14983v1",
            "title": "Neural Network Based Approach to Recognition of Meteor Tracks in the\n  Mini-EUSO Telescope Data",
            "updated": "2023-11-25T10:00:49Z",
            "published": "2023-11-25T10:00:49Z",
            "summary": "Mini-EUSO is a wide-angle fluorescence telescope that registers ultraviolet\n(UV) radiation in the nocturnal atmosphere of Earth from the International\nSpace Station. Meteors are among multiple phenomena that manifest themselves\nnot only in the visible range but also in the UV. We present two simple\nartificial neural networks that allow for recognizing meteor signals in the\nMini-EUSO data with high accuracy in terms of a binary classification problem.\nWe expect that similar architectures can be effectively used for signal\nrecognition in other fluorescence telescopes, regardless of the nature of the\nsignal. Due to their simplicity, the networks can be implemented in onboard\nelectronics of future orbital or balloon experiments.",
            "author": [
                "Mikhail Zotov",
                "Dmitry Anzhiganov",
                "Aleksandr Kryazhenkov",
                "Dario Barghini",
                "Matteo Battisti",
                "Alexander Belov",
                "Mario Bertaina",
                "Marta Bianciotto",
                "Francesca Bisconti",
                "Carl Blaksley",
                "Sylvie Blin",
                "Giorgio Cambi\u00e8",
                "Francesca Capel",
                "Marco Casolino",
                "Toshikazu Ebisuzaki",
                "Johannes Eser",
                "Francesco Fenu",
                "Massimo Alberto Franceschi",
                "Alessio Golzio",
                "Philippe Gorodetzky",
                "Fumiyoshi Kajino",
                "Hiroshi Kasuga",
                "Pavel Klimov",
                "Massimiliano Manfrin",
                "Laura Marcelli",
                "Hiroko Miyamoto",
                "Alexey Murashov",
                "Tommaso Napolitano",
                "Hiroshi Ohmori",
                "Angela Olinto",
                "Etienne Parizot",
                "Piergiorgio Picozza",
                "Lech Wiktor Piotrowski",
                "Zbigniew Plebaniak",
                "Guillaume Pr\u00e9v\u00f4t",
                "Enzo Reali",
                "Marco Ricci",
                "Giulia Romoli",
                "Naoto Sakaki",
                "Kenji Shinozaki",
                "Christophe De La Taille",
                "Yoshiyuki Takizawa",
                "Michal Vr\u00e1bel",
                "Lawrence Wiencke"
            ],
            "link": [
                "http://dx.doi.org/10.3390/a16090448",
                "http://arxiv.org/abs/2311.14983v1",
                "http://arxiv.org/pdf/2311.14983v1"
            ],
            "primary_category": "astro-ph.IM",
            "category": [
                "astro-ph.IM",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14982v1",
            "title": "Active Queue Management with Data-Driven Delay Violation Probability\n  Predictors",
            "updated": "2023-11-25T10:00:10Z",
            "published": "2023-11-25T10:00:10Z",
            "summary": "The increasing demand for latency-sensitive applications has necessitated the\ndevelopment of sophisticated algorithms that efficiently manage packets with\nend-to-end delay targets traversing the networked infrastructure. Network\ncomponents must consider minimizing the packets' end-to-end delay violation\nprobabilities (DVP) as a guiding principle throughout the transmission path to\nensure timely deliveries. Active queue management (AQM) schemes are commonly\nused to mitigate congestion by dropping packets and controlling queuing delay.\nToday's established AQM schemes are threshold-driven, identifying congestion\nand trigger packet dropping using a predefined criteria which is unaware of\npackets' DVPs. In this work, we propose a novel framework, Delta, that combines\nend-to-end delay characterization with AQM for minimizing DVP. In a queuing\ntheoretic environment, we show that such a policy is feasible by utilizing a\ndata-driven approach to predict the queued packets' DVPs. That enables Delta\nAQM to effectively handle links with arbitrary stationary service time\nprocesses. The implementation is described in detail, and its performance is\nevaluated and compared with state of the art AQM algorithms. Our results show\nthe Delta outperforms current AQM schemes substantially, in particular in\nscenarios where high reliability, i.e. high quantiles of the tail latency\ndistribution, are of interest.",
            "author": [
                "Samie Mostafavi",
                "Neelabhro Roy",
                "Gy\u00f6rgy D\u00e1n",
                "James Gross"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14982v1",
                "http://arxiv.org/pdf/2311.14982v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14981v1",
            "title": "Multi-task Planar Reconstruction with Feature Warping Guidance",
            "updated": "2023-11-25T09:53:42Z",
            "published": "2023-11-25T09:53:42Z",
            "summary": "Piece-wise planar 3D reconstruction simultaneously segments plane instances\nand recovers their 3D plane parameters from an image, which is particularly\nuseful for indoor or man-made environments. Efficient reconstruction of 3D\nplanes coupled with semantic predictions offers advantages for a wide range of\napplications requiring scene understanding and concurrent spatial mapping.\nHowever, most existing planar reconstruction models either neglect semantic\npredictions or do not run efficiently enough for real-time applications. We\nintroduce SoloPlanes, a real-time planar reconstruction model based on a\nmodified instance segmentation architecture which simultaneously predicts\nsemantics for each plane instance, along with plane parameters and piece-wise\nplane instance masks. By providing multi-view guidance in feature space, we\nachieve an improvement in instance mask segmentation despite only warping plane\nfeatures due to the nature of feature sharing in multi-task learning. Our model\nsimultaneously predicts semantics using single images at inference time, while\nachieving real-time predictions at 43 FPS. The code will be released\npost-publication.",
            "author": [
                "Luan Wei",
                "Anna Hilsmann",
                "Peter Eisert"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14981v1",
                "http://arxiv.org/pdf/2311.14981v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14980v1",
            "title": "Long-time behavior of the time-dependent damped nonlinear Schrodinger\n  equation",
            "updated": "2023-11-25T09:45:47Z",
            "published": "2023-11-25T09:45:47Z",
            "summary": "We investigate the large time behavior of the solutions to the nonlinear\nfocusing Schr\\\"odinger equation with a time-dependent damping in the energy\nsub-critical regime. The scattering results obtained in this work constitute a\nnatural extension of the ones in [15] where a constant damping is considered.",
            "author": [
                "Makram Hamouda",
                "Mohamed Majdoub"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14980v1",
                "http://arxiv.org/pdf/2311.14980v1"
            ],
            "primary_category": "math.AP",
            "category": [
                "math.AP",
                "math-ph",
                "math.MP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14972v1",
            "title": "Leveraging Neural Networks with Attention Mechanism for High-Order\n  Accuracy in Charge Density in Particle-in-Cell Simulation",
            "updated": "2023-11-25T09:10:14Z",
            "published": "2023-11-25T09:10:14Z",
            "summary": "In this research, we introduce an innovative three-network architecture that\ncomprises an encoder-decoder framework with an attention mechanism. The\narchitecture comprises a 1st-order-pre-trainer, a 2nd-order-improver, and a\ndiscriminator network, designed to boost the order accuracy of charge density\nin Particle-In-Cell (PIC) simulations. We acquire our training data from our\nself-developed 3-D PIC code, JefiPIC. The training procedure starts with the\n1st-order-pre-trainer, which is trained on a large dataset to predict charge\ndensities based on the provided article positions. Subsequently, we fine-tune\nthe 1st-order-pre-trainer, whose predictions then serve as inputs to the\n2nd-order-improver. Meanwhile, we train the 2nd-order-improver and\ndiscriminator network using a smaller volume of 2nd-order data, thereby\nachieving to generate charge density with 2nd-order accuracy. In the concluding\nphase, we replace JefiPIC's conventional particle interpolation process with\nour trained neural network. Our results demonstrate that the neural\nnetwork-enhanced PIC simulation can effectively simulate plasmas with 2\nnd-order accuracy. This highlights the advantage of our proposed neural\nnetwork: it can achieve higher-accuracy data with fewer real labels.",
            "author": [
                "Jian-Nan Chen",
                "Jun-Jie Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14972v1",
                "http://arxiv.org/pdf/2311.14972v1"
            ],
            "primary_category": "physics.comp-ph",
            "category": [
                "physics.comp-ph",
                "physics.plasm-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14970v1",
            "title": "UWB Radar SLAM: an Anchorless Approach in Vision Denied Indoor\n  Environments",
            "updated": "2023-11-25T09:07:42Z",
            "published": "2023-11-25T09:07:42Z",
            "summary": "LiDAR and cameras are frequently used as sensors for simultaneous\nlocalization and mapping (SLAM). However, these sensors are prone to failure\nunder low visibility (e.g. smoke) or places with reflective surfaces (e.g.\nmirrors). On the other hand, electromagnetic waves exhibit better penetration\nproperties when the wavelength increases, thus are not affected by low\nvisibility. Hence, this paper presents ultra-wideband (UWB) radar as an\nalternative to the existing sensors. UWB is generally known to be used in\nanchor-tag SLAM systems. One or more anchors are installed in the environment\nand the tags are attached to the robots. Although this method performs well\nunder low visibility, modifying the existing infrastructure is not always\nfeasible. UWB has also been used in peer-to-peer ranging collaborative SLAM\nsystems. However, this requires more than a single robot and does not include\nmapping in the mentioned environment like smoke. Therefore, the presented\napproach in this paper solely depends on the UWB transceivers mounted on-board.\nIn addition, an extended Kalman filter (EKF) SLAM is used to solve the SLAM\nproblem at the back-end. Experiments were conducted and demonstrated that the\nproposed UWB-based radar SLAM is able to map natural point landmarks inside an\nindoor environment while improving robot localization.",
            "author": [
                "H. A. G. C. Premachandra",
                "Ran Liu",
                "Chau Yuen",
                "U-Xuan Tan"
            ],
            "link": [
                "http://dx.doi.org/10.1109/LRA.2023.3293354",
                "http://arxiv.org/abs/2311.14970v1",
                "http://arxiv.org/pdf/2311.14970v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14966v1",
            "title": "Walking a Tightrope -- Evaluating Large Language Models in High-Risk\n  Domains",
            "updated": "2023-11-25T08:58:07Z",
            "published": "2023-11-25T08:58:07Z",
            "summary": "High-risk domains pose unique challenges that require language models to\nprovide accurate and safe responses. Despite the great success of large\nlanguage models (LLMs), such as ChatGPT and its variants, their performance in\nhigh-risk domains remains unclear. Our study delves into an in-depth analysis\nof the performance of instruction-tuned LLMs, focusing on factual accuracy and\nsafety adherence. To comprehensively assess the capabilities of LLMs, we\nconduct experiments on six NLP datasets including question answering and\nsummarization tasks within two high-risk domains: legal and medical. Further\nqualitative analysis highlights the existing limitations inherent in current\nLLMs when evaluating in high-risk domains. This underscores the essential\nnature of not only improving LLM capabilities but also prioritizing the\nrefinement of domain-specific metrics, and embracing a more human-centric\napproach to enhance safety and factual reliability. Our findings advance the\nfield toward the concerns of properly evaluating LLMs in high-risk domains,\naiming to steer the adaptability of LLMs in fulfilling societal obligations and\naligning with forthcoming regulations, such as the EU AI Act.",
            "author": [
                "Chia-Chien Hung",
                "Wiem Ben Rim",
                "Lindsay Frost",
                "Lars Bruckner",
                "Carolin Lawrence"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14966v1",
                "http://arxiv.org/pdf/2311.14966v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14964v1",
            "title": "Selective Inference for Changepoint detection by Recurrent Neural\n  Network",
            "updated": "2023-11-25T08:34:31Z",
            "published": "2023-11-25T08:34:31Z",
            "summary": "In this study, we investigate the quantification of the statistical\nreliability of detected change points (CPs) in time series using a Recurrent\nNeural Network (RNN). Thanks to its flexibility, RNN holds the potential to\neffectively identify CPs in time series characterized by complex dynamics.\nHowever, there is an increased risk of erroneously detecting random noise\nfluctuations as CPs. The primary goal of this study is to rigorously control\nthe risk of false detections by providing theoretically valid p-values to the\nCPs detected by RNN. To achieve this, we introduce a novel method based on the\nframework of Selective Inference (SI). SI enables valid inferences by\nconditioning on the event of hypothesis selection, thus mitigating selection\nbias. In this study, we apply SI framework to RNN-based CP detection, where\ncharacterizing the complex process of RNN selecting CPs is our main technical\nchallenge. We demonstrate the validity and effectiveness of the proposed method\nthrough artificial and real data experiments.",
            "author": [
                "Tomohiro Shiraishi",
                "Daiki Miwa",
                "Vo Nguyen Le Duy",
                "Ichiro Takeuchi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14964v1",
                "http://arxiv.org/pdf/2311.14964v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14961v2",
            "title": "Repetition factorization of automatic sequences",
            "updated": "2023-11-29T11:50:02Z",
            "published": "2023-11-25T08:29:45Z",
            "summary": "Following Inoue et al., we define a word to be a repetition if it is a\n(fractional) power of exponent at least 2. A word has a repetition\nfactorization if it is the product of repetitions. We study repetition\nfactorizations in several (generalized) automatic sequences, including the\ninfinite Fibonacci word, the Thue-Morse word, paperfolding words, and the\nRudin-Shapiro sequence.",
            "author": [
                "Jeffrey Shallit",
                "Xinhao Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14961v2",
                "http://arxiv.org/pdf/2311.14961v2"
            ],
            "primary_category": "cs.FL",
            "category": [
                "cs.FL",
                "cs.DM",
                "math.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14957v1",
            "title": "Multi-Scale Sub-Band Constant-Q Transform Discriminator for\n  High-Fidelity Vocoder",
            "updated": "2023-11-25T07:49:09Z",
            "published": "2023-11-25T07:49:09Z",
            "summary": "Generative Adversarial Network (GAN) based vocoders are superior in inference\nspeed and synthesis quality when reconstructing an audible waveform from an\nacoustic representation. This study focuses on improving the discriminator to\npromote GAN-based vocoders. Most existing time-frequency-representation-based\ndiscriminators are rooted in Short-Time Fourier Transform (STFT), whose\ntime-frequency resolution in a spectrogram is fixed, making it incompatible\nwith signals like singing voices that require flexible attention for different\nfrequency bands. Motivated by that, our study utilizes the Constant-Q Transform\n(CQT), which owns dynamic resolution among frequencies, contributing to a\nbetter modeling ability in pitch accuracy and harmonic tracking. Specifically,\nwe propose a Multi-Scale Sub-Band CQT (MS-SB-CQT) Discriminator, which operates\non the CQT spectrogram at multiple scales and performs sub-band processing\naccording to different octaves. Experiments conducted on both speech and\nsinging voices confirm the effectiveness of our proposed method. Moreover, we\nalso verified that the CQT-based and the STFT-based discriminators could be\ncomplementary under joint training. Specifically, enhanced by the proposed\nMS-SB-CQT and the existing MS-STFT Discriminators, the MOS of HiFi-GAN can be\nboosted from 3.27 to 3.87 for seen singers and from 3.40 to 3.78 for unseen\nsingers.",
            "author": [
                "Yicheng Gu",
                "Xueyao Zhang",
                "Liumeng Xue",
                "Zhizheng Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14957v1",
                "http://arxiv.org/pdf/2311.14957v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14951v2",
            "title": "Programmable high-dimensional Hamiltonian in a photonic waveguide array",
            "updated": "2023-11-28T05:29:16Z",
            "published": "2023-11-25T07:32:39Z",
            "summary": "Waveguide lattices offer a compact and stable platform for a range of\napplications, including quantum walks, topological effects, condensed matter\nsystem simulation, and classical and quantum information processing. In such\nlattices, the Hamiltonian's hopping and on-site terms determine the optical\nevolution, which can be engineered using waveguide spacing and refractive index\nprofile. While waveguide lattices have been realized in various photonic\nplatforms, these devices have always been static and designed for specific\napplications. We present a programmable waveguide array in which the\nHamiltonian terms can be electro-optically tuned to implement various\nHamiltonian continuous-time evolutions on a single device. We used a single\narray with 11 waveguides in lithium niobate, controlled via 22 electrodes, to\nperform a range of experiments that realized the Su-Schriffer-Heeger model, the\nAubrey-Andre model, and Anderson localization, which is equivalent to over 2500\nstatic devices. Our architecture's micron-scale local electric fields\nindependently control waveguide coupling coefficients and effective indices,\nwhich overcomes cross-talk limitations of thermo-optic phase shifters in other\nplatforms such as silicon, silicon-nitride, and silica. Electro-optic control\nallows for ultra-fast and more precise reconfigurability with lower power\nconsumption, and with quantum input states, our platform can enable the study\nof multiple condensed matter quantum dynamics with a single device.",
            "author": [
                "Yang Yang",
                "Robert J. Chapman",
                "Ben Haylock",
                "Francesco Lenzini",
                "Yogesh N. Joglekar",
                "Mirko Lobino",
                "Alberto Peruzzo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14951v2",
                "http://arxiv.org/pdf/2311.14951v2"
            ],
            "primary_category": "physics.optics",
            "category": [
                "physics.optics",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14950v1",
            "title": "An exact solution for the magnetic diffusion problem with a\n  step-function resistivity model",
            "updated": "2023-11-25T07:23:59Z",
            "published": "2023-11-25T07:23:59Z",
            "summary": "In the magnetic diffusion problem, a magnetic diffusion equation is coupled\nby an Ohmic heating energy equation. The Ohmic heating can make the magnetic\ndiffusion coefficient (i. e., the resistivity) vary violently, and make the\ndiffusion a highly nonlinear process. For this reason, the problem is normally\nvery hard to be solved analytically. In this article, under the condition of a\nstep-function resistivity and a constant boundary magnetic field, we\nsuccessfully derived an exact solution for this nonlinear problem, which should\nbe an interesting thing in the area of partial differential equations. What's\nmore, the solution could serve as a valuable benchmark example for testing\nsimulation methods of the magnetic diffusion problem.",
            "author": [
                "Bo Xiao",
                "Ganghua Wang",
                "Li Zhao",
                "Chunsheng Feng",
                "Shi Shu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14950v1",
                "http://arxiv.org/pdf/2311.14950v1"
            ],
            "primary_category": "math-ph",
            "category": [
                "math-ph",
                "math.MP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14949v1",
            "title": "Vector-Quantized Prompt Learning for Paraphrase Generation",
            "updated": "2023-11-25T07:13:06Z",
            "published": "2023-11-25T07:13:06Z",
            "summary": "Deep generative modeling of natural languages has achieved many successes,\nsuch as producing fluent sentences and translating from one language into\nanother. However, the development of generative modeling techniques for\nparaphrase generation still lags behind largely due to the challenges in\naddressing the complex conflicts between expression diversity and semantic\npreservation. This paper proposes to generate diverse and high-quality\nparaphrases by exploiting the pre-trained models with instance-dependent\nprompts. To learn generalizable prompts, we assume that the number of abstract\ntransforming patterns of paraphrase generation (governed by prompts) is finite\nand usually not large. Therefore, we present vector-quantized prompts as the\ncues to control the generation of pre-trained models. Extensive experiments\ndemonstrate that the proposed method achieves new state-of-art results on three\nbenchmark datasets, including Quora, Wikianswers, and MSCOCO. We will release\nall the code upon acceptance.",
            "author": [
                "Haotian Luo",
                "Yixin Liu",
                "Peidong Liu",
                "Xianggen Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14949v1",
                "http://arxiv.org/pdf/2311.14949v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14946v1",
            "title": "RFSoC-based front-end electronics for pulse detection",
            "updated": "2023-11-25T06:51:38Z",
            "published": "2023-11-25T06:51:38Z",
            "summary": "Radiation measurement relies on pulse detection, which can be performed using\nvarious configurations of high-speed analog-to-digital converters (ADCs) and\nfield-programmable gate arrays (FPGAs). For optimal power consumption, design\nsimplicity, system flexibility, and the availability of DSP slices, we consider\nthe Radio Frequency System-on-Chip (RFSoC) to be a more suitable option than\ntraditional setups. To this end, we have developed custom RFSoC-based\nelectronics and verified its feasibility. The ADCs on RFSoC exhibit a flat\nfrequency response of 1-125 MHz. The root-mean-square (RMS) noise level is 2.1\nADC without any digital signal processing. The digital signal processing\nimproves the RMS noise level to 0.8 ADC (input equivalent 40 Vrms). Baseline\ncorrection via digital signal processing can effectively prevent\nphotomultiplier overshoot after a large pulse. Crosstalk between all channels\nis less than -55 dB. The measured data transfer speed can support up to 32 kHz\ntrigger rates (corresponding to 750 Mbps). Overall, our RFSoC-based electronics\nare highly suitable for pulse detection, and after some modifications, they\nwill be employed in the Kamioka Liquid Scintillator Anti-Neutrino Detector\n(KamLAND).",
            "author": [
                "S. N. Axani",
                "S. Futagi",
                "M. Garcia",
                "C. Grant",
                "K. Hosokawa",
                "S. Ieki",
                "K. Inoue",
                "K. Ishidoshiro",
                "N. Kawada",
                "Y. Matsumoto",
                "T. Nakahata",
                "K. Nakamura",
                "R. Shouji",
                "H. Song",
                "L. A. Winslow"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14946v1",
                "http://arxiv.org/pdf/2311.14946v1"
            ],
            "primary_category": "physics.ins-det",
            "category": [
                "physics.ins-det"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14943v1",
            "title": "Generation of polarized electron beams through self-injection in the\n  interaction of a laser with a pre-polarized plasma",
            "updated": "2023-11-25T06:35:13Z",
            "published": "2023-11-25T06:35:13Z",
            "summary": "Polarized electron beam production via laser wakefield acceleration in\npre-polarized plasma is investigated by particle-in-cell simulations. The\nevolution of the electron beam polarization is studied based on the\nThomas-Bargmann-Michel-Telegdi equation for the transverse and longitudinal\nself-injection, and the depolarization process is found to be influenced by the\ninjection schemes. In the case of transverse self-injection as found typically\nin the bubble regime, the spin precession of the accelerated electrons is\nmainly influenced by the wakefield. However, in the case of longitudinal\ninjection in the quasi-one-dimensional regime (for example, F. Y. Li \\emph{et\nal}., Phys. Rev. Lett. 110, 135002 (2013)), the direction of electron spin\noscillates in the laser filed. Since the electrons move around the laser axis,\nthe net influence of the laser field is nearly zero and the contribution of the\nwakefield can be ignored. Finally, an ultra-short electron beam with\npolarization of $99\\%$ can be obtained using longitudinal self-injection.",
            "author": [
                "L. R. Yin",
                "X. F. Li",
                "Y. J. Gu",
                "N. Cao",
                "Q. Kong",
                "M. Buescher",
                "S. M. Weng",
                "M. Chen",
                "Z. M. Sheng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14943v1",
                "http://arxiv.org/pdf/2311.14943v1"
            ],
            "primary_category": "physics.plasm-ph",
            "category": [
                "physics.plasm-ph",
                "physics.acc-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14942v1",
            "title": "Hybrid Precoding and Combining for mmWave Full-Duplex Joint Radar and\n  Communication Systems under Self-Interference",
            "updated": "2023-11-25T06:24:45Z",
            "published": "2023-11-25T06:24:45Z",
            "summary": "In the context of integrated sensing and communication (ISAC), a full-duplex\n(FD) transceiver can operate as a monostatic radar while maintaining\ncommunication capabilities. This paper investigates the design of precoders and\ncombiners for a joint radar and communication (JRC) system at mmWave\nfrequencies. The primary goals of the design are to minimize self-interference\n(SI) caused by FD operation, while guaranteeing certain performance in terms of\nsome sensing and communication metrics, as well as taking into account the\nhardware limitations coming from a hybrid MIMO architecture. Specifically, we\nintroduce a generalized eigenvalue-based precoder that takes into account\ndownlink user rate, radar gain, and SI suppression. Since the hybrid\nanalog/digital architecture degrades the SI suppression capability of the\nprecoder, we further enhance SI suppression with the analog combiner. Our\nnumerical results demonstrate that the proposed architecture achieves the\nrequired radar gain and SI mitigation while incurring a small loss in downlink\nspectral efficiency. Additionally, the numerical experiments also show that the\nuse of orthogonal frequency division multiplexing (OFDM) for radar processing\nwith the proposed beamforming architecture results in highly accurate range and\nvelocity estimates for detected targets.",
            "author": [
                "Murat Bayraktar",
                "Nuria Gonz\u00e1lez-Prelcic",
                "Hao Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14942v1",
                "http://arxiv.org/pdf/2311.14942v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14941v1",
            "title": "Development of a Chemistry Dynamic Load Balancing Solver with Sparse\n  Analytical Jacobian Approach for Rapid and Accurate Reactive Flow Simulations",
            "updated": "2023-11-25T06:12:13Z",
            "published": "2023-11-25T06:12:13Z",
            "summary": "In addressing the demands of industrial high-fidelity computation, the\npresent study introduces a rapid and accurate customized solver developed on\nthe OpenFOAM platform. To enhance computational efficiency, a novel integrated\nacceleration strategy is introduced. Initially, a sparse analytical Jacobian\napproach utilizing the SpeedCHEM chemistry library was implemented to increase\nthe efficiency of the ODE solver. Subsequently, the Dynamic Load Balancing\n(DLB) code was employed to uniformly distribute the computational workload for\nchemistry among multiple processes. Further optimization was achieved through\nthe introduction of the Open Multi-Processing (OpenMP) method to enhance\nparallel computing efficiency. Lastly, the Local Time Stepping (LTS) scheme was\nintegrated to maximize the individual time step for each computational cell,\nresulting in a noteworthy minimum speed-up of over 31 times. The effectiveness\nand robustness of this customized solver were systematically validated against\nthree distinct partially turbulent premixed flames, Sandia Flames D, E, and F.\nAdditionally, a comparative analysis was conducted, encompassing different\nturbulence models, turbulent Prandtl numbers, and model constants, resulting in\nthe recommendation of optimal numerical parameters for various conditions. The\npresent study offers one viable solution for rapid and accurate calculations in\nthe OpenFOAM platform, while also providing insights into the selection of\nturbulence models and parameters for industrial numerical simulation.",
            "author": [
                "Yinan Yang",
                "Tsukasa Hori",
                "Shinya Sawada",
                "Fumiteru Akamatsu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14941v1",
                "http://arxiv.org/pdf/2311.14941v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn",
                "cs.NA",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14935v1",
            "title": "A Novel Deep Clustering Framework for Fine-Scale Parcellation of\n  Amygdala Using dMRI Tractography",
            "updated": "2023-11-25T05:43:51Z",
            "published": "2023-11-25T05:43:51Z",
            "summary": "The amygdala plays a vital role in emotional processing and exhibits\nstructural diversity that necessitates fine-scale parcellation for a\ncomprehensive understanding of its anatomico-functional correlations. Diffusion\nMRI tractography is an advanced imaging technique that can estimate the brain's\nwhite matter structural connectivity to potentially reveal the topography of\nthe amygdala for studying its subdivisions. In this work, we present a deep\nclustering pipeline to perform automated, fine-scale parcellation of the\namygdala using diffusion MRI tractography. First, we incorporate a newly\nproposed deep learning approach to enable accurate segmentation of the amygdala\ndirectly on the dMRI data. Next, we design a novel streamline clustering-based\nstructural connectivity feature for a robust representation of voxels within\nthe amygdala. Finally, we improve the popular joint dimensionality reduction\nand k-means clustering approach to enable amygdala parcellation at a finer\nscale. With the proposed method, we obtain nine unique amygdala parcels.\nExperiments show that these parcels can be consistently identified across\nsubjects and have good correspondence to the widely used coarse-scale amygdala\nparcellation.",
            "author": [
                "Haolin He",
                "Ce Zhu",
                "Le Zhang",
                "Yipeng Liu",
                "Xiao Xu",
                "Yuqian Chen",
                "Leo Zekelman",
                "Jarrett Rushmore",
                "Yogesh Rathi",
                "Nikos Makris",
                "Lauren J. O'Donnell",
                "Fan Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14935v1",
                "http://arxiv.org/pdf/2311.14935v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14933v1",
            "title": "ArcaDB: A Container-based Disaggregated Query Engine for Heterogenous\n  Computational Environments",
            "updated": "2023-11-25T05:31:31Z",
            "published": "2023-11-25T05:31:31Z",
            "summary": "Modern enterprises rely on data management systems to collect, store, and\nanalyze vast amounts of data related with their operations. Nowadays, clusters\nand hardware accelerators (e.g., GPUs, TPUs) have become a necessity to scale\nwith the data processing demands in many applications related to social media,\nbioinformatics, surveillance systems, remote sensing, and medical informatics.\nGiven this new scenario, the architecture of data analytics engines must evolve\nto take advantage of these new technological trends. In this paper, we present\nArcaDB: a disaggregated query engine that leverages container technology to\nplace operators at compute nodes that fit their performance profile. In ArcaDB,\na query plan is dispatched to worker nodes that have different computing\ncharacteristics. Each operator is annotated with the preferred type of compute\nnode for execution, and ArcaDB ensures that the operator gets picked up by the\nappropriate workers. We have implemented a prototype version of ArcaDB using\nJava, Python, and Docker containers. We have also completed a preliminary\nperformance study of this prototype, using images and scientific data. This\nstudy shows that ArcaDB can speed up query performance by a factor of 3.5x in\ncomparison with a shared-nothing, symmetric arrangement.",
            "author": [
                "Kristalys Ruiz-Rohena",
                "Manuel Rodriguez-Martinez"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14933v1",
                "http://arxiv.org/pdf/2311.14933v1"
            ],
            "primary_category": "cs.DB",
            "category": [
                "cs.DB"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14926v1",
            "title": "FreePIH: Training-Free Painterly Image Harmonization with Diffusion\n  Model",
            "updated": "2023-11-25T04:23:49Z",
            "published": "2023-11-25T04:23:49Z",
            "summary": "This paper provides an efficient training-free painterly image harmonization\n(PIH) method, dubbed FreePIH, that leverages only a pre-trained diffusion model\nto achieve state-of-the-art harmonization results. Unlike existing methods that\nrequire either training auxiliary networks or fine-tuning a large pre-trained\nbackbone, or both, to harmonize a foreground object with a painterly-style\nbackground image, our FreePIH tames the denoising process as a plug-in module\nfor foreground image style transfer. Specifically, we find that the very last\nfew steps of the denoising (i.e., generation) process strongly correspond to\nthe stylistic information of images, and based on this, we propose to augment\nthe latent features of both the foreground and background images with Gaussians\nfor a direct denoising-based harmonization. To guarantee the fidelity of the\nharmonized image, we make use of multi-scale features to enforce the\nconsistency of the content and stability of the foreground objects in the\nlatent space, and meanwhile, aligning both fore-/back-grounds with the same\nstyle. Moreover, to accommodate the generation with more structural and\ntextural details, we further integrate text prompts to attend to the latent\nfeatures, hence improving the generation quality. Quantitative and qualitative\nevaluations on COCO and LAION 5B datasets demonstrate that our method can\nsurpass representative baselines by large margins.",
            "author": [
                "Ruibin Li",
                "Jingcai Guo",
                "Song Guo",
                "Qihua Zhou",
                "Jie Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14926v1",
                "http://arxiv.org/pdf/2311.14926v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14925v1",
            "title": "Coordinate-based Neural Network for Fourier Phase Retrieval",
            "updated": "2023-11-25T04:23:23Z",
            "published": "2023-11-25T04:23:23Z",
            "summary": "Fourier phase retrieval is essential for high-definition imaging of nanoscale\nstructures across diverse fields, notably coherent diffraction imaging. This\nstudy presents the Single impliCit neurAl Network (SCAN), a tool built upon\ncoordinate neural networks meticulously designed for enhanced phase retrieval\nperformance. Bypassing the pitfalls of conventional iterative methods, which\nfrequently face high computational loads and are prone to noise interference,\nSCAN adeptly connects object coordinates to their amplitude and phase within a\nunified network in an unsupervised manner. While many existing methods\nprimarily use Fourier magnitude in their loss function, our approach\nincorporates both the predicted magnitude and phase, enhancing retrieval\naccuracy. Comprehensive tests validate SCAN's superiority over traditional and\nother deep learning models regarding accuracy and noise robustness. We also\ndemonstrate that SCAN excels in the ptychography setting.",
            "author": [
                "Tingyou Li",
                "Zixin Xu",
                "Yong S. Chu",
                "Xiaojing Huang",
                "Jizhou Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14925v1",
                "http://arxiv.org/pdf/2311.14925v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16476v1",
            "title": "LANS: A Layout-Aware Neural Solver for Plane Geometry Problem",
            "updated": "2023-11-25T04:11:19Z",
            "published": "2023-11-25T04:11:19Z",
            "summary": "Geometry problem solving (GPS) is a challenging mathematical reasoning task\nrequiring multi-modal understanding, fusion and reasoning. Existing neural\nsolvers take GPS as a vision-language task but be short in the representation\nof geometry diagrams which carry rich and complex layout information. In this\npaper, we propose a layout-aware neural solver named LANS, integrated with two\nnew modules: multimodal layout-aware pre-trained language model (MLA-PLM) and\nlayout-aware fusion attention (LA-FA). MLA-PLM adopts structural and semantic\npre-training (SSP) to implement global relationship modeling, and point\nmatching pre-training (PMP) to achieve alignment between visual points and\ntextual points. LA-FA employs a layout-aware attention mask to realize\npoint-guided cross-modal fusion for further boosting layout awareness of LANS.\nExtensive experiments on datasets Geometry3K and PGPS9K validate the\neffectiveness of the layout-aware modules and superior problem solving\nperformance of our LANS solver, over existing symbolic solvers and neural\nsolvers. The code will make public available soon.",
            "author": [
                "Ming-Liang Zhang",
                "Zhong-Zhi Li",
                "Fei Yin",
                "Cheng-Lin Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16476v1",
                "http://arxiv.org/pdf/2311.16476v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16511v1",
            "title": "GPT4Video: A Unified Multimodal Large Language Model for\n  lnstruction-Followed Understanding and Safety-Aware Generation",
            "updated": "2023-11-25T04:05:59Z",
            "published": "2023-11-25T04:05:59Z",
            "summary": "While the recent advances in Multimodal Large Language Models (MLLMs)\nconstitute a significant leap forward in the field, these models are\npredominantly confined to the realm of input-side multimodal comprehension,\nlacking the capacity for multimodal content generation. To fill this gap, we\npresent GPT4Video, a unified multi-model framework that empowers Large Language\nModels (LLMs) with the capability of both video understanding and generation.\nSpecifically, we develop an instruction-following-based approach integrated\nwith the stable diffusion generative model, which has demonstrated to\neffectively and securely handle video generation scenarios. GPT4Video offers\nthe following benefits: 1) It exhibits impressive capabilities in both video\nunderstanding and generation scenarios. For example, GPT4Video outperforms\nValley by 11.8\\% on the Video Question Answering task, and surpasses NExt-GPT\nby 2.3\\% on the Text to Video generation task. 2) it endows the LLM/MLLM with\nvideo generation capabilities without requiring additional training parameters\nand can flexibly interface with a wide range of models to perform video\ngeneration. 3) it maintains a safe and healthy conversation not only in\noutput-side but also the input side in an end-to-end manner. Qualitative and\nqualitative experiments demonstrate that GPT4Video holds the potential to\nfunction as a effective, safe and Humanoid-like video assistant that can handle\nboth video understanding and generation scenarios.",
            "author": [
                "Zhanyu Wang",
                "Longyue Wang",
                "Zhen Zhao",
                "Minghao Wu",
                "Chenyang Lyu",
                "Huayang Li",
                "Deng Cai",
                "Luping Zhou",
                "Shuming Shi",
                "Zhaopeng Tu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16511v1",
                "http://arxiv.org/pdf/2311.16511v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14922v1",
            "title": "GBD-TS: Goal-based Pedestrian Trajectory Prediction with Diffusion using\n  Tree Sampling Algorithm",
            "updated": "2023-11-25T03:55:06Z",
            "published": "2023-11-25T03:55:06Z",
            "summary": "Predicting pedestrian trajectories is crucial for improving the safety and\neffectiveness of autonomous driving and mobile robots. However, this task is\nnontrivial due to the inherent stochasticity of human motion, which naturally\nrequires the predictor to generate multi-model prediction. Previous works have\nused various generative methods, such as GAN and VAE, for pedestrian trajectory\nprediction. Nevertheless, these methods may suffer from problems, including\nmode collapse and relatively low-quality results. The denoising diffusion\nprobabilistic model (DDPM) has recently been applied to trajectory prediction\ndue to its simple training process and powerful reconstruction ability.\nHowever, current diffusion-based methods are straightforward without fully\nleveraging input information and usually require many denoising iterations\nleading to a long inference time or an additional network for initialization.\nTo address these challenges and promote the application of diffusion models in\ntrajectory prediction, we propose a novel scene-aware multi-modal pedestrian\ntrajectory prediction framework called GBD. GBD combines goal prediction with\nthe diffusion network. First, the goal predictor produces multiple goals, and\nthen the diffusion network generates multi-modal trajectories conditioned on\nthese goals. Furthermore, we introduce a new diffusion sampling algorithm named\ntree sampling (TS), which leverages common feature to reduce the inference time\nand improve accuracy for multi-modal prediction. Experimental results\ndemonstrate that our GBD-TS method achieves state-of-the-art performance with\nreal-time inference speed.",
            "author": [
                "Ge Sun",
                "Sheng Wang",
                "Yang Xiao",
                "Lei Zhu",
                "Ming Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14922v1",
                "http://arxiv.org/pdf/2311.14922v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14920v1",
            "title": "DECap: Towards Generalized Explicit Caption Editing via Diffusion\n  Mechanism",
            "updated": "2023-11-25T03:52:03Z",
            "published": "2023-11-25T03:52:03Z",
            "summary": "Explicit Caption Editing (ECE) -- refining reference image captions through a\nsequence of explicit edit operations (e.g., KEEP, DETELE) -- has raised\nsignificant attention due to its explainable and human-like nature. After\ntraining with carefully designed reference and ground-truth caption pairs,\nstate-of-the-art ECE models exhibit limited generalization ability beyond the\noriginal training data distribution, i.e., they are tailored to refine content\ndetails only in in-domain samples but fail to correct errors in out-of-domain\nsamples. To this end, we propose a new Diffusion-based Explicit Caption editing\nmethod: DECap. Specifically, we reformulate the ECE task as a denoising process\nunder the diffusion mechanism, and introduce innovative edit-based noising and\ndenoising processes. Thanks to this design, the noising process can help to\neliminate the need for meticulous paired data selection by directly introducing\nword-level noises for training, learning diverse distribution over input\nreference caption. The denoising process involves the explicit predictions of\nedit operations and corresponding content words, refining reference captions\nthrough iterative step-wise editing. To further efficiently implement our\ndiffusion process and improve the inference speed, DECap discards the prevalent\nmulti-stage design and directly generates edit operations and content words\nsimultaneously. Extensive ablations have demonstrated the strong generalization\nability of DECap in various scenarios. More interestingly, it even shows great\npotential in improving the quality and controllability of caption generation.",
            "author": [
                "Zhen Wang",
                "Jun Xiao",
                "Tao Chen",
                "Long Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14920v1",
                "http://arxiv.org/pdf/2311.14920v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14919v1",
            "title": "Faster Minimum Bayes Risk Decoding with Confidence-based Pruning",
            "updated": "2023-11-25T03:38:14Z",
            "published": "2023-11-25T03:38:14Z",
            "summary": "Minimum Bayes risk (MBR) decoding outputs the hypothesis with the highest\nexpected utility over the model distribution for some utility function. It has\nbeen shown to improve accuracy over beam search in conditional language\ngeneration problems and especially neural machine translation, in both human\nand automatic evaluations. However, the standard sampling-based algorithm for\nMBR is substantially more computationally expensive than beam search, requiring\na large number of samples as well as a quadratic number of calls to the utility\nfunction, limiting its applicability. We describe an algorithm for MBR which\ngradually grows the number of samples used to estimate the utility while\npruning hypotheses that are unlikely to have the highest utility according to\nconfidence estimates obtained with bootstrap sampling. Our method requires\nfewer samples and drastically reduces the number of calls to the utility\nfunction compared to standard MBR while being statistically indistinguishable\nin terms of accuracy. We demonstrate the effectiveness of our approach in\nexperiments on three language pairs, using chrF++ and COMET as\nutility/evaluation metrics.",
            "author": [
                "Julius Cheng",
                "Andreas Vlachos"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14919v1",
                "http://arxiv.org/pdf/2311.14919v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14918v1",
            "title": "Resolution- and Stimulus-agnostic Super-Resolution of Ultra-High-Field\n  Functional MRI: Application to Visual Studies",
            "updated": "2023-11-25T03:33:36Z",
            "published": "2023-11-25T03:33:36Z",
            "summary": "High-resolution fMRI provides a window into the brain's mesoscale\norganization. Yet, higher spatial resolution increases scan times, to\ncompensate for the low signal and contrast-to-noise ratio. This work introduces\na deep learning-based 3D super-resolution (SR) method for fMRI. By\nincorporating a resolution-agnostic image augmentation framework, our method\nadapts to varying voxel sizes without retraining. We apply this innovative\ntechnique to localize fine-scale motion-selective sites in the early visual\nareas. Detection of these sites typically requires a resolution higher than 1\nmm isotropic, whereas here, we visualize them based on lower resolution (2-3mm\nisotropic) fMRI data. Remarkably, the super-resolved fMRI is able to recover\nhigh-frequency detail of the interdigitated organization of these sites\n(relative to the color-selective sites), even with training data sourced from\ndifferent subjects and experimental paradigms -- including non-visual\nresting-state fMRI, underscoring its robustness and versatility. Quantitative\nand qualitative results indicate that our method has the potential to enhance\nthe spatial resolution of fMRI, leading to a drastic reduction in acquisition\ntime.",
            "author": [
                "Hongwei Bran Li",
                "Matthew S. Rosen",
                "Shahin Nasr",
                "Juan Eugenio Iglesias"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14918v1",
                "http://arxiv.org/pdf/2311.14918v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14917v1",
            "title": "Consolidate Viability and Information Theories for Task-Oriented\n  Communications: A Homeostasis Solution",
            "updated": "2023-11-25T03:32:18Z",
            "published": "2023-11-25T03:32:18Z",
            "summary": "The next generation of cellular networks, 6G, is expected to offer a range of\nexciting applications and services, including holographic communication,\nmachine-to-machine communication, and data sensing from millions of devices.\nThere is an incremental exhaustion of the spectral resources. It is crucial to\nefficiently manage these resources through value-driven approaches that\neliminate waste and continually enhance the communication process. These\nmanagement principles align with the Task-Oriented Communications (TOC)\nphilosophy. The aim is to allocate the minimum necessary communication resource\naccording to the receiver's objective and continuously improve the\ncommunication process. However, it is currently unclear how to build knowledge\nof the receiver's goal and operate accordingly for efficient-resource\nutilization. Our management approach combines viability theory and transfer\nentropy to ensure that the actor remains within a viable space as per their\ngoal and to gradually reduce the information exchange through knowledge\naccumulation. We discuss these theories in the context of TOC and examine their\napplication in the plant process control case. Finally, we provide insights\ninto future research directions from computational, performance, and protocol\nperspectives.",
            "author": [
                "Ozgur Ercetin",
                "Mohaned Chraiti",
                "Rustu Erciyes Karakaya"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14917v1",
                "http://arxiv.org/pdf/2311.14917v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "cs.SY",
                "eess.SY",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14916v2",
            "title": "An Efficient Game-Theoretic Planner for Automated Lane Merging with\n  Multi-Modal Behavior Understanding",
            "updated": "2023-12-02T10:24:12Z",
            "published": "2023-11-25T03:26:00Z",
            "summary": "In this paper, we propose a novel behavior planner that combines game theory\nwith search-based planning for automated lane merging. Specifically, inspired\nby human drivers, we model the interaction between vehicles as a gap selection\nprocess. To overcome the challenge of multi-modal behavior exhibited by the\nsurrounding vehicles, we formulate the trajectory selection as a matrix game\nand compute an equilibrium. Next, we validate our proposed planner in the\nhigh-fidelity simulator CARLA and demonstrate its effectiveness in handling\ninteractions in dense traffic scenarios.",
            "author": [
                "Luyao Zhang",
                "Shaohang Han",
                "Sergio Grammatico"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14916v2",
                "http://arxiv.org/pdf/2311.14916v2"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.RO",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14914v1",
            "title": "A Replica-BCS theory for dirty superconductors",
            "updated": "2023-11-25T03:19:47Z",
            "published": "2023-11-25T03:19:47Z",
            "summary": "Motivated by the discovery of the anomalous metal state in superconductor\nthin films, we revisit in this paper the problem of dirty superconductors using\na replica-symmetric BCS (RS-BCS) theory for dirty metals with net attractive\ninteractions. Within the RS-BCS mean field theory, we show that the (dirty)\nsuperconductor transits to a Cooper-pair-glass state beyond a critical strength\nof disorder. The single particle tunneling density of states and the superfluid\ndensity are computed within the RS-BCS theory for different strengths of\ndisorder. We find that the single-particle spectral gap is strongly enhanced by\ndisorder and the superfluid density reduces rapidly from the corresponding\nclean superconducting limit with increasing strength of disorder but remains\nfinite in the Cooper-pair-glass state. The nature of the Cooper-pair-glass\nstate and relevance of our result to the anomalous metal state are briefly\ndiscussed.",
            "author": [
                "Yat Fan Lau",
                "Tai Kai Ng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14914v1",
                "http://arxiv.org/pdf/2311.14914v1"
            ],
            "primary_category": "cond-mat.supr-con",
            "category": [
                "cond-mat.supr-con",
                "cond-mat.dis-nn"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14913v1",
            "title": "Tensor Unfolding Characterization",
            "updated": "2023-11-25T03:17:49Z",
            "published": "2023-11-25T03:17:49Z",
            "summary": "Tensors play a pivotal role in the realms of science and engineering,\nparticularly in the realms of data analysis, machine learning, and\ncomputational mathematics. The process of unfolding a tensor into matrices,\ncommonly known as tensor unfolding or matricization, serves as a valuable\ntechnique for simplifying the representation of tensors with higher orders. In\nthis study, we initially derive unfolded matrices from a specified tensor over\na B{'e}zout ring using a matrix equivalence relation. We proceed to elucidate\nthe relationships between eigenvalues and eigenvectors within these unfolded\nmatrices. Additionally, we employ the localization approach outlined by\nGerstein to ascertain the count of distinct matrix equivalence classes present\namong the unfolded matrices.",
            "author": [
                "Shih-Yu Chang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14913v1",
                "http://arxiv.org/pdf/2311.14913v1"
            ],
            "primary_category": "math.RA",
            "category": [
                "math.RA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14912v1",
            "title": "Electroweak corrections to Higgs boson production via Z Z fusion at the\n  future LHeC",
            "updated": "2023-11-25T03:11:25Z",
            "published": "2023-11-25T03:11:25Z",
            "summary": "An important mechanism for production of the Higgs boson at the prospective\nLarge Hadron-electron Collider (LHeC) is via neutral current (NC) weak boson\nfusion (WBF) processes. Aside from its role in measurements of Higgs couplings\nwithin the standard model, this production mode is particularly useful in\nsearchings of Higgs decays into invisble particles in various models for the\nHigg portal dark matter. In this work we compute the electroweak corrections\nfor the NC WBF at the LHeC up to the 1-loop level. For a center-of-mass energy\nof 1.98 TeV, the magnitudes of the relative corrections for the total cross\nsection at next-to-leading (NLO) order are respectively 8% and 17%, in the two\nrenormalization schemes we use. The NLO terms also distort various\ndistributions (notably, those for Higgs and electron observables) computed at\nthe leading order. Along with our previous treatment of the charge current\nprocesses, this paper completes the calulation of the NLO EW effects for the\ndominant Higgs production modes at the LHeC.",
            "author": [
                "Hanying Xiong",
                "Hongsheng Hou",
                "Zhuoni Qian",
                "Qingjun Xu",
                "Bowen Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14912v1",
                "http://arxiv.org/pdf/2311.14912v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16181v1",
            "title": "mvlearnR and Shiny App for multiview learning",
            "updated": "2023-11-25T03:01:12Z",
            "published": "2023-11-25T03:01:12Z",
            "summary": "The package mvlearnR and accompanying Shiny App is intended for integrating\ndata from multiple sources or views or modalities (e.g. genomics, proteomics,\nclinical and demographic data). Most existing software packages for multiview\nlearning are decentralized and offer limited capabilities, making it difficult\nfor users to perform comprehensive integrative analysis. The new package wraps\nstatistical and machine learning methods and graphical tools, providing a\nconvenient and easy data integration workflow. For users with limited\nprogramming language, we provide a Shiny Application to facilitate data\nintegration anywhere and on any device. The methods have potential to offer\ndeeper insights into complex disease mechanisms.\n  Availability and Implementation: mvlearnR is available from the following\nGitHub repository: https://github.com/lasandrall/mvlearnR. The web application\nis hosted on shinyapps.io and available at:\nhttps://multi-viewlearn.shinyapps.io/MultiView_Modeling/",
            "author": [
                "Elise F. Palzer",
                "Sandra E. Safo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16181v1",
                "http://arxiv.org/pdf/2311.16181v1"
            ],
            "primary_category": "q-bio.GN",
            "category": [
                "q-bio.GN",
                "cs.LG",
                "stat.AP",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14909v1",
            "title": "Continual Referring Expression Comprehension via Dual Modular\n  Memorization",
            "updated": "2023-11-25T02:58:51Z",
            "published": "2023-11-25T02:58:51Z",
            "summary": "Referring Expression Comprehension (REC) aims to localize an image region of\na given object described by a natural-language expression. While promising\nperformance has been demonstrated, existing REC algorithms make a strong\nassumption that training data feeding into a model are given upfront, which\ndegrades its practicality for real-world scenarios. In this paper, we propose\nContinual Referring Expression Comprehension (CREC), a new setting for REC,\nwhere a model is learning on a stream of incoming tasks. In order to\ncontinuously improve the model on sequential tasks without forgetting prior\nlearned knowledge and without repeatedly re-training from a scratch, we propose\nan effective baseline method named Dual Modular Memorization (DMM), which\nalleviates the problem of catastrophic forgetting by two memorization modules:\nImplicit-Memory and Explicit-Memory. Specifically, the former module aims to\nconstrain drastic changes to important parameters learned on old tasks when\nlearning a new task; while the latter module maintains a buffer pool to\ndynamically select and store representative samples of each seen task for\nfuture rehearsal. We create three benchmarks for the new CREC setting, by\nrespectively re-splitting three widely-used REC datasets RefCOCO, RefCOCO+ and\nRefCOCOg into sequential tasks. Extensive experiments on the constructed\nbenchmarks demonstrate that our DMM method significantly outperforms other\nalternatives, based on two popular REC backbones. We make the source code and\nbenchmarks publicly available to foster future progress in this field:\nhttps://github.com/zackschen/DMM.",
            "author": [
                "Heng Tao Shen",
                "Cheng Chen",
                "Peng Wang",
                "Lianli Gao",
                "Meng Wang",
                "Jingkuan Song"
            ],
            "link": [
                "http://dx.doi.org/10.1109/TIP.2022.3212317",
                "http://arxiv.org/abs/2311.14909v1",
                "http://arxiv.org/pdf/2311.14909v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14908v1",
            "title": "Support Vector Machine Implementation on MPI-CUDA and Tensorflow\n  Framework",
            "updated": "2023-11-25T02:52:37Z",
            "published": "2023-11-25T02:52:37Z",
            "summary": "Support Vector Machine (SVM) algorithm requires a high computational cost\n(both in memory and time) to solve a complex quadratic programming (QP)\noptimization problem during the training process. Consequently, SVM\nnecessitates high computing hardware capabilities. The central processing unit\n(CPU) clock frequency cannot be increased due to physical limitations in the\nminiaturization process. However, the potential of parallel multi-architecture,\navailable in both multi-core CPUs and highly scalable GPUs, emerges as a\npromising solution to enhance algorithm performance. Therefore, there is an\nopportunity to reduce the high computational time required by SVM for solving\nthe QP optimization problem. This paper presents a comparative study that\nimplements the SVM algorithm on different parallel architecture frameworks. The\nexperimental results show that SVM MPI-CUDA implementation achieves a speedup\nover SVM TensorFlow implementation on different datasets. Moreover, SVM\nTensorFlow implementation provides a cross-platform solution that can be\nmigrated to alternative hardware components, which will reduces the development\ntime.",
            "author": [
                "Islam Elgarhy"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14908v1",
                "http://arxiv.org/pdf/2311.14908v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14907v1",
            "title": "Transitioning to Tomorrow: The Global Journey Towards a Sustainable\n  Energy Economy",
            "updated": "2023-11-25T02:51:33Z",
            "published": "2023-11-25T02:51:33Z",
            "summary": "The spotlight is on the intertwined nature of sustainability and energy\ntransition. As the world grapples with environmental challenges, the push for a\ngreen approach to energy is more crucial than ever. This transition promises\nnot just a cleaner planet but also better public health and job opportunities.\nThere is a call for united front from policymakers, businesses, and communities\nto fast-track this eco-friendly shift.",
            "author": [
                "Rajini K R Karduri"
            ],
            "link": [
                "http://dx.doi.org/10.13140/RG.2.2.14081.63841",
                "http://arxiv.org/abs/2311.14907v1",
                "http://arxiv.org/pdf/2311.14907v1"
            ],
            "primary_category": "physics.soc-ph",
            "category": [
                "physics.soc-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14906v1",
            "title": "AutoEval-Video: An Automatic Benchmark for Assessing Large Vision\n  Language Models in Open-Ended Video Question Answering",
            "updated": "2023-11-25T02:46:12Z",
            "published": "2023-11-25T02:46:12Z",
            "summary": "We propose a novel and challenging benchmark, AutoEval-Video, to\ncomprehensively evaluate large vision-language models in open-ended video\nquestion answering. The comprehensiveness of AutoEval-Video is demonstrated in\ntwo aspects: 1) AutoEval-Video constructs open-ended video-questions across 9\nskill dimensions, addressing capabilities of perception, comprehension, and\ngeneration. 2) AutoEval-Video contains newly collected videos that cover over\n40 distinct themes. To efficiently evaluate responses to the open-ended\nquestions, we employ an LLM-based evaluation approach, but instead of merely\nproviding a reference answer, we annotate unique evaluation rules for every\nsingle instance (video-question pair). To maximize the robustness of these\nrules, we develop a novel adversarial annotation mechanism. By using\ninstance-specific rules as prompt, GPT-4, as an automatic evaluator, can\nachieve a stable evaluation accuracy of around 97.0\\%, comparable to the 94.9\\%\n- 97.5\\% accuracy of a human evaluator. Furthermore, we assess the performance\nof eight large vision-language models on AutoEval-Video. Among them,\nGPT-4V(ision) significantly outperforms other models, achieving an accuracy of\n32.2\\%. However, there is still substantial room for improvement compared to\nhuman accuracy of 72.8\\%. By conducting an extensive case study, we uncover\nseveral drawbacks of GPT-4V, such as limited temporal and dynamic\ncomprehension, and overly general responses. Code is available at\n\\href{https://github.com/Xiuyuan-Chen/AutoEval-Video}{\\color{magenta}https://github.com/Xiuyuan-Chen/AutoEval-Video}.",
            "author": [
                "Xiuyuan Chen",
                "Yuan Lin",
                "Yuchen Zhang",
                "Weiran Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14906v1",
                "http://arxiv.org/pdf/2311.14906v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14904v1",
            "title": "LLM-Assisted Code Cleaning For Training Accurate Code Generators",
            "updated": "2023-11-25T02:45:50Z",
            "published": "2023-11-25T02:45:50Z",
            "summary": "Natural language to code generation is an important application area of LLMs\nand has received wide attention from the community. The majority of relevant\nstudies have exclusively concentrated on increasing the quantity and functional\ncorrectness of training sets while disregarding other stylistic elements of\nprograms. More recently, data quality has garnered a lot of interest and\nmultiple works have showcased its importance for improving performance. In this\nwork, we investigate data quality for code and find that making the code more\nstructured and readable leads to improved code generation performance of the\nsystem. We build a novel data-cleaning pipeline that uses these principles to\ntransform existing programs by 1.) renaming variables, 2.) modularizing and\ndecomposing complex code into smaller helper sub-functions, and 3.) inserting\nnatural-language based plans via LLM based transformations. We evaluate our\napproach on two challenging algorithmic code generation benchmarks and find\nthat fine-tuning CodeLLaMa-7B on our transformed modularized programs improves\nthe performance by up to 30% compared to fine-tuning on the original dataset.\nAdditionally, we demonstrate improved performance from using a smaller amount\nof higher-quality data, finding that a model fine-tuned on the entire original\ndataset is outperformed by a model trained on 15% of our cleaned dataset. Even\nin comparison to closed-source models, our models outperform the much larger\nAlphaCoder models.",
            "author": [
                "Naman Jain",
                "Tianjun Zhang",
                "Wei-Lin Chiang",
                "Joseph E. Gonzalez",
                "Koushik Sen",
                "Ion Stoica"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14904v1",
                "http://arxiv.org/pdf/2311.14904v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14903v1",
            "title": "Code Generation Based Grading: Evaluating an Auto-grading Mechanism for\n  \"Explain-in-Plain-English\" Questions",
            "updated": "2023-11-25T02:45:00Z",
            "published": "2023-11-25T02:45:00Z",
            "summary": "Comprehending and elucidating the purpose of code is often cited as being a\nkey learning objective within introductory programming courses. To address this\nobjective ``Explain-in-Plain-English'' questions, in which students are shown a\nsegment of code and asked to provide an abstract description of the code's\npurpose, have been adopted. However, given EiPE questions require a natural\nlanguage response, they often require manual grading which is time-consuming\nfor course staff and delays feedback for students. With the advent of large\nlanguage models (LLMs) capable of generating code, responses to EiPE questions\ncan be used to generate code segments, the correctness of which can then be\neasily verified using test cases. We refer to this approach as \"Code Generation\nBased Grading\" (CGBG) and in this paper we explore its agreement with human\ngraders using EiPE responses from past exams in an introductory programming\ncourse taught in Python. Overall, we find that CGBG achieves moderate agreement\nwith human graders with the primary area of disagreement being its leniency\nwith respect to low-level and line-by-line descriptions of code.",
            "author": [
                "David H. Smith IV",
                "Craig Zilles"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14903v1",
                "http://arxiv.org/pdf/2311.14903v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14901v1",
            "title": "Code Search Debiasing:Improve Search Results beyond Overall Ranking\n  Performance",
            "updated": "2023-11-25T02:31:22Z",
            "published": "2023-11-25T02:31:22Z",
            "summary": "Code search engine is an essential tool in software development. Many code\nsearch methods have sprung up, focusing on the overall ranking performance of\ncode search. In this paper, we study code search from another perspective by\nanalyzing the bias of code search models. Biased code search engines provide\npoor user experience, even though they show promising overall performance. Due\nto different development conventions (e.g., prefer long queries or\nabbreviations), some programmers will find the engine useful, while others may\nfind it hard to get desirable search results. To mitigate biases, we develop a\ngeneral debiasing framework that employs reranking to calibrate search results.\nIt can be easily plugged into existing engines and handle new code search\nbiases discovered in the future. Experiments show that our framework can\neffectively reduce biases. Meanwhile, the overall ranking performance of code\nsearch gets improved after debiasing.",
            "author": [
                "Sheng Zhang",
                "Hui Li",
                "Yanlin Wang",
                "Zhao Wei",
                "Yong Xiu",
                "Juhong Wang",
                "Rongong Ji"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14901v1",
                "http://arxiv.org/pdf/2311.14901v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14900v1",
            "title": "Resfusion: Prior Residual Noise embedded Denoising Diffusion\n  Probabilistic Models",
            "updated": "2023-11-25T02:09:38Z",
            "published": "2023-11-25T02:09:38Z",
            "summary": "Recently, Denoising Diffusion Probabilistic Models have been widely used in\nimage segmentation, by generating segmentation masks conditioned on the input\nimage. However, previous works can not seamlessly integrate existing end-to-end\nmodels with denoising diffusion models. Existing research can only select\nacceleration steps based on experience rather than calculating them\nspecifically. Moreover, most methods are limited to small models and\nsmall-scale datasets, unable to generalize to general datasets and a wider\nrange of tasks. Therefore, we propose Resfusion with a novel resnoise-diffusion\nprocess, which gradually generates segmentation masks or any type of target\nimage, seamlessly integrating state-of-the-art end-to-end models and denoising\ndiffusion models. Resfusion bridges the discrepancy between the likelihood\noutput and the ground truth output through a Markov process. Through the novel\nsmooth equivalence transformation in resnoise-diffusion process, we determine\nthe optimal acceleration step. Experimental results demonstrate that Resfusion\ncombines the capabilities of existing end-to-end models and denoising diffusion\nmodels, further enhancing performance and achieving outstanding results.\nMoreover, Resfusion is not limited to segmentation tasks, it can easily\ngeneralize to any general tasks of image generation and exhibit strong\ncompetitiveness.",
            "author": [
                "Shi Zhenning",
                "Dong Changsheng",
                "Pan Bin",
                "Xie Xueshuo",
                "He Along",
                "Qu Qiaoying",
                "Li Tao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14900v1",
                "http://arxiv.org/pdf/2311.14900v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16180v1",
            "title": "Aiming to Minimize Alcohol-Impaired Road Fatalities: Utilizing\n  Fairness-Aware and Domain Knowledge-Infused Artificial Intelligence",
            "updated": "2023-11-25T02:05:39Z",
            "published": "2023-11-25T02:05:39Z",
            "summary": "Approximately 30% of all traffic fatalities in the United States are\nattributed to alcohol-impaired driving. This means that, despite stringent laws\nagainst this offense in every state, the frequency of drunk driving accidents\nis alarming, resulting in approximately one person being killed every 45\nminutes. The process of charging individuals with Driving Under the Influence\n(DUI) is intricate and can sometimes be subjective, involving multiple stages\nsuch as observing the vehicle in motion, interacting with the driver, and\nconducting Standardized Field Sobriety Tests (SFSTs). Biases have been observed\nthrough racial profiling, leading to some groups and geographical areas facing\nfewer DUI tests, resulting in many actual DUI incidents going undetected,\nultimately leading to a higher number of fatalities. To tackle this issue, our\nresearch introduces an Artificial Intelligence-based predictor that is both\nfairness-aware and incorporates domain knowledge to analyze DUI-related\nfatalities in different geographic locations. Through this model, we gain\nintriguing insights into the interplay between various demographic groups,\nincluding age, race, and income. By utilizing the provided information to\nallocate policing resources in a more equitable and efficient manner, there is\npotential to reduce DUI-related fatalities and have a significant impact on\nroad safety.",
            "author": [
                "Tejas Venkateswaran",
                "Sheikh Rabiul Islam",
                "Md Golam Moula Mehedi Hasan",
                "Mohiuddin Ahmed"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16180v1",
                "http://arxiv.org/pdf/2311.16180v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14898v1",
            "title": "HongTu: Scalable Full-Graph GNN Training on Multiple GPUs (via\n  communication-optimized CPU data offloading)",
            "updated": "2023-11-25T01:55:08Z",
            "published": "2023-11-25T01:55:08Z",
            "summary": "Full-graph training on graph neural networks (GNN) has emerged as a promising\ntraining method for its effectiveness. Full-graph training requires extensive\nmemory and computation resources. To accelerate this training process,\nresearchers have proposed employing multi-GPU processing. However the\nscalability of existing frameworks is limited as they necessitate maintaining\nthe training data for every layer in GPU memory. To efficiently train on large\ngraphs, we present HongTu, a scalable full-graph GNN training system running on\nGPU-accelerated platforms. HongTu stores vertex data in CPU memory and offloads\ntraining to GPUs. HongTu employs a memory-efficient full-graph training\nframework that reduces runtime memory consumption by using partition-based\ntraining and recomputation-caching-hybrid intermediate data management. To\naddress the issue of increased host-GPU communication caused by duplicated\nneighbor access among partitions, HongTu employs a deduplicated communication\nframework that converts the redundant host-GPU communication to efficient\ninter/intra-GPU data access. Further, HongTu uses a cost model-guided graph\nreorganization method to minimize communication overhead. Experimental results\non a 4XA100 GPU server show that HongTu effectively supports billion-scale\nfull-graph GNN training while reducing host-GPU data communication by 25%-71%.\nCompared to the full-graph GNN system DistGNN running on 16 CPU nodes, HongTu\nachieves speedups ranging from 7.8X to 20.2X. For small graphs where the\ntraining data fits into the GPUs, HongTu achieves performance comparable to\nexisting GPU-based GNN systems.",
            "author": [
                "Qiange Wang",
                "Yao Chen",
                "Weng-Fai Wong",
                "Bingsheng He"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3626733",
                "http://arxiv.org/abs/2311.14898v1",
                "http://arxiv.org/pdf/2311.14898v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14896v1",
            "title": "Suppressing Coherent Synchrotron Radiation Effects in Chicane Bunch\n  Compressors",
            "updated": "2023-11-25T01:42:22Z",
            "published": "2023-11-25T01:42:22Z",
            "summary": "The most significant advances in the accelerator-based light sources (i.e.,\nx-ray free electron lasers) are driven by the development of bunch compression\nand high-brightness sources in the last several decades. For bunch compression,\nthe symmetric four-dipole $C$-chicane is typically exploited since it is\nsimple, effective, and naturally dispersion-free at all orders. However, the\nemission of the coherent synchrotron radiation (CSR), becomes a main\ncontributing factor to transverse emittance degradation during bunch\ncompression. Suppressing CSR effect is necessary otherwise the anticipative\ncompression schemes are susceptible to beam quality degradation. To alleviate\nthis difficulty, this paper reports a CSR-cancelled theoretical design for\nasymmetric $C$- and $S$-chicanes. The CSR cancelation conditions of the two\nchicanes are derived with the aid of the point-kick model. A rigorous analysis\nis provided to verify the proposed CSR cancelation conditions for asymmetric\n$C$- and $S$-chicanes, performed by the integration method and ELEGANT\nsimulations. Compared to the symmetric $C$- and $S$-chicanes with identical\nbunch compression targets, the CSR-induced emittance growth of the asymmetric\nones can be reduced by two orders of magnitude and at the order of 0.1\\%. The\ndemonstration of this novel discovery opens the door for the chicane bunch\ncompressors to meet the ever-increasing demands of future accelerator\napplications, particularly important in the field of x-ray free electron\nlasers.",
            "author": [
                "Fancong Zeng",
                "Yi Jiao",
                "Weihang Liu",
                "Cheng-Ying Tsai"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14896v1",
                "http://arxiv.org/pdf/2311.14896v1"
            ],
            "primary_category": "physics.acc-ph",
            "category": [
                "physics.acc-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14895v1",
            "title": "Data-Driven Nonlinear State Observation using Video Measurements",
            "updated": "2023-11-25T01:40:58Z",
            "published": "2023-11-25T01:40:58Z",
            "summary": "State observation is necessary for feedback control but often challenging for\nnonlinear systems. While Kazantzis-Kravaris/Luenberger (KKL) observer gives a\ngeneric design, its model-based numerical solution is difficult. In this paper,\nwe propose a simple method to determine a data-driven KKL observer, namely to\n(i) transform the measured output signals by a linear time-invariant dynamics,\nand (ii) reduce the dimensionality to principal components. This approach is\nespecially suitable for systems with rich measurements and low-dimensional\nstate space, for example, when videos can be obtained in real time. We present\nan application to a video of the well-known Belousov-Zhabotinsky (B-Z) reaction\nsystem with severe nonlinearity, where the data-driven KKL observer recovers an\noscillatory state orbit with slow damping.",
            "author": [
                "Cormak Weeks",
                "Wentao Tang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14895v1",
                "http://arxiv.org/pdf/2311.14895v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14890v1",
            "title": "Segment-Based Wall Treatment Model for Heat Transfer Rate in Smoothed\n  Particle Hydrodynamics",
            "updated": "2023-11-25T00:59:36Z",
            "published": "2023-11-25T00:59:36Z",
            "summary": "In this study, a smoothed particle hydrodynamics (SPH) model that applies a\nsegment-based boundary treatment is used to simulate natural convection. In a\nnatural convection simulated using an SPH model, the wall boundary treatment is\na major issue because accurate heat transfer from boundaries should be\ncalculated. The boundary particle method, which models the boundary by placing\nmultiple layers of particles on and behind the wall boundary, is the most\nwidely used boundary treatment method. Although this method can impose accurate\nboundary conditions, boundary modeling for complex shapes is challenging and\nrequires excessive computational costs depending on the boundary shape. In this\nstudy, we utilize a segment-based boundary treatment method to model the wall\nboundary and apply this method to the energy conservation equation for the wall\nheat transfer model. The proposed method solves the problems arising from the\nuse of boundary particles and simultaneously provides accurate heat transfer\ncalculation results for the wall. In various numerical examples, the proposed\nmethod is verified through a comparison with available experimental results,\nSPH results using the boundary particle method, and finite volume method (FVM)\nresults.",
            "author": [
                "Hyung-Jun Park",
                "Jaekwang Kim",
                "Hyojin Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14890v1",
                "http://arxiv.org/pdf/2311.14890v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn",
                "cs.NA",
                "math.NA",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14877v1",
            "title": "Triadic percolation induces dynamical topological patterns in\n  higher-order networks",
            "updated": "2023-11-25T00:00:30Z",
            "published": "2023-11-25T00:00:30Z",
            "summary": "Triadic interactions are higher-order interactions that occur when a set of\nnodes affects the interaction between two other nodes. Examples of triadic\ninteractions are present in the brain when glia modulate the synaptic signals\namong neuron pairs or when interneuron axon-axonic synapses enable presynaptic\ninhibition and facilitation, and in ecosystems when one or more species can\naffect the interaction among two other species. On random graphs, triadic\npercolation has been recently shown to turn percolation into a fully-fledged\ndynamical process in which the size of the giant component undergoes a route to\nchaos. However, in many real cases, triadic interactions are local and occur on\nspatially embedded networks. Here we show that triadic interactions in spatial\nnetworks induce a very complex spatio-temporal modulation of the giant\ncomponent which gives rise to triadic percolation patterns with significantly\ndifferent topology. We classify the observed patterns (stripes, octopus, and\nsmall clusters) with topological data analysis and we assess their information\ncontent (entropy and complexity). Moreover, we illustrate the multistability of\nthe dynamics of the triadic percolation patterns and we provide a comprehensive\nphase diagram of the model. These results open new perspectives in percolation\nas they demonstrate that in presence of spatial triadic interactions, the giant\ncomponent can acquire a time-varying topology. Hence, this work provides a\ntheoretical framework that can be applied to model realistic scenarios in which\nthe giant component is time-dependent as in neuroscience.",
            "author": [
                "Ana P. Mill\u00e1n",
                "Hanlin Sun",
                "Joaqu\u00ecn J. Torres",
                "Ginestra Bianconi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14877v1",
                "http://arxiv.org/pdf/2311.14877v1"
            ],
            "primary_category": "nlin.AO",
            "category": [
                "nlin.AO",
                "cond-mat.dis-nn",
                "cond-mat.stat-mech",
                "nlin.CD",
                "physics.soc-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14876v1",
            "title": "Exploiting Large Language Models (LLMs) through Deception Techniques and\n  Persuasion Principles",
            "updated": "2023-11-24T23:57:44Z",
            "published": "2023-11-24T23:57:44Z",
            "summary": "With the recent advent of Large Language Models (LLMs), such as ChatGPT from\nOpenAI, BARD from Google, Llama2 from Meta, and Claude from Anthropic AI, gain\nwidespread use, ensuring their security and robustness is critical. The\nwidespread use of these language models heavily relies on their reliability and\nproper usage of this fascinating technology. It is crucial to thoroughly test\nthese models to not only ensure its quality but also possible misuses of such\nmodels by potential adversaries for illegal activities such as hacking. This\npaper presents a novel study focusing on exploitation of such large language\nmodels against deceptive interactions. More specifically, the paper leverages\nwidespread and borrows well-known techniques in deception theory to investigate\nwhether these models are susceptible to deceitful interactions.\n  This research aims not only to highlight these risks but also to pave the way\nfor robust countermeasures that enhance the security and integrity of language\nmodels in the face of sophisticated social engineering tactics. Through\nsystematic experiments and analysis, we assess their performance in these\ncritical security domains. Our results demonstrate a significant finding in\nthat these large language models are susceptible to deception and social\nengineering attacks.",
            "author": [
                "Sonali Singh",
                "Faranak Abri",
                "Akbar Siami Namin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14876v1",
                "http://arxiv.org/pdf/2311.14876v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14875v2",
            "title": "Uncertainty Aware AI for 2D MRI Segmentation",
            "updated": "2023-11-28T11:27:27Z",
            "published": "2023-11-24T23:54:33Z",
            "summary": "Robust uncertainty estimations are necessary in safety-critical applications\nof Deep Learning. One such example is the semantic segmentation of medical\nimages, whilst deep-learning approaches have high performance in such tasks\nthey lack interpretability as they give no indication of their confidence when\nmaking classification decisions. Robust and interpretable segmentation is a\ncritical first stage in automatically screening for pathologies hence the\noptimal solution is one which can provide high accuracy but also capture the\nunderlying uncertainty. In this work, we present an uncertainty-aware\nsegmentation model, BA U-Net, for use on MRI data that incorporates Bayesian\nNeural Networks and Attention Mechanisms to provide accurate and interpretable\nsegmentations. We evaluated our model on the publicly available BraTS 2020\ndataset using F1 Score and Intersection Over Union (IoU) as evaluation metrics.",
            "author": [
                "Lohith Konathala"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14875v2",
                "http://arxiv.org/pdf/2311.14875v2"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14872v1",
            "title": "The Power Board of the KM3NeT Digital Optical Module: design, upgrade,\n  and production",
            "updated": "2023-11-24T23:50:14Z",
            "published": "2023-11-24T23:50:14Z",
            "summary": "The KM3NeT Collaboration is building an underwater neutrino observatory at\nthe bottom of the Mediterranean Sea consisting of two neutrino telescopes, both\ncomposed of a three-dimensional array of light detectors, known as digital\noptical modules. Each digital optical module contains a set of 31 three inch\nphotomultiplier tubes distributed over the surface of a 0.44 m diameter\npressure-resistant glass sphere. The module includes also calibration\ninstruments and electronics for power, readout and data acquisition. The power\nboard was developed to supply power to all the elements of the digital optical\nmodule. The design of the power board began in 2013, and several prototypes\nwere produced and tested. After an exhaustive validation process in various\nlaboratories within the KM3NeT Collaboration, a mass production batch began,\nresulting in the construction of over 1200 power boards so far. These boards\nwere integrated in the digital optical modules that have already been produced\nand deployed, 828 until October 2023. In 2017, an upgrade of the power board,\nto increase reliability and efficiency, was initiated. After the validation of\na pre-production series, a production batch of 800 upgraded boards is currently\nunderway. This paper describes the design, architecture, upgrade, validation,\nand production of the power board, including the reliability studies and tests\nconducted to ensure the safe operation at the bottom of the Mediterranean Sea\nthroughout the observatory's lifespan",
            "author": [
                "S. Aiello",
                "A. Albert",
                "S. Alves Garre",
                "Z. Aly",
                "A. Ambrosone",
                "F. Ameli",
                "M. Andre",
                "E. Androutsou",
                "M. Anguita",
                "L. Aphecetche",
                "M. Ardid",
                "S. Ardid",
                "H. Atmani",
                "J. Aublin",
                "F. Badaracco",
                "L. Bailly-Salins",
                "Z. Bardacova",
                "B. Baret",
                "A. Bariego Quintana",
                "S. Basegmez du Pree",
                "Y. Becherini",
                "M. Bendahman",
                "F. Benfenati",
                "M. Benhassi",
                "D. M. Benoit",
                "E. Berbee",
                "V. Bertin",
                "V. van Beveren",
                "S. Biagi",
                "M. Boettcher",
                "D. Bonanno",
                "J. Boumaaza",
                "M. Bouta",
                "M. Bouwhuis",
                "C. Bozza",
                "R. M. Bozza",
                "H. Branzas",
                "F. Bretaudeau",
                "R. Bruijn",
                "J. Brunner",
                "R. Bruno",
                "E. Buis",
                "R. Buompane",
                "J. Busto",
                "B. Caiffi",
                "D. Calvo",
                "S. Campion",
                "A. Capone",
                "F. Careniniu",
                "V. Carretero",
                "T. Cartraud",
                "P. Castaldi",
                "V. Cecchini",
                "S. Celli",
                "L. Cerisy",
                "M. Chabab",
                "M. Chadolias",
                "C. Champion",
                "A. Chena",
                "S. Cherubini",
                "T. Chiarusi",
                "M. Circella",
                "R. Cocimano",
                "J. A. B. Coelho",
                "A. Coleiro",
                "S. Colonges",
                "R. Coniglione",
                "P. Coyle",
                "A. Creusot",
                "G. Cuttone",
                "R. Dallier",
                "Y. Darras",
                "A. De Benedittis",
                "B. De Martino",
                "V. Decoene",
                "R. Del Burgo",
                "I. Del Rosso",
                "U. M. Di Cerbo",
                "L. S. Di Mauro",
                "I. Di Palma",
                "A. F. D\u00edaz",
                "C. Diaz",
                "D. Diego-Tortosa",
                "C. Distefano",
                "A. Domia",
                "C. Donzaud",
                "D. Dornic",
                "M. Dorra",
                "E. Drakopoulou",
                "D. Drouhin",
                "R. Dvornicky",
                "T. Eberla",
                "E. Eckerova",
                "A. Eddymaoui",
                "T. van Eeden",
                "M. Eff",
                "D. van Eijk",
                "I. El Bojaddaini",
                "S. El Hedri",
                "A. Enzenhofer",
                "G. Ferrara",
                "M. D. Filipovica",
                "F. Filippini",
                "D. Franciotti",
                "L. A. Fusco",
                "O. Gabellaa",
                "J. Gabriela",
                "S. Gagliardini",
                "T. Gal",
                "J. Garc\u0131a Mendez",
                "A. Garcia Soto",
                "C. Gatius Oliver",
                "N. Gei\u00dfelbrecht",
                "H. Ghaddari",
                "L. Gialanella",
                "B. K. Gibson",
                "E. Giorgio",
                "I. Goos",
                "P. Goswami",
                "D. Goupilliere",
                "S. R. Gozzini",
                "R. Gracia",
                "K. Grafa",
                "C. Guidi",
                "B. Guillon",
                "M. Gutierrez",
                "H. van Haren",
                "A. Heijboer",
                "A. Hekalo",
                "L. Henniga",
                "J. J. Hernandez-Rey",
                "W. Idrissi Ibnsalih",
                "G. Illuminati",
                "P. Jansweijer",
                "M. de Jonga",
                "P. de Jonga",
                "B. J. Jung",
                "P. Kalaczynski",
                "O. Kalekin",
                "U. F. Katz",
                "A. Khatun",
                "G. Kistauri",
                "C. Kopper",
                "A. Kouchner",
                "V. Kueviakoe",
                "V. Kulikovskiy",
                "R. Kvatadze",
                "M. Labalme",
                "R. Lahmann",
                "G. Larosa",
                "C. Lastoria",
                "A. Lazo",
                "S. Le Stum",
                "G. Lehaut",
                "E. Leonora",
                "N. Lessing",
                "G. Levi",
                "M. Lindsey Clark",
                "P. Litrico",
                "F. Longhitano",
                "J. Majumdar",
                "L. Malerba",
                "F. Mamedov",
                "J. Manczak",
                "A. Manfredae",
                "M. Marconi",
                "A. Margiotta",
                "A. Marinelli",
                "C. Markou",
                "L. Martin",
                "J. A. Mart\u0131nez-Mora",
                "F. Marzaioli",
                "M. Mastrodicasa",
                "S. Mastroianni",
                "S. Miccich",
                "G. Miele",
                "P. Migliozzi",
                "E. Migneco",
                "S. Minutoli",
                "M. L. Mitsou",
                "C. M. Mollo",
                "L. Morales-Gallegos",
                "M. Morga",
                "A. Moussa",
                "I. Mozun Mateo",
                "R. Muller",
                "P. Musico",
                "M. R. Musone",
                "M. Musumeci",
                "S. Navas",
                "A. Nayerhoda",
                "C. A. Nicolau",
                "B. Nkosi",
                "B. O. Fearraigh",
                "V. Oliviero",
                "A. Orlando",
                "E. Oukacha",
                "D. Paesani",
                "J. Palacios Gonzalez",
                "G. Papalashvili",
                "V. Parisi",
                "E. J. Pastor Gomez",
                "A. M. Pauna",
                "G. E. Pavalas",
                "G. Pellegrini",
                "S. Pe\u00f1aa Martinez",
                "M. Perrin-Terrin",
                "J. Perronnel",
                "V. Pestel",
                "R. Pestes",
                "P. Piattelli",
                "C. Poirre",
                "V. Popa",
                "T. Pradier",
                "J. Prado",
                "S. Pulvirenti",
                "G. Quemener",
                "C. A. Quiroz-Rangel",
                "U. Rahaman",
                "N. Randazzo",
                "R. Randriatoamana",
                "S. Razzaque",
                "I. C. Rea",
                "D. Real",
                "G. Riccobene",
                "J. Robinson",
                "A. Romanov",
                "A. Saina",
                "F. Salesa Greus",
                "D. F. E. Samtleben",
                "A. Sanchez Losa",
                "S. Sanfilippo",
                "M. Sanguineti",
                "C. Santonastaso",
                "D. Santonocito",
                "P. Sapienza",
                "J. Schmelling",
                "J. Schnabel",
                "J. Schumann",
                "H. M. Schutt",
                "J. Seneca",
                "N. Sennan",
                "B. Setter",
                "I. Sgura",
                "R. Shanidze",
                "A. Sharma",
                "Y. Shitov",
                "F. Simkovic",
                "A. Simonelli",
                "A. Sinopoulou",
                "M. V. Smirnov",
                "B. Spisso",
                "M. Spurio",
                "D. Stavropoulos",
                "I. Stekl",
                "M. Taiuti",
                "Y. Tayalati",
                "H. Thiersen",
                "I. Tosta e Melo",
                "E. Tragi",
                "B. Trocme",
                "V. Tsourapis",
                "E. Tzamariudaki",
                "A. Vacheret",
                "A. Valer Melchor",
                "V. Valsecchi",
                "V. Van Elewyck",
                "G. Vannoye",
                "G. Vasileiadis",
                "F. Vazquez de Sola",
                "C. Verilhac",
                "A. Veutro",
                "S. Viola",
                "D. Vivolo",
                "J. Wilms",
                "E. de Wolf",
                "H. Yepes Ramirez",
                "G. Zarpapis",
                "S. Zavatarelli",
                "A. Zegarelli",
                "D. Zito",
                "J. D. Zornoza",
                "J. Zuniga",
                "N. Zywuck"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14872v1",
                "http://arxiv.org/pdf/2311.14872v1"
            ],
            "primary_category": "astro-ph.IM",
            "category": [
                "astro-ph.IM",
                "physics.ins-det"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14871v1",
            "title": "Tracing Influence at Scale: A Contrastive Learning Approach to Linking\n  Public Comments and Regulator Responses",
            "updated": "2023-11-24T23:32:13Z",
            "published": "2023-11-24T23:32:13Z",
            "summary": "U.S. Federal Regulators receive over one million comment letters each year\nfrom businesses, interest groups, and members of the public, all advocating for\nchanges to proposed regulations. These comments are believed to have\nwide-ranging impacts on public policy. However, measuring the impact of\nspecific comments is challenging because regulators are required to respond to\ncomments but they do not have to specify which comments they are addressing. In\nthis paper, we propose a simple yet effective solution to this problem by using\nan iterative contrastive method to train a neural model aiming for matching\ntext from public comments to responses written by regulators. We demonstrate\nthat our proposal substantially outperforms a set of selected text-matching\nbaselines on a human-annotated test set. Furthermore, it delivers performance\ncomparable to the most advanced gigantic language model (i.e., GPT-4), and is\nmore cost-effective when handling comments and regulator responses matching in\nlarger scale.",
            "author": [
                "Linzi Xing",
                "Brad Hackinen",
                "Giuseppe Carenini"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14871v1",
                "http://arxiv.org/pdf/2311.14871v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14870v1",
            "title": "Multi-scale energy homogenization for 3D printed microstructures with a\n  Diritchlet boundary condition relaxation under plastic deformation",
            "updated": "2023-11-24T23:28:46Z",
            "published": "2023-11-24T23:28:46Z",
            "summary": "The present work is a proof of concept of the capabilities of paralellization\nin the calculation of metamaterials in a non-linear regime. In this work we\nsubdivided the bulk material into subregions where the mechanical properties\nare homogenized energetically. We demonstrate that the calculation can be\nsubdivided to save RAM memory and fit the local non-linear behaviour of the\nmetamaterial. This methodology has the potentiality to be implemented in the\nparallelization of those calculations, where the right estimation of the energy\nof the local processes at every step is important.",
            "author": [
                "Antonio Tabanera",
                "Luis Saucedo-Mora",
                "Miguel Angel Sanz",
                "Francisco J. Montans"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14870v1",
                "http://arxiv.org/pdf/2311.14870v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14865v1",
            "title": "Improving Cross-Domain Hate Speech Generalizability with Emotion\n  Knowledge",
            "updated": "2023-11-24T23:00:36Z",
            "published": "2023-11-24T23:00:36Z",
            "summary": "Reliable automatic hate speech (HS) detection systems must adapt to the\nin-flow of diverse new data to curtail hate speech. However, hate speech\ndetection systems commonly lack generalizability in identifying hate speech\ndissimilar to data used in training, impeding their robustness in real-world\ndeployments. In this work, we propose a hate speech generalization framework\nthat leverages emotion knowledge in a multitask architecture to improve the\ngeneralizability of hate speech detection in a cross-domain setting. We\ninvestigate emotion corpora with varying emotion categorical scopes to\ndetermine the best corpus scope for supplying emotion knowledge to foster\ngeneralized hate speech detection. We further assess the relationship between\nusing pretrained Transformers models adapted for hate speech and its effect on\nour emotion-enriched hate speech generalization model. We perform extensive\nexperiments on six publicly available datasets sourced from different online\ndomains and show that our emotion-enriched HS detection generalization method\ndemonstrates consistent generalization improvement in cross-domain evaluation,\nincreasing generalization performance up to 18.1% and average cross-domain\nperformance up to 8.5%, according to the F1 measure.",
            "author": [
                "Shi Yin Hong",
                "Susan Gauch"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14865v1",
                "http://arxiv.org/pdf/2311.14865v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14859v1",
            "title": "An Empirical Investigation into Benchmarking Model Multiplicity for\n  Trustworthy Machine Learning: A Case Study on Image Classification",
            "updated": "2023-11-24T22:30:38Z",
            "published": "2023-11-24T22:30:38Z",
            "summary": "Deep learning models have proven to be highly successful. Yet, their\nover-parameterization gives rise to model multiplicity, a phenomenon in which\nmultiple models achieve similar performance but exhibit distinct underlying\nbehaviours. This multiplicity presents a significant challenge and necessitates\nadditional specifications in model selection to prevent unexpected failures\nduring deployment. While prior studies have examined these concerns, they focus\non individual metrics in isolation, making it difficult to obtain a\ncomprehensive view of multiplicity in trustworthy machine learning. Our work\nstands out by offering a one-stop empirical benchmark of multiplicity across\nvarious dimensions of model design and its impact on a diverse set of\ntrustworthy metrics. In this work, we establish a consistent language for\nstudying model multiplicity by translating several trustworthy metrics into\naccuracy under appropriate interventions. We also develop a framework, which we\ncall multiplicity sheets, to benchmark multiplicity in various scenarios. We\ndemonstrate the advantages of our setup through a case study in image\nclassification and provide actionable insights into the impact and trends of\ndifferent hyperparameters on model multiplicity. Finally, we show that\nmultiplicity persists in deep learning models even after enforcing additional\nspecifications during model selection, highlighting the severity of\nover-parameterization. The concerns of under-specification thus remain, and we\nseek to promote a more comprehensive discussion of multiplicity in trustworthy\nmachine learning.",
            "author": [
                "Prakhar Ganesh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14859v1",
                "http://arxiv.org/pdf/2311.14859v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14858v1",
            "title": "Enhanced MIMO-DCT-OFDM System Using Cosine Domain Equalizer",
            "updated": "2023-11-24T22:25:38Z",
            "published": "2023-11-24T22:25:38Z",
            "summary": "Discrete Cosine Transform (DCT) can be used instead of conventional Discrete\nFourier Transform (DFT) for the Orthogonal Frequency Division Multiplexing\n(OFDM) construction, which offers many advantages. In this paper, the\nMultiple-Input-Multiple-Output (MIMO) DCT-OFDM is enhanced using a proposed\nCosine Domain Equalizer (CDE) instead of a Frequency Domain Equalizer (FDE).\nThe results are evaluated through the Rayleigh fading channel with Co-Carrier\nFrequency Offset (Co-CFO) of different MIMO configurations. The average bit\nerror probability and the simulated time of the proposed scheme and the\nconventional one is compared, which indicates the importance of the proposed\nscheme. Also, a closed formula for the number of arithmetic operations of the\nproposed equalizer is developed. The proposed equalizer gives a simulation time\nreduction of about 81.21%, 83.74% compared to that of the conventional LZF-FDE,\nand LMMSE-FDE, respectively for the case of 4x4 configuration.",
            "author": [
                "Khaled Ramadan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14858v1",
                "http://arxiv.org/pdf/2311.14858v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "cs.PF",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.00805v1",
            "title": "Gender inference: can chatGPT outperform common commercial tools?",
            "updated": "2023-11-24T22:09:14Z",
            "published": "2023-11-24T22:09:14Z",
            "summary": "An increasing number of studies use gender information to understand\nphenomena such as gender bias, inequity in access and participation, or the\nimpact of the Covid pandemic response. Unfortunately, most datasets do not\ninclude self-reported gender information, making it necessary for researchers\nto infer gender from other information, such as names or names and country\ninformation. An important limitation of these tools is that they fail to\nappropriately capture the fact that gender exists on a non-binary scale,\nhowever, it remains important to evaluate and compare how well these tools\nperform in a variety of contexts. In this paper, we compare the performance of\na generative Artificial Intelligence (AI) tool ChatGPT with three commercially\navailable list-based and machine learning-based gender inference tools (Namsor,\nGender-API, and genderize.io) on a unique dataset. Specifically, we use a large\nOlympic athlete dataset and report how variations in the input (e.g., first\nname and first and last name, with and without country information) impact the\naccuracy of their predictions. We report results for the full set, as well as\nfor the subsets: medal versus non-medal winners, athletes from the largest\nEnglish-speaking countries, and athletes from East Asia. On these sets, we find\nthat Namsor is the best traditional commercially available tool. However,\nChatGPT performs at least as well as Namsor and often outperforms it,\nespecially for the female sample when country and/or last name information is\navailable. All tools perform better on medalists versus non-medalists and on\nnames from English-speaking countries. Although not designed for this purpose,\nChatGPT may be a cost-effective tool for gender prediction. In the future, it\nmight even be possible for ChatGPT or other large scale language models to\nbetter identify self-reported gender rather than report gender on a binary\nscale.",
            "author": [
                "Michelle Alexopoulos",
                "Kelly Lyons",
                "Kaushar Mahetaji",
                "Marcus Emmanuel Barnes",
                "Rogan Gutwillinger"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00805v1",
                "http://arxiv.org/pdf/2312.00805v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14852v1",
            "title": "Self-aligned photonic defect microcavities with site-controlled quantum\n  dots",
            "updated": "2023-11-24T22:04:07Z",
            "published": "2023-11-24T22:04:07Z",
            "summary": "Despite the superiority in quantum properties, self-assembled semiconductor\nquantum dots face challenges in terms of scalable device integration because of\ntheir random growth positions, originating from the Stranski-Krastanov growth\nmode. Even with existing site-controlled growth techniques, for example,\nnanohole or buried stressor concepts, a further lithography and etching step\nwith high spatial alignment requirements isnecessary to accurately integrate\nQDs into the nanophotonic devices. Here, we report on the fabrication and\ncharacterization of strain-induced site-controlled microcavities where\nsite-controlled quantum dots are positioned at the antinode of the optical mode\nfield in a self-aligned manner without the need of any further nano-processing.\nWe show that the Q-factor, mode volume, height, and the ellipticity of\nsite-controlled microcavities can be tailored by the size of an integrated\nAlAs/Al2O3 buried stressor, with an opening ranging from 1 to 4 $\\mu$m. Lasing\nsignatures, including super-linear input-output response, linewidth narrowing\nnear threshold, and gain competition above threshold, are observed for a\n3.6-$\\mu$m self-aligned cavity with a Q-factor of 18000. Furthermore, by\nwaiving the rather complex lateral nano-structuring usually performed during\nthe fabrication process of micropillar lasers and vertical-cavity surface\nemitting lasers, quasi-planar site-controlled cavities exhibit no detrimental\neffects of excitation power induced heating and thermal rollover. Our\nstraightforward deterministic nanofabrication concept of high-quality quantum\ndot microcavities integrates seamlessly with the industrial-matured\nmanufacturing process and the buried-stressor techniques, paving the way for\nexceptional scalability and straightforward manufacturing of high-\\b{eta}\nmicrolasers and bright quantum light sources.",
            "author": [
                "C. -W. Shih",
                "I. Limame",
                "C. C. Palekar",
                "A. Koulas-Simos",
                "A. Kaganskiy",
                "P. Klenovsk\u00fd",
                "S. Reitzenstein"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14852v1",
                "http://arxiv.org/pdf/2311.14852v1"
            ],
            "primary_category": "cond-mat.mes-hall",
            "category": [
                "cond-mat.mes-hall",
                "physics.optics"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14851v1",
            "title": "Unified Medical Image Pre-training in Language-Guided Common Semantic\n  Space",
            "updated": "2023-11-24T22:01:12Z",
            "published": "2023-11-24T22:01:12Z",
            "summary": "Vision-Language Pre-training (VLP) has shown the merits of analysing medical\nimages, by leveraging the semantic congruence between medical images and their\ncorresponding reports. It efficiently learns visual representations, which in\nturn facilitates enhanced analysis and interpretation of intricate imaging\ndata. However, such observation is predominantly justified on single-modality\ndata (mostly 2D images like X-rays), adapting VLP to learning unified\nrepresentations for medical images in real scenario remains an open challenge.\nThis arises from medical images often encompass a variety of modalities,\nespecially modalities with different various number of dimensions (e.g., 3D\nimages like Computed Tomography). To overcome the aforementioned challenges, we\npropose an Unified Medical Image Pre-training framework, namely UniMedI, which\nutilizes diagnostic reports as common semantic space to create unified\nrepresentations for diverse modalities of medical images (especially for 2D and\n3D images). Under the text's guidance, we effectively uncover visual modality\ninformation, identifying the affected areas in 2D X-rays and slices containing\nlesion in sophisticated 3D CT scans, ultimately enhancing the consistency\nacross various medical imaging modalities. To demonstrate the effectiveness and\nversatility of UniMedI, we evaluate its performance on both 2D and 3D images\nacross 10 different datasets, covering a wide range of medical image tasks such\nas classification, segmentation, and retrieval. UniMedI has demonstrated\nsuperior performance in downstream tasks, showcasing its effectiveness in\nestablishing a universal medical visual representation.",
            "author": [
                "Xiaoxuan He",
                "Yifan Yang",
                "Xinyang Jiang",
                "Xufang Luo",
                "Haoji Hu",
                "Siyun Zhao",
                "Dongsheng Li",
                "Yuqing Yang",
                "Lili Qiu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14851v1",
                "http://arxiv.org/pdf/2311.14851v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14847v1",
            "title": "Experimental and numerical study of a second-order transition in the\n  behavior of confined self-propelled particles",
            "updated": "2023-11-24T21:32:29Z",
            "published": "2023-11-24T21:32:29Z",
            "summary": "In this study, we conduct experimental investigations on the behavior of\nconfined self-propelled particles within a circular arena, employing small\ncommercial robots capable of locomotion, communication, and information\nprocessing. These robots execute circular trajectories, which can be clockwise\nor counterclockwise, based on two internal states. Using a majority-based\nstochastic decision algorithm, each robot can reverse its direction based on\nthe states of two neighboring robots. By manipulating a control parameter\ngoverning the interaction, the system exhibits a transition-from a state where\nall robots rotate randomly to one where they rotate uniformly in the same\ndirection. Moreover, this transition significantly impacts the trajectories of\nthe robots. To extend our findings to larger systems, we introduce a\nmathematical model enabling characterization of the order transition type and\nthe resulting trajectories. Our results reveal a second-order transition from\nactive Brownian to chiral motion. Lastly, we analyze the particle density\nwithin the arena, examining how it varies concerning system size and the\ncontrol parameter.",
            "author": [
                "E. Barone",
                "G. A. Patterson"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14847v1",
                "http://arxiv.org/pdf/2311.14847v1"
            ],
            "primary_category": "cond-mat.other",
            "category": [
                "cond-mat.other",
                "cond-mat.soft"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14843v1",
            "title": "Unveiling the 3D structure of nova shells with MUSE -- The case of RR\n  Pic",
            "updated": "2023-11-24T20:52:30Z",
            "published": "2023-11-24T20:52:30Z",
            "summary": "Nova eruptions occur in cataclysmic variables when enough material has been\naccreted onto the surface of the white dwarf primary. As a consequence, the\nmaterial that has been accumulated until then is expelled into the interstellar\nmedium, forming an expanding nova shell around the system. Understanding the\nphysical process that shapes the morphology of nova shells is essential to\nfully comprehend how the ejection mechanism operates during nova eruptions.\nBecause of its closeness and age, the nova shell around the classical nova RR\nPic (Nova Pic 1925) is an ideal target for studying the evolving morphology of\nnova shells. In this work, we present an IFS study of the RR Pic nova shell,\nwith a particular emphasis on the extraction of the 3D morphology of the shell.\nThe nova shell was observed by the Multi-Unit Spectroscopic Explorer (MUSE)\ninstrument placed at the ESO-VLT. The MUSE datacube confirms the presence of\nthe nova shell in H$\\rm\\alpha$, H$\\rm\\beta$ and [OIII], and very faintly in\n[NII]. A comparison with previous observations suggests that the shell\ncontinues in its free-expansion phase but with the different parts of the shell\napparently expanding at different rates. The data analysis corroborates the\nprevious vision that the shell is composed of an equatorial ring and polar\nfilaments. At the same time, the new data also reveal that [OIII] is confined\nin gaps located in the tropical regions of the shell where no Hydrogen is\nobserved. The flux measurements indicate that ~99% of the shell flux is\nconfined to the equatorial ring, while the polar filaments show a flux\nasymmetry between the NE and SW filaments. We have estimated the mass of the\nshell to be ~5x10$^{-5}$M$_\\odot$. From the analysis of the 3D-extracted data,\nwe determine that the ring structure extends ~8,000 au from the central binary,\nand has a position angle of ~155 deg and an inclination of ~74 deg.",
            "author": [
                "Lientur Celed\u00f3n",
                "Linda Schmidtobreick",
                "Claus Tappert",
                "Fernando Selman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14843v1",
                "http://arxiv.org/pdf/2311.14843v1"
            ],
            "primary_category": "astro-ph.SR",
            "category": [
                "astro-ph.SR",
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14840v1",
            "title": "Control of Equalization of Invariants",
            "updated": "2023-11-24T20:39:53Z",
            "published": "2023-11-24T20:39:53Z",
            "summary": "A new class of control problems is discussed - homeostasis control.\nHomeostasis control problems can be considered as control problems with a given\ntarget set, in particular, as a problem of stabilizing the values of some\ntarget function, which is an invariant of the control free system. The report\nexamines a more general class: equalizing the values of two or more objective\nfunctions, each of which is an invariant of the corresponding subsystem of a\ncomplex system. An approach to the design of control algorithms based on the\nspeed gradient method is proposed and the conditions for the pplicability of\nthe approach are established.",
            "author": [
                "Alexander Fradkov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14840v1",
                "http://arxiv.org/pdf/2311.14840v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14838v1",
            "title": "OpusCleaner and OpusTrainer, open source toolkits for training Machine\n  Translation and Large language models",
            "updated": "2023-11-24T20:24:00Z",
            "published": "2023-11-24T20:24:00Z",
            "summary": "Developing high quality machine translation systems is a labour intensive,\nchallenging and confusing process for newcomers to the field. We present a pair\nof tools OpusCleaner and OpusTrainer that aim to simplify the process, reduce\nthe amount of work and lower the entry barrier for newcomers.\n  OpusCleaner is a data downloading, cleaning, and proprocessing toolkit. It is\ndesigned to allow researchers to quickly download, visualise and preprocess\nbilingual (or monolingual) data that comes from many different sources, each of\nthem with different quality, issues, and unique filtering/preprocessing\nrequirements.\n  OpusTrainer is a data scheduling and data augmenting tool aimed at building\nlarge scale, robust machine translation systems and large language models. It\nfeatures deterministic data mixing from many different sources, on-the-fly data\naugmentation and more.\n  Using these tools, we showcase how we can use it to create high quality\nmachine translation model robust to noisy user input; multilingual models and\nterminology aware models.",
            "author": [
                "Nikolay Bogoychev",
                "Jelmer van der Linde",
                "Graeme Nail",
                "Barry Haddow",
                "Jaume Zaragoza-Bernabeu",
                "Gema Ram\u00edrez-S\u00e1nchez",
                "Lukas Weymann",
                "Tudor Nicolae Mateiu",
                "Jind\u0159ich Helcl",
                "Mikko Aulamo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14838v1",
                "http://arxiv.org/pdf/2311.14838v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14837v2",
            "title": "Benchmarking Robustness of Text-Image Composed Retrieval",
            "updated": "2023-11-30T18:14:48Z",
            "published": "2023-11-24T20:16:38Z",
            "summary": "Text-image composed retrieval aims to retrieve the target image through the\ncomposed query, which is specified in the form of an image plus some text that\ndescribes desired modifications to the input image. It has recently attracted\nattention due to its ability to leverage both information-rich images and\nconcise language to precisely express the requirements for target images.\nHowever, the robustness of these approaches against real-world corruptions or\nfurther text understanding has never been studied. In this paper, we perform\nthe first robustness study and establish three new diversified benchmarks for\nsystematic analysis of text-image composed retrieval against natural\ncorruptions in both vision and text and further probe textural understanding.\nFor natural corruption analysis, we introduce two new large-scale benchmark\ndatasets, CIRR-C and FashionIQ-C for testing in open domain and fashion domain\nrespectively, both of which apply 15 visual corruptions and 7 textural\ncorruptions. For textural understanding analysis, we introduce a new diagnostic\ndataset CIRR-D by expanding the original raw data with synthetic data, which\ncontains modified text to better probe textual understanding ability including\nnumerical variation, attribute variation, object removal, background variation,\nand fine-grained evaluation. The code and benchmark datasets are available at\nhttps://github.com/SunTongtongtong/Benchmark-Robustness-Text-Image-Compose-Retrieval.",
            "author": [
                "Shitong Sun",
                "Jindong Gu",
                "Shaogang Gong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14837v2",
                "http://arxiv.org/pdf/2311.14837v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14836v2",
            "title": "Custom Data Augmentation for low resource ASR using Bark and\n  Retrieval-Based Voice Conversion",
            "updated": "2023-12-02T20:42:10Z",
            "published": "2023-11-24T20:16:29Z",
            "summary": "This paper proposes two innovative methodologies to construct customized\nCommon Voice datasets for low-resource languages like Hindi. The first\nmethodology leverages Bark, a transformer-based text-to-audio model developed\nby Suno, and incorporates Meta's enCodec and a pre-trained HuBert model to\nenhance Bark's performance. The second methodology employs Retrieval-Based\nVoice Conversion (RVC) and uses the Ozen toolkit for data preparation. Both\nmethodologies contribute to the advancement of ASR technology and offer\nvaluable insights into addressing the challenges of constructing customized\nCommon Voice datasets for under-resourced languages. Furthermore, they provide\na pathway to achieving high-quality, personalized voice generation for a range\nof applications.",
            "author": [
                "Anand Kamble",
                "Aniket Tathe",
                "Suyash Kumbharkar",
                "Atharva Bhandare",
                "Anirban C. Mitra"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14836v2",
                "http://arxiv.org/pdf/2311.14836v2"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.CL",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14835v2",
            "title": "Weak Alignment Supervision from Hybrid Model Improves End-to-end ASR",
            "updated": "2023-11-30T20:18:56Z",
            "published": "2023-11-24T20:14:28Z",
            "summary": "In this paper, we aim to create weak alignment supervision from an existing\nhybrid system to aid the end-to-end modeling of automatic speech recognition.\nTowards this end, we use the existing hybrid ASR system to produce triphone\nalignments of the training audios. We then create a cross-entropy loss at a\ncertain layer of the encoder using the derived alignments. In contrast to the\ngeneral one-hot cross-entropy losses, here we use a cross-entropy loss with a\nlabel smoothing parameter to regularize the supervision. As a comparison, we\nalso conduct the experiments with one-hot cross-entropy losses and CTC losses\nwith loss weighting. The results show that placing the weak alignment\nsupervision with the label smoothing parameter of 0.5 at the third encoder\nlayer outperforms the other two approaches and leads to about 5\\% relative WER\nreduction on the TED-LIUM 2 dataset over the baseline. We see similar\nimprovements when applying the method out-of-the-box on a Tagalog end-to-end\nASR system.",
            "author": [
                "Jintao Jiang",
                "Yingbo Gao",
                "Zoltan Tuske"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14835v2",
                "http://arxiv.org/pdf/2311.14835v2"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.CL",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14834v2",
            "title": "The MIP Workshop 2023 Computational Competition on Reoptimization",
            "updated": "2023-11-29T10:07:22Z",
            "published": "2023-11-24T20:12:30Z",
            "summary": "This paper describes the computational challenge developed for a\ncomputational competition held in 2023 for the $20^{\\textrm{th}}$ anniversary\nof the Mixed Integer Programming Workshop. The topic of this competition was\nreoptimization, also known as warm starting, of mixed integer linear\noptimization problems after slight changes to the input data for a common\nformulation. The challenge was to accelerate the proof of optimality of the\nmodified instances by leveraging the information from the solving processes of\npreviously solved instances, all while creating high-quality primal solutions.\nSpecifically, we discuss the competition's format, the creation of public and\nhidden datasets, and the evaluation criteria. Our goal is to establish a\nmethodology for the generation of benchmark instances and an evaluation\nframework, along with benchmark datasets, to foster future research on\nreoptimization of mixed integer linear optimization problems.",
            "author": [
                "Suresh Bolusani",
                "Mathieu Besan\u00e7on",
                "Ambros Gleixner",
                "Timo Berthold",
                "Claudia D'Ambrosio",
                "Gonzalo Mu\u00f1oz",
                "Joseph Paat",
                "Dimitri Thomopulos"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14834v2",
                "http://arxiv.org/pdf/2311.14834v2"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "90-08, 90C11, 90C57"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14831v1",
            "title": "Study of MMSE-Based Resource Allocation for Clustered Cell-Free Massive\n  MIMO Networks",
            "updated": "2023-11-24T20:00:43Z",
            "published": "2023-11-24T20:00:43Z",
            "summary": "In this paper, a downlink cell-free massive multiple-input multiple-output\n(CF massive MIMO) system and a network clustering is considered. Closed form\nsum-rate expressions are derived for CF and the clustered CF (CLCF) networks\nwhere linear precoders included zero forcing (ZF) and minimum mean square error\n(MMSE) are implemented. An MMSE-based resource allocation technique with\nmultiuser scheduling based on an enhanced greedy technique and power allocation\nbased on the gradient descent (GD) method is proposed in the CLCF network to\nimprove the system performance. Numerical results show that the proposed\ntechnique is superior to the existing approaches and the computational cost and\nthe signaling load are essentially reduced in the CLCF network.",
            "author": [
                "S. Mashdour",
                "R. C. de Lamare"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14831v1",
                "http://arxiv.org/pdf/2311.14831v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14830v1",
            "title": "Active galaxy nuclei: current state of the problem",
            "updated": "2023-11-24T19:57:43Z",
            "published": "2023-11-24T19:57:43Z",
            "summary": "This review presents the main points of current advances in the field of\nactive galactic nuclei (AGN). A brief historical excursion about the search for\nthe nature of AGN is given. The problem of close binary systems consisting of\nsupermassive black holes located in the centers of galaxies is discussed in\ndetails. The main characteristics, as well as new methods for studying and\n``weighing'' these new objects, are described. This paper is based on a\npresentation made in the astrophysical seminar, which dedicated to the memory\nof the outstanding astrophysicist N.G. Bochkarev (took place on May 19, 2023 at\nthe Sternberg Astronomical Institute of Moscow State University).",
            "author": [
                "Elena Seifina"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14830v1",
                "http://arxiv.org/pdf/2311.14830v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA",
                "F.2.2"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14829v2",
            "title": "Proximal Algorithms for Accelerated Langevin Dynamics",
            "updated": "2023-11-28T15:27:26Z",
            "published": "2023-11-24T19:56:01Z",
            "summary": "We develop a novel class of MCMC algorithms based on a stochastized Nesterov\nscheme. With an appropriate addition of noise, the result is a\ntime-inhomogeneous underdamped Langevin equation, which we prove emits a\nspecified target distribution as its invariant measure. Convergence rates to\nstationarity under Wasserstein-2 distance are established as well.\nMetropolis-adjusted and stochastic gradient versions of the proposed Langevin\ndynamics are also provided. Experimental illustrations show superior\nperformance of the proposed method over typical Langevin samplers for different\nmodels in statistics and image processing including better mixing of the\nresulting Markov chains.",
            "author": [
                "Duy H. Thai",
                "Alexander L. Young",
                "David B. Dunson"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14829v2",
                "http://arxiv.org/pdf/2311.14829v2"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14828v1",
            "title": "Deep Latent Force Models: ODE-based Process Convolutions for Bayesian\n  Deep Learning",
            "updated": "2023-11-24T19:55:57Z",
            "published": "2023-11-24T19:55:57Z",
            "summary": "Effectively modeling phenomena present in highly nonlinear dynamical systems\nwhilst also accurately quantifying uncertainty is a challenging task, which\noften requires problem-specific techniques. We outline the deep latent force\nmodel (DLFM), a domain-agnostic approach to tackling this problem, which\nconsists of a deep Gaussian process architecture where the kernel at each layer\nis derived from an ordinary differential equation using the framework of\nprocess convolutions. Two distinct formulations of the DLFM are presented which\nutilise weight-space and variational inducing points-based Gaussian process\napproximations, both of which are amenable to doubly stochastic variational\ninference. We provide evidence that our model is capable of capturing highly\nnonlinear behaviour in real-world multivariate time series data. In addition,\nwe find that our approach achieves comparable performance to a number of other\nprobabilistic models on benchmark regression tasks. We also empirically assess\nthe negative impact of the inducing points framework on the extrapolation\ncapabilities of LFM-based models.",
            "author": [
                "Thomas Baldwin-McDonald",
                "Mauricio A. \u00c1lvarez"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14828v1",
                "http://arxiv.org/pdf/2311.14828v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14826v1",
            "title": "Quantum tunnelling without a barrier",
            "updated": "2023-11-24T19:50:49Z",
            "published": "2023-11-24T19:50:49Z",
            "summary": "Tunnelling is a renowned concept in modern physics that highlights the\npeculiarity of non-classical dynamics. Despite its ubiquity questions remain.\nWe focus on tunnelling through the barrier created by a strong laser field that\nilluminates an atomic target, which is essential to the creation of attosecond\npulses and ultimately all attosecond processes. Here, we present an optical\ntunnelling event that, unexpectedly, happens at a time when the instantaneous\nelectric field is zero and there is no barrier. We discover this strong-field\nionisation event by introducing the colour-switchover technique $-$ the gradual\nreplacement of a laser field with its second harmonic $-$ within which the\nzero-field tunnelling appears when the two amplitudes are equal. This event is\na topologically stable feature and it appears at all Keldysh parameters. The\ntunnelling without a barrier highlights the disconnect between the standard\nintuition built on the picture of a quasi-static barrier, and the nonadiabatic\nnature of the process. Our findings provide a key ingredient to the\nunderstanding of strong-field processes, such as high-harmonic generation and\nlaser-induced electron diffraction, driven by the increasingly accessible class\nof strongly polychromatic light fields.",
            "author": [
                "Anne Weber",
                "Margarita Khokhlova",
                "Emilio Pisanty"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14826v1",
                "http://arxiv.org/pdf/2311.14826v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "physics.atom-ph",
                "physics.optics"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14824v1",
            "title": "A Reusable AI-Enabled Defect Detection System for Railway Using\n  Ensembled CNN",
            "updated": "2023-11-24T19:45:55Z",
            "published": "2023-11-24T19:45:55Z",
            "summary": "Accurate Defect detection is crucial for ensuring the trustworthiness of\nintelligent railway systems. Current approaches rely on single deep-learning\nmodels, like CNNs, which employ a large amount of data to capture underlying\npatterns. Training a new defect classifier with limited samples often leads to\noverfitting and poor performance on unseen images. To address this, researchers\nhave advocated transfer learning and fine-tuning the pre-trained models.\nHowever, using a single backbone network in transfer learning still may cause\nbottleneck issues and inconsistent performance if it is not suitable for a\nspecific problem domain. To overcome these challenges, we propose a reusable\nAI-enabled defect detection approach. By combining ensemble learning with\ntransfer learning models (VGG-19, MobileNetV3, and ResNet-50), we improved the\nclassification accuracy and achieved consistent performance at a certain phase\nof training. Our empirical analysis demonstrates better and more consistent\nperformance compared to other state-of-the-art approaches. The consistency\nsubstantiates the reusability of the defect detection system for newly evolved\ndefected rail parts. Therefore we anticipate these findings to benefit further\nresearch and development of reusable AI-enabled solutions for railway systems.",
            "author": [
                "Rahatara Ferdousi",
                "Fedwa Laamarti",
                "Chunsheng Yang",
                "Abdulmotaleb El Saddik"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14824v1",
                "http://arxiv.org/pdf/2311.14824v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG",
                "68T45, 68T05",
                "I.2.10; I.5.2"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14822v1",
            "title": "Text and Click inputs for unambiguous open vocabulary instance\n  segmentation",
            "updated": "2023-11-24T19:37:57Z",
            "published": "2023-11-24T19:37:57Z",
            "summary": "Segmentation localizes objects in an image on a fine-grained per-pixel scale.\nSegmentation benefits by humans-in-the-loop to provide additional input of\nobjects to segment using a combination of foreground or background clicks.\nTasks include photoediting or novel dataset annotation, where human annotators\nleverage an existing segmentation model instead of drawing raw pixel level\nannotations. We propose a new segmentation process, Text + Click segmentation,\nwhere a model takes as input an image, a text phrase describing a class to\nsegment, and a single foreground click specifying the instance to segment.\nCompared to previous approaches, we leverage open-vocabulary image-text models\nto support a wide-range of text prompts. Conditioning segmentations on text\nprompts improves the accuracy of segmentations on novel or unseen classes. We\ndemonstrate that the combination of a single user-specified foreground click\nand a text prompt allows a model to better disambiguate overlapping or\nco-occurring semantic categories, such as \"tie\", \"suit\", and \"person\". We study\nthese results across common segmentation datasets such as refCOCO, COCO, VOC,\nand OpenImages. Source code available here.",
            "author": [
                "Nikolai Warner",
                "Meera Hahn",
                "Jonathan Huang",
                "Irfan Essa",
                "Vighnesh Birodkar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14822v1",
                "http://arxiv.org/pdf/2311.14822v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14816v1",
            "title": "Learning Arousal-Valence Representation from Categorical Emotion Labels\n  of Speech",
            "updated": "2023-11-24T19:23:37Z",
            "published": "2023-11-24T19:23:37Z",
            "summary": "Dimensional representations of speech emotions such as the arousal-valence\n(AV) representation provide a continuous and fine-grained description and\ncontrol than their categorical counterparts. They have wide applications in\ntasks such as dynamic emotion understanding and expressive text-to-speech\nsynthesis. Existing methods that predict the dimensional emotion representation\nfrom speech cast it as a supervised regression task. These methods face data\nscarcity issues, as dimensional annotations are much harder to acquire than\ncategorical labels. In this work, we propose to learn the AV representation\nfrom categorical emotion labels of speech. We start by learning a rich and\nemotion-relevant high-dimensional speech feature representation using\nself-supervised pre-training and emotion classification fine-tuning. This\nrepresentation is then mapped to the 2D AV space according to psychological\nfindings through anchored dimensionality reduction. Experiments show that our\nmethod achieves a Concordance Correlation Coefficient (CCC) performance\ncomparable to state-of-the-art supervised regression methods on IEMOCAP without\nleveraging ground-truth AV annotations during training. This validates our\nproposed approach on AV prediction. Furthermore, visualization of AV\npredictions on MEAD and EmoDB datasets shows the interpretability of the\nlearned AV representations.",
            "author": [
                "Enting Zhou",
                "You Zhang",
                "Zhiyao Duan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14816v1",
                "http://arxiv.org/pdf/2311.14816v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14815v1",
            "title": "Geometric theory on large-scale and local determination of density\n  dependence of a recovering large carnivore population",
            "updated": "2023-11-24T19:18:43Z",
            "published": "2023-11-24T19:18:43Z",
            "summary": "Density-dependent population growth is a feature of large carnivores like\nwolves ($\\textit{Canis lupus}$), with mechanisms typically attributed to\nresource (e.g. prey) limitation. Such mechanisms are local phenomena and rely\non individuals having access to information, such as prey availability at their\nlocation. Using over four decades of wolf population and range expansion data\nfrom Wisconsin (USA) wolves, we found that the population not only exhibited\ndensity dependence locally but also at landscape scale. Superficially, one may\nconsider space as yet another limiting resource to explain landscape-scale\ndensity dependence. However, this view poses an information puzzle: most\nindividuals do not have access to global information such as range-wide habitat\navailability as they would for local prey availability. How would the\npopulation \"know\" when to slow their range expansion? To understand observed\nlarge-scale spatial density dependence, we propose a reaction-diffusion model,\nfirst introduced by Fisher and Kolmogorov, with a \"travelling wave\" solution,\nwherein the population expands from a core range that quickly achieves local\ncarrying capacity. Early-stage acceleration and later-stage deceleration of\npopulation growth can be explained by early elongation of an expanding frontier\nand a later collision of the expanding frontier with a habitat boundary. Such a\nprocess does not require individuals to have global density information. We\nillustrate our proposal with simulations and spatial visualizations of wolf\nrecolonization in the western Great Lakes region over time relative to habitat\nsuitability. We further synthesize previous studies on wolf habitat selection\nin the western Great Lakes region and argue that the habitat boundary appeared\nto be driven by spatial variation in mortality, likely associated with human\nuse of the landscape.",
            "author": [
                "Yunyi Shen",
                "Erik R. Olson",
                "Timothy R. Van Deelen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14815v1",
                "http://arxiv.org/pdf/2311.14815v1"
            ],
            "primary_category": "q-bio.PE",
            "category": [
                "q-bio.PE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14812v1",
            "title": "Robust Joint Estimation of Galaxy Redshift and Spectral Templates using\n  Online Dictionary Learning",
            "updated": "2023-11-24T19:09:26Z",
            "published": "2023-11-24T19:09:26Z",
            "summary": "We present a novel approach to analyzing astronomical spectral survey data\nusing our non-linear extension of an online dictionary learning algorithm.\nCurrent and upcoming surveys such as SPHEREx will use spectral data to build a\n3D map of the universe by estimating the redshifts of millions of galaxies.\nExisting algorithms rely on hand-curated external templates and have limited\nperformance due to model mismatch error. Our algorithm addresses this\nlimitation by jointly estimating both the underlying spectral features in\ncommon across the entire dataset, as well as the redshift of each galaxy. Our\nonline approach scales well to large datasets since we only process a single\nspectrum in memory at a time. Our algorithm performs better than a\nstate-of-the-art existing algorithm when analyzing a mock SPHEREx dataset,\nachieving a NMAD standard deviation of 0.18% and a catastrophic error rate of\n0.40% when analyzing noiseless data. Our algorithm also performs well over a\nwide range of signal to noise ratios (SNR), delivering sub-percent NMAD and\ncatastrophic error above median SNR of 20. We released our algorithm publicly\nat github.com/HyperspectralDictionaryLearning/BryanEtAl2023 .",
            "author": [
                "Sean Bryan",
                "Ayan Barekzai",
                "Delondrae Carter",
                "Philip Mauskopf",
                "Julian Mena",
                "Danielle Rivera",
                "Abel S. Uriarte",
                "Pao-Yu Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14812v1",
                "http://arxiv.org/pdf/2311.14812v1"
            ],
            "primary_category": "astro-ph.IM",
            "category": [
                "astro-ph.IM",
                "astro-ph.CO",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14809v1",
            "title": "JWST and ALMA discern the assembly of structural and obscured components\n  in a high-redshift starburst galaxy",
            "updated": "2023-11-24T19:06:16Z",
            "published": "2023-11-24T19:06:16Z",
            "summary": "We present observations and analysis of the starburst, PACS-819, at z=1.45\n($M_*=10^{10.7}$ M$_{ \\odot}$), using high-resolution ($0^{\\prime \\prime}.1$;\n0.8 kpc) ALMA and multi-wavelength JWST images from the COSMOS-Web program.\nDissimilar to HST/ACS images in the rest-frame UV, the redder NIRCam and MIRI\nimages reveal a smooth central mass concentration and spiral-like features,\natypical for such an intense starburst. Through dynamical modeling of the CO\nJ=5--4 emission with ALMA, PACS-819 is rotation-dominated thus has a disk-like\nnature. However, kinematic anomalies in CO and asymmetric features in the bluer\nJWST bands (e.g., F150W) support a more disturbed nature likely due to\ninteractions. The JWST imaging further enables us to map the distribution of\nstellar mass and dust attenuation, thus clarifying the relationships between\ndifferent structural components, not discernable in the previous HST images.\nThe CO J = 5 -- 4 and FIR dust continuum emission are co-spatial with a\nheavily-obscured starbursting core (<1 kpc) which is partially surrounded by\nmuch less obscured star-forming structures including a prominent arc, possibly\na tidally-distorted dwarf galaxy, and a clump, either a sign of an ongoing\nviolent disk instability or a recently accreted low-mass satellite. With\nspatially-resolved maps, we find a high molecular gas fraction in the central\narea reaching $\\sim3$ ($M_{\\text{gas}}$/$M_*$) and short depletion times\n($M_{\\text{gas}}/SFR\\sim$ 120 Myrs) across the entire system. These\nobservations provide insights into the complex nature of starbursts in the\ndistant universe and underscore the wealth of complementary information from\nhigh-resolution observations with both ALMA and JWST.",
            "author": [
                "Zhaoxuan Liu",
                "John D. Silverman",
                "Emanuele Daddi",
                "Annagrazia Puglisi",
                "Alvio Renzini",
                "Boris S. Kalita",
                "Jeyhan S. Kartaltepe",
                "Daichi Kashino",
                "Giulia Rodighiero",
                "Wiphu Rujopakarn",
                "Tomoko L. Suzuki",
                "Takumi S. Tanaka",
                "Francesco Valentino",
                "Irham Taufik Andika",
                "Caitlin M. Casey",
                "Andreas Faisst",
                "Maximilien Franco",
                "Ghassem Gozaliasl",
                "Steven Gillman",
                "Christopher C. Hayward",
                "Anton M. Koekemoer",
                "Vasily Kokorev",
                "Erini Lambrides",
                "Minju M. Lee",
                "Georgios E. Magdis",
                "Santosh Harish",
                "Henry Joy McCracken",
                "Jason Rhodes",
                "Marko Shuntov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14809v1",
                "http://arxiv.org/pdf/2311.14809v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14808v1",
            "title": "Data-to-Text Bilingual Generation",
            "updated": "2023-11-24T19:05:57Z",
            "published": "2023-11-24T19:05:57Z",
            "summary": "This document illustrates the use of pyrealb for generating two parallel\ntexts (English and French) from a single source of data. The data selection and\ntext organisation processes are shared between the two languages. only language\ndependent word and phrasing choices are distinct processes. The realized texts\nthus convey identical information in both languages without the risk of being\nlost in translation. This is especially important in cases where strict and\nsimultaneous bilingualism is required. We first present the types of\napplications targeted by this approach and how the pyrealb English and French\nrealizer can be used for achieving this goal in a natural way. We describe an\nobject-oriented organization to ensure a convenient realization in both\nlanguages. To illustrate the process, different types of applications are then\nbriefly sketched with links to the source code. A brief comparison of the text\ngeneration is given with the output of an instance of a GPT.",
            "author": [
                "Guy Lapalme"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14808v1",
                "http://arxiv.org/pdf/2311.14808v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14807v1",
            "title": "Multifractal detrended fluctuation analysis of rainfall time series in\n  the Guadeloupe archipelago",
            "updated": "2023-11-24T19:03:38Z",
            "published": "2023-11-24T19:03:38Z",
            "summary": "Due to the vulnerability of the Caribbean islands to the climate change\nissue, it is important to investigate the behavior of rainfall. In addition,\nthe soil of the French West Indies Islands has been contaminated by an\ninsecticide (Chlordecone) whose decontamination is mainly done by drainage\nwater. Thus, it is crucial to investigate the fluctuations of rainfall in these\ncomplex environments. In this study, 19 daily rainfall series recorded in\ndifferent stations of Guadeloupe archipelago from 2005 to 2014 were analyzed\nwith the multifractal detrended fluctuation analysis (MF-DFA) method. The aim\nof this work is to characterize the long-range correlations and multifractal\nproperties of the time series and to find geographical patterns over the three\nmost important islands. This is the first study that addresses the analysis of\nmultifractal properties of rainfall series in the Caribbean islands. This\nregion is typically characterized by the almost constant influence of the trade\nwinds and a high exposure to changes in the general atmospheric circulation. 12\nstations exhibit two different power-law scaling regions in rainfall series,\nwith distinct long-range correlations and multifractal properties for large and\nsmall scales. On the contrary, the rest of stations only show a single region\nof scales for relatively small scales. Hurst exponents reveal persistent\nlong-range correlations. In the most eastern analyzed areas, larger scales\nexhibit higher persistence than smaller scales, which suggests a relationship\nbetween persistence and the highest exposure to the trade winds. Stronger\nconclusions can be drawn from multifractal spectra, which indicate that most\nrainfall series have a multifractal nature with higher complexity and degree of\nmultifractality at the smallest scales. Furthermore, a clear dependence of\nmultifractal nature on the latitude is revealed.",
            "author": [
                "J. Gomez-Gomez",
                "T. Plocoste",
                "E. Alexis",
                "F. J. Jimenez-Hornero",
                "E. Gutierrez de Rave",
                "S. P. Nuiro"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.jhydrol.2023.130377",
                "http://arxiv.org/abs/2311.14807v1",
                "http://arxiv.org/pdf/2311.14807v1"
            ],
            "primary_category": "physics.ao-ph",
            "category": [
                "physics.ao-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14803v1",
            "title": "Black hole spectroscopy beyond Kerr: agnostic and theory-based tests\n  with next-generation interferometers",
            "updated": "2023-11-24T19:00:03Z",
            "published": "2023-11-24T19:00:03Z",
            "summary": "Black hole spectroscopy is a clean and powerful tool to test gravity in the\nstrong-field regime and to probe the nature of compact objects. Next-generation\nground-based detectors, such as the Einstein Telescope and Cosmic Explorer,\nwill observe thousands of binary black hole mergers with large signal-to-noise\nratios, allowing for accurate measurements of the remnant black hole\nquasinormal mode frequencies and damping times. In previous work we developed\nan observable-based parametrization of the quasinormal mode spectrum of\nspinning black holes beyond general relativity (ParSpec). In this paper we use\nthis parametrization to ask: can next-generation detectors detect or constrain\ndeviations from the Kerr spectrum by stacking multiple observations of binary\nmergers from astrophysically motivated populations? We focus on two families of\ntests: (i) agnostic (null) tests, and (ii) theory-based tests, which make use\nof quasinormal frequency calculations in specific modified theories of gravity.\nWe consider in particular two quadratic gravity theories\n(Einstein-scalar-Gauss-Bonnet and dynamical Chern-Simons gravity) and various\neffective field theory-based extensions of general relativity. We find that\nrobust inference of hypothetical corrections to general relativity requires\npushing the slow-rotation expansion to high orders. Even when high-order\nexpansions are available, ringdown observations alone may not be sufficient to\nmeasure deviations from the Kerr spectrum for theories with dimensionful\ncoupling constants. This is because the constraints are dominated by \"light\"\nblack hole remnants, and only few of them have sufficiently high\nsignal-to-noise ratio in the ringdown. Black hole spectroscopy with\nnext-generation detectors may be able to set tight constraints on theories with\ndimensionless coupling, as long as we assume prior knowledge of the mass and\nspin of the remnant black hole.",
            "author": [
                "Andrea Maselli",
                "Sophia Yi",
                "Lorenzo Pierini",
                "Vania Vellucci",
                "Luca Reali",
                "Leonardo Gualtieri",
                "Emanuele Berti"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14803v1",
                "http://arxiv.org/pdf/2311.14803v1"
            ],
            "primary_category": "gr-qc",
            "category": [
                "gr-qc",
                "astro-ph.HE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14796v1",
            "title": "Scattering from an external field in quantum chromodynamics at high\n  energies: from foundations to interdisciplinary connections",
            "updated": "2023-11-24T19:00:01Z",
            "published": "2023-11-24T19:00:01Z",
            "summary": "We review the factorization of the $S$-matrix elements in the context of\nparticle scattering off an external field, which can serve as a model for the\nfield of a large nucleus. The factorization takes the form of a convolution of\nlight cone wave functions describing the physical incoming and outgoing states\nin terms of bare partons, and products of Wilson lines. The latter represent\nthe interaction between the bare partons and the external field. Specializing\nto elastic scattering amplitudes of onia at very high energies, we introduce\nthe color dipole model, which formulates the calculation of the modulus-squared\nof the wave functions in quantum chromodynamics with the help of a branching\nrandom walk, and the scattering amplitudes as observables on this classical\nstochastic process. Methods developed for general branching processes produce\nanalytical formulas for the asymptotics of such observables, and thus enable\none to derive exact large-rapidity expressions for onium-nucleus cross\nsections, from which electron-nucleus cross sections may be inferred.",
            "author": [
                "Athanasia-Konstantina Angelopoulou",
                "Anh Dung Le",
                "St\u00e9phane Munier"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14796v1",
                "http://arxiv.org/pdf/2311.14796v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14792v1",
            "title": "A soft and transient ultraluminous X-ray source with 6-h modulation in\n  the NGC 300 galaxy",
            "updated": "2023-11-24T19:00:00Z",
            "published": "2023-11-24T19:00:00Z",
            "summary": "We investigate the nature of CXOU J005440.5-374320 (J0054), a peculiar bright\n($\\sim$$4\\times10^{39}$ erg/s) and soft X-ray transient in the spiral galaxy\nNGC 300 with a 6-hour periodic flux modulation that was detected in a 2014\nChandra observation. Subsequent observations with Chandra and XMM-Newton, as\nwell as a large observational campaign of NGC 300 and its sources performed\nwith the Swift Neil Gehrels Observatory, showed that this source exhibits\nrecurrent flaring activity: four other outbursts were detected across $\\sim$8\nyears of monitoring. Using data from the Swift/UVOT archive and from the\nXMM-Newton/OM and Gaia catalogues, we noted the source is likely associated\nwith a bright blue optical/ultraviolet counterpart. This prompted us to perform\nfollow-up observations with the Southern African Large Telescope in December\n2019. With the multi-wavelength information at hand, we discuss several\npossibilities for the nature of J0054. Although none is able to account for the\nfull range of the observed peculiar features, we found that the two most\npromising scenarios are a stellar-mass compact object in a binary system with a\nWolf$-$Rayet star companion, or the recurrent tidal stripping of a stellar\nobject trapped in a system with an intermediate-mass ($\\sim1000$ $M_\\odot$)\nblack hole.",
            "author": [
                "A. Sacchi",
                "P. Esposito",
                "D. de Martino",
                "R. Soria",
                "G. L. Israel",
                "A. A. C. Sander",
                "L. Sidoli",
                "D. A. H. Buckley",
                "I. M. Monageng",
                "A. Tiengo",
                "M. Arca Sedda",
                "C. Pinto",
                "R. Di Stefano",
                "M. Imbrogno",
                "A. Carleo",
                "G. Rivolta"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14792v1",
                "http://arxiv.org/pdf/2311.14792v1"
            ],
            "primary_category": "astro-ph.HE",
            "category": [
                "astro-ph.HE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14794v1",
            "title": "The Role of Vectors in Reheating",
            "updated": "2023-11-24T19:00:00Z",
            "published": "2023-11-24T19:00:00Z",
            "summary": "We explore various aspects concerning the role of vector bosons during the\nreheating process. Generally, reheating occurs during the period of\noscillations of the inflaton condensate and the evolution of the radiation bath\ndepends on the inflaton equation of state. For oscillations about a quadratic\nminimum, the equation of state parameter, $w = p/\\rho =0$, and the evolution of\nthe temperature, $T(a)$ with respect to the scale factor is independent of the\nspin of the inflaton decay products. However, for cases when $w>0$, there is a\ndependence on the spin, and here we consider the evolution when the inflaton\ndecays or scatters to vector bosons. We also investigate the gravitational\nproduction of vector bosons as potential dark matter candidates. Gravitational\nproduction predominantly occurs through the longitudinal mode. We compare these\nresults to the gravitational production of scalars.",
            "author": [
                "Marcos A. G. Garcia",
                "Kunio Kaneta",
                "Wenqi Ke",
                "Yann Mambrini",
                "Keith A. Olive",
                "Sarunas Verner"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14794v1",
                "http://arxiv.org/pdf/2311.14794v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "astro-ph.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14795v1",
            "title": "Pulsar Nulling and Vacuum Radio Emission from Axion Clouds",
            "updated": "2023-11-24T19:00:00Z",
            "published": "2023-11-24T19:00:00Z",
            "summary": "Non-relativistic axions can be efficiently produced in in the polar caps of\npulsars, resulting in the formation of a dense cloud of gravitationally bound\naxions. Here, we investigate the interplay between such an axion cloud and the\nelectrodynamics in the pulsar magnetosphere, focusing specifically on the\ndynamics in the polar caps, where the impact of the axion cloud is expected to\nbe most pronounced. For sufficiently light axions $m_a \\lesssim 10^{-7}$ eV, we\nshow that the axion cloud can occasionally screen the local electric field\nresponsible for particle acceleration and pair production, inducing a periodic\nnulling of the pulsar's intrinsic radio emission. At larger axion masses, the\nsmall-scale fluctuations in the axion field tend to suppress the back-reaction\nof the axion on the electrodynamics; however, we point out that the incoherent\noscillations of the axion in short-lived regions of vacuum near the neutron\nstar surface can produce a narrow radio line, which provides a complementary\nsource of radio emission to the plasma-resonant emission processes identified\nin previous work. While this work focuses on the leading order correction to\npair production in the magnetosphere, we speculate that there can exist\ndramatic deviations in the electrodynamics of these systems when the axion\nback-reaction becomes non-linear.",
            "author": [
                "Andrea Caputo",
                "Samuel J. Witte",
                "Alexander A. Philippov",
                "Ted Jacobson"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14795v1",
                "http://arxiv.org/pdf/2311.14795v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "astro-ph.CO",
                "astro-ph.HE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14671v1",
            "title": "SEGIC: Unleashing the Emergent Correspondence for In-Context\n  Segmentation",
            "updated": "2023-11-24T18:59:42Z",
            "published": "2023-11-24T18:59:42Z",
            "summary": "In-context segmentation aims at segmenting novel images using a few labeled\nexample images, termed as \"in-context examples\", exploring content similarities\nbetween examples and the target. The resulting models can be generalized\nseamlessly to novel segmentation tasks, significantly reducing the labeling and\ntraining costs compared with conventional pipelines. However, in-context\nsegmentation is more challenging than classic ones due to its meta-learning\nnature, requiring the model to learn segmentation rules conditioned on a few\nsamples, not just the segmentation. Unlike previous work with ad-hoc or\nnon-end-to-end designs, we propose SEGIC, an end-to-end segment-in-context\nframework built upon a single vision foundation model (VFM). In particular,\nSEGIC leverages the emergent correspondence within VFM to capture dense\nrelationships between target images and in-context samples. As such,\ninformation from in-context samples is then extracted into three types of\ninstructions, i.e. geometric, visual, and meta instructions, serving as\nexplicit conditions for the final mask prediction. SEGIC is a straightforward\nyet effective approach that yields state-of-the-art performance on one-shot\nsegmentation benchmarks. Notably, SEGIC can be easily generalized to diverse\ntasks, including video object segmentation and open-vocabulary segmentation.\nCode will be available at \\url{https://github.com/MengLcool/SEGIC}.",
            "author": [
                "Lingchen Meng",
                "Shiyi Lan",
                "Hengduo Li",
                "Jose M. Alvarez",
                "Zuxuan Wu",
                "Yu-Gang Jiang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14671v1",
                "http://arxiv.org/pdf/2311.14671v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.15826v1",
            "title": "GeoChat: Grounded Large Vision-Language Model for Remote Sensing",
            "updated": "2023-11-24T18:59:10Z",
            "published": "2023-11-24T18:59:10Z",
            "summary": "Recent advancements in Large Vision-Language Models (VLMs) have shown great\npromise in natural image domains, allowing users to hold a dialogue about given\nvisual content. However, such general-domain VLMs perform poorly for Remote\nSensing (RS) scenarios, leading to inaccurate or fabricated information when\npresented with RS domain-specific queries. Such a behavior emerges due to the\nunique challenges introduced by RS imagery. For example, to handle\nhigh-resolution RS imagery with diverse scale changes across categories and\nmany small objects, region-level reasoning is necessary alongside holistic\nscene interpretation. Furthermore, the lack of domain-specific multimodal\ninstruction following data as well as strong backbone models for RS make it\nhard for the models to align their behavior with user queries. To address these\nlimitations, we propose GeoChat - the first versatile remote sensing VLM that\noffers multitask conversational capabilities with high-resolution RS images.\nSpecifically, GeoChat can not only answer image-level queries but also accepts\nregion inputs to hold region-specific dialogue. Furthermore, it can visually\nground objects in its responses by referring to their spatial coordinates. To\naddress the lack of domain-specific datasets, we generate a novel RS multimodal\ninstruction-following dataset by extending image-text pairs from existing\ndiverse RS datasets. We establish a comprehensive benchmark for RS multitask\nconversations and compare with a number of baseline methods. GeoChat\ndemonstrates robust zero-shot performance on various RS tasks, e.g., image and\nregion captioning, visual question answering, scene classification, visually\ngrounded conversations and referring detection. Our code is available at\nhttps://github.com/mbzuai-oryx/geochat.",
            "author": [
                "Kartik Kuckreja",
                "Muhammad Sohail Danish",
                "Muzammal Naseer",
                "Abhijit Das",
                "Salman Khan",
                "Fahad Shahbaz Khan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.15826v1",
                "http://arxiv.org/pdf/2311.15826v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14670v1",
            "title": "Differentiable and accelerated spherical harmonic and Wigner transforms",
            "updated": "2023-11-24T18:59:04Z",
            "published": "2023-11-24T18:59:04Z",
            "summary": "Many areas of science and engineering encounter data defined on spherical\nmanifolds. Modelling and analysis of spherical data often necessitates\nspherical harmonic transforms, at high degrees, and increasingly requires\nefficient computation of gradients for machine learning or other differentiable\nprogramming tasks. We develop novel algorithmic structures for accelerated and\ndifferentiable computation of generalised Fourier transforms on the sphere\n$\\mathbb{S}^2$ and rotation group $\\text{SO}(3)$, i.e. spherical harmonic and\nWigner transforms, respectively. We present a recursive algorithm for the\ncalculation of Wigner $d$-functions that is both stable to high harmonic\ndegrees and extremely parallelisable. By tightly coupling this with separable\nspherical transforms, we obtain algorithms that exhibit an extremely\nparallelisable structure that is well-suited for the high throughput computing\nof modern hardware accelerators (e.g. GPUs). We also develop a hybrid automatic\nand manual differentiation approach so that gradients can be computed\nefficiently. Our algorithms are implemented within the JAX differentiable\nprogramming framework in the S2FFT software code. Numerous samplings of the\nsphere are supported, including equiangular and HEALPix sampling. Computational\nerrors are at the order of machine precision for spherical samplings that admit\na sampling theorem. When benchmarked against alternative C codes we observe up\nto a 400-fold acceleration. Furthermore, when distributing over multiple GPUs\nwe achieve very close to optimal linear scaling with increasing number of GPUs\ndue to the highly parallelised and balanced nature of our algorithms. Provided\naccess to sufficiently many GPUs our transforms thus exhibit an unprecedented\neffective linear time complexity.",
            "author": [
                "Matthew A. Price",
                "Jason D. McEwen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14670v1",
                "http://arxiv.org/pdf/2311.14670v1"
            ],
            "primary_category": "physics.comp-ph",
            "category": [
                "physics.comp-ph",
                "astro-ph.IM",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14669v1",
            "title": "Landau Singularities Revisited",
            "updated": "2023-11-24T18:58:41Z",
            "published": "2023-11-24T18:58:41Z",
            "summary": "We reformulate the analysis of singularities of Feynman integrals in a way\nthat can be practically applied to perturbative computations in the Standard\nModel in dimensional regularization. After highlighting issues in the textbook\ntreatment of Landau singularities, we develop an algorithm for classifying and\ncomputing them using techniques from computational algebraic geometry. We\nintroduce an algebraic variety called the principal Landau determinant, which\ncaptures the singularities even in the presence of massless particles or UV/IR\ndivergences. We illustrate this for 114 example diagrams, including a\ncutting-edge 2-loop 5-point non-planar QCD process with multiple mass scales.\nThe algorithms introduced in this work are implemented in the open-source Julia\npackage PLD.jl available at https://mathrepo.mis.mpg.de/PLD/.",
            "author": [
                "Claudia Fevola",
                "Sebastian Mizera",
                "Simon Telen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14669v1",
                "http://arxiv.org/pdf/2311.14669v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th",
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14664v1",
            "title": "On the structure of genealogical trees associated with explosive\n  Crump-Mode-Jagers branching processes",
            "updated": "2023-11-24T18:55:26Z",
            "published": "2023-11-24T18:55:26Z",
            "summary": "We study the structure of genealogical trees associated with explosive\nCrump-Mode-Jagers branching processes (stopped at the explosion time), proving\ncriteria for the associated tree to contain a node of infinite degree (a star)\nor an infinite path. Next, we provide uniqueness criteria under which with\nprobability $1$ there exists exactly one of a unique star or a unique infinite\npath. Under the latter uniqueness criteria, we also provide an example where,\nwith strictly positive probability less than $1$, there exists a unique node of\ninfinite degree in the model, thus this probability is not restricted to being\n$0$ or $1$. Moreover, we provide structure theorems when there is a star, when\ncertain trees appear as sub-trees of the star infinitely often. We apply our\nresults to general discrete evolving tree models of explosive recursive trees\nwith fitness, and as particular cases, we study a family of super-linear\npreferential attachment models with fitness. In the latter regime, we derive\nphase transitions in the model parameters in three different examples, leading\nto either exactly one star with probability $1$, or one infinite path with\nprobability $1$, with every node having finite degree. Furthermore, we\nhighlight examples where sub-trees $T$ of arbitrary size can appear infinitely\noften; behaviour that is markedly distinct from super-linear preferential\nattachment models studied in the literature so far.",
            "author": [
                "Tejas Iyer",
                "Bas Lodewijks"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14664v1",
                "http://arxiv.org/pdf/2311.14664v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14658v1",
            "title": "Convergence Analysis for Learning Orthonormal Deep Linear Neural\n  Networks",
            "updated": "2023-11-24T18:46:54Z",
            "published": "2023-11-24T18:46:54Z",
            "summary": "Enforcing orthonormal or isometric property for the weight matrices has been\nshown to enhance the training of deep neural networks by mitigating gradient\nexploding/vanishing and increasing the robustness of the learned networks.\nHowever, despite its practical performance, the theoretical analysis of\northonormality in neural networks is still lacking; for example, how\northonormality affects the convergence of the training process. In this letter,\nwe aim to bridge this gap by providing convergence analysis for training\northonormal deep linear neural networks. Specifically, we show that Riemannian\ngradient descent with an appropriate initialization converges at a linear rate\nfor training orthonormal deep linear neural networks with a class of loss\nfunctions. Unlike existing works that enforce orthonormal weight matrices for\nall the layers, our approach excludes this requirement for one layer, which is\ncrucial to establish the convergence guarantee. Our results shed light on how\nincreasing the number of hidden layers can impact the convergence speed.\nExperimental results validate our theoretical analysis.",
            "author": [
                "Zhen Qin",
                "Xuwei Tan",
                "Zhihui Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14658v1",
                "http://arxiv.org/pdf/2311.14658v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14656v2",
            "title": "Charting New Territories: Exploring the Geographic and Geospatial\n  Capabilities of Multimodal LLMs",
            "updated": "2023-11-30T18:56:42Z",
            "published": "2023-11-24T18:46:02Z",
            "summary": "Multimodal large language models (MLLMs) have shown remarkable capabilities\nacross a broad range of tasks but their knowledge and abilities in the\ngeographic and geospatial domains are yet to be explored, despite potential\nwide-ranging benefits to navigation, environmental research, urban development,\nand disaster response. We conduct a series of experiments exploring various\nvision capabilities of MLLMs within these domains, particularly focusing on the\nfrontier model GPT-4V, and benchmark its performance against open-source\ncounterparts. Our methodology involves challenging these models with a\nsmall-scale geographic benchmark consisting of a suite of visual tasks, testing\ntheir abilities across a spectrum of complexity. The analysis uncovers not only\nwhere such models excel, including instances where they outperform humans, but\nalso where they falter, providing a balanced view of their capabilities in the\ngeographic domain. To enable the comparison and evaluation of future models,\nour benchmark will be publicly released.",
            "author": [
                "Jonathan Roberts",
                "Timo L\u00fcddecke",
                "Rehan Sheikh",
                "Kai Han",
                "Samuel Albanie"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14656v2",
                "http://arxiv.org/pdf/2311.14656v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14655v1",
            "title": "A Sparse Factor Model for Clustering High-Dimensional Longitudinal Data",
            "updated": "2023-11-24T18:44:14Z",
            "published": "2023-11-24T18:44:14Z",
            "summary": "Recent advances in engineering technologies have enabled the collection of a\nlarge number of longitudinal features. This wealth of information presents\nunique opportunities for researchers to investigate the complex nature of\ndiseases and uncover underlying disease mechanisms. However, analyzing such\nkind of data can be difficult due to its high dimensionality, heterogeneity and\ncomputational challenges. In this paper, we propose a Bayesian nonparametric\nmixture model for clustering high-dimensional mixed-type (e.g., continuous,\ndiscrete and categorical) longitudinal features. We employ a sparse factor\nmodel on the joint distribution of random effects and the key idea is to induce\nclustering at the latent factor level instead of the original data to escape\nthe curse of dimensionality. The number of clusters is estimated through a\nDirichlet process prior. An efficient Gibbs sampler is developed to estimate\nthe posterior distribution of the model parameters. Analysis of real and\nsimulated data is presented and discussed. Our study demonstrates that the\nproposed model serves as a useful analytical tool for clustering\nhigh-dimensional longitudinal data.",
            "author": [
                "Zihang Lu",
                "Noirrit Kiran Chandra"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14655v1",
                "http://arxiv.org/pdf/2311.14655v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14788v1",
            "title": "Evaluating Large Language Models through Gender and Racial Stereotypes",
            "updated": "2023-11-24T18:41:16Z",
            "published": "2023-11-24T18:41:16Z",
            "summary": "Language Models have ushered a new age of AI gaining traction within the NLP\ncommunity as well as amongst the general population. AI's ability to make\npredictions, generations and its applications in sensitive decision-making\nscenarios, makes it even more important to study these models for possible\nbiases that may exist and that can be exaggerated. We conduct a quality\ncomparative study and establish a framework to evaluate language models under\nthe premise of two kinds of biases: gender and race, in a professional setting.\nWe find out that while gender bias has reduced immensely in newer models, as\ncompared to older ones, racial bias still exists.",
            "author": [
                "Ananya Malik"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14788v1",
                "http://arxiv.org/pdf/2311.14788v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14653v1",
            "title": "Data-driven Prior Learning for Bayesian Optimisation",
            "updated": "2023-11-24T18:37:52Z",
            "published": "2023-11-24T18:37:52Z",
            "summary": "Transfer learning for Bayesian optimisation has generally assumed a strong\nsimilarity between optimisation tasks, with at least a subset having similar\noptimal inputs. This assumption can reduce computational costs, but it is\nviolated in a wide range of optimisation problems where transfer learning may\nnonetheless be useful. We replace this assumption with a weaker one only\nrequiring the shape of the optimisation landscape to be similar, and analyse\nthe recent method Prior Learning for Bayesian Optimisation - PLeBO - in this\nsetting. By learning priors for the hyperparameters of the Gaussian process\nsurrogate model we can better approximate the underlying function, especially\nfor few function evaluations. We validate the learned priors and compare to a\nbreadth of transfer learning approaches, using synthetic data and a recent air\npollution optimisation problem as benchmarks. We show that PLeBO and prior\ntransfer find good inputs in fewer evaluations.",
            "author": [
                "Sigrid Passano Hellan",
                "Christopher G. Lucas",
                "Nigel H. Goddard"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14653v1",
                "http://arxiv.org/pdf/2311.14653v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14652v1",
            "title": "One Pass Streaming Algorithm for Super Long Token Attention\n  Approximation in Sublinear Space",
            "updated": "2023-11-24T18:35:00Z",
            "published": "2023-11-24T18:35:00Z",
            "summary": "Deploying Large Language Models (LLMs) in streaming applications that involve\nlong contexts, particularly for extended dialogues and text analysis, is of\nparamount importance but presents two significant challenges. Firstly, the\nmemory consumption is substantial during the decoding phase due to the caching\nof Key and Value states (KV) of previous tokens. Secondly, attention\ncomputation is time-consuming with a time complexity of $O(n^2)$ for the\ngeneration of each token. In recent OpenAI DevDay (Nov 6, 2023), OpenAI\nreleased a new model that is able to support a 128K-long document, in our\npaper, we focus on the memory-efficient issue when context length $n$ is much\ngreater than 128K ($n \\gg 2^d$). Considering a single-layer self-attention with\nQuery, Key, and Value matrices $Q, K, V \\in \\mathbb{R}^{n \\times d}$, the\npolynomial method approximates the attention output $T \\in \\mathbb{R}^{n \\times\nd}$. It accomplishes this by constructing $U_1, U_2 \\in \\mathbb{R}^{n \\times\nt}$ to expedite attention ${\\sf Attn}(Q, K, V)$ computation within $n^{1+o(1)}$\ntime executions. Despite this, storing the Key and Value matrices $K, V \\in\n\\mathbb{R}^{n \\times d}$ still necessitates $O( n d)$ space, leading to\nsignificant memory usage. In response to these challenges, we introduce a new\nalgorithm that only reads one pass of the data in streaming fashion. This\nmethod employs sublinear space $o(n)$ to store three sketch matrices,\nalleviating the need for exact $K, V$ storage. Notably, our algorithm exhibits\nexceptional memory-efficient performance with super-long tokens. As the token\nlength $n$ increases, our error guarantee diminishes while the memory usage\nremains nearly constant. This unique attribute underscores the potential of our\ntechnique in efficiently handling LLMs in streaming applications.",
            "author": [
                "Raghav Addanki",
                "Chenyang Li",
                "Zhao Song",
                "Chiwun Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14652v1",
                "http://arxiv.org/pdf/2311.14652v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14651v1",
            "title": "History Filtering in Imperfect Information Games: Algorithms and\n  Complexity",
            "updated": "2023-11-24T18:34:36Z",
            "published": "2023-11-24T18:34:36Z",
            "summary": "Historically applied exclusively to perfect information games, depth-limited\nsearch with value functions has been key to recent advances in AI for imperfect\ninformation games. Most prominent approaches with strong theoretical guarantees\nrequire subgame decomposition - a process in which a subgame is computed from\npublic information and player beliefs. However, subgame decomposition can\nitself require non-trivial computations, and its tractability depends on the\nexistence of efficient algorithms for either full enumeration or generation of\nthe histories that form the root of the subgame. Despite this, no formal\nanalysis of the tractability of such computations has been established in prior\nwork, and application domains have often consisted of games, such as poker, for\nwhich enumeration is trivial on modern hardware. Applying these ideas to more\ncomplex domains requires understanding their cost.\n  In this work, we introduce and analyze the computational aspects and\ntractability of filtering histories for subgame decomposition. We show that\nconstructing a single history from the root of the subgame is generally\nintractable, and then provide a necessary and sufficient condition for\nefficient enumeration. We also introduce a novel Markov Chain Monte Carlo-based\ngeneration algorithm for trick-taking card games - a domain where enumeration\nis often prohibitively expensive. Our experiments demonstrate its improved\nscalability in the trick-taking card game Oh Hell. These contributions clarify\nwhen and how depth-limited search via subgame decomposition can be an effective\ntool for sequential decision-making in imperfect information settings.",
            "author": [
                "Christopher Solinas",
                "Douglas Rebstock",
                "Nathan R. Sturtevant",
                "Michael Buro"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14651v1",
                "http://arxiv.org/pdf/2311.14651v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14650v2",
            "title": "GVEL: Fast Graph Loading in Edgelist and Compressed Sparse Row (CSR)\n  formats",
            "updated": "2023-11-27T09:24:50Z",
            "published": "2023-11-24T18:32:34Z",
            "summary": "Efficient IO techniques are crucial in high-performance graph processing\nframeworks like Gunrock and Hornet, as fast graph loading is essential to\nminimize processing time and reduce system/cloud usage charges. This research\nstudy presents approaches for efficiently reading an Edgelist from a text file\nand converting it to a Compressed Sparse Row (CSR) representation. On a server\nwith dual 16-core Intel Xeon Gold 6226R processors and MegaRAID SAS-3 storage,\nour approach, which we term as GVEL, outperforms Hornet, Gunrock, and PIGO by\nsignificant margins in CSR reading, exhibiting an average speedup of 78x, 112x,\nand 1.8x, respectively. For Edgelist reading, GVEL is 2.6x faster than PIGO on\naverage, and achieves a Edgelist read rate of 1.9 billion edges/s. For every\ndoubling of threads, GVEL improves performance at an average rate of 1.9x and\n1.7x for reading Edgelist and reading CSR respectively.",
            "author": [
                "Subhajit Sahu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14650v2",
                "http://arxiv.org/pdf/2311.14650v2"
            ],
            "primary_category": "cs.PF",
            "category": [
                "cs.PF",
                "B.8.2"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14649v1",
            "title": "Learning in Deep Factor Graphs with Gaussian Belief Propagation",
            "updated": "2023-11-24T18:31:11Z",
            "published": "2023-11-24T18:31:11Z",
            "summary": "We propose an approach to do learning in Gaussian factor graphs. We treat all\nrelevant quantities (inputs, outputs, parameters, latents) as random variables\nin a graphical model, and view both training and prediction as inference\nproblems with different observed nodes. Our experiments show that these\nproblems can be efficiently solved with belief propagation (BP), whose updates\nare inherently local, presenting exciting opportunities for distributed and\nasynchronous training. Our approach can be scaled to deep networks and provides\na natural means to do continual learning: use the BP-estimated parameter\nmarginals of the current task as parameter priors for the next. On a video\ndenoising task we demonstrate the benefit of learnable parameters over a\nclassical factor graph approach and we show encouraging performance of deep\nfactor graphs for continual image classification on MNIST.",
            "author": [
                "Seth Nabarro",
                "Mark van der Wilk",
                "Andrew J Davison"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14649v1",
                "http://arxiv.org/pdf/2311.14649v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14648v2",
            "title": "Calibrated Language Models Must Hallucinate",
            "updated": "2023-12-03T15:28:02Z",
            "published": "2023-11-24T18:29:50Z",
            "summary": "Recent language models generate false but plausible-sounding text with\nsurprising frequency. Such \"hallucinations\" are an obstacle to the usability of\nlanguage-based AI systems and can harm people who rely upon their outputs. This\nwork shows shows that there is an inherent statistical lower-bound on the rate\nthat pretrained language models hallucinate certain types of facts, having\nnothing to do with the transformer LM architecture or data quality. For\n\"arbitrary\" facts whose veracity cannot be determined from the training data,\nwe show that hallucinations must occur at a certain rate for language models\nthat satisfy a statistical calibration condition appropriate for generative\nlanguage models. Specifically, if the maximum probability of any fact is\nbounded, we show that the probability of generating a hallucination is close to\nthe fraction of facts that occur exactly once in the training data (a\n\"Good-Turing\" estimate), even assuming ideal training data without errors.\n  One conclusion is that models pretrained to be sufficiently good predictors\n(i.e., calibrated) may require post-training to mitigate hallucinations on the\ntype of arbitrary facts that tend to appear once in the training set. However,\nour analysis also suggests that there is no statistical reason that pretraining\nwill lead to hallucination on facts that tend to appear more than once in the\ntraining data (like references to publications such as articles and books,\nwhose hallucinations have been particularly notable and problematic) or on\nsystematic facts (like arithmetic calculations). Therefore, different\narchitectures and learning algorithms may mitigate these latter types of\nhallucinations.",
            "author": [
                "Adam Tauman Kalai",
                "Santosh S. Vempala"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14648v2",
                "http://arxiv.org/pdf/2311.14648v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14639v1",
            "title": "Unsupervised high-throughput segmentation of cells and cell nuclei in\n  quantitative phase images",
            "updated": "2023-11-24T18:12:06Z",
            "published": "2023-11-24T18:12:06Z",
            "summary": "In the effort to aid cytologic diagnostics by establishing automatic single\ncell screening using high throughput digital holographic microscopy for\nclinical studies thousands of images and millions of cells are captured. The\nbottleneck lies in an automatic, fast, and unsupervised segmentation technique\nthat does not limit the types of cells which might occur. We propose an\nunsupervised multistage method that segments correctly without confusing noise\nor reflections with cells and without missing cells that also includes the\ndetection of relevant inner structures, especially the cell nucleus in the\nunstained cell. In an effort to make the information reasonable and\ninterpretable for cytopathologists, we also introduce new cytoplasmic and\nnuclear features of potential help for cytologic diagnoses which exploit the\nquantitative phase information inherent to the measurement scheme. We show that\nthe segmentation provides consistently good results over many experiments on\npatient samples in a reasonable per cell analysis time.",
            "author": [
                "Julia Sistermanns",
                "Ellen Emken",
                "Gregor Weirich",
                "Oliver Hayden",
                "Wolfgang Utschick"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14639v1",
                "http://arxiv.org/pdf/2311.14639v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "q-bio.CB",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14787v1",
            "title": "Rashba splitting in polar-nonpolar sandwich heterostructure : A DFT\n  Study",
            "updated": "2023-11-24T18:09:37Z",
            "published": "2023-11-24T18:09:37Z",
            "summary": "In this study, we employ density functional theory (DFT) based\nfirst-principles calculations to investigate the spin-orbit effects in the\nelectronic structure of a polar-nonpolar sandwich heterostructure namely\nLAO$_{2.5}$/STO$_{5.5}$/LAO$_{2.5}$. Our focus on the Ti-3d bands reveals an\ninverted ordering of the STO-$\\rm t_{2g}$ orbital near the n-type interface,\nconsistent with earlier experimental work. In contrast, toward the p-type\ninterface, the orbital ordering aligns with the natural ordering of STO\norbitals, influenced by crystal field splitting. Interestingly, we have found a\nstrong inter-orbital coupling between $t_{2g}$ and $e_g$ orbital, which has not\nbeen reported earlier in $\\rm SrTiO_3$ based 2D system. Additionally, our\nobservations highlight that the cubic Rashba splitting in this system surpasses\nthe linear Rashba splitting, contrary to experimental findings. This\ncomprehensive analysis contributes to a refined understanding of the role of\norbital mixing in Rashba splitting in the sandwich oxide heterostructures.",
            "author": [
                "Sanchari Bhattacharya",
                "Sanjoy Datta"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14787v1",
                "http://arxiv.org/pdf/2311.14787v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14636v1",
            "title": "Baryon Asymmetry from the Decay and Scattering of a Majorana Fermion\n  Pair Coupled to Quarks",
            "updated": "2023-11-24T18:09:10Z",
            "published": "2023-11-24T18:09:10Z",
            "summary": "We compute the baryon asymmetry in decay and scattering processes involving\nthe electromagnetically charge-neutral fermion $\\chi$ that carries nonzero\nbaryon number and interacts with quark-like fermions $U,D$ via a vector-vector\ndimension-six effective operator, in the theory we developed in our earlier\nwork. Majorana masses, that break baryon number, split the Dirac fermion $\\chi$\ninto a pair of Majorana fermions $\\chi_n$ with indefinite baryon number. We\nidentify loop amplitudes for $\\chi_n$ decay and scattering processes that are\nsensitive to the baryon number violation. The phases in the Majorana mass and\ncouplings, in conjunction with a phase of $\\pi/2$ from intermediate onshell\n$U,D$ in the loop, lead to $C$ and $CP$ violation in these processes. For some\nrepresentative parameter choices, we numerically compute the decay and\nscattering baryon asymmetries between the process and its conjugate process,\nand find that the asymmetry generated is phenomenologically very interesting.",
            "author": [
                "Shrihari Gopalakrishna",
                "Rakesh Tibrewala"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14636v1",
                "http://arxiv.org/pdf/2311.14636v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14635v1",
            "title": "Automated Detection and Counting of Windows using UAV Imagery based\n  Remote Sensing",
            "updated": "2023-11-24T18:08:42Z",
            "published": "2023-11-24T18:08:42Z",
            "summary": "Despite the technological advancements in the construction and surveying\nsector, the inspection of salient features like windows in an\nunder-construction or existing building is predominantly a manual process.\nMoreover, the number of windows present in a building is directly related to\nthe magnitude of deformation it suffers under earthquakes. In this research, a\nmethod to accurately detect and count the number of windows of a building by\ndeploying an Unmanned Aerial Vehicle (UAV) based remote sensing system is\nproposed. The proposed two-stage method automates the identification and\ncounting of windows by developing computer vision pipelines that utilize data\nfrom UAV's onboard camera and other sensors. Quantitative and Qualitative\nresults show the effectiveness of our proposed approach in accurately detecting\nand counting the windows compared to the existing method.",
            "author": [
                "Dhruv Patel",
                "Shivani Chepuri",
                "Sarvesh Thakur",
                "K. Harikumar",
                "Ravi Kiran S.",
                "K. Madhava Krishna"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14635v1",
                "http://arxiv.org/pdf/2311.14635v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14786v1",
            "title": "GPT-4V Takes the Wheel: Evaluating Promise and Challenges for Pedestrian\n  Behavior Prediction",
            "updated": "2023-11-24T18:02:49Z",
            "published": "2023-11-24T18:02:49Z",
            "summary": "Existing pedestrian behavior prediction methods rely primarily on deep neural\nnetworks that utilize features extracted from video frame sequences. Although\nthese vision-based models have shown promising results, they face limitations\nin effectively capturing and utilizing the dynamic spatio-temporal interactions\nbetween the target pedestrian and its surrounding traffic elements, crucial for\naccurate reasoning. Additionally, training these models requires manually\nannotating domain-specific datasets, a process that is expensive,\ntime-consuming, and difficult to generalize to new environments and scenarios.\nThe recent emergence of Large Multimodal Models (LMMs) offers potential\nsolutions to these limitations due to their superior visual understanding and\ncausal reasoning capabilities, which can be harnessed through semi-supervised\ntraining. GPT-4V(ision), the latest iteration of the state-of-the-art\nLarge-Language Model GPTs, now incorporates vision input capabilities. This\nreport provides a comprehensive evaluation of the potential of GPT-4V for\npedestrian behavior prediction in autonomous driving using publicly available\ndatasets: JAAD, PIE, and WiDEVIEW. Quantitative and qualitative evaluations\ndemonstrate GPT-4V(ision)'s promise in zero-shot pedestrian behavior prediction\nand driving scene understanding ability for autonomous driving. However, it\nstill falls short of the state-of-the-art traditional domain-specific models.\nChallenges include difficulties in handling small pedestrians and vehicles in\nmotion. These limitations highlight the need for further research and\ndevelopment in this area.",
            "author": [
                "Jia Huang",
                "Peng Jiang",
                "Alvika Gautam",
                "Srikanth Saripalli"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14786v1",
                "http://arxiv.org/pdf/2311.14786v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14633v1",
            "title": "One Strike, You're Out: Detecting Markush Structures in Low\n  Signal-to-Noise Ratio Images",
            "updated": "2023-11-24T18:02:14Z",
            "published": "2023-11-24T18:02:14Z",
            "summary": "Modern research increasingly relies on automated methods to assist\nresearchers. An example of this is Optical Chemical Structure Recognition\n(OCSR), which aids chemists in retrieving information about chemicals from\nlarge amounts of documents. Markush structures are chemical structures that\ncannot be parsed correctly by OCSR and cause errors. The focus of this research\nwas to propose and test a novel method for classifying Markush structures.\nWithin this method, a comparison was made between fixed-feature extraction and\nend-to-end learning (CNN). The end-to-end method performed significantly better\nthan the fixed-feature method, achieving 0.928 (0.035 SD) Macro F1 compared to\nthe fixed-feature method's 0.701 (0.052 SD). Because of the nature of the\nexperiment, these figures are a lower bound and can be improved further. These\nresults suggest that Markush structures can be filtered out effectively and\naccurately using the proposed method. When implemented into OCSR pipelines,\nthis method can improve their performance and use to other researchers.",
            "author": [
                "Thomas Jurriaans",
                "Kinga Szarkowska",
                "Eric Nalisnick",
                "Markus Schwoerer",
                "Camilo Thorne",
                "Saber Akhondi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14633v1",
                "http://arxiv.org/pdf/2311.14633v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14631v2",
            "title": "CatVersion: Concatenating Embeddings for Diffusion-Based Text-to-Image\n  Personalization",
            "updated": "2023-11-30T14:42:07Z",
            "published": "2023-11-24T17:55:10Z",
            "summary": "We propose CatVersion, an inversion-based method that learns the personalized\nconcept through a handful of examples. Subsequently, users can utilize text\nprompts to generate images that embody the personalized concept, thereby\nachieving text-to-image personalization. In contrast to existing approaches\nthat emphasize word embedding learning or parameter fine-tuning for the\ndiffusion model, which potentially causes concept dilution or overfitting, our\nmethod concatenates embeddings on the feature-dense space of the text encoder\nin the diffusion model to learn the gap between the personalized concept and\nits base class, aiming to maximize the preservation of prior knowledge in\ndiffusion models while restoring the personalized concepts. To this end, we\nfirst dissect the text encoder's integration in the image generation process to\nidentify the feature-dense space of the encoder. Afterward, we concatenate\nembeddings on the Keys and Values in this space to learn the gap between the\npersonalized concept and its base class. In this way, the concatenated\nembeddings ultimately manifest as a residual on the original attention output.\nTo more accurately and unbiasedly quantify the results of personalized image\ngeneration, we improve the CLIP image alignment score based on masks.\nQualitatively and quantitatively, CatVersion helps to restore personalization\nconcepts more faithfully and enables more robust editing.",
            "author": [
                "Ruoyu Zhao",
                "Mingrui Zhu",
                "Shiyin Dong",
                "Nannan Wang",
                "Xinbo Gao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14631v2",
                "http://arxiv.org/pdf/2311.14631v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14629v1",
            "title": "Light New Physics in $B\\to K^{(*)}\u03bd\\bar\u03bd$?",
            "updated": "2023-11-24T17:48:20Z",
            "published": "2023-11-24T17:48:20Z",
            "summary": "The study of the rare decays $B\\to K^{(*)} \\nu \\bar\\nu$ offers a window into\nthe dynamics operating at the electroweak scale, allowing studies of the\nStandard Model and searches for heavy new physics. However, the analysis of\nthese decays is also potentially sensitive to the on-shell production of new\nlight bosons $X$ through the process $B\\to K^{(*)} X$. In particular, Belle~II\nhas recently measured $B^+\\to K^+\\nu\\bar\\nu$, finding a $2.8\\sigma$ excess\nunder the assumption of heavy new physics. Since this excess is rather\nlocalized in the kaon energy, a fit that includes the decay mode $B^+\\to K^+ X$\nto the kinematic distributions prefers $m_X\\approx2\\,$GeV with branching\nfraction Br$[B\\to KX]=(8.8\\pm2.5)\\times 10^{-6}$ and a significance of\n$\\approx3.6\\sigma$. However, no excess was found in the BaBar measurements of\n$B\\to K^{(*)} \\nu \\bar\\nu$, and a global analysis of the Belle II and BaBar\ndata leads to Br$[B\\to KX]=(5.1\\pm2.1)\\times 10^{-6}$ with a reduced\nsignificance of $\\approx2.4\\sigma$. We then study various simplified\ndark-flavoured models and present a possible UV completion based on a gauged\n$B_3-L_3$ symmetry, highlighting the discovery potential of dedicated searches\nfor $B\\to K^{(*)}X$ at Belle II.",
            "author": [
                "Wolfgang Altmannshofer",
                "Andreas Crivellin",
                "Huw Haigh",
                "Gianluca Inguglia",
                "Jorge Martin Camalich"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14629v1",
                "http://arxiv.org/pdf/2311.14629v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14627v3",
            "title": "A new use of the Kurdyka-Lojasiewicz property to study asymptotic\n  behaviours of some stochastic optimization algorithms in a non-convex\n  differentiable framework",
            "updated": "2023-11-30T14:35:59Z",
            "published": "2023-11-24T17:44:38Z",
            "summary": "The asymptotic analysis of a generic stochastic optimization algorithm mainly\nrelies on the establishment of a specific descent condition. While the\nconvexity assumption allows for technical shortcuts and generally leads to\nstrict convergence, dealing with the non-convex framework, on the contrary,\nrequires the use of specific results as those relying on the\nKurdyka-Lojasiewicz (KL) theory. While such tools have become popular in the\nfield of deterministic optimisation, they are much less widespread in the\nstochastic context and, in this case, the few works making use of them are\nessentially based on trajectory-by-trajectory approaches. In this paper, we\npropose a new methodology, also based on KL theory, for deeper asymptotic\ninvestigations on a stochastic scheme verifying a descent condition. The\nspecificity of our work is here to be of macroscopic nature insofar as our\nstrategy of proof is more in-expectation-based and therefore seems more natural\ntypically with respect to the noise properties, of conditional order,\nencountered in the stochastic literature nowadays.",
            "author": [
                "Jean-Baptiste Fest"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14627v3",
                "http://arxiv.org/pdf/2311.14627v3"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14626v1",
            "title": "Time-reversal-like degeneracies distinguished by the anomalous Hall\n  effect in a metallic kagome ice compound",
            "updated": "2023-11-24T17:41:39Z",
            "published": "2023-11-24T17:41:39Z",
            "summary": "In magnetic crystals, despite the explicit breaking of time-reversal\nsymmetry, two equilibrium states related by time reversal are always\nenergetically degenerate. In ferromagnets such time-reversal degeneracy can be\nmanifested by hysteresis loops in the magnetic field dependence of the\nmagnetization and, if metallic, in the anomalous Hall effect. Importantly, both\nquantities simply change signs but not their absolute sizes under time\nreversal, which follows from their fundamental definitions. Our integral\nexperimental and theoretical study shows that in the metallic kagome spin ice\nHoAgGe subject to finite magnetic fields parallel to the kagome plane, an\nemergent time-reversal-like degeneracy appears between magnetic states that\nhave the same energy and net magnetization, but different sizes of the\nanomalous Hall effect. These degeneracies are unraveled by finite hysteresis in\nthe field-dependent anomalous Hall effect contrasted with the vanishing\nhysteresis in the magnetization, which appears only at low-temperatures T$<$4K\nwhen the kagome spin ice is fully ordered into $\\sqrt{3}$$\\times$$\\sqrt{3}$\nstate. By explicitly determining the degenerate states and calculating the\ncorresponding physical properties using a tight-binding model, we nailed down\nthe time-reversal-like operation that transforms these degenerate states into\neach other. The operation is related to the nontrivial distortion of the kagome\nlattice in HoAgGe and is effective only because of the richness of degenerate\nstates unique to kagome spin ice. Our work points to the powerful role of the\nanomalous Hall effect to diagnose hidden symmetries in frustrated spin systems.",
            "author": [
                "Kan Zhao",
                "Yoshi Tokiwa",
                "Hua Chen",
                "Philipp Gegenwart"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14626v1",
                "http://arxiv.org/pdf/2311.14626v1"
            ],
            "primary_category": "cond-mat.str-el",
            "category": [
                "cond-mat.str-el",
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.00043v1",
            "title": "Who is leading in AI? An analysis of industry AI research",
            "updated": "2023-11-24T17:36:09Z",
            "published": "2023-11-24T17:36:09Z",
            "summary": "AI research is increasingly industry-driven, making it crucial to understand\ncompany contributions to this field. We compare leading AI companies by\nresearch publications, citations, size of training runs, and contributions to\nalgorithmic innovations. Our analysis reveals the substantial role played by\nGoogle, OpenAI and Meta. We find that these three companies have been\nresponsible for some of the largest training runs, developed a large fraction\nof the algorithmic innovations that underpin large language models, and led in\nvarious metrics of citation impact. In contrast, leading Chinese companies such\nas Tencent and Baidu had a lower impact on many of these metrics compared to US\ncounterparts. We observe many industry labs are pursuing large training runs,\nand that training runs from relative newcomers -- such as OpenAI and Anthropic\n-- have matched or surpassed those of long-standing incumbents such as Google.\nThe data reveals a diverse ecosystem of companies steering AI progress, though\nUS labs such as Google, OpenAI and Meta lead across critical metrics.",
            "author": [
                "Ben Cottier",
                "Tamay Besiroglu",
                "David Owen"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00043v1",
                "http://arxiv.org/pdf/2312.00043v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14621v1",
            "title": "Received Signal and Channel Parameter Estimation in Molecular\n  Communications",
            "updated": "2023-11-24T17:30:51Z",
            "published": "2023-11-24T17:30:51Z",
            "summary": "Molecular communication (MC) is a paradigm that employs molecules as\ninformation transmitters, hence, requiring unconventional transceivers and\ndetection techniques for the Internet of Bio-Nano Things (IoBNT). In this\nstudy, we provide a novel MC model that incorporates a spherical transmitter\nand receiver with partial absorption. This model offers a more realistic\nrepresentation than receiver architectures in literature, e.g. passive or\nentirely absorbing configurations. An optimization-based technique utilizing\nparticle swarm optimization (PSO) is employed to accurately estimate the\ncumulative number of molecules received. This technique yields nearly constant\ncorrection parameters and demonstrates a significant improvement of 5 times in\nterms of root mean square error (RMSE). The estimated channel model provides an\napproximate analytical impulse response; hence, it is used for estimating\nchannel parameters such as distance, diffusion coefficient, or a combination of\nboth. We apply iterative maximum likelihood estimation (MLE) for the parameter\nestimation, which gives consistent errors compared to the estimated Cramer-Rao\nLower Bound (CLRB).",
            "author": [
                "O. Tansel Baydas",
                "Ozgur B. Akan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14621v1",
                "http://arxiv.org/pdf/2311.14621v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14617v1",
            "title": "Neural Style Transfer for Computer Games",
            "updated": "2023-11-24T17:25:12Z",
            "published": "2023-11-24T17:25:12Z",
            "summary": "Neural Style Transfer (NST) research has been applied to images, videos, 3D\nmeshes and radiance fields, but its application to 3D computer games remains\nrelatively unexplored. Whilst image and video NST systems can be used as a\npost-processing effect for a computer game, this results in undesired artefacts\nand diminished post-processing effects. Here, we present an approach for\ninjecting depth-aware NST as part of the 3D rendering pipeline. Qualitative and\nquantitative experiments are used to validate our in-game stylisation\nframework. We demonstrate temporally consistent results of artistically\nstylised game scenes, outperforming state-of-the-art image and video NST\nmethods.",
            "author": [
                "Eleftherios Ioannou",
                "Steve Maddock"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14617v1",
                "http://arxiv.org/pdf/2311.14617v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.02178v1",
            "title": "Hierarchical ML Codebook Design for Extreme MIMO Beam Management",
            "updated": "2023-11-24T17:14:11Z",
            "published": "2023-11-24T17:14:11Z",
            "summary": "Beam management is a strategy to unify beamforming and channel state\ninformation (CSI) acquisition with large antenna arrays in 5G. Codebooks serve\nmultiple uses in beam management including beamforming reference signals, CSI\nreporting, and analog beam training. In this paper, we propose and evaluate a\nmachine learning-refined codebook design process for extremely large\nmultiple-input multiple-output (X-MIMO) systems. We propose a neural network\nand beam selection strategy to design the initial access and refinement\ncodebooks using end-to-end learning from beamspace representations. The\nalgorithm, called Extreme-Beam Management (X-BM), can significantly improve the\nperformance of extremely large arrays as envisioned for 6G and capture\nrealistic wireless and physical layer aspects. Our results show an 8dB\nimprovement in initial access and overall effective spectral efficiency\nimprovements compared to traditional codebook methods.",
            "author": [
                "Ryan M. Dreifuerst",
                "Robert W. Heath Jr"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02178v1",
                "http://arxiv.org/pdf/2312.02178v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.IT",
                "cs.LG",
                "cs.SY",
                "eess.SY",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14783v1",
            "title": "cryptoRAN: A review on cryptojacking and ransomware attacks w.r.t.\n  banking industry -- threats, challenges, & problems",
            "updated": "2023-11-24T17:08:58Z",
            "published": "2023-11-24T17:08:58Z",
            "summary": "In the banking industry, ransomware is a well-known threat, but since the\nbeginning of 2022, cryptojacking, an emerging threat is posing a considerable\nchallenge to the banking industry. Ransomware has variants, and the attackers\nkeep changing the nature of these variants. This review paper studies the\ncomplex background of these two threats and scrutinizes the actual challenges,\nand problems that the banking industry and financial institutions face. These\nthreats, though distinct in nature, share commonalities, such as financial\nmotivations and sophisticated techniques. We focus on examining the newly\nemerged variants of ransomware while we provide a comprehensive idea of\ncryptojacking and its nature. This paper involves a detailed breakdown of the\nspecific threats posed by cryptojacking and ransomware. It explores the\ntechniques cybercriminals use, the variabilities they look for, and the\npotential consequences for financial institutions and their customers. This\npaper also finds out how cybercriminals change their techniques following the\nsecurity upgrades, and why financial firms including banks need to be proactive\nabout cyber threats. Additionally, this paper reviews the background study of\nsome existing papers, finds the research gaps that need to be addressed, and\nprovides suggestions including a conclusion and future scope on those disputes.\nLastly, we introduce a Digital Forensics and Incident Response (DFIR) approach\nfor up-to-date cyber threat hunting processes for minimizing both cryptojacking\nand ransomware attacks in the banking industry.",
            "author": [
                "Naresh Kshetri",
                "Mir Mehedi Rahman",
                "Sayed Abu Sayeed",
                "Irin Sultana"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14783v1",
                "http://arxiv.org/pdf/2311.14783v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14601v1",
            "title": "A Metalearned Neural Circuit for Nonparametric Bayesian Inference",
            "updated": "2023-11-24T16:43:17Z",
            "published": "2023-11-24T16:43:17Z",
            "summary": "Most applications of machine learning to classification assume a closed set\nof balanced classes. This is at odds with the real world, where class\noccurrence statistics often follow a long-tailed power-law distribution and it\nis unlikely that all classes are seen in a single sample. Nonparametric\nBayesian models naturally capture this phenomenon, but have significant\npractical barriers to widespread adoption, namely implementation complexity and\ncomputational inefficiency. To address this, we present a method for extracting\nthe inductive bias from a nonparametric Bayesian model and transferring it to\nan artificial neural network. By simulating data with a nonparametric Bayesian\nprior, we can metalearn a sequence model that performs inference over an\nunlimited set of classes. After training, this \"neural circuit\" has distilled\nthe corresponding inductive bias and can successfully perform sequential\ninference over an open set of classes. Our experimental results show that the\nmetalearned neural circuit achieves comparable or better performance than\nparticle filter-based methods for inference in these models while being faster\nand simpler to use than methods that explicitly incorporate Bayesian\nnonparametric inference.",
            "author": [
                "Jake C. Snell",
                "Gianluca Bencomo",
                "Thomas L. Griffiths"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14601v1",
                "http://arxiv.org/pdf/2311.14601v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NE",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14598v1",
            "title": "Target-driven splitting SPH optimization of thermal conductivity\n  distribution",
            "updated": "2023-11-24T16:37:58Z",
            "published": "2023-11-24T16:37:58Z",
            "summary": "Efficiently enhancing heat conduction through optimized distribution of a\nlimited quantity of high thermal conductivity material is paramount in cooling\nelectronic devices and numerous other applications. This paper introduces a\ntarget-driven all-at-once approach for PDE-constrained optimization and derives\na splitting smoothed particle hydrodynamics (SPH) method for optimizing the\ndistribution of thermal conductivity in heat conduction problems. In this\nmethod, the optimization iteration of the system is split into several easily\naddressed steps. A targeting step is employed to progressively enforce the\ndirect target, which potentially leads to increased PDE residuals. Then, these\nresiduals are recovered through an evolution step of the design variable. After\nthis, a PDE solution step is carried out to further decrease the PDE residuals,\nand the system is ready for the next iteration. Unlike the simulation-based\napproaches, the present method does not rely on the adjoint state equation and\nconverged state variable field in each iteration, and the optimization process\nis significantly simplified and accelerated. With the utilization of an\nimplicit SPH splitting operator and a general numerical regularization\nformulation, the information propagation is further accelerated and the\nnumerical stability is greatly enhanced. Typical examples of heat conduction\noptimization demonstrate that the current method yields optimal results\ncomparable to previous methods and exhibits considerable computational\nefficiency. Moreover, the optimal results feature more moderate extreme values,\nwhich offers distinct advantages for the easier selection of appropriate\nmaterial with high thermal conductivity.",
            "author": [
                "Bo Zhang",
                "Chi Zhang",
                "Xiangyu Hu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14598v1",
                "http://arxiv.org/pdf/2311.14598v1"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14782v1",
            "title": "One Fits All: Universal Time Series Analysis by Pretrained LM and\n  Specially Designed Adaptors",
            "updated": "2023-11-24T16:32:47Z",
            "published": "2023-11-24T16:32:47Z",
            "summary": "Despite the impressive achievements of pre-trained models in the fields of\nnatural language processing (NLP) and computer vision (CV), progress in the\ndomain of time series analysis has been limited. In contrast to NLP and CV,\nwhere a single model can handle various tasks, time series analysis still\nrelies heavily on task-specific methods for activities such as classification,\nanomaly detection, forecasting, and few-shot learning. The primary obstacle to\ndeveloping a pre-trained model for time series analysis is the scarcity of\nsufficient training data. In our research, we overcome this obstacle by\nutilizing pre-trained models from language or CV, which have been trained on\nbillions of data points, and apply them to time series analysis. We assess the\neffectiveness of the pre-trained transformer model in two ways. Initially, we\nmaintain the original structure of the self-attention and feedforward layers in\nthe residual blocks of the pre-trained language or image model, using the\nFrozen Pre-trained Transformer (FPT) for time series analysis with the addition\nof projection matrices for input and output. Additionally, we introduce four\nunique adapters, designed specifically for downstream tasks based on the\npre-trained model, including forecasting and anomaly detection. These adapters\nare further enhanced with efficient parameter tuning, resulting in superior\nperformance compared to all state-of-the-art methods.Our comprehensive\nexperimental studies reveal that (a) the simple FPT achieves top-tier\nperformance across various time series analysis tasks; and (b) fine-tuning the\nFPT with the custom-designed adapters can further elevate its performance,\noutshining specialized task-specific models.",
            "author": [
                "Tian Zhou",
                "Peisong Niu",
                "Xue Wang",
                "Liang Sun",
                "Rong Jin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14782v1",
                "http://arxiv.org/pdf/2311.14782v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14594v1",
            "title": "MABFuzz: Multi-Armed Bandit Algorithms for Fuzzing Processors",
            "updated": "2023-11-24T16:32:43Z",
            "published": "2023-11-24T16:32:43Z",
            "summary": "As the complexities of processors keep increasing, the task of effectively\nverifying their integrity and security becomes ever more daunting. The\nintricate web of instructions, microarchitectural features, and\ninterdependencies woven into modern processors pose a formidable challenge for\neven the most diligent verification and security engineers. To tackle this\ngrowing concern, recently, researchers have developed fuzzing techniques\nexplicitly tailored for hardware processors. However, a prevailing issue with\nthese hardware fuzzers is their heavy reliance on static strategies to make\ndecisions in their algorithms. To address this problem, we develop a novel\ndynamic and adaptive decision-making framework, MABFuzz, that uses multi-armed\nbandit (MAB) algorithms to fuzz processors. MABFuzz is agnostic to, and hence,\napplicable to, any existing hardware fuzzer. In the process of designing\nMABFuzz, we encounter challenges related to the compatibility of MAB algorithms\nwith fuzzers and maximizing their efficacy for fuzzing. We overcome these\nchallenges by modifying the fuzzing process and tailoring MAB algorithms to\naccommodate special requirements for hardware fuzzing.\n  We integrate three widely used MAB algorithms in a state-of-the-art hardware\nfuzzer and evaluate them on three popular RISC-V-based processors. Experimental\nresults demonstrate the ability of MABFuzz to cover a broader spectrum of\nprocessors' intricate landscapes and doing so with remarkable efficiency. In\nparticular, MABFuzz achieves up to 308x speedup in detecting vulnerabilities\nand up to 5x speedup in achieving coverage compared to a state-of-the-art\ntechnique.",
            "author": [
                "Vasudev Gohil",
                "Rahul Kande",
                "Chen Chen",
                "Ahmad-Reza Sadeghi",
                "Jeyavijayan Rajendran"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14594v1",
                "http://arxiv.org/pdf/2311.14594v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14593v1",
            "title": "Visualizing Plasma Physics Simulations in Immersive Environments",
            "updated": "2023-11-24T16:32:06Z",
            "published": "2023-11-24T16:32:06Z",
            "summary": "Plasma physics simulations create complex datasets for which researchers need\nstate-of-the-art visualization tools to gain insights. These datasets are 3D in\nnature but are commonly depicted and analyzed using 2D idioms displayed on 2D\nscreens. These offer limited understandability in a domain where spatial\nawareness is key. Virtual reality (VR) can be used as an alternative to\nconventional means for analyzing such datasets. VR has been known to improve\ndepth and spatial relationship perception, which are fundamental for obtaining\ninsights into 3D plasma morphology. Likewise, VR can potentially increase user\nengagement by offering more immersive and enjoyable experiences. Methods This\nstudy presents PlasmaVR, a proof-of-concept VR tool for visualizing datasets\nresulting from plasma physics simulations. It enables immersive\nmultidimensional data visualization of particles, scalar, and vector fields and\nuses a more natural interface. The study includes user evaluation with domain\nexperts where PlasmaVR was employed to assess the possible benefits of\nimmersive environments in plasma physics visualization. The experimental group\ncomprised five plasma physics researchers who were asked to perform tasks\ndesigned to represent their typical analysis workflow. To assess the\nsuitability of the prototype for the different types of tasks, a set of\nobjective metrics, such as completion time and number of errors, were measured.\nThe prototype's usability was also evaluated using a standard System Usability\nSurvey questionnaire.",
            "author": [
                "Nuno Verdelho Trindade",
                "Oscar Amaro",
                "David Bras",
                "Daniel Goncalves",
                "Jo\u00e3o Madeiras Pereira",
                "Alfredo Ferreira"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14593v1",
                "http://arxiv.org/pdf/2311.14593v1"
            ],
            "primary_category": "cs.GR",
            "category": [
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14591v1",
            "title": "Cooperative Multi-Monostatic Sensing for Object Localization in 6G\n  Networks",
            "updated": "2023-11-24T16:30:42Z",
            "published": "2023-11-24T16:30:42Z",
            "summary": "Enabling passive sensing of the environment using cellular base stations\n(BSs) will be one of the disruptive features of the sixth-generation (6G)\nnetworks. However, accurate localization and positioning of objects are\nchallenging to achieve as multipath significantly degrades the reflected echos.\nExisting localization techniques perform well under the assumption of large\nbandwidth available but perform poorly in bandwidth-limited scenarios. To\nalleviate this problem, in this work, we introduce a 5G New Radio (NR)-based\ncooperative multi-monostatic sensing framework for passive target localization\nthat operates in the Frequency Range 1 (FR1) band. We propose a novel\nfusion-based estimation process that can mitigate the effect of multipath by\nassigning appropriate weight to the range estimation of each BS. Extensive\nsimulation results using ray-tracing demonstrate the efficacy of the proposed\nmulti-sensing framework in bandwidth-limited scenarios.",
            "author": [
                "Maximiliano Rivera Figueroa",
                "Pradyumna Kumar Bishoyi",
                "Marina Petrova"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14591v1",
                "http://arxiv.org/pdf/2311.14591v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14780v1",
            "title": "Wavelength-multiplexed Multi-mode EUV Reflection Ptychography based on\n  Automatic-Differentiation",
            "updated": "2023-11-24T16:21:36Z",
            "published": "2023-11-24T16:21:36Z",
            "summary": "Ptychographic extreme ultraviolet (EUV) diffractive imaging has emerged as a\npromising candidate for the next-generation metrology solutions in the\nsemiconductor industry, as it can image wafer samples in reflection geometry at\nthe nanoscale. This technique has surged attention recently, owing to the\nsignificant progress in high-harmonic generation (HHG) EUV sources and\nadvancements in both hardware and software for computation.\n  In this study, a novel algorithm is introduced and tested, which enables\nwavelength-multiplexed reconstruction that enhances the measurement throughput\nand introduces data diversity, allowing the accurate characterisation of sample\nstructures. To tackle the inherent instabilities of the HHG source, a modal\napproach was adopted, which represents the cross-density function of the\nillumination by a series of mutually incoherent and independent spatial modes.\n  The proposed algorithm was implemented on a mainstream machine learning\nplatform, which leverages automatic differentiation to manage the drastic\ngrowth in model complexity and expedites the computation using GPU\nacceleration. By optimising over 200 million parameters, we demonstrate the\nalgorithm's capacity to accommodate experimental uncertainties and achieve a\nresolution approaching the diffraction limit in reflection geometry. The\nreconstruction of wafer samples with 20-nm heigh patterned gold structures on a\nsilicon substrate highlights our ability to handle complex physical\ninterrelations involving a multitude of parameters. These results establish\nptychography as an efficient and accurate metrology tool.",
            "author": [
                "Yifeng Shao",
                "Sven Weerdenburg",
                "Jacob Seifert",
                "H. Paul Urbach",
                "Allard P. Mosk",
                "Wim Coene"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14780v1",
                "http://arxiv.org/pdf/2311.14780v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "physics.optics"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14583v1",
            "title": "GPT Struct Me: Probing GPT Models on Narrative Entity Extraction",
            "updated": "2023-11-24T16:19:04Z",
            "published": "2023-11-24T16:19:04Z",
            "summary": "The importance of systems that can extract structured information from\ntextual data becomes increasingly pronounced given the ever-increasing volume\nof text produced on a daily basis. Having a system that can effectively extract\nsuch information in an interoperable manner would be an asset for several\ndomains, be it finance, health, or legal. Recent developments in natural\nlanguage processing led to the production of powerful language models that can,\nto some degree, mimic human intelligence. Such effectiveness raises a pertinent\nquestion: Can these models be leveraged for the extraction of structured\ninformation? In this work, we address this question by evaluating the\ncapabilities of two state-of-the-art language models -- GPT-3 and GPT-3.5,\ncommonly known as ChatGPT -- in the extraction of narrative entities, namely\nevents, participants, and temporal expressions. This study is conducted on the\nText2Story Lusa dataset, a collection of 119 Portuguese news articles whose\nannotation framework includes a set of entity structures along with several\ntags and attribute values. We first select the best prompt template through an\nablation study over prompt components that provide varying degrees of\ninformation on a subset of documents of the dataset. Subsequently, we use the\nbest templates to evaluate the effectiveness of the models on the remaining\ndocuments. The results obtained indicate that GPT models are competitive with\nout-of-the-box baseline systems, presenting an all-in-one alternative for\npractitioners with limited resources. By studying the strengths and limitations\nof these models in the context of information extraction, we offer insights\nthat can guide future improvements and avenues to explore in this field.",
            "author": [
                "Hugo Sousa",
                "Nuno Guimar\u00e3es",
                "Al\u00edpio Jorge",
                "Ricardo Campos"
            ],
            "link": [
                "http://dx.doi.org/10.1109/WI-IAT59888.2023.00063",
                "http://arxiv.org/abs/2311.14583v1",
                "http://arxiv.org/pdf/2311.14583v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14582v1",
            "title": "Theoretical investigation of slow gain recovery of quantum cascade\n  lasers observed in pump-probe experiment",
            "updated": "2023-11-24T16:14:48Z",
            "published": "2023-11-24T16:14:48Z",
            "summary": "Time-resolved spectroscopy-based pump-probe experiments performed on quantum\ncascade lasers (QCLs) exhibit an initial fast gain recovery followed by a slow\ntail such that the equilibrium gain is not recovered in a cavity round-trip\ntime. This ultra-slow gain recovery or non-recovered gain cannot be explained\nby only the intersubband carrier dynamics of QCLs. This work shows that the\nFabry-Perot cavity dynamics and localized intersubband electron heating of QCLs\nare essential in ultra-slow and nonrecovered gain recovery. We developed a\ncomprehensive model, coupling cavity dynamics to the intersubband electrons'\nthermal evolution. We employ a four-level coupled Maxwell-Bloch model that\nconsiders temperature-dependent scattering and transport mechanisms in\ncalculating the gain recovery dynamics. If an intense pump pulse electrically\npumped close to the threshold propagates in the forward direction after being\ncoupled into the cavity, the reflected pump pulse will significantly deplete\nthe gain medium while propagating in the backward direction. Additionally, we\nshow that the intersubband electron sustains a localized high temperature even\nafter the pump pulse has left, which affects the overall carrier dynamics and\nleads to an ultra-slow gain recovery process. At near-perfect reflectivity, we\nobserve a gain depletion of 4% for 2 mm QCL. We further demonstrate that an\nadditional 10% gain depletion of probe pulse is seen at a steady state when the\nlaser is pumped at 1.6 times the threshold compared to the case where the hot\nelectron effect is not considered.",
            "author": [
                "Mrinmoy Kundu",
                "Aroni Ghosh",
                "Abdullah Jubair Bin Iqbal",
                "Muhammad Anisuzzaman Talukder"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14582v1",
                "http://arxiv.org/pdf/2311.14582v1"
            ],
            "primary_category": "physics.optics",
            "category": [
                "physics.optics"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14580v1",
            "title": "Large Language Models as Automated Aligners for benchmarking\n  Vision-Language Models",
            "updated": "2023-11-24T16:12:05Z",
            "published": "2023-11-24T16:12:05Z",
            "summary": "With the advancements in Large Language Models (LLMs), Vision-Language Models\n(VLMs) have reached a new level of sophistication, showing notable competence\nin executing intricate cognition and reasoning tasks. However, existing\nevaluation benchmarks, primarily relying on rigid, hand-crafted datasets to\nmeasure task-specific performance, face significant limitations in assessing\nthe alignment of these increasingly anthropomorphic models with human\nintelligence. In this work, we address the limitations via Auto-Bench, which\ndelves into exploring LLMs as proficient aligners, measuring the alignment\nbetween VLMs and human intelligence and value through automatic data curation\nand assessment. Specifically, for data curation, Auto-Bench utilizes LLMs\n(e.g., GPT-4) to automatically generate a vast set of question-answer-reasoning\ntriplets via prompting on visual symbolic representations (e.g., captions,\nobject locations, instance relationships, and etc.). The curated data closely\nmatches human intent, owing to the extensive world knowledge embedded in LLMs.\nThrough this pipeline, a total of 28.5K human-verified and 3,504K unfiltered\nquestion-answer-reasoning triplets have been curated, covering 4 primary\nabilities and 16 sub-abilities. We subsequently engage LLMs like GPT-3.5 to\nserve as judges, implementing the quantitative and qualitative automated\nassessments to facilitate a comprehensive evaluation of VLMs. Our validation\nresults reveal that LLMs are proficient in both evaluation data curation and\nmodel assessment, achieving an average agreement rate of 85%. We envision\nAuto-Bench as a flexible, scalable, and comprehensive benchmark for evaluating\nthe evolving sophisticated VLMs.",
            "author": [
                "Yuanfeng Ji",
                "Chongjian Ge",
                "Weikai Kong",
                "Enze Xie",
                "Zhengying Liu",
                "Zhengguo Li",
                "Ping Luo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14580v1",
                "http://arxiv.org/pdf/2311.14580v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14576v1",
            "title": "Physics-Informed Tensor Basis Neural Network for Turbulence Closure\n  Modeling",
            "updated": "2023-11-24T16:07:35Z",
            "published": "2023-11-24T16:07:35Z",
            "summary": "Despite the increasing availability of high-performance computational\nresources, Reynolds-Averaged Navier-Stokes (RANS) simulations remain the\nworkhorse for the analysis of turbulent flows in real-world applications.\nLinear eddy viscosity models (LEVM), the most commonly employed model type,\ncannot accurately predict complex states of turbulence. This work combines a\ndeep-neural-network-based, nonlinear eddy viscosity model with turbulence\nrealizability constraints as an inductive bias in order to yield improved\npredictions of the anisotropy tensor. Using visualizations based on the\nbarycentric map, we show that the proposed machine learning method's anisotropy\ntensor predictions offer a significant improvement over all LEVMs in\ntraditionally challenging cases with surface curvature and flow separation.\nHowever, this improved anisotropy tensor does not, in general, yield improved\nmean-velocity and pressure field predictions in comparison with the\nbest-performing LEVM.",
            "author": [
                "Leon Riccius",
                "Atul Agrawal",
                "Phaedon-Stelios Koutsourelakis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14576v1",
                "http://arxiv.org/pdf/2311.14576v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14575v1",
            "title": "Oriented singquandles and related algebraic structures",
            "updated": "2023-11-24T16:05:46Z",
            "published": "2023-11-24T16:05:46Z",
            "summary": "In this paper we consider the algebraic structures related to invariants of\ntopological structures introduced respectively in [CEKL22] and [ADEM19]. Our\nmain results is to show how all these structures are closely related to each\nother using the language of binary operations.",
            "author": [
                "Marco Bonatto"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14575v1",
                "http://arxiv.org/pdf/2311.14575v1"
            ],
            "primary_category": "math.GR",
            "category": [
                "math.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14561v1",
            "title": "Quantum Coding with Finite Thermodynamic Resources",
            "updated": "2023-11-24T15:48:49Z",
            "published": "2023-11-24T15:48:49Z",
            "summary": "Quantum direct coding or Schumacher compression generalised the ideas of\nShannon theory, gave an operational meaning to the von Neumann entropy and\nestablished the term qubit. But remembering that information processing is\ncarried out by physical processes prompts one to wonder what thermodynamic\nresources are required to compress quantum information and how they constrain\none's ability to perform this task. That is, if Alice and Bob only have access\nto thermal quantum states and clocks with finite accuracy, how well can they\nmeasure, encode and decode pure quantum state messages? In this work we examine\nthese questions by modelling Alice's typical measurement as a unitary involving\na measurement probe, investigating imperfect timekeeping on encoding and\ndecoding and considering the role of temperature in Bob's appended qubits. In\ndoing so, we derive fidelity bounds for this protocol involving the\ncorrelations Alice can form with their measurement probe, the variance of the\nclock's ticks and the temperature of Bob's qubits. Finally, we give an insight\ninto the entropy produced by these two agents throughout the compression\nprotocol by relating the resources they use to a quantum thermodynamic cooling\nprotocol.",
            "author": [
                "Jake Xuereb",
                "Tiago Debarba",
                "Marcus Huber",
                "Paul Erker"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14561v1",
                "http://arxiv.org/pdf/2311.14561v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14778v1",
            "title": "Anomaly detection in cross-country money transfer temporal networks",
            "updated": "2023-11-24T15:46:32Z",
            "published": "2023-11-24T15:46:32Z",
            "summary": "During the last decades, Anti-Financial Crime (AFC) entities and Financial\nInstitutions have put a constantly increasing effort to reduce financial crime\nand detect fraudulent activities, that are changing and developing in extremely\ncomplex ways. We propose an anomaly detection approach based on network\nanalysis to help AFC officers navigating through the high load of information\nthat is typical of AFC data-driven scenarios. By experimenting on a large\nfinancial dataset of more than 80M cross-country wire transfers, we leverage on\nthe properties of complex networks to develop a tool for explainable anomaly\ndetection, that can help in identifying outliers that could be engaged in\npotentially malicious activities according to financial regulations. We\nidentify a set of network centrality measures that provide useful insights on\nindividual nodes; by keeping track of the evolution over time of the\ncentrality-based node rankings, we are able to highlight sudden and unexpected\nchanges in the roles of individual nodes that deserve further attention by AFC\nofficers. Such changes can hardly be noticed by means of current AFC practices,\nthat sometimes can lack a higher-level, global vision of the system. This\napproach represents a preliminary step in the automation of AFC and AML\nprocesses, serving the purpose of facilitating the work of AFC officers by\nproviding them with a top-down view of the picture emerging from financial\ndata.",
            "author": [
                "Salvatore Vilella",
                "Arthur Thomas Edward Capozzi Lupi",
                "Marco Fornasiero",
                "Dario Moncalvo",
                "Valeria Ricci",
                "Silvia Ronchiadin",
                "Giancarlo Ruffo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14778v1",
                "http://arxiv.org/pdf/2311.14778v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "cs.CE",
                "cs.IR",
                "I.2.1; H.3.3"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14556v1",
            "title": "Binary central stars of planetary nebulae in the Large Magellanic Cloud",
            "updated": "2023-11-24T15:39:41Z",
            "published": "2023-11-24T15:39:41Z",
            "summary": "Close binary central stars of planetary nebulae (PNe) must have formed\nthrough a common envelope evolution during the giant phase experienced by one\nof the stars. Transfer of the angular momentum from the binary system to the\nenvelope leads to the shortening of the binary separations from the radius of\nred giant to the radius of the order of few tenths of AU. Thus, close binary\ncentral stars of planetary nebulae are laboratories to study the common\nenvelope phase of evolution. The close binary fraction in the Galaxy has been\nmeasured in various sky surveys, but the close binary fraction is not yet well\nconstrained for the Magellanic Clouds, and our results may help the study of\ncommon envelope evolution in low-metallicity environments. This paper presents\na continuation of our study of variability in the Magellanic Cloud planetary\nnebulae on the basis of data from the OGLE survey. Previously, we had analysed\nthe OGLE data in the Small Magellanic Cloud. Here, the study is extended to the\nLarge Magellanic Cloud (LMC). In this paper we search for close binary central\nstars with the aim to constrain the binary fraction and period distribution in\nthe LMC. We identified 290 counterparts of PNe in the LMC in the I-band images\nfrom the OGLE-III and OGLE-IV surveys. However, the light curves of ten objects\nwere not accessible in the OGLE database, and thus we analysed the time series\nphotometry of 280 PNe. In total, 32 variables were found, but 5 of them turned\nout to be foreground objects. Another 18 objects show irregular or regular\nvariability that is not attributable to the binarity of their central stars.\nTheir status and the nature of their variability will be verified in the\nfollow-up paper. Nine binary central stars of PNe with periods between 0.24 and\n23.6 days were discovered. The obtained fraction for the LMC PNe is\n3.3^(+2.6)_(-1.6)% without correcting for incompleteness.",
            "author": [
                "M. G\u0142adkowski",
                "M. Hajduk",
                "R. Smolec",
                "R. Szczerba",
                "I. Soszy\u0144ski"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14556v1",
                "http://arxiv.org/pdf/2311.14556v1"
            ],
            "primary_category": "astro-ph.SR",
            "category": [
                "astro-ph.SR",
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14777v1",
            "title": "From Text to Image: Exploring GPT-4Vision's Potential in Advanced\n  Radiological Analysis across Subspecialties",
            "updated": "2023-11-24T15:39:29Z",
            "published": "2023-11-24T15:39:29Z",
            "summary": "The study evaluates and compares GPT-4 and GPT-4Vision for radiological\ntasks, suggesting GPT-4Vision may recognize radiological features from images,\nthereby enhancing its diagnostic potential over text-based descriptions.",
            "author": [
                "Felix Busch",
                "Tianyu Han",
                "Marcus Makowski",
                "Daniel Truhn",
                "Keno Bressem",
                "Lisa Adams"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14777v1",
                "http://arxiv.org/pdf/2311.14777v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16177v1",
            "title": "A hybrid local search algorithm for the Continuous Energy-Constrained\n  Scheduling Problem",
            "updated": "2023-11-24T15:38:59Z",
            "published": "2023-11-24T15:38:59Z",
            "summary": "We consider the Continuous Energy-Constrained Scheduling Problem (CECSP). A\nset of jobs has to be processed on a continuous, shared resource. A schedule\nfor a job consists of a start time, completion time, and a resource consumption\nprofile. We want to find a schedule such that: each job does not start before\nits release time, is completed before its deadline, satisfies its full resource\nrequirement, and respects its lower and upper bounds on resource consumption\nduring processing. Our objective is to minimize the total weighted completion\ntime. We present a hybrid local search approach, using simulated annealing and\nlinear programming, and compare it to a mixed-integer linear programming (MILP)\nformulation. We show that the hybrid local search approach matches the MILP\nformulation in solution quality for small instances, and is able to find a\nfeasible solution for larger instances in reasonable time.",
            "author": [
                "Roel Brouwer",
                "Marjan van den Akker",
                "Han Hoogeveen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16177v1",
                "http://arxiv.org/pdf/2311.16177v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14553v1",
            "title": "Analyzing Cross-Phase Effects of Reactive Power Intervention on\n  Distribution Voltage Control",
            "updated": "2023-11-24T15:36:55Z",
            "published": "2023-11-24T15:36:55Z",
            "summary": "Increasing photovoltaic (PV) penetration in the distribution system can often\nlead to voltage violations. Mitigation of these violations requires reactive\npower intervention from PV inverters. However, the unbalanced nature of the\ndistribution system leads to mixed effects on the voltages of nearby nodes for\neach inverter injecting or absorbing reactive power. In particular, reactive\npower absorption to reduce over-voltage in one phase can exacerbate\nover-voltage in a different phase. In this paper, the factors impacting the\nincremental and decremental voltage effects of reactive power intervention are\nanalyzed in detail. The result of these effects on the distribution system\nperformance is presented to highlight their significance and the need to factor\nthem in for any coordinated voltage control algorithm.",
            "author": [
                "Dhaval Dalal",
                "Anamitra Pal",
                "Raja Ayyanar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14553v1",
                "http://arxiv.org/pdf/2311.14553v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14552v2",
            "title": "Griffon: Spelling out All Object Locations at Any Granularity with Large\n  Language Models",
            "updated": "2023-11-27T09:54:00Z",
            "published": "2023-11-24T15:35:07Z",
            "summary": "Replicating the innate human ability to detect all objects based on free-form\ntexts at any granularity remains a formidable challenge for Vision-Language\nmodels. Current Large Vision Language Models (LVLMs) are predominantly\nconstrained to grounding a single, pre-existing object, relying solely on data\nfrom Referring Expression Comprehension tasks. The limitation leads to a\ncompromise in model design, necessitating the introduction of visual expert\nmodels or the integration of customized head structures. Beyond these\nconstraints, our research delves into the untapped potential of LVLMs and\nuncover their inherent capability for basic object perception, allowing them to\naccurately identify and locate objects of interest. Building on this insight,\nwe introduce a novel language-prompted localization dataset designed to fully\nunleash the capabilities of LVLMs in integrating fine-grained object perception\nwith precise location awareness. More importantly, we present\n$\\textbf{Griffon}$, a purely LVLM-based baseline, which does not require the\nintroduction of any special tokens, expert models, or additional detection\nmodules. It simply maintains a consistent structure with popular LVLMs by\nunifying data formats across various localization-related scenarios and is\ntrained end-to-end through a well-designed pipeline. Comprehensive experiments\ndemonstrate that $\\textbf{Griffon}$ not only achieves state-of-the-art\nperformance on the fine-grained RefCOCO series but also approaches the\ncapabilities of the expert model Faster RCNN on the detection benchmark MSCOCO.",
            "author": [
                "Yufei Zhan",
                "Yousong Zhu",
                "Zhiyang Chen",
                "Fan Yang",
                "Ming Tang",
                "Jinqiao Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14552v2",
                "http://arxiv.org/pdf/2311.14552v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14551v1",
            "title": "Laser polarization control of ionization-injected electron beams and\n  x-ray radiation in laser wakefield accelerators",
            "updated": "2023-11-24T15:32:54Z",
            "published": "2023-11-24T15:32:54Z",
            "summary": "In this paper we have studied the influence of the laser polarization on the\ndynamics of the ionization-injected electron beams and subsequently the\nproperties of the emitted betatron radiation in laser wakefield accelerators\n(LWFAs). While ionizing by a strong field laser radiation, generated\nphoto-electrons carry a residual transverse momentum in excess of the\nionization potential via the above threshold ionization process. This above\nthreshold ionization (ATI) momentum explicitly depends on the polarization\nstate of the ionizing laser and eventually governs the dynamics of the electron\nbeam trapped inside the wake potential. In order to systematically investigate\nthe effect of the laser polarization, here, we have employed complete three\ndimensional Particle-in-Cell simulations in the nonlinear bubble regime of the\nLWFAs. We focus, in particular, on the effects the laser polarization has on\nthe ionization injection mechanism, and how these features affect the final\nbeam properties, such as, beam charge, energy, energy spread and transverse\nemittance. We have also found that as the laser polarization gradually changes\nfrom linear to circular, the helicity of the electron trajectory, and hence the\nangular momentum carried by the beam increases significantly. Studies have been\nfurther extended to reveal the effect of the laser polarization on the\nradiation emitted by the accelerated electrons. The far field radiation spectra\nhave been calculated for the linear (LP) and circular polarization (CP) states\nof the laser. It has been shown that the spatial distributions and the\npolarization properties (Stokes parameters) of the emitted radiation for the\nabove two cases are substantially different. Therefore, our study provides a\nfacile and efficient alternative to regulate the properties of the accelerated\nelectron beams and x-ray radiation in LWFAs, utilizing ionization injection\nmechanism.",
            "author": [
                "Arghya Mukherjee",
                "Daniel Seipt"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14551v1",
                "http://arxiv.org/pdf/2311.14551v1"
            ],
            "primary_category": "physics.plasm-ph",
            "category": [
                "physics.plasm-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14550v1",
            "title": "Dynamics of metrics in measure spaces and scaling entropy",
            "updated": "2023-11-24T15:31:57Z",
            "published": "2023-11-24T15:31:57Z",
            "summary": "This survey is dedicated to a new direction in the theory of dynamical\nsystems: the dynamics of metrics in measure spaces and new (catalytic)\ninvariants of transformations with invariant measure. A space equipped with a\nmeasure and a metric naturally consistent with each other (a metric triple, or\nan $mm$-space) automatically determines the notion of its entropy class, thus\nallowing one to construct a theory of scaling entropy for dynamical systems\nwith invariant measure, which is different and more general compared to the\nShannon-Kolmogorov theory. This possibility was hinted at by Shannon himself,\nbut the hint went unnoticed. The classification of metric triples in terms of\nmatrix distributions presented in this paper was proposed by M. Gromov and A.\nVershik. We describe some corollaries obtained by applying this theory.\n  A brief overview of the paper is presented in the first chapter.",
            "author": [
                "A. M. Vershik",
                "G. A. Veprev",
                "P. B. Zatitskii"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14550v1",
                "http://arxiv.org/pdf/2311.14550v1"
            ],
            "primary_category": "math.DS",
            "category": [
                "math.DS",
                "Primary 28C15, 28D05, 37A05, 37A35"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14545v1",
            "title": "A fuzzy algorithm for image rescaling and its comparison with other\n  methods of digital image processing",
            "updated": "2023-11-24T15:24:02Z",
            "published": "2023-11-24T15:24:02Z",
            "summary": "The aim of this paper is to present a comparison among the fuzzy-type\nalgorithm for image rescaling introduced by Jurio et al., 2011, quoted in the\nlist of references, with some other existing algorithms such as the classical\nbicubic algorithm and the so-called sampling Kantorovich (SK) one. Note that,\nthe SK algorithm is a recent tool for image rescaling and enhancement that\nrevealed to be useful in several applications to real world problems, while\nbicubic algorithm is widely known in the literature. The comparison among the\nabove mentioned algorithms (all implemented by MatLab programming language) has\nbeen done in term of suitable similarity indexes such as the\nPeak-Signal-to-Noise-Ratio (PSNR) and the likelihood index $S$. Moreover, also\nthe CPU time of the considered algorithms has been analysed.",
            "author": [
                "Danilo Costarelli",
                "Anna Rita Sambucini"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14545v1",
                "http://arxiv.org/pdf/2311.14545v1"
            ],
            "primary_category": "math.FA",
            "category": [
                "math.FA",
                "94A08, 68U10, 41A35, 41A30, 03E72"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14543v1",
            "title": "Data-Efficient Alignment of Large Language Models with Human Feedback\n  Through Natural Language",
            "updated": "2023-11-24T15:20:36Z",
            "published": "2023-11-24T15:20:36Z",
            "summary": "Learning from human feedback is a prominent technique to align the output of\nlarge language models (LLMs) with human expectations. Reinforcement learning\nfrom human feedback (RLHF) leverages human preference signals that are in the\nform of ranking of response pairs to perform this alignment. However, human\npreference on LLM outputs can come in much richer forms including natural\nlanguage, which may provide detailed feedback on strengths and weaknesses of a\ngiven response. In this work we investigate data efficiency of modeling human\nfeedback that is in natural language. Specifically, we fine-tune an open-source\nLLM, e.g., Falcon-40B-Instruct, on a relatively small amount (1000 records or\neven less) of human feedback in natural language in the form of critiques and\nrevisions of responses. We show that this model is able to improve the quality\nof responses from even some of the strongest LLMs such as ChatGPT, BARD, and\nVicuna, through critique and revision of those responses. For instance, through\none iteration of revision of ChatGPT responses, the revised responses have\n56.6% win rate over the original ones, and this win rate can be further\nimproved to 65.9% after applying the revision for five iterations.",
            "author": [
                "Di Jin",
                "Shikib Mehri",
                "Devamanyu Hazarika",
                "Aishwarya Padmakumar",
                "Sungjin Lee",
                "Yang Liu",
                "Mahdi Namazifar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14543v1",
                "http://arxiv.org/pdf/2311.14543v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14542v1",
            "title": "ToddlerDiffusion: Flash Interpretable Controllable Diffusion Model",
            "updated": "2023-11-24T15:20:01Z",
            "published": "2023-11-24T15:20:01Z",
            "summary": "Diffusion-based generative models excel in perceptually impressive synthesis\nbut face challenges in interpretability. This paper introduces\nToddlerDiffusion, an interpretable 2D diffusion image-synthesis framework\ninspired by the human generation system. Unlike traditional diffusion models\nwith opaque denoising steps, our approach decomposes the generation process\ninto simpler, interpretable stages; generating contours, a palette, and a\ndetailed colored image. This not only enhances overall performance but also\nenables robust editing and interaction capabilities. Each stage is meticulously\nformulated for efficiency and accuracy, surpassing Stable-Diffusion (LDM).\nExtensive experiments on datasets like LSUN-Churches and COCO validate our\napproach, consistently outperforming existing methods. ToddlerDiffusion\nachieves notable efficiency, matching LDM performance on LSUN-Churches while\noperating three times faster with a 3.76 times smaller architecture. Our source\ncode is provided in the supplementary material and will be publicly accessible.",
            "author": [
                "Eslam Mohamed Bakr",
                "Liangbing Zhao",
                "Vincent Tao Hu",
                "Matthieu Cord",
                "Patrick Perez",
                "Mohamed Elhoseiny"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14542v1",
                "http://arxiv.org/pdf/2311.14542v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14540v2",
            "title": "RDF Stream Taxonomy: Systematizing RDF Stream Types in Research and\n  Practice",
            "updated": "2023-12-07T09:29:40Z",
            "published": "2023-11-24T15:11:15Z",
            "summary": "Over the years, RDF streaming was explored in research and practice from many\nangles, resulting in a wide range of RDF stream definitions. This variety\npresents a major challenge in discussing and integrating streaming solutions,\ndue to the lack of a common language. This work attempts to address this\ncritical research gap, by systematizing RDF stream types present in the\nliterature in a novel taxonomy. The proposed RDF Stream Taxonomy (RDF-STaX) is\nembodied in an OWL 2 DL ontology that follows the FAIR principles, making it\nreadily applicable in practice. Extensive documentation and additional\nresources are provided, to foster the adoption of the ontology. Two realized\nuse cases are presented, demonstrating the usefulness of the resource in\ndiscussing research works and annotating streaming datasets. Another result of\nthis contribution is the novel nanopublications dataset, which serves as a\ncollaborative, living state-of-the-art review of RDF streaming. The aim of\nRDF-STaX is to address a real need of the community for a better way to\nsystematize and describe RDF streams. The resource is designed to help drive\ninnovation in RDF streaming, by fostering scientific discussion, cooperation,\nand tool interoperability.",
            "author": [
                "Piotr Sowinski",
                "Pawel Szmeja",
                "Maria Ganzha",
                "Marcin Paprzycki"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14540v2",
                "http://arxiv.org/pdf/2311.14540v2"
            ],
            "primary_category": "cs.DB",
            "category": [
                "cs.DB",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14539v1",
            "title": "CMed-GPT: Prompt Tuning for Entity-Aware Chinese Medical Dialogue\n  Generation",
            "updated": "2023-11-24T15:10:56Z",
            "published": "2023-11-24T15:10:56Z",
            "summary": "Medical dialogue generation relies on natural language generation techniques\nto enable online medical consultations. Recently, the widespread adoption of\nlarge-scale models in the field of natural language processing has facilitated\nrapid advancements in this technology. Existing medical dialogue models are\nmostly based on BERT and pre-trained on English corpora, but there is a lack of\nhigh-performing models on the task of Chinese medical dialogue generation. To\nsolve the above problem, this paper proposes CMed-GPT, which is the GPT\npre-training language model based on Chinese medical domain text. The model is\navailable in two versions, namely, base and large, with corresponding\nperplexity values of 8.64 and 8.01. Additionally, we incorporate lexical and\nentity embeddings into the dialogue text in a uniform manner to meet the\nrequirements of downstream dialogue generation tasks. By applying both\nfine-tuning and p-tuning to CMed-GPT, we lowered the PPL from 8.44 to 7.35.\nThis study not only confirms the exceptional performance of the CMed-GPT model\nin generating Chinese biomedical text but also highlights the advantages of\np-tuning over traditional fine-tuning with prefix prompts. Furthermore, we\nvalidate the significance of incorporating external information in medical\ndialogue generation, which enhances the quality of dialogue generation.",
            "author": [
                "Zhijie Qu",
                "Juan Li",
                "Zerui Ma",
                "Jianqiang Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14539v1",
                "http://arxiv.org/pdf/2311.14539v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14536v1",
            "title": "Exploring beyond-mean-field logarithmic divergences in Fermi-polaron\n  energy",
            "updated": "2023-11-24T15:04:13Z",
            "published": "2023-11-24T15:04:13Z",
            "summary": "We perform a diagrammatic analysis of the energy of a mobile impurity\nimmersed in a strongly interacting two component Fermi gas to second order in\nthe impurity-bath interaction. These corrections demonstrate divergent behavior\nin the limit of large impurity momentum. We show the fundamental processes\nresponsible for these logarithmically divergent terms.\n  We study the problem in the general case without any assumptions regarding\nthe fermion-fermion interactions in the bath. We show that the divergent term\ncan be summed up to all orders in the Fermi-Fermi interaction and that the\nresulting expression is equivalent to the one obtained in the few body\ncalculation.\n  Finally, we provide a perturbative calculation to the second order in the\nFermi-Fermi interaction in the annex, and we show the diagrams responsible for\nthese terms.",
            "author": [
                "Ragheed Alhyder",
                "Fr\u00e9d\u00e9ric Chevy",
                "Xavier Leyronas"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14536v1",
                "http://arxiv.org/pdf/2311.14536v1"
            ],
            "primary_category": "cond-mat.quant-gas",
            "category": [
                "cond-mat.quant-gas"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14534v1",
            "title": "Finding Foundation Models for Time Series Classification with a PreText\n  Task",
            "updated": "2023-11-24T15:03:55Z",
            "published": "2023-11-24T15:03:55Z",
            "summary": "Over the past decade, Time Series Classification (TSC) has gained an\nincreasing attention. While various methods were explored, deep learning -\nparticularly through Convolutional Neural Networks (CNNs)-stands out as an\neffective approach. However, due to the limited availability of training data,\ndefining a foundation model for TSC that overcomes the overfitting problem is\nstill a challenging task. The UCR archive, encompassing a wide spectrum of\ndatasets ranging from motion recognition to ECG-based heart disease detection,\nserves as a prime example for exploring this issue in diverse TSC scenarios. In\nthis paper, we address the overfitting challenge by introducing pre-trained\ndomain foundation models. A key aspect of our methodology is a novel pretext\ntask that spans multiple datasets. This task is designed to identify the\noriginating dataset of each time series sample, with the goal of creating\nflexible convolution filters that can be applied across different datasets. The\nresearch process consists of two phases: a pre-training phase where the model\nacquires general features through the pretext task, and a subsequent\nfine-tuning phase for specific dataset classifications. Our extensive\nexperiments on the UCR archive demonstrate that this pre-training strategy\nsignificantly outperforms the conventional training approach without\npre-training. This strategy effectively reduces overfitting in small datasets\nand provides an efficient route for adapting these models to new datasets, thus\nadvancing the capabilities of deep learning in TSC.",
            "author": [
                "Ali Ismail-Fawaz",
                "Maxime Devanne",
                "Stefano Berretti",
                "Jonathan Weber",
                "Germain Forestier"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14534v1",
                "http://arxiv.org/pdf/2311.14534v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14532v1",
            "title": "Digital Twin-Native AI-Driven Service Architecture for Industrial\n  Networks",
            "updated": "2023-11-24T14:56:13Z",
            "published": "2023-11-24T14:56:13Z",
            "summary": "The dramatic increase in the connectivity demand results in an excessive\namount of Internet of Things (IoT) sensors. To meet the management needs of\nthese large-scale networks, such as accurate monitoring and learning\ncapabilities, Digital Twin (DT) is the key enabler. However, current attempts\nregarding DT implementations remain insufficient due to the perpetual\nconnectivity requirements of IoT networks. Furthermore, the sensor data\nstreaming in IoT networks cause higher processing time than traditional\nmethods. In addition to these, the current intelligent mechanisms cannot\nperform well due to the spatiotemporal changes in the implemented IoT network\nscenario. To handle these challenges, we propose a DT-native AI-driven service\narchitecture in support of the concept of IoT networks. Within the proposed\nDT-native architecture, we implement a TCP-based data flow pipeline and a\nReinforcement Learning (RL)-based learner model. We apply the proposed\narchitecture to one of the broad concepts of IoT networks, the Internet of\nVehicles (IoV). We measure the efficiency of our proposed architecture and note\n~30% processing time-saving thanks to the TCP-based data flow pipeline.\nMoreover, we test the performance of the learner model by applying several\nlearning rate combinations for actor and critic networks and highlight the most\nsuccessive model.",
            "author": [
                "Kubra Duran",
                "Matthew Broadbent",
                "Gokhan Yurdakul",
                "Berk Canberk"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14532v1",
                "http://arxiv.org/pdf/2311.14532v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14530v1",
            "title": "Machine Translation for Ge'ez Language",
            "updated": "2023-11-24T14:55:23Z",
            "published": "2023-11-24T14:55:23Z",
            "summary": "Machine translation (MT) for low-resource languages such as Ge'ez, an ancient\nlanguage that is no longer spoken in daily life, faces challenges such as\nout-of-vocabulary words, domain mismatches, and lack of sufficient labeled\ntraining data. In this work, we explore various methods to improve Ge'ez MT,\nincluding transfer-learning from related languages, optimizing shared\nvocabulary and token segmentation approaches, finetuning large pre-trained\nmodels, and using large language models (LLMs) for few-shot translation with\nfuzzy matches. We develop a multilingual neural machine translation (MNMT)\nmodel based on languages relatedness, which brings an average performance\nimprovement of about 4 BLEU compared to standard bilingual models. We also\nattempt to finetune the NLLB-200 model, one of the most advanced translation\nmodels available today, but find that it performs poorly with only 4k training\nsamples for Ge'ez. Furthermore, we experiment with using GPT-3.5, a\nstate-of-the-art LLM, for few-shot translation with fuzzy matches, which\nleverages embedding similarity-based retrieval to find context examples from a\nparallel corpus. We observe that GPT-3.5 achieves a remarkable BLEU score of\n9.2 with no initial knowledge of Ge'ez, but still lower than the MNMT baseline\nof 15.2. Our work provides insights into the potential and limitations of\ndifferent approaches for low-resource and ancient language MT.",
            "author": [
                "Aman Kassahun Wassie"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14530v1",
                "http://arxiv.org/pdf/2311.14530v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14529v1",
            "title": "In situ Imaging of Precipitate Formation in Additively Manufactured\n  Al-Alloys by Scanning X-ray Fluorescence",
            "updated": "2023-11-24T14:54:09Z",
            "published": "2023-11-24T14:54:09Z",
            "summary": "A new family of high-strength Al-alloys has recently been developed, tailored\nfor the powder bed fusion-laser beam process. In these alloys, Mn, Cr and Zr\nare incorporated in solid solution at amounts up to three times that of\nequilibrium in the as-printed state. Mn and Cr-enriched precipitates that form\nduring printing and heat treatment influence the material's mechanical\nproperties. In this study, direct imaging of these precipitates was\naccomplished through the utilisation of in situ synchrotron-based scanning\nX-ray fluorescence. During heat treatment, a selective accumulation of Cr and\nMn in two distinct types of precipitates at grain boundaries was observed.\nAdditionally, the microstructure at the melt-pool boundary, containing\nprecipitates found in the as-printed state, remains thermally stable during the\nheat treatment. The study demonstrates the significant value of employing\nhigh-sensitivity in-situ X-ray fluorescence microscopy in exploring the\nkinetics of sub-micrometre scale precipitation.",
            "author": [
                "Isac Lazar",
                "Bharat Mehta",
                "Vendulka Bertschov\u00e1",
                "Sri Bala Aditya Malladi",
                "Zhe Ren",
                "Srashtasrita Das",
                "Johannes Hagemann",
                "Gerald Falkenberg",
                "Karin Frisk",
                "Anders Mikkelsen",
                "Lars Nyborg"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14529v1",
                "http://arxiv.org/pdf/2311.14529v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14521v2",
            "title": "GaussianEditor: Swift and Controllable 3D Editing with Gaussian\n  Splatting",
            "updated": "2023-12-01T10:09:21Z",
            "published": "2023-11-24T14:46:59Z",
            "summary": "3D editing plays a crucial role in many areas such as gaming and virtual\nreality. Traditional 3D editing methods, which rely on representations like\nmeshes and point clouds, often fall short in realistically depicting complex\nscenes. On the other hand, methods based on implicit 3D representations, like\nNeural Radiance Field (NeRF), render complex scenes effectively but suffer from\nslow processing speeds and limited control over specific scene areas. In\nresponse to these challenges, our paper presents GaussianEditor, an innovative\nand efficient 3D editing algorithm based on Gaussian Splatting (GS), a novel 3D\nrepresentation. GaussianEditor enhances precision and control in editing\nthrough our proposed Gaussian semantic tracing, which traces the editing target\nthroughout the training process. Additionally, we propose Hierarchical Gaussian\nsplatting (HGS) to achieve stabilized and fine results under stochastic\ngenerative guidance from 2D diffusion models. We also develop editing\nstrategies for efficient object removal and integration, a challenging task for\nexisting methods. Our comprehensive experiments demonstrate GaussianEditor's\nsuperior control, efficacy, and rapid performance, marking a significant\nadvancement in 3D editing. Project Page:\nhttps://buaacyw.github.io/gaussian-editor/",
            "author": [
                "Yiwen Chen",
                "Zilong Chen",
                "Chi Zhang",
                "Feng Wang",
                "Xiaofeng Yang",
                "Yikai Wang",
                "Zhongang Cai",
                "Lei Yang",
                "Huaping Liu",
                "Guosheng Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14521v2",
                "http://arxiv.org/pdf/2311.14521v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14520v1",
            "title": "Shifted Composition I: Harnack and Reverse Transport Inequalities",
            "updated": "2023-11-24T14:46:48Z",
            "published": "2023-11-24T14:46:48Z",
            "summary": "We formulate a new information-theoretic principle--the shifted composition\nrule--which bounds the divergence (e.g., Kullback-Leibler or R\\'enyi) between\nthe laws of two stochastic processes via the introduction of auxiliary shifts.\nIn this paper, we apply this principle to prove reverse transport inequalities\nfor diffusions which, by duality, imply F.-Y. Wang's celebrated dimension-free\nHarnack inequalities. Our approach bridges continuous-time coupling methods\nfrom geometric analysis with the discrete-time shifted divergence technique\nfrom differential privacy and sampling. It also naturally gives rise to (1) an\nalternative continuous-time coupling method based on optimal transport, which\nbypasses Girsanov transformations, (2) functional inequalities for\ndiscrete-time processes, and (3) a family of \"reverse\" Harnack inequalities.",
            "author": [
                "Jason M. Altschuler",
                "Sinho Chewi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14520v1",
                "http://arxiv.org/pdf/2311.14520v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR",
                "cs.IT",
                "math.AP",
                "math.FA",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14519v1",
            "title": "Benchmarking Large Language Models for Log Analysis, Security, and\n  Interpretation",
            "updated": "2023-11-24T14:46:14Z",
            "published": "2023-11-24T14:46:14Z",
            "summary": "Large Language Models (LLM) continue to demonstrate their utility in a\nvariety of emergent capabilities in different fields. An area that could\nbenefit from effective language understanding in cybersecurity is the analysis\nof log files. This work explores LLMs with different architectures (BERT,\nRoBERTa, DistilRoBERTa, GPT-2, and GPT-Neo) that are benchmarked for their\ncapacity to better analyze application and system log files for security.\nSpecifically, 60 fine-tuned language models for log analysis are deployed and\nbenchmarked. The resulting models demonstrate that they can be used to perform\nlog analysis effectively with fine-tuning being particularly important for\nappropriate domain adaptation to specific log types. The best-performing\nfine-tuned sequence classification model (DistilRoBERTa) outperforms the\ncurrent state-of-the-art; with an average F1-Score of 0.998 across six datasets\nfrom both web application and system log sources. To achieve this, we propose\nand implement a new experimentation pipeline (LLM4Sec) which leverages LLMs for\nlog analysis experimentation, evaluation, and analysis.",
            "author": [
                "Egil Karlsen",
                "Xiao Luo",
                "Nur Zincir-Heywood",
                "Malcolm Heywood"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14519v1",
                "http://arxiv.org/pdf/2311.14519v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14517v1",
            "title": "tinyCLAP: Distilling Constrastive Language-Audio Pretrained Models",
            "updated": "2023-11-24T14:45:53Z",
            "published": "2023-11-24T14:45:53Z",
            "summary": "Contrastive Language-Audio Pretraining (CLAP) became of crucial importance in\nthe field of audio and speech processing. Its employment ranges from sound\nevent detection to text-to-audio generation. However, one of the main\nlimitations is the considerable amount of data required in the training process\nand the overall computational complexity during inference. This paper\ninvestigates how we can reduce the complexity of contrastive language-audio\npre-trained models, yielding an efficient model that we call tinyCLAP. We\nderive an unimodal distillation loss from first principles and explore how the\ndimensionality of the shared, multimodal latent space can be reduced via\npruning. TinyCLAP uses only 6% of the original Microsoft CLAP parameters with a\nminimal reduction (less than 5%) in zero-shot classification performance across\nthe three sound event detection datasets on which it was tested",
            "author": [
                "Francesco Paissan",
                "Elisabetta Farella"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14517v1",
                "http://arxiv.org/pdf/2311.14517v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.CL",
                "cs.LG",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14515v1",
            "title": "On RIS-Aided SIMO Gaussian Channels: Towards A Single-RF MIMO\n  Transceiver Architecture",
            "updated": "2023-11-24T14:43:42Z",
            "published": "2023-11-24T14:43:42Z",
            "summary": "In this paper, for a single-input multiple-output (SIMO) system aided by a\npassive reconfigurable intelligent surface (RIS), the joint transmission\naccomplished by the single transmit antenna and the RIS with multiple\ncontrollable reflective elements is considered. Relying on a general capacity\nupper bound derived by a maximum-trace argument, we respectively characterize\nthe capacity of such \\rev{a} channel in the low-SNR or the rank-one regimes, in\nwhich the optimal configuration of the RIS is proved to be beamforming with\ncarefully-chosen phase shifts. To exploit the potential of modulating extra\ninformation on the RIS, based on the QR decomposition, successive interference\ncancellation, and a strategy named \\textit{partially beamforming and partially\ninformation-carrying}, we propose a novel transceiver architecture with only a\nsingle RF front end at the transmitter, by which the considered channel can be\nregarded as a concatenation of a vector Gaussian channel and several\nphase-modulated channels. Especially, we investigate a class of vector Gaussian\nchannels with a hypersphere input support constraint, and not only generalize\nthe existing result to arbitrary-dimensional real spaces but also present its\nhigh-order capacity asymptotics, by which both capacities of\nhypersphere-constrained channels and achievable rates of the proposed\ntransceiver with two different signaling schemes can be well-approximated.\nInformation-theoretic analyses show that the transceiver architecture designed\nfor the SIMO channel has a boosted multiplexing gain, rather than one for the\nconventionally-used optimized beamforming scheme.Numerical results verify our\nderived asymptotics and show notable superiority of the proposed transceiver.",
            "author": [
                "Ru-Han Chen",
                "Jing Zhou",
                "Yonggang Zhu",
                "Kai Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14515v1",
                "http://arxiv.org/pdf/2311.14515v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14512v1",
            "title": "The centroid speed as a characteristic of the group speed of solar\n  coronal fast magnetoacoustic wave trains",
            "updated": "2023-11-24T14:41:17Z",
            "published": "2023-11-24T14:41:17Z",
            "summary": "The highly-filamented nature of the coronal plasma significantly influences\ndynamic processes in the corona such as magnetohydrodynamic waves and\noscillations. Fast magnetoacoustic waves, guided by coronal plasma\nnon-uniformities, exhibit strong geometric dispersion, forming quasi-periodic\nfast-propagating (QFP) wave trains. QFP wave trains are observed in\nextreme-ultraviolet imaging data and indirectly in microwaves and low-frequency\nradio, aiding in understanding the magnetic connectivity, energy, and mass\ntransport in the corona. However, measuring the field-aligned group speed of\nQFP wave trains, as a key parameter for seismological analysis, is challenging\ndue to strong dispersion and associated rapid evolution of the wave train\nenvelope. We demonstrate that the group speed of QFP wave trains formed in\nplane low-$\\beta$ coronal plasma non-uniformities can be assessed through the\npropagation of the wave train's effective centre of mass, referred to as the\nwave train's centroid speed. This centroid speed, as a potential observable, is\nshown empirically to correspond to the group speed of the most energetic\nFourier harmonic in the wave train. The centroid speed is found to be almost\ninsensitive to the waveguide density contrast with the ambient corona, and to\nvary with the steepness of the transverse density profile. The discrepancy\nbetween the centroid speed as the group speed measure and the phase speed at\nthe corresponding wavelength is shown to reach 70\\%, which is crucial for the\nenergy flux estimation and interpretation of observations.",
            "author": [
                "Dmitrii Y. Kolotkov",
                "Valery M. Nakariakov",
                "Maximilien Cloesen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14512v1",
                "http://arxiv.org/pdf/2311.14512v1"
            ],
            "primary_category": "astro-ph.SR",
            "category": [
                "astro-ph.SR",
                "physics.space-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14508v1",
            "title": "Filasofia: A Framework for Streamlined Development of Real-Time Surgical\n  Simulations",
            "updated": "2023-11-24T14:33:41Z",
            "published": "2023-11-24T14:33:41Z",
            "summary": "Virtual reality simulation has become a popular approach for training and\nassessing medical students. It offers diverse scenarios, realistic visuals, and\nquantitative performance metrics for objective evaluation. However, creating\nthese simulations can be time-consuming and complex, even for experienced\nusers. The SOFA framework is an open-source solution that efficiently simulates\nfinite element (FE) models in real-time. Yet, some users find it challenging to\nnavigate the software due to the numerous components required for a basic\nsimulation and their variability. Additionally, SOFA has limited visual\nrendering capabilities, leading developers to integrate other software for\nhigh-quality visuals. To address these issues, we developed Filasofia, a\ndedicated framework that simplifies development, provides modern visualization,\nand allows fine-tuning using SOFA objects. Our experiments demonstrate that\nFilasofia outperforms conventional SOFA simulations, even with real-time\nsubdivision. Our design approach aims to streamline development while offering\nflexibility for fine-tuning. Future work will focus on further simplification\nof the development process for users.",
            "author": [
                "Vladimir Poliakov",
                "Dzmitry Tsetserukou",
                "Emmanuel Vander Poorten"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14508v1",
                "http://arxiv.org/pdf/2311.14508v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14506v1",
            "title": "Multi-Class Anomaly Detection based on Regularized Discriminative\n  Coupled hypersphere-based Feature Adaptation",
            "updated": "2023-11-24T14:26:07Z",
            "published": "2023-11-24T14:26:07Z",
            "summary": "In anomaly detection, identification of anomalies across diverse product\ncategories is a complex task. This paper introduces a new model by including\nclass discriminative properties obtained by a modified Regularized\nDiscriminative Variational Auto-Encoder (RD-VAE) in the feature extraction\nprocess of Coupled-hypersphere-based Feature Adaptation (CFA). By doing so, the\nproposed Regularized Discriminative Coupled-hypersphere-based Feature\nAdaptation (RD-CFA), forms a solution for multi-class anomaly detection. By\nusing the discriminative power of RD-VAE to capture intricate class\ndistributions, combined with CFA's robust anomaly detection capability, the\nproposed method excels in discerning anomalies across various classes.\nExtensive evaluations on multi-class anomaly detection and localization using\nthe MVTec AD and BeanTech AD datasets showcase the effectiveness of RD-CFA\ncompared to eight leading contemporary methods.",
            "author": [
                "Mehdi Rafiei",
                "Alexandros Iosifidis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14506v1",
                "http://arxiv.org/pdf/2311.14506v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14505v1",
            "title": "Analysing the Impact of Removing Infrequent Words on Topic Quality in\n  LDA Models",
            "updated": "2023-11-24T14:20:12Z",
            "published": "2023-11-24T14:20:12Z",
            "summary": "An initial procedure in text-as-data applications is text preprocessing. One\nof the typical steps, which can substantially facilitate computations, consists\nin removing infrequent words believed to provide limited information about the\ncorpus. Despite popularity of vocabulary pruning, not many guidelines on how to\nimplement it are available in the literature. The aim of the paper is to fill\nthis gap by examining the effects of removing infrequent words for the quality\nof topics estimated using Latent Dirichlet Allocation. The analysis is based on\nMonte Carlo experiments taking into account different criteria for infrequent\nterms removal and various evaluation metrics. The results indicate that pruning\nis beneficial and that the share of vocabulary which might be eliminated can be\nquite considerable.",
            "author": [
                "Victor Bystrov",
                "Viktoriia Naboka-Krell",
                "Anna Staszewska-Bystrova",
                "Peter Winker"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14505v1",
                "http://arxiv.org/pdf/2311.14505v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14504v1",
            "title": "Ultra-slow dynamics of free-running ring lasers: towards a minimal model",
            "updated": "2023-11-24T14:19:57Z",
            "published": "2023-11-24T14:19:57Z",
            "summary": "The dynamics of a resonant, free-running ring laser, in the common case of a\nfast relaxation of the atomic polarization, is unexpectedly highly singular. As\nshown in [Phys. Rev. Research, {\\bf 5}, 023059 (2023)], this is due to the\ncloseness to a pure Hamiltonian dynamics ruled by a nonlinear wave equation,\nherein named Klein-Gordon-Toda model. In this paper, we derive a\nquasi-Hamiltonian model which allows describing realistic systems. In\nparticular, we identify two nearly conserved, energy-like quantities, which\n``naturally\" exhibit an ultra-slow dynamics confirmed and highlighted by\nnumerical simulations. A minimal version of the quasi-Hamiltonian model is\nfinally derived, which does not only reproduce the laser thresholds, but also\nhelps understanding the origin of the nearly integrable character of the laser\ndynamics.",
            "author": [
                "Giovanni Giacomelli",
                "Antonio Politi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14504v1",
                "http://arxiv.org/pdf/2311.14504v1"
            ],
            "primary_category": "physics.optics",
            "category": [
                "physics.optics",
                "nlin.CD"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14503v2",
            "title": "Back-action supercurrent diodes",
            "updated": "2023-11-29T05:58:35Z",
            "published": "2023-11-24T14:18:28Z",
            "summary": "Back-action refers to a response that retro-acts on a system to tailor its\nproperties with respect to an external stimulus. This self-induced effect\ngenerally belongs to both the natural and technological realm, ranging from\nneural networks to optics and electronic circuitry. In electronics, back-action\nmechanisms are at the heart of many classes of devices such as amplifiers,\noscillators, and sensors. Here, we demonstrate that back-action can be\nsuccessfully exploited to achieve $\\textit{non-reciprocal}$ transport in\nsuperconducting circuits. Our device realizes a supercurrent diode, since the\ndissipationless current flows in one direction whereas dissipative transport\noccurs in the opposite direction. Supercurrent diodes presented so far rely on\nmagnetic elements or vortices to mediate charge transport or external magnetic\nfields to break time-reversal symmetry. In our implementation, back-action\nsolely turns a conventional reciprocal superconducting weak link with no\nasymmetry between the current bias directions into a diode, where the critical\ncurrent amplitude depends on the bias sign. The self-interaction of the\nsupercurrent with the device stems from the gate tunability of the critical\ncurrent, which uniquely promotes up to $\\sim$88% of magnetic field-free signal\nrectification and diode functionality with selectable polarity. The concept we\nintroduce is very general and can be applied directly to a large variety of\ndevices, thereby opening novel functionalities in superconducting electronics.",
            "author": [
                "Daniel Margineda",
                "Alessandro Crippa",
                "Elia Strambini",
                "Yuri Fukaya",
                "Maria Teresa Mercaldo",
                "Carmine Ortix",
                "Mario Cuoco",
                "Francesco Giazotto"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14503v2",
                "http://arxiv.org/pdf/2311.14503v2"
            ],
            "primary_category": "cond-mat.mes-hall",
            "category": [
                "cond-mat.mes-hall",
                "cond-mat.supr-con"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14497v1",
            "title": "Advancing High-Throughput Combinatorial Aging Studies of Hybrid\n  Perovskite Thin-Films via Precise Automated Characterization Methods and\n  Machine Learning Assisted Analysis",
            "updated": "2023-11-24T14:13:11Z",
            "published": "2023-11-24T14:13:11Z",
            "summary": "To optimize materials' stability, automated high-throughput workflows are of\nincreasing interest. However, many of those workflows use processes not\nsuitable for large-area depositions which limits the transferability of\nresults. While combinatorial approaches based on vapour-based depositions are\ninherently scalable, their potential for controlled stability assessments has\nyet to be exploited. Based on MAPbI3 thin-films as a prototypical system, we\ndemonstrate a combinatorial inert-gas workflow to study materials degradation\nbased on intrinsic factors only, closely resembling conditions in encapsulated\nde-vices. Through a comprehensive set of automated X-Ray fluorescence (XRF),\nX-Ray diffraction (XRD) and UV-Vis characterizations, we aim to obtain a\nholistic understanding of thin-film properties of pristine and aged thin-films.\nFrom phase changes derived from XRD characterizations before and after aging,\nwe observe simi-lar aging behaviours for MAPbI3 thin-films with varying PbI2\nresiduals. Using a custom-designed in-situ UV-Vis aging setup, the\ncombinatorial libraries are exposed to relevant aging conditions, such as heat\nor light-bias exposure. Simultaneously, UV-Vis photospectroscopy is performed\nto gain kinetic insights into the aging process which can be linked to\nintrinsic degradation processes such as autocatalytic decomposition. Despite\nscattering effects, which complicate the conventional interpretation of in-situ\nUV-Vis results, we demonstrate how a machine learning model trained on the\ncomprehensive characterization data before and after the aging process can link\noptical changes to phase changes during aging. Consequently, this approach does\nnot only enable semi-quantitative comparisons of materials' stability but also\nprovides detailed insights into the underlying degradation processes which are\notherwise mostly reported for investigations on single samples.",
            "author": [
                "Alexander Wieczorek",
                "Austin G. Kuba",
                "Jan Sommerh\u00e4user",
                "Luis Nicklaus Caceres",
                "Christian Wolff",
                "Sebastian Siol"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14497v1",
                "http://arxiv.org/pdf/2311.14497v1"
            ],
            "primary_category": "physics.app-ph",
            "category": [
                "physics.app-ph",
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14495v1",
            "title": "StableSSM: Alleviating the Curse of Memory in State-space Models through\n  Stable Reparameterization",
            "updated": "2023-11-24T14:08:31Z",
            "published": "2023-11-24T14:08:31Z",
            "summary": "In this paper, we investigate the long-term memory learning capabilities of\nstate-space models (SSMs) from the perspective of parameterization. We prove\nthat state-space models without any reparameterization exhibit a memory\nlimitation similar to that of traditional RNNs: the target relationships that\ncan be stably approximated by state-space models must have an exponential\ndecaying memory. Our analysis identifies this \"curse of memory\" as a result of\nthe recurrent weights converging to a stability boundary, suggesting that a\nreparameterization technique can be effective. To this end, we introduce a\nclass of reparameterization techniques for SSMs that effectively lift its\nmemory limitations. Besides improving approximation capabilities, we further\nillustrate that a principled choice of reparameterization scheme can also\nenhance optimization stability. We validate our findings using synthetic\ndatasets and language models.",
            "author": [
                "Shida Wang",
                "Qianxiao Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14495v1",
                "http://arxiv.org/pdf/2311.14495v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL",
                "math.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14494v2",
            "title": "MVControl: Adding Conditional Control to Multi-view Diffusion for\n  Controllable Text-to-3D Generation",
            "updated": "2023-11-27T12:39:42Z",
            "published": "2023-11-24T14:07:53Z",
            "summary": "We introduce MVControl, a novel neural network architecture that enhances\nexisting pre-trained multi-view 2D diffusion models by incorporating additional\ninput conditions, e.g. edge maps. Our approach enables the generation of\ncontrollable multi-view images and view-consistent 3D content. To achieve\ncontrollable multi-view image generation, we leverage MVDream as our base\nmodel, and train a new neural network module as additional plugin for\nend-to-end task-specific condition learning. To precisely control the shapes\nand views of generated images, we innovatively propose a new conditioning\nmechanism that predicts an embedding encapsulating the input spatial and view\nconditions, which is then injected to the network globally. Once MVControl is\ntrained, score-distillation (SDS) loss based optimization can be performed to\ngenerate 3D content, in which process we propose to use a hybrid diffusion\nprior. The hybrid prior relies on a pre-trained Stable-Diffusion network and\nour trained MVControl for additional guidance. Extensive experiments\ndemonstrate that our method achieves robust generalization and enables the\ncontrollable generation of high-quality 3D content. Code available at\nhttps://github.com/WU-CVGL/MVControl/.",
            "author": [
                "Zhiqi Li",
                "Yiming Chen",
                "Lingzhe Zhao",
                "Peidong Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14494v2",
                "http://arxiv.org/pdf/2311.14494v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14492v1",
            "title": "Numerical Generalized Randomized HMC processes for restricted domains",
            "updated": "2023-11-24T14:06:18Z",
            "published": "2023-11-24T14:06:18Z",
            "summary": "We propose a generic approach for numerically efficient simulation from\nanalytically intractable distributions with constrained support. Our approach\nrelies upon Generalized Randomized Hamiltonian Monte Carlo (GRHMC) processes\nand combines these with a randomized transition kernel that appropriately\nadjusts the Hamiltonian flow at the boundary of the constrained domain,\nensuring that it remains within the domain. The numerical implementation of\nthis constrained GRHMC process exploits the sparsity of the randomized\ntransition kernel and the specific structure of the constraints so that the\nproposed approach is numerically accurate, computationally fast and operational\neven in high-dimensional applications. We illustrate this approach with\nposterior distributions of several Bayesian models with challenging parameter\ndomain constraints in applications to real-word data sets. Building on the\ncapability of GRHMC processes to efficiently explore otherwise challenging and\nhigh-dimensional posteriors, the proposed method expands the set of Bayesian\nmodels that can be analyzed by using the standard Markov-Chain Monte-Carlo\n(MCMC) methodology, As such, it can advance the development and use of Bayesian\nmodels with useful constrained priors, which are difficult to handle with\nexisting methods. The article is accompanied by an R-package\n(\\url{https://github.com/torekleppe/pdmphmc}), which allows for automatically\nimplementing GRHMC processes for arbitrary target distributions and domain\nconstraints.",
            "author": [
                "Tore Selland Kleppe",
                "Roman Liesenfeld"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14492v1",
                "http://arxiv.org/pdf/2311.14492v1"
            ],
            "primary_category": "stat.CO",
            "category": [
                "stat.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14490v1",
            "title": "Overview Of The 2023 Icassp Sp Clarity Challenge: Speech Enhancement For\n  Hearing Aids",
            "updated": "2023-11-24T14:02:55Z",
            "published": "2023-11-24T14:02:55Z",
            "summary": "This paper reports on the design and outcomes of the ICASSP SP Clarity\nChallenge: Speech Enhancement for Hearing Aids. The scenario was a listener\nattending to a target speaker in a noisy, domestic environment. There were\nmultiple interferers and head rotation by the listener. The challenge extended\nthe second Clarity Enhancement Challenge (CEC2) by fixing the amplification\nstage of the hearing aid; evaluating with a combined metric for speech\nintelligibility and quality; and providing two evaluation sets, one based on\nsimulation and the other on real-room measurements. Five teams improved on the\nbaseline system for the simulated evaluation set, but the performance on the\nmeasured evaluation set was much poorer. Investigations are on-going to\ndetermine the exact cause of the mismatch between the simulated and measured\ndata sets. The presence of transducer noise in the measurements, lower order\nAmbisonics harming the ability for systems to exploit binaural cues and the\ndifferences between real and simulated room impulse responses are suggested\ncauses",
            "author": [
                "Trevor J. Cox",
                "Jon Barker",
                "Will Bailey",
                "Simone Graetzer",
                "Michael A. Akeroyd",
                "John F. Culling",
                "Graham Naylor"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14490v1",
                "http://arxiv.org/pdf/2311.14490v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14488v1",
            "title": "Lightweight Framework for Automated Kidney Stone Detection using coronal\n  CT images",
            "updated": "2023-11-24T14:00:18Z",
            "published": "2023-11-24T14:00:18Z",
            "summary": "Kidney stone disease results in millions of annual visits to emergency\ndepartments in the United States. Computed tomography (CT) scans serve as the\nstandard imaging modality for efficient detection of kidney stones. Various\napproaches utilizing convolutional neural networks (CNNs) have been proposed to\nimplement automatic diagnosis of kidney stones. However, there is a growing\ninterest in employing fast and efficient CNNs on edge devices in clinical\npractice. In this paper, we propose a lightweight fusion framework for kidney\ndetection and kidney stone diagnosis on coronal CT images. In our design, we\naim to minimize the computational costs of training and inference while\nimplementing an automated approach. The experimental results indicate that our\nframework can achieve competitive outcomes using only 8\\% of the original\ntraining data. These results include an F1 score of 96\\% and a False Negative\n(FN) error rate of 4\\%. Additionally, the average detection time per CT image\non a CPU is 0.62 seconds. Reproducibility: Framework implementation and models\navailable on GitHub.",
            "author": [
                "Fangyijie Wang",
                "Guenole Silvestre",
                "Kathleen M. Curran"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14488v1",
                "http://arxiv.org/pdf/2311.14488v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14487v1",
            "title": "Reconciliation of expert priors for quantities and events and\n  application within the probabilistic Delphi method",
            "updated": "2023-11-24T13:55:10Z",
            "published": "2023-11-24T13:55:10Z",
            "summary": "We consider the problem of aggregating the judgements of a group of experts\nto form a single prior distribution representing the judgements of the group.\nWe develop a Bayesian hierarchical model to reconcile the judgements of the\ngroup of experts based on elicited quantiles for continuous quantities and\nprobabilities for one-off events. Previous Bayesian reconciliation methods have\nnot been used widely, if at all, in contrast to pooling methods and\nconsensus-based approaches. To address this we embed Bayesian reconciliation\nwithin the probabilistic Delphi method. The result is to furnish the outcome of\nthe probabilistic Delphi method with a direct probabilistic interpretation,\nwith the resulting prior representing the judgements of the decision maker. We\ncan use the rationales from the Delphi process to group the experts for the\nhierarchical modelling. We illustrate the approach with applications to studies\nevaluating erosion in embankment dams and pump failures in a water pumping\nstation, and assess the properties of the approach using the TU Delft database\nof expert judgement studies. We see that, even using an off-the-shelf\nimplementation of the approach, it out-performs individual experts, equal\nweighting of experts and the classical method based on the log score.",
            "author": [
                "Kevin J. Wilson",
                "Malcolm Farrow",
                "Simon French",
                "David Hartley"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14487v1",
                "http://arxiv.org/pdf/2311.14487v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14486v1",
            "title": "Is there a (Pseudo)Scalar at 95 GeV?",
            "updated": "2023-11-24T13:52:11Z",
            "published": "2023-11-24T13:52:11Z",
            "summary": "We discuss the possibility of interpreting the recent experimental hints, in\nfavour of a 95 GeV resonance, with extensions of the Standard Model featuring\nan extra Higgs doublet and SM scalar (2HDM+s) or pseudoscalar singlet (2HDM+a).\nThe possibility of reproducing the experimental anomalies will be compared with\nthe theoretical constraints on the extended Higgs sector as well as\ncomplementary bounds coming from flavour physics as well as other colliders\nsearchers. For both the 2HDM+s and 2HDM+a we will consider a generic natural\nflavour conserving (NFC) as well as the customary Type-I, -II, -X and -Y\nconfigurations of the Yukawa coupling to the BSM Higgs bosons.",
            "author": [
                "Giorgio Arcadi",
                "Giorgio Busoni",
                "David Cabo-Almeida",
                "Navneet Krishnan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14486v1",
                "http://arxiv.org/pdf/2311.14486v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14485v1",
            "title": "Towards Interpretable Classification of Leukocytes based on Deep\n  Learning",
            "updated": "2023-11-24T13:48:37Z",
            "published": "2023-11-24T13:48:37Z",
            "summary": "Label-free approaches are attractive in cytological imaging due to their\nflexibility and cost efficiency. They are supported by machine learning\nmethods, which, despite the lack of labeling and the associated lower contrast,\ncan classify cells with high accuracy where the human observer has little\nchance to discriminate cells. In order to better integrate these workflows into\nthe clinical decision making process, this work investigates the calibration of\nconfidence estimation for the automated classification of leukocytes. In\naddition, different visual explanation approaches are compared, which should\nbring machine decision making closer to professional healthcare applications.\nFurthermore, we were able to identify general detection patterns in neural\nnetworks and demonstrate the utility of the presented approaches in different\nscenarios of blood cell analysis.",
            "author": [
                "Stefan R\u00f6hrl",
                "Johannes Groll",
                "Manuel Lengl",
                "Simon Schumann",
                "Christian Klenk",
                "Dominik Heim",
                "Martin Knopp",
                "Oliver Hayden",
                "Klaus Diepold"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14485v1",
                "http://arxiv.org/pdf/2311.14485v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.00804v1",
            "title": "Automatic detection of problem-gambling signs from online texts using\n  large language models",
            "updated": "2023-11-24T13:48:02Z",
            "published": "2023-11-24T13:48:02Z",
            "summary": "Problem gambling is a major public health concern and is associated with\nprofound psychological distress and economic problems. There are numerous\ngambling communities on the internet where users exchange information about\ngames, gambling tactics, as well as gambling-related problems. Individuals\nexhibiting higher levels of problem gambling engage more in such communities.\nOnline gambling communities may provide insights into problem-gambling\nbehaviour. Using data scraped from a major German gambling discussion board, we\nfine-tuned a large language model, specifically a Bidirectional Encoder\nRepresentations from Transformers (BERT) model, to predict signs of\nproblem-gambling from forum posts. Training data were generated by manual\nannotation and by taking into account diagnostic criteria and gambling-related\ncognitive distortions. Using k-fold cross-validation, our models achieved a\nprecision of 0.95 and F1 score of 0.71, demonstrating that satisfactory\nclassification performance can be achieved by generating high-quality training\nmaterial through manual annotation based on diagnostic criteria. The current\nstudy confirms that a BERT-based model can be reliably used on small data sets\nand to detect signatures of problem gambling in online communication data. Such\ncomputational approaches may have potential for the detection of changes in\nproblem-gambling prevalence among online users.",
            "author": [
                "Elke Smith",
                "Nils Reiter",
                "Jan Peters"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00804v1",
                "http://arxiv.org/pdf/2312.00804v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14483v1",
            "title": "SER_AMPEL: A multi-source dataset for SER of Italian older adults",
            "updated": "2023-11-24T13:47:25Z",
            "published": "2023-11-24T13:47:25Z",
            "summary": "In this paper, SER_AMPEL, a multi-source dataset for speech emotion\nrecognition (SER) is presented. The peculiarity of the dataset is that it is\ncollected with the aim of providing a reference for speech emotion recognition\nin case of Italian older adults. The dataset is collected following different\nprotocols, in particular considering acted conversations, extracted from movies\nand TV series, and recording natural conversations where the emotions are\nelicited by proper questions. The evidence of the need for such a dataset\nemerges from the analysis of the state of the art. Preliminary considerations\non the critical issues of SER are reported analyzing the classification results\non a subset of the proposed dataset.",
            "author": [
                "Alessandra Grossi",
                "Francesca Gasparini"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14483v1",
                "http://arxiv.org/pdf/2311.14483v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.CL",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14482v1",
            "title": "Sliding Window FastEdit: A Framework for Lesion Annotation in Whole-body\n  PET Images",
            "updated": "2023-11-24T13:45:58Z",
            "published": "2023-11-24T13:45:58Z",
            "summary": "Deep learning has revolutionized the accurate segmentation of diseases in\nmedical imaging. However, achieving such results requires training with\nnumerous manual voxel annotations. This requirement presents a challenge for\nwhole-body Positron Emission Tomography (PET) imaging, where lesions are\nscattered throughout the body. To tackle this problem, we introduce SW-FastEdit\n- an interactive segmentation framework that accelerates the labeling by\nutilizing only a few user clicks instead of voxelwise annotations. While prior\ninteractive models crop or resize PET volumes due to memory constraints, we use\nthe complete volume with our sliding window-based interactive scheme. Our model\noutperforms existing non-sliding window interactive models on the AutoPET\ndataset and generalizes to the previously unseen HECKTOR dataset. A user study\nrevealed that annotators achieve high-quality predictions with only 10 click\niterations and a low perceived NASA-TLX workload. Our framework is implemented\nusing MONAI Label and is available:\nhttps://github.com/matt3o/AutoPET2-Submission/",
            "author": [
                "Matthias Hadlich",
                "Zdravko Marinov",
                "Moon Kim",
                "Enrico Nasca",
                "Jens Kleesiek",
                "Rainer Stiefelhagen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14482v1",
                "http://arxiv.org/pdf/2311.14482v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.AI",
                "cs.CV",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14479v1",
            "title": "Controlled Text Generation via Language Model Arithmetic",
            "updated": "2023-11-24T13:41:12Z",
            "published": "2023-11-24T13:41:12Z",
            "summary": "As Large Language Models (LLMs) are deployed more widely, customization with\nrespect to vocabulary, style and character becomes more important. In this work\nwe introduce model arithmetic, a novel inference framework for composing and\nbiasing LLMs without the need for model (re)training or highly specific\ndatasets. In addition, the framework allows for more precise control of\ngenerated text than direct prompting and prior controlled text generation (CTG)\ntechniques. Using model arithmetic, we can express prior CTG techniques as\nsimple formulas and naturally extend them to new and more effective\nformulations. Further, we show that speculative sampling, a technique for\nefficient LLM sampling, extends to our setting. This enables highly efficient\ntext generation with multiple composed models with only marginal overhead over\na single model. Our empirical evaluation demonstrates that model arithmetic\nallows fine-grained control of generated text while outperforming\nstate-of-the-art on the task of toxicity reduction.",
            "author": [
                "Jasper Dekoninck",
                "Marc Fischer",
                "Luca Beurer-Kellner",
                "Martin Vechev"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14479v1",
                "http://arxiv.org/pdf/2311.14479v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14478v1",
            "title": "Depletion-induced crystallization of anisotropic triblock colloids",
            "updated": "2023-11-24T13:39:46Z",
            "published": "2023-11-24T13:39:46Z",
            "summary": "The intricate interplay between colloidal particle shape and precisely\nengineered interaction potentials has paved the way for the discovery of\nunprecedented crystal structures in both two and three dimensions. Here, we\nmake use of anisotropic triblock colloidal particles composed of two distinct\nmaterials. The resulting surface charge heterogeneity can be exploited to\ngenerate regioselective depletion interactions and directional bonding. Using\nextensive molecular dynamics simulations and a dimensionality reduction\nanalysis approach, we map out state diagrams for the self-assembly of such\ncolloids as a function of their aspect ratio and packing fraction for varying\ndepletant sizes in a quasi two-dimensional set-up. We observe the formation of\na wide variety of crystal structures such as a herringbone, brick-wall, tilted\nbrick-wall, and (tilted) ladder-like structures. More specifically, we\ndetermine the optimal parameters to enhance crystallization, and investigate\nthe nucleation process. Additionally, we explore the potential of using crystal\nmonolayers as templates for deposition, thereby creating complex\nthree-dimensional structures that hold promise for future applications.",
            "author": [
                "Fabrizio Camerin",
                "Susana Mar\u00edn-Aguilar",
                "Marjolein Dijkstra"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14478v1",
                "http://arxiv.org/pdf/2311.14478v1"
            ],
            "primary_category": "cond-mat.soft",
            "category": [
                "cond-mat.soft"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14477v1",
            "title": "Simulation Limitations of Affine Cellular Automata",
            "updated": "2023-11-24T13:38:34Z",
            "published": "2023-11-24T13:38:34Z",
            "summary": "Cellular automata are a famous model of computation, yet it is still a\nchallenging task to assess the computational capacity of a given automaton;\nespecially when it comes to showing negative results. In this paper, we focus\non studying this problem via the notion of CA relative simulation. We say that\nautomaton A is simulated by B if each space-time diagram of A can be, after\nsuitable transformations, reproduced by B.\n  We study affine automata - i.e., automata whose local rules are affine\nmappings of vector spaces. This broad class contains the well-studied cases of\nadditive automata. The main result of this paper shows that (almost) every\nautomaton affine over a finite field F_p can only simulate affine automata over\nF_p. We discuss how this general result implies, and widely surpasses,\nlimitations of additive automata previously proved in the literature.\n  We provide a formalization of the simulation notions into algebraic language\nand discuss how this opens a new path to showing negative results about the\ncomputational power of cellular automata using deeper algebraic theorems.",
            "author": [
                "Barbora Hudcov\u00e1",
                "Jakub Kr\u00e1sensk\u00fd"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14477v1",
                "http://arxiv.org/pdf/2311.14477v1"
            ],
            "primary_category": "cs.FL",
            "category": [
                "cs.FL"
            ]
        }
    }
]