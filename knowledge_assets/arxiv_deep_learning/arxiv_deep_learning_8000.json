[
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16103v1",
            "title": "LaksNet: an end-to-end deep learning model for self-driving cars in\n  Udacity simulator",
            "updated": "2023-10-24T18:11:25Z",
            "published": "2023-10-24T18:11:25Z",
            "summary": "The majority of road accidents occur because of human errors, including\ndistraction, recklessness, and drunken driving. One of the effective ways to\novercome this dangerous situation is by implementing self-driving technologies\nin vehicles. In this paper, we focus on building an efficient deep-learning\nmodel for self-driving cars. We propose a new and effective convolutional\nneural network model called `LaksNet' consisting of four convolutional layers\nand two fully connected layers. We conduct extensive experiments using our\nLaksNet model with the training data generated from the Udacity simulator. Our\nmodel outperforms many existing pre-trained ImageNet and NVIDIA models in terms\nof the duration of the car for which it drives without going off the track on\nthe simulator.",
            "author": [
                "Lakshmikar R. Polamreddy",
                "Youshan Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16103v1",
                "http://arxiv.org/pdf/2310.16103v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16102v1",
            "title": "Learned, Uncertainty-driven Adaptive Acquisition for Photon-Efficient\n  Multiphoton Microscopy",
            "updated": "2023-10-24T18:06:03Z",
            "published": "2023-10-24T18:06:03Z",
            "summary": "Multiphoton microscopy (MPM) is a powerful imaging tool that has been a\ncritical enabler for live tissue imaging. However, since most multiphoton\nmicroscopy platforms rely on point scanning, there is an inherent trade-off\nbetween acquisition time, field of view (FOV), phototoxicity, and image\nquality, often resulting in noisy measurements when fast, large FOV, and/or\ngentle imaging is needed. Deep learning could be used to denoise multiphoton\nmicroscopy measurements, but these algorithms can be prone to hallucination,\nwhich can be disastrous for medical and scientific applications. We propose a\nmethod to simultaneously denoise and predict pixel-wise uncertainty for\nmultiphoton imaging measurements, improving algorithm trustworthiness and\nproviding statistical guarantees for the deep learning predictions.\nFurthermore, we propose to leverage this learned, pixel-wise uncertainty to\ndrive an adaptive acquisition technique that rescans only the most uncertain\nregions of a sample. We demonstrate our method on experimental noisy MPM\nmeasurements of human endometrium tissues, showing that we can maintain fine\nfeatures and outperform other denoising methods while predicting uncertainty at\neach pixel. Finally, with our adaptive acquisition technique, we demonstrate a\n120X reduction in acquisition time and total light dose while successfully\nrecovering fine features in the sample. We are the first to demonstrate\ndistribution-free uncertainty quantification for a denoising task with real\nexperimental data and the first to propose adaptive acquisition based on\nreconstruction uncertainty",
            "author": [
                "Cassandra Tong Ye",
                "Jiashu Han",
                "Kunzan Liu",
                "Anastasios Angelopoulos",
                "Linda Griffith",
                "Kristina Monakhova",
                "Sixian You"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16102v1",
                "http://arxiv.org/pdf/2310.16102v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "physics.optics"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16100v1",
            "title": "Deep Feature Registration for Unsupervised Domain Adaptation",
            "updated": "2023-10-24T18:04:53Z",
            "published": "2023-10-24T18:04:53Z",
            "summary": "While unsupervised domain adaptation has been explored to leverage the\nknowledge from a labeled source domain to an unlabeled target domain, existing\nmethods focus on the distribution alignment between two domains. However, how\nto better align source and target features is not well addressed. In this\npaper, we propose a deep feature registration (DFR) model to generate\nregistered features that maintain domain invariant features and simultaneously\nminimize the domain-dissimilarity of registered features and target features\nvia histogram matching. We further employ a pseudo label refinement process,\nwhich considers both probabilistic soft selection and center-based hard\nselection to improve the quality of pseudo labels in the target domain.\nExtensive experiments on multiple UDA benchmarks demonstrate the effectiveness\nof our DFR model, resulting in new state-of-the-art performance.",
            "author": [
                "Youshan Zhang",
                "Brian D. Davison"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16100v1",
                "http://arxiv.org/pdf/2310.16100v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16099v1",
            "title": "Anatomically-aware Uncertainty for Semi-supervised Image Segmentation",
            "updated": "2023-10-24T18:03:07Z",
            "published": "2023-10-24T18:03:07Z",
            "summary": "Semi-supervised learning relaxes the need of large pixel-wise labeled\ndatasets for image segmentation by leveraging unlabeled data. A prominent way\nto exploit unlabeled data is to regularize model predictions. Since the\npredictions of unlabeled data can be unreliable, uncertainty-aware schemes are\ntypically employed to gradually learn from meaningful and reliable predictions.\nUncertainty estimation methods, however, rely on multiple inferences from the\nmodel predictions that must be computed for each training step, which is\ncomputationally expensive. Moreover, these uncertainty maps capture pixel-wise\ndisparities and do not consider global information. This work proposes a novel\nmethod to estimate segmentation uncertainty by leveraging global information\nfrom the segmentation masks. More precisely, an anatomically-aware\nrepresentation is first learnt to model the available segmentation masks. The\nlearnt representation thereupon maps the prediction of a new segmentation into\nan anatomically-plausible segmentation. The deviation from the plausible\nsegmentation aids in estimating the underlying pixel-level uncertainty in order\nto further guide the segmentation network. The proposed method consequently\nestimates the uncertainty using a single inference from our representation,\nthereby reducing the total computation. We evaluate our method on two publicly\navailable segmentation datasets of left atria in cardiac MRIs and of multiple\norgans in abdominal CTs. Our anatomically-aware method improves the\nsegmentation accuracy over the state-of-the-art semi-supervised methods in\nterms of two commonly used evaluation metrics.",
            "author": [
                "Sukesh Adiga V",
                "Jose Dolz",
                "Herve Lombaert"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16099v1",
                "http://arxiv.org/pdf/2310.16099v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16095v1",
            "title": "CR-COPEC: Causal Rationale of Corporate Performance Changes to Learn\n  from Financial Reports",
            "updated": "2023-10-24T18:00:40Z",
            "published": "2023-10-24T18:00:40Z",
            "summary": "In this paper, we introduce CR-COPEC called Causal Rationale of Corporate\nPerformance Changes from financial reports. This is a comprehensive large-scale\ndomain-adaptation causal sentence dataset to detect financial performance\nchanges of corporate. CR-COPEC contributes to two major achievements. First, it\ndetects causal rationale from 10-K annual reports of the U.S. companies, which\ncontain experts' causal analysis following accounting standards in a formal\nmanner. This dataset can be widely used by both individual investors and\nanalysts as material information resources for investing and decision making\nwithout tremendous effort to read through all the documents. Second, it\ncarefully considers different characteristics which affect the financial\nperformance of companies in twelve industries. As a result, CR-COPEC can\ndistinguish causal sentences in various industries by taking unique narratives\nin each industry into consideration. We also provide an extensive analysis of\nhow well CR-COPEC dataset is constructed and suited for classifying target\nsentences as causal ones with respect to industry characteristics. Our dataset\nand experimental codes are publicly available.",
            "author": [
                "Ye Eun Chun",
                "Sunjae Kwon",
                "Kyunghwan Sohn",
                "Nakwon Sung",
                "Junyoup Lee",
                "Byungki Seo",
                "Kevin Compher",
                "Seung-won Hwang",
                "Jaesik Choi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16095v1",
                "http://arxiv.org/pdf/2310.16095v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16096v1",
            "title": "Contextual Bandits for Evaluating and Improving Inventory Control\n  Policies",
            "updated": "2023-10-24T18:00:40Z",
            "published": "2023-10-24T18:00:40Z",
            "summary": "Solutions to address the periodic review inventory control problem with\nnonstationary random demand, lost sales, and stochastic vendor lead times\ntypically involve making strong assumptions on the dynamics for either\napproximation or simulation, and applying methods such as optimization, dynamic\nprogramming, or reinforcement learning. Therefore, it is important to analyze\nand evaluate any inventory control policy, in particular to see if there is\nroom for improvement. We introduce the concept of an equilibrium policy, a\ndesirable property of a policy that intuitively means that, in hindsight,\nchanging only a small fraction of actions does not result in materially more\nreward. We provide a light-weight contextual bandit-based algorithm to evaluate\nand occasionally tweak policies, and show that this method achieves favorable\nguarantees, both theoretically and in empirical studies.",
            "author": [
                "Dean Foster",
                "Randy Jia",
                "Dhruv Madeka"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16096v1",
                "http://arxiv.org/pdf/2310.16096v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16088v1",
            "title": "Physical Properties of 5,000 Cool LMC Supergiants with Gaia XP Spectra:\n  A Detailed Portrait of the Upper HR Diagram Hints at Missing Supernova\n  Progenitors",
            "updated": "2023-10-24T18:00:02Z",
            "published": "2023-10-24T18:00:02Z",
            "summary": "Characterizing the physical properties of cool supergiants allows us to probe\nthe final stages of a massive star's evolution before it undergoes core\ncollapse. Despite their importance, the fundamental properties for these stars\n-- $T_{\\rm eff}$ and $\\log L/L_\\odot$ -- are only known for a limited number of\nobjects. The third data release of the Gaia mission contains precise photometry\nand low-resolution spectroscopy of hundreds of cool supergiants in the LMC with\nwell-constrained properties. Using these data, we train a simple and\neasily-interpretable machine learning model to regress effective temperatures\nand luminosities with high accuracy and precision comparable to the training\ndata. We then apply our model to 5000 cool supergiants, many of which have no\npreviously-published $T_{\\rm eff}$ or $L$ estimates. The resulting\nHertzprung-Russell diagram is well-populated, allowing us to study the\ndistribution of cool supergiants in great detail. Examining the luminosity\nfunctions of our sample, we find a notable flattening in the luminosity\nfunction of yellow supergiants above $\\log L/L_\\odot=5$, and a corresponding\nsteepening of the red supergiant luminosity function. We place this finding in\ncontext with previous results, and present its implications for the infamous\nred supergiant problem.",
            "author": [
                "Trevor Z. Dorn-Wallenstein",
                "Kathryn F. Neugent",
                "Emily M. Levesque"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16088v1",
                "http://arxiv.org/pdf/2310.16088v1"
            ],
            "primary_category": "astro-ph.SR",
            "category": [
                "astro-ph.SR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16052v1",
            "title": "Synthetic Data as Validation",
            "updated": "2023-10-24T17:59:55Z",
            "published": "2023-10-24T17:59:55Z",
            "summary": "This study leverages synthetic data as a validation set to reduce overfitting\nand ease the selection of the best model in AI development. While synthetic\ndata have been used for augmenting the training set, we find that synthetic\ndata can also significantly diversify the validation set, offering marked\nadvantages in domains like healthcare, where data are typically limited,\nsensitive, and from out-domain sources (i.e., hospitals). In this study, we\nillustrate the effectiveness of synthetic data for early cancer detection in\ncomputed tomography (CT) volumes, where synthetic tumors are generated and\nsuperimposed onto healthy organs, thereby creating an extensive dataset for\nrigorous validation. Using synthetic data as validation can improve AI\nrobustness in both in-domain and out-domain test sets. Furthermore, we\nestablish a new continual learning framework that continuously trains AI models\non a stream of out-domain data with synthetic tumors. The AI model trained and\nvalidated in dynamically expanding synthetic data can consistently outperform\nmodels trained and validated exclusively on real-world data. Specifically, the\nDSC score for liver tumor segmentation improves from 26.7% (95% CI:\n22.6%-30.9%) to 34.5% (30.8%-38.2%) when evaluated on an in-domain dataset and\nfrom 31.1% (26.0%-36.2%) to 35.4% (32.1%-38.7%) on an out-domain dataset.\nImportantly, the performance gain is particularly significant in identifying\nvery tiny liver tumors (radius < 5mm) in CT volumes, with Sensitivity improving\nfrom 33.1% to 55.4% on an in-domain dataset and 33.9% to 52.3% on an out-domain\ndataset, justifying the efficacy in early detection of cancer. The application\nof synthetic data, from both training and validation perspectives, underlines a\npromising avenue to enhance AI robustness when dealing with data from varying\ndomains.",
            "author": [
                "Qixin Hu",
                "Alan Yuille",
                "Zongwei Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16052v1",
                "http://arxiv.org/pdf/2310.16052v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16050v1",
            "title": "EquivAct: SIM(3)-Equivariant Visuomotor Policies beyond Rigid Object\n  Manipulation",
            "updated": "2023-10-24T17:59:48Z",
            "published": "2023-10-24T17:59:48Z",
            "summary": "If a robot masters folding a kitchen towel, we would also expect it to master\nfolding a beach towel. However, existing works for policy learning that rely on\ndata set augmentations are still limited in achieving this level of\ngeneralization. Our insight is to add equivariance to both the visual object\nrepresentation and policy architecture. We propose EquivAct which utilizes\nSIM(3)-equivariant network structures that guarantee generalization across all\npossible object translations, 3D rotations, and scales by construction.\nTraining of EquivAct is done in two phases. We first pre-train a\nSIM(3)-equivariant visual representation on simulated scene point clouds. Then,\nwe learn a SIM(3)-equivariant visuomotor policy on top of the pre-trained\nvisual representation using a small amount of source task demonstrations. We\ndemonstrate that after training, the learned policy directly transfers to\nobjects that substantially differ in scale, position and orientation from the\nsource demonstrations. In simulation, we evaluate our method in three\nmanipulation tasks involving deformable and articulated objects thereby going\nbeyond the typical rigid object manipulation tasks that prior works considered.\nWe show that our method outperforms prior works that do not use equivariant\narchitectures or do not use our contrastive pre-training procedure. We also\nshow quantitative and qualitative experiments on three real robot tasks, where\nthe robot watches twenty demonstrations of a tabletop task and transfers\nzero-shot to a mobile manipulation task in a much larger setup. Project\nwebsite: https://equivact.github.io",
            "author": [
                "Jingyun Yang",
                "Congyue Deng",
                "Jimmy Wu",
                "Rika Antonova",
                "Leonidas Guibas",
                "Jeannette Bohg"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16050v1",
                "http://arxiv.org/pdf/2310.16050v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16048v1",
            "title": "AI Alignment and Social Choice: Fundamental Limitations and Policy\n  Implications",
            "updated": "2023-10-24T17:59:04Z",
            "published": "2023-10-24T17:59:04Z",
            "summary": "Aligning AI agents to human intentions and values is a key bottleneck in\nbuilding safe and deployable AI applications. But whose values should AI agents\nbe aligned with? Reinforcement learning with human feedback (RLHF) has emerged\nas the key framework for AI alignment. RLHF uses feedback from human\nreinforcers to fine-tune outputs; all widely deployed large language models\n(LLMs) use RLHF to align their outputs to human values. It is critical to\nunderstand the limitations of RLHF and consider policy challenges arising from\nthese limitations. In this paper, we investigate a specific challenge in\nbuilding RLHF systems that respect democratic norms. Building on impossibility\nresults in social choice theory, we show that, under fairly broad assumptions,\nthere is no unique voting protocol to universally align AI systems using RLHF\nthrough democratic processes. Further, we show that aligning AI agents with the\nvalues of all individuals will always violate certain private ethical\npreferences of an individual user i.e., universal AI alignment using RLHF is\nimpossible. We discuss policy implications for the governance of AI systems\nbuilt using RLHF: first, the need for mandating transparent voting rules to\nhold model builders accountable. Second, the need for model builders to focus\non developing AI agents that are narrowly aligned to specific user groups.",
            "author": [
                "Abhilash Mishra"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16048v1",
                "http://arxiv.org/pdf/2310.16048v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.CY",
                "cs.HC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16047v1",
            "title": "From Posterior Sampling to Meaningful Diversity in Image Restoration",
            "updated": "2023-10-24T17:58:54Z",
            "published": "2023-10-24T17:58:54Z",
            "summary": "Image restoration problems are typically ill-posed in the sense that each\ndegraded image can be restored in infinitely many valid ways. To accommodate\nthis, many works generate a diverse set of outputs by attempting to randomly\nsample from the posterior distribution of natural images given the degraded\ninput. Here we argue that this strategy is commonly of limited practical value\nbecause of the heavy tail of the posterior distribution. Consider for example\ninpainting a missing region of the sky in an image. Since there is a high\nprobability that the missing region contains no object but clouds, any set of\nsamples from the posterior would be entirely dominated by (practically\nidentical) completions of sky. However, arguably, presenting users with only\none clear sky completion, along with several alternative solutions such as\nairships, birds, and balloons, would better outline the set of possibilities.\nIn this paper, we initiate the study of meaningfully diverse image restoration.\nWe explore several post-processing approaches that can be combined with any\ndiverse image restoration method to yield semantically meaningful diversity.\nMoreover, we propose a practical approach for allowing diffusion based image\nrestoration methods to generate meaningfully diverse outputs, while incurring\nonly negligent computational overhead. We conduct extensive user studies to\nanalyze the proposed techniques, and find the strategy of reducing similarity\nbetween outputs to be significantly favorable over posterior sampling. Code and\nexamples are available in https://noa-cohen.github.io/MeaningfulDiversityInIR",
            "author": [
                "Noa Cohen",
                "Hila Manor",
                "Yuval Bahat",
                "Tomer Michaeli"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16047v1",
                "http://arxiv.org/pdf/2310.16047v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16046v1",
            "title": "A Unified, Scalable Framework for Neural Population Decoding",
            "updated": "2023-10-24T17:58:26Z",
            "published": "2023-10-24T17:58:26Z",
            "summary": "Our ability to use deep learning approaches to decipher neural activity would\nlikely benefit from greater scale, in terms of both model size and datasets.\nHowever, the integration of many neural recordings into one unified model is\nchallenging, as each recording contains the activity of different neurons from\ndifferent individual animals. In this paper, we introduce a training framework\nand architecture designed to model the population dynamics of neural activity\nacross diverse, large-scale neural recordings. Our method first tokenizes\nindividual spikes within the dataset to build an efficient representation of\nneural events that captures the fine temporal structure of neural activity. We\nthen employ cross-attention and a PerceiverIO backbone to further construct a\nlatent tokenization of neural population activities. Utilizing this\narchitecture and training framework, we construct a large-scale multi-session\nmodel trained on large datasets from seven nonhuman primates, spanning over 158\ndifferent sessions of recording from over 27,373 neural units and over 100\nhours of recordings. In a number of different tasks, we demonstrate that our\npretrained model can be rapidly adapted to new, unseen sessions with\nunspecified neuron correspondence, enabling few-shot performance with minimal\nlabels. This work presents a powerful new approach for building deep learning\ntools to analyze neural data and stakes out a clear path to training at scale.",
            "author": [
                "Mehdi Azabou",
                "Vinam Arora",
                "Venkataramana Ganesh",
                "Ximeng Mao",
                "Santosh Nachimuthu",
                "Michael J. Mendelson",
                "Blake Richards",
                "Matthew G. Perich",
                "Guillaume Lajoie",
                "Eva L. Dyer"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16046v1",
                "http://arxiv.org/pdf/2310.16046v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16045v1",
            "title": "Woodpecker: Hallucination Correction for Multimodal Large Language\n  Models",
            "updated": "2023-10-24T17:58:07Z",
            "published": "2023-10-24T17:58:07Z",
            "summary": "Hallucination is a big shadow hanging over the rapidly evolving Multimodal\nLarge Language Models (MLLMs), referring to the phenomenon that the generated\ntext is inconsistent with the image content. In order to mitigate\nhallucinations, existing studies mainly resort to an instruction-tuning manner\nthat requires retraining the models with specific data. In this paper, we pave\na different way, introducing a training-free method named Woodpecker. Like a\nwoodpecker heals trees, it picks out and corrects hallucinations from the\ngenerated text. Concretely, Woodpecker consists of five stages: key concept\nextraction, question formulation, visual knowledge validation, visual claim\ngeneration, and hallucination correction. Implemented in a post-remedy manner,\nWoodpecker can easily serve different MLLMs, while being interpretable by\naccessing intermediate outputs of the five stages. We evaluate Woodpecker both\nquantitatively and qualitatively and show the huge potential of this new\nparadigm. On the POPE benchmark, our method obtains a 30.66%/24.33% improvement\nin accuracy over the baseline MiniGPT-4/mPLUG-Owl. The source code is released\nat https://github.com/BradyFU/Woodpecker.",
            "author": [
                "Shukang Yin",
                "Chaoyou Fu",
                "Sirui Zhao",
                "Tong Xu",
                "Hao Wang",
                "Dianbo Sui",
                "Yunhang Shen",
                "Ke Li",
                "Xing Sun",
                "Enhong Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16045v1",
                "http://arxiv.org/pdf/2310.16045v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16042v2",
            "title": "WebWISE: Web Interface Control and Sequential Exploration with Large\n  Language Models",
            "updated": "2023-10-25T03:54:11Z",
            "published": "2023-10-24T17:57:03Z",
            "summary": "The paper investigates using a Large Language Model (LLM) to automatically\nperform web software tasks using click, scroll, and text input operations.\nPrevious approaches, such as reinforcement learning (RL) or imitation learning,\nare inefficient to train and task-specific. Our method uses filtered Document\nObject Model (DOM) elements as observations and performs tasks step-by-step,\nsequentially generating small programs based on the current observations. We\nuse in-context learning, either benefiting from a single manually provided\nexample, or an automatically generated example based on a successful zero-shot\ntrial. We evaluate the proposed method on the MiniWob++ benchmark. With only\none in-context example, our WebWISE method achieves similar or better\nperformance than other methods that require many demonstrations or trials.",
            "author": [
                "Heyi Tao",
                "Sethuraman T V",
                "Michal Shlapentokh-Rothman",
                "Derek Hoiem"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16042v2",
                "http://arxiv.org/pdf/2310.16042v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16035v1",
            "title": "What's Left? Concept Grounding with Logic-Enhanced Foundation Models",
            "updated": "2023-10-24T17:50:20Z",
            "published": "2023-10-24T17:50:20Z",
            "summary": "Recent works such as VisProg and ViperGPT have smartly composed foundation\nmodels for visual reasoning-using large language models (LLMs) to produce\nprograms that can be executed by pre-trained vision-language models. However,\nthey operate in limited domains, such as 2D images, not fully exploiting the\ngeneralization of language: abstract concepts like \"left\" can also be grounded\nin 3D, temporal, and action data, as in moving to your left. This limited\ngeneralization stems from these inference-only methods' inability to learn or\nadapt pre-trained models to a new domain. We propose the Logic-Enhanced\nFoundation Model (LEFT), a unified framework that learns to ground and reason\nwith concepts across domains with a differentiable, domain-independent,\nfirst-order logic-based program executor. LEFT has an LLM interpreter that\noutputs a program represented in a general, logic-based reasoning language,\nwhich is shared across all domains and tasks. LEFT's executor then executes the\nprogram with trainable domain-specific grounding modules. We show that LEFT\nflexibly learns concepts in four domains: 2D images, 3D scenes, human motions,\nand robotic manipulation. It exhibits strong reasoning ability in a wide\nvariety of tasks, including those that are complex and not seen during\ntraining, and can be easily applied to new domains.",
            "author": [
                "Joy Hsu",
                "Jiayuan Mao",
                "Joshua B. Tenenbaum",
                "Jiajun Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16035v1",
                "http://arxiv.org/pdf/2310.16035v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16029v1",
            "title": "Finetuning Offline World Models in the Real World",
            "updated": "2023-10-24T17:46:12Z",
            "published": "2023-10-24T17:46:12Z",
            "summary": "Reinforcement Learning (RL) is notoriously data-inefficient, which makes\ntraining on a real robot difficult. While model-based RL algorithms (world\nmodels) improve data-efficiency to some extent, they still require hours or\ndays of interaction to learn skills. Recently, offline RL has been proposed as\na framework for training RL policies on pre-existing datasets without any\nonline interaction. However, constraining an algorithm to a fixed dataset\ninduces a state-action distribution shift between training and inference, and\nlimits its applicability to new tasks. In this work, we seek to get the best of\nboth worlds: we consider the problem of pretraining a world model with offline\ndata collected on a real robot, and then finetuning the model on online data\ncollected by planning with the learned model. To mitigate extrapolation errors\nduring online interaction, we propose to regularize the planner at test-time by\nbalancing estimated returns and (epistemic) model uncertainty. We evaluate our\nmethod on a variety of visuo-motor control tasks in simulation and on a real\nrobot, and find that our method enables few-shot finetuning to seen and unseen\ntasks even when offline data is limited. Videos, code, and data are available\nat https://yunhaifeng.com/FOWM .",
            "author": [
                "Yunhai Feng",
                "Nicklas Hansen",
                "Ziyan Xiong",
                "Chandramouli Rajagopalan",
                "Xiaolong Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16029v1",
                "http://arxiv.org/pdf/2310.16029v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16028v1",
            "title": "What Algorithms can Transformers Learn? A Study in Length Generalization",
            "updated": "2023-10-24T17:43:29Z",
            "published": "2023-10-24T17:43:29Z",
            "summary": "Large language models exhibit surprising emergent generalization properties,\nyet also struggle on many simple reasoning tasks such as arithmetic and parity.\nThis raises the question of if and when Transformer models can learn the true\nalgorithm for solving a task. We study the scope of Transformers' abilities in\nthe specific setting of length generalization on algorithmic tasks. Here, we\npropose a unifying framework to understand when and how Transformers can\nexhibit strong length generalization on a given task. Specifically, we leverage\nRASP (Weiss et al., 2021) -- a programming language designed for the\ncomputational model of a Transformer -- and introduce the RASP-Generalization\nConjecture: Transformers tend to length generalize on a task if the task can be\nsolved by a short RASP program which works for all input lengths. This simple\nconjecture remarkably captures most known instances of length generalization on\nalgorithmic tasks. Moreover, we leverage our insights to drastically improve\ngeneralization performance on traditionally hard tasks (such as parity and\naddition). On the theoretical side, we give a simple example where the\n\"min-degree-interpolator\" model of learning from Abbe et al. (2023) does not\ncorrectly predict Transformers' out-of-distribution behavior, but our\nconjecture does. Overall, our work provides a novel perspective on the\nmechanisms of compositional generalization and the algorithmic capabilities of\nTransformers.",
            "author": [
                "Hattie Zhou",
                "Arwen Bradley",
                "Etai Littwin",
                "Noam Razin",
                "Omid Saremi",
                "Josh Susskind",
                "Samy Bengio",
                "Preetum Nakkiran"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16028v1",
                "http://arxiv.org/pdf/2310.16028v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16027v1",
            "title": "TimewarpVAE: Simultaneous Time-Warping and Representation Learning of\n  Trajectories",
            "updated": "2023-10-24T17:43:16Z",
            "published": "2023-10-24T17:43:16Z",
            "summary": "Human demonstrations of trajectories are an important source of training data\nfor many machine learning problems. However, the difficulty of collecting human\ndemonstration data for complex tasks makes learning efficient representations\nof those trajectories challenging. For many problems, such as for handwriting\nor for quasistatic dexterous manipulation, the exact timings of the\ntrajectories should be factored from their spatial path characteristics. In\nthis work, we propose TimewarpVAE, a fully differentiable manifold-learning\nalgorithm that incorporates Dynamic Time Warping (DTW) to simultaneously learn\nboth timing variations and latent factors of spatial variation. We show how the\nTimewarpVAE algorithm learns appropriate time alignments and meaningful\nrepresentations of spatial variations in small handwriting and fork\nmanipulation datasets. Our results have lower spatial reconstruction test error\nthan baseline approaches and the learned low-dimensional representations can be\nused to efficiently generate semantically meaningful novel trajectories.",
            "author": [
                "Travers Rhodes",
                "Daniel D. Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16027v1",
                "http://arxiv.org/pdf/2310.16027v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16020v2",
            "title": "ConvBKI: Real-Time Probabilistic Semantic Mapping Network with\n  Quantifiable Uncertainty",
            "updated": "2023-10-26T12:37:00Z",
            "published": "2023-10-24T17:30:26Z",
            "summary": "In this paper, we develop a modular neural network for real-time semantic\nmapping in uncertain environments, which explicitly updates per-voxel\nprobabilistic distributions within a neural network layer. Our approach\ncombines the reliability of classical probabilistic algorithms with the\nperformance and efficiency of modern neural networks. Although robotic\nperception is often divided between modern differentiable methods and classical\nexplicit methods, a union of both is necessary for real-time and trustworthy\nperformance. We introduce a novel Convolutional Bayesian Kernel Inference\n(ConvBKI) layer which incorporates semantic segmentation predictions online\ninto a 3D map through a depthwise convolution layer by leveraging conjugate\npriors. We compare ConvBKI against state-of-the-art deep learning approaches\nand probabilistic algorithms for mapping to evaluate reliability and\nperformance. We also create a Robot Operating System (ROS) package of ConvBKI\nand test it on real-world perceptually challenging off-road driving data.",
            "author": [
                "Joey Wilson",
                "Yuewei Fu",
                "Joshua Friesen",
                "Parker Ewen",
                "Andrew Capodieci",
                "Paramsothy Jayakumar",
                "Kira Barton",
                "Maani Ghaffari"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16020v2",
                "http://arxiv.org/pdf/2310.16020v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16015v1",
            "title": "Physically Explainable Deep Learning for Convective Initiation\n  Nowcasting Using GOES-16 Satellite Observations",
            "updated": "2023-10-24T17:18:44Z",
            "published": "2023-10-24T17:18:44Z",
            "summary": "Convection initiation (CI) nowcasting remains a challenging problem for both\nnumerical weather prediction models and existing nowcasting algorithms. In this\nstudy, object-based probabilistic deep learning models are developed to predict\nCI based on multichannel infrared GOES-R satellite observations. The data come\nfrom patches surrounding potential CI events identified in Multi-Radar\nMulti-Sensor Doppler weather radar products over the Great Plains region from\nJune and July 2020 and June 2021. An objective radar-based approach is used to\nidentify these events. The deep learning models significantly outperform the\nclassical logistic model at lead times up to 1 hour, especially on the false\nalarm ratio. Through case studies, the deep learning model exhibits the\ndependence on the characteristics of clouds and moisture at multiple levels.\nModel explanation further reveals the model's decision-making process with\ndifferent baselines. The explanation results highlight the importance of\nmoisture and cloud features at different levels depending on the choice of\nbaseline. Our study demonstrates the advantage of using different baselines in\nfurther understanding model behavior and gaining scientific insights.",
            "author": [
                "Da Fan",
                "Steven J. Greybush",
                "David John Gagne II",
                "Eugene E. Clothiaux"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16015v1",
                "http://arxiv.org/pdf/2310.16015v1"
            ],
            "primary_category": "physics.ao-ph",
            "category": [
                "physics.ao-ph",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16076v1",
            "title": "Practical Computational Power of Linear Transformers and Their Recurrent\n  and Self-Referential Extensions",
            "updated": "2023-10-24T17:17:01Z",
            "published": "2023-10-24T17:17:01Z",
            "summary": "Recent studies of the computational power of recurrent neural networks (RNNs)\nreveal a hierarchy of RNN architectures, given real-time and finite-precision\nassumptions. Here we study auto-regressive Transformers with linearised\nattention, a.k.a. linear Transformers (LTs) or Fast Weight Programmers (FWPs).\nLTs are special in the sense that they are equivalent to RNN-like sequence\nprocessors with a fixed-size state, while they can also be expressed as the\nnow-popular self-attention networks. We show that many well-known results for\nthe standard Transformer directly transfer to LTs/FWPs. Our formal language\nrecognition experiments demonstrate how recently proposed FWP extensions such\nas recurrent FWPs and self-referential weight matrices successfully overcome\ncertain limitations of the LT, e.g., allowing for generalisation on the parity\nproblem. Our code is public.",
            "author": [
                "Kazuki Irie",
                "R\u00f3bert Csord\u00e1s",
                "J\u00fcrgen Schmidhuber"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16076v1",
                "http://arxiv.org/pdf/2310.16076v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17817v1",
            "title": "Bayesian imaging inverse problem with SA-Roundtrip prior via HMC-pCN\n  sampler",
            "updated": "2023-10-24T17:16:45Z",
            "published": "2023-10-24T17:16:45Z",
            "summary": "Bayesian inference with deep generative prior has received considerable\ninterest for solving imaging inverse problems in many scientific and\nengineering fields. The selection of the prior distribution is learned from,\nand therefore an important representation learning of, available prior\nmeasurements. The SA-Roundtrip, a novel deep generative prior, is introduced to\nenable controlled sampling generation and identify the data's intrinsic\ndimension. This prior incorporates a self-attention structure within a\nbidirectional generative adversarial network. Subsequently, Bayesian inference\nis applied to the posterior distribution in the low-dimensional latent space\nusing the Hamiltonian Monte Carlo with preconditioned Crank-Nicolson (HMC-pCN)\nalgorithm, which is proven to be ergodic under specific conditions. Experiments\nconducted on computed tomography (CT) reconstruction with the MNIST and\nTomoPhantom datasets reveal that the proposed method outperforms\nstate-of-the-art comparisons, consistently yielding a robust and superior point\nestimator along with precise uncertainty quantification.",
            "author": [
                "Jiayu Qian",
                "Yuanyuan Liu",
                "Jingya Yang",
                "Qingping Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17817v1",
                "http://arxiv.org/pdf/2310.17817v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.AI",
                "cs.LG",
                "math.PR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16014v1",
            "title": "Human-in-the-Loop Task and Motion Planning for Imitation Learning",
            "updated": "2023-10-24T17:15:16Z",
            "published": "2023-10-24T17:15:16Z",
            "summary": "Imitation learning from human demonstrations can teach robots complex\nmanipulation skills, but is time-consuming and labor intensive. In contrast,\nTask and Motion Planning (TAMP) systems are automated and excel at solving\nlong-horizon tasks, but they are difficult to apply to contact-rich tasks. In\nthis paper, we present Human-in-the-Loop Task and Motion Planning (HITL-TAMP),\na novel system that leverages the benefits of both approaches. The system\nemploys a TAMP-gated control mechanism, which selectively gives and takes\ncontrol to and from a human teleoperator. This enables the human teleoperator\nto manage a fleet of robots, maximizing data collection efficiency. The\ncollected human data is then combined with an imitation learning framework to\ntrain a TAMP-gated policy, leading to superior performance compared to training\non full task demonstrations. We compared HITL-TAMP to a conventional\nteleoperation system -- users gathered more than 3x the number of demos given\nthe same time budget. Furthermore, proficient agents (75\\%+ success) could be\ntrained from just 10 minutes of non-expert teleoperation data. Finally, we\ncollected 2.1K demos with HITL-TAMP across 12 contact-rich, long-horizon tasks\nand show that the system often produces near-perfect agents. Videos and\nadditional results at https://hitltamp.github.io .",
            "author": [
                "Ajay Mandlekar",
                "Caelan Garrett",
                "Danfei Xu",
                "Dieter Fox"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16014v1",
                "http://arxiv.org/pdf/2310.16014v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16009v1",
            "title": "Spatio-temporal reconstruction of drop impact dynamics by means of\n  color-coded glare points and deep learning",
            "updated": "2023-10-24T17:03:42Z",
            "published": "2023-10-24T17:03:42Z",
            "summary": "The present work introduces a deep learning approach for the\nthree-dimensional reconstruction of the spatio-temporal dynamics of the\ngas-liquid interface in two-phase flows on the basis of monocular images\nobtained via optical measurement techniques. The dynamics of liquid droplets\nimpacting onto structured solid substrates are captured through high-speed\nimaging in an extended shadowgraphy setup with additional reflective glare\npoints from lateral light sources that encode further three-dimensional\ninformation of the gas-liquid interface in the images. A neural network is\nlearned for the physically correct reconstruction of the droplet dynamics on a\nlabelled dataset generated by synthetic image rendering on the basis of\ngas-liquid interface shapes obtained from direct numerical simulation. The\nemployment of synthetic image rendering allows for the efficient generation of\ntraining data and circumvents the introduction of errors resulting from the\ninherent discrepancy of the droplet shapes between experiment and simulation.\nThe accurate reconstruction of the gas-liquid interface during droplet\nimpingement on the basis of images obtained in the experiment demonstrates the\npracticality of the presented approach based on neural networks and synthetic\ntraining data generation. The introduction of glare points from lateral light\nsources in the experiments is shown to improve the reconstruction accuracy,\nwhich indicates that the neural network learns to leverage the additional\nthree-dimensional information encoded in the images for a more accurate depth\nestimation. Furthermore, the physically reasonable reconstruction of unknown\ngas-liquid interface shapes indicates that the neural network learned a\nversatile model of the involved two-phase flow phenomena during droplet\nimpingement.",
            "author": [
                "Maximilian Dreisbach",
                "Jochen Kriegseis",
                "Alexander Stroh"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16009v1",
                "http://arxiv.org/pdf/2310.16009v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16006v1",
            "title": "Machine-learning the phase diagram of a strongly-interacting Fermi gas",
            "updated": "2023-10-24T17:00:05Z",
            "published": "2023-10-24T17:00:05Z",
            "summary": "We determine the phase diagram of strongly correlated fermions in the\ncrossover from Bose-Einstein condensates of molecules (BEC) to Cooper pairs of\nfermions (BCS) utilizing an artificial neural network. By applying advanced\nimage recognition techniques to the momentum distribution of the fermions, a\nquantity which has been widely considered as featureless for providing\ninformation about the condensed state, we measure the critical temperature and\nshow that it exhibits a maximum on the bosonic side of the crossover.\nAdditionally, we back-analyze the trained neural network and demonstrate that\nit interprets physically relevant quantities.",
            "author": [
                "M. Link",
                "K. Gao",
                "A. Kell",
                "M. Breyer",
                "D. Eberz",
                "B. Rauf",
                "M. K\u00f6hl"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16006v1",
                "http://arxiv.org/pdf/2310.16006v1"
            ],
            "primary_category": "cond-mat.quant-gas",
            "category": [
                "cond-mat.quant-gas"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16005v1",
            "title": "MLFMF: Data Sets for Machine Learning for Mathematical Formalization",
            "updated": "2023-10-24T17:00:00Z",
            "published": "2023-10-24T17:00:00Z",
            "summary": "We introduce MLFMF, a collection of data sets for benchmarking recommendation\nsystems used to support formalization of mathematics with proof assistants.\nThese systems help humans identify which previous entries (theorems,\nconstructions, datatypes, and postulates) are relevant in proving a new theorem\nor carrying out a new construction. Each data set is derived from a library of\nformalized mathematics written in proof assistants Agda or Lean. The collection\nincludes the largest Lean~4 library Mathlib, and some of the largest Agda\nlibraries: the standard library, the library of univalent mathematics\nAgda-unimath, and the TypeTopology library. Each data set represents the\ncorresponding library in two ways: as a heterogeneous network, and as a list of\ns-expressions representing the syntax trees of all the entries in the library.\nThe network contains the (modular) structure of the library and the references\nbetween entries, while the s-expressions give complete and easily parsed\ninformation about every entry. We report baseline results using standard graph\nand word embeddings, tree ensembles, and instance-based learning algorithms.\nThe MLFMF data sets provide solid benchmarking support for further\ninvestigation of the numerous machine learning approaches to formalized\nmathematics. The methodology used to extract the networks and the s-expressions\nreadily applies to other libraries, and is applicable to other proof\nassistants. With more than $250\\,000$ entries in total, this is currently the\nlargest collection of formalized mathematical knowledge in machine learnable\nformat.",
            "author": [
                "Andrej Bauer",
                "Matej Petkovi\u0107",
                "Ljup\u010do Todorovski"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16005v1",
                "http://arxiv.org/pdf/2310.16005v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15999v1",
            "title": "Transitivity Recovering Decompositions: Interpretable and Robust\n  Fine-Grained Relationships",
            "updated": "2023-10-24T16:48:56Z",
            "published": "2023-10-24T16:48:56Z",
            "summary": "Recent advances in fine-grained representation learning leverage\nlocal-to-global (emergent) relationships for achieving state-of-the-art\nresults. The relational representations relied upon by such methods, however,\nare abstract. We aim to deconstruct this abstraction by expressing them as\ninterpretable graphs over image views. We begin by theoretically showing that\nabstract relational representations are nothing but a way of recovering\ntransitive relationships among local views. Based on this, we design\nTransitivity Recovering Decompositions (TRD), a graph-space search algorithm\nthat identifies interpretable equivalents of abstract emergent relationships at\nboth instance and class levels, and with no post-hoc computations. We\nadditionally show that TRD is provably robust to noisy views, with empirical\nevidence also supporting this finding. The latter allows TRD to perform at par\nor even better than the state-of-the-art, while being fully interpretable.\nImplementation is available at https://github.com/abhrac/trd.",
            "author": [
                "Abhra Chaudhuri",
                "Massimiliano Mancini",
                "Zeynep Akata",
                "Anjan Dutta"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15999v1",
                "http://arxiv.org/pdf/2310.15999v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15994v1",
            "title": "Training models using forces computed by stochastic electronic structure\n  methods",
            "updated": "2023-10-24T16:40:43Z",
            "published": "2023-10-24T16:40:43Z",
            "summary": "Quantum Monte Carlo (QMC) can play a very important role in generating\naccurate data needed for constructing potential energy surfaces. We argue that\nQMC has advantages in terms of a smaller systematic bias and an ability to\ncover phase space more completely. The stochastic noise can ease the training\nof the machine learning model. We discuss how stochastic errors affect the\ngeneration of effective models by analyzing the errors within a linear least\nsquares procedure, finding that there is an advantage to having many relatively\nimprecise data points for constructing models. We then analyze the effect of\nnoise on a model of many-body silicon finding that noise in some situations\nimproves the resulting model. We then study the effect of QMC noise on two\nmachine learning models of dense hydrogen used in a recent study of its phase\ndiagram. The noise enable us to estimate the errors in the model. We conclude\nwith a discussion of future research problems.",
            "author": [
                "David M. Ceperley",
                "Scott Jensen",
                "Yubo Yang",
                "Hongwei Niu",
                "Carlo Pierleoni",
                "Markus Holzmann"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15994v1",
                "http://arxiv.org/pdf/2310.15994v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15991v1",
            "title": "White-box Compiler Fuzzing Empowered by Large Language Models",
            "updated": "2023-10-24T16:39:06Z",
            "published": "2023-10-24T16:39:06Z",
            "summary": "Compiler correctness is crucial, as miscompilation falsifying the program\nbehaviors can lead to serious consequences. In the literature, fuzzing has been\nextensively studied to uncover compiler defects. However, compiler fuzzing\nremains challenging: Existing arts focus on black- and grey-box fuzzing, which\ngenerates tests without sufficient understanding of internal compiler\nbehaviors. As such, they often fail to construct programs to exercise\nconditions of intricate optimizations. Meanwhile, traditional white-box\ntechniques are computationally inapplicable to the giant codebase of compilers.\nRecent advances demonstrate that Large Language Models (LLMs) excel in code\ngeneration/understanding tasks and have achieved state-of-the-art performance\nin black-box fuzzing. Nonetheless, prompting LLMs with compiler source-code\ninformation remains a missing piece of research in compiler testing.\n  To this end, we propose WhiteFox, the first white-box compiler fuzzer using\nLLMs with source-code information to test compiler optimization. WhiteFox\nadopts a dual-model framework: (i) an analysis LLM examines the low-level\noptimization source code and produces requirements on the high-level test\nprograms that can trigger the optimization; (ii) a generation LLM produces test\nprograms based on the summarized requirements. Additionally,\noptimization-triggering tests are used as feedback to further enhance the test\ngeneration on the fly. Our evaluation on four popular compilers shows that\nWhiteFox can generate high-quality tests to exercise deep optimizations\nrequiring intricate conditions, practicing up to 80 more optimizations than\nstate-of-the-art fuzzers. To date, WhiteFox has found in total 96 bugs, with 80\nconfirmed as previously unknown and 51 already fixed. Beyond compiler testing,\nWhiteFox can also be adapted for white-box fuzzing of other complex, real-world\nsoftware systems in general.",
            "author": [
                "Chenyuan Yang",
                "Yinlin Deng",
                "Runyu Lu",
                "Jiayi Yao",
                "Jiawei Liu",
                "Reyhaneh Jabbarvand",
                "Lingming Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15991v1",
                "http://arxiv.org/pdf/2310.15991v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.LG",
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15989v1",
            "title": "Detecting the phase transition in a strongly-interacting Fermi gas by\n  unsupervised machine learning",
            "updated": "2023-10-24T16:38:09Z",
            "published": "2023-10-24T16:38:09Z",
            "summary": "We study the critical temperature of the superfluid phase transition of\nstrongly-interacting fermions in the crossover regime between a\nBardeen-Cooper-Schrieffer (BCS) superconductor and a Bose-Einstein condensate\n(BEC) of dimers. To this end, we employ the technique of unsupervised machine\nlearning using an autoencoder neural network which we directly apply to\ntime-of-flight images of the fermions. We extract the critical temperature of\nthe phase transition from trend changes in the data distribution revealed in\nthe latent space of the autoencoder bottleneck.",
            "author": [
                "D. Eberz",
                "M. Link",
                "A. Kell",
                "M. Breyer",
                "K. Gao",
                "M. K\u00f6hl"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15989v1",
                "http://arxiv.org/pdf/2310.15989v1"
            ],
            "primary_category": "cond-mat.quant-gas",
            "category": [
                "cond-mat.quant-gas"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15987v1",
            "title": "Dissecting In-Context Learning of Translations in GPTs",
            "updated": "2023-10-24T16:37:18Z",
            "published": "2023-10-24T16:37:18Z",
            "summary": "Most of the recent work in leveraging Large Language Models (LLMs) such as\nGPT-3 for Machine Translation (MT) has focused on selecting the few-shot\nsamples for prompting. In this work, we try to better understand the role of\ndemonstration attributes for the in-context learning of translations through\nperturbations of high-quality, in-domain demonstrations. We find that\nasymmetric perturbation of the source-target mappings yield vastly different\nresults. We show that the perturbation of the source side has surprisingly\nlittle impact, while target perturbation can drastically reduce translation\nquality, suggesting that it is the output text distribution that provides the\nmost important learning signal during in-context learning of translations. We\npropose a method named Zero-Shot-Context to add this signal automatically in\nZero-Shot prompting. We demonstrate that it improves upon the zero-shot\ntranslation performance of GPT-3, even making it competitive with few-shot\nprompted translations.",
            "author": [
                "Vikas Raunak",
                "Hany Hassan Awadalla",
                "Arul Menezes"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15987v1",
                "http://arxiv.org/pdf/2310.15987v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15985v1",
            "title": "Vision-Language Pseudo-Labels for Single-Positive Multi-Label Learning",
            "updated": "2023-10-24T16:36:51Z",
            "published": "2023-10-24T16:36:51Z",
            "summary": "This paper presents a novel approach to Single-Positive Multi-label Learning.\nIn general multi-label learning, a model learns to predict multiple labels or\ncategories for a single input image. This is in contrast with standard\nmulti-class image classification, where the task is predicting a single label\nfrom many possible labels for an image. Single-Positive Multi-label Learning\n(SPML) specifically considers learning to predict multiple labels when there is\nonly a single annotation per image in the training data. Multi-label learning\nis in many ways a more realistic task than single-label learning as real-world\ndata often involves instances belonging to multiple categories simultaneously;\nhowever, most common computer vision datasets predominantly contain single\nlabels due to the inherent complexity and cost of collecting multiple high\nquality annotations for each instance. We propose a novel approach called\nVision-Language Pseudo-Labeling (VLPL), which uses a vision-language model to\nsuggest strong positive and negative pseudo-labels, and outperforms the current\nSOTA methods by 5.5% on Pascal VOC, 18.4% on MS-COCO, 15.2% on NUS-WIDE, and\n8.4% on CUB-Birds. Our code and data are available at\nhttps://github.com/mvrl/VLPL.",
            "author": [
                "Xin Xing",
                "Zhexiao Xiong",
                "Abby Stylianou",
                "Srikumar Sastry",
                "Liyu Gong",
                "Nathan Jacobs"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15985v1",
                "http://arxiv.org/pdf/2310.15985v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15978v1",
            "title": "Graph Deep Learning for Time Series Forecasting",
            "updated": "2023-10-24T16:26:38Z",
            "published": "2023-10-24T16:26:38Z",
            "summary": "Graph-based deep learning methods have become popular tools to process\ncollections of correlated time series. Differently from traditional\nmultivariate forecasting methods, neural graph-based predictors take advantage\nof pairwise relationships by conditioning forecasts on a (possibly dynamic)\ngraph spanning the time series collection. The conditioning can take the form\nof an architectural inductive bias on the neural forecasting architecture,\nresulting in a family of deep learning models called spatiotemporal graph\nneural networks. Such relational inductive biases enable the training of global\nforecasting models on large time-series collections, while at the same time\nlocalizing predictions w.r.t. each element in the set (i.e., graph nodes) by\naccounting for local correlations among them (i.e., graph edges). Indeed,\nrecent theoretical and practical advances in graph neural networks and deep\nlearning for time series forecasting make the adoption of such processing\nframeworks appealing and timely. However, most of the studies in the literature\nfocus on proposing variations of existing neural architectures by taking\nadvantage of modern deep learning practices, while foundational and\nmethodological aspects have not been subject to systematic investigation. To\nfill the gap, this paper aims to introduce a comprehensive methodological\nframework that formalizes the forecasting problem and provides design\nprinciples for graph-based predictive models and methods to assess their\nperformance. At the same time, together with an overview of the field, we\nprovide design guidelines, recommendations, and best practices, as well as an\nin-depth discussion of open challenges and future research directions.",
            "author": [
                "Andrea Cini",
                "Ivan Marisca",
                "Daniele Zambon",
                "Cesare Alippi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15978v1",
                "http://arxiv.org/pdf/2310.15978v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15975v2",
            "title": "Data-driven Traffic Simulation: A Comprehensive Review",
            "updated": "2023-11-23T07:15:23Z",
            "published": "2023-10-24T16:25:13Z",
            "summary": "Autonomous vehicles (AVs) have the potential to significantly revolutionize\nsociety by providing a secure and efficient mode of transportation. Recent\nyears have witnessed notable advancements in autonomous driving perception and\nprediction, but the challenge of validating the performance of AVs remains\nlargely unresolved. Data-driven microscopic traffic simulation has become an\nimportant tool for autonomous driving testing due to 1) availability of\nhigh-fidelity traffic data; 2) its advantages of enabling large-scale testing\nand scenario reproducibility; and 3) its potential in reactive and realistic\ntraffic simulation. However, a comprehensive review of this topic is currently\nlacking. This paper aims to fill this gap by summarizing relevant studies. The\nprimary objective of this paper is to review current research efforts and\nprovide a futuristic perspective that will benefit future developments in the\nfield. It introduces the general issues of data-driven traffic simulation and\noutlines key concepts and terms. After overviewing traffic simulation, various\ndatasets and evaluation metrics commonly used are reviewed. The paper then\noffers a comprehensive evaluation of imitation learning, reinforcement\nlearning, deep generative and deep learning methods, summarizing each and\nanalyzing their advantages and disadvantages in detail. Moreover, it evaluates\nthe state-of-the-art, existing challenges, and future research directions.",
            "author": [
                "Di Chen",
                "Meixin Zhu",
                "Hao Yang",
                "Xuesong Wang",
                "Yinhai Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15975v2",
                "http://arxiv.org/pdf/2310.15975v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15976v1",
            "title": "Convergence of Sign-based Random Reshuffling Algorithms for Nonconvex\n  Optimization",
            "updated": "2023-10-24T16:25:13Z",
            "published": "2023-10-24T16:25:13Z",
            "summary": "signSGD is popular in nonconvex optimization due to its communication\nefficiency. Yet, existing analyses of signSGD rely on assuming that data are\nsampled with replacement in each iteration, contradicting the practical\nimplementation where data are randomly reshuffled and sequentially fed into the\nalgorithm. We bridge this gap by proving the first convergence result of\nsignSGD with random reshuffling (SignRR) for nonconvex optimization. Given the\ndataset size $n$, the number of epochs of data passes $T$, and the variance\nbound of a stochastic gradient $\\sigma^2$, we show that SignRR has the same\nconvergence rate $O(\\log(nT)/\\sqrt{nT} + \\|\\sigma\\|_1)$ as signSGD\n\\citep{bernstein2018signsgd}. We then present SignRVR and SignRVM, which\nleverage variance-reduced gradients and momentum updates respectively, both\nconverging at $O(\\log(nT)/\\sqrt{nT})$. In contrast with the analysis of\nsignSGD, our results do not require an extremely large batch size in each\niteration to be of the same order as the total number of iterations\n\\citep{bernstein2018signsgd} or the signs of stochastic and true gradients\nmatch element-wise with a minimum probability of 1/2\n\\citep{safaryan2021stochastic}. We also extend our algorithms to cases where\ndata are distributed across different machines, yielding dist-SignRVR and\ndist-SignRVM, both converging at $O(\\log(n_0T)/\\sqrt{n_0T})$, where $n_0$ is\nthe dataset size of a single machine. We back up our theoretical findings\nthrough experiments on simulated and real-world problems, verifying that\nrandomly reshuffled sign methods match or surpass existing baselines.",
            "author": [
                "Zhen Qin",
                "Zhishuai Liu",
                "Pan Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15976v1",
                "http://arxiv.org/pdf/2310.15976v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC",
                "math.OC",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15974v1",
            "title": "Minimax Forward and Backward Learning of Evolving Tasks with Performance\n  Guarantees",
            "updated": "2023-10-24T16:21:41Z",
            "published": "2023-10-24T16:21:41Z",
            "summary": "For a sequence of classification tasks that arrive over time, it is common\nthat tasks are evolving in the sense that consecutive tasks often have a higher\nsimilarity. The incremental learning of a growing sequence of tasks holds\npromise to enable accurate classification even with few samples per task by\nleveraging information from all the tasks in the sequence (forward and backward\nlearning). However, existing techniques developed for continual learning and\nconcept drift adaptation are either designed for tasks with time-independent\nsimilarities or only aim to learn the last task in the sequence. This paper\npresents incremental minimax risk classifiers (IMRCs) that effectively exploit\nforward and backward learning and account for evolving tasks. In addition, we\nanalytically characterize the performance improvement provided by forward and\nbackward learning in terms of the tasks' expected quadratic change and the\nnumber of tasks. The experimental evaluation shows that IMRCs can result in a\nsignificant performance improvement, especially for reduced sample sizes.",
            "author": [
                "Ver\u00f3nica \u00c1lvarez",
                "Santiago Mazuelas",
                "Jose A. Lozano"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15974v1",
                "http://arxiv.org/pdf/2310.15974v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15970v3",
            "title": "Accented Speech Recognition With Accent-specific Codebooks",
            "updated": "2023-10-27T02:54:29Z",
            "published": "2023-10-24T16:10:58Z",
            "summary": "Speech accents pose a significant challenge to state-of-the-art automatic\nspeech recognition (ASR) systems. Degradation in performance across\nunderrepresented accents is a severe deterrent to the inclusive adoption of\nASR. In this work, we propose a novel accent adaptation approach for end-to-end\nASR systems using cross-attention with a trainable set of codebooks. These\nlearnable codebooks capture accent-specific information and are integrated\nwithin the ASR encoder layers. The model is trained on accented English speech,\nwhile the test data also contained accents which were not seen during training.\nOn the Mozilla Common Voice multi-accented dataset, we show that our proposed\napproach yields significant performance gains not only on the seen English\naccents (up to $37\\%$ relative improvement in word error rate) but also on the\nunseen accents (up to $5\\%$ relative improvement in WER). Further, we\nillustrate benefits for a zero-shot transfer setup on the L2Artic dataset. We\nalso compare the performance with other approaches based on accent adversarial\ntraining.",
            "author": [
                "Darshan Prabhu",
                "Preethi Jyothi",
                "Sriram Ganapathy",
                "Vinit Unni"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15970v3",
                "http://arxiv.org/pdf/2310.15970v3"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15966v1",
            "title": "Constructing and Machine Learning Calabi-Yau Five-folds",
            "updated": "2023-10-24T16:07:08Z",
            "published": "2023-10-24T16:07:08Z",
            "summary": "We construct all possible complete intersection Calabi-Yau five-folds in a\nproduct of four or less complex projective spaces, with up to four constraints.\nWe obtain $27068$ spaces, which are not related by permutations of rows and\ncolumns of the configuration matrix, and determine the Euler number for all of\nthem. Excluding the $3909$ product manifolds among those, we calculate the\ncohomological data for $12433$ cases, i.e. $53.7 \\%$ of the non-product spaces,\nobtaining $2375$ different Hodge diamonds. The dataset containing all the above\ninformation is available at\nhttps://www.dropbox.com/scl/fo/z7ii5idt6qxu36e0b8azq/h?rlkey=0qfhx3tykytduobpld510gsfy&dl=0\n. The distributions of the invariants are presented, and a comparison with the\nlower-dimensional analogues is discussed. Supervised machine learning is\nperformed on the cohomological data, via classifier and regressor (both fully\nconnected and convolutional) neural networks. We find that $h^{1,1}$ can be\nlearnt very efficiently, with very high $R^2$ score and an accuracy of $96\\%$,\ni.e. $96 \\%$ of the predictions exactly match the correct values. For\n$h^{1,4},h^{2,3}, \\eta$, we also find very high $R^2$ scores, but the accuracy\nis lower, due to the large ranges of possible values.",
            "author": [
                "R. Alawadhi",
                "D. Angella",
                "A. Leonardo",
                "T. Schettini Gherardini"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15966v1",
                "http://arxiv.org/pdf/2310.15966v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th",
                "cs.LG",
                "math.AG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15961v1",
            "title": "Mixture of Tokens: Efficient LLMs through Cross-Example Aggregation",
            "updated": "2023-10-24T16:03:57Z",
            "published": "2023-10-24T16:03:57Z",
            "summary": "Despite the promise of Mixture of Experts (MoE) models in increasing\nparameter counts of Transformer models while maintaining training and inference\ncosts, their application carries notable drawbacks. The key strategy of these\nmodels is to, for each processed token, activate at most a few experts -\nsubsets of an extensive feed-forward layer. But this approach is not without\nits challenges. The operation of matching experts and tokens is discrete, which\nmakes MoE models prone to issues like training instability and uneven expert\nutilization. Existing techniques designed to address these concerns, such as\nauxiliary losses or balance-aware matching, result either in lower model\nperformance or are more difficult to train. In response to these issues, we\npropose Mixture of Tokens, a fully-differentiable model that retains the\nbenefits of MoE architectures while avoiding the aforementioned difficulties.\nRather than routing tokens to experts, this approach mixes tokens from\ndifferent examples prior to feeding them to experts, enabling the model to\nlearn from all token-expert combinations. Importantly, this mixing can be\ndisabled to avoid mixing of different sequences during inference. Crucially,\nthis method is fully compatible with both masked and causal Large Language\nModel training and inference.",
            "author": [
                "Szymon Antoniak",
                "Sebastian Jaszczur",
                "Micha\u0142 Krutul",
                "Maciej Pi\u00f3ro",
                "Jakub Krajewski",
                "Jan Ludziejewski",
                "Tomasz Odrzyg\u00f3\u017ad\u017a",
                "Marek Cygan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15961v1",
                "http://arxiv.org/pdf/2310.15961v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02088v1",
            "title": "Combining Deep Learning on Order Books with Reinforcement Learning for\n  Profitable Trading",
            "updated": "2023-10-24T15:58:58Z",
            "published": "2023-10-24T15:58:58Z",
            "summary": "High-frequency trading is prevalent, where automated decisions must be made\nquickly to take advantage of price imbalances and patterns in price action that\nforecast near-future movements. While many algorithms have been explored and\ntested, analytical methods fail to harness the whole nature of the market\nenvironment by focusing on a limited domain. With the evergrowing machine\nlearning field, many large-scale end-to-end studies on raw data have been\nsuccessfully employed to increase the domain scope for profitable trading but\nare very difficult to replicate. Combining deep learning on the order books\nwith reinforcement learning is one way of breaking down large-scale end-to-end\nlearning into more manageable and lightweight components for reproducibility,\nsuitable for retail trading.\n  The following work focuses on forecasting returns across multiple horizons\nusing order flow imbalance and training three temporal-difference learning\nmodels for five financial instruments to provide trading signals. The\ninstruments used are two foreign exchange pairs (GBPUSD and EURUSD), two\nindices (DE40 and FTSE100), and one commodity (XAUUSD). The performances of\nthese 15 agents are evaluated through backtesting simulation, and successful\nmodels proceed through to forward testing on a retail trading platform. The\nresults prove potential but require further minimal modifications for\nconsistently profitable trading to fully handle retail trading costs, slippage,\nand spread fluctuation.",
            "author": [
                "Koti S. Jaddu",
                "Paul A. Bilokon"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02088v1",
                "http://arxiv.org/pdf/2311.02088v1"
            ],
            "primary_category": "q-fin.CP",
            "category": [
                "q-fin.CP",
                "cs.AI",
                "cs.LG",
                "q-fin.PM",
                "q-fin.TR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15955v1",
            "title": "Decoupled DETR: Spatially Disentangling Localization and Classification\n  for Improved End-to-End Object Detection",
            "updated": "2023-10-24T15:54:11Z",
            "published": "2023-10-24T15:54:11Z",
            "summary": "The introduction of DETR represents a new paradigm for object detection.\nHowever, its decoder conducts classification and box localization using shared\nqueries and cross-attention layers, leading to suboptimal results. We observe\nthat different regions of interest in the visual feature map are suitable for\nperforming query classification and box localization tasks, even for the same\nobject. Salient regions provide vital information for classification, while the\nboundaries around them are more favorable for box regression. Unfortunately,\nsuch spatial misalignment between these two tasks greatly hinders DETR's\ntraining. Therefore, in this work, we focus on decoupling localization and\nclassification tasks in DETR. To achieve this, we introduce a new design scheme\ncalled spatially decoupled DETR (SD-DETR), which includes a task-aware query\ngeneration module and a disentangled feature learning process. We elaborately\ndesign the task-aware query initialization process and divide the\ncross-attention block in the decoder to allow the task-aware queries to match\ndifferent visual regions. Meanwhile, we also observe that the prediction\nmisalignment problem for high classification confidence and precise\nlocalization exists, so we propose an alignment loss to further guide the\nspatially decoupled DETR training. Through extensive experiments, we\ndemonstrate that our approach achieves a significant improvement in MSCOCO\ndatasets compared to previous work. For instance, we improve the performance of\nConditional DETR by 4.5 AP. By spatially disentangling the two tasks, our\nmethod overcomes the misalignment problem and greatly improves the performance\nof DETR for object detection.",
            "author": [
                "Manyuan Zhang",
                "Guanglu Song",
                "Yu Liu",
                "Hongsheng Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15955v1",
                "http://arxiv.org/pdf/2310.15955v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15952v3",
            "title": "Improving Robustness and Reliability in Medical Image Classification\n  with Latent-Guided Diffusion and Nested-Ensembles",
            "updated": "2023-11-10T09:52:03Z",
            "published": "2023-10-24T15:53:07Z",
            "summary": "While deep learning models have achieved remarkable success across a range of\nmedical image analysis tasks, deployment of these models in real clinical\ncontexts requires that they be robust to variability in the acquired images.\nWhile many methods apply predefined transformations to augment the training\ndata to enhance test-time robustness, these transformations may not ensure the\nmodel's robustness to the diverse variability seen in patient images. In this\npaper, we introduce a novel three-stage approach based on transformers coupled\nwith conditional diffusion models, with the goal of improving model robustness\nto the kinds of imaging variability commonly encountered in practice without\nthe need for pre-determined data augmentation strategies. To this end, multiple\nimage encoders first learn hierarchical feature representations to build\ndiscriminative latent spaces. Next, a reverse diffusion process, guided by the\nlatent code, acts on an informative prior and proposes prediction candidates in\na generative manner. Finally, several prediction candidates are aggregated in a\nbi-level aggregation protocol to produce the final output. Through extensive\nexperiments on medical imaging benchmark datasets, we show that our method\nimproves upon state-of-the-art methods in terms of robustness and confidence\ncalibration. Additionally, we introduce a strategy to quantify the prediction\nuncertainty at the instance level, increasing their trustworthiness to\nclinicians using them in clinical practice.",
            "author": [
                "Xing Shen",
                "Hengguan Huang",
                "Brennan Nichyporuk",
                "Tal Arbel"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15952v3",
                "http://arxiv.org/pdf/2310.15952v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15951v1",
            "title": "Weighted Distance Nearest Neighbor Condensing",
            "updated": "2023-10-24T15:51:20Z",
            "published": "2023-10-24T15:51:20Z",
            "summary": "The problem of nearest neighbor condensing has enjoyed a long history of\nstudy, both in its theoretical and practical aspects. In this paper, we\nintroduce the problem of weighted distance nearest neighbor condensing, where\none assigns weights to each point of the condensed set, and then new points are\nlabeled based on their weighted distance nearest neighbor in the condensed set.\n  We study the theoretical properties of this new model, and show that it can\nproduce dramatically better condensing than the standard nearest neighbor rule,\nyet is characterized by generalization bounds almost identical to the latter.\nWe then suggest a condensing heuristic for our new problem. We demonstrate\nBayes consistency for this heuristic, and also show promising empirical\nresults.",
            "author": [
                "Lee-Ad Gottlieb",
                "Timor Sharabi",
                "Roi Weiss"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15951v1",
                "http://arxiv.org/pdf/2310.15951v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15950v1",
            "title": "Representation Learning with Large Language Models for Recommendation",
            "updated": "2023-10-24T15:51:13Z",
            "published": "2023-10-24T15:51:13Z",
            "summary": "Recommender systems have seen significant advancements with the influence of\ndeep learning and graph neural networks, particularly in capturing complex\nuser-item relationships. However, these graph-based recommenders heavily depend\non ID-based data, potentially disregarding valuable textual information\nassociated with users and items, resulting in less informative learned\nrepresentations. Moreover, the utilization of implicit feedback data introduces\npotential noise and bias, posing challenges for the effectiveness of user\npreference learning. While the integration of large language models (LLMs) into\ntraditional ID-based recommenders has gained attention, challenges such as\nscalability issues, limitations in text-only reliance, and prompt input\nconstraints need to be addressed for effective implementation in practical\nrecommender systems. To address these challenges, we propose a model-agnostic\nframework RLMRec that aims to enhance existing recommenders with LLM-empowered\nrepresentation learning. It proposes a recommendation paradigm that integrates\nrepresentation learning with LLMs to capture intricate semantic aspects of user\nbehaviors and preferences. RLMRec incorporates auxiliary textual signals,\ndevelops a user/item profiling paradigm empowered by LLMs, and aligns the\nsemantic space of LLMs with the representation space of collaborative\nrelational signals through a cross-view alignment framework. This work further\nestablish a theoretical foundation demonstrating that incorporating textual\nsignals through mutual information maximization enhances the quality of\nrepresentations. In our evaluation, we integrate RLMRec with state-of-the-art\nrecommender models, while also analyzing its efficiency and robustness to noise\ndata. Our implementation codes are available at\nhttps://github.com/HKUDS/RLMRec.",
            "author": [
                "Xubin Ren",
                "Wei Wei",
                "Lianghao Xia",
                "Lixin Su",
                "Suqi Cheng",
                "Junfeng Wang",
                "Dawei Yin",
                "Chao Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15950v1",
                "http://arxiv.org/pdf/2310.15950v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15941v1",
            "title": "This is not a Dataset: A Large Negation Benchmark to Challenge Large\n  Language Models",
            "updated": "2023-10-24T15:38:21Z",
            "published": "2023-10-24T15:38:21Z",
            "summary": "Although large language models (LLMs) have apparently acquired a certain\nlevel of grammatical knowledge and the ability to make generalizations, they\nfail to interpret negation, a crucial step in Natural Language Processing. We\ntry to clarify the reasons for the sub-optimal performance of LLMs\nunderstanding negation. We introduce a large semi-automatically generated\ndataset of circa 400,000 descriptive sentences about commonsense knowledge that\ncan be true or false in which negation is present in about 2/3 of the corpus in\ndifferent forms. We have used our dataset with the largest available open LLMs\nin a zero-shot approach to grasp their generalization and inference capability\nand we have also fine-tuned some of the models to assess whether the\nunderstanding of negation can be trained. Our findings show that, while LLMs\nare proficient at classifying affirmative sentences, they struggle with\nnegative sentences and lack a deep understanding of negation, often relying on\nsuperficial cues. Although fine-tuning the models on negative sentences\nimproves their performance, the lack of generalization in handling negation is\npersistent, highlighting the ongoing challenges of LLMs regarding negation\nunderstanding and generalization. The dataset and code are publicly available.",
            "author": [
                "Iker Garc\u00eda-Ferrero",
                "Bego\u00f1a Altuna",
                "Javier \u00c1lvez",
                "Itziar Gonzalez-Dios",
                "German Rigau"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15941v1",
                "http://arxiv.org/pdf/2310.15941v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15940v1",
            "title": "Combining Behaviors with the Successor Features Keyboard",
            "updated": "2023-10-24T15:35:54Z",
            "published": "2023-10-24T15:35:54Z",
            "summary": "The Option Keyboard (OK) was recently proposed as a method for transferring\nbehavioral knowledge across tasks. OK transfers knowledge by adaptively\ncombining subsets of known behaviors using Successor Features (SFs) and\nGeneralized Policy Improvement (GPI). However, it relies on hand-designed\nstate-features and task encodings which are cumbersome to design for every new\nenvironment. In this work, we propose the \"Successor Features Keyboard\" (SFK),\nwhich enables transfer with discovered state-features and task encodings. To\nenable discovery, we propose the \"Categorical Successor Feature Approximator\"\n(CSFA), a novel learning algorithm for estimating SFs while jointly discovering\nstate-features and task encodings. With SFK and CSFA, we achieve the first\ndemonstration of transfer with SFs in a challenging 3D environment where all\nthe necessary representations are discovered. We first compare CSFA against\nother methods for approximating SFs and show that only CSFA discovers\nrepresentations compatible with SF&GPI at this scale. We then compare SFK\nagainst transfer learning baselines and show that it transfers most quickly to\nlong-horizon tasks.",
            "author": [
                "Wilka Carvalho",
                "Andre Saraiva",
                "Angelos Filos",
                "Andrew Kyle Lampinen",
                "Loic Matthey",
                "Richard L. Lewis",
                "Honglak Lee",
                "Satinder Singh",
                "Danilo J. Rezende",
                "Daniel Zoran"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15940v1",
                "http://arxiv.org/pdf/2310.15940v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15939v1",
            "title": "Blip-Up Blip-Down Circular EPI (BUDA-cEPI) for Distortion-Free dMRI with\n  Rapid Unrolled Deep Learning Reconstruction",
            "updated": "2023-10-24T15:35:00Z",
            "published": "2023-10-24T15:35:00Z",
            "summary": "Purpose: We implemented the blip-up, blip-down circular echo planar imaging\n(BUDA-cEPI) sequence with readout and phase partial Fourier to reduced\noff-resonance effect and T2* blurring. BUDA-cEPI reconstruction with S-based\nlow-rank modeling of local k-space neighborhoods (S-LORAKS) is shown to be\neffective at reconstructing the highly under-sampled BUDA-cEPI data, but it is\ncomputationally intensive. Thus, we developed an ML-based reconstruction\ntechnique termed \"BUDA-cEPI RUN-UP\" to enable fast reconstruction.\n  Methods: BUDA-cEPI RUN-UP - a model-based framework that incorporates\noff-resonance and eddy current effects was unrolled through an artificial\nneural network with only six gradient updates. The unrolled network alternates\nbetween data consistency (i.e., forward BUDA-cEPI and its adjoint) and\nregularization steps where U-Net plays a role as the regularizer. To handle the\npartial Fourier effect, the virtual coil concept was also incorporated into the\nreconstruction to effectively take advantage of the smooth phase prior, and\ntrained to predict the ground-truth images obtained by BUDA-cEPI with S-LORAKS.\n  Results: BUDA-cEPI with S-LORAKS reconstruction enabled the management of\noff-resonance, partial Fourier, and residual aliasing artifacts. However, the\nreconstruction time is approximately 225 seconds per slice, which may not be\npractical in a clinical setting. In contrast, the proposed BUDA-cEPI RUN-UP\nyielded similar results to BUDA-cEPI with S-LORAKS, with less than a 5%\nnormalized root mean square error detected, while the reconstruction time is\napproximately 3 seconds.\n  Conclusion: BUDA-cEPI RUN-UP was shown to reduce the reconstruction time by\n~88x when compared to the state-of-the-art technique, while preserving imaging\ndetails as demonstrated through DTI application.",
            "author": [
                "Uten Yarach",
                "Itthi Chatnuntawech",
                "Congyu Liao",
                "Surat Teerapittayanon",
                "Siddharth Srinivasan Iyer",
                "Tae Hyung Kim",
                "Justin Haldar",
                "Jaejin Cho",
                "Berkin Bilgic",
                "Yuxin Hu",
                "Brian Hargreaves",
                "Kawin Setsompop"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15939v1",
                "http://arxiv.org/pdf/2310.15939v1"
            ],
            "primary_category": "physics.med-ph",
            "category": [
                "physics.med-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15938v1",
            "title": "ABKD: Graph Neural Network Compression with Attention-Based Knowledge\n  Distillation",
            "updated": "2023-10-24T15:34:30Z",
            "published": "2023-10-24T15:34:30Z",
            "summary": "Graph Neural Networks (GNNs) have proven to be quite versatile for a variety\nof applications, including recommendation systems, fake news detection, drug\ndiscovery, and even computer vision. Due to the expanding size of\ngraph-structured data, GNN models have also increased in complexity, leading to\nsubstantial latency issues. This is primarily attributed to the irregular\nstructure of graph data and its access pattern into memory. The natural\nsolution to reduce latency is to compress large GNNs into small GNNs. One way\nto do this is via knowledge distillation (KD). However, most KD approaches for\nGNNs only consider the outputs of the last layers and do not consider the\noutputs of the intermediate layers of the GNNs; these layers may contain\nimportant inductive biases indicated by the graph structure. To address this\nshortcoming, we propose a novel KD approach to GNN compression that we call\nAttention-Based Knowledge Distillation (ABKD). ABKD is a KD approach that uses\nattention to identify important intermediate teacher-student layer pairs and\nfocuses on aligning their outputs. ABKD enables higher compression of GNNs with\na smaller accuracy dropoff compared to existing KD approaches. On average, we\nachieve a 1.79% increase in accuracy with a 32.3x compression ratio on\nOGBN-Mag, a large graph dataset, compared to state-of-the-art approaches.",
            "author": [
                "Anshul Ahluwalia",
                "Rohit Das",
                "Payman Behnam",
                "Alind Khare",
                "Pan Li",
                "Alexey Tumanov"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15938v1",
                "http://arxiv.org/pdf/2310.15938v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15935v1",
            "title": "Mediator Interpretation and Faster Learning Algorithms for Linear\n  Correlated Equilibria in General Extensive-Form Games",
            "updated": "2023-10-24T15:32:54Z",
            "published": "2023-10-24T15:32:54Z",
            "summary": "A recent paper by Farina & Pipis (2023) established the existence of\nuncoupled no-linear-swap regret dynamics with polynomial-time iterations in\nextensive-form games. The equilibrium points reached by these dynamics, known\nas linear correlated equilibria, are currently the tightest known relaxation of\ncorrelated equilibrium that can be learned in polynomial time in any finite\nextensive-form game. However, their properties remain vastly unexplored, and\ntheir computation is onerous. In this paper, we provide several contributions\nshedding light on the fundamental nature of linear-swap regret. First, we show\na connection between linear deviations and a generalization of communication\ndeviations in which the player can make queries to a \"mediator\" who replies\nwith action recommendations, and, critically, the player is not constrained to\nmatch the timing of the game as would be the case for communication deviations.\nWe coin this latter set the untimed communication (UTC) deviations. We show\nthat the UTC deviations coincide precisely with the linear deviations, and\ntherefore that any player minimizing UTC regret also minimizes linear-swap\nregret. We then leverage this connection to develop state-of-the-art no-regret\nalgorithms for computing linear correlated equilibria, both in theory and in\npractice. In theory, our algorithms achieve polynomially better per-iteration\nruntimes; in practice, our algorithms represent the state of the art by several\norders of magnitude.",
            "author": [
                "Brian Hu Zhang",
                "Gabriele Farina",
                "Tuomas Sandholm"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15935v1",
                "http://arxiv.org/pdf/2310.15935v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15932v1",
            "title": "Online Robust Mean Estimation",
            "updated": "2023-10-24T15:28:43Z",
            "published": "2023-10-24T15:28:43Z",
            "summary": "We study the problem of high-dimensional robust mean estimation in an online\nsetting. Specifically, we consider a scenario where $n$ sensors are measuring\nsome common, ongoing phenomenon. At each time step $t=1,2,\\ldots,T$, the\n$i^{th}$ sensor reports its readings $x^{(i)}_t$ for that time step. The\nalgorithm must then commit to its estimate $\\mu_t$ for the true mean value of\nthe process at time $t$. We assume that most of the sensors observe independent\nsamples from some common distribution $X$, but an $\\epsilon$-fraction of them\nmay instead behave maliciously. The algorithm wishes to compute a good\napproximation $\\mu$ to the true mean $\\mu^\\ast := \\mathbf{E}[X]$. We note that\nif the algorithm is allowed to wait until time $T$ to report its estimate, this\nreduces to the well-studied problem of robust mean estimation. However, the\nrequirement that our algorithm produces partial estimates as the data is coming\nin substantially complicates the situation.\n  We prove two main results about online robust mean estimation in this model.\nFirst, if the uncorrupted samples satisfy the standard condition of\n$(\\epsilon,\\delta)$-stability, we give an efficient online algorithm that\noutputs estimates $\\mu_t$, $t \\in [T],$ such that with high probability it\nholds that $\\|\\mu-\\mu^\\ast\\|_2 = O(\\delta \\log(T))$, where $\\mu = (\\mu_t)_{t\n\\in [T]}$. We note that this error bound is nearly competitive with the best\noffline algorithms, which would achieve $\\ell_2$-error of $O(\\delta)$. Our\nsecond main result shows that with additional assumptions on the input (most\nnotably that $X$ is a product distribution) there are inefficient algorithms\nwhose error does not depend on $T$ at all.",
            "author": [
                "Daniel M. Kane",
                "Ilias Diakonikolas",
                "Hanshen Xiao",
                "Sihan Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15932v1",
                "http://arxiv.org/pdf/2310.15932v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DS",
                "math.ST",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15929v1",
            "title": "E-Sparse: Boosting the Large Language Model Inference through\n  Entropy-based N:M Sparsity",
            "updated": "2023-10-24T15:27:15Z",
            "published": "2023-10-24T15:27:15Z",
            "summary": "Traditional pruning methods are known to be challenging to work in Large\nLanguage Models (LLMs) for Generative AI because of their unaffordable training\nprocess and large computational demands. For the first time, we introduce the\ninformation entropy of hidden state features into a pruning metric design,\nnamely E-Sparse, to improve the accuracy of N:M sparsity on LLM. E-Sparse\nemploys the information richness to leverage the channel importance, and\nfurther incorporates several novel techniques to put it into effect: (1) it\nintroduces information entropy to enhance the significance of parameter weights\nand input feature norms as a novel pruning metric, and performs N:M sparsity\nwithout modifying the remaining weights. (2) it designs global naive shuffle\nand local block shuffle to quickly optimize the information distribution and\nadequately cope with the impact of N:M sparsity on LLMs' accuracy. E-Sparse is\nimplemented as a Sparse-GEMM on FasterTransformer and runs on NVIDIA Ampere\nGPUs. Extensive experiments on the LLaMA family and OPT models show that\nE-Sparse can significantly speed up the model inference over the dense model\n(up to 1.53X) and obtain significant memory saving (up to 43.52%), with\nacceptable accuracy loss.",
            "author": [
                "Yun Li",
                "Lin Niu",
                "Xipeng Zhang",
                "Kai Liu",
                "Jianchen Zhu",
                "Zhanhui Kang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15929v1",
                "http://arxiv.org/pdf/2310.15929v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15921v1",
            "title": "Contrastive Learning-based Sentence Encoders Implicitly Weight\n  Informative Words",
            "updated": "2023-10-24T15:22:04Z",
            "published": "2023-10-24T15:22:04Z",
            "summary": "The performance of sentence encoders can be significantly improved through\nthe simple practice of fine-tuning using contrastive loss. A natural question\narises: what characteristics do models acquire during contrastive learning?\nThis paper theoretically and experimentally shows that contrastive-based\nsentence encoders implicitly weight words based on information-theoretic\nquantities; that is, more informative words receive greater weight, while\nothers receive less. The theory states that, in the lower bound of the optimal\nvalue of the contrastive learning objective, the norm of word embedding\nreflects the information gain associated with the distribution of surrounding\nwords. We also conduct comprehensive experiments using various models, multiple\ndatasets, two methods to measure the implicit weighting of models (Integrated\nGradients and SHAP), and two information-theoretic quantities (information gain\nand self-information). The results provide empirical evidence that contrastive\nfine-tuning emphasizes informative words.",
            "author": [
                "Hiroto Kurita",
                "Goro Kobayashi",
                "Sho Yokoi",
                "Kentaro Inui"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15921v1",
                "http://arxiv.org/pdf/2310.15921v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15916v1",
            "title": "In-Context Learning Creates Task Vectors",
            "updated": "2023-10-24T15:17:14Z",
            "published": "2023-10-24T15:17:14Z",
            "summary": "In-context learning (ICL) in Large Language Models (LLMs) has emerged as a\npowerful new learning paradigm. However, its underlying mechanism is still not\nwell understood. In particular, it is challenging to map it to the \"standard\"\nmachine learning framework, where one uses a training set $S$ to find a\nbest-fitting function $f(x)$ in some hypothesis class. Here we make progress on\nthis problem by showing that the functions learned by ICL often have a very\nsimple structure: they correspond to the transformer LLM whose only inputs are\nthe query $x$ and a single \"task vector\" calculated from the training set.\nThus, ICL can be seen as compressing $S$ into a single task vector\n$\\boldsymbol{\\theta}(S)$ and then using this task vector to modulate the\ntransformer to produce the output. We support the above claim via comprehensive\nexperiments across a range of models and tasks.",
            "author": [
                "Roee Hendel",
                "Mor Geva",
                "Amir Globerson"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15916v1",
                "http://arxiv.org/pdf/2310.15916v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16074v1",
            "title": "RePoseDM: Recurrent Pose Alignment and Gradient Guidance for Pose Guided\n  Image Synthesis",
            "updated": "2023-10-24T15:16:19Z",
            "published": "2023-10-24T15:16:19Z",
            "summary": "Pose-guided person image synthesis task requires re-rendering a reference\nimage, which should have a photorealistic appearance and flawless pose\ntransfer. Since person images are highly structured, existing approaches\nrequire dense connections for complex deformations and occlusions because these\nare generally handled through multi-level warping and masking in latent space.\nBut the feature maps generated by convolutional neural networks do not have\nequivariance, and hence even the multi-level warping does not have a perfect\npose alignment. Inspired by the ability of the diffusion model to generate\nphotorealistic images from the given conditional guidance, we propose recurrent\npose alignment to provide pose-aligned texture features as conditional\nguidance. Moreover, we propose gradient guidance from pose interaction fields,\nwhich output the distance from the valid pose manifold given a target pose as\ninput. This helps in learning plausible pose transfer trajectories that result\nin photorealism and undistorted texture details. Extensive results on two\nlarge-scale benchmarks and a user study demonstrate the ability of our proposed\napproach to generate photorealistic pose transfer under challenging scenarios.\nAdditionally, we prove the efficiency of gradient guidance in pose-guided image\ngeneration on the HumanArt dataset with fine-tuned stable diffusion.",
            "author": [
                "Anant Khandelwal"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16074v1",
                "http://arxiv.org/pdf/2310.16074v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15913v1",
            "title": "Mitigate Domain Shift by Primary-Auxiliary Objectives Association for\n  Generalizing Person ReID",
            "updated": "2023-10-24T15:15:57Z",
            "published": "2023-10-24T15:15:57Z",
            "summary": "While deep learning has significantly improved ReID model accuracy under the\nindependent and identical distribution (IID) assumption, it has also become\nclear that such models degrade notably when applied to an unseen novel domain\ndue to unpredictable/unknown domain shift. Contemporary domain generalization\n(DG) ReID models struggle in learning domain-invariant representation solely\nthrough training on an instance classification objective. We consider that a\ndeep learning model is heavily influenced and therefore biased towards\ndomain-specific characteristics, e.g., background clutter, scale and viewpoint\nvariations, limiting the generalizability of the learned model, and hypothesize\nthat the pedestrians are domain invariant owning they share the same structural\ncharacteristics. To enable the ReID model to be less domain-specific from these\npure pedestrians, we introduce a method that guides model learning of the\nprimary ReID instance classification objective by a concurrent auxiliary\nlearning objective on weakly labeled pedestrian saliency detection. To solve\nthe problem of conflicting optimization criteria in the model parameter space\nbetween the two learning objectives, we introduce a Primary-Auxiliary\nObjectives Association (PAOA) mechanism to calibrate the loss gradients of the\nauxiliary task towards the primary learning task gradients. Benefiting from the\nharmonious multitask learning design, our model can be extended with the recent\ntest-time diagram to form the PAOA+, which performs on-the-fly optimization\nagainst the auxiliary objective in order to maximize the model's generative\ncapacity in the test target domain. Experiments demonstrate the superiority of\nthe proposed PAOA model.",
            "author": [
                "Qilei Li",
                "Shaogang Gong"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15913v1",
                "http://arxiv.org/pdf/2310.15913v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15912v1",
            "title": "Climate Change Impact on Agricultural Land Suitability: An Interpretable\n  Machine Learning-Based Eurasia Case Study",
            "updated": "2023-10-24T15:15:28Z",
            "published": "2023-10-24T15:15:28Z",
            "summary": "The United Nations has identified improving food security and reducing hunger\nas essential components of its sustainable development goals. As of 2021,\napproximately 828 million people worldwide are experiencing hunger and\nmalnutrition, with numerous fatalities reported. Climate change significantly\nimpacts agricultural land suitability, potentially leading to severe food\nshortages and subsequent social and political conflicts. To address this\npressing issue, we have developed a machine learning-based approach to predict\nthe risk of substantial land suitability degradation and changes in irrigation\npatterns. Our study focuses on Central Eurasia, a region burdened with economic\nand social challenges.\n  This study represents a pioneering effort in utilizing machine learning\nmethods to assess the impact of climate change on agricultural land suitability\nunder various carbon emissions scenarios. Through comprehensive feature\nimportance analysis, we unveil specific climate and terrain characteristics\nthat exert influence on land suitability. Our approach achieves remarkable\naccuracy, offering policymakers invaluable insights to facilitate informed\ndecisions aimed at averting a humanitarian crisis, including strategies such as\nthe provision of additional water and fertilizers. This research underscores\nthe tremendous potential of machine learning in addressing global challenges,\nwith a particular emphasis on mitigating hunger and malnutrition.",
            "author": [
                "Valeriy Shevchenko",
                "Daria Taniushkina",
                "Aleksander Lukashevich",
                "Aleksandr Bulkin",
                "Roland Grinis",
                "Kirill Kovalev",
                "Veronika Narozhnaia",
                "Nazar Sotiriadi",
                "Alexander Krenke",
                "Yury Maximov"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15912v1",
                "http://arxiv.org/pdf/2310.15912v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15910v1",
            "title": "Characterizing Mechanisms for Factual Recall in Language Models",
            "updated": "2023-10-24T15:15:18Z",
            "published": "2023-10-24T15:15:18Z",
            "summary": "Language Models (LMs) often must integrate facts they memorized in\npretraining with new information that appears in a given context. These two\nsources can disagree, causing competition within the model, and it is unclear\nhow an LM will resolve the conflict. On a dataset that queries for knowledge of\nworld capitals, we investigate both distributional and mechanistic determinants\nof LM behavior in such situations. Specifically, we measure the proportion of\nthe time an LM will use a counterfactual prefix (e.g., \"The capital of Poland\nis London\") to overwrite what it learned in pretraining (\"Warsaw\"). On Pythia\nand GPT2, the training frequency of both the query country (\"Poland\") and the\nin-context city (\"London\") highly affect the models' likelihood of using the\ncounterfactual. We then use head attribution to identify individual attention\nheads that either promote the memorized answer or the in-context answer in the\nlogits. By scaling up or down the value vector of these heads, we can control\nthe likelihood of using the in-context answer on new data. This method can\nincrease the rate of generating the in-context answer to 88\\% of the time\nsimply by scaling a single head at runtime. Our work contributes to a body of\nevidence showing that we can often localize model behaviors to specific\ncomponents and provides a proof of concept for how future methods might control\nmodel behavior dynamically at runtime.",
            "author": [
                "Qinan Yu",
                "Jack Merullo",
                "Ellie Pavlick"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15910v1",
                "http://arxiv.org/pdf/2310.15910v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15905v1",
            "title": "Is Probing All You Need? Indicator Tasks as an Alternative to Probing\n  Embedding Spaces",
            "updated": "2023-10-24T15:08:12Z",
            "published": "2023-10-24T15:08:12Z",
            "summary": "The ability to identify and control different kinds of linguistic information\nencoded in vector representations of words has many use cases, especially for\nexplainability and bias removal. This is usually done via a set of simple\nclassification tasks, termed probes, to evaluate the information encoded in the\nembedding space. However, the involvement of a trainable classifier leads to\nentanglement between the probe's results and the classifier's nature. As a\nresult, contemporary works on probing include tasks that do not involve\ntraining of auxiliary models. In this work we introduce the term indicator\ntasks for non-trainable tasks which are used to query embedding spaces for the\nexistence of certain properties, and claim that this kind of tasks may point to\na direction opposite to probes, and that this contradiction complicates the\ndecision on whether a property exists in an embedding space. We demonstrate our\nclaims with two test cases, one dealing with gender debiasing and another with\nthe erasure of morphological information from embedding spaces. We show that\nthe application of a suitable indicator provides a more accurate picture of the\ninformation captured and removed compared to probes. We thus conclude that\nindicator tasks should be implemented and taken into consideration when\neliciting information from embedded representations.",
            "author": [
                "Tal Levy",
                "Omer Goldman",
                "Reut Tsarfaty"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15905v1",
                "http://arxiv.org/pdf/2310.15905v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15904v1",
            "title": "Do Stochastic Parrots have Feelings Too? Improving Neural Detection of\n  Synthetic Text via Emotion Recognition",
            "updated": "2023-10-24T15:07:35Z",
            "published": "2023-10-24T15:07:35Z",
            "summary": "Recent developments in generative AI have shone a spotlight on\nhigh-performance synthetic text generation technologies. The now wide\navailability and ease of use of such models highlights the urgent need to\nprovide equally powerful technologies capable of identifying synthetic text.\nWith this in mind, we draw inspiration from psychological studies which suggest\nthat people can be driven by emotion and encode emotion in the text they\ncompose. We hypothesize that pretrained language models (PLMs) have an\naffective deficit because they lack such an emotional driver when generating\ntext and consequently may generate synthetic text which has affective\nincoherence i.e. lacking the kind of emotional coherence present in\nhuman-authored text. We subsequently develop an emotionally aware detector by\nfine-tuning a PLM on emotion. Experiment results indicate that our\nemotionally-aware detector achieves improvements across a range of synthetic\ntext generators, various sized models, datasets, and domains. Finally, we\ncompare our emotionally-aware synthetic text detector to ChatGPT in the task of\nidentification of its own output and show substantial gains, reinforcing the\npotential of emotion as a signal to identify synthetic text. Code, models, and\ndatasets are available at https: //github.com/alanagiasi/emoPLMsynth",
            "author": [
                "Alan Cowap",
                "Yvette Graham",
                "Jennifer Foster"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15904v1",
                "http://arxiv.org/pdf/2310.15904v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15903v2",
            "title": "Neural Collapse in Multi-label Learning with Pick-all-label Loss",
            "updated": "2023-11-01T03:59:09Z",
            "published": "2023-10-24T15:07:16Z",
            "summary": "We study deep neural networks for the multi-label classification (MLab) task\nthrough the lens of neural collapse (NC). Previous works have been restricted\nto the multi-class classification setting and discovered a prevalent NC\nphenomenon comprising of the following properties for the last-layer features:\n(i) the variability of features within every class collapses to zero, (ii) the\nset of feature means form an equi-angular tight frame (ETF), and (iii) the last\nlayer classifiers collapse to the feature mean upon some scaling. We generalize\nthe study to multi-label learning, and prove for the first time that a\ngeneralized NC phenomenon holds with the \"pick-all-label\" formulation. Under\nthe natural analog of the unconstrained feature model (UFM), we establish that\nthe only global classifier of the pick-all-label cross entropy loss display the\nsame ETF geometry which further collapse to multiplicity-1 feature class means.\nBesides, we discover a combinatorial property in generalized NC which is unique\nfor multi-label learning that we call \"tag-wise average\" property, where the\nfeature class-means of samples with multiple labels are scaled average of the\nfeature class-means of single label tags. Theoretically, we establish global\noptimality result for the pick-all-label cross-entropy risk for the UFM.\nAdditionally, We also provide empirical evidence to support our investigation\ninto training deep neural networks on multi-label datasets, resulting in\nimproved training efficiency.",
            "author": [
                "Pengyu Li",
                "Yutong Wang",
                "Xiao Li",
                "Qing Qu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15903v2",
                "http://arxiv.org/pdf/2310.15903v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16073v1",
            "title": "Correlation Debiasing for Unbiased Scene Graph Generation in Videos",
            "updated": "2023-10-24T14:59:51Z",
            "published": "2023-10-24T14:59:51Z",
            "summary": "Dynamic scene graph generation (SGG) from videos requires not only\ncomprehensive understanding of objects across the scenes that are prone to\ntemporal fluctuations but also a model the temporal motions and interactions\nwith different objects. Moreover, the long-tailed distribution of visual\nrelationships is the crucial bottleneck of most dynamic SGG methods, since most\nof them focus on capturing spatio-temporal context using complex architectures,\nwhich leads to the generation of biased scene graphs. To address these\nchallenges, we propose FloCoDe: Flow-aware temporal consistency and Correlation\nDebiasing with uncertainty attenuation for unbiased dynamic scene graphs.\nFloCoDe employs feature warping using flow to detect temporally consistent\nobjects across the frames. In addition, it uses correlation debiasing to learn\nthe unbiased relation representation for long-tailed classes. Moreover, to\nattenuate the predictive uncertainties, it uses a mixture of sigmoidal\ncross-entropy loss and contrastive loss to incorporate label correlations to\nidentify the commonly co-occurring relations and help debias the long-tailed\nones. Extensive experimental evaluation shows a performance gain as high as\n4.1% showing the superiority of generating more unbiased scene graphs.",
            "author": [
                "Anant Khandelwal"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16073v1",
                "http://arxiv.org/pdf/2310.16073v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15890v3",
            "title": "Cross-feature Contrastive Loss for Decentralized Deep Learning on\n  Heterogeneous Data",
            "updated": "2023-12-05T20:31:51Z",
            "published": "2023-10-24T14:48:23Z",
            "summary": "The current state-of-the-art decentralized learning algorithms mostly assume\nthe data distribution to be Independent and Identically Distributed (IID).\nHowever, in practical scenarios, the distributed datasets can have\nsignificantly heterogeneous data distributions across the agents. In this work,\nwe present a novel approach for decentralized learning on heterogeneous data,\nwhere data-free knowledge distillation through contrastive loss on\ncross-features is utilized to improve performance. Cross-features for a pair of\nneighboring agents are the features (i.e., last hidden layer activations)\nobtained from the data of an agent with respect to the model parameters of the\nother agent. We demonstrate the effectiveness of the proposed technique through\nan exhaustive set of experiments on various Computer Vision datasets (CIFAR-10,\nCIFAR-100, Fashion MNIST, Imagenette, and ImageNet), model architectures, and\nnetwork topologies. Our experiments show that the proposed method achieves\nsuperior performance (0.2-4% improvement in test accuracy) compared to other\nexisting techniques for decentralized learning on heterogeneous data.",
            "author": [
                "Sai Aparna Aketi",
                "Kaushik Roy"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15890v3",
                "http://arxiv.org/pdf/2310.15890v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15888v1",
            "title": "State Sequences Prediction via Fourier Transform for Representation\n  Learning",
            "updated": "2023-10-24T14:47:02Z",
            "published": "2023-10-24T14:47:02Z",
            "summary": "While deep reinforcement learning (RL) has been demonstrated effective in\nsolving complex control tasks, sample efficiency remains a key challenge due to\nthe large amounts of data required for remarkable performance. Existing\nresearch explores the application of representation learning for data-efficient\nRL, e.g., learning predictive representations by predicting long-term future\nstates. However, many existing methods do not fully exploit the structural\ninformation inherent in sequential state signals, which can potentially improve\nthe quality of long-term decision-making but is difficult to discern in the\ntime domain. To tackle this problem, we propose State Sequences Prediction via\nFourier Transform (SPF), a novel method that exploits the frequency domain of\nstate sequences to extract the underlying patterns in time series data for\nlearning expressive representations efficiently. Specifically, we theoretically\nanalyze the existence of structural information in state sequences, which is\nclosely related to policy performance and signal regularity, and then propose\nto predict the Fourier transform of infinite-step future state sequences to\nextract such information. One of the appealing features of SPF is that it is\nsimple to implement while not requiring storage of infinite-step future states\nas prediction targets. Experiments demonstrate that the proposed method\noutperforms several state-of-the-art algorithms in terms of both sample\nefficiency and performance.",
            "author": [
                "Mingxuan Ye",
                "Yufei Kuang",
                "Jie Wang",
                "Rui Yang",
                "Wengang Zhou",
                "Houqiang Li",
                "Feng Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15888v1",
                "http://arxiv.org/pdf/2310.15888v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02087v1",
            "title": "Design Of Rubble Analyzer Probe Using ML For Earthquake",
            "updated": "2023-10-24T14:43:42Z",
            "published": "2023-10-24T14:43:42Z",
            "summary": "The earthquake rubble analyzer uses machine learning to detect human presence\nvia ambient sounds, achieving 97.45% accuracy. It also provides real-time\nenvironmental data, aiding in assessing survival prospects for trapped\nindividuals, crucial for post-earthquake rescue efforts",
            "author": [
                "Abhishek Sebastian",
                "R Pragna",
                "K Vishal Vythianathan",
                "Dasaraju Sohan Sai",
                "U Shiva Sri Hari Al",
                "R Anirudh",
                "Apurv Choudhary"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02087v1",
                "http://arxiv.org/pdf/2311.02087v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.AI",
                "cs.LG",
                "eess.AS",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15883v1",
            "title": "Attitude Takeover Control for Noncooperative Space Targets Based on\n  Gaussian Processes with Online Model Learning",
            "updated": "2023-10-24T14:38:11Z",
            "published": "2023-10-24T14:38:11Z",
            "summary": "One major challenge for autonomous attitude takeover control for on-orbit\nservicing of spacecraft is that an accurate dynamic motion model of the\ncombined vehicles is highly nonlinear, complex and often costly to identify\nonline, which makes traditional model-based control impractical for this task.\nTo address this issue, a recursive online sparse Gaussian Process (GP)-based\nlearning strategy for attitude takeover control of noncooperative targets with\nmaneuverability is proposed, where the unknown dynamics are online compensated\nbased on the learnt GP model in a semi-feedforward manner. The method enables\nthe continuous use of on-orbit data to successively improve the learnt model\nduring online operation and has reduced computational load compared to standard\nGP regression. Next to the GP-based feedforward, a feedback controller is\nproposed that varies its gains based on the predicted model confidence,\nensuring robustness of the overall scheme. Moreover, rigorous theoretical\nproofs of Lyapunov stability and boundedness guarantees of the proposed\nmethod-driven closed-loop system are provided in the probabilistic sense. A\nsimulation study based on a high-fidelity simulator is used to show the\neffectiveness of the proposed strategy and demonstrate its high performance.",
            "author": [
                "Yuhan Liu",
                "Pengyu Wang",
                "Chang-Hun Lee",
                "Roland T\u00f3th"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15883v1",
                "http://arxiv.org/pdf/2310.15883v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18363v1",
            "title": "A Contextualized Real-Time Multimodal Emotion Recognition for\n  Conversational Agents using Graph Convolutional Networks in Reinforcement\n  Learning",
            "updated": "2023-10-24T14:31:17Z",
            "published": "2023-10-24T14:31:17Z",
            "summary": "Owing to the recent developments in Generative Artificial Intelligence\n(GenAI) and Large Language Models (LLM), conversational agents are becoming\nincreasingly popular and accepted. They provide a human touch by interacting in\nways familiar to us and by providing support as virtual companions. Therefore,\nit is important to understand the user's emotions in order to respond\nconsiderately. Compared to the standard problem of emotion recognition,\nconversational agents face an additional constraint in that recognition must be\nreal-time. Studies on model architectures using audio, visual, and textual\nmodalities have mainly focused on emotion classification using full video\nsequences that do not provide online features. In this work, we present a novel\nparadigm for contextualized Emotion Recognition using Graph Convolutional\nNetwork with Reinforcement Learning (conER-GRL). Conversations are partitioned\ninto smaller groups of utterances for effective extraction of contextual\ninformation. The system uses Gated Recurrent Units (GRU) to extract multimodal\nfeatures from these groups of utterances. More importantly, Graph Convolutional\nNetworks (GCN) and Reinforcement Learning (RL) agents are cascade trained to\ncapture the complex dependencies of emotion features in interactive scenarios.\nComparing the results of the conER-GRL model with other state-of-the-art models\non the benchmark dataset IEMOCAP demonstrates the advantageous capabilities of\nthe conER-GRL architecture in recognizing emotions in real-time from multimodal\nconversational signals.",
            "author": [
                "Fathima Abdul Rahman",
                "Guang Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18363v1",
                "http://arxiv.org/pdf/2310.18363v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.HC",
                "cs.LG",
                "I.2.10"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15872v1",
            "title": "KirchhoffNet: A Circuit Bridging Message Passing and Continuous-Depth\n  Models",
            "updated": "2023-10-24T14:28:00Z",
            "published": "2023-10-24T14:28:00Z",
            "summary": "In this paper, we exploit a fundamental principle of analog electronic\ncircuitry, Kirchhoff's current law, to introduce a unique class of neural\nnetwork models that we refer to as KirchhoffNet. KirchhoffNet establishes close\nconnections with message passing neural networks and continuous-depth networks.\nWe demonstrate that even in the absence of any traditional layers (such as\nconvolution, pooling, or linear layers), KirchhoffNet attains 98.86% test\naccuracy on the MNIST dataset, comparable with state of the art (SOTA) results.\nWhat makes KirchhoffNet more intriguing is its potential in the realm of\nhardware. Contemporary deep neural networks are conventionally deployed on\nGPUs. In contrast, KirchhoffNet can be physically realized by an analog\nelectronic circuit. Moreover, we justify that irrespective of the number of\nparameters within a KirchhoffNet, its forward calculation can always be\ncompleted within 1/f seconds, with f representing the hardware's clock\nfrequency. This characteristic introduces a promising technology for\nimplementing ultra-large-scale neural networks.",
            "author": [
                "Zhengqi Gao",
                "Fan-Keng Sun",
                "Duane S. Boning"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15872v1",
                "http://arxiv.org/pdf/2310.15872v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.AR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18362v1",
            "title": "SoK: Memorization in General-Purpose Large Language Models",
            "updated": "2023-10-24T14:25:53Z",
            "published": "2023-10-24T14:25:53Z",
            "summary": "Large Language Models (LLMs) are advancing at a remarkable pace, with myriad\napplications under development. Unlike most earlier machine learning models,\nthey are no longer built for one specific application but are designed to excel\nin a wide range of tasks. A major part of this success is due to their huge\ntraining datasets and the unprecedented number of model parameters, which allow\nthem to memorize large amounts of information contained in the training data.\nThis memorization goes beyond mere language, and encompasses information only\npresent in a few documents. This is often desirable since it is necessary for\nperforming tasks such as question answering, and therefore an important part of\nlearning, but also brings a whole array of issues, from privacy and security to\ncopyright and beyond. LLMs can memorize short secrets in the training data, but\ncan also memorize concepts like facts or writing styles that can be expressed\nin text in many different ways. We propose a taxonomy for memorization in LLMs\nthat covers verbatim text, facts, ideas and algorithms, writing styles,\ndistributional properties, and alignment goals. We describe the implications of\neach type of memorization - both positive and negative - for model performance,\nprivacy, security and confidentiality, copyright, and auditing, and ways to\ndetect and prevent memorization. We further highlight the challenges that arise\nfrom the predominant way of defining memorization with respect to model\nbehavior instead of model weights, due to LLM-specific phenomena such as\nreasoning capabilities or differences between decoding algorithms. Throughout\nthe paper, we describe potential risks and opportunities arising from\nmemorization in LLMs that we hope will motivate new research directions.",
            "author": [
                "Valentin Hartmann",
                "Anshuman Suri",
                "Vincent Bindschaedler",
                "David Evans",
                "Shruti Tople",
                "Robert West"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18362v1",
                "http://arxiv.org/pdf/2310.18362v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15865v1",
            "title": "Using Causality-Aware Graph Neural Networks to Predict Temporal\n  Centralities in Dynamic Graphs",
            "updated": "2023-10-24T14:23:10Z",
            "published": "2023-10-24T14:23:10Z",
            "summary": "Node centralities play a pivotal role in network science, social network\nanalysis, and recommender systems. In temporal data, static path-based\ncentralities like closeness or betweenness can give misleading results about\nthe true importance of nodes in a temporal graph. To address this issue,\ntemporal generalizations of betweenness and closeness have been defined that\nare based on the shortest time-respecting paths between pairs of nodes.\nHowever, a major issue of those generalizations is that the calculation of such\npaths is computationally expensive. Addressing this issue, we study the\napplication of De Bruijn Graph Neural Networks (DBGNN), a causality-aware graph\nneural network architecture, to predict temporal path-based centralities in\ntime series data. We experimentally evaluate our approach in 13 temporal graphs\nfrom biological and social systems and show that it considerably improves the\nprediction of both betweenness and closeness centrality compared to a static\nGraph Convolutional Neural Network.",
            "author": [
                "Franziska Heeg",
                "Ingo Scholtes"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15865v1",
                "http://arxiv.org/pdf/2310.15865v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15861v1",
            "title": "Social Learning of General Rules",
            "updated": "2023-10-24T14:21:52Z",
            "published": "2023-10-24T14:21:52Z",
            "summary": "Why do agents adopt a particular general behavioral rule among a collection\nof possible alternatives? To address this question, we introduce a dynamic\nsocial learning framework, where agents rely on general rules of thumb and\nimitate the behavioral rules of successful peers. We find the social learning\noutcome can be characterized independent of the initial rule distribution. When\none dominant general rule consistently yields superior problem-specific\noutcomes, social learning almost surely leads all agents to adopt this dominant\nrule; otherwise, provided the population is sufficiently large, the better rule\nfor the more frequent problem becomes the consensus rule with arbitrarily high\nprobability. As a result, the behavioral rule selected by the social learning\nprocess need not maximize social welfare. We complement our theoretical\nanalysis with an application to the market sentiment selection in a stochastic\nproduction market.",
            "author": [
                "Enrique Urbano Arellano",
                "Xinyang Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15861v1",
                "http://arxiv.org/pdf/2310.15861v1"
            ],
            "primary_category": "econ.TH",
            "category": [
                "econ.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16853v1",
            "title": "CP-BCS: Binary Code Summarization Guided by Control Flow Graph and\n  Pseudo Code",
            "updated": "2023-10-24T14:20:39Z",
            "published": "2023-10-24T14:20:39Z",
            "summary": "Automatically generating function summaries for binaries is an extremely\nvaluable but challenging task, since it involves translating the execution\nbehavior and semantics of the low-level language (assembly code) into\nhuman-readable natural language. However, most current works on understanding\nassembly code are oriented towards generating function names, which involve\nnumerous abbreviations that make them still confusing. To bridge this gap, we\nfocus on generating complete summaries for binary functions, especially for\nstripped binary (no symbol table and debug information in reality). To fully\nexploit the semantics of assembly code, we present a control flow graph and\npseudo code guided binary code summarization framework called CP-BCS. CP-BCS\nutilizes a bidirectional instruction-level control flow graph and pseudo code\nthat incorporates expert knowledge to learn the comprehensive binary function\nexecution behavior and logic semantics. We evaluate CP-BCS on 3 different\nbinary optimization levels (O1, O2, and O3) for 3 different computer\narchitectures (X86, X64, and ARM). The evaluation results demonstrate CP-BCS is\nsuperior and significantly improves the efficiency of reverse engineering.",
            "author": [
                "Tong Ye",
                "Lingfei Wu",
                "Tengfei Ma",
                "Xuhong Zhang",
                "Yangkai Du",
                "Peiyu Liu",
                "Shouling Ji",
                "Wenhai Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16853v1",
                "http://arxiv.org/pdf/2310.16853v1"
            ],
            "primary_category": "cs.PL",
            "category": [
                "cs.PL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15858v1",
            "title": "Topology-aware Debiased Self-supervised Graph Learning for\n  Recommendation",
            "updated": "2023-10-24T14:16:19Z",
            "published": "2023-10-24T14:16:19Z",
            "summary": "In recommendation, graph-based Collaborative Filtering (CF) methods mitigate\nthe data sparsity by introducing Graph Contrastive Learning (GCL). However, the\nrandom negative sampling strategy in these GCL-based CF models neglects the\nsemantic structure of users (items), which not only introduces false negatives\n(negatives that are similar to anchor user (item)) but also ignores the\npotential positive samples. To tackle the above issues, we propose\nTopology-aware Debiased Self-supervised Graph Learning (TDSGL) for\nrecommendation, which constructs contrastive pairs according to the semantic\nsimilarity between users (items). Specifically, since the original user-item\ninteraction data commendably reflects the purchasing intent of users and\ncertain characteristics of items, we calculate the semantic similarity between\nusers (items) on interaction data. Then, given a user (item), we construct its\nnegative pairs by selecting users (items) which embed different semantic\nstructures to ensure the semantic difference between the given user (item) and\nits negatives. Moreover, for a user (item), we design a feature extraction\nmodule that converts other semantically similar users (items) into an auxiliary\npositive sample to acquire a more informative representation. Experimental\nresults show that the proposed model outperforms the state-of-the-art models\nsignificantly on three public datasets. Our model implementation codes are\navailable at https://github.com/malajikuai/TDSGL.",
            "author": [
                "Lei Han",
                "Hui Yan",
                "Zhicheng Qiao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15858v1",
                "http://arxiv.org/pdf/2310.15858v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15853v1",
            "title": "Improving Event Time Prediction by Learning to Partition the Event Time\n  Space",
            "updated": "2023-10-24T14:11:40Z",
            "published": "2023-10-24T14:11:40Z",
            "summary": "Recently developed survival analysis methods improve upon existing approaches\nby predicting the probability of event occurrence in each of a number\npre-specified (discrete) time intervals. By avoiding placing strong parametric\nassumptions on the event density, this approach tends to improve prediction\nperformance, particularly when data are plentiful. However, in clinical\nsettings with limited available data, it is often preferable to judiciously\npartition the event time space into a limited number of intervals well suited\nto the prediction task at hand. In this work, we develop a method to learn from\ndata a set of cut points defining such a partition. We show that in two\nsimulated datasets, we are able to recover intervals that match the underlying\ngenerative model. We then demonstrate improved prediction performance on three\nreal-world observational datasets, including a large, newly harmonized stroke\nrisk prediction dataset. Finally, we argue that our approach facilitates\nclinical decision-making by suggesting time intervals that are most appropriate\nfor each task, in the sense that they facilitate more accurate risk prediction.",
            "author": [
                "Jimmy Hickey",
                "Ricardo Henao",
                "Daniel Wojdyla",
                "Michael Pencina",
                "Matthew M. Engelhard"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15853v1",
                "http://arxiv.org/pdf/2310.15853v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15852v1",
            "title": "Using Artificial French Data to Understand the Emergence of Gender Bias\n  in Transformer Language Models",
            "updated": "2023-10-24T14:08:37Z",
            "published": "2023-10-24T14:08:37Z",
            "summary": "Numerous studies have demonstrated the ability of neural language models to\nlearn various linguistic properties without direct supervision. This work takes\nan initial step towards exploring the less researched topic of how neural\nmodels discover linguistic properties of words, such as gender, as well as the\nrules governing their usage. We propose to use an artificial corpus generated\nby a PCFG based on French to precisely control the gender distribution in the\ntraining data and determine under which conditions a model correctly captures\ngender information or, on the contrary, appears gender-biased.",
            "author": [
                "Lina Conti",
                "Guillaume Wisniewski"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15852v1",
                "http://arxiv.org/pdf/2310.15852v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15850v1",
            "title": "Posterior Estimation for Dynamic PET imaging using Conditional\n  Variational Inference",
            "updated": "2023-10-24T14:05:30Z",
            "published": "2023-10-24T14:05:30Z",
            "summary": "This work aims efficiently estimating the posterior distribution of kinetic\nparameters for dynamic positron emission tomography (PET) imaging given a\nmeasurement of time of activity curve. Considering the inherent information\nloss from parametric imaging to measurement space with the forward kinetic\nmodel, the inverse mapping is ambiguous. The conventional (but expensive)\nsolution can be the Markov Chain Monte Carlo (MCMC) sampling, which is known to\nproduce unbiased asymptotical estimation. We propose a deep-learning-based\nframework for efficient posterior estimation. Specifically, we counteract the\ninformation loss in the forward process by introducing latent variables. Then,\nwe use a conditional variational autoencoder (CVAE) and optimize its evidence\nlower bound. The well-trained decoder is able to infer the posterior with a\ngiven measurement and the sampled latent variables following a simple\nmultivariate Gaussian distribution. We validate our CVAE-based method using\nunbiased MCMC as the reference for low-dimensional data (a single brain region)\nwith the simplified reference tissue model.",
            "author": [
                "Xiaofeng Liu",
                "Thibault Marin",
                "Tiss Amal",
                "Jonghye Woo",
                "Georges El Fakhri",
                "Jinsong Ouyang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15850v1",
                "http://arxiv.org/pdf/2310.15850v1"
            ],
            "primary_category": "physics.med-ph",
            "category": [
                "physics.med-ph",
                "cs.AI",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15848v3",
            "title": "On Responsible Machine Learning Datasets with Fairness, Privacy, and\n  Regulatory Norms",
            "updated": "2023-11-25T04:02:29Z",
            "published": "2023-10-24T14:01:53Z",
            "summary": "Artificial Intelligence (AI) has made its way into various scientific fields,\nproviding astonishing improvements over existing algorithms for a wide variety\nof tasks. In recent years, there have been severe concerns over the\ntrustworthiness of AI technologies. The scientific community has focused on the\ndevelopment of trustworthy AI algorithms. However, machine and deep learning\nalgorithms, popular in the AI community today, depend heavily on the data used\nduring their development. These learning algorithms identify patterns in the\ndata, learning the behavioral objective. Any flaws in the data have the\npotential to translate directly into algorithms. In this study, we discuss the\nimportance of Responsible Machine Learning Datasets and propose a framework to\nevaluate the datasets through a responsible rubric. While existing work focuses\non the post-hoc evaluation of algorithms for their trustworthiness, we provide\na framework that considers the data component separately to understand its role\nin the algorithm. We discuss responsible datasets through the lens of fairness,\nprivacy, and regulatory compliance and provide recommendations for constructing\nfuture datasets. After surveying over 100 datasets, we use 60 datasets for\nanalysis and demonstrate that none of these datasets is immune to issues of\nfairness, privacy preservation, and regulatory compliance. We provide\nmodifications to the ``datasheets for datasets\" with important additions for\nimproved dataset documentation. With governments around the world regularizing\ndata protection laws, the method for the creation of datasets in the scientific\ncommunity requires revision. We believe this study is timely and relevant in\ntoday's era of AI.",
            "author": [
                "Surbhi Mittal",
                "Kartik Thakral",
                "Richa Singh",
                "Mayank Vatsa",
                "Tamar Glaser",
                "Cristian Canton Ferrer",
                "Tal Hassner"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15848v3",
                "http://arxiv.org/pdf/2310.15848v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15845v1",
            "title": "Pre-training Music Classification Models via Music Source Separation",
            "updated": "2023-10-24T13:57:55Z",
            "published": "2023-10-24T13:57:55Z",
            "summary": "In this paper, we study whether music source separation can be used as a\npre-training strategy for music representation learning, targeted at music\nclassification tasks. To this end, we first pre-train U-Net networks under\nvarious music source separation objectives, such as the isolation of vocal or\ninstrumental sources from a musical piece; afterwards, we attach a\nconvolutional tail network to the pre-trained U-Net and jointly finetune the\nwhole network. The features learned by the separation network are also\npropagated to the tail network through skip connections. Experimental results\nin two widely used and publicly available datasets indicate that pre-training\nthe U-Nets with a music source separation objective can improve performance\ncompared to both training the whole network from scratch and using the tail\nnetwork as a standalone in two music classification tasks: music auto-tagging,\nwhen vocal separation is used, and music genre classification for the case of\nmulti-source separation.",
            "author": [
                "Christos Garoufis",
                "Athanasia Zlatintsi",
                "Petros Maragos"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15845v1",
                "http://arxiv.org/pdf/2310.15845v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16071v1",
            "title": "Grid Frequency Forecasting in University Campuses using Convolutional\n  LSTM",
            "updated": "2023-10-24T13:53:51Z",
            "published": "2023-10-24T13:53:51Z",
            "summary": "The modern power grid is facing increasing complexities, primarily stemming\nfrom the integration of renewable energy sources and evolving consumption\npatterns. This paper introduces an innovative methodology that harnesses\nConvolutional Neural Networks (CNN) and Long Short-Term Memory (LSTM) networks\nto establish robust time series forecasting models for grid frequency. These\nmodels effectively capture the spatiotemporal intricacies inherent in grid\nfrequency data, significantly enhancing prediction accuracy and bolstering\npower grid reliability. The research explores the potential and development of\nindividualized Convolutional LSTM (ConvLSTM) models for buildings within a\nuniversity campus, enabling them to be independently trained and evaluated for\neach building. Individual ConvLSTM models are trained on power consumption data\nfor each campus building and forecast the grid frequency based on historical\ntrends. The results convincingly demonstrate the superiority of the proposed\nmodels over traditional forecasting techniques, as evidenced by performance\nmetrics such as Mean Square Error (MSE), Mean Absolute Error (MAE), and Mean\nAbsolute Percentage Error (MAPE). Additionally, an Ensemble Model is formulated\nto aggregate insights from the building-specific models, delivering\ncomprehensive forecasts for the entire campus. This approach ensures the\nprivacy and security of power consumption data specific to each building.",
            "author": [
                "Aneesh Sathe",
                "Wen Ren Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16071v1",
                "http://arxiv.org/pdf/2310.16071v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18361v1",
            "title": "Clinical Decision Support System for Unani Medicine Practitioners",
            "updated": "2023-10-24T13:49:18Z",
            "published": "2023-10-24T13:49:18Z",
            "summary": "Like other fields of Traditional Medicines, Unani Medicines have been found\nas an effective medical practice for ages. It is still widely used in the\nsubcontinent, particularly in Pakistan and India. However, Unani Medicines\nPractitioners are lacking modern IT applications in their everyday clinical\npractices. An Online Clinical Decision Support System may address this\nchallenge to assist apprentice Unani Medicines practitioners in their\ndiagnostic processes. The proposed system provides a web-based interface to\nenter the patient's symptoms, which are then automatically analyzed by our\nsystem to generate a list of probable diseases. The system allows practitioners\nto choose the most likely disease and inform patients about the associated\ntreatment options remotely. The system consists of three modules: an Online\nClinical Decision Support System, an Artificial Intelligence Inference Engine,\nand a comprehensive Unani Medicines Database. The system employs advanced AI\ntechniques such as Decision Trees, Deep Learning, and Natural Language\nProcessing. For system development, the project team used a technology stack\nthat includes React, FastAPI, and MySQL. Data and functionality of the\napplication is exposed using APIs for integration and extension with similar\ndomain applications. The novelty of the project is that it addresses the\nchallenge of diagnosing diseases accurately and efficiently in the context of\nUnani Medicines principles. By leveraging the power of technology, the proposed\nClinical Decision Support System has the potential to ease access to healthcare\nservices and information, reduce cost, boost practitioner and patient\nsatisfaction, improve speed and accuracy of the diagnostic process, and provide\neffective treatments remotely. The application will be useful for Unani\nMedicines Practitioners, Patients, Government Drug Regulators, Software\nDevelopers, and Medical Researchers.",
            "author": [
                "Haider Sultan",
                "Hafiza Farwa Mahmood",
                "Noor Fatima",
                "Marriyam Nadeem",
                "Talha Waheed"
            ],
            "link": [
                "http://dx.doi.org/10.13140/RG.2.2.15161.54887/1",
                "http://arxiv.org/abs/2310.18361v1",
                "http://arxiv.org/pdf/2310.18361v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16070v1",
            "title": "Spatial-Temporal Hypergraph Neural Network for Traffic Forecasting",
            "updated": "2023-10-24T13:49:13Z",
            "published": "2023-10-24T13:49:13Z",
            "summary": "Traffic forecasting, which benefits from mobile Internet development and\nposition technologies, plays a critical role in Intelligent Transportation\nSystems. It helps to implement rich and varied transportation applications and\nbring convenient transportation services to people based on collected traffic\ndata. Most existing methods usually leverage graph-based deep learning networks\nto model the complex road network for traffic forecasting shallowly. Despite\ntheir effectiveness, these methods are generally limited in fully capturing\nhigh-order spatial dependencies caused by road network topology and high-order\ntemporal dependencies caused by traffic dynamics. To tackle the above issues,\nwe focus on the essence of traffic system and propose STHODE: Spatio-Temporal\nHypergraph Neural Ordinary Differential Equation Network, which combines road\nnetwork topology and traffic dynamics to capture high-order spatio-temporal\ndependencies in traffic data. Technically, STHODE consists of a spatial module\nand a temporal module. On the one hand, we construct a spatial hypergraph and\nleverage an adaptive MixHop hypergraph ODE network to capture high-order\nspatial dependencies. On the other hand, we utilize a temporal hypergraph and\nemploy a hyperedge evolving ODE network to capture high-order temporal\ndependencies. Finally, we aggregate the outputs of stacked STHODE layers to\nmutually enhance the prediction performance. Extensive experiments conducted on\nfour real-world traffic datasets demonstrate the superior performance of our\nproposed model compared to various baselines.",
            "author": [
                "Chengzhi Yao",
                "Zhi Li",
                "Junbo Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16070v1",
                "http://arxiv.org/pdf/2310.16070v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.12856v2",
            "title": "Density of States Prediction of Crystalline Materials via Prompt-guided\n  Multi-Modal Transformer",
            "updated": "2023-11-23T02:00:09Z",
            "published": "2023-10-24T13:43:17Z",
            "summary": "The density of states (DOS) is a spectral property of crystalline materials,\nwhich provides fundamental insights into various characteristics of the\nmaterials. While previous works mainly focus on obtaining high-quality\nrepresentations of crystalline materials for DOS prediction, we focus on\npredicting the DOS from the obtained representations by reflecting the nature\nof DOS: DOS determines the general distribution of states as a function of\nenergy. That is, DOS is not solely determined by the crystalline material but\nalso by the energy levels, which has been neglected in previous works. In this\npaper, we propose to integrate heterogeneous information obtained from the\ncrystalline materials and the energies via a multi-modal transformer, thereby\nmodeling the complex relationships between the atoms in the crystalline\nmaterials and various energy levels for DOS prediction. Moreover, we propose to\nutilize prompts to guide the model to learn the crystal structural\nsystem-specific interactions between crystalline materials and energies.\nExtensive experiments on two types of DOS, i.e., Phonon DOS and Electron DOS,\nwith various real-world scenarios demonstrate the superiority of\nDOSTransformer. The source code for DOSTransformer is available at\nhttps://github.com/HeewoongNoh/DOSTransformer.",
            "author": [
                "Namkyeong Lee",
                "Heewoong Noh",
                "Sungwon Kim",
                "Dongmin Hyun",
                "Gyoung S. Na",
                "Chanyoung Park"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12856v2",
                "http://arxiv.org/pdf/2311.12856v2"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15836v1",
            "title": "A Diffusion Weighted Graph Framework for New Intent Discovery",
            "updated": "2023-10-24T13:43:01Z",
            "published": "2023-10-24T13:43:01Z",
            "summary": "New Intent Discovery (NID) aims to recognize both new and known intents from\nunlabeled data with the aid of limited labeled data containing only known\nintents. Without considering structure relationships between samples, previous\nmethods generate noisy supervisory signals which cannot strike a balance\nbetween quantity and quality, hindering the formation of new intent clusters\nand effective transfer of the pre-training knowledge. To mitigate this\nlimitation, we propose a novel Diffusion Weighted Graph Framework (DWGF) to\ncapture both semantic similarities and structure relationships inherent in\ndata, enabling more sufficient and reliable supervisory signals. Specifically,\nfor each sample, we diffuse neighborhood relationships along semantic paths\nguided by the nearest neighbors for multiple hops to characterize its local\nstructure discriminately. Then, we sample its positive keys and weigh them\nbased on semantic similarities and local structures for contrastive learning.\nDuring inference, we further propose Graph Smoothing Filter (GSF) to explicitly\nutilize the structure relationships to filter high-frequency noise embodied in\nsemantically ambiguous samples on the cluster boundary. Extensive experiments\nshow that our method outperforms state-of-the-art models on all evaluation\nmetrics across multiple benchmark datasets. Code and data are available at\nhttps://github.com/yibai-shi/DWGF.",
            "author": [
                "Wenkai Shi",
                "Wenbin An",
                "Feng Tian",
                "Qinghua Zheng",
                "QianYing Wang",
                "Ping Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15836v1",
                "http://arxiv.org/pdf/2310.15836v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15831v2",
            "title": "A Comparative Study of Variational Autoencoders, Normalizing Flows, and\n  Score-based Diffusion Models for Electrical Impedance Tomography",
            "updated": "2023-11-29T11:39:34Z",
            "published": "2023-10-24T13:36:44Z",
            "summary": "Electrical Impedance Tomography (EIT) is a widely employed imaging technique\nin industrial inspection, geophysical prospecting, and medical imaging.\nHowever, the inherent nonlinearity and ill-posedness of EIT image\nreconstruction present challenges for classical regularization techniques, such\nas the critical selection of regularization terms and the lack of prior\nknowledge. Deep generative models (DGMs) have been shown to play a crucial role\nin learning implicit regularizers and prior knowledge. This study aims to\ninvestigate the potential of three DGMs-variational autoencoder networks,\nnormalizing flow, and score-based diffusion model-to learn implicit\nregularizers in learning-based EIT imaging. We first introduce background\ninformation on EIT imaging and its inverse problem formulation. Next, we\npropose three algorithms for performing EIT inverse problems based on\ncorresponding DGMs. Finally, we present numerical and visual experiments, which\nreveal that (1) no single method consistently outperforms the others across all\nsettings, and (2) when reconstructing an object with 2 anomalies using a\nwell-trained model based on a training dataset containing 4 anomalies, the\nconditional normalizing flow model (CNF) exhibits the best generalization in\nlow-level noise, while the conditional score-based diffusion model (CSD*)\ndemonstrates the best generalization in high-level noise settings. We hope our\npreliminary efforts will encourage other researchers to assess their DGMs in\nEIT and other nonlinear inverse problems.",
            "author": [
                "Huihui Wang",
                "Guixian Xu",
                "Qingping Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15831v2",
                "http://arxiv.org/pdf/2310.15831v2"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15830v1",
            "title": "Localization of Small Leakages in Water Distribution Networks using\n  Concept Drift Explanation Methods",
            "updated": "2023-10-24T13:33:19Z",
            "published": "2023-10-24T13:33:19Z",
            "summary": "Facing climate change the already limited availability of drinking water will\ndecrease in the future rendering drinking water an increasingly scarce\nresource. Considerable amounts of it are lost through leakages in water\ntransportation and distribution networks. Leakage detection and localization\nare challenging problems due to the complex interactions and changing demands\nin water distribution networks. Especially small leakages are hard to pinpoint\nyet their localization is vital to avoid water loss over long periods of time.\nWhile there exist different approaches to solving the tasks of leakage\ndetection and localization, they are relying on various information about the\nsystem, e.g. real-time demand measurements and the precise network topology,\nwhich is an unrealistic assumption in many real-world scenarios. In contrast,\nthis work attempts leakage localization using pressure measurements only. For\nthis purpose, first, leakages in the water distribution network are modeled\nemploying Bayesian networks, and the system dynamics are analyzed. We then show\nhow the problem is connected to and can be considered through the lens of\nconcept drift. In particular, we argue that model-based explanations of concept\ndrift are a promising tool for localizing leakages given limited information\nabout the network. The methodology is experimentally evaluated using realistic\nbenchmark scenarios.",
            "author": [
                "Valerie Vaquet",
                "Fabian Hinder",
                "Kathrin Lammers",
                "Jonas Vaquet",
                "Barbara Hammer"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15830v1",
                "http://arxiv.org/pdf/2310.15830v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15827v1",
            "title": "Automatic Aorta Segmentation with Heavily Augmented, High-Resolution 3-D\n  ResUNet: Contribution to the SEG.A Challenge",
            "updated": "2023-10-24T13:28:46Z",
            "published": "2023-10-24T13:28:46Z",
            "summary": "Automatic aorta segmentation from 3-D medical volumes is an important yet\ndifficult task. Several factors make the problem challenging, e.g. the\npossibility of aortic dissection or the difficulty with segmenting and\nannotating the small branches. This work presents a contribution by the MedGIFT\nteam to the SEG.A challenge organized during the MICCAI 2023 conference. We\npropose a fully automated algorithm based on deep encoder-decoder architecture.\nThe main assumption behind our work is that data preprocessing and augmentation\nare much more important than the deep architecture, especially in low data\nregimes. Therefore, the solution is based on a variant of traditional\nconvolutional U-Net. The proposed solution achieved a Dice score above 0.9 for\nall testing cases with the highest stability among all participants. The method\nscored 1st, 4th, and 3rd in terms of the clinical evaluation, quantitative\nresults, and volumetric meshing quality, respectively. We freely release the\nsource code, pretrained model, and provide access to the algorithm on the\nGrand-Challenge platform.",
            "author": [
                "Marek Wodzinski",
                "Henning M\u00fcller"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15827v1",
                "http://arxiv.org/pdf/2310.15827v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15826v1",
            "title": "One or Two Things We know about Concept Drift -- A Survey on Monitoring\n  Evolving Environments",
            "updated": "2023-10-24T13:25:19Z",
            "published": "2023-10-24T13:25:19Z",
            "summary": "The world surrounding us is subject to constant change. These changes,\nfrequently described as concept drift, influence many industrial and technical\nprocesses. As they can lead to malfunctions and other anomalous behavior, which\nmay be safety-critical in many scenarios, detecting and analyzing concept drift\nis crucial. In this paper, we provide a literature review focusing on concept\ndrift in unsupervised data streams. While many surveys focus on supervised data\nstreams, so far, there is no work reviewing the unsupervised setting. However,\nthis setting is of particular relevance for monitoring and anomaly detection\nwhich are directly applicable to many tasks and challenges in engineering. This\nsurvey provides a taxonomy of existing work on drift detection. Besides, it\ncovers the current state of research on drift localization in a systematic way.\nIn addition to providing a systematic literature review, this work provides\nprecise mathematical definitions of the considered problems and contains\nstandardized experiments on parametric artificial datasets allowing for a\ndirect comparison of different strategies for detection and localization.\nThereby, the suitability of different schemes can be analyzed systematically\nand guidelines for their usage in real-world scenarios can be provided.\nFinally, there is a section on the emerging topic of explaining concept drift.",
            "author": [
                "Fabian Hinder",
                "Valerie Vaquet",
                "Barbara Hammer"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15826v1",
                "http://arxiv.org/pdf/2310.15826v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03370v1",
            "title": "CMIP X-MOS: Improving Climate Models with Extreme Model Output\n  Statistics",
            "updated": "2023-10-24T13:18:53Z",
            "published": "2023-10-24T13:18:53Z",
            "summary": "Climate models are essential for assessing the impact of greenhouse gas\nemissions on our changing climate and the resulting increase in the frequency\nand severity of natural disasters. Despite the widespread acceptance of climate\nmodels produced by the Coupled Model Intercomparison Project (CMIP), they still\nface challenges in accurately predicting climate extremes, which pose most\nsignificant threats to both people and the environment. To address this\nlimitation and improve predictions of natural disaster risks, we introduce\nExtreme Model Output Statistics (X-MOS). This approach utilizes deep regression\ntechniques to precisely map CMIP model outputs to real measurements obtained\nfrom weather stations, which results in a more accurate analysis of the XXI\nclimate extremes. In contrast to previous research, our study places a strong\nemphasis on enhancing the estimation of the tails of future climate parameter\ndistributions. The latter supports decision-makers, enabling them to better\nassess climate-related risks across the globe.",
            "author": [
                "Vsevolod Morozov",
                "Artem Galliamov",
                "Aleksandr Lukashevich",
                "Antonina Kurdukova",
                "Yury Maximov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03370v1",
                "http://arxiv.org/pdf/2311.03370v1"
            ],
            "primary_category": "physics.ao-ph",
            "category": [
                "physics.ao-ph",
                "cs.LG",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15819v1",
            "title": "Generative Language Models Exhibit Social Identity Biases",
            "updated": "2023-10-24T13:17:40Z",
            "published": "2023-10-24T13:17:40Z",
            "summary": "The surge in popularity of large language models has given rise to concerns\nabout biases that these models could learn from humans. In this study, we\ninvestigate whether ingroup solidarity and outgroup hostility, fundamental\nsocial biases known from social science, are present in 51 large language\nmodels. We find that almost all foundational language models and some\ninstruction fine-tuned models exhibit clear ingroup-positive and\noutgroup-negative biases when prompted to complete sentences (e.g., \"We\nare...\"). A comparison of LLM-generated sentences with human-written sentences\non the internet reveals that these models exhibit similar level, if not\ngreater, levels of bias than human text. To investigate where these biases stem\nfrom, we experimentally varied the amount of ingroup-positive or\noutgroup-negative sentences the model was exposed to during fine-tuning in the\ncontext of the United States Democrat-Republican divide. Doing so resulted in\nthe models exhibiting a marked increase in ingroup solidarity and an even\ngreater increase in outgroup hostility. Furthermore, removing either\ningroup-positive or outgroup-negative sentences (or both) from the fine-tuning\ndata leads to a significant reduction in both ingroup solidarity and outgroup\nhostility, suggesting that biases can be reduced by removing biased training\ndata. Our findings suggest that modern language models exhibit fundamental\nsocial identity biases and that such biases can be mitigated by curating\ntraining data. Our results have practical implications for creating less biased\nlarge-language models and further underscore the need for more research into\nuser interactions with LLMs to prevent potential bias reinforcement in humans.",
            "author": [
                "Tiancheng Hu",
                "Yara Kyrychenko",
                "Steve Rathje",
                "Nigel Collier",
                "Sander van der Linden",
                "Jon Roozenbeek"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15819v1",
                "http://arxiv.org/pdf/2310.15819v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15817v1",
            "title": "Discriminator Guidance for Autoregressive Diffusion Models",
            "updated": "2023-10-24T13:14:22Z",
            "published": "2023-10-24T13:14:22Z",
            "summary": "We introduce discriminator guidance in the setting of Autoregressive\nDiffusion Models. The use of a discriminator to guide a diffusion process has\npreviously been used for continuous diffusion models, and in this work we\nderive ways of using a discriminator together with a pretrained generative\nmodel in the discrete case. First, we show that using an optimal discriminator\nwill correct the pretrained model and enable exact sampling from the underlying\ndata distribution. Second, to account for the realistic scenario of using a\nsub-optimal discriminator, we derive a sequential Monte Carlo algorithm which\niteratively takes the predictions from the discrimiator into account during the\ngeneration process. We test these approaches on the task of generating\nmolecular graphs and show how the discriminator improves the generative\nperformance over using only the pretrained model.",
            "author": [
                "Filip Ekstr\u00f6m Kelvinius",
                "Fredrik Lindsten"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15817v1",
                "http://arxiv.org/pdf/2310.15817v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15816v1",
            "title": "Nonlinear dimensionality reduction then and now: AIMs for dissipative\n  PDEs in the ML era",
            "updated": "2023-10-24T13:10:43Z",
            "published": "2023-10-24T13:10:43Z",
            "summary": "This study presents a collection of purely data-driven workflows for\nconstructing reduced-order models (ROMs) for distributed dynamical systems. The\nROMs we focus on, are data-assisted models inspired by, and templated upon, the\ntheory of Approximate Inertial Manifolds (AIMs); the particular motivation is\nthe so-called post-processing Galerkin method of Garcia-Archilla, Novo and\nTiti. Its applicability can be extended: the need for accurate truncated\nGalerkin projections and for deriving closed-formed corrections can be\ncircumvented using machine learning tools. When the right latent variables are\nnot a priori known, we illustrate how autoencoders as well as Diffusion Maps (a\nmanifold learning scheme) can be used to discover good sets of latent variables\nand test their explainability. The proposed methodology can express the ROMs in\nterms of (a) theoretical (Fourier coefficients), (b) linear data-driven (POD\nmodes) and/or (c) nonlinear data-driven (Diffusion Maps) coordinates. Both\nBlack-Box and (theoretically-informed and data-corrected) Gray-Box models are\ndescribed; the necessity for the latter arises when truncated Galerkin\nprojections are so inaccurate as to not be amenable to post-processing. We use\nthe Chafee-Infante reaction-diffusion and the Kuramoto-Sivashinsky dissipative\npartial differential equations to illustrate and successfully test the overall\nframework.",
            "author": [
                "Eleni D. Koronaki",
                "Nikolaos Evangelou",
                "Cristina P. Martin-Linares",
                "Edriss S. Titi",
                "Ioannis G. Kevrekidis"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15816v1",
                "http://arxiv.org/pdf/2310.15816v1"
            ],
            "primary_category": "math.DS",
            "category": [
                "math.DS",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15815v1",
            "title": "Good Better Best: Self-Motivated Imitation Learning for noisy\n  Demonstrations",
            "updated": "2023-10-24T13:09:56Z",
            "published": "2023-10-24T13:09:56Z",
            "summary": "Imitation Learning (IL) aims to discover a policy by minimizing the\ndiscrepancy between the agent's behavior and expert demonstrations. However, IL\nis susceptible to limitations imposed by noisy demonstrations from non-expert\nbehaviors, presenting a significant challenge due to the lack of supplementary\ninformation to assess their expertise. In this paper, we introduce\nSelf-Motivated Imitation LEarning (SMILE), a method capable of progressively\nfiltering out demonstrations collected by policies deemed inferior to the\ncurrent policy, eliminating the need for additional information. We utilize the\nforward and reverse processes of Diffusion Models to emulate the shift in\ndemonstration expertise from low to high and vice versa, thereby extracting the\nnoise information that diffuses expertise. Then, the noise information is\nleveraged to predict the diffusion steps between the current policy and\ndemonstrators, which we theoretically demonstrate its equivalence to their\nexpertise gap. We further explain in detail how the predicted diffusion steps\nare applied to filter out noisy demonstrations in a self-motivated manner and\nprovide its theoretical grounds. Through empirical evaluations on MuJoCo tasks,\nwe demonstrate that our method is proficient in learning the expert policy\namidst noisy demonstrations, and effectively filters out demonstrations with\nexpertise inferior to the current policy.",
            "author": [
                "Ye Yuan",
                "Xin Li",
                "Yong Heng",
                "Leiji Zhang",
                "MingZhong Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15815v1",
                "http://arxiv.org/pdf/2310.15815v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15797v1",
            "title": "Random Entity Quantization for Parameter-Efficient Compositional\n  Knowledge Graph Representation",
            "updated": "2023-10-24T12:48:52Z",
            "published": "2023-10-24T12:48:52Z",
            "summary": "Representation Learning on Knowledge Graphs (KGs) is essential for downstream\ntasks. The dominant approach, KG Embedding (KGE), represents entities with\nindependent vectors and faces the scalability challenge. Recent studies propose\nan alternative way for parameter efficiency, which represents entities by\ncomposing entity-corresponding codewords matched from predefined small-scale\ncodebooks. We refer to the process of obtaining corresponding codewords of each\nentity as entity quantization, for which previous works have designed\ncomplicated strategies. Surprisingly, this paper shows that simple random\nentity quantization can achieve similar results to current strategies. We\nanalyze this phenomenon and reveal that entity codes, the quantization outcomes\nfor expressing entities, have higher entropy at the code level and Jaccard\ndistance at the codeword level under random entity quantization. Therefore,\ndifferent entities become more easily distinguished, facilitating effective KG\nrepresentation. The above results show that current quantization strategies are\nnot critical for KG representation, and there is still room for improvement in\nentity distinguishability beyond current strategies. The code to reproduce our\nresults is available at https://github.com/JiaangL/RandomQuantization.",
            "author": [
                "Jiaang Li",
                "Quan Wang",
                "Yi Liu",
                "Licheng Zhang",
                "Zhendong Mao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15797v1",
                "http://arxiv.org/pdf/2310.15797v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15793v1",
            "title": "Improving generalization in large language models by learning prefix\n  subspaces",
            "updated": "2023-10-24T12:44:09Z",
            "published": "2023-10-24T12:44:09Z",
            "summary": "This article focuses on large language models (LLMs) fine-tuning in the\nscarce data regime (also known as the \"few-shot\" learning setting). We propose\na method to increase the generalization capabilities of LLMs based on neural\nnetwork subspaces. This optimization method, recently introduced in computer\nvision, aims to improve model generalization by identifying wider local optima\nthrough the joint optimization of an entire simplex of models in parameter\nspace. Its adaptation to massive, pretrained transformers, however, poses some\nchallenges. First, their considerable number of parameters makes it difficult\nto train several models jointly, and second, their deterministic parameter\ninitialization schemes make them unfit for the subspace method as originally\nproposed. We show in this paper that \"Parameter Efficient Fine-Tuning\" (PEFT)\nmethods, however, are perfectly compatible with this original approach, and\npropose to learn entire simplex of continuous prefixes. We test our method on a\nvariant of the GLUE benchmark adapted to the few-shot learning setting, and\nshow that both our contributions jointly lead to a gain in average performances\ncompared to sota methods. The implementation can be found at the following\nlink: https://github.com/Liloulou/prefix_subspace",
            "author": [
                "Louis Falissard",
                "Vincent Guigue",
                "Laure Soulier"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15793v1",
                "http://arxiv.org/pdf/2310.15793v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15788v1",
            "title": "qPOTS: Efficient batch multiobjective Bayesian optimization via Pareto\n  optimal Thompson sampling",
            "updated": "2023-10-24T12:35:15Z",
            "published": "2023-10-24T12:35:15Z",
            "summary": "Classical evolutionary approaches for multiobjective optimization are quite\neffective but incur a lot of queries to the objectives; this can be prohibitive\nwhen objectives are expensive oracles. A sample-efficient approach to solving\nmultiobjective optimization is via Gaussian process (GP) surrogates and\nBayesian optimization (BO). Multiobjective Bayesian optimization (MOBO)\ninvolves the construction of an acquisition function which is optimized to\nacquire new observation candidates. This ``inner'' optimization can be hard due\nto various reasons: acquisition functions being nonconvex, nondifferentiable\nand/or unavailable in analytical form; the success of MOBO heavily relies on\nthis inner optimization. We do away with this hard acquisition function\noptimization step and propose a simple, but effective, Thompson sampling based\napproach ($q\\texttt{POTS}$) where new candidate(s) are chosen from the Pareto\nfrontier of random GP posterior sample paths obtained by solving a much cheaper\nmultiobjective optimization problem. To further improve computational\ntractability in higher dimensions we propose an automated active set of\ncandidates selection combined with a Nystr\\\"{o}m approximation. Our approach\napplies to arbitrary GP prior assumptions and demonstrates strong empirical\nperformance over the state of the art, both in terms of accuracy and\ncomputational efficiency, on synthetic as well as real-world experiments.",
            "author": [
                "S. Ashwin Renganathan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15788v1",
                "http://arxiv.org/pdf/2310.15788v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15787v1",
            "title": "SequenceMatch: Revisiting the design of weak-strong augmentations for\n  Semi-supervised learning",
            "updated": "2023-10-24T12:34:58Z",
            "published": "2023-10-24T12:34:58Z",
            "summary": "Semi-supervised learning (SSL) has become popular in recent years because it\nallows the training of a model using a large amount of unlabeled data. However,\none issue that many SSL methods face is the confirmation bias, which occurs\nwhen the model is overfitted to the small labeled training dataset and produces\noverconfident, incorrect predictions. To address this issue, we propose\nSequenceMatch, an efficient SSL method that utilizes multiple data\naugmentations. The key element of SequenceMatch is the inclusion of a medium\naugmentation for unlabeled data. By taking advantage of different augmentations\nand the consistency constraints between each pair of augmented examples,\nSequenceMatch helps reduce the divergence between the prediction distribution\nof the model for weakly and strongly augmented examples. In addition,\nSequenceMatch defines two different consistency constraints for high and\nlow-confidence predictions. As a result, SequenceMatch is more data-efficient\nthan ReMixMatch, and more time-efficient than both ReMixMatch ($\\times4$) and\nCoMatch ($\\times2$) while having higher accuracy. Despite its simplicity,\nSequenceMatch consistently outperforms prior methods on standard benchmarks,\nsuch as CIFAR-10/100, SVHN, and STL-10. It also surpasses prior\nstate-of-the-art methods by a large margin on large-scale datasets such as\nImageNet, with a 38.46\\% error rate. Code is available at\nhttps://github.com/beandkay/SequenceMatch.",
            "author": [
                "Khanh-Binh Nguyen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15787v1",
                "http://arxiv.org/pdf/2310.15787v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15786v1",
            "title": "Amortised Inference in Neural Networks for Small-Scale Probabilistic\n  Meta-Learning",
            "updated": "2023-10-24T12:34:25Z",
            "published": "2023-10-24T12:34:25Z",
            "summary": "The global inducing point variational approximation for BNNs is based on\nusing a set of inducing inputs to construct a series of conditional\ndistributions that accurately approximate the conditionals of the true\nposterior distribution. Our key insight is that these inducing inputs can be\nreplaced by the actual data, such that the variational distribution consists of\na set of approximate likelihoods for each datapoint. This structure lends\nitself to amortised inference, in which the parameters of each approximate\nlikelihood are obtained by passing each datapoint through a meta-model known as\nthe inference network. By training this inference network across related\ndatasets, we can meta-learn Bayesian inference over task-specific BNNs.",
            "author": [
                "Matthew Ashman",
                "Tommy Rochussen",
                "Adrian Weller"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15786v1",
                "http://arxiv.org/pdf/2310.15786v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15780v1",
            "title": "Make LLM a Testing Expert: Bringing Human-like Interaction to Mobile GUI\n  Testing via Functionality-aware Decisions",
            "updated": "2023-10-24T12:30:26Z",
            "published": "2023-10-24T12:30:26Z",
            "summary": "Automated Graphical User Interface (GUI) testing plays a crucial role in\nensuring app quality, especially as mobile applications have become an integral\npart of our daily lives. Despite the growing popularity of learning-based\ntechniques in automated GUI testing due to their ability to generate human-like\ninteractions, they still suffer from several limitations, such as low testing\ncoverage, inadequate generalization capabilities, and heavy reliance on\ntraining data. Inspired by the success of Large Language Models (LLMs) like\nChatGPT in natural language understanding and question answering, we formulate\nthe mobile GUI testing problem as a Q&A task. We propose GPTDroid, asking LLM\nto chat with the mobile apps by passing the GUI page information to LLM to\nelicit testing scripts, and executing them to keep passing the app feedback to\nLLM, iterating the whole process. Within this framework, we have also\nintroduced a functionality-aware memory prompting mechanism that equips the LLM\nwith the ability to retain testing knowledge of the whole process and conduct\nlong-term, functionality-based reasoning to guide exploration. We evaluate it\non 93 apps from Google Play and demonstrate that it outperforms the best\nbaseline by 32% in activity coverage, and detects 31% more bugs at a faster\nrate. Moreover, GPTDroid identify 53 new bugs on Google Play, of which 35 have\nbeen confirmed and fixed.",
            "author": [
                "Zhe Liu",
                "Chunyang Chen",
                "Junjie Wang",
                "Mengzhuo Chen",
                "Boyu Wu",
                "Xing Che",
                "Dandan Wang",
                "Qing Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15780v1",
                "http://arxiv.org/pdf/2310.15780v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15771v1",
            "title": "Control problems on infinite horizon subject to time-dependent pure\n  state constraints",
            "updated": "2023-10-24T12:17:23Z",
            "published": "2023-10-24T12:17:23Z",
            "summary": "In the last decades, control problems with infinite horizons and discount\nfactors have become increasingly central not only for economics but also for\napplications in artificial intelligence and machine learning. The strong links\nbetween reinforcement learning and control theory have led to major efforts\ntowards the development of algorithms to learn how to solve constrained control\nproblems. In particular, discount plays a role in addressing the challenges\nthat come with models that have unbounded disturbances. Although algorithms\nhave been extensively explored, few results take into account time-dependent\nstate constraints, which are imposed in most real-world control applications.\nFor this purpose, here we investigate feasibility and sufficient conditions for\nLipschitz regularity of the value function for a class of discounted infinite\nhorizon optimal control problems subject to time-dependent constraints. We\nfocus on problems with data that allow nonautonomous dynamics, and Lagrangian\nand state constraints that can be unbounded with possibly nonsmooth boundaries.",
            "author": [
                "Vincenzo Basco"
            ],
            "link": [
                "http://dx.doi.org/10.1007/s00498-023-00372-3",
                "http://arxiv.org/abs/2310.15771v1",
                "http://arxiv.org/pdf/2310.15771v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15767v2",
            "title": "Unpaired MRI Super Resolution with Self-Supervised Contrastive Learning",
            "updated": "2023-11-09T10:40:54Z",
            "published": "2023-10-24T12:13:51Z",
            "summary": "High-resolution (HR) magnetic resonance imaging (MRI) is crucial for\nenhancing diagnostic accuracy in clinical settings. Nonetheless, the inherent\nlimitation of MRI resolution restricts its widespread applicability. Deep\nlearning-based image super-resolution (SR) methods exhibit promise in improving\nMRI resolution without additional cost. However, these methods frequently\nrequire a substantial number of HR MRI images for training, which can be\nchallenging to acquire. In this paper, we propose an unpaired MRI SR approach\nthat employs self-supervised contrastive learning to enhance SR performance\nwith limited training data. Our approach leverages both authentic HR images and\nsynthetically generated SR images to construct positive and negative sample\npairs, thus facilitating the learning of discriminative features. Empirical\nresults presented in this study underscore significant enhancements in the peak\nsignal-to-noise ratio and structural similarity index, even when a paucity of\nHR images is available. These findings accentuate the potential of our approach\nin addressing the challenge of limited training data, thereby contributing to\nthe advancement of high-resolution MRI in clinical applications.",
            "author": [
                "Hao Li",
                "Quanwei Liu",
                "Jianan Liu",
                "Xiling Liu",
                "Yanni Dong",
                "Tao Huang",
                "Zhihan Lv"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15767v2",
                "http://arxiv.org/pdf/2310.15767v2"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15766v1",
            "title": "Robust Learning via Conditional Prevalence Adjustment",
            "updated": "2023-10-24T12:13:49Z",
            "published": "2023-10-24T12:13:49Z",
            "summary": "Healthcare data often come from multiple sites in which the correlations\nbetween confounding variables can vary widely. If deep learning models exploit\nthese unstable correlations, they might fail catastrophically in unseen sites.\nAlthough many methods have been proposed to tackle unstable correlations, each\nhas its limitations. For example, adversarial training forces models to\ncompletely ignore unstable correlations, but doing so may lead to poor\npredictive performance. Other methods (e.g. Invariant risk minimization [4])\ntry to learn domain-invariant representations that rely only on stable\nassociations by assuming a causal data-generating process (input X causes class\nlabel Y ). Thus, they may be ineffective for anti-causal tasks (Y causes X),\nwhich are common in computer vision. We propose a method called CoPA\n(Conditional Prevalence-Adjustment) for anti-causal tasks. CoPA assumes that\n(1) generation mechanism is stable, i.e. label Y and confounding variable(s) Z\ngenerate X, and (2) the unstable conditional prevalence in each site E fully\naccounts for the unstable correlations between X and Y . Our crucial\nobservation is that confounding variables are routinely recorded in healthcare\nsettings and the prevalence can be readily estimated, for example, from a set\nof (Y, Z) samples (no need for corresponding samples of X). CoPA can work even\nif there is a single training site, a scenario which is often overlooked by\nexisting methods. Our experiments on synthetic and real data show CoPA beating\ncompetitive baselines.",
            "author": [
                "Minh Nguyen",
                "Alan Q. Wang",
                "Heejong Kim",
                "Mert R. Sabuncu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15766v1",
                "http://arxiv.org/pdf/2310.15766v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15764v1",
            "title": "Debiasing, calibrating, and improving Semi-supervised Learning\n  performance via simple Ensemble Projector",
            "updated": "2023-10-24T12:11:19Z",
            "published": "2023-10-24T12:11:19Z",
            "summary": "Recent studies on semi-supervised learning (SSL) have achieved great success.\nDespite their promising performance, current state-of-the-art methods tend\ntoward increasingly complex designs at the cost of introducing more network\ncomponents and additional training procedures. In this paper, we propose a\nsimple method named Ensemble Projectors Aided for Semi-supervised Learning\n(EPASS), which focuses mainly on improving the learned embeddings to boost the\nperformance of the existing contrastive joint-training semi-supervised learning\nframeworks. Unlike standard methods, where the learned embeddings from one\nprojector are stored in memory banks to be used with contrastive learning,\nEPASS stores the ensemble embeddings from multiple projectors in memory banks.\nAs a result, EPASS improves generalization, strengthens feature representation,\nand boosts performance. For instance, EPASS improves strong baselines for\nsemi-supervised learning by 39.47\\%/31.39\\%/24.70\\% top-1 error rate, while\nusing only 100k/1\\%/10\\% of labeled data for SimMatch, and achieves\n40.24\\%/32.64\\%/25.90\\% top-1 error rate for CoMatch on the ImageNet dataset.\nThese improvements are consistent across methods, network architectures, and\ndatasets, proving the general effectiveness of the proposed methods. Code is\navailable at https://github.com/beandkay/EPASS.",
            "author": [
                "Khanh-Binh Nguyen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15764v1",
                "http://arxiv.org/pdf/2310.15764v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15758v1",
            "title": "Learning From Free-Text Human Feedback -- Collect New Datasets Or Extend\n  Existing Ones?",
            "updated": "2023-10-24T12:01:11Z",
            "published": "2023-10-24T12:01:11Z",
            "summary": "Learning from free-text human feedback is essential for dialog systems, but\nannotated data is scarce and usually covers only a small fraction of error\ntypes known in conversational AI. Instead of collecting and annotating new\ndatasets from scratch, recent advances in synthetic dialog generation could be\nused to augment existing dialog datasets with the necessary annotations.\nHowever, to assess the feasibility of such an effort, it is important to know\nthe types and frequency of free-text human feedback included in these datasets.\nIn this work, we investigate this question for a variety of commonly used\ndialog datasets, including MultiWoZ, SGD, BABI, PersonaChat,\nWizards-of-Wikipedia, and the human-bot split of the Self-Feeding Chatbot.\nUsing our observations, we derive new taxonomies for the annotation of\nfree-text human feedback in dialogs and investigate the impact of including\nsuch data in response generation for three SOTA language generation models,\nincluding GPT-2, LLAMA, and Flan-T5. Our findings provide new insights into the\ncomposition of the datasets examined, including error types, user response\ntypes, and the relations between them.",
            "author": [
                "Dominic Petrak",
                "Nafise Sadat Moosavi",
                "Ye Tian",
                "Nikolai Rozanov",
                "Iryna Gurevych"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15758v1",
                "http://arxiv.org/pdf/2310.15758v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15753v1",
            "title": "Efficient CPU-Optimized Parameter Estimation for Modeling Fish Schooling\n  Behavior in Large Particle Systems",
            "updated": "2023-10-24T11:56:13Z",
            "published": "2023-10-24T11:56:13Z",
            "summary": "The schooling behavior of fish can be studied through simulations involving a\nlarge number of interacting particles. In such systems, each individual\nparticle is guided by behavior rules, which include aggregation towards a\ncentroid, collision avoidance, and direction alignment. The movement vector of\neach particle may be expressed as a linear combination of behaviors, with\nunknown parameters that define a trade-off among several behavioral\nconstraints. A fitness function for collective schooling behavior encompasses\nall individual particle parameters.\n  For a large number of interacting particles in a complex environment,\nheuristic methods, such as evolutionary algorithms, are used to optimize the\nfitness function, ensuring that the resulting decision rule preserves\ncollective behavior. However, these algorithms exhibit slow convergence, making\nthem inefficient in terms of CPU time cost.\n  This paper proposes a CPU-efficient iterative (Cluster, Partition, Refine --\nCPR) algorithm for estimating decision rule parameters for a large number of\ninteracting particles. In the first step, we employ the K-Means (unsupervised\nlearning) algorithm to cluster candidate solutions. Then, we partition the\nsearch space using Voronoi tessellation over the defined clusters. We assess\nthe quality of each cluster based on the fitness function, with the centroid of\ntheir Voronoi cells representing the clusters. Subsequently, we refine the\nsearch space by introducing new cells into a number of identified well-fitting\nVoronoi cells. This process is repeated until convergence.\n  A comparison of the performance of the CPR algorithm with a standard Genetic\nAlgorithm reveals that the former converges faster than the latter. We also\ndemonstrate that the application of the CPR algorithm results in a schooling\nbehavior consistent with empirical observations.",
            "author": [
                "S. Arabeei",
                "S. Subbey"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15753v1",
                "http://arxiv.org/pdf/2310.15753v1"
            ],
            "primary_category": "q-bio.PE",
            "category": [
                "q-bio.PE",
                "92D40, 92C20, 65K05, 68T05",
                "G.1.6; G.4; I.2.8; I.6.5; J.3; D.2.8"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15752v1",
            "title": "Integrating Language Models into Direct Speech Translation: An\n  Inference-Time Solution to Control Gender Inflection",
            "updated": "2023-10-24T11:55:16Z",
            "published": "2023-10-24T11:55:16Z",
            "summary": "When translating words referring to the speaker, speech translation (ST)\nsystems should not resort to default masculine generics nor rely on potentially\nmisleading vocal traits. Rather, they should assign gender according to the\nspeakers' preference. The existing solutions to do so, though effective, are\nhardly feasible in practice as they involve dedicated model re-training on\ngender-labeled ST data. To overcome these limitations, we propose the first\ninference-time solution to control speaker-related gender inflections in ST.\nOur approach partially replaces the (biased) internal language model (LM)\nimplicitly learned by the ST decoder with gender-specific external LMs.\nExperiments on en->es/fr/it show that our solution outperforms the base models\nand the best training-time mitigation strategy by up to 31.0 and 1.6 points in\ngender accuracy, respectively, for feminine forms. The gains are even larger\n(up to 32.0 and 3.4) in the challenging condition where speakers' vocal traits\nconflict with their gender.",
            "author": [
                "Dennis Fucci",
                "Marco Gaido",
                "Sara Papi",
                "Mauro Cettolo",
                "Matteo Negri",
                "Luisa Bentivogli"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15752v1",
                "http://arxiv.org/pdf/2310.15752v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16851v1",
            "title": "Deep Learning Models for Classification of COVID-19 Cases by Medical\n  Images",
            "updated": "2023-10-24T11:48:40Z",
            "published": "2023-10-24T11:48:40Z",
            "summary": "In recent times, the use of chest Computed Tomography (CT) images for\ndetecting coronavirus infections has gained significant attention, owing to\ntheir ability to reveal bilateral changes in affected individuals. However,\nclassifying patients from medical images presents a formidable challenge,\nparticularly in identifying such bilateral changes. To tackle this challenge,\nour study harnesses the power of deep learning models for the precise\nclassification of infected patients. Our research involves a comparative\nanalysis of deep transfer learning-based classification models, including\nDenseNet201, GoogleNet, and AlexNet, against carefully chosen supervised\nlearning models. Additionally, our work encompasses Covid-19 classification,\nwhich involves the identification and differentiation of medical images, such\nas X-rays and electrocardiograms, that exhibit telltale signs of Covid-19\ninfection. This comprehensive approach ensures that our models can handle a\nwide range of medical image types and effectively identify characteristic\npatterns indicative of Covid-19. By conducting meticulous research and\nemploying advanced deep learning techniques, we have made significant strides\nin enhancing the accuracy and speed of Covid-19 diagnosis. Our results\ndemonstrate the effectiveness of these models and their potential to make\nsubstantial contributions to the global effort to combat COVID-19.",
            "author": [
                "Amir Ali"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16851v1",
                "http://arxiv.org/pdf/2310.16851v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15746v1",
            "title": "Failures Pave the Way: Enhancing Large Language Models through\n  Tuning-free Rule Accumulation",
            "updated": "2023-10-24T11:40:34Z",
            "published": "2023-10-24T11:40:34Z",
            "summary": "Large Language Models (LLMs) have showcased impressive performance. However,\ndue to their inability to capture relationships among samples, these frozen\nLLMs inevitably keep repeating similar mistakes. In this work, we propose our\nTuning-free Rule Accumulation (TRAN) framework, which guides LLMs in improving\ntheir performance by learning from previous mistakes. Considering data arrives\nsequentially, LLMs gradually accumulate rules from incorrect cases, forming a\nrule collection. These rules are then utilized by the LLMs to avoid making\nsimilar mistakes when processing subsequent inputs. Moreover, the rules remain\nindependent of the primary prompts, seamlessly complementing prompt design\nstrategies. Experimentally, we show that TRAN improves over recent baselines by\na large margin.",
            "author": [
                "Zeyuan Yang",
                "Peng Li",
                "Yang Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15746v1",
                "http://arxiv.org/pdf/2310.15746v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15744v1",
            "title": "Analyzing Single Cell RNA Sequencing with Topological Nonnegative Matrix\n  Factorization",
            "updated": "2023-10-24T11:36:41Z",
            "published": "2023-10-24T11:36:41Z",
            "summary": "Single-cell RNA sequencing (scRNA-seq) is a relatively new technology that\nhas stimulated enormous interest in statistics, data science, and computational\nbiology due to the high dimensionality, complexity, and large scale associated\nwith scRNA-seq data. Nonnegative matrix factorization (NMF) offers a unique\napproach due to its meta-gene interpretation of resulting low-dimensional\ncomponents. However, NMF approaches suffer from the lack of multiscale\nanalysis. This work introduces two persistent Laplacian regularized NMF\nmethods, namely, topological NMF (TNMF) and robust topological NMF (rTNMF). By\nemploying a total of 12 datasets, we demonstrate that the proposed TNMF and\nrTNMF significantly outperform all other NMF-based methods. We have also\nutilized TNMF and rTNMF for the visualization of popular Uniform Manifold\nApproximation and Projection (UMAP) and t-distributed stochastic neighbor\nembedding (t-SNE).",
            "author": [
                "Yuta Hozumi",
                "Guo-Wei Wei"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15744v1",
                "http://arxiv.org/pdf/2310.15744v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "math.AT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15743v1",
            "title": "RAPL: A Relation-Aware Prototype Learning Approach for Few-Shot\n  Document-Level Relation Extraction",
            "updated": "2023-10-24T11:35:23Z",
            "published": "2023-10-24T11:35:23Z",
            "summary": "How to identify semantic relations among entities in a document when only a\nfew labeled documents are available? Few-shot document-level relation\nextraction (FSDLRE) is crucial for addressing the pervasive data scarcity\nproblem in real-world scenarios. Metric-based meta-learning is an effective\nframework widely adopted for FSDLRE, which constructs class prototypes for\nclassification. However, existing works often struggle to obtain class\nprototypes with accurate relational semantics: 1) To build prototype for a\ntarget relation type, they aggregate the representations of all entity pairs\nholding that relation, while these entity pairs may also hold other relations,\nthus disturbing the prototype. 2) They use a set of generic NOTA\n(none-of-the-above) prototypes across all tasks, neglecting that the NOTA\nsemantics differs in tasks with different target relation types. In this paper,\nwe propose a relation-aware prototype learning method for FSDLRE to strengthen\nthe relational semantics of prototype representations. By judiciously\nleveraging the relation descriptions and realistic NOTA instances as guidance,\nour method effectively refines the relation prototypes and generates\ntask-specific NOTA prototypes. Extensive experiments demonstrate that our\nmethod outperforms state-of-the-art approaches by average 2.61% $F_1$ across\nvarious settings of two FSDLRE benchmarks.",
            "author": [
                "Shiao Meng",
                "Xuming Hu",
                "Aiwei Liu",
                "Shu'ang Li",
                "Fukun Ma",
                "Yawen Yang",
                "Lijie Wen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15743v1",
                "http://arxiv.org/pdf/2310.15743v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "68T50",
                "I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15742v2",
            "title": "Improving Diffusion Models for ECG Imputation with an Augmented Template\n  Prior",
            "updated": "2023-11-14T12:02:43Z",
            "published": "2023-10-24T11:34:15Z",
            "summary": "Pulsative signals such as the electrocardiogram (ECG) are extensively\ncollected as part of routine clinical care. However, noisy and poor-quality\nrecordings are a major issue for signals collected using mobile health systems,\ndecreasing the signal quality, leading to missing values, and affecting\nautomated downstream tasks. Recent studies have explored the imputation of\nmissing values in ECG with probabilistic time-series models. Nevertheless, in\ncomparison with the deterministic models, their performance is still limited,\nas the variations across subjects and heart-beat relationships are not\nexplicitly considered in the training objective. In this work, to improve the\nimputation and forecasting accuracy for ECG with probabilistic models, we\npresent a template-guided denoising diffusion probabilistic model (DDPM),\nPulseDiff, which is conditioned on an informative prior for a range of health\nconditions. Specifically, 1) we first extract a subject-level pulsative\ntemplate from the observed values to use as an informative prior of the missing\nvalues, which personalises the prior; 2) we then add beat-level stochastic\nshift terms to augment the prior, which considers variations in the position\nand amplitude of the prior at each beat; 3) we finally design a confidence\nscore to consider the health condition of the subject, which ensures our prior\nis provided safely. Experiments with the PTBXL dataset reveal that PulseDiff\nimproves the performance of two strong DDPM baseline models, CSDI and\nSSSD$^{S4}$, verifying that our method guides the generation of DDPMs while\nmanaging the uncertainty. When combined with SSSD$^{S4}$, PulseDiff outperforms\nthe leading deterministic model for short-interval missing data and is\ncomparable for long-interval data loss.",
            "author": [
                "Alexander Jenkins",
                "Zehua Chen",
                "Fu Siong Ng",
                "Danilo Mandic"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15742v2",
                "http://arxiv.org/pdf/2310.15742v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16065v1",
            "title": "The Hyperdimensional Transform: a Holographic Representation of\n  Functions",
            "updated": "2023-10-24T11:33:39Z",
            "published": "2023-10-24T11:33:39Z",
            "summary": "Integral transforms are invaluable mathematical tools to map functions into\nspaces where they are easier to characterize. We introduce the hyperdimensional\ntransform as a new kind of integral transform. It converts square-integrable\nfunctions into noise-robust, holographic, high-dimensional representations\ncalled hyperdimensional vectors. The central idea is to approximate a function\nby a linear combination of random functions. We formally introduce a set of\nstochastic, orthogonal basis functions and define the hyperdimensional\ntransform and its inverse. We discuss general transform-related properties such\nas its uniqueness, approximation properties of the inverse transform, and the\nrepresentation of integrals and derivatives. The hyperdimensional transform\noffers a powerful, flexible framework that connects closely with other integral\ntransforms, such as the Fourier, Laplace, and fuzzy transforms. Moreover, it\nprovides theoretical foundations and new insights for the field of\nhyperdimensional computing, a computing paradigm that is rapidly gaining\nattention for efficient and explainable machine learning algorithms, with\npotential applications in statistical modelling and machine learning. In\naddition, we provide straightforward and easily understandable code, which can\nfunction as a tutorial and allows for the reproduction of the demonstrated\nexamples, from computing the transform to solving differential equations.",
            "author": [
                "Pieter Dewulf",
                "Michiel Stock",
                "Bernard De Baets"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16065v1",
                "http://arxiv.org/pdf/2310.16065v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15741v1",
            "title": "Interpretable Medical Image Classification using Prototype Learning and\n  Privileged Information",
            "updated": "2023-10-24T11:28:59Z",
            "published": "2023-10-24T11:28:59Z",
            "summary": "Interpretability is often an essential requirement in medical imaging.\nAdvanced deep learning methods are required to address this need for\nexplainability and high performance. In this work, we investigate whether\nadditional information available during the training process can be used to\ncreate an understandable and powerful model. We propose an innovative solution\ncalled Proto-Caps that leverages the benefits of capsule networks, prototype\nlearning and the use of privileged information. Evaluating the proposed\nsolution on the LIDC-IDRI dataset shows that it combines increased\ninterpretability with above state-of-the-art prediction performance. Compared\nto the explainable baseline model, our method achieves more than 6 % higher\naccuracy in predicting both malignancy (93.0 %) and mean characteristic\nfeatures of lung nodules. Simultaneously, the model provides case-based\nreasoning with prototype representations that allow visual validation of\nradiologist-defined attributes.",
            "author": [
                "Luisa Gallee",
                "Meinrad Beer",
                "Michael Goetz"
            ],
            "link": [
                "http://dx.doi.org/10.1007/978-3-031-43895-0_41",
                "http://arxiv.org/abs/2310.15741v1",
                "http://arxiv.org/pdf/2310.15741v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15723v1",
            "title": "Data Processing Engine (DPE): Data Analysis Tool for Particle Tracking\n  and Mixed Radiation Field Characterization with Pixel Detectors Timepix",
            "updated": "2023-10-24T10:59:43Z",
            "published": "2023-10-24T10:59:43Z",
            "summary": "Hybrid semiconductor pixelated detectors from the Timepix family are advanced\ndetectors for online particle tracking, offering energy measurement and precise\ntime stamping capabilities for particles of various types and energies. This\ninherent capability makes them highly suitable for various applications,\nincluding imaging, medical fields such as radiotherapy and particle therapy,\nspace-based applications aboard satellites and the International Space Station,\nand industrial applications. The data generated by these detectors is complex,\nnecessitating the development and deployment of various analytical techniques\nto extract essential information. For this purpose, and to aid the Timepix user\ncommunity, it was designed and developed the \"Data Processing Engine\" (DPE) as\nan advanced tool for data processing designed explicitly for Timepix detectors.\nThe functionality of the DPE is structured into three distinct processing\nlevels: i) Pre-processing: This phase involves clusterization and the\napplication of necessary calibrations and corrections. ii) Processing: This\nstage includes particle classification, employing machine learning algorithms,\nand the recognition of radiation fields. iii) Post-processing: Involves various\nanalyses, such as directional analysis, coincidence analysis, frame analysis,\nCompton directional analysis, and the generation of physics products, are\nperformed. The core of the DPE is supported by an extensive experimental\ndatabase containing calibrations and referential radiation fields of typical\nenvironments, including protons, ions, electrons, gamma rays and X-rays, as\nwell as thermal and fast neutrons. To enhance accessibility, the DPE is\nimplemented into various user interface platforms such as a command-line tool,\nan application programming interface, and as a graphical user interface in the\nform of a web portal.",
            "author": [
                "Marek Lukas",
                "Granja Carlos",
                "Jakubek Jan",
                "Ingerle Jan",
                "Turecek Daniel",
                "Vuolo Marco",
                "Oancea Cristina"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15723v1",
                "http://arxiv.org/pdf/2310.15723v1"
            ],
            "primary_category": "physics.med-ph",
            "category": [
                "physics.med-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15722v1",
            "title": "Re-Temp: Relation-Aware Temporal Representation Learning for Temporal\n  Knowledge Graph Completion",
            "updated": "2023-10-24T10:58:33Z",
            "published": "2023-10-24T10:58:33Z",
            "summary": "Temporal Knowledge Graph Completion (TKGC) under the extrapolation setting\naims to predict the missing entity from a fact in the future, posing a\nchallenge that aligns more closely with real-world prediction problems.\nExisting research mostly encodes entities and relations using sequential graph\nneural networks applied to recent snapshots. However, these approaches tend to\noverlook the ability to skip irrelevant snapshots according to entity-related\nrelations in the query and disregard the importance of explicit temporal\ninformation. To address this, we propose our model, Re-Temp (Relation-Aware\nTemporal Representation Learning), which leverages explicit temporal embedding\nas input and incorporates skip information flow after each timestamp to skip\nunnecessary information for prediction. Additionally, we introduce a two-phase\nforward propagation method to prevent information leakage. Through the\nevaluation on six TKGC (extrapolation) datasets, we demonstrate that our model\noutperforms all eight recent state-of-the-art models by a significant margin.",
            "author": [
                "Kunze Wang",
                "Soyeon Caren Han",
                "Josiah Poon"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15722v1",
                "http://arxiv.org/pdf/2310.15722v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15720v2",
            "title": "Ensemble of Task-Specific Language Models for Brain Encoding",
            "updated": "2023-11-09T07:03:54Z",
            "published": "2023-10-24T10:52:41Z",
            "summary": "Language models have been shown to be rich enough to encode fMRI activations\nof certain Regions of Interest in our Brains. Previous works have explored\ntransfer learning from representations learned for popular natural language\nprocessing tasks for predicting brain responses. In our work, we improve the\nperformance of such encoders by creating an ensemble model out of 10 popular\nLanguage Models (2 syntactic and 8 semantic). We beat the current baselines by\n10% on average across all ROIs through our ensembling methods.",
            "author": [
                "Arvindh Arun",
                "Jerrin John",
                "Sanjai Kumaran"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15720v2",
                "http://arxiv.org/pdf/2310.15720v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15719v1",
            "title": "Recurrent Linear Transformers",
            "updated": "2023-10-24T10:51:50Z",
            "published": "2023-10-24T10:51:50Z",
            "summary": "The self-attention mechanism in the transformer architecture is capable of\ncapturing long-range dependencies and it is the main reason behind its\neffectiveness in processing sequential data. Nevertheless, despite their\nsuccess, transformers have two significant drawbacks that still limit their\nbroader applicability: (1) In order to remember past information, the\nself-attention mechanism requires access to the whole history to be provided as\ncontext. (2) The inference cost in transformers is expensive. In this paper we\nintroduce recurrent alternatives to the transformer self-attention mechanism\nthat offer a context-independent inference cost, leverage long-range\ndependencies effectively, and perform well in practice. We evaluate our\napproaches in reinforcement learning problems where the aforementioned\ncomputational limitations make the application of transformers nearly\ninfeasible. We quantify the impact of the different components of our\narchitecture in a diagnostic environment and assess performance gains in 2D and\n3D pixel-based partially-observable environments. When compared to a\nstate-of-the-art architecture, GTrXL, inference in our approach is at least 40%\ncheaper while reducing memory use in more than 50%. Our approach either\nperforms similarly or better than GTrXL, improving more than 37% upon GTrXL\nperformance on harder tasks.",
            "author": [
                "Subhojeet Pramanik",
                "Esraa Elelimy",
                "Marlos C. Machado",
                "Adam White"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15719v1",
                "http://arxiv.org/pdf/2310.15719v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15709v1",
            "title": "Causal Representation Learning Made Identifiable by Grouping of\n  Observational Variables",
            "updated": "2023-10-24T10:38:02Z",
            "published": "2023-10-24T10:38:02Z",
            "summary": "A topic of great current interest is Causal Representation Learning (CRL),\nwhose goal is to learn a causal model for hidden features in a data-driven\nmanner. Unfortunately, CRL is severely ill-posed since it is a combination of\nthe two notoriously ill-posed problems of representation learning and causal\ndiscovery. Yet, finding practical identifiability conditions that guarantee a\nunique solution is crucial for its practical applicability. Most approaches so\nfar have been based on assumptions on the latent causal mechanisms, such as\ntemporal causality, or existence of supervision or interventions; these can be\ntoo restrictive in actual applications. Here, we show identifiability based on\nnovel, weak constraints, which requires no temporal structure, intervention,\nnor weak supervision. The approach is based assuming the observational mixing\nexhibits a suitable grouping of the observational variables. We also propose a\nnovel self-supervised estimation framework consistent with the model, prove its\nstatistical consistency, and experimentally show its superior CRL performances\ncompared to the state-of-the-art baselines. We further demonstrate its\nrobustness against latent confounders and causal cycles.",
            "author": [
                "Hiroshi Morioka",
                "Aapo Hyv\u00e4rinen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15709v1",
                "http://arxiv.org/pdf/2310.15709v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10737v1",
            "title": "AI-enhanced Auto-correction of Programming Exercises: How Effective is\n  GPT-3.5?",
            "updated": "2023-10-24T10:35:36Z",
            "published": "2023-10-24T10:35:36Z",
            "summary": "Timely formative feedback is considered as one of the most important drivers\nfor effective learning. Delivering timely and individualized feedback is\nparticularly challenging in large classes in higher education. Recently Large\nLanguage Models such as GPT-3 became available to the public that showed\npromising results on various tasks such as code generation and code\nexplanation. This paper investigates the potential of AI in providing\npersonalized code correction and generating feedback. Based on existing student\nsubmissions of two different real-world assignments, the correctness of the\nAI-aided e-assessment as well as the characteristics such as fault\nlocalization, correctness of hints, and code style suggestions of the generated\nfeedback are investigated. The results show that 73 % of the submissions were\ncorrectly identified as either correct or incorrect. In 59 % of these cases,\nGPT-3.5 also successfully generated effective and high-quality feedback.\nAdditionally, GPT-3.5 exhibited weaknesses in its evaluation, including\nlocalization of errors that were not the actual errors, or even hallucinated\nerrors. Implications and potential new usage scenarios are discussed.",
            "author": [
                "Imen Azaiz",
                "Oliver Deckarm",
                "Sven Strickroth"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10737v1",
                "http://arxiv.org/pdf/2311.10737v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.AI",
                "cs.HC",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15706v1",
            "title": "Solving large flexible job shop scheduling instances by generating a\n  diverse set of scheduling policies with deep reinforcement learning",
            "updated": "2023-10-24T10:35:08Z",
            "published": "2023-10-24T10:35:08Z",
            "summary": "The Flexible Job Shop Scheduling Problem (FJSSP) has been extensively studied\nin the literature, and multiple approaches have been proposed within the\nheuristic, exact, and metaheuristic methods. However, the industry's demand to\nbe able to respond in real-time to disruptive events has generated the\nnecessity to be able to generate new schedules within a few seconds. Among\nthese methods, under this constraint, only dispatching rules (DRs) are capable\nof generating schedules, even though their quality can be improved. To improve\nthe results, recent methods have been proposed for modeling the FJSSP as a\nMarkov Decision Process (MDP) and employing reinforcement learning to create a\npolicy that generates an optimal solution assigning operations to machines.\nNonetheless, there is still room for improvement, particularly in the larger\nFJSSP instances which are common in real-world scenarios. Therefore, the\nobjective of this paper is to propose a method capable of robustly solving\nlarge instances of the FJSSP. To achieve this, we propose a novel way of\nmodeling the FJSSP as an MDP using graph neural networks. We also present two\nmethods to make inference more robust: generating a diverse set of scheduling\npolicies that can be parallelized and limiting them using DRs. We have tested\nour approach on synthetically generated instances and various public benchmarks\nand found that our approach outperforms dispatching rules and achieves better\nresults than three other recent deep reinforcement learning methods on larger\nFJSSP instances.",
            "author": [
                "Imanol Echeverria",
                "Maialen Murua",
                "Roberto Santana"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15706v1",
                "http://arxiv.org/pdf/2310.15706v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15705v1",
            "title": "Learning-based Scheduling for Information Accuracy and Freshness in\n  Wireless Networks",
            "updated": "2023-10-24T10:31:34Z",
            "published": "2023-10-24T10:31:34Z",
            "summary": "We consider a system of multiple sources, a single communication channel, and\na single monitoring station. Each source measures a time-varying quantity with\nvarying levels of accuracy and one of them sends its update to the monitoring\nstation via the channel. The probability of success of each attempted\ncommunication is a function of the source scheduled for transmitting its\nupdate. Both the probability of correct measurement and the probability of\nsuccessful transmission of all the sources are unknown to the scheduler. The\nmetric of interest is the reward received by the system which depends on the\naccuracy of the last update received by the destination and the\nAge-of-Information (AoI) of the system. We model our scheduling problem as a\nvariant of the multi-arm bandit problem with sources as different arms. We\ncompare the performance of all $4$ standard bandit policies, namely, ETC,\n$\\epsilon$-greedy, UCB, and TS suitably adjusted to our system model via\nsimulations. In addition, we provide analytical guarantees of $2$ of these\npolicies, ETC, and $\\epsilon$-greedy. Finally, we characterize the lower bound\non the cumulative regret achievable by any policy.",
            "author": [
                "Hitesh Gudwani"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15705v1",
                "http://arxiv.org/pdf/2310.15705v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15699v2",
            "title": "DACOOP-A: Decentralized Adaptive Cooperative Pursuit via Attention",
            "updated": "2023-10-28T13:47:41Z",
            "published": "2023-10-24T10:15:07Z",
            "summary": "Integrating rule-based policies into reinforcement learning promises to\nimprove data efficiency and generalization in cooperative pursuit problems.\nHowever, most implementations do not properly distinguish the influence of\nneighboring robots in observation embedding or inter-robot interaction rules,\nleading to information loss and inefficient cooperation. This paper proposes a\ncooperative pursuit algorithm named Decentralized Adaptive COOperative Pursuit\nvia Attention (DACOOP-A) by empowering reinforcement learning with artificial\npotential field and attention mechanisms. An attention-based framework is\ndeveloped to emphasize important neighbors by concurrently integrating the\nlearned attention scores into observation embedding and inter-robot interaction\nrules. A KL divergence regularization is introduced to alleviate the resultant\nlearning stability issue. Improvements in data efficiency and generalization\nare demonstrated through numerical simulations. Extensive quantitative analysis\nand ablation studies are performed to illustrate the advantages of the proposed\nmodules. Real-world experiments are performed to justify the feasibility of\ndeploying DACOOP-A in physical systems.",
            "author": [
                "Zheng Zhang",
                "Dengyu Zhang",
                "Qingrui Zhang",
                "Wei Pan",
                "Tianjiang Hu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15699v2",
                "http://arxiv.org/pdf/2310.15699v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15694v4",
            "title": "COPF: Continual Learning Human Preference through Optimal Policy Fitting",
            "updated": "2023-10-28T02:00:39Z",
            "published": "2023-10-24T10:05:32Z",
            "summary": "The technique of Reinforcement Learning from Human Feedback (RLHF) is a\ncommonly employed method to improve pre-trained Language Models (LM), enhancing\ntheir ability to conform to human preferences. Nevertheless, the current\nRLHF-based LMs necessitate full retraining each time novel queries or feedback\nare introduced, which becomes a challenging task because human preferences can\nvary between different domains or tasks. Retraining LMs poses practical\ndifficulties in many real-world situations due to the significant time and\ncomputational resources required, along with concerns related to data privacy.\nTo address this limitation, we propose a new method called Continual Optimal\nPolicy Fitting (COPF), in which we estimate a series of optimal policies using\nthe Monte Carlo method, and then continually fit the policy sequence with the\nfunction regularization. COPF involves a single learning phase and doesn't\nnecessitate complex reinforcement learning. Importantly, it shares the\ncapability with RLHF to learn from unlabeled data, making it flexible for\ncontinual preference learning. Our experimental results show that COPF\noutperforms strong Continuous learning (CL) baselines when it comes to\nconsistently aligning with human preferences on different tasks and domains.",
            "author": [
                "Han Zhang",
                "Lin Gui",
                "Yuanzhao Zhai",
                "Hui Wang",
                "Yu Lei",
                "Ruifeng Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15694v4",
                "http://arxiv.org/pdf/2310.15694v4"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15693v1",
            "title": "Towards Automated Recipe Genre Classification using Semi-Supervised\n  Learning",
            "updated": "2023-10-24T10:03:27Z",
            "published": "2023-10-24T10:03:27Z",
            "summary": "Sharing cooking recipes is a great way to exchange culinary ideas and provide\ninstructions for food preparation. However, categorizing raw recipes found\nonline into appropriate food genres can be challenging due to a lack of\nadequate labeled data. In this study, we present a dataset named the\n``Assorted, Archetypal, and Annotated Two Million Extended (3A2M+) Cooking\nRecipe Dataset\" that contains two million culinary recipes labeled in\nrespective categories with extended named entities extracted from recipe\ndescriptions. This collection of data includes various features such as title,\nNER, directions, and extended NER, as well as nine different labels\nrepresenting genres including bakery, drinks, non-veg, vegetables, fast food,\ncereals, meals, sides, and fusions. The proposed pipeline named 3A2M+ extends\nthe size of the Named Entity Recognition (NER) list to address missing named\nentities like heat, time or process from the recipe directions using two NER\nextraction tools. 3A2M+ dataset provides a comprehensive solution to the\nvarious challenging recipe-related tasks, including classification, named\nentity recognition, and recipe generation. Furthermore, we have demonstrated\ntraditional machine learning, deep learning and pre-trained language models to\nclassify the recipes into their corresponding genre and achieved an overall\naccuracy of 98.6\\%. Our investigation indicates that the title feature played a\nmore significant role in classifying the genre.",
            "author": [
                "Nazmus Sakib",
                "G. M. Shahariar",
                "Md. Mohsinul Kabir",
                "Md. Kamrul Hasan",
                "Hasan Mahmud"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15693v1",
                "http://arxiv.org/pdf/2310.15693v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15690v1",
            "title": "Physics-Informed with Power-Enhanced Residual Network for Interpolation\n  and Inverse Problems",
            "updated": "2023-10-24T10:01:15Z",
            "published": "2023-10-24T10:01:15Z",
            "summary": "This paper introduces a novel neural network structure called the\nPower-Enhancing residual network, designed to improve interpolation\ncapabilities for both smooth and non-smooth functions in 2D and 3D settings. By\nadding power terms to residual elements, the architecture boosts the network's\nexpressive power. The study explores network depth, width, and optimization\nmethods, showing the architecture's adaptability and performance advantages.\nConsistently, the results emphasize the exceptional accuracy of the proposed\nPower-Enhancing residual network, particularly for non-smooth functions.\nReal-world examples also confirm its superiority over plain neural network in\nterms of accuracy, convergence, and efficiency. The study also looks at the\nimpact of deeper network. Moreover, the proposed architecture is also applied\nto solving the inverse Burgers' equation, demonstrating superior performance.\nIn conclusion, the Power-Enhancing residual network offers a versatile solution\nthat significantly enhances neural network capabilities. The codes implemented\nare available at: \\url{https://github.com/CMMAi/ResNet_for_PINN}.",
            "author": [
                "Amir Noorizadegan",
                "D. L. Young",
                "Y. C. Hon",
                "C. S. Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15690v1",
                "http://arxiv.org/pdf/2310.15690v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "math.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15688v1",
            "title": "Nighttime Thermal Infrared Image Colorization with Feedback-based Object\n  Appearance Learning",
            "updated": "2023-10-24T09:59:55Z",
            "published": "2023-10-24T09:59:55Z",
            "summary": "Stable imaging in adverse environments (e.g., total darkness) makes thermal\ninfrared (TIR) cameras a prevalent option for night scene perception. However,\nthe low contrast and lack of chromaticity of TIR images are detrimental to\nhuman interpretation and subsequent deployment of RGB-based vision algorithms.\nTherefore, it makes sense to colorize the nighttime TIR images by translating\nthem into the corresponding daytime color images (NTIR2DC). Despite the\nimpressive progress made in the NTIR2DC task, how to improve the translation\nperformance of small object classes is under-explored. To address this problem,\nwe propose a generative adversarial network incorporating feedback-based object\nappearance learning (FoalGAN). Specifically, an occlusion-aware mixup module\nand corresponding appearance consistency loss are proposed to reduce the\ncontext dependence of object translation. As a representative example of small\nobjects in nighttime street scenes, we illustrate how to enhance the realism of\ntraffic light by designing a traffic light appearance loss. To further improve\nthe appearance learning of small objects, we devise a dual feedback learning\nstrategy to selectively adjust the learning frequency of different samples. In\naddition, we provide pixel-level annotation for a subset of the Brno dataset,\nwhich can facilitate the research of NTIR image understanding under multiple\nweather conditions. Extensive experiments illustrate that the proposed FoalGAN\nis not only effective for appearance learning of small objects, but also\noutperforms other image translation methods in terms of semantic preservation\nand edge consistency for the NTIR2DC task.",
            "author": [
                "Fu-Ya Luo",
                "Shu-Lin Liu",
                "Yi-Jun Cao",
                "Kai-Fu Yang",
                "Chang-Yong Xie",
                "Yong Liu",
                "Yong-Jie Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15688v1",
                "http://arxiv.org/pdf/2310.15688v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15684v1",
            "title": "Improving Biomedical Abstractive Summarisation with Knowledge\n  Aggregation from Citation Papers",
            "updated": "2023-10-24T09:56:46Z",
            "published": "2023-10-24T09:56:46Z",
            "summary": "Abstracts derived from biomedical literature possess distinct domain-specific\ncharacteristics, including specialised writing styles and biomedical\nterminologies, which necessitate a deep understanding of the related\nliterature. As a result, existing language models struggle to generate\ntechnical summaries that are on par with those produced by biomedical experts,\ngiven the absence of domain-specific background knowledge. This paper aims to\nenhance the performance of language models in biomedical abstractive\nsummarisation by aggregating knowledge from external papers cited within the\nsource article. We propose a novel attention-based citation aggregation model\nthat integrates domain-specific knowledge from citation papers, allowing neural\nnetworks to generate summaries by leveraging both the paper content and\nrelevant knowledge from citation papers. Furthermore, we construct and release\na large-scale biomedical summarisation dataset that serves as a foundation for\nour research. Extensive experiments demonstrate that our model outperforms\nstate-of-the-art approaches and achieves substantial improvements in\nabstractive biomedical text summarisation.",
            "author": [
                "Chen Tang",
                "Shun Wang",
                "Tomas Goldsack",
                "Chenghua Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15684v1",
                "http://arxiv.org/pdf/2310.15684v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15681v2",
            "title": "Fixed-Budget Real-Valued Combinatorial Pure Exploration of Multi-Armed\n  Bandit",
            "updated": "2023-11-15T11:10:12Z",
            "published": "2023-10-24T09:47:32Z",
            "summary": "We study the real-valued combinatorial pure exploration of the multi-armed\nbandit in the fixed-budget setting. We first introduce the Combinatorial\nSuccessive Asign (CSA) algorithm, which is the first algorithm that can\nidentify the best action even when the size of the action class is\nexponentially large with respect to the number of arms. We show that the upper\nbound of the probability of error of the CSA algorithm matches a lower bound up\nto a logarithmic factor in the exponent. Then, we introduce another algorithm\nnamed the Minimax Combinatorial Successive Accepts and Rejects\n(Minimax-CombSAR) algorithm for the case where the size of the action class is\npolynomial, and show that it is optimal, which matches a lower bound. Finally,\nwe experimentally compare the algorithms with previous methods and show that\nour algorithm performs better.",
            "author": [
                "Shintaro Nakamura",
                "Masashi Sugiyama"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15681v2",
                "http://arxiv.org/pdf/2310.15681v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15679v1",
            "title": "Mechanism of charge transport in lithium thiophosphate",
            "updated": "2023-10-24T09:43:09Z",
            "published": "2023-10-24T09:43:09Z",
            "summary": "Lithium ortho-thiophosphate ($\\textrm{Li}_3\\textrm{PS}_4$) has emerged as a\npromising candidate for solid-state-electrolyte batteries, thanks to its highly\nconductive phases, cheap components, and large electrochemical stability range.\nNonetheless, the microscopic mechanisms of Li-ion transport in\n$\\textrm{Li}_3\\textrm{PS}_4$ are far to be fully understood, the role of\n$\\textrm{PS}_4$ dynamics in charge transport still being controversial. In this\nwork, we build machine learning potentials targeting state-of-the-art DFT\nreferences (PBEsol, r$^2$SCAN, and PBE0) to tackle this problem in all known\nphases of $\\textrm{Li}_3\\textrm{PS}_4$ ($\\alpha$, $\\beta$ and $\\gamma$), for\nlarge system sizes and timescales. We discuss the physical origin of the\nobserved superionic behavior of $\\textrm{Li}_3\\textrm{PS}_4$: the activation of\n$\\textrm{PS}_4$ flipping drives a structural transition to a highly conductive\nphase, characterized by an increase of Li-site availability and by a drastic\nreduction in the activation energy of Li-ion diffusion. We also rule out any\npaddle-wheel effects of $\\textrm{PS}_4$ tetrahedra in the superionic phases --\npreviously claimed to enhance Li-ion diffusion -- due to the\norders-of-magnitude difference between the rate of $\\textrm{PS}_4$ flips and\nLi-ion hops at all temperatures below melting. We finally elucidate the role of\ninter-ionic dynamical correlations in charge transport, by highlighting the\nfailure of the Nernst-Einstein approximation to estimate the electrical\nconductivity. Our results show a strong dependence on the target DFT reference,\nwith PBE0 yielding the best quantitative agreement with experimental\nmeasurements not only for the electronic band-gap but also for the electrical\nconductivity of $\\beta$- and $\\alpha$-$\\textrm{Li}_3\\textrm{PS}_4$.",
            "author": [
                "Lorenzo Gigli",
                "Davide Tisi",
                "Federico Grasselli",
                "Michele Ceriotti"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15679v1",
                "http://arxiv.org/pdf/2310.15679v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15677v1",
            "title": "Robot-Relay : Building-Wide, Calibration-Less Visual Servoing with\n  Learned Sensor Handover Network",
            "updated": "2023-10-24T09:41:23Z",
            "published": "2023-10-24T09:41:23Z",
            "summary": "We present a system which grows and manages a network of remote viewpoints\nduring the natural installation cycle for a newly installed camera network or a\nnewly deployed robot fleet. No explicit notion of camera position or\norientation is required, neither global - i.e. relative to a building plan -\nnor local - i.e. relative to an interesting point in a room. Furthermore, no\nmetric relationship between viewpoints is required. Instead, we leverage our\nprior work in effective remote control without extrinsic or intrinsic\ncalibration and extend it to the multi-camera setting. In this, we memorise,\nfrom simultaneous robot detections in the tracker thread, soft pixel-wise\ntopological connections between viewpoints. We demonstrate our system with\nrepeated autonomous traversals of workspaces connected by a network of six\ncameras across a productive office environment.",
            "author": [
                "Luke Robinson",
                "Matthew Gadd",
                "Paul Newman",
                "Daniele De Martini"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15677v1",
                "http://arxiv.org/pdf/2310.15677v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15674v1",
            "title": "IceCube -- Neutrinos in Deep Ice The Top 3 Solutions from the Public\n  Kaggle Competition",
            "updated": "2023-10-24T09:36:29Z",
            "published": "2023-10-24T09:36:29Z",
            "summary": "During the public Kaggle competition \"IceCube -- Neutrinos in Deep Ice\",\nthousands of reconstruction algorithms were created and submitted, aiming to\nestimate the direction of neutrino events recorded by the IceCube detector.\nHere we describe in detail the three ultimate best, award-winning solutions.\nThe data handling, architecture, and training process of each of these machine\nlearning models is laid out, followed up by an in-depth comparison of the\nperformance on the kaggle datatset. We show that on cascade events in IceCube\nabove 10 TeV, the best kaggle solution is able to achieve an angular resolution\nof better than 5 degrees, and for tracks correspondingly better than 0.5\ndegrees. These performance measures compare favourably to the current\nstate-of-the-art in the field.",
            "author": [
                "Habib Bukhari",
                "Dipam Chakraborty",
                "Philipp Eller",
                "Takuya Ito",
                "Maxim V. Shugaev",
                "Rasmus \u00d8rs\u00f8e"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15674v1",
                "http://arxiv.org/pdf/2310.15674v1"
            ],
            "primary_category": "astro-ph.HE",
            "category": [
                "astro-ph.HE",
                "hep-ex",
                "physics.data-an"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15671v2",
            "title": "Quality flags for GSP-Phot Gaia DR3 astrophysical parameters with\n  machine learning: Effective temperatures case study",
            "updated": "2023-11-17T14:32:19Z",
            "published": "2023-10-24T09:30:59Z",
            "summary": "Gaia Data Release 3 (DR3) provides extensive information on the astrophysical\nproperties of stars, such as effective temperature, surface gravity,\nmetallicity, and luminosity, for over 470 million objects. However, as Gaia's\nstellar parameters in GSP-Phot module are derived through model-dependent\nmethods and indirect measurements, it can lead to additional systematic errors\nin the derived parameters. In this study, we compare GSP-Phot effective\ntemperature estimates with two high-resolution and high signal-to-noise\nspectroscopic catalogues: APOGEE DR17 and GALAH DR3, aiming to assess the\nreliability of Gaia's temperatures. We introduce an approach to distinguish\ngood-quality Gaia DR3 effective temperatures using machine-learning methods\nsuch as XGBoost, CatBoost and LightGBM. The models create quality flags, which\ncan help one to distinguish good-quality GSP-Phot effective temperatures. We\ntest our models on three independent datasets, including PASTEL, a compilation\nof spectroscopically derived stellar parameters from different high-resolution\nstudies. The results of the test suggest that with these models it is possible\nto filter effective temperatures as accurate as 250 K with ~ 90 per cent\nprecision even in complex regions, such as the Galactic plane. Consequently,\nthe models developed herein offer a valuable quality assessment tool for\nGSP-Phot effective temperatures in Gaia DR3. Consequently, the developed models\noffer a valuable quality assessment tool for GSP-Phot effective temperatures in\nGaia DR3. The dataset with flags for all GSP-Phot effective temperature\nestimates, is publicly available, as are the models themselves.",
            "author": [
                "Aleksandra S. Avdeeva",
                "Dana A. Kovaleva",
                "Oleg Yu. Malkov",
                "Gang Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15671v2",
                "http://arxiv.org/pdf/2310.15671v2"
            ],
            "primary_category": "astro-ph.SR",
            "category": [
                "astro-ph.SR",
                "astro-ph.EP",
                "astro-ph.GA",
                "astro-ph.IM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15664v1",
            "title": "Expression Syntax Information Bottleneck for Math Word Problems",
            "updated": "2023-10-24T09:23:57Z",
            "published": "2023-10-24T09:23:57Z",
            "summary": "Math Word Problems (MWP) aims to automatically solve mathematical questions\ngiven in texts. Previous studies tend to design complex models to capture\nadditional information in the original text so as to enable the model to gain\nmore comprehensive features. In this paper, we turn our attention in the\nopposite direction, and work on how to discard redundant features containing\nspurious correlations for MWP. To this end, we design an Expression Syntax\nInformation Bottleneck method for MWP (called ESIB) based on variational\ninformation bottleneck, which extracts essential features of expression syntax\ntree while filtering latent-specific redundancy containing syntax-irrelevant\nfeatures. The key idea of ESIB is to encourage multiple models to predict the\nsame expression syntax tree for different problem representations of the same\nproblem by mutual learning so as to capture consistent information of\nexpression syntax tree and discard latent-specific redundancy. To improve the\ngeneralization ability of the model and generate more diverse expressions, we\ndesign a self-distillation loss to encourage the model to rely more on the\nexpression syntax information in the latent space. Experimental results on two\nlarge-scale benchmarks show that our model not only achieves state-of-the-art\nresults but also generates more diverse solutions. The code is available.",
            "author": [
                "Jing Xiong",
                "Chengming Li",
                "Min Yang",
                "Xiping Hu",
                "Bin Hu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15664v1",
                "http://arxiv.org/pdf/2310.15664v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15662v1",
            "title": "Interactive Generalized Additive Model and Its Applications in Electric\n  Load Forecasting",
            "updated": "2023-10-24T09:17:47Z",
            "published": "2023-10-24T09:17:47Z",
            "summary": "Electric load forecasting is an indispensable component of electric power\nsystem planning and management. Inaccurate load forecasting may lead to the\nthreat of outages or a waste of energy. Accurate electric load forecasting is\nchallenging when there is limited data or even no data, such as load\nforecasting in holiday, or under extreme weather conditions. As high-stakes\ndecision-making usually follows after load forecasting, model interpretability\nis crucial for the adoption of forecasting models. In this paper, we propose an\ninteractive GAM which is not only interpretable but also can incorporate\nspecific domain knowledge in electric power industry for improved performance.\nThis boosting-based GAM leverages piecewise linear functions and can be learned\nthrough our efficient algorithm. In both public benchmark and electricity\ndatasets, our interactive GAM outperforms current state-of-the-art methods and\ndemonstrates good generalization ability in the cases of extreme weather\nevents. We launched a user-friendly web-based tool based on interactive GAM and\nalready incorporated it into our eForecaster product, a unified AI platform for\nelectricity forecasting.",
            "author": [
                "Linxiao Yang",
                "Rui Ren",
                "Xinyue Gu",
                "Liang Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15662v1",
                "http://arxiv.org/pdf/2310.15662v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16063v1",
            "title": "Enhancing Traffic Prediction with Learnable Filter Module",
            "updated": "2023-10-24T09:16:13Z",
            "published": "2023-10-24T09:16:13Z",
            "summary": "Modeling future traffic conditions often relies heavily on complex\nspatial-temporal neural networks to capture spatial and temporal correlations,\nwhich can overlook the inherent noise in the data. This noise, often\nmanifesting as unexpected short-term peaks or drops in traffic observation, is\ntypically caused by traffic accidents or inherent sensor vibration. In\npractice, such noise can be challenging to model due to its stochastic nature\nand can lead to overfitting risks if a neural network is designed to learn this\nbehavior. To address this issue, we propose a learnable filter module to filter\nout noise in traffic data adaptively. This module leverages the Fourier\ntransform to convert the data to the frequency domain, where noise is filtered\nbased on its pattern. The denoised data is then recovered to the time domain\nusing the inverse Fourier transform. Our approach focuses on enhancing the\nquality of the input data for traffic prediction models, which is a critical\nyet often overlooked aspect in the field. We demonstrate that the proposed\nmodule is lightweight, easy to integrate with existing models, and can\nsignificantly improve traffic prediction performance. Furthermore, we validate\nour approach with extensive experimental results on real-world datasets,\nshowing that it effectively mitigates noise and enhances prediction accuracy.",
            "author": [
                "Yuanshao Zhu",
                "Yongchao Ye",
                "Xiangyu Zhao",
                "James J. Q. Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16063v1",
                "http://arxiv.org/pdf/2310.16063v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16062v1",
            "title": "Confounder Balancing in Adversarial Domain Adaptation for Pre-Trained\n  Large Models Fine-Tuning",
            "updated": "2023-10-24T09:11:45Z",
            "published": "2023-10-24T09:11:45Z",
            "summary": "The excellent generalization, contextual learning, and emergence abilities in\nthe pre-trained large models (PLMs) handle specific tasks without direct\ntraining data, making them the better foundation models in the adversarial\ndomain adaptation (ADA) methods to transfer knowledge learned from the source\ndomain to target domains. However, existing ADA methods fail to account for the\nconfounder properly, which is the root cause of the source data distribution\nthat differs from the target domains. This study proposes an adversarial domain\nadaptation with confounder balancing for PLMs fine-tuning (ADA-CBF). The\nADA-CBF includes a PLM as the foundation model for a feature extractor, a\ndomain classifier and a confounder classifier, and they are jointly trained\nwith an adversarial loss. This loss is designed to improve the domain-invariant\nrepresentation learning by diluting the discrimination in the domain\nclassifier. At the same time, the adversarial loss also balances the confounder\ndistribution among source and unmeasured domains in training. Compared to\nexisting ADA methods, ADA-CBF can correctly identify confounders in\ndomain-invariant features, thereby eliminating the confounder biases in the\nextracted features from PLMs. The confounder classifier in ADA-CBF is designed\nas a plug-and-play and can be applied in the confounder measurable,\nunmeasurable, or partially measurable environments. Empirical results on\nnatural language processing and computer vision downstream tasks show that\nADA-CBF outperforms the newest GPT-4, LLaMA2, ViT and ADA methods.",
            "author": [
                "Shuoran Jiang",
                "Qingcai Chen",
                "Yang Xiang",
                "Youcheng Pan",
                "Xiangping Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16062v1",
                "http://arxiv.org/pdf/2310.16062v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15657v1",
            "title": "Testing the Limits: Unusual Text Inputs Generation for Mobile App Crash\n  Detection with Large Language Model",
            "updated": "2023-10-24T09:10:51Z",
            "published": "2023-10-24T09:10:51Z",
            "summary": "Mobile applications have become a ubiquitous part of our daily life,\nproviding users with access to various services and utilities. Text input, as\nan important interaction channel between users and applications, plays an\nimportant role in core functionality such as search queries, authentication,\nmessaging, etc. However, certain special text (e.g., -18 for Font Size) can\ncause the app to crash, and generating diversified unusual inputs for fully\ntesting the app is highly demanded. Nevertheless, this is also challenging due\nto the combination of explosion dilemma, high context sensitivity, and complex\nconstraint relations. This paper proposes InputBlaster which leverages the LLM\nto automatically generate unusual text inputs for mobile app crash detection.\nIt formulates the unusual inputs generation problem as a task of producing a\nset of test generators, each of which can yield a batch of unusual text inputs\nunder the same mutation rule. In detail, InputBlaster leverages LLM to produce\nthe test generators together with the mutation rules serving as the reasoning\nchain, and utilizes the in-context learning schema to demonstrate the LLM with\nexamples for boosting the performance. InputBlaster is evaluated on 36 text\ninput widgets with cash bugs involving 31 popular Android apps, and results\nshow that it achieves 78% bug detection rate, with 136% higher than the best\nbaseline. Besides, we integrate it with the automated GUI testing tool and\ndetect 37 unseen crashes in real-world apps from Google Play.",
            "author": [
                "Zhe Liu",
                "Chunyang Chen",
                "Junjie Wang",
                "Mengzhuo Chen",
                "Boyu Wu",
                "Xing Che",
                "Dandan Wang",
                "Qing Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15657v1",
                "http://arxiv.org/pdf/2310.15657v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15656v1",
            "title": "Momentum Gradient-based Untargeted Attack on Hypergraph Neural Networks",
            "updated": "2023-10-24T09:10:45Z",
            "published": "2023-10-24T09:10:45Z",
            "summary": "Hypergraph Neural Networks (HGNNs) have been successfully applied in various\nhypergraph-related tasks due to their excellent higher-order representation\ncapabilities. Recent works have shown that deep learning models are vulnerable\nto adversarial attacks. Most studies on graph adversarial attacks have focused\non Graph Neural Networks (GNNs), and the study of adversarial attacks on HGNNs\nremains largely unexplored. In this paper, we try to reduce this gap. We design\na new HGNNs attack model for the untargeted attack, namely MGHGA, which focuses\non modifying node features. We consider the process of HGNNs training and use a\nsurrogate model to implement the attack before hypergraph modeling.\nSpecifically, MGHGA consists of two parts: feature selection and feature\nmodification. We use a momentum gradient mechanism to choose the attack node\nfeatures in the feature selection module. In the feature modification module,\nwe use two feature generation approaches (direct modification and sign\ngradient) to enable MGHGA to be employed on discrete and continuous datasets.\nWe conduct extensive experiments on five benchmark datasets to validate the\nattack performance of MGHGA in the node and the visual object classification\ntasks. The results show that MGHGA improves performance by an average of 2%\ncompared to the than the baselines.",
            "author": [
                "Yang Chen",
                "Stjepan Picek",
                "Zhonglin Ye",
                "Zhaoyang Wang",
                "Haixing Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15656v1",
                "http://arxiv.org/pdf/2310.15656v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15655v1",
            "title": "Breaking of brightness consistency in optical flow with a lightweight\n  CNN network",
            "updated": "2023-10-24T09:10:43Z",
            "published": "2023-10-24T09:10:43Z",
            "summary": "Sparse optical flow is widely used in various computer vision tasks, however\nassuming brightness consistency limits its performance in High Dynamic Range\n(HDR) environments. In this work, a lightweight network is used to extract\nillumination robust convolutional features and corners with strong invariance.\nModifying the typical brightness consistency of the optical flow method to the\nconvolutional feature consistency yields the light-robust hybrid optical flow\nmethod. The proposed network runs at 190 FPS on a commercial CPU because it\nuses only four convolutional layers to extract feature maps and score maps\nsimultaneously. Since the shallow network is difficult to train directly, a\ndeep network is designed to compute the reliability map that helps it. An\nend-to-end unsupervised training mode is used for both networks. To validate\nthe proposed method, we compare corner repeatability and matching performance\nwith origin optical flow under dynamic illumination. In addition, a more\naccurate visual inertial system is constructed by replacing the optical flow\nmethod in VINS-Mono. In a public HDR dataset, it reduces translation errors by\n93\\%. The code is publicly available at https://github.com/linyicheng1/LET-NET.",
            "author": [
                "Yicheng Lin",
                "Shuo Wang",
                "Yunlong Jiang",
                "Bin Han"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15655v1",
                "http://arxiv.org/pdf/2310.15655v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15654v1",
            "title": "A Survey on Detection of LLMs-Generated Content",
            "updated": "2023-10-24T09:10:26Z",
            "published": "2023-10-24T09:10:26Z",
            "summary": "The burgeoning capabilities of advanced large language models (LLMs) such as\nChatGPT have led to an increase in synthetic content generation with\nimplications across a variety of sectors, including media, cybersecurity,\npublic discourse, and education. As such, the ability to detect LLMs-generated\ncontent has become of paramount importance. We aim to provide a detailed\noverview of existing detection strategies and benchmarks, scrutinizing their\ndifferences and identifying key challenges and prospects in the field,\nadvocating for more adaptable and robust models to enhance detection accuracy.\nWe also posit the necessity for a multi-faceted approach to defend against\nvarious attacks to counter the rapidly advancing capabilities of LLMs. To the\nbest of our knowledge, this work is the first comprehensive survey on the\ndetection in the era of LLMs. We hope it will provide a broad understanding of\nthe current landscape of LLMs-generated content detection, offering a guiding\nreference for researchers and practitioners striving to uphold the integrity of\ndigital information in an era increasingly dominated by synthetic content. The\nrelevant papers are summarized and will be consistently updated at\nhttps://github.com/Xianjun-Yang/Awesome_papers_on_LLMs_detection.git.",
            "author": [
                "Xianjun Yang",
                "Liangming Pan",
                "Xuandong Zhao",
                "Haifeng Chen",
                "Linda Petzold",
                "William Yang Wang",
                "Wei Cheng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15654v1",
                "http://arxiv.org/pdf/2310.15654v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.CY",
                "cs.HC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15653v1",
            "title": "Deceptive Fairness Attacks on Graphs via Meta Learning",
            "updated": "2023-10-24T09:10:14Z",
            "published": "2023-10-24T09:10:14Z",
            "summary": "We study deceptive fairness attacks on graphs to answer the following\nquestion: How can we achieve poisoning attacks on a graph learning model to\nexacerbate the bias deceptively? We answer this question via a bi-level\noptimization problem and propose a meta learning-based framework named FATE.\nFATE is broadly applicable with respect to various fairness definitions and\ngraph learning models, as well as arbitrary choices of manipulation operations.\nWe further instantiate FATE to attack statistical parity and individual\nfairness on graph neural networks. We conduct extensive experimental\nevaluations on real-world datasets in the task of semi-supervised node\nclassification. The experimental results demonstrate that FATE could amplify\nthe bias of graph neural networks with or without fairness consideration while\nmaintaining the utility on the downstream task. We hope this paper provides\ninsights into the adversarial robustness of fair graph learning and can shed\nlight on designing robust and fair graph learning in future studies.",
            "author": [
                "Jian Kang",
                "Yinglong Xia",
                "Ross Maciejewski",
                "Jiebo Luo",
                "Hanghang Tong"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15653v1",
                "http://arxiv.org/pdf/2310.15653v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15649v1",
            "title": "Probing nuclear physics with supernova gravitational waves and machine\n  learning",
            "updated": "2023-10-24T09:08:22Z",
            "published": "2023-10-24T09:08:22Z",
            "summary": "Core-collapse supernovae are sources of powerful gravitational waves (GWs).\nWe assess the possibility of extracting information about the equation of state\n(EOS) of high density matter from the GW signal. We use the bounce and early\npost-bounce signals of rapidly rotating supernovae. A large set of GW signals\nis generated using general relativistic hydrodynamics simulations for various\nEOS models. The uncertainty in the electron capture rate is parametrized by\ngenerating signals for six different models. To classify EOSs based on the GW\ndata, we train a convolutional neural network (CNN) model. Even with the\nuncertainty in the electron capture rates, we find that the CNN models can\nclassify the EOSs with an average accuracy of about 87 percent for a set of\nfour distinct EOS models.",
            "author": [
                "Ayan Mitra",
                "Daniil Orel",
                "Y. Sultan Abylkairov",
                "Bekdaulet Shukirgaliyev",
                "Ernazar Abdikamalov"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15649v1",
                "http://arxiv.org/pdf/2310.15649v1"
            ],
            "primary_category": "astro-ph.HE",
            "category": [
                "astro-ph.HE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15648v1",
            "title": "Dynamic Convolutional Neural Networks as Efficient Pre-trained Audio\n  Models",
            "updated": "2023-10-24T09:08:20Z",
            "published": "2023-10-24T09:08:20Z",
            "summary": "The introduction of large-scale audio datasets, such as AudioSet, paved the\nway for Transformers to conquer the audio domain and replace CNNs as the\nstate-of-the-art neural network architecture for many tasks. Audio Spectrogram\nTransformers are excellent at exploiting large datasets, creating powerful\npre-trained models that surpass CNNs when fine-tuned on downstream tasks.\nHowever, current popular Audio Spectrogram Transformers are demanding in terms\nof computational complexity compared to CNNs. Recently, we have shown that, by\nemploying Transformer-to-CNN Knowledge Distillation, efficient CNNs can catch\nup with and even outperform Transformers on large datasets. In this work, we\nextend this line of research and increase the capacity of efficient CNNs by\nintroducing dynamic CNN blocks, constructed of dynamic non-linearities, dynamic\nconvolutions and attention mechanisms. We show that these dynamic CNNs\noutperform traditional efficient CNNs, in terms of the performance-complexity\ntrade-off and parameter efficiency, at the task of audio tagging on the\nlarge-scale AudioSet. Our experiments further indicate that the introduced\ndynamic CNNs achieve better performance on downstream tasks and scale up well,\nattaining Transformer performance and even outperforming them on AudioSet and\nseveral downstream tasks.",
            "author": [
                "Florian Schmid",
                "Khaled Koutini",
                "Gerhard Widmer"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15648v1",
                "http://arxiv.org/pdf/2310.15648v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.LG",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15645v1",
            "title": "Light up that Droid! On the Effectiveness of Static Analysis Features\n  against App Obfuscation for Android Malware Detection",
            "updated": "2023-10-24T09:07:23Z",
            "published": "2023-10-24T09:07:23Z",
            "summary": "Malware authors have seen obfuscation as the mean to bypass malware detectors\nbased on static analysis features. For Android, several studies have confirmed\nthat many anti-malware products are easily evaded with simple program\ntransformations. As opposed to these works, ML detection proposals for Android\nleveraging static analysis features have also been proposed as\nobfuscation-resilient. Therefore, it needs to be determined to what extent the\nuse of a specific obfuscation strategy or tool poses a risk for the validity of\nML malware detectors for Android based on static analysis features. To shed\nsome light in this regard, in this article we assess the impact of specific\nobfuscation techniques on common features extracted using static analysis and\ndetermine whether the changes are significant enough to undermine the\neffectiveness of ML malware detectors that rely on these features. The\nexperimental results suggest that obfuscation techniques affect all static\nanalysis features to varying degrees across different tools. However, certain\nfeatures retain their validity for ML malware detection even in the presence of\nobfuscation. Based on these findings, we propose a ML malware detector for\nAndroid that is robust against obfuscation and outperforms current\nstate-of-the-art detectors.",
            "author": [
                "Borja Molina-Coronado",
                "Antonio Ruggia",
                "Usue Mori",
                "Alessio Merlo",
                "Alexander Mendiburu",
                "Jose Miguel-Alonso"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15645v1",
                "http://arxiv.org/pdf/2310.15645v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LG",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15641v1",
            "title": "Guaranteed Coverage Prediction Intervals with Gaussian Process\n  Regression",
            "updated": "2023-10-24T08:59:40Z",
            "published": "2023-10-24T08:59:40Z",
            "summary": "Gaussian Process Regression (GPR) is a popular regression method, which\nunlike most Machine Learning techniques, provides estimates of uncertainty for\nits predictions. These uncertainty estimates however, are based on the\nassumption that the model is well-specified, an assumption that is violated in\nmost practical applications, since the required knowledge is rarely available.\nAs a result, the produced uncertainty estimates can become very misleading; for\nexample the prediction intervals (PIs) produced for the 95\\% confidence level\nmay cover much less than 95\\% of the true labels. To address this issue, this\npaper introduces an extension of GPR based on a Machine Learning framework\ncalled, Conformal Prediction (CP). This extension guarantees the production of\nPIs with the required coverage even when the model is completely misspecified.\nThe proposed approach combines the advantages of GPR with the valid coverage\nguarantee of CP, while the performed experimental results demonstrate its\nsuperiority over existing methods.",
            "author": [
                "Harris Papadopoulos"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15641v1",
                "http://arxiv.org/pdf/2310.15641v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15636v1",
            "title": "Career Path Prediction using Resume Representation Learning and\n  Skill-based Matching",
            "updated": "2023-10-24T08:56:06Z",
            "published": "2023-10-24T08:56:06Z",
            "summary": "The impact of person-job fit on job satisfaction and performance is widely\nacknowledged, which highlights the importance of providing workers with next\nsteps at the right time in their career. This task of predicting the next step\nin a career is known as career path prediction, and has diverse applications\nsuch as turnover prevention and internal job mobility. Existing methods to\ncareer path prediction rely on large amounts of private career history data to\nmodel the interactions between job titles and companies. We propose leveraging\nthe unexplored textual descriptions that are part of work experience sections\nin resumes. We introduce a structured dataset of 2,164 anonymized career\nhistories, annotated with ESCO occupation labels. Based on this dataset, we\npresent a novel representation learning approach, CareerBERT, specifically\ndesigned for work history data. We develop a skill-based model and a text-based\nmodel for career path prediction, which achieve 35.24% and 39.61% recall@10\nrespectively on our dataset. Finally, we show that both approaches are\ncomplementary as a hybrid approach achieves the strongest result with 43.01%\nrecall@10.",
            "author": [
                "Jens-Joris Decorte",
                "Jeroen Van Hautte",
                "Johannes Deleu",
                "Chris Develder",
                "Thomas Demeester"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15636v1",
                "http://arxiv.org/pdf/2310.15636v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15627v1",
            "title": "Contextual directed acyclic graphs",
            "updated": "2023-10-24T08:52:04Z",
            "published": "2023-10-24T08:52:04Z",
            "summary": "Estimating the structure of directed acyclic graphs (DAGs) from observational\ndata remains a significant challenge in machine learning. Most research in this\narea concentrates on learning a single DAG for the entire population. This\npaper considers an alternative setting where the graph structure varies across\nindividuals based on available \"contextual\" features. We tackle this contextual\nDAG problem via a neural network that maps the contextual features to a DAG,\nrepresented as a weighted adjacency matrix. The neural network is equipped with\na novel projection layer that ensures the output matrices are sparse and\nsatisfy a recently developed characterization of acyclicity. We devise a\nscalable computational framework for learning contextual DAGs and provide a\nconvergence guarantee and an analytical gradient for backpropagating through\nthe projection layer. Our experiments suggest that the new approach can recover\nthe true context-specific graph where existing approaches fail.",
            "author": [
                "Ryan Thompson",
                "Edwin V. Bonilla",
                "Robert Kohn"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15627v1",
                "http://arxiv.org/pdf/2310.15627v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15624v1",
            "title": "GUPNet++: Geometry Uncertainty Propagation Network for Monocular 3D\n  Object Detection",
            "updated": "2023-10-24T08:45:15Z",
            "published": "2023-10-24T08:45:15Z",
            "summary": "Geometry plays a significant role in monocular 3D object detection. It can be\nused to estimate object depth by using the perspective projection between\nobject's physical size and 2D projection in the image plane, which can\nintroduce mathematical priors into deep models. However, this projection\nprocess also introduces error amplification, where the error of the estimated\nheight is amplified and reflected into the projected depth. It leads to\nunreliable depth inferences and also impairs training stability. To tackle this\nproblem, we propose a novel Geometry Uncertainty Propagation Network (GUPNet++)\nby modeling geometry projection in a probabilistic manner. This ensures depth\npredictions are well-bounded and associated with a reasonable uncertainty. The\nsignificance of introducing such geometric uncertainty is two-fold: (1). It\nmodels the uncertainty propagation relationship of the geometry projection\nduring training, improving the stability and efficiency of the end-to-end model\nlearning. (2). It can be derived to a highly reliable confidence to indicate\nthe quality of the 3D detection result, enabling more reliable detection\ninference. Experiments show that the proposed approach not only obtains\n(state-of-the-art) SOTA performance in image-based monocular 3D detection but\nalso demonstrates superiority in efficacy with a simplified framework.",
            "author": [
                "Yan Lu",
                "Xinzhu Ma",
                "Lei Yang",
                "Tianzhu Zhang",
                "Yating Liu",
                "Qi Chu",
                "Tong He",
                "Yonghui Li",
                "Wanli Ouyang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15624v1",
                "http://arxiv.org/pdf/2310.15624v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15615v1",
            "title": "Super-resolved rainfall prediction with physics-aware deep learning",
            "updated": "2023-10-24T08:29:28Z",
            "published": "2023-10-24T08:29:28Z",
            "summary": "Rainfall prediction at the kilometre-scale up to a few hours in the future is\nkey for planning and safety. But it is challenging given the complex influence\nof climate change on cloud processes and the limited skill of weather models at\nthis scale. Following the set-up proposed by the \\emph{weather4cast} challenge\nof NeurIPS, we build a two-step deep-learning solution for predicting rainfall\noccurrence at ground radar high spatial resolution starting from coarser\nresolution weather satellite images. Our approach is designed to predict future\nsatellite images with a physics-aware ConvLSTM network, which is then converted\ninto precipitation maps through a U-Net. We find that our two-step pipeline\noutperforms the baseline model and we quantify the benefits of including\nphysical information. We find that local-scale rainfall predictions with good\naccuracy starting from satellite radiances can be obtained for up to 4 hours in\nthe future.",
            "author": [
                "S. Moran",
                "B. Demir",
                "F. Serva",
                "B. Le Saux"
            ],
            "link": [
                "http://dx.doi.org/10.2760/46796",
                "http://arxiv.org/abs/2310.15615v1",
                "http://arxiv.org/pdf/2310.15615v1"
            ],
            "primary_category": "physics.ao-ph",
            "category": [
                "physics.ao-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15614v2",
            "title": "Sparse Bayesian neural networks for regression: Tackling overfitting and\n  computational challenges in uncertainty quantification",
            "updated": "2023-10-25T17:29:22Z",
            "published": "2023-10-24T08:29:14Z",
            "summary": "Neural networks (NNs) are primarily developed within the frequentist\nstatistical framework. Nevertheless, frequentist NNs lack the capability to\nprovide uncertainties in the predictions, and hence their robustness can not be\nadequately assessed. Conversely, the Bayesian neural networks (BNNs) naturally\noffer predictive uncertainty by applying Bayes' theorem. However, their\ncomputational requirements pose significant challenges. Moreover, both\nfrequentist NNs and BNNs suffer from overfitting issues when dealing with noisy\nand sparse data, which render their predictions unwieldy away from the\navailable data space. To address both these problems simultaneously, we\nleverage insights from a hierarchical setting in which the parameter priors are\nconditional on hyperparameters to construct a BNN by applying a semi-analytical\nframework known as nonlinear sparse Bayesian learning (NSBL). We call our\nnetwork sparse Bayesian neural network (SBNN) which aims to address the\npractical and computational issues associated with BNNs. Simultaneously,\nimposing a sparsity-inducing prior encourages the automatic pruning of\nredundant parameters based on the automatic relevance determination (ARD)\nconcept. This process involves removing redundant parameters by optimally\nselecting the precision of the parameters prior probability density functions\n(pdfs), resulting in a tractable treatment for overfitting. To demonstrate the\nbenefits of the SBNN algorithm, the study presents an illustrative regression\nproblem and compares the results of a BNN using standard Bayesian inference,\nhierarchical Bayesian inference, and a BNN equipped with the proposed\nalgorithm. Subsequently, we demonstrate the importance of considering the full\nparameter posterior by comparing the results with those obtained using the\nLaplace approximation with and without NSBL.",
            "author": [
                "Nastaran Dabiran",
                "Brandon Robinson",
                "Rimple Sandhu",
                "Mohammad Khalil",
                "Dominique Poirel",
                "Abhijit Sarkar"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15614v2",
                "http://arxiv.org/pdf/2310.15614v2"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15612v3",
            "title": "Machine Translation for Nko: Tools, Corpora and Baseline Results",
            "updated": "2023-11-15T08:47:28Z",
            "published": "2023-10-24T08:27:56Z",
            "summary": "Currently, there is no usable machine translation system for Nko, a language\nspoken by tens of millions of people across multiple West African countries,\nwhich holds significant cultural and educational value.\n  To address this issue, we present a set of tools, resources, and baseline\nresults aimed towards the development of usable machine translation systems for\nNko and other languages that do not currently have sufficiently large parallel\ntext corpora available.\n  (1) Fria$\\parallel$el: A novel collaborative parallel text curation software\nthat incorporates quality control through copyedit-based workflows.\n  (2) Expansion of the FLoRes-200 and NLLB-Seed corpora with 2,009 and 6,193\nhigh-quality Nko translations in parallel with 204 and 40 other languages.\n  (3) nicolingua-0005: A collection of trilingual and bilingual corpora with\n130,850 parallel segments and monolingual corpora containing over 3 million Nko\nwords.\n  (4) Baseline bilingual and multilingual neural machine translation results\nwith the best model scoring 30.83 English-Nko chrF++ on FLoRes-devtest.",
            "author": [
                "Moussa Koulako Bala Doumbouya",
                "Baba Mamadi Dian\u00e9",
                "Solo Farabado Ciss\u00e9",
                "Djibrila Dian\u00e9",
                "Abdoulaye Sow",
                "S\u00e9r\u00e9 Moussa Doumbouya",
                "Daouda Bangoura",
                "Fod\u00e9 Moriba Bayo",
                "Ibrahima Sory 2. Cond\u00e9",
                "Kalo Mory Dian\u00e9",
                "Chris Piech",
                "Christopher Manning"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15612v3",
                "http://arxiv.org/pdf/2310.15612v3"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CY",
                "cs.HC",
                "cs.LG",
                "I.2.6; I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15610v1",
            "title": "Using Slisemap to interpret physical data",
            "updated": "2023-10-24T08:25:49Z",
            "published": "2023-10-24T08:25:49Z",
            "summary": "Manifold visualisation techniques are commonly used to visualise\nhigh-dimensional datasets in physical sciences. In this paper we apply a\nrecently introduced manifold visualisation method, called Slise, on datasets\nfrom physics and chemistry. Slisemap combines manifold visualisation with\nexplainable artificial intelligence. Explainable artificial intelligence is\nused to investigate the decision processes of black box machine learning models\nand complex simulators. With Slisemap we find an embedding such that data items\nwith similar local explanations are grouped together. Hence, Slisemap gives us\nan overview of the different behaviours of a black box model. This makes\nSlisemap into a supervised manifold visualisation method, where the patterns in\nthe embedding reflect a target property. In this paper we show how Slisemap can\nbe used and evaluated on physical data and that Slisemap is helpful in finding\nmeaningful information on classification and regression models trained on these\ndatasets.",
            "author": [
                "Lauri Sepp\u00e4l\u00e4inen",
                "Anton Bj\u00f6rklund",
                "Vitus Besel",
                "Kai Puolam\u00e4ki"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15610v1",
                "http://arxiv.org/pdf/2310.15610v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15605v1",
            "title": "tagE: Enabling an Embodied Agent to Understand Human Instructions",
            "updated": "2023-10-24T08:17:48Z",
            "published": "2023-10-24T08:17:48Z",
            "summary": "Natural language serves as the primary mode of communication when an\nintelligent agent with a physical presence engages with human beings. While a\nplethora of research focuses on natural language understanding (NLU),\nencompassing endeavors such as sentiment analysis, intent prediction, question\nanswering, and summarization, the scope of NLU directed at situations\nnecessitating tangible actions by an embodied agent remains limited. The\ninherent ambiguity and incompleteness inherent in natural language present\nchallenges for intelligent agents striving to decipher human intention. To\ntackle this predicament head-on, we introduce a novel system known as task and\nargument grounding for Embodied agents (tagE). At its core, our system employs\nan inventive neural network model designed to extract a series of tasks from\ncomplex task instructions expressed in natural language. Our proposed model\nadopts an encoder-decoder framework enriched with nested decoding to\neffectively extract tasks and their corresponding arguments from these\nintricate instructions. These extracted tasks are then mapped (or grounded) to\nthe robot's established collection of skills, while the arguments find\ngrounding in objects present within the environment. To facilitate the training\nand evaluation of our system, we have curated a dataset featuring complex\ninstructions. The results of our experiments underscore the prowess of our\napproach, as it outperforms robust baseline models.",
            "author": [
                "Chayan Sarkar",
                "Avik Mitra",
                "Pradip Pramanick",
                "Tapas Nayak"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15605v1",
                "http://arxiv.org/pdf/2310.15605v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15597v1",
            "title": "Emergent Communication in Interactive Sketch Question Answering",
            "updated": "2023-10-24T08:00:20Z",
            "published": "2023-10-24T08:00:20Z",
            "summary": "Vision-based emergent communication (EC) aims to learn to communicate through\nsketches and demystify the evolution of human communication. Ironically,\nprevious works neglect multi-round interaction, which is indispensable in human\ncommunication. To fill this gap, we first introduce a novel Interactive Sketch\nQuestion Answering (ISQA) task, where two collaborative players are interacting\nthrough sketches to answer a question about an image in a multi-round manner.\nTo accomplish this task, we design a new and efficient interactive EC system,\nwhich can achieve an effective balance among three evaluation factors,\nincluding the question answering accuracy, drawing complexity and human\ninterpretability. Our experimental results including human evaluation\ndemonstrate that multi-round interactive mechanism facilitates targeted and\nefficient communication between intelligent agents with decent human\ninterpretability.",
            "author": [
                "Zixing Lei",
                "Yiming Zhang",
                "Yuxin Xiong",
                "Siheng Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15597v1",
                "http://arxiv.org/pdf/2310.15597v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15594v1",
            "title": "Retrieval-based Knowledge Transfer: An Effective Approach for Extreme\n  Large Language Model Compression",
            "updated": "2023-10-24T07:58:20Z",
            "published": "2023-10-24T07:58:20Z",
            "summary": "Large-scale pre-trained language models (LLMs) have demonstrated exceptional\nperformance in various natural language processing (NLP) tasks. However, the\nmassive size of these models poses huge challenges for their deployment in\nreal-world applications. While numerous model compression techniques have been\nproposed, most of them are not well-suited for achieving extreme model\ncompression when there is a significant gap in model scale. In this paper, we\nintroduce a novel compression paradigm called Retrieval-based Knowledge\nTransfer (RetriKT), which effectively transfers the knowledge of LLMs to\nextremely small-scale models (e.g., 1%). In particular, our approach extracts\nknowledge from LLMs to construct a knowledge store, from which the small-scale\nmodel can retrieve relevant information and leverage it for effective\ninference. To improve the quality of the model, soft prompt tuning and Proximal\nPolicy Optimization (PPO) reinforcement learning techniques are employed.\nExtensive experiments are conducted on low-resource tasks from SuperGLUE and\nGLUE benchmarks. The results demonstrate that the proposed approach\nsignificantly enhances the performance of small-scale models by leveraging the\nknowledge from LLMs.",
            "author": [
                "Jiduan Liu",
                "Jiahao Liu",
                "Qifan Wang",
                "Jingang Wang",
                "Xunliang Cai",
                "Dongyan Zhao",
                "Ran Lucien Wang",
                "Rui Yan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15594v1",
                "http://arxiv.org/pdf/2310.15594v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15593v1",
            "title": "RecipeMeta: Metapath-enhanced Recipe Recommendation on Heterogeneous\n  Recipe Network",
            "updated": "2023-10-24T07:58:14Z",
            "published": "2023-10-24T07:58:14Z",
            "summary": "Recipe is a set of instructions that describes how to make food. It can help\npeople from the preparation of ingredients, food cooking process, etc. to\nprepare the food, and increasingly in demand on the Web. To help users find the\nvast amount of recipes on the Web, we address the task of recipe\nrecommendation. Due to multiple data types and relationships in a recipe, we\ncan treat it as a heterogeneous network to describe its information more\naccurately. To effectively utilize the heterogeneous network, metapath was\nproposed to describe the higher-level semantic information between two entities\nby defining a compound path from peer entities. Therefore, we propose a\nmetapath-enhanced recipe recommendation framework, RecipeMeta, that combines\nGNN (Graph Neural Network)-based representation learning and specific\nmetapath-based information in a recipe to predict User-Recipe pairs for\nrecommendation. Through extensive experiments, we demonstrate that the proposed\nmodel, RecipeMeta, outperforms state-of-the-art methods for recipe\nrecommendation.",
            "author": [
                "Jialiang Shi",
                "Takahiro Komamizu",
                "Keisuke Doman",
                "Haruya Kyutoku",
                "Ichiro Ide"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15593v1",
                "http://arxiv.org/pdf/2310.15593v1"
            ],
            "primary_category": "cs.MM",
            "category": [
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15591v1",
            "title": "Machine-Learning-Based Non-Local Kinetic Energy Density Functional for\n  Simple Metals and Alloys",
            "updated": "2023-10-24T07:55:07Z",
            "published": "2023-10-24T07:55:07Z",
            "summary": "Developing an accurate kinetic energy density functional (KEDF) remains a\nmajor hurdle in orbital-free density functional theory. We propose a\nmachine-learning-based physical-constrained non-local (MPN) KEDF and implement\nit with the usage of the bulk-derived local pseudopotentials and plane wave\nbasis sets in the ABACUS package. The MPN KEDF is designed to satisfy three\nexact physical constraints: the scaling law of electron kinetic energy, the\nfree electron gas limit, and the non-negativity of Pauli energy density. The\nMPN KEDF is systematically tested for simple metals, including Li, Mg, Al, and\n59 alloys. We conclude that incorporating non-local information for designing\nnew KEDFs and obeying exact physical constraints are essential to improve the\naccuracy, transferability, and stability of ML-based KEDF. These results shed\nnew light on the construction of ML-based functionals.",
            "author": [
                "Liang Sun",
                "Mohan Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15591v1",
                "http://arxiv.org/pdf/2310.15591v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15587v1",
            "title": "ScanDL: A Diffusion Model for Generating Synthetic Scanpaths on Texts",
            "updated": "2023-10-24T07:52:19Z",
            "published": "2023-10-24T07:52:19Z",
            "summary": "Eye movements in reading play a crucial role in psycholinguistic research\nstudying the cognitive mechanisms underlying human language processing. More\nrecently, the tight coupling between eye movements and cognition has also been\nleveraged for language-related machine learning tasks such as the\ninterpretability, enhancement, and pre-training of language models, as well as\nthe inference of reader- and text-specific properties. However, scarcity of eye\nmovement data and its unavailability at application time poses a major\nchallenge for this line of research. Initially, this problem was tackled by\nresorting to cognitive models for synthesizing eye movement data. However, for\nthe sole purpose of generating human-like scanpaths, purely data-driven\nmachine-learning-based methods have proven to be more suitable. Following\nrecent advances in adapting diffusion processes to discrete data, we propose\nScanDL, a novel discrete sequence-to-sequence diffusion model that generates\nsynthetic scanpaths on texts. By leveraging pre-trained word representations\nand jointly embedding both the stimulus text and the fixation sequence, our\nmodel captures multi-modal interactions between the two inputs. We evaluate\nScanDL within- and across-dataset and demonstrate that it significantly\noutperforms state-of-the-art scanpath generation methods. Finally, we provide\nan extensive psycholinguistic analysis that underlines the model's ability to\nexhibit human-like reading behavior. Our implementation is made available at\nhttps://github.com/DiLi-Lab/ScanDL.",
            "author": [
                "Lena S. Bolliger",
                "David R. Reich",
                "Patrick Haller",
                "Deborah N. Jakobi",
                "Paul Prasse",
                "Lena A. J\u00e4ger"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15587v1",
                "http://arxiv.org/pdf/2310.15587v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15586v1",
            "title": "Detecting Intentional AIS Shutdown in Open Sea Maritime Surveillance\n  Using Self-Supervised Deep Learning",
            "updated": "2023-10-24T07:51:29Z",
            "published": "2023-10-24T07:51:29Z",
            "summary": "In maritime traffic surveillance, detecting illegal activities, such as\nillegal fishing or transshipment of illicit products is a crucial task of the\ncoastal administration. In the open sea, one has to rely on Automatic\nIdentification System (AIS) message transmitted by on-board transponders, which\nare captured by surveillance satellites. However, insincere vessels often\nintentionally shut down their AIS transponders to hide illegal activities. In\nthe open sea, it is very challenging to differentiate intentional AIS shutdowns\nfrom missing reception due to protocol limitations, bad weather conditions or\nrestricting satellite positions. This paper presents a novel approach for the\ndetection of abnormal AIS missing reception based on self-supervised deep\nlearning techniques and transformer models. Using historical data, the trained\nmodel predicts if a message should be received in the upcoming minute or not.\nAfterwards, the model reports on detected anomalies by comparing the prediction\nwith what actually happens. Our method can process AIS messages in real-time,\nin particular, more than 500 Millions AIS messages per month, corresponding to\nthe trajectories of more than 60 000 ships. The method is evaluated on 1-year\nof real-world data coming from four Norwegian surveillance satellites. Using\nrelated research results, we validated our method by rediscovering already\ndetected intentional AIS shutdowns.",
            "author": [
                "Pierre Bernab\u00e9",
                "Arnaud Gotlieb",
                "Bruno Legeard",
                "Dusica Marijan",
                "Frank Olaf Sem-Jacobsen",
                "Helge Spieker"
            ],
            "link": [
                "http://dx.doi.org/10.1109/TITS.2023.3322690",
                "http://arxiv.org/abs/2310.15586v1",
                "http://arxiv.org/pdf/2310.15586v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15585v1",
            "title": "Multimodal Representations for Teacher-Guided Compositional Visual\n  Reasoning",
            "updated": "2023-10-24T07:51:08Z",
            "published": "2023-10-24T07:51:08Z",
            "summary": "Neural Module Networks (NMN) are a compelling method for visual question\nanswering, enabling the translation of a question into a program consisting of\na series of reasoning sub-tasks that are sequentially executed on the image to\nproduce an answer. NMNs provide enhanced explainability compared to integrated\nmodels, allowing for a better understanding of the underlying reasoning\nprocess. To improve the effectiveness of NMNs we propose to exploit features\nobtained by a large-scale cross-modal encoder. Also, the current training\napproach of NMNs relies on the propagation of module outputs to subsequent\nmodules, leading to the accumulation of prediction errors and the generation of\nfalse answers. To mitigate this, we introduce an NMN learning strategy\ninvolving scheduled teacher guidance. Initially, the model is fully guided by\nthe ground-truth intermediate outputs, but gradually transitions to an\nautonomous behavior as training progresses. This reduces error accumulation,\nthus improving training efficiency and final performance.We demonstrate that by\nincorporating cross-modal features and employing more effective training\ntechniques for NMN, we achieve a favorable balance between performance and\ntransparency in the reasoning process.",
            "author": [
                "Wafa Aissa",
                "Marin Ferecatu",
                "Michel Crucianu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15585v1",
                "http://arxiv.org/pdf/2310.15585v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15584v1",
            "title": "Accelerating Split Federated Learning over Wireless Communication\n  Networks",
            "updated": "2023-10-24T07:49:56Z",
            "published": "2023-10-24T07:49:56Z",
            "summary": "The development of artificial intelligence (AI) provides opportunities for\nthe promotion of deep neural network (DNN)-based applications. However, the\nlarge amount of parameters and computational complexity of DNN makes it\ndifficult to deploy it on edge devices which are resource-constrained. An\nefficient method to address this challenge is model partition/splitting, in\nwhich DNN is divided into two parts which are deployed on device and server\nrespectively for co-training or co-inference. In this paper, we consider a\nsplit federated learning (SFL) framework that combines the parallel model\ntraining mechanism of federated learning (FL) and the model splitting structure\nof split learning (SL). We consider a practical scenario of heterogeneous\ndevices with individual split points of DNN. We formulate a joint problem of\nsplit point selection and bandwidth allocation to minimize the system latency.\nBy using alternating optimization, we decompose the problem into two\nsub-problems and solve them optimally. Experiment results demonstrate the\nsuperiority of our work in latency reduction and accuracy improvement.",
            "author": [
                "Ce Xu",
                "Jinxuan Li",
                "Yuan Liu",
                "Yushi Ling",
                "Miaowen Wen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15584v1",
                "http://arxiv.org/pdf/2310.15584v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NI",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15583v1",
            "title": "Learning Agility and Adaptive Legged Locomotion via Curricular Hindsight\n  Reinforcement Learning",
            "updated": "2023-10-24T07:48:40Z",
            "published": "2023-10-24T07:48:40Z",
            "summary": "Agile and adaptive maneuvers such as fall recovery, high-speed turning, and\nsprinting in the wild are challenging for legged systems. We propose a\nCurricular Hindsight Reinforcement Learning (CHRL) that learns an end-to-end\ntracking controller that achieves powerful agility and adaptation for the\nlegged robot. The two key components are (I) a novel automatic curriculum\nstrategy on task difficulty and (ii) a Hindsight Experience Replay strategy\nadapted to legged locomotion tasks. We demonstrated successful agile and\nadaptive locomotion on a real quadruped robot that performed fall recovery\nautonomously, coherent trotting, sustained outdoor speeds up to 3.45 m/s, and\ntuning speeds up to 3.2 rad/s. This system produces adaptive behaviours\nresponding to changing situations and unexpected disturbances on natural\nterrains like grass and dirt.",
            "author": [
                "Sicen Li",
                "Yiming Pang",
                "Panju Bai",
                "Zhaojin Liu",
                "Jiawei Li",
                "Shihao Hu",
                "Liquan Wang",
                "Gang Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15583v1",
                "http://arxiv.org/pdf/2310.15583v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15581v2",
            "title": "Deep ReLU neural networks overcome the curse of dimensionality when\n  approximating semilinear partial integro-differential equations",
            "updated": "2023-10-26T14:22:49Z",
            "published": "2023-10-24T07:46:38Z",
            "summary": "In this paper we consider PIDEs with gradient-independent Lipschitz\ncontinuous nonlinearities and prove that deep neural networks with ReLU\nactivation function can approximate solutions of such semilinear PIDEs without\ncurse of dimensionality in the sense that the required number of parameters in\nthe deep neural networks increases at most polynomially in both the dimension $\nd $ of the corresponding PIDE and the reciprocal of the prescribed accuracy\n$\\epsilon $.",
            "author": [
                "Ariel Neufeld",
                "Tuan Anh Nguyen",
                "Sizhou Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15581v2",
                "http://arxiv.org/pdf/2310.15581v2"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA",
                "math.AP",
                "math.PR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15580v1",
            "title": "Identifiable Latent Polynomial Causal Models Through the Lens of Change",
            "updated": "2023-10-24T07:46:10Z",
            "published": "2023-10-24T07:46:10Z",
            "summary": "Causal representation learning aims to unveil latent high-level causal\nrepresentations from observed low-level data. One of its primary tasks is to\nprovide reliable assurance of identifying these latent causal models, known as\nidentifiability. A recent breakthrough explores identifiability by leveraging\nthe change of causal influences among latent causal variables across multiple\nenvironments \\citep{liu2022identifying}. However, this progress rests on the\nassumption that the causal relationships among latent causal variables adhere\nstrictly to linear Gaussian models. In this paper, we extend the scope of\nlatent causal models to involve nonlinear causal relationships, represented by\npolynomial models, and general noise distributions conforming to the\nexponential family. Additionally, we investigate the necessity of imposing\nchanges on all causal parameters and present partial identifiability results\nwhen part of them remains unchanged. Further, we propose a novel empirical\nestimation method, grounded in our theoretical finding, that enables learning\nconsistent latent causal representations. Our experimental results, obtained\nfrom both synthetic and real-world data, validate our theoretical contributions\nconcerning identifiability and consistency.",
            "author": [
                "Yuhang Liu",
                "Zhen Zhang",
                "Dong Gong",
                "Mingming Gong",
                "Biwei Huang",
                "Anton van den Hengel",
                "Kun Zhang",
                "Javen Qinfeng Shi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15580v1",
                "http://arxiv.org/pdf/2310.15580v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15578v3",
            "title": "VMAF Re-implementation on PyTorch: Some Experimental Results",
            "updated": "2023-12-01T10:06:21Z",
            "published": "2023-10-24T07:42:04Z",
            "summary": "Based on the standard VMAF implementation we propose an implementation of\nVMAF using PyTorch framework. For this implementation comparisons with the\nstandard (libvmaf) show the discrepancy $\\lesssim 10^{-2}$ in VMAF units. We\ninvestigate gradients computation when using VMAF as an objective function and\ndemonstrate that training using this function does not result in ill-behaving\ngradients. The implementation is then used to train a preprocessing filter. It\nis demonstrated that its performance is superior to the unsharp masking filter.\nThe resulting filter is also easy for implementation and can be applied in\nvideo processing tasks for video copression improvement. This is confirmed by\nthe results of numerical experiments.",
            "author": [
                "Kirill Aistov",
                "Maxim Koroteev"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15578v3",
                "http://arxiv.org/pdf/2310.15578v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15577v1",
            "title": "CONTRASTE: Supervised Contrastive Pre-training With Aspect-based Prompts\n  For Aspect Sentiment Triplet Extraction",
            "updated": "2023-10-24T07:40:09Z",
            "published": "2023-10-24T07:40:09Z",
            "summary": "Existing works on Aspect Sentiment Triplet Extraction (ASTE) explicitly focus\non developing more efficient fine-tuning techniques for the task. Instead, our\nmotivation is to come up with a generic approach that can improve the\ndownstream performances of multiple ABSA tasks simultaneously. Towards this, we\npresent CONTRASTE, a novel pre-training strategy using CONTRastive learning to\nenhance the ASTE performance. While we primarily focus on ASTE, we also\ndemonstrate the advantage of our proposed technique on other ABSA tasks such as\nACOS, TASD, and AESC. Given a sentence and its associated (aspect, opinion,\nsentiment) triplets, first, we design aspect-based prompts with corresponding\nsentiments masked. We then (pre)train an encoder-decoder model by applying\ncontrastive learning on the decoder-generated aspect-aware sentiment\nrepresentations of the masked terms. For fine-tuning the model weights thus\nobtained, we then propose a novel multi-task approach where the base\nencoder-decoder model is combined with two complementary modules, a\ntagging-based Opinion Term Detector, and a regression-based Triplet Count\nEstimator. Exhaustive experiments on four benchmark datasets and a detailed\nablation study establish the importance of each of our proposed components as\nwe achieve new state-of-the-art ASTE results.",
            "author": [
                "Rajdeep Mukherjee",
                "Nithish Kannen",
                "Saurabh Kumar Pandey",
                "Pawan Goyal"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15577v1",
                "http://arxiv.org/pdf/2310.15577v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15576v5",
            "title": "A Near-Quadratic Sample Complexity Reduction for Agnostic Learning via\n  Quantum Algorithms",
            "updated": "2023-11-15T05:27:54Z",
            "published": "2023-10-24T07:39:16Z",
            "summary": "Using quantum algorithms, we obtain, for accuracy $\\epsilon>0$ and confidence\n$1-\\delta,0<\\delta <1,$ a new sample complexity upper bound of\n$O((\\mbox{log}(\\frac{1}{\\delta}))/\\epsilon)$ as $\\epsilon,\\delta\\rightarrow 0$\n(up to a polylogarithmic factor in $\\epsilon^{-1}$) for a general agnostic\nlearning model, provided the hypothesis class is of finite cardinality. This\ngreatly improves upon a corresponding sample complexity of asymptotic order\n$\\Theta((\\mbox{log}(\\frac{1}{\\delta}))/\\epsilon^{2})$ known in the literature\nto be attainable by means of classical (non-quantum) algorithms for an agnostic\nlearning problem also with hypothesis set of finite cardinality (see, for\nexample, Arunachalam and de Wolf (2018) and the classical statistical learning\ntheory references cited there). Thus, for general agnostic learning, the\nquantum speedup in the rate of learning that we achieve is quadratic in\n$\\epsilon^{-1}$ (up to a polylogarithmic factor).",
            "author": [
                "Daniel Z. Zanger"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15576v5",
                "http://arxiv.org/pdf/2310.15576v5"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15575v1",
            "title": "POE: Process of Elimination for Multiple Choice Reasoning",
            "updated": "2023-10-24T07:38:43Z",
            "published": "2023-10-24T07:38:43Z",
            "summary": "Language models (LMs) are capable of conducting in-context learning for\nmultiple choice reasoning tasks, but the options in these tasks are treated\nequally. As humans often first eliminate wrong options before picking the final\ncorrect answer, we argue a similar two-step strategy can make LMs better at\nthese tasks. To this end, we present the Process of Elimination (POE), a\ntwo-step scoring method. In the first step, POE scores each option, and\neliminates seemingly wrong options. In the second step, POE masks these wrong\noptions, and makes the final prediction from the remaining options. Zero-shot\nexperiments on 8 reasoning tasks illustrate the effectiveness of POE, and a\nfollowing analysis finds our method to be especially performant on logical\nreasoning tasks. We further analyze the effect of masks, and show that POE\napplies to few-shot settings and large language models (LLMs) like ChatGPT.",
            "author": [
                "Chenkai Ma",
                "Xinya Du"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15575v1",
                "http://arxiv.org/pdf/2310.15575v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15571v1",
            "title": "Visually Grounded Continual Language Learning with Selective\n  Specialization",
            "updated": "2023-10-24T07:35:23Z",
            "published": "2023-10-24T07:35:23Z",
            "summary": "A desirable trait of an artificial agent acting in the visual world is to\ncontinually learn a sequence of language-informed tasks while striking a\nbalance between sufficiently specializing in each task and building a\ngeneralized knowledge for transfer. Selective specialization, i.e., a careful\nselection of model components to specialize in each task, is a strategy to\nprovide control over this trade-off. However, the design of selection\nstrategies requires insights on the role of each model component in learning\nrather specialized or generalizable representations, which poses a gap in\ncurrent research. Thus, our aim with this work is to provide an extensive\nanalysis of selection strategies for visually grounded continual language\nlearning. Due to the lack of suitable benchmarks for this purpose, we introduce\ntwo novel diagnostic datasets that provide enough control and flexibility for a\nthorough model analysis. We assess various heuristics for module specialization\nstrategies as well as quantifiable measures for two different types of model\narchitectures. Finally, we design conceptually simple approaches based on our\nanalysis that outperform common continual learning baselines. Our results\ndemonstrate the need for further efforts towards better aligning continual\nlearning algorithms with the learning behaviors of individual model parts.",
            "author": [
                "Kyra Ahrens",
                "Lennart Bengtson",
                "Jae Hee Lee",
                "Stefan Wermter"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15571v1",
                "http://arxiv.org/pdf/2310.15571v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15568v1",
            "title": "I$^2$MD: 3D Action Representation Learning with Inter- and Intra-modal\n  Mutual Distillation",
            "updated": "2023-10-24T07:22:17Z",
            "published": "2023-10-24T07:22:17Z",
            "summary": "Recent progresses on self-supervised 3D human action representation learning\nare largely attributed to contrastive learning. However, in conventional\ncontrastive frameworks, the rich complementarity between different skeleton\nmodalities remains under-explored. Moreover, optimized with distinguishing\nself-augmented samples, models struggle with numerous similar positive\ninstances in the case of limited action categories. In this work, we tackle the\naforementioned problems by introducing a general Inter- and Intra-modal Mutual\nDistillation (I$^2$MD) framework. In I$^2$MD, we first re-formulate the\ncross-modal interaction as a Cross-modal Mutual Distillation (CMD) process.\nDifferent from existing distillation solutions that transfer the knowledge of a\npre-trained and fixed teacher to the student, in CMD, the knowledge is\ncontinuously updated and bidirectionally distilled between modalities during\npre-training. To alleviate the interference of similar samples and exploit\ntheir underlying contexts, we further design the Intra-modal Mutual\nDistillation (IMD) strategy, In IMD, the Dynamic Neighbors Aggregation (DNA)\nmechanism is first introduced, where an additional cluster-level discrimination\nbranch is instantiated in each modality. It adaptively aggregates\nhighly-correlated neighboring features, forming local cluster-level\ncontrasting. Mutual distillation is then performed between the two branches for\ncross-level knowledge exchange. Extensive experiments on three datasets show\nthat our approach sets a series of new records.",
            "author": [
                "Yunyao Mao",
                "Jiajun Deng",
                "Wengang Zhou",
                "Zhenbo Lu",
                "Wanli Ouyang",
                "Houqiang Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15568v1",
                "http://arxiv.org/pdf/2310.15568v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15559v1",
            "title": "From Oja's Algorithm to the Multiplicative Weights Update Method with\n  Applications",
            "updated": "2023-10-24T07:02:47Z",
            "published": "2023-10-24T07:02:47Z",
            "summary": "Oja's algorithm is a well known online algorithm studied mainly in the\ncontext of stochastic principal component analysis. We make a simple\nobservation, yet to the best of our knowledge a novel one, that when applied to\na any (not necessarily stochastic) sequence of symmetric matrices which share\ncommon eigenvectors, the regret of Oja's algorithm could be directly bounded in\nterms of the regret of the well known multiplicative weights update method for\nthe problem of prediction with expert advice. Several applications to\noptimization with quadratic forms over the unit sphere in $\\reals^n$ are\ndiscussed.",
            "author": [
                "Dan Garber"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15559v1",
                "http://arxiv.org/pdf/2310.15559v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15556v2",
            "title": "TCRA-LLM: Token Compression Retrieval Augmented Large Language Model for\n  Inference Cost Reduction",
            "updated": "2023-10-25T07:50:52Z",
            "published": "2023-10-24T06:56:38Z",
            "summary": "Since ChatGPT released its API for public use, the number of applications\nbuilt on top of commercial large language models (LLMs) increase exponentially.\nOne popular usage of such models is leveraging its in-context learning ability\nand generating responses given user queries leveraging knowledge obtained by\nretrieval augmentation. One problem of deploying commercial retrieval-augmented\nLLMs is the cost due to the additionally retrieved context that largely\nincreases the input token size of the LLMs. To mitigate this, we propose a\ntoken compression scheme that includes two methods: summarization compression\nand semantic compression. The first method applies a T5-based model that is\nfine-tuned by datasets generated using self-instruct containing samples with\nvarying lengths and reduce token size by doing summarization. The second method\nfurther compresses the token size by removing words with lower impact on the\nsemantic. In order to adequately evaluate the effectiveness of the proposed\nmethods, we propose and utilize a dataset called Food-Recommendation DB (FRDB)\nfocusing on food recommendation for women around pregnancy period or infants.\nOur summarization compression can reduce 65% of the retrieval token size with\nfurther 0.3% improvement on the accuracy; semantic compression provides a more\nflexible way to trade-off the token size with performance, for which we can\nreduce the token size by 20% with only 1.6% of accuracy drop.",
            "author": [
                "Junyi Liu",
                "Liangzhi Li",
                "Tong Xiang",
                "Bowen Wang",
                "Yiming Qian"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15556v2",
                "http://arxiv.org/pdf/2310.15556v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15555v1",
            "title": "Transfer learning for day-ahead load forecasting: a case study on\n  European national electricity demand time series",
            "updated": "2023-10-24T06:54:50Z",
            "published": "2023-10-24T06:54:50Z",
            "summary": "Short-term load forecasting (STLF) is crucial for the daily operation of\npower grids. However, the non-linearity, non-stationarity, and randomness\ncharacterizing electricity demand time series renders STLF a challenging task.\nVarious forecasting approaches have been proposed for improving STLF, including\nneural network (NN) models which are trained using data from multiple\nelectricity demand series that may not necessary include the target series. In\nthe present study, we investigate the performance of this special case of STLF,\ncalled transfer learning (TL), by considering a set of 27 time series that\nrepresent the national day-ahead electricity demand of indicative European\ncountries. We employ a popular and easy-to-implement NN model and perform a\nclustering analysis to identify similar patterns among the series and assist\nTL. In this context, two different TL approaches, with and without the\nclustering step, are compiled and compared against each other as well as a\ntypical NN training setup. Our results demonstrate that TL can outperform the\nconventional approach, especially when clustering techniques are considered.",
            "author": [
                "Alexandros-Menelaos Tzortzis",
                "Sotiris Pelekis",
                "Evangelos Spiliotis",
                "Spiros Mouzakitis",
                "John Psarras",
                "Dimitris Askounis"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15555v1",
                "http://arxiv.org/pdf/2310.15555v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15552v1",
            "title": "Unveiling Multilinguality in Transformer Models: Exploring Language\n  Specificity in Feed-Forward Networks",
            "updated": "2023-10-24T06:45:00Z",
            "published": "2023-10-24T06:45:00Z",
            "summary": "Recent research suggests that the feed-forward module within Transformers can\nbe viewed as a collection of key-value memories, where the keys learn to\ncapture specific patterns from the input based on the training examples. The\nvalues then combine the output from the 'memories' of the keys to generate\npredictions about the next token. This leads to an incremental process of\nprediction that gradually converges towards the final token choice near the\noutput layers. This interesting perspective raises questions about how\nmultilingual models might leverage this mechanism. Specifically, for\nautoregressive models trained on two or more languages, do all neurons (across\nlayers) respond equally to all languages? No! Our hypothesis centers around the\nnotion that during pretraining, certain model parameters learn strong\nlanguage-specific features, while others learn more language-agnostic (shared\nacross languages) features. To validate this, we conduct experiments utilizing\nparallel corpora of two languages that the model was initially pretrained on.\nOur findings reveal that the layers closest to the network's input or output\ntend to exhibit more language-specific behaviour compared to the layers in the\nmiddle.",
            "author": [
                "Sunit Bhattacharya",
                "Ondrej Bojar"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15552v1",
                "http://arxiv.org/pdf/2310.15552v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15550v1",
            "title": "PET Synthesis via Self-supervised Adaptive Residual Estimation\n  Generative Adversarial Network",
            "updated": "2023-10-24T06:43:56Z",
            "published": "2023-10-24T06:43:56Z",
            "summary": "Positron emission tomography (PET) is a widely used, highly sensitive\nmolecular imaging in clinical diagnosis. There is interest in reducing the\nradiation exposure from PET but also maintaining adequate image quality. Recent\nmethods using convolutional neural networks (CNNs) to generate synthesized\nhigh-quality PET images from low-dose counterparts have been reported to be\nstate-of-the-art for low-to-high image recovery methods. However, these methods\nare prone to exhibiting discrepancies in texture and structure between\nsynthesized and real images. Furthermore, the distribution shift between\nlow-dose PET and standard PET has not been fully investigated. To address these\nissues, we developed a self-supervised adaptive residual estimation generative\nadversarial network (SS-AEGAN). We introduce (1) An adaptive residual\nestimation mapping mechanism, AE-Net, designed to dynamically rectify the\npreliminary synthesized PET images by taking the residual map between the\nlow-dose PET and synthesized output as the input, and (2) A self-supervised\npre-training strategy to enhance the feature representation of the coarse\ngenerator. Our experiments with a public benchmark dataset of total-body PET\nimages show that SS-AEGAN consistently outperformed the state-of-the-art\nsynthesis methods with various dose reduction factors.",
            "author": [
                "Yuxin Xue",
                "Lei Bi",
                "Yige Peng",
                "Michael Fulham",
                "David Dagan Feng",
                "Jinman Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15550v1",
                "http://arxiv.org/pdf/2310.15550v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15549v1",
            "title": "Algorithmic Regularization in Tensor Optimization: Towards a Lifted\n  Approach in Matrix Sensing",
            "updated": "2023-10-24T06:40:26Z",
            "published": "2023-10-24T06:40:26Z",
            "summary": "Gradient descent (GD) is crucial for generalization in machine learning\nmodels, as it induces implicit regularization, promoting compact\nrepresentations. In this work, we examine the role of GD in inducing implicit\nregularization for tensor optimization, particularly within the context of the\nlifted matrix sensing framework. This framework has been recently proposed to\naddress the non-convex matrix sensing problem by transforming spurious\nsolutions into strict saddles when optimizing over symmetric, rank-1 tensors.\nWe show that, with sufficiently small initialization scale, GD applied to this\nlifted problem results in approximate rank-1 tensors and critical points with\nescape directions. Our findings underscore the significance of the tensor\nparametrization of matrix sensing, in combination with first-order methods, in\nachieving global optimality in such problems.",
            "author": [
                "Ziye Ma",
                "Javad Lavaei",
                "Somayeh Sojoudi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15549v1",
                "http://arxiv.org/pdf/2310.15549v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15548v2",
            "title": "Knowledge-driven Meta-learning for CSI Feedback",
            "updated": "2023-10-25T04:15:56Z",
            "published": "2023-10-24T06:40:18Z",
            "summary": "Accurate and effective channel state information (CSI) feedback is a key\ntechnology for massive multiple-input and multiple-output systems. Recently,\ndeep learning (DL) has been introduced for CSI feedback enhancement through\nmassive collected training data and lengthy training time, which is quite\ncostly and impractical for realistic deployment. In this article, a\nknowledge-driven meta-learning approach is proposed, where the DL model\ninitialized by the meta model obtained from meta training phase is able to\nachieve rapid convergence when facing a new scenario during target retraining\nphase. Specifically, instead of training with massive data collected from\nvarious scenarios, the meta task environment is constructed based on the\nintrinsic knowledge of spatial-frequency characteristics of CSI for meta\ntraining. Moreover, the target task dataset is also augmented by exploiting the\nknowledge of statistical characteristics of wireless channel, so that the DL\nmodel can achieve higher performance with small actually collected dataset and\nshort training time. In addition, we provide analyses of rationale for the\nimprovement yielded by the knowledge in both phases. Simulation results\ndemonstrate the superiority of the proposed approach from the perspective of\nfeedback performance and convergence speed.",
            "author": [
                "Han Xiao",
                "Wenqiang Tian",
                "Wendong Liu",
                "Jiajia Guo",
                "Zhi Zhang",
                "Shi Jin",
                "Zhihua Shi",
                "Li Guo",
                "Jia Shen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15548v2",
                "http://arxiv.org/pdf/2310.15548v2"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16061v1",
            "title": "Segue: Side-information Guided Generative Unlearnable Examples for\n  Facial Privacy Protection in Real World",
            "updated": "2023-10-24T06:22:37Z",
            "published": "2023-10-24T06:22:37Z",
            "summary": "The widespread use of face recognition technology has given rise to privacy\nconcerns, as many individuals are worried about the collection and utilization\nof their facial data. To address these concerns, researchers are actively\nexploring the concept of ``unlearnable examples\", by adding imperceptible\nperturbation to data in the model training stage, which aims to prevent the\nmodel from learning discriminate features of the target face. However, current\nmethods are inefficient and cannot guarantee transferability and robustness at\nthe same time, causing impracticality in the real world. To remedy it, we\npropose a novel method called Segue: Side-information guided generative\nunlearnable examples. Specifically, we leverage a once-trained multiple-used\nmodel to generate the desired perturbation rather than the time-consuming\ngradient-based method. To improve transferability, we introduce side\ninformation such as true labels and pseudo labels, which are inherently\nconsistent across different scenarios. For robustness enhancement, a distortion\nlayer is integrated into the training pipeline. Extensive experiments\ndemonstrate that the proposed Segue is much faster than previous methods\n(1000$\\times$) and achieves transferable effectiveness across different\ndatasets and model architectures. Furthermore, it can resist JPEG compression,\nadversarial training, and some standard data augmentations.",
            "author": [
                "Zhiling Zhang",
                "Jie Zhang",
                "Kui Zhang",
                "Wenbo Zhou",
                "Weiming Zhang",
                "Nenghai Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16061v1",
                "http://arxiv.org/pdf/2310.16061v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15543v2",
            "title": "Symmetry-preserving graph attention network to solve routing problems at\n  multiple resolutions",
            "updated": "2023-11-19T22:24:59Z",
            "published": "2023-10-24T06:22:20Z",
            "summary": "Travelling Salesperson Problems (TSPs) and Vehicle Routing Problems (VRPs)\nhave achieved reasonable improvement in accuracy and computation time with the\nadaptation of Machine Learning (ML) methods. However, none of the previous\nworks completely respects the symmetries arising from TSPs and VRPs including\nrotation, translation, permutation, and scaling. In this work, we introduce the\nfirst-ever completely equivariant model and training to solve combinatorial\nproblems. Furthermore, it is essential to capture the multiscale structure\n(i.e. from local to global information) of the input graph, especially for the\ncases of large and long-range graphs, while previous methods are limited to\nextracting only local information that can lead to a local or sub-optimal\nsolution. To tackle the above limitation, we propose a Multiresolution scheme\nin combination with Equivariant Graph Attention network (mEGAT) architecture,\nwhich can learn the optimal route based on low-level and high-level graph\nresolutions in an efficient way. In particular, our approach constructs a\nhierarchy of coarse-graining graphs from the input graph, in which we try to\nsolve the routing problems on simple low-level graphs first, then utilize that\nknowledge for the more complex high-level graphs. Experimentally, we have shown\nthat our model outperforms existing baselines and proved that symmetry\npreservation and multiresolution are important recipes for solving\ncombinatorial problems in a data-driven manner. Our source code is publicly\navailable at https://github.com/HySonLab/Multires-NP-hard",
            "author": [
                "Cong Dao Tran",
                "Thong Bach",
                "Truong Son Hy"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15543v2",
                "http://arxiv.org/pdf/2310.15543v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18359v1",
            "title": "DeSIQ: Towards an Unbiased, Challenging Benchmark for Social\n  Intelligence Understanding",
            "updated": "2023-10-24T06:21:34Z",
            "published": "2023-10-24T06:21:34Z",
            "summary": "Social intelligence is essential for understanding and reasoning about human\nexpressions, intents and interactions. One representative benchmark for its\nstudy is Social Intelligence Queries (Social-IQ), a dataset of multiple-choice\nquestions on videos of complex social interactions. We define a comprehensive\nmethodology to study the soundness of Social-IQ, as the soundness of such\nbenchmark datasets is crucial to the investigation of the underlying research\nproblem. Our analysis reveals that Social-IQ contains substantial biases, which\ncan be exploited by a moderately strong language model to learn spurious\ncorrelations to achieve perfect performance without being given the context or\neven the question. We introduce DeSIQ, a new challenging dataset, constructed\nby applying simple perturbations to Social-IQ. Our empirical analysis shows\nDeSIQ significantly reduces the biases in the original Social-IQ dataset.\nFurthermore, we examine and shed light on the effect of model size, model\nstyle, learning settings, commonsense knowledge, and multi-modality on the new\nbenchmark performance. Our new dataset, observations and findings open up\nimportant research questions for the study of social intelligence.",
            "author": [
                "Xiao-Yu Guo",
                "Yuan-Fang Li",
                "Gholamreza Haffari"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18359v1",
                "http://arxiv.org/pdf/2310.18359v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15541v1",
            "title": "Improving Language Models Meaning Understanding and Consistency by\n  Learning Conceptual Roles from Dictionary",
            "updated": "2023-10-24T06:15:15Z",
            "published": "2023-10-24T06:15:15Z",
            "summary": "The non-humanlike behaviour of contemporary pre-trained language models\n(PLMs) is a leading cause undermining their trustworthiness. A striking\nphenomenon of such faulty behaviours is the generation of inconsistent\npredictions, which produces logically contradictory results, such as generating\ndifferent predictions for texts delivering the same meaning or violating\nlogical properties. Previous studies exploited data augmentation or implemented\nspecialised loss functions to alleviate the issue. However, their usage is\nlimited, because they consume expensive training resources for large-sized PLMs\nand can only handle a certain consistency type. To this end, we propose a\npractical approach that alleviates the inconsistent behaviour issue by\nfundamentally improving PLMs' meaning awareness. Based on the conceptual role\ntheory, our method allows PLMs to capture accurate meaning by learning precise\ninterrelationships between concepts from word-definition pairs in a dictionary.\nNext, we propose an efficient parameter integration technique that updates only\na few additional parameters to combine the learned interrelationship with PLMs'\npre-trained knowledge. Our experimental results reveal that the approach can\nconcurrently improve multiple types of consistency, enables efficient knowledge\nintegration, and easily applies to other languages.",
            "author": [
                "Myeongjun Erik Jang",
                "Thomas Lukasiewicz"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15541v1",
                "http://arxiv.org/pdf/2310.15541v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15539v1",
            "title": "SteloCoder: a Decoder-Only LLM for Multi-Language to Python Code\n  Translation",
            "updated": "2023-10-24T06:04:28Z",
            "published": "2023-10-24T06:04:28Z",
            "summary": "With the recent focus on Large Language Models (LLMs), both StarCoder (Li et\nal., 2023) and Code Llama (Rozi\\`ere et al., 2023) have demonstrated remarkable\nperformance in code generation. However, there is still a need for improvement\nin code translation functionality with efficient training techniques. In\nresponse to this, we introduce SteloCoder, a decoder-only StarCoder-based LLM\ndesigned specifically for multi-programming language-to-Python code\ntranslation. In particular, SteloCoder achieves C++, C#, JavaScript, Java, or\nPHP-to-Python code translation without specifying the input programming\nlanguage. We modified StarCoder model architecture by incorporating a\nMixture-of-Experts (MoE) technique featuring five experts and a gating network\nfor multi-task handling. Experts are obtained by StarCoder fine-tuning.\nSpecifically, we use a Low-Rank Adaptive Method (LoRA) technique, limiting each\nexpert size as only 0.06% of number of StarCoder's parameters. At the same\ntime, to enhance training efficiency in terms of time, we adopt curriculum\nlearning strategy and use self-instruct data for efficient fine-tuning. As a\nresult, each expert takes only 6 hours to train on one single 80Gb A100 HBM.\nWith experiments on XLCoST datasets, SteloCoder achieves an average of 73.76\nCodeBLEU score in multi-programming language-to-Python translation, surpassing\nthe top performance from the leaderboard by at least 3.5. This accomplishment\nis attributed to only 45M extra parameters with StarCoder as the backbone and\n32 hours of valid training on one 80GB A100 HBM. The source code is release\nhere: https://github.com/sade-adrien/SteloCoder.",
            "author": [
                "Jialing Pan",
                "Adrien Sad\u00e9",
                "Jin Kim",
                "Eric Soriano",
                "Guillem Sole",
                "Sylvain Flamant"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15539v1",
                "http://arxiv.org/pdf/2310.15539v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15533v1",
            "title": "Learning with Noisy Labels Using Collaborative Sample Selection and\n  Contrastive Semi-Supervised Learning",
            "updated": "2023-10-24T05:37:20Z",
            "published": "2023-10-24T05:37:20Z",
            "summary": "Learning with noisy labels (LNL) has been extensively studied, with existing\napproaches typically following a framework that alternates between clean sample\nselection and semi-supervised learning (SSL). However, this approach has a\nlimitation: the clean set selected by the Deep Neural Network (DNN) classifier,\ntrained through self-training, inevitably contains noisy samples. This mixture\nof clean and noisy samples leads to misguidance in DNN training during SSL,\nresulting in impaired generalization performance due to confirmation bias\ncaused by error accumulation in sample selection. To address this issue, we\npropose a method called Collaborative Sample Selection (CSS), which leverages\nthe large-scale pre-trained model CLIP. CSS aims to remove the mixed noisy\nsamples from the identified clean set. We achieve this by training a\n2-Dimensional Gaussian Mixture Model (2D-GMM) that combines the probabilities\nfrom CLIP with the predictions from the DNN classifier. To further enhance the\nadaptation of CLIP to LNL, we introduce a co-training mechanism with a\ncontrastive loss in semi-supervised learning. This allows us to jointly train\nthe prompt of CLIP and the DNN classifier, resulting in improved feature\nrepresentation, boosted classification performance of DNNs, and reciprocal\nbenefits to our Collaborative Sample Selection. By incorporating auxiliary\ninformation from CLIP and utilizing prompt fine-tuning, we effectively\neliminate noisy samples from the clean set and mitigate confirmation bias\nduring training. Experimental results on multiple benchmark datasets\ndemonstrate the effectiveness of our proposed method in comparison with the\nstate-of-the-art approaches.",
            "author": [
                "Qing Miao",
                "Xiaohe Wu",
                "Chao Xu",
                "Yanli Ji",
                "Wangmeng Zuo",
                "Yiwen Guo",
                "Zhaopeng Meng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15533v1",
                "http://arxiv.org/pdf/2310.15533v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15532v1",
            "title": "Role of sea quarks in the nucleon transverse spin",
            "updated": "2023-10-24T05:36:53Z",
            "published": "2023-10-24T05:36:53Z",
            "summary": "We present a phenomenological extraction of transversity distribution\nfunctions and Collins fragmentation functions by simultaneously fitting to\nsemi-inclusive deep inelastic scattering and electron-positron annihilation\ndata. The analysis is performed within the transverse momentum dependent\nfactorization formalism, and sea quark transversity distributions are taken\ninto account for the first time. We find the $\\bar u$ quark favors a negative\ntransversity distribution while that of the $\\bar d$ quark is consistent with\nzero according to the current accuracy. In addition, based on a combined\nanalysis of world data and simulated data, we quantitatively demonstrate the\nimpact of the proposed Electron-ion Collider in China on precise determinations\nof the transversity distributions, especially for sea quarks, and the Collins\nfragmentation functions.",
            "author": [
                "Chunhua Zeng",
                "Hongxin Dong",
                "Tianbo Liu",
                "Peng Sun",
                "Yuxiang Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15532v1",
                "http://arxiv.org/pdf/2310.15532v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15526v1",
            "title": "Privacy Amplification for Matrix Mechanisms",
            "updated": "2023-10-24T05:16:52Z",
            "published": "2023-10-24T05:16:52Z",
            "summary": "Privacy amplification exploits randomness in data selection to provide\ntighter differential privacy (DP) guarantees. This analysis is key to DP-SGD's\nsuccess in machine learning, but, is not readily applicable to the newer\nstate-of-the-art algorithms. This is because these algorithms, known as\nDP-FTRL, use the matrix mechanism to add correlated noise instead of\nindependent noise as in DP-SGD.\n  In this paper, we propose \"MMCC\", the first algorithm to analyze privacy\namplification via sampling for any generic matrix mechanism. MMCC is nearly\ntight in that it approaches a lower bound as $\\epsilon\\to0$. To analyze\ncorrelated outputs in MMCC, we prove that they can be analyzed as if they were\nindependent, by conditioning them on prior outputs. Our \"conditional\ncomposition theorem\" has broad utility: we use it to show that the noise added\nto binary-tree-DP-FTRL can asymptotically match the noise added to DP-SGD with\namplification. Our amplification algorithm also has practical empirical\nutility: we show it leads to significant improvement in the privacy-utility\ntrade-offs for DP-FTRL algorithms on standard benchmarks.",
            "author": [
                "Christopher A. Choquette-Choo",
                "Arun Ganesh",
                "Thomas Steinke",
                "Abhradeep Thakurta"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15526v1",
                "http://arxiv.org/pdf/2310.15526v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15524v1",
            "title": "On the Inherent Privacy Properties of Discrete Denoising Diffusion\n  Models",
            "updated": "2023-10-24T05:07:31Z",
            "published": "2023-10-24T05:07:31Z",
            "summary": "Privacy concerns have led to a surge in the creation of synthetic datasets,\nwith diffusion models emerging as a promising avenue. Although prior studies\nhave performed empirical evaluations on these models, there has been a gap in\nproviding a mathematical characterization of their privacy-preserving\ncapabilities. To address this, we present the pioneering theoretical\nexploration of the privacy preservation inherent in discrete diffusion models\n(DDMs) for discrete dataset generation. Focusing on per-instance differential\nprivacy (pDP), our framework elucidates the potential privacy leakage for each\ndata point in a given training dataset, offering insights into data\npreprocessing to reduce privacy risks of the synthetic dataset generation via\nDDMs. Our bounds also show that training with $s$-sized data points leads to a\nsurge in privacy leakage from $(\\epsilon,\n\\mathcal{O}(\\frac{1}{s^2\\epsilon}))$-pDP to $(\\epsilon,\n\\mathcal{O}(\\frac{1}{s\\epsilon}))$-pDP during the transition from the pure\nnoise to the synthetic clean data phase, and a faster decay in diffusion\ncoefficients amplifies the privacy guarantee. Finally, we empirically verify\nour theoretical findings on both synthetic and real-world datasets.",
            "author": [
                "Rongzhe Wei",
                "Eleonora Krea\u010di\u0107",
                "Haoyu Wang",
                "Haoteng Yin",
                "Eli Chien",
                "Vamsi K. Potluru",
                "Pan Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15524v1",
                "http://arxiv.org/pdf/2310.15524v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15523v1",
            "title": "Generative and Contrastive Paradigms Are Complementary for Graph\n  Self-Supervised Learning",
            "updated": "2023-10-24T05:06:06Z",
            "published": "2023-10-24T05:06:06Z",
            "summary": "For graph self-supervised learning (GSSL), masked autoencoder (MAE) follows\nthe generative paradigm and learns to reconstruct masked graph edges or node\nfeatures. Contrastive Learning (CL) maximizes the similarity between augmented\nviews of the same graph and is widely used for GSSL. However, MAE and CL are\nconsidered separately in existing works for GSSL. We observe that the MAE and\nCL paradigms are complementary and propose the graph contrastive masked\nautoencoder (GCMAE) framework to unify them. Specifically, by focusing on local\nedges or node features, MAE cannot capture global information of the graph and\nis sensitive to particular edges and features. On the contrary, CL excels in\nextracting global information because it considers the relation between graphs.\nAs such, we equip GCMAE with an MAE branch and a CL branch, and the two\nbranches share a common encoder, which allows the MAE branch to exploit the\nglobal information extracted by the CL branch. To force GCMAE to capture global\ngraph structures, we train it to reconstruct the entire adjacency matrix\ninstead of only the masked edges as in existing works. Moreover, a\ndiscrimination loss is proposed for feature reconstruction, which improves the\ndisparity between node embeddings rather than reducing the reconstruction error\nto tackle the feature smoothing problem of MAE. We evaluate GCMAE on four\npopular graph tasks (i.e., node classification, node clustering, link\nprediction, and graph classification) and compare with 14 state-of-the-art\nbaselines. The results show that GCMAE consistently provides good accuracy\nacross these tasks, and the maximum accuracy improvement is up to 3.2% compared\nwith the best-performing baseline.",
            "author": [
                "Yuxiang Wang",
                "Xiao Yan",
                "Chuang Hu",
                "Fangcheng Fu",
                "Wentao Zhang",
                "Hao Wang",
                "Shuo Shang",
                "Jiawei Jiang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15523v1",
                "http://arxiv.org/pdf/2310.15523v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15516v2",
            "title": "Graph Attention-based Deep Reinforcement Learning for solving the\n  Chinese Postman Problem with Load-dependent costs",
            "updated": "2023-11-20T05:06:11Z",
            "published": "2023-10-24T04:50:32Z",
            "summary": "Recently, Deep reinforcement learning (DRL) models have shown promising\nresults in solving routing problems. However, most DRL solvers are commonly\nproposed to solve node routing problems, such as the Traveling Salesman Problem\n(TSP). Meanwhile, there has been limited research on applying neural methods to\narc routing problems, such as the Chinese Postman Problem (CPP), since they\noften feature irregular and complex solution spaces compared to TSP. To fill\nthese gaps, this paper proposes a novel DRL framework to address the CPP with\nload-dependent costs (CPP-LC) (Corberan et al., 2018), which is a complex arc\nrouting problem with load constraints. The novelty of our method is two-fold.\nFirst, we formulate the CPP-LC as a Markov Decision Process (MDP) sequential\nmodel. Subsequently, we introduce an autoregressive model based on DRL, namely\nArc-DRL, consisting of an encoder and decoder to address the CPP-LC challenge\neffectively. Such a framework allows the DRL model to work efficiently and\nscalably to arc routing problems. Furthermore, we propose a new bio-inspired\nmeta-heuristic solution based on Evolutionary Algorithm (EA) for CPP-LC.\nExtensive experiments show that Arc-DRL outperforms existing meta-heuristic\nmethods such as Iterative Local Search (ILS) and Variable Neighborhood Search\n(VNS) proposed by (Corberan et al., 2018) on large benchmark datasets for\nCPP-LC regarding both solution quality and running time; while the EA gives the\nbest solution quality with much more running time. We release our C++\nimplementations for metaheuristics such as EA, ILS and VNS along with the code\nfor data generation and our generated data at\nhttps://github.com/HySonLab/Chinese_Postman_Problem",
            "author": [
                "Truong Son Hy",
                "Cong Dao Tran"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15516v2",
                "http://arxiv.org/pdf/2310.15516v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15513v1",
            "title": "A Joint Matrix Factorization Analysis of Multilingual Representations",
            "updated": "2023-10-24T04:43:45Z",
            "published": "2023-10-24T04:43:45Z",
            "summary": "We present an analysis tool based on joint matrix factorization for comparing\nlatent representations of multilingual and monolingual models. An alternative\nto probing, this tool allows us to analyze multiple sets of representations in\na joint manner. Using this tool, we study to what extent and how\nmorphosyntactic features are reflected in the representations learned by\nmultilingual pre-trained models. We conduct a large-scale empirical study of\nover 33 languages and 17 morphosyntactic categories. Our findings demonstrate\nvariations in the encoding of morphosyntactic information across upper and\nlower layers, with category-specific differences influenced by language\nproperties. Hierarchical clustering of the factorization outputs yields a tree\nstructure that is related to phylogenetic trees manually crafted by linguists.\nMoreover, we find the factorization outputs exhibit strong associations with\nperformance observed across different cross-lingual tasks. We release our code\nto facilitate future research.",
            "author": [
                "Zheng Zhao",
                "Yftah Ziser",
                "Bonnie Webber",
                "Shay B. Cohen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15513v1",
                "http://arxiv.org/pdf/2310.15513v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15511v1",
            "title": "KITAB: Evaluating LLMs on Constraint Satisfaction for Information\n  Retrieval",
            "updated": "2023-10-24T04:40:38Z",
            "published": "2023-10-24T04:40:38Z",
            "summary": "We study the ability of state-of-the art models to answer constraint\nsatisfaction queries for information retrieval (e.g., 'a list of ice cream\nshops in San Diego'). In the past, such queries were considered to be tasks\nthat could only be solved via web-search or knowledge bases. More recently,\nlarge language models (LLMs) have demonstrated initial emergent abilities in\nthis task. However, many current retrieval benchmarks are either saturated or\ndo not measure constraint satisfaction. Motivated by rising concerns around\nfactual incorrectness and hallucinations of LLMs, we present KITAB, a new\ndataset for measuring constraint satisfaction abilities of language models.\nKITAB consists of book-related data across more than 600 authors and 13,000\nqueries, and also offers an associated dynamic data collection and constraint\nverification approach for acquiring similar test data for other authors. Our\nextended experiments on GPT4 and GPT3.5 characterize and decouple common\nfailure modes across dimensions such as information popularity, constraint\ntypes, and context availability. Results show that in the absence of context,\nmodels exhibit severe limitations as measured by irrelevant information,\nfactual errors, and incompleteness, many of which exacerbate as information\npopularity decreases. While context availability mitigates irrelevant\ninformation, it is not helpful for satisfying constraints, identifying\nfundamental barriers to constraint satisfaction. We open source our\ncontributions to foster further research on improving constraint satisfaction\nabilities of future models.",
            "author": [
                "Marah I Abdin",
                "Suriya Gunasekar",
                "Varun Chandrasekaran",
                "Jerry Li",
                "Mert Yuksekgonul",
                "Rahee Ghosh Peshawaria",
                "Ranjita Naik",
                "Besmira Nushi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15511v1",
                "http://arxiv.org/pdf/2310.15511v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL",
                "cs.IR",
                "I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19820v1",
            "title": "NetDistiller: Empowering Tiny Deep Learning via In-Situ Distillation",
            "updated": "2023-10-24T04:27:51Z",
            "published": "2023-10-24T04:27:51Z",
            "summary": "Boosting the task accuracy of tiny neural networks (TNNs) has become a\nfundamental challenge for enabling the deployments of TNNs on edge devices\nwhich are constrained by strict limitations in terms of memory, computation,\nbandwidth, and power supply. To this end, we propose a framework called\nNetDistiller to boost the achievable accuracy of TNNs by treating them as\nsub-networks of a weight-sharing teacher constructed by expanding the number of\nchannels of the TNN. Specifically, the target TNN model is jointly trained with\nthe weight-sharing teacher model via (1) gradient surgery to tackle the\ngradient conflicts between them and (2) uncertainty-aware distillation to\nmitigate the overfitting of the teacher model. Extensive experiments across\ndiverse tasks validate NetDistiller's effectiveness in boosting TNNs'\nachievable accuracy over state-of-the-art methods. Our code is available at\nhttps://github.com/GATECH-EIC/NetDistiller.",
            "author": [
                "Shunyao Zhang",
                "Yonggan Fu",
                "Shang Wu",
                "Jyotikrishna Dass",
                "Haoran You",
                "Yingyan",
                "Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19820v1",
                "http://arxiv.org/pdf/2310.19820v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15504v1",
            "title": "Cross-view Self-localization from Synthesized Scene-graphs",
            "updated": "2023-10-24T04:16:27Z",
            "published": "2023-10-24T04:16:27Z",
            "summary": "Cross-view self-localization is a challenging scenario of visual place\nrecognition in which database images are provided from sparse viewpoints.\nRecently, an approach for synthesizing database images from unseen viewpoints\nusing NeRF (Neural Radiance Fields) technology has emerged with impressive\nperformance. However, synthesized images provided by these techniques are often\nof lower quality than the original images, and furthermore they significantly\nincrease the storage cost of the database. In this study, we explore a new\nhybrid scene model that combines the advantages of view-invariant appearance\nfeatures computed from raw images and view-dependent spatial-semantic features\ncomputed from synthesized images. These two types of features are then fused\ninto scene graphs, and compressively learned and recognized by a graph neural\nnetwork. The effectiveness of the proposed method was verified using a novel\ncross-view self-localization dataset with many unseen views generated using a\nphotorealistic Habitat simulator.",
            "author": [
                "Ryogo Yamamoto",
                "Kanji Tanaka"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15504v1",
                "http://arxiv.org/pdf/2310.15504v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15495v4",
            "title": "AMG: Automated Efficient Approximate Multiplier Generator for FPGAs via\n  Bayesian Optimization",
            "updated": "2023-10-28T10:52:12Z",
            "published": "2023-10-24T03:44:06Z",
            "summary": "Approximate computing is a promising approach to reduce the power, delay, and\narea in hardware design for many error-resilient applications such as machine\nlearning (ML) and digital signal processing (DSP) systems, in which multipliers\nusually are key arithmetic units. Due to the underlying architectural\ndifferences between ASICs and FPGAs, existing ASIC-based approximate\nmultipliers do not offer symmetrical gains when they are implemented by FPGA\nresources. In this paper, we propose AMG, an open-source automated approximate\nmultiplier generator for FPGAs driven by Bayesian optimization (BO) with\nparallel evaluation. The proposed method simplifies the exact half adders (HAs)\nfor the initial partial product (PP) compression in a multiplier while\npreserving coarse-grained additions for the following accumulation. The\ngenerated multipliers can be effectively mapped to lookup tables (LUTs) and\ncarry chains provided by modern FPGAs, reducing hardware costs with acceptable\nerrors. Compared with 1167 multipliers from previous works, our generated\nmultipliers can form a Pareto front with 28.70%-38.47% improvements in terms of\nthe product of hardware cost and error on average. All source codes, reproduced\nmultipliers, and our generated multipliers are available at\nhttps://github.com/phyzhenli/AMG.",
            "author": [
                "Zhen Li",
                "Hao Zhou",
                "Lingli Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15495v4",
                "http://arxiv.org/pdf/2310.15495v4"
            ],
            "primary_category": "cs.AR",
            "category": [
                "cs.AR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15492v1",
            "title": "Robust Representation Learning for Unified Online Top-K Recommendation",
            "updated": "2023-10-24T03:42:20Z",
            "published": "2023-10-24T03:42:20Z",
            "summary": "In large-scale industrial e-commerce, the efficiency of an online\nrecommendation system is crucial in delivering highly relevant item/content\nadvertising that caters to diverse business scenarios. However, most existing\nstudies focus solely on item advertising, neglecting the significance of\ncontent advertising. This oversight results in inconsistencies within the\nmulti-entity structure and unfair retrieval. Furthermore, the challenge of\nretrieving top-k advertisements from multi-entity advertisements across\ndifferent domains adds to the complexity. Recent research proves that\nuser-entity behaviors within different domains exhibit characteristics of\ndifferentiation and homogeneity. Therefore, the multi-domain matching models\ntypically rely on the hybrid-experts framework with domain-invariant and\ndomain-specific representations. Unfortunately, most approaches primarily focus\non optimizing the combination mode of different experts, failing to address the\ninherent difficulty in optimizing the expert modules themselves. The existence\nof redundant information across different domains introduces interference and\ncompetition among experts, while the distinct learning objectives of each\ndomain lead to varying optimization challenges among experts. To tackle these\nissues, we propose robust representation learning for the unified online top-k\nrecommendation. Our approach constructs unified modeling in entity space to\nensure data fairness. The robust representation learning employs domain\nadversarial learning and multi-view wasserstein distribution learning to learn\nrobust representations. Moreover, the proposed method balances conflicting\nobjectives through the homoscedastic uncertainty weights and orthogonality\nconstraints. Various experiments validate the effectiveness and rationality of\nour proposed method, which has been successfully deployed online to serve real\nbusiness scenarios.",
            "author": [
                "Minfang Lu",
                "Yuchen Jiang",
                "Huihui Dong",
                "Qi Li",
                "Ziru Xu",
                "Yuanlin Liu",
                "Lixia Wu",
                "Haoyuan Hu",
                "Han Zhu",
                "Yuning Jiang",
                "Jian Xu",
                "Bo Zheng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15492v1",
                "http://arxiv.org/pdf/2310.15492v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15479v2",
            "title": "AutoDiff: combining Auto-encoder and Diffusion model for tabular data\n  synthesizing",
            "updated": "2023-11-17T03:24:50Z",
            "published": "2023-10-24T03:15:19Z",
            "summary": "Diffusion model has become a main paradigm for synthetic data generation in\nmany subfields of modern machine learning, including computer vision, language\nmodel, or speech synthesis. In this paper, we leverage the power of diffusion\nmodel for generating synthetic tabular data. The heterogeneous features in\ntabular data have been main obstacles in tabular data synthesis, and we tackle\nthis problem by employing the auto-encoder architecture. When compared with the\nstate-of-the-art tabular synthesizers, the resulting synthetic tables from our\nmodel show nice statistical fidelities to the real data, and perform well in\ndownstream tasks for machine learning utilities. We conducted the experiments\nover $15$ publicly available datasets. Notably, our model adeptly captures the\ncorrelations among features, which has been a long-standing challenge in\ntabular data synthesis. Our code is available at\nhttps://github.com/UCLA-Trustworthy-AI-Lab/AutoDiffusion.",
            "author": [
                "Namjoon Suh",
                "Xiaofeng Lin",
                "Din-Yin Hsieh",
                "Merhdad Honarkhah",
                "Guang Cheng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15479v2",
                "http://arxiv.org/pdf/2310.15479v2"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15478v3",
            "title": "How to Train Your Neural Control Barrier Function: Learning Safety\n  Filters for Complex Input-Constrained Systems",
            "updated": "2023-12-05T04:31:45Z",
            "published": "2023-10-24T03:15:15Z",
            "summary": "Control barrier functions (CBF) have become popular as a safety filter to\nguarantee the safety of nonlinear dynamical systems for arbitrary inputs.\nHowever, it is difficult to construct functions that satisfy the CBF\nconstraints for high relative degree systems with input constraints. To address\nthese challenges, recent work has explored learning CBFs using neural networks\nvia neural CBF (NCBF). However, such methods face difficulties when scaling to\nhigher dimensional systems under input constraints. In this work, we first\nidentify challenges that NCBFs face during training. Next, to address these\nchallenges, we propose policy neural CBF (PNCBF), a method of constructing CBFs\nby learning the value function of a nominal policy, and show that the value\nfunction of the maximum-over-time cost is a CBF. We demonstrate the\neffectiveness of our method in simulation on a variety of systems ranging from\ntoy linear systems to an F-16 jet with a 16-dimensional state space. Finally,\nwe validate our approach on a two-agent quadcopter system on hardware under\ntight input constraints.",
            "author": [
                "Oswin So",
                "Zachary Serlin",
                "Makai Mann",
                "Jake Gonzales",
                "Kwesi Rutledge",
                "Nicholas Roy",
                "Chuchu Fan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15478v3",
                "http://arxiv.org/pdf/2310.15478v3"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18358v1",
            "title": "A Communication Theory Perspective on Prompting Engineering Methods for\n  Large Language Models",
            "updated": "2023-10-24T03:05:21Z",
            "published": "2023-10-24T03:05:21Z",
            "summary": "The springing up of Large Language Models (LLMs) has shifted the community\nfrom single-task-orientated natural language processing (NLP) research to a\nholistic end-to-end multi-task learning paradigm. Along this line of research\nendeavors in the area, LLM-based prompting methods have attracted much\nattention, partially due to the technological advantages brought by prompt\nengineering (PE) as well as the underlying NLP principles disclosed by various\nprompting methods. Traditional supervised learning usually requires training a\nmodel based on labeled data and then making predictions. In contrast, PE\nmethods directly use the powerful capabilities of existing LLMs (i.e., GPT-3\nand GPT-4) via composing appropriate prompts, especially under few-shot or\nzero-shot scenarios. Facing the abundance of studies related to the prompting\nand the ever-evolving nature of this field, this article aims to (i) illustrate\na novel perspective to review existing PE methods, within the well-established\ncommunication theory framework; (ii) facilitate a better/deeper understanding\nof developing trends of existing PE methods used in four typical tasks; (iii)\nshed light on promising research directions for future PE methods.",
            "author": [
                "Yuanfeng Song",
                "Yuanqin He",
                "Xuefang Zhao",
                "Hanlin Gu",
                "Di Jiang",
                "Haijun Yang",
                "Lixin Fan",
                "Qiang Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18358v1",
                "http://arxiv.org/pdf/2310.18358v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15472v1",
            "title": "Interpretable Survival Analysis for Heart Failure Risk Prediction",
            "updated": "2023-10-24T02:56:05Z",
            "published": "2023-10-24T02:56:05Z",
            "summary": "Survival analysis, or time-to-event analysis, is an important and widespread\nproblem in healthcare research. Medical research has traditionally relied on\nCox models for survival analysis, due to their simplicity and interpretability.\nCox models assume a log-linear hazard function as well as proportional hazards\nover time, and can perform poorly when these assumptions fail. Newer survival\nmodels based on machine learning avoid these assumptions and offer improved\naccuracy, yet sometimes at the expense of model interpretability, which is\nvital for clinical use. We propose a novel survival analysis pipeline that is\nboth interpretable and competitive with state-of-the-art survival models.\nSpecifically, we use an improved version of survival stacking to transform a\nsurvival analysis problem to a classification problem, ControlBurn to perform\nfeature selection, and Explainable Boosting Machines to generate interpretable\npredictions. To evaluate our pipeline, we predict risk of heart failure using a\nlarge-scale EHR database. Our pipeline achieves state-of-the-art performance\nand provides interesting and novel insights about risk factors for heart\nfailure.",
            "author": [
                "Mike Van Ness",
                "Tomas Bosschieter",
                "Natasha Din",
                "Andrew Ambrosy",
                "Alexander Sandhu",
                "Madeleine Udell"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15472v1",
                "http://arxiv.org/pdf/2310.15472v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15470v1",
            "title": "Continual Event Extraction with Semantic Confusion Rectification",
            "updated": "2023-10-24T02:48:50Z",
            "published": "2023-10-24T02:48:50Z",
            "summary": "We study continual event extraction, which aims to extract incessantly\nemerging event information while avoiding forgetting. We observe that the\nsemantic confusion on event types stems from the annotations of the same text\nbeing updated over time. The imbalance between event types even aggravates this\nissue. This paper proposes a novel continual event extraction model with\nsemantic confusion rectification. We mark pseudo labels for each sentence to\nalleviate semantic confusion. We transfer pivotal knowledge between current and\nprevious models to enhance the understanding of event types. Moreover, we\nencourage the model to focus on the semantics of long-tailed event types by\nleveraging other associated types. Experimental results show that our model\noutperforms state-of-the-art baselines and is proficient in imbalanced\ndatasets.",
            "author": [
                "Zitao Wang",
                "Xinyi Wang",
                "Wei Hu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15470v1",
                "http://arxiv.org/pdf/2310.15470v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15469v1",
            "title": "The Janus Interface: How Fine-Tuning in Large Language Models Amplifies\n  the Privacy Risks",
            "updated": "2023-10-24T02:48:19Z",
            "published": "2023-10-24T02:48:19Z",
            "summary": "The era post-2018 marked the advent of Large Language Models (LLMs), with\ninnovations such as OpenAI's ChatGPT showcasing prodigious linguistic prowess.\nAs the industry galloped toward augmenting model parameters and capitalizing on\nvast swaths of human language data, security and privacy challenges also\nemerged. Foremost among these is the potential inadvertent accrual of Personal\nIdentifiable Information (PII) during web-based data acquisition, posing risks\nof unintended PII disclosure. While strategies like RLHF during training and\nCatastrophic Forgetting have been marshaled to control the risk of privacy\ninfringements, recent advancements in LLMs, epitomized by OpenAI's fine-tuning\ninterface for GPT-3.5, have reignited concerns. One may ask: can the\nfine-tuning of LLMs precipitate the leakage of personal information embedded\nwithin training datasets? This paper reports the first endeavor to seek the\nanswer to the question, particularly our discovery of a new LLM exploitation\navenue, called the Janus attack. In the attack, one can construct a PII\nassociation task, whereby an LLM is fine-tuned using a minuscule PII dataset,\nto potentially reinstate and reveal concealed PIIs. Our findings indicate that,\nwith a trivial fine-tuning outlay, LLMs such as GPT-3.5 can transition from\nbeing impermeable to PII extraction to a state where they divulge a substantial\nproportion of concealed PII. This research, through its deep dive into the\nJanus attack vector, underscores the imperative of navigating the intricate\ninterplay between LLM utility and privacy preservation.",
            "author": [
                "Xiaoyi Chen",
                "Siyuan Tang",
                "Rui Zhu",
                "Shijun Yan",
                "Lei Jin",
                "Zihao Wang",
                "Liya Su",
                "XiaoFeng Wang",
                "Haixu Tang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15469v1",
                "http://arxiv.org/pdf/2310.15469v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15468v1",
            "title": "Empowering Distributed Solutions in Renewable Energy Systems and Grid\n  Optimization",
            "updated": "2023-10-24T02:45:16Z",
            "published": "2023-10-24T02:45:16Z",
            "summary": "This study delves into the shift from centralized to decentralized approaches\nin the electricity industry, with a particular focus on how machine learning\n(ML) advancements play a crucial role in empowering renewable energy sources\nand improving grid management. ML models have become increasingly important in\npredicting renewable energy generation and consumption, utilizing various\ntechniques like artificial neural networks, support vector machines, and\ndecision trees. Furthermore, data preprocessing methods, such as data\nsplitting, normalization, decomposition, and discretization, are employed to\nenhance prediction accuracy.\n  The incorporation of big data and ML into smart grids offers several\nadvantages, including heightened energy efficiency, more effective responses to\ndemand, and better integration of renewable energy sources. Nevertheless,\nchallenges like handling large data volumes, ensuring cybersecurity, and\nobtaining specialized expertise must be addressed. The research investigates\nvarious ML applications within the realms of solar energy, wind energy, and\nelectric distribution and storage, illustrating their potential to optimize\nenergy systems. To sum up, this research demonstrates the evolving landscape of\nthe electricity sector as it shifts from centralized to decentralized solutions\nthrough the application of ML innovations and distributed decision-making,\nultimately shaping a more efficient and sustainable energy future.",
            "author": [
                "Mohammad Mohammadi",
                "Ali Mohammadi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15468v1",
                "http://arxiv.org/pdf/2310.15468v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15467v2",
            "title": "Policy Optimization of Finite-Horizon Kalman Filter with Unknown Noise\n  Covariance",
            "updated": "2023-10-27T15:32:29Z",
            "published": "2023-10-24T02:44:35Z",
            "summary": "This paper is on learning the Kalman gain by policy optimization method.\nFirstly, we reformulate the finite-horizon Kalman filter as a policy\noptimization problem of the dual system. Secondly, we obtain the global linear\nconvergence of exact gradient descent method in the setting of known\nparameters. Thirdly, the gradient estimation and stochastic gradient descent\nmethod are proposed to solve the policy optimization problem, and further the\nglobal linear convergence and sample complexity of stochastic gradient descent\nare provided for the setting of unknown noise covariance matrices and known\nmodel parameters.",
            "author": [
                "Haoran Li",
                "Yuan-Hua Ni"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15467v2",
                "http://arxiv.org/pdf/2310.15467v2"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15466v1",
            "title": "EKGNet: A 10.96\u03bcW Fully Analog Neural Network for Intra-Patient\n  Arrhythmia Classification",
            "updated": "2023-10-24T02:37:49Z",
            "published": "2023-10-24T02:37:49Z",
            "summary": "We present an integrated approach by combining analog computing and deep\nlearning for electrocardiogram (ECG) arrhythmia classification. We propose\nEKGNet, a hardware-efficient and fully analog arrhythmia classification\narchitecture that archives high accuracy with low power consumption. The\nproposed architecture leverages the energy efficiency of transistors operating\nin the subthreshold region, eliminating the need for analog-to-digital\nconverters (ADC) and static random access memory (SRAM). The system design\nincludes a novel analog sequential Multiply-Accumulate (MAC) circuit that\nmitigates process, supply voltage, and temperature variations. Experimental\nevaluations on PhysioNet's MIT-BIH and PTB Diagnostics datasets demonstrate the\neffectiveness of the proposed method, achieving average balanced accuracy of\n95% and 94.25% for intra-patient arrhythmia classification and myocardial\ninfarction (MI) classification, respectively. This innovative approach presents\na promising avenue for developing low-power arrhythmia classification systems\nwith enhanced accuracy and transferability in biomedical applications.",
            "author": [
                "Benyamin Haghi",
                "Lin Ma",
                "Sahin Lale",
                "Anima Anandkumar",
                "Azita Emami"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15466v1",
                "http://arxiv.org/pdf/2310.15466v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15461v1",
            "title": "Facilitating Self-Guided Mental Health Interventions Through\n  Human-Language Model Interaction: A Case Study of Cognitive Restructuring",
            "updated": "2023-10-24T02:23:34Z",
            "published": "2023-10-24T02:23:34Z",
            "summary": "Self-guided mental health interventions, such as \"do-it-yourself\" tools to\nlearn and practice coping strategies, show great promise to improve access to\nmental health care. However, these interventions are often cognitively\ndemanding and emotionally triggering, creating accessibility barriers that\nlimit their wide-scale implementation and adoption. In this paper, we study how\nhuman-language model interaction can support self-guided mental health\ninterventions. We take cognitive restructuring, an evidence-based therapeutic\ntechnique to overcome negative thinking, as a case study. In an IRB-approved\nrandomized field study on a large mental health website with 15,531\nparticipants, we design and evaluate a system that uses language models to\nsupport people through various steps of cognitive restructuring. Our findings\nreveal that our system positively impacts emotional intensity for 67% of\nparticipants and helps 65% overcome negative thoughts. Although adolescents\nreport relatively worse outcomes, we find that tailored interventions that\nsimplify language model generations improve overall effectiveness and equity.",
            "author": [
                "Ashish Sharma",
                "Kevin Rushton",
                "Inna Wanyin Lin",
                "Theresa Nguyen",
                "Tim Althoff"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15461v1",
                "http://arxiv.org/pdf/2310.15461v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15455v1",
            "title": "UI Layout Generation with LLMs Guided by UI Grammar",
            "updated": "2023-10-24T02:00:12Z",
            "published": "2023-10-24T02:00:12Z",
            "summary": "The recent advances in Large Language Models (LLMs) have stimulated interest\namong researchers and industry professionals, particularly in their application\nto tasks concerning mobile user interfaces (UIs). This position paper\ninvestigates the use of LLMs for UI layout generation. Central to our\nexploration is the introduction of UI grammar -- a novel approach we proposed\nto represent the hierarchical structure inherent in UI screens. The aim of this\napproach is to guide the generative capacities of LLMs more effectively and\nimprove the explainability and controllability of the process. Initial\nexperiments conducted with GPT-4 showed the promising capability of LLMs to\nproduce high-quality user interfaces via in-context learning. Furthermore, our\npreliminary comparative study suggested the potential of the grammar-based\napproach in improving the quality of generative results in specific aspects.",
            "author": [
                "Yuwen Lu",
                "Ziang Tong",
                "Qinyi Zhao",
                "Chengzhi Zhang",
                "Toby Jia-Jun Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15455v1",
                "http://arxiv.org/pdf/2310.15455v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15454v1",
            "title": "Private Learning with Public Features",
            "updated": "2023-10-24T01:59:28Z",
            "published": "2023-10-24T01:59:28Z",
            "summary": "We study a class of private learning problems in which the data is a join of\nprivate and public features. This is often the case in private personalization\ntasks such as recommendation or ad prediction, in which features related to\nindividuals are sensitive, while features related to items (the movies or songs\nto be recommended, or the ads to be shown to users) are publicly available and\ndo not require protection. A natural question is whether private algorithms can\nachieve higher utility in the presence of public features. We give a positive\nanswer for multi-encoder models where one of the encoders operates on public\nfeatures. We develop new algorithms that take advantage of this separation by\nonly protecting certain sufficient statistics (instead of adding noise to the\ngradient). This method has a guaranteed utility improvement for linear\nregression, and importantly, achieves the state of the art on two standard\nprivate recommendation benchmarks, demonstrating the importance of methods that\nadapt to the private-public feature separation.",
            "author": [
                "Walid Krichene",
                "Nicolas Mayoraz",
                "Steffen Rendle",
                "Shuang Song",
                "Abhradeep Thakurta",
                "Li Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15454v1",
                "http://arxiv.org/pdf/2310.15454v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15450v1",
            "title": "General Identifiability and Achievability for Causal Representation\n  Learning",
            "updated": "2023-10-24T01:47:44Z",
            "published": "2023-10-24T01:47:44Z",
            "summary": "This paper focuses on causal representation learning (CRL) under a general\nnonparametric causal latent model and a general transformation model that maps\nthe latent data to the observational data. It establishes\n\\textbf{identifiability} and \\textbf{achievability} results using two hard\n\\textbf{uncoupled} interventions per node in the latent causal graph. Notably,\none does not know which pair of intervention environments have the same node\nintervened (hence, uncoupled environments). For identifiability, the paper\nestablishes that perfect recovery of the latent causal model and variables is\nguaranteed under uncoupled interventions. For achievability, an algorithm is\ndesigned that uses observational and interventional data and recovers the\nlatent causal model and variables with provable guarantees for the algorithm.\nThis algorithm leverages score variations across different environments to\nestimate the inverse of the transformer and, subsequently, the latent\nvariables. The analysis, additionally, recovers the existing identifiability\nresult for two hard \\textbf{coupled} interventions, that is when metadata about\nthe pair of environments that have the same node intervened is known. It is\nnoteworthy that the existing results on non-parametric identifiability require\nassumptions on interventions and additional faithfulness assumptions. This\npaper shows that when observational data is available, additional faithfulness\nassumptions are unnecessary.",
            "author": [
                "Burak Var\u0131c\u0131",
                "Emre Acart\u00fcrk",
                "Karthikeyan Shanmugam",
                "Ali Tajer"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15450v1",
                "http://arxiv.org/pdf/2310.15450v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15448v1",
            "title": "An accelerated first-order regularized momentum descent ascent algorithm\n  for stochastic nonconvex-concave minimax problems",
            "updated": "2023-10-24T01:45:11Z",
            "published": "2023-10-24T01:45:11Z",
            "summary": "Stochastic nonconvex minimax problems have attracted wide attention in\nmachine learning, signal processing and many other fields in recent years. In\nthis paper, we propose an accelerated first-order regularized momentum descent\nascent algorithm (FORMDA) for solving stochastic nonconvex-concave minimax\nproblems. The iteration complexity of the algorithm is proved to be\n$\\tilde{\\mathcal{O}}(\\varepsilon ^{-6.5})$ to obtain an\n$\\varepsilon$-stationary point, which achieves the best-known complexity bound\nfor single-loop algorithms to solve the stochastic nonconvex-concave minimax\nproblems under the stationarity of the objective function.",
            "author": [
                "Huiling Zhang",
                "Zi Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15448v1",
                "http://arxiv.org/pdf/2310.15448v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15440v1",
            "title": "Learning Dynamics in Linear VAE: Posterior Collapse Threshold,\n  Superfluous Latent Space Pitfalls, and Speedup with KL Annealing",
            "updated": "2023-10-24T01:20:27Z",
            "published": "2023-10-24T01:20:27Z",
            "summary": "Variational autoencoders (VAEs) face a notorious problem wherein the\nvariational posterior often aligns closely with the prior, a phenomenon known\nas posterior collapse, which hinders the quality of representation learning. To\nmitigate this problem, an adjustable hyperparameter $\\beta$ and a strategy for\nannealing this parameter, called KL annealing, are proposed. This study\npresents a theoretical analysis of the learning dynamics in a minimal VAE. It\nis rigorously proved that the dynamics converge to a deterministic process\nwithin the limit of large input dimensions, thereby enabling a detailed\ndynamical analysis of the generalization error. Furthermore, the analysis shows\nthat the VAE initially learns entangled representations and gradually acquires\ndisentangled representations. A fixed-point analysis of the deterministic\nprocess reveals that when $\\beta$ exceeds a certain threshold, posterior\ncollapse becomes inevitable regardless of the learning period. Additionally,\nthe superfluous latent variables for the data-generative factors lead to\noverfitting of the background noise; this adversely affects both generalization\nand learning convergence. The analysis further unveiled that appropriately\ntuned KL annealing can accelerate convergence.",
            "author": [
                "Yuma Ichikawa",
                "Koji Hukushima"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15440v1",
                "http://arxiv.org/pdf/2310.15440v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cond-mat.dis-nn",
                "cs.LG",
                "math.ST",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15436v1",
            "title": "VGX: Large-Scale Sample Generation for Boosting Learning-Based Software\n  Vulnerability Analyses",
            "updated": "2023-10-24T01:05:00Z",
            "published": "2023-10-24T01:05:00Z",
            "summary": "Accompanying the successes of learning-based defensive software vulnerability\nanalyses is the lack of large and quality sets of labeled vulnerable program\nsamples, which impedes further advancement of those defenses. Existing\nautomated sample generation approaches have shown potentials yet still fall\nshort of practical expectations due to the high noise in the generated samples.\nThis paper proposes VGX, a new technique aimed for large-scale generation of\nhigh-quality vulnerability datasets. Given a normal program, VGX identifies the\ncode contexts in which vulnerabilities can be injected, using a customized\nTransformer featured with a new value-flowbased position encoding and\npre-trained against new objectives particularly for learning code structure and\ncontext. Then, VGX materializes vulnerability-injection code editing in the\nidentified contexts using patterns of such edits obtained from both historical\nfixes and human knowledge about real-world vulnerabilities. Compared to four\nstate-of-the-art (SOTA) baselines (pattern-, Transformer-, GNN-, and\npattern+Transformer-based), VGX achieved 99.09-890.06% higher F1 and\n22.45%-328.47% higher label accuracy. For in-the-wild sample production, VGX\ngenerated 150,392 vulnerable samples, from which we randomly chose 10% to\nassess how much these samples help vulnerability detection, localization, and\nrepair. Our results show SOTA techniques for these three application tasks\nachieved 19.15-330.80% higher F1, 12.86-19.31% higher top-10 accuracy, and\n85.02-99.30% higher top-50 accuracy, respectively, by adding those samples to\ntheir original training data. These samples also helped a SOTA vulnerability\ndetector discover 13 more real-world vulnerabilities (CVEs) in critical systems\n(e.g., Linux kernel) that would be missed by the original model.",
            "author": [
                "Yu Nong",
                "Richard Fang",
                "Guangbei Yi",
                "Kunsong Zhao",
                "Xiapu Luo",
                "Feng Chen",
                "Haipeng Cai"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15436v1",
                "http://arxiv.org/pdf/2310.15436v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15433v1",
            "title": "Off-Policy Evaluation for Large Action Spaces via Policy Convolution",
            "updated": "2023-10-24T01:00:01Z",
            "published": "2023-10-24T01:00:01Z",
            "summary": "Developing accurate off-policy estimators is crucial for both evaluating and\noptimizing for new policies. The main challenge in off-policy estimation is the\ndistribution shift between the logging policy that generates data and the\ntarget policy that we aim to evaluate. Typically, techniques for correcting\ndistribution shift involve some form of importance sampling. This approach\nresults in unbiased value estimation but often comes with the trade-off of high\nvariance, even in the simpler case of one-step contextual bandits. Furthermore,\nimportance sampling relies on the common support assumption, which becomes\nimpractical when the action space is large. To address these challenges, we\nintroduce the Policy Convolution (PC) family of estimators. These methods\nleverage latent structure within actions -- made available through action\nembeddings -- to strategically convolve the logging and target policies. This\nconvolution introduces a unique bias-variance trade-off, which can be\ncontrolled by adjusting the amount of convolution. Our experiments on synthetic\nand benchmark datasets demonstrate remarkable mean squared error (MSE)\nimprovements when using PC, especially when either the action space or policy\nmismatch becomes large, with gains of up to 5 - 6 orders of magnitude over\nexisting estimators.",
            "author": [
                "Noveen Sachdeva",
                "Lequn Wang",
                "Dawen Liang",
                "Nathan Kallus",
                "Julian McAuley"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15433v1",
                "http://arxiv.org/pdf/2310.15433v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15431v2",
            "title": "What Makes it Ok to Set a Fire? Iterative Self-distillation of Contexts\n  and Rationales for Disambiguating Defeasible Social and Moral Situations",
            "updated": "2023-11-01T04:39:14Z",
            "published": "2023-10-24T00:51:29Z",
            "summary": "Moral or ethical judgments rely heavily on the specific contexts in which\nthey occur. Understanding varying shades of defeasible contextualizations\n(i.e., additional information that strengthens or attenuates the moral\nacceptability of an action) is critical to accurately represent the subtlety\nand intricacy of grounded human moral judgment in real-life scenarios.\n  We introduce defeasible moral reasoning: a task to provide grounded contexts\nthat make an action more or less morally acceptable, along with commonsense\nrationales that justify the reasoning. To elicit high-quality task data, we\ntake an iterative self-distillation approach that starts from a small amount of\nunstructured seed knowledge from GPT-3 and then alternates between (1)\nself-distillation from student models; (2) targeted filtering with a critic\nmodel trained by human judgment (to boost validity) and NLI (to boost\ndiversity); (3) self-imitation learning (to amplify the desired data quality).\nThis process yields a student model that produces defeasible contexts with\nimproved validity, diversity, and defeasibility. From this model we distill a\nhigh-quality dataset, \\delta-Rules-of-Thumb, of 1.2M entries of\ncontextualizations and rationales for 115K defeasible moral actions rated\nhighly by human annotators 85.9% to 99.8% of the time. Using \\delta-RoT we\nobtain a final student model that wins over all intermediate student models by\na notable margin.",
            "author": [
                "Kavel Rao",
                "Liwei Jiang",
                "Valentina Pyatkin",
                "Yuling Gu",
                "Niket Tandon",
                "Nouha Dziri",
                "Faeze Brahman",
                "Yejin Choi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15431v2",
                "http://arxiv.org/pdf/2310.15431v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18356v2",
            "title": "LoRAShear: Efficient Large Language Model Structured Pruning and\n  Knowledge Recovery",
            "updated": "2023-10-31T04:21:33Z",
            "published": "2023-10-24T00:47:26Z",
            "summary": "Large Language Models (LLMs) have transformed the landscape of artificial\nintelligence, while their enormous size presents significant challenges in\nterms of computational costs. We introduce LoRAShear, a novel efficient\napproach to structurally prune LLMs and recover knowledge. Given general LLMs,\nLoRAShear at first creates the dependency graphs over LoRA modules to discover\nminimally removal structures and analyze the knowledge distribution. It then\nproceeds progressive structured pruning on LoRA adaptors and enables inherent\nknowledge transfer to better preserve the information in the redundant\nstructures. To recover the lost knowledge during pruning, LoRAShear\nmeticulously studies and proposes a dynamic fine-tuning schemes with dynamic\ndata adaptors to effectively narrow down the performance gap to the full\nmodels. Numerical results demonstrate that by only using one GPU within a\ncouple of GPU days, LoRAShear effectively reduced footprint of LLMs by 20% with\nonly 1.0% performance degradation and significantly outperforms\nstate-of-the-arts. The source code will be available at\nhttps://github.com/microsoft/lorashear.",
            "author": [
                "Tianyi Chen",
                "Tianyu Ding",
                "Badal Yadav",
                "Ilya Zharkov",
                "Luming Liang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18356v2",
                "http://arxiv.org/pdf/2310.18356v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15425v1",
            "title": "The Mason-Alberta Phonetic Segmenter: A forced alignment system based on\n  deep neural networks and interpolation",
            "updated": "2023-10-24T00:43:54Z",
            "published": "2023-10-24T00:43:54Z",
            "summary": "Forced alignment systems automatically determine boundaries between segments\nin speech data, given an orthographic transcription. These tools are\ncommonplace in phonetics to facilitate the use of speech data that would be\ninfeasible to manually transcribe and segment. In the present paper, we\ndescribe a new neural network-based forced alignment system, the Mason-Alberta\nPhonetic Segmenter (MAPS). The MAPS aligner serves as a testbed for two\npossible improvements we pursue for forced alignment systems. The first is\ntreating the acoustic model in a forced aligner as a tagging task, rather than\na classification task, motivated by the common understanding that segments in\nspeech are not truly discrete and commonly overlap. The second is an\ninterpolation technique to allow boundaries more precise than the common 10 ms\nlimit in modern forced alignment systems. We compare configurations of our\nsystem to a state-of-the-art system, the Montreal Forced Aligner. The tagging\napproach did not generally yield improved results over the Montreal Forced\nAligner. However, a system with the interpolation technique had a 27.92%\nincrease relative to the Montreal Forced Aligner in the amount of boundaries\nwithin 10 ms of the target on the test set. We also reflect on the task and\ntraining process for acoustic modeling in forced alignment, highlighting how\nthe output targets for these models do not match phoneticians' conception of\nsimilarity between phones and that reconciliation of this tension may require\nrethinking the task and output targets or how speech itself should be\nsegmented.",
            "author": [
                "Matthew C. Kelley",
                "Scott James Perry",
                "Benjamin V. Tucker"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15425v1",
                "http://arxiv.org/pdf/2310.15425v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.CL",
                "cs.LG",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15418v1",
            "title": "Fractal Landscapes in Policy Optimization",
            "updated": "2023-10-24T00:22:19Z",
            "published": "2023-10-24T00:22:19Z",
            "summary": "Policy gradient lies at the core of deep reinforcement learning (RL) in\ncontinuous domains. Despite much success, it is often observed in practice that\nRL training with policy gradient can fail for many reasons, even on standard\ncontrol problems with known solutions. We propose a framework for understanding\none inherent limitation of the policy gradient approach: the optimization\nlandscape in the policy space can be extremely non-smooth or fractal for\ncertain classes of MDPs, such that there does not exist gradient to be\nestimated in the first place. We draw on techniques from chaos theory and\nnon-smooth analysis, and analyze the maximal Lyapunov exponents and H\\\"older\nexponents of the policy optimization objectives. Moreover, we develop a\npractical method that can estimate the local smoothness of objective function\nfrom samples to identify when the training process has encountered fractal\nlandscapes. We show experiments to illustrate how some failure cases of policy\noptimization can be explained by such fractal landscapes.",
            "author": [
                "Tao Wang",
                "Sylvia Herbert",
                "Sicun Gao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15418v1",
                "http://arxiv.org/pdf/2310.15418v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15416v1",
            "title": "Nominality Score Conditioned Time Series Anomaly Detection by\n  Point/Sequential Reconstruction",
            "updated": "2023-10-24T00:14:57Z",
            "published": "2023-10-24T00:14:57Z",
            "summary": "Time series anomaly detection is challenging due to the complexity and\nvariety of patterns that can occur. One major difficulty arises from modeling\ntime-dependent relationships to find contextual anomalies while maintaining\ndetection accuracy for point anomalies. In this paper, we propose a framework\nfor unsupervised time series anomaly detection that utilizes point-based and\nsequence-based reconstruction models. The point-based model attempts to\nquantify point anomalies, and the sequence-based model attempts to quantify\nboth point and contextual anomalies. Under the formulation that the observed\ntime point is a two-stage deviated value from a nominal time point, we\nintroduce a nominality score calculated from the ratio of a combined value of\nthe reconstruction errors. We derive an induced anomaly score by further\nintegrating the nominality score and anomaly score, then theoretically prove\nthe superiority of the induced anomaly score over the original anomaly score\nunder certain conditions. Extensive studies conducted on several public\ndatasets show that the proposed framework outperforms most state-of-the-art\nbaselines for time series anomaly detection.",
            "author": [
                "Chih-Yu Lai",
                "Fan-Keng Sun",
                "Zhengqi Gao",
                "Jeffrey H. Lang",
                "Duane S. Boning"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15416v1",
                "http://arxiv.org/pdf/2310.15416v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15414v1",
            "title": "Diverse Conventions for Human-AI Collaboration",
            "updated": "2023-10-24T00:07:20Z",
            "published": "2023-10-24T00:07:20Z",
            "summary": "Conventions are crucial for strong performance in cooperative multi-agent\ngames, because they allow players to coordinate on a shared strategy without\nexplicit communication. Unfortunately, standard multi-agent reinforcement\nlearning techniques, such as self-play, converge to conventions that are\narbitrary and non-diverse, leading to poor generalization when interacting with\nnew partners. In this work, we present a technique for generating diverse\nconventions by (1) maximizing their rewards during self-play, while (2)\nminimizing their rewards when playing with previously discovered conventions\n(cross-play), stimulating conventions to be semantically different. To ensure\nthat learned policies act in good faith despite the adversarial optimization of\ncross-play, we introduce \\emph{mixed-play}, where an initial state is randomly\ngenerated by sampling self-play and cross-play transitions and the player\nlearns to maximize the self-play reward from this initial state. We analyze the\nbenefits of our technique on various multi-agent collaborative games, including\nOvercooked, and find that our technique can adapt to the conventions of humans,\nsurpassing human-level performance when paired with real users.",
            "author": [
                "Bidipta Sarkar",
                "Andy Shih",
                "Dorsa Sadigh"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15414v1",
                "http://arxiv.org/pdf/2310.15414v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15411v1",
            "title": "Efficient Active Learning Halfspaces with Tsybakov Noise: A Non-convex\n  Optimization Approach",
            "updated": "2023-10-23T23:55:28Z",
            "published": "2023-10-23T23:55:28Z",
            "summary": "We study the problem of computationally and label efficient PAC active\nlearning $d$-dimensional halfspaces with Tsybakov\nNoise~\\citep{tsybakov2004optimal} under structured unlabeled data\ndistributions. Inspired by~\\cite{diakonikolas2020learning}, we prove that any\napproximate first-order stationary point of a smooth nonconvex loss function\nyields a halfspace with a low excess error guarantee. In light of the above\nstructural result, we design a nonconvex optimization-based algorithm with a\nlabel complexity of $\\tilde{O}(d\n(\\frac{1}{\\epsilon})^{\\frac{8-6\\alpha}{3\\alpha-1}})$\\footnote{In the main body\nof this work, we use $\\tilde{O}(\\cdot), \\tilde{\\Theta}(\\cdot)$ to hide factors\nof the form $\\polylog(d, \\frac{1}{\\epsilon}, \\frac{1}{\\delta})$}, under the\nassumption that the Tsybakov noise parameter $\\alpha \\in (\\frac13, 1]$, which\nnarrows down the gap between the label complexities of the previously known\nefficient passive or active\nalgorithms~\\citep{diakonikolas2020polynomial,zhang2021improved} and the\ninformation-theoretic lower bound in this setting.",
            "author": [
                "Yinan Li",
                "Chicheng Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15411v1",
                "http://arxiv.org/pdf/2310.15411v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16060v1",
            "title": "Adaptive Fuzzy Tracking Control for Nonlinear State Constrained\n  Pure-Feedback Systems With Input Delay via Dynamic Surface Technique",
            "updated": "2023-10-23T23:31:47Z",
            "published": "2023-10-23T23:31:47Z",
            "summary": "This brief constructs the adaptive backstepping control scheme for a class of\npure-feedback systems with input delay and full state constraints. With the\nhelp of Mean Value Theorem, the pure-feedback system is transformed into\nstrict-feedback one. Barrier Lyapunov functions are employed to guarantee all\nof the states remain constrained within predefined sets. By introducing the\nPade approximation method and corresponding intermediate, the impact generated\nby input delay on the output tracking performance of the system can be\neliminated. Furthermore, a low-pass filter driven by a newly-defined control\ninput, is employed to generate the actual control input, which facilitates the\ndesign of backstepping control. To approximate the unknown functions with a\ndesired level of accuracy, the fuzzy logic systems (FLSs) are utilized by\nchoosing appropriate fuzzy rules, logics and so on. The minimal learning\nparameter (MLP) technique is employed to decrease the number of nodes and\nparameters in FLSs, and dynamic surface control (DSC) technique is leveraged to\navoid so-called \"explosion of complexity\". Moreover, smooth robust compensators\nare introduced to circumvent the influences of external disturbance and\napproximation errors. By stability analysis, it is proved that all of signals\nin the closed-loop system are semi-globally ultimately uniform bounded, and the\ntracking error can be within a arbitrary small neighbor of origin via selecting\nappropriate parameters of controllers. Finally, the results of numerical\nillustration are provided to demonstrate the effectiveness of the designed\nmethod.",
            "author": [
                "Ju Wu",
                "Tong Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16060v1",
                "http://arxiv.org/pdf/2310.16060v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15402v1",
            "title": "Towards contrast-agnostic soft segmentation of the spinal cord",
            "updated": "2023-10-23T23:15:28Z",
            "published": "2023-10-23T23:15:28Z",
            "summary": "Spinal cord segmentation is clinically relevant and is notably used to\ncompute spinal cord cross-sectional area (CSA) for the diagnosis and monitoring\nof cord compression or neurodegenerative diseases such as multiple sclerosis.\nWhile several semi and automatic methods exist, one key limitation remains: the\nsegmentation depends on the MRI contrast, resulting in different CSA across\ncontrasts. This is partly due to the varying appearance of the boundary between\nthe spinal cord and the cerebrospinal fluid that depends on the sequence and\nacquisition parameters. This contrast-sensitive CSA adds variability in\nmulti-center studies where protocols can vary, reducing the sensitivity to\ndetect subtle atrophies. Moreover, existing methods enhance the CSA variability\nby training one model per contrast, while also producing binary masks that do\nnot account for partial volume effects. In this work, we present a deep\nlearning-based method that produces soft segmentations of the spinal cord.\nUsing the Spine Generic Public Database of healthy participants\n($\\text{n}=267$; $\\text{contrasts}=6$), we first generated participant-wise\nsoft ground truth (GT) by averaging the binary segmentations across all 6\ncontrasts. These soft GT, along with a regression-based loss function, were\nthen used to train a UNet model for spinal cord segmentation. We evaluated our\nmodel against state-of-the-art methods and performed ablation studies involving\ndifferent GT mask types, loss functions, and contrast-specific models. Our\nresults show that using the soft average segmentations along with a regression\nloss function reduces CSA variability ($p < 0.05$, Wilcoxon signed-rank test).\nThe proposed spinal cord segmentation model generalizes better than the\nstate-of-the-art contrast-specific methods amongst unseen datasets, vendors,\ncontrasts, and pathologies (compression, lesions), while accounting for partial\nvolume effects.",
            "author": [
                "Sandrine B\u00e9dard",
                "Naga Karthik Enamundram",
                "Charidimos Tsagkas",
                "Emanuele Pravat\u00e0",
                "Cristina Granziera",
                "Andrew Smith",
                "Kenneth Arnold Weber II",
                "Julien Cohen-Adad"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15402v1",
                "http://arxiv.org/pdf/2310.15402v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15393v1",
            "title": "DoGE: Domain Reweighting with Generalization Estimation",
            "updated": "2023-10-23T22:51:58Z",
            "published": "2023-10-23T22:51:58Z",
            "summary": "The coverage and composition of the pretraining data corpus significantly\nimpacts the generalization ability of large language models. Conventionally,\nthe pretraining corpus is composed of various source domains (e.g. CommonCrawl,\nWikipedia, Github etc.) according to certain sampling probabilities (domain\nweights). However, current methods lack a principled way to optimize domain\nweights for ultimate goal for generalization. We propose DOmain reweighting\nwith Generalization Estimation (DoGE), where we reweigh the sampling\nprobability from each domain based on its contribution to the final\ngeneralization objective assessed by a gradient-based generalization estimation\nfunction. First, we train a small-scale proxy model with a min-max optimization\nto obtain the reweighted domain weights. At each step, the domain weights are\nupdated to maximize the overall generalization gain by mirror descent. Finally\nwe use the obtained domain weights to train a larger scale full-size language\nmodel. On SlimPajama-6B dataset, with universal generalization objective, DoGE\nachieves better average perplexity and zero-shot reasoning accuracy. On\nout-of-domain generalization tasks, DoGE reduces perplexity on the target\ndomain by a large margin. We further apply a parameter-selection scheme which\nimproves the efficiency of generalization estimation.",
            "author": [
                "Simin Fan",
                "Matteo Pagliardini",
                "Martin Jaggi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15393v1",
                "http://arxiv.org/pdf/2310.15393v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15390v2",
            "title": "MEMPSEP III. A machine learning-oriented multivariate data set for\n  forecasting the Occurrence and Properties of Solar Energetic Particle Events\n  using a Multivariate Ensemble Approach",
            "updated": "2023-10-26T20:48:52Z",
            "published": "2023-10-23T22:42:23Z",
            "summary": "We introduce a new multivariate data set that utilizes multiple spacecraft\ncollecting in-situ and remote sensing heliospheric measurements shown to be\nlinked to physical processes responsible for generating solar energetic\nparticles (SEPs). Using the Geostationary Operational Environmental Satellites\n(GOES) flare event list from Solar Cycle (SC) 23 and part of SC 24 (1998-2013),\nwe identify 252 solar events (flares) that produce SEPs and 17,542 events that\ndo not. For each identified event, we acquire the local plasma properties at 1\nau, such as energetic proton and electron data, upstream solar wind conditions,\nand the interplanetary magnetic field vector quantities using various\ninstruments onboard GOES and the Advanced Composition Explorer (ACE)\nspacecraft. We also collect remote sensing data from instruments onboard the\nSolar Dynamic Observatory (SDO), Solar and Heliospheric Observatory (SoHO), and\nthe Wind solar radio instrument WAVES. The data set is designed to allow for\nvariations of the inputs and feature sets for machine learning (ML) in\nheliophysics and has a specific purpose for forecasting the occurrence of SEP\nevents and their subsequent properties. This paper describes a dataset created\nfrom multiple publicly available observation sources that is validated,\ncleaned, and carefully curated for our machine-learning pipeline. The dataset\nhas been used to drive the newly-developed Multivariate Ensemble of Models for\nProbabilistic Forecast of Solar Energetic Particles (MEMPSEP; see MEMPSEP I\n(Chatterjee et al., 2023) and MEMPSEP II (Dayeh et al., 2023) for associated\npapers).",
            "author": [
                "Kimberly Moreland",
                "Maher Dayeh",
                "Hazel M. Bain",
                "Subhamoy Chatterjee",
                "Andres Munoz-Jaramillo",
                "Samuel Hart"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15390v2",
                "http://arxiv.org/pdf/2310.15390v2"
            ],
            "primary_category": "astro-ph.SR",
            "category": [
                "astro-ph.SR",
                "cs.LG",
                "physics.space-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15389v1",
            "title": "Irreducible Curriculum for Language Model Pretraining",
            "updated": "2023-10-23T22:41:33Z",
            "published": "2023-10-23T22:41:33Z",
            "summary": "Automatic data selection and curriculum design for training large language\nmodels is challenging, with only a few existing methods showing improvements\nover standard training. Furthermore, current schemes focus on domain-level\nselection, overlooking the more fine-grained contributions of each individual\ntraining point. It is difficult to apply traditional datapoint selection\nmethods on large language models: most online batch selection methods perform\ntwo-times forward or backward passes, which introduces considerable extra costs\nwith large-scale models. To mitigate these obstacles, we propose irreducible\ncurriculum as a curriculum learning algorithm for language model pretraining,\nwhich prioritizes samples with higher learnability. Specifically, to avoid\nprohibitive extra computation overhead, we simulate the sample loss along the\nmain model's training trajectory using a small-scale proxy model. Our\nexperiments on the RedPajama-1B dataset demonstrate a consistent improvement on\nvalidation perplexity across all 7 domains compared to random uniform baseline\nand the anti-curriculum strategy. Our method also reduces the sharpness of the\nnetwork and illustrates a better 5-shot accuracy on MMLU benchmarks.",
            "author": [
                "Simin Fan",
                "Martin Jaggi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15389v1",
                "http://arxiv.org/pdf/2310.15389v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15388v1",
            "title": "Remote Heart Rate Monitoring in Smart Environments from Videos with\n  Self-supervised Pre-training",
            "updated": "2023-10-23T22:41:04Z",
            "published": "2023-10-23T22:41:04Z",
            "summary": "Recent advances in deep learning have made it increasingly feasible to\nestimate heart rate remotely in smart environments by analyzing videos.\nHowever, a notable limitation of deep learning methods is their heavy reliance\non extensive sets of labeled data for effective training. To address this\nissue, self-supervised learning has emerged as a promising avenue. Building on\nthis, we introduce a solution that utilizes self-supervised contrastive\nlearning for the estimation of remote photoplethysmography (PPG) and heart rate\nmonitoring, thereby reducing the dependence on labeled data and enhancing\nperformance. We propose the use of 3 spatial and 3 temporal augmentations for\ntraining an encoder through a contrastive framework, followed by utilizing the\nlate-intermediate embeddings of the encoder for remote PPG and heart rate\nestimation. Our experiments on two publicly available datasets showcase the\nimprovement of our proposed approach over several related works as well as\nsupervised learning baselines, as our results approach the state-of-the-art. We\nalso perform thorough experiments to showcase the effects of using different\ndesign choices such as the video representation learning method, the\naugmentations used in the pre-training stage, and others. We also demonstrate\nthe robustness of our proposed method over the supervised learning approaches\non reduced amounts of labeled data.",
            "author": [
                "Divij Gupta",
                "Ali Etemad"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15388v1",
                "http://arxiv.org/pdf/2310.15388v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15387v1",
            "title": "Error analysis of generative adversarial network",
            "updated": "2023-10-23T22:39:28Z",
            "published": "2023-10-23T22:39:28Z",
            "summary": "The generative adversarial network (GAN) is an important model developed for\nhigh-dimensional distribution learning in recent years. However, there is a\npressing need for a comprehensive method to understand its error convergence\nrate. In this research, we focus on studying the error convergence rate of the\nGAN model that is based on a class of functions encompassing the discriminator\nand generator neural networks. These functions are VC type with bounded\nenvelope function under our assumptions, enabling the application of the\nTalagrand inequality. By employing the Talagrand inequality and Borel-Cantelli\nlemma, we establish a tight convergence rate for the error of GAN. This method\ncan also be applied on existing error estimations of GAN and yields improved\nconvergence rates. In particular, the error defined with the neural network\ndistance is a special case error in our definition.",
            "author": [
                "Mahmud Hasan",
                "Hailin Sang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15387v1",
                "http://arxiv.org/pdf/2310.15387v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15386v2",
            "title": "Course Correcting Koopman Representations",
            "updated": "2023-11-23T06:32:10Z",
            "published": "2023-10-23T22:36:31Z",
            "summary": "Koopman representations aim to learn features of nonlinear dynamical systems\n(NLDS) which lead to linear dynamics in the latent space. Theoretically, such\nfeatures can be used to simplify many problems in modeling and control of NLDS.\nIn this work we study autoencoder formulations of this problem, and different\nways they can be used to model dynamics, specifically for future state\nprediction over long horizons. We discover several limitations of predicting\nfuture states in the latent space and propose an inference-time mechanism,\nwhich we refer to as Periodic Reencoding, for faithfully capturing long term\ndynamics. We justify this method both analytically and empirically via\nexperiments in low and high dimensional NLDS.",
            "author": [
                "Mahan Fathi",
                "Clement Gehring",
                "Jonathan Pilault",
                "David Kanaa",
                "Pierre-Luc Bacon",
                "Ross Goroshin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15386v2",
                "http://arxiv.org/pdf/2310.15386v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.RO",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18355v1",
            "title": "Health Disparities through Generative AI Models: A Comparison Study\n  Using A Domain Specific large language model",
            "updated": "2023-10-23T21:24:05Z",
            "published": "2023-10-23T21:24:05Z",
            "summary": "Health disparities are differences in health outcomes and access to\nhealthcare between different groups, including racial and ethnic minorities,\nlow-income people, and rural residents. An artificial intelligence (AI) program\ncalled large language models (LLMs) can understand and generate human language,\nimproving health communication and reducing health disparities. There are many\nchallenges in using LLMs in human-doctor interaction, including the need for\ndiverse and representative data, privacy concerns, and collaboration between\nhealthcare providers and technology experts. We introduce the comparative\ninvestigation of domain-specific large language models such as SciBERT with a\nmulti-purpose LLMs BERT. We used cosine similarity to analyze text queries\nabout health disparities in exam rooms when factors such as race are used\nalone. Using text queries, SciBERT fails when it doesn't differentiate between\nqueries text: \"race\" alone and \"perpetuates health disparities.\" We believe\nclinicians can use generative AI to create a draft response when communicating\nasynchronously with patients. However, careful attention must be paid to ensure\nthey are developed and implemented ethically and equitably.",
            "author": [
                "Yohn Jairo Parra Bautista",
                "Vinicious Lima",
                "Carlos Theran",
                "Richard Alo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18355v1",
                "http://arxiv.org/pdf/2310.18355v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15371v1",
            "title": "Vicinal Feature Statistics Augmentation for Federated 3D Medical Volume\n  Segmentation",
            "updated": "2023-10-23T21:14:52Z",
            "published": "2023-10-23T21:14:52Z",
            "summary": "Federated learning (FL) enables multiple client medical institutes\ncollaboratively train a deep learning (DL) model with privacy protection.\nHowever, the performance of FL can be constrained by the limited availability\nof labeled data in small institutes and the heterogeneous (i.e., non-i.i.d.)\ndata distribution across institutes. Though data augmentation has been a proven\ntechnique to boost the generalization capabilities of conventional centralized\nDL as a \"free lunch\", its application in FL is largely underexplored. Notably,\nconstrained by costly labeling, 3D medical segmentation generally relies on\ndata augmentation. In this work, we aim to develop a vicinal feature-level data\naugmentation (VFDA) scheme to efficiently alleviate the local feature shift and\nfacilitate collaborative training for privacy-aware FL segmentation. We take\nboth the inner- and inter-institute divergence into consideration, without the\nneed for cross-institute transfer of raw data or their mixup. Specifically, we\nexploit the batch-wise feature statistics (e.g., mean and standard deviation)\nin each institute to abstractly represent the discrepancy of data, and model\neach feature statistic probabilistically via a Gaussian prototype, with the\nmean corresponding to the original statistic and the variance quantifying the\naugmentation scope. From the vicinal risk minimization perspective, novel\nfeature statistics can be drawn from the Gaussian distribution to fulfill\naugmentation. The variance is explicitly derived by the data bias in each\nindividual institute and the underlying feature statistics characterized by all\nparticipating institutes. The added-on VFDA consistently yielded marked\nimprovements over six advanced FL methods on both 3D brain tumor and cardiac\nsegmentation.",
            "author": [
                "Yongsong Huang",
                "Wanqing Xie",
                "Mingzhen Li",
                "Mingmei Cheng",
                "Jinzhou Wu",
                "Weixiao Wang",
                "Jane You",
                "Xiaofeng Liu"
            ],
            "link": [
                "http://dx.doi.org/10.1007/978-3-031-34048-2_28",
                "http://arxiv.org/abs/2310.15371v1",
                "http://arxiv.org/pdf/2310.15371v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.AI",
                "cs.CV",
                "cs.LG",
                "physics.med-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15368v2",
            "title": "Deep Integrated Explanations",
            "updated": "2023-10-28T03:43:15Z",
            "published": "2023-10-23T21:03:30Z",
            "summary": "This paper presents Deep Integrated Explanations (DIX) - a universal method\nfor explaining vision models. DIX generates explanation maps by integrating\ninformation from the intermediate representations of the model, coupled with\ntheir corresponding gradients. Through an extensive array of both objective and\nsubjective evaluations spanning diverse tasks, datasets, and model\nconfigurations, we showcase the efficacy of DIX in generating faithful and\naccurate explanation maps, while surpassing current state-of-the-art methods.",
            "author": [
                "Oren Barkan",
                "Yehonatan Elisha",
                "Jonathan Weill",
                "Yuval Asher",
                "Amit Eshel",
                "Noam Koenigstein"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15368v2",
                "http://arxiv.org/pdf/2310.15368v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15365v1",
            "title": "Prandtl number effects on extreme mixing events in forced stratified\n  turbulence",
            "updated": "2023-10-23T20:58:39Z",
            "published": "2023-10-23T20:58:39Z",
            "summary": "Relatively strongly stratified turbulent flows tend to self-organise into a\n'layered anisotropic stratified turbulence' (LAST) regime, characterised by\nrelatively deep and well-mixed density 'layers' separated by relatively thin\n'interfaces' of enhanced density gradient. Understanding the associated mixing\ndynamics is a central problem in geophysical fluid dynamics. It is challenging\nto study 'LAST' mixing, as it is associated with Reynolds numbers $Re := UL/\\nu\n\\gg 1$ and Froude numbers $Fr :=(2\\pi U)/(L N) \\ll 1$, ($U$ and $L$ being\ncharacteristic velocity and length scales, $\\nu$ being the kinematic viscosity\nand $N$ the buoyancy frequency). Since a sufficiently large dynamic range\n(largely) unaffected by stratification and viscosity is required, it is also\nnecessary for the buoyancy Reynolds number $Re_{b} := \\epsilon/(\\nu N^{2}) \\gg\n1$ where $\\epsilon$ is the (appropriately volume-averaged) turbulent kinetic\nenergy dissipation rate. This requirement is exacerbated for oceanically\nrelevant flows, as the Prandtl number $Pr := \\nu/\\kappa = \\mathcal{O}(10)$ in\nthermally-stratified water (where $\\kappa$ is the thermal diffusivity), thus\nleading (potentially) to even finer density field structures. We report here on\nfour forced fully resolved direct numerical simulations of stratified\nturbulence at various Froude ($Fr=0.5, 2$) and Prandtl numbers ($Pr=1, 7$)\nforced so that $Re_{b}=50$, with resolutions up to $30240 \\times 30240 \\times\n3780$. We find that, as $Pr$ increases, emergent 'interfaces' become finer and\ntheir contribution to bulk mixing characteristics decreases at the expense of\nthe small-scale density structures populating the well-mixed 'layers'. However,\nextreme mixing events (as quantified by significantly elevated local\ndestruction rates of buoyancy variance $\\chi_0$) are always preferentially\nfound in the (statically stable) interfaces, irrespective of the value of $Pr$.",
            "author": [
                "Nicolaos Petropoulos",
                "Miles M. P. Couchman",
                "Ali Mashayek",
                "Stephen M. de Bruyn Kops",
                "Colm-cille P. Caulfield"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15365v1",
                "http://arxiv.org/pdf/2310.15365v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15358v1",
            "title": "Learning Fair Representations with High-Confidence Guarantees",
            "updated": "2023-10-23T20:43:03Z",
            "published": "2023-10-23T20:43:03Z",
            "summary": "Representation learning is increasingly employed to generate representations\nthat are predictive across multiple downstream tasks. The development of\nrepresentation learning algorithms that provide strong fairness guarantees is\nthus important because it can prevent unfairness towards disadvantaged groups\nfor all downstream prediction tasks. To prevent unfairness towards\ndisadvantaged groups in all downstream tasks, it is crucial to provide\nrepresentation learning algorithms that provide fairness guarantees. In this\npaper, we formally define the problem of learning representations that are fair\nwith high confidence. We then introduce the Fair Representation learning with\nhigh-confidence Guarantees (FRG) framework, which provides high-confidence\nguarantees for limiting unfairness across all downstream models and tasks, with\nuser-defined upper bounds. After proving that FRG ensures fairness for all\ndownstream models and tasks with high probability, we present empirical\nevaluations that demonstrate FRG's effectiveness at upper bounding unfairness\nfor multiple downstream models and tasks.",
            "author": [
                "Yuhong Luo",
                "Austin Hoag",
                "Philip S. Thomas"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15358v1",
                "http://arxiv.org/pdf/2310.15358v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CY",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15355v1",
            "title": "Why LLMs Hallucinate, and How to Get (Evidential) Closure: Perceptual,\n  Intensional, and Extensional Learning for Faithful Natural Language\n  Generation",
            "updated": "2023-10-23T20:35:52Z",
            "published": "2023-10-23T20:35:52Z",
            "summary": "We show that LLMs hallucinate because their output is not constrained to be\nsynonymous with claims for which they have evidence: a condition that we call\nevidential closure. Information about the truth or falsity of sentences is not\nstatistically identified in the standard neural probabilistic language model\nsetup, and so cannot be conditioned on to generate new strings. We then show\nhow to constrain LLMs to produce output that does satisfy evidential closure. A\nmultimodal LLM must learn about the external world (perceptual learning); it\nmust learn a mapping from strings to states of the world (extensional\nlearning); and, to achieve fluency when generalizing beyond a body of evidence,\nit must learn mappings from strings to their synonyms (intensional learning).\nThe output of a unimodal LLM must be synonymous with strings in a validated\nevidence set. Finally, we present a heuristic procedure, Learn-Babble-Prune,\nthat yields faithful output from an LLM by rejecting output that is not\nsynonymous with claims for which the LLM has evidence.",
            "author": [
                "Adam Bouyamourn"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15355v1",
                "http://arxiv.org/pdf/2310.15355v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15351v1",
            "title": "Random Exploration in Bayesian Optimization: Order-Optimal Regret and\n  Computational Efficiency",
            "updated": "2023-10-23T20:30:44Z",
            "published": "2023-10-23T20:30:44Z",
            "summary": "We consider Bayesian optimization using Gaussian Process models, also\nreferred to as kernel-based bandit optimization. We study the methodology of\nexploring the domain using random samples drawn from a distribution. We show\nthat this random exploration approach achieves the optimal error rates. Our\nanalysis is based on novel concentration bounds in an infinite dimensional\nHilbert space established in this work, which may be of independent interest.\nWe further develop an algorithm based on random exploration with domain\nshrinking and establish its order-optimal regret guarantees under both\nnoise-free and noisy settings. In the noise-free setting, our analysis closes\nthe existing gap in regret performance and thereby resolves a COLT open\nproblem. The proposed algorithm also enjoys a computational advantage over\nprevailing methods due to the random exploration that obviates the expensive\noptimization of a non-convex acquisition function for choosing the query points\nat each iteration.",
            "author": [
                "Sudeep Salgia",
                "Sattar Vakili",
                "Qing Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15351v1",
                "http://arxiv.org/pdf/2310.15351v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18354v1",
            "title": "A Review of Reinforcement Learning for Natural Language Processing, and\n  Applications in Healthcare",
            "updated": "2023-10-23T20:26:15Z",
            "published": "2023-10-23T20:26:15Z",
            "summary": "Reinforcement learning (RL) has emerged as a powerful approach for tackling\ncomplex medical decision-making problems such as treatment planning,\npersonalized medicine, and optimizing the scheduling of surgeries and\nappointments. It has gained significant attention in the field of Natural\nLanguage Processing (NLP) due to its ability to learn optimal strategies for\ntasks such as dialogue systems, machine translation, and question-answering.\nThis paper presents a review of the RL techniques in NLP, highlighting key\nadvancements, challenges, and applications in healthcare. The review begins by\nvisualizing a roadmap of machine learning and its applications in healthcare.\nAnd then it explores the integration of RL with NLP tasks. We examined dialogue\nsystems where RL enables the learning of conversational strategies, RL-based\nmachine translation models, question-answering systems, text summarization, and\ninformation extraction. Additionally, ethical considerations and biases in\nRL-NLP systems are addressed.",
            "author": [
                "Ying Liu",
                "Haozhu Wang",
                "Huixue Zhou",
                "Mingchen Li",
                "Yu Hou",
                "Sicheng Zhou",
                "Fang Wang",
                "Rama Hoetzlein",
                "Rui Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18354v1",
                "http://arxiv.org/pdf/2310.18354v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15349v1",
            "title": "Scalable machine learning-assisted clear-box characterization for\n  optimally controlled photonic circuits",
            "updated": "2023-10-23T20:24:30Z",
            "published": "2023-10-23T20:24:30Z",
            "summary": "Photonic integrated circuits offer a compact and stable platform for\ngenerating, manipulating, and detecting light. They are instrumental for\nclassical and quantum applications. Imperfections stemming from fabrication\nconstraints, tolerances and operation wavelength impose limitations on the\naccuracy and thus utility of current photonic integrated devices. Mitigating\nthese imperfections typically necessitates a model of the underlying physical\nstructure and the estimation of parameters that are challenging to access.\nDirect solutions are currently lacking for mesh configurations extending beyond\ntrivial cases. We introduce a scalable and innovative method to characterize\nphotonic chips through an iterative machine learning-assisted procedure. Our\nmethod is based on a clear-box approach that harnesses a fully modeled virtual\nreplica of the photonic chip to characterize. The process is sample-efficient\nand can be carried out with a continuous-wave laser and powermeters. The model\nestimates individual passive phases, crosstalk, beamsplitter reflectivity\nvalues and relative input/output losses. Building upon the accurate\ncharacterization results, we mitigate imperfections to enable enhanced control\nover the device. We validate our characterization and imperfection mitigation\nmethods on a 12-mode Clements-interferometer equipped with 126 phase shifters,\nachieving beyond state-of-the-art chip control with an average 99.77 %\namplitude fidelity on 100 implemented Haar-random unitary matrices.",
            "author": [
                "Andreas Fyrillas",
                "Olivier Faure",
                "Nicolas Maring",
                "Jean Senellart",
                "Nadia Belabas"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15349v1",
                "http://arxiv.org/pdf/2310.15349v1"
            ],
            "primary_category": "physics.optics",
            "category": [
                "physics.optics",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15343v1",
            "title": "Burgers' pinns with implicit euler transfer learning",
            "updated": "2023-10-23T20:15:45Z",
            "published": "2023-10-23T20:15:45Z",
            "summary": "The Burgers equation is a well-established test case in the computational\nmodeling of several phenomena such as fluid dynamics, gas dynamics, shock\ntheory, cosmology, and others. In this work, we present the application of\nPhysics-Informed Neural Networks (PINNs) with an implicit Euler transfer\nlearning approach to solve the Burgers equation. The proposed approach consists\nin seeking a time-discrete solution by a sequence of Artificial Neural Networks\n(ANNs). At each time step, the previous ANN transfers its knowledge to the next\nnetwork model, which learns the current time solution by minimizing a loss\nfunction based on the implicit Euler approximation of the Burgers equation. The\napproach is tested for two benchmark problems: the first with an exact solution\nand the other with an alternative analytical solution. In comparison to the\nusual PINN models, the proposed approach has the advantage of requiring smaller\nneural network architectures with similar accurate results and potentially\ndecreasing computational costs.",
            "author": [
                "Vit\u00f3ria Biesek",
                "Pedro Henrique de Almeida Konzen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15343v1",
                "http://arxiv.org/pdf/2310.15343v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NA",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15342v2",
            "title": "Towards Hybrid-grained Feature Interaction Selection for Deep Sparse\n  Network",
            "updated": "2023-10-30T15:01:26Z",
            "published": "2023-10-23T20:15:30Z",
            "summary": "Deep sparse networks are widely investigated as a neural network architecture\nfor prediction tasks with high-dimensional sparse features, with which feature\ninteraction selection is a critical component. While previous methods primarily\nfocus on how to search feature interaction in a coarse-grained space, less\nattention has been given to a finer granularity. In this work, we introduce a\nhybrid-grained feature interaction selection approach that targets both feature\nfield and feature value for deep sparse networks. To explore such expansive\nspace, we propose a decomposed space which is calculated on the fly. We then\ndevelop a selection algorithm called OptFeature, which efficiently selects the\nfeature interaction from both the feature field and the feature value\nsimultaneously. Results from experiments on three large real-world benchmark\ndatasets demonstrate that OptFeature performs well in terms of accuracy and\nefficiency. Additional studies support the feasibility of our method.",
            "author": [
                "Fuyuan Lyu",
                "Xing Tang",
                "Dugang Liu",
                "Chen Ma",
                "Weihong Luo",
                "Liang Chen",
                "Xiuqiang He",
                "Xue Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15342v2",
                "http://arxiv.org/pdf/2310.15342v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15334v1",
            "title": "ADMM Training Algorithms for Residual Networks: Convergence, Complexity\n  and Parallel Training",
            "updated": "2023-10-23T20:01:06Z",
            "published": "2023-10-23T20:01:06Z",
            "summary": "We design a series of serial and parallel proximal point (gradient) ADMMs for\nthe fully connected residual networks (FCResNets) training problem by\nintroducing auxiliary variables. Convergence of the proximal point version is\nproven based on a Kurdyka-Lojasiewicz (KL) property analysis framework, and we\ncan ensure a locally R-linear or sublinear convergence rate depending on the\ndifferent ranges of the Kurdyka-Lojasiewicz (KL) exponent, in which a necessary\nauxiliary function is constructed to realize our goal. Moreover, the advantages\nof the parallel implementation in terms of lower time complexity and less\n(per-node) memory consumption are analyzed theoretically. To the best of our\nknowledge, this is the first work analyzing the convergence, convergence rate,\ntime complexity and (per-node) runtime memory requirement of the ADMM applied\nin the FCResNets training problem theoretically. Experiments are reported to\nshow the high speed, better performance, robustness and potential in the deep\nnetwork training tasks. Finally, we present the advantage and potential of our\nparallel training in large-scale problems.",
            "author": [
                "Jintao Xu",
                "Yifei Li",
                "Wenxun Xing"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15334v1",
                "http://arxiv.org/pdf/2310.15334v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15333v1",
            "title": "Estimating Trustworthy and Safe Optimal Treatment Regimes",
            "updated": "2023-10-23T19:59:10Z",
            "published": "2023-10-23T19:59:10Z",
            "summary": "Recent statistical and reinforcement learning methods have significantly\nadvanced patient care strategies. However, these approaches face substantial\nchallenges in high-stakes contexts, including missing data, inherent\nstochasticity, and the critical requirements for interpretability and patient\nsafety. Our work operationalizes a safe and interpretable framework to identify\noptimal treatment regimes. This approach involves matching patients with\nsimilar medical and pharmacological characteristics, allowing us to construct\nan optimal policy via interpolation. We perform a comprehensive simulation\nstudy to demonstrate the framework's ability to identify optimal policies even\nin complex settings. Ultimately, we operationalize our approach to study\nregimes for treating seizures in critically ill patients. Our findings strongly\nsupport personalized treatment strategies based on a patient's medical history\nand pharmacological features. Notably, we identify that reducing medication\ndoses for patients with mild and brief seizure episodes while adopting\naggressive treatment for patients in intensive care unit experiencing intense\nseizures leads to more favorable outcomes.",
            "author": [
                "Harsh Parikh",
                "Quinn Lanners",
                "Zade Akras",
                "Sahar F. Zafar",
                "M. Brandon Westover",
                "Cynthia Rudin",
                "Alexander Volfovsky"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15333v1",
                "http://arxiv.org/pdf/2310.15333v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.AP",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15330v1",
            "title": "Unsupervised Federated Learning: A Federated Gradient EM Algorithm for\n  Heterogeneous Mixture Models with Robustness against Adversarial Attacks",
            "updated": "2023-10-23T19:53:36Z",
            "published": "2023-10-23T19:53:36Z",
            "summary": "While supervised federated learning approaches have enjoyed significant\nsuccess, the domain of unsupervised federated learning remains relatively\nunderexplored. In this paper, we introduce a novel federated gradient EM\nalgorithm designed for the unsupervised learning of mixture models with\nheterogeneous mixture proportions across tasks. We begin with a comprehensive\nfinite-sample theory that holds for general mixture models, then apply this\ngeneral theory on Gaussian Mixture Models (GMMs) and Mixture of Regressions\n(MoRs) to characterize the explicit estimation error of model parameters and\nmixture proportions. Our proposed federated gradient EM algorithm demonstrates\nseveral key advantages: adaptability to unknown task similarity, resilience\nagainst adversarial attacks on a small fraction of data sources, protection of\nlocal data privacy, and computational and communication efficiency.",
            "author": [
                "Ye Tian",
                "Haolei Weng",
                "Yang Feng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15330v1",
                "http://arxiv.org/pdf/2310.15330v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15329v1",
            "title": "Serverless Federated Learning with flwr-serverless",
            "updated": "2023-10-23T19:49:59Z",
            "published": "2023-10-23T19:49:59Z",
            "summary": "Federated learning is becoming increasingly relevant and popular as we\nwitness a surge in data collection and storage of personally identifiable\ninformation. Alongside these developments there have been many proposals from\ngovernments around the world to provide more protections for individuals' data\nand a heightened interest in data privacy measures. As deep learning continues\nto become more relevant in new and existing domains, it is vital to develop\nstrategies like federated learning that can effectively train data from\ndifferent sources, such as edge devices, without compromising security and\nprivacy. Recently, the Flower (\\texttt{Flwr}) Python package was introduced to\nprovide a scalable, flexible, and easy-to-use framework for implementing\nfederated learning. However, to date, Flower is only able to run synchronous\nfederated learning which can be costly and time-consuming to run because the\nprocess is bottlenecked by client-side training jobs that are slow or fragile.\nHere, we introduce \\texttt{flwr-serverless}, a wrapper around the Flower\npackage that extends its functionality to allow for both synchronous and\nasynchronous federated learning with minimal modification to Flower's design\nparadigm. Furthermore, our approach to federated learning allows the process to\nrun without a central server, which increases the domains of application and\naccessibility of its use. This paper presents the design details and usage of\nthis approach through a series of experiments that were conducted using public\ndatasets. Overall, we believe that our approach decreases the time and cost to\nrun federated training and provides an easier way to implement and experiment\nwith federated learning systems.",
            "author": [
                "Sanjeev V. Namjoshi",
                "Reese Green",
                "Krishi Sharma",
                "Zhangzhang Si"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15329v1",
                "http://arxiv.org/pdf/2310.15329v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15328v1",
            "title": "DeepVox and SAVE-CT: a contrast- and dose-independent 3D deep learning\n  approach for thoracic aorta segmentation and aneurysm prediction using\n  computed tomography scans",
            "updated": "2023-10-23T19:48:58Z",
            "published": "2023-10-23T19:48:58Z",
            "summary": "Thoracic aortic aneurysm (TAA) is a fatal disease which potentially leads to\ndissection or rupture through progressive enlargement of the aorta. It is\nusually asymptomatic and screening recommendation are limited. The\ngold-standard evaluation is performed by computed tomography angiography (CTA)\nand radiologists time-consuming assessment. Scans for other indications could\nhelp on this screening, however if acquired without contrast enhancement or\nwith low dose protocol, it can make the clinical evaluation difficult, besides\nincreasing the scans quantity for the radiologists. In this study, it was\nselected 587 unique CT scans including control and TAA patients, acquired with\nlow and standard dose protocols, with or without contrast enhancement. A novel\nsegmentation model, DeepVox, exhibited dice score coefficients of 0.932 and\n0.897 for development and test sets, respectively, with faster training speed\nin comparison to models reported in the literature. The novel TAA\nclassification model, SAVE-CT, presented accuracies of 0.930 and 0.922 for\ndevelopment and test sets, respectively, using only the binary segmentation\nmask from DeepVox as input, without hand-engineered features. These two models\ntogether are a potential approach for TAA screening, as they can handle\nvariable number of slices as input, handling thoracic and thoracoabdominal\nsequences, in a fully automated contrast- and dose-independent evaluation. This\nmay assist to decrease TAA mortality and prioritize the evaluation queue of\npatients for radiologists.",
            "author": [
                "Matheus del-Valle",
                "Lariza Laura de Oliveira",
                "Henrique Cursino Vieira",
                "Henrique Min Ho Lee",
                "Lucas Lembran\u00e7a Pinheiro",
                "Maria Fernanda Portugal",
                "Newton Shydeo Brand\u00e3o Miyoshi",
                "Nelson Wolosker"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15328v1",
                "http://arxiv.org/pdf/2310.15328v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG",
                "I.2; I.4"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15325v1",
            "title": "LXMERT Model Compression for Visual Question Answering",
            "updated": "2023-10-23T19:46:41Z",
            "published": "2023-10-23T19:46:41Z",
            "summary": "Large-scale pretrained models such as LXMERT are becoming popular for\nlearning cross-modal representations on text-image pairs for vision-language\ntasks. According to the lottery ticket hypothesis, NLP and computer vision\nmodels contain smaller subnetworks capable of being trained in isolation to\nfull performance. In this paper, we combine these observations to evaluate\nwhether such trainable subnetworks exist in LXMERT when fine-tuned on the VQA\ntask. In addition, we perform a model size cost-benefit analysis by\ninvestigating how much pruning can be done without significant loss in\naccuracy. Our experiment results demonstrate that LXMERT can be effectively\npruned by 40%-60% in size with 3% loss in accuracy.",
            "author": [
                "Maryam Hashemi",
                "Ghazaleh Mahmoudi",
                "Sara Kodeiri",
                "Hadi Sheikhi",
                "Sauleh Eetemadi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15325v1",
                "http://arxiv.org/pdf/2310.15325v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15319v1",
            "title": "Hallucination Detection for Grounded Instruction Generation",
            "updated": "2023-10-23T19:36:28Z",
            "published": "2023-10-23T19:36:28Z",
            "summary": "We investigate the problem of generating instructions to guide humans to\nnavigate in simulated residential environments. A major issue with current\nmodels is hallucination: they generate references to actions or objects that\nare inconsistent with what a human follower would perform or encounter along\nthe described path. We develop a model that detects these hallucinated\nreferences by adopting a model pre-trained on a large corpus of image-text\npairs, and fine-tuning it with a contrastive loss that separates correct\ninstructions from instructions containing synthesized hallucinations. Our final\nmodel outperforms several baselines, including using word probability estimated\nby the instruction-generation model, and supervised models based on LSTM and\nTransformer.",
            "author": [
                "Lingjun Zhao",
                "Khanh Nguyen",
                "Hal Daum\u00e9 III"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15319v1",
                "http://arxiv.org/pdf/2310.15319v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15318v1",
            "title": "HetGPT: Harnessing the Power of Prompt Tuning in Pre-Trained\n  Heterogeneous Graph Neural Networks",
            "updated": "2023-10-23T19:35:57Z",
            "published": "2023-10-23T19:35:57Z",
            "summary": "Graphs have emerged as a natural choice to represent and analyze the\nintricate patterns and rich information of the Web, enabling applications such\nas online page classification and social recommendation. The prevailing\n\"pre-train, fine-tune\" paradigm has been widely adopted in graph machine\nlearning tasks, particularly in scenarios with limited labeled nodes. However,\nthis approach often exhibits a misalignment between the training objectives of\npretext tasks and those of downstream tasks. This gap can result in the\n\"negative transfer\" problem, wherein the knowledge gained from pre-training\nadversely affects performance in the downstream tasks. The surge in\nprompt-based learning within Natural Language Processing (NLP) suggests the\npotential of adapting a \"pre-train, prompt\" paradigm to graphs as an\nalternative. However, existing graph prompting techniques are tailored to\nhomogeneous graphs, neglecting the inherent heterogeneity of Web graphs. To\nbridge this gap, we propose HetGPT, a general post-training prompting framework\nto improve the predictive performance of pre-trained heterogeneous graph neural\nnetworks (HGNNs). The key is the design of a novel prompting function that\nintegrates a virtual class prompt and a heterogeneous feature prompt, with the\naim to reformulate downstream tasks to mirror pretext tasks. Moreover, HetGPT\nintroduces a multi-view neighborhood aggregation mechanism, capturing the\ncomplex neighborhood structure in heterogeneous graphs. Extensive experiments\non three benchmark datasets demonstrate HetGPT's capability to enhance the\nperformance of state-of-the-art HGNNs on semi-supervised node classification.",
            "author": [
                "Yihong Ma",
                "Ning Yan",
                "Jiayu Li",
                "Masood Mortazavi",
                "Nitesh V. Chawla"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15318v1",
                "http://arxiv.org/pdf/2310.15318v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15316v1",
            "title": "Probing Representations for Document-level Event Extraction",
            "updated": "2023-10-23T19:33:04Z",
            "published": "2023-10-23T19:33:04Z",
            "summary": "The probing classifiers framework has been employed for interpreting deep\nneural network models for a variety of natural language processing (NLP)\napplications. Studies, however, have largely focused on sentencelevel NLP\ntasks. This work is the first to apply the probing paradigm to representations\nlearned for document-level information extraction (IE). We designed eight\nembedding probes to analyze surface, semantic, and event-understanding\ncapabilities relevant to document-level event extraction. We apply them to the\nrepresentations acquired by learning models from three different LLM-based\ndocument-level IE approaches on a standard dataset. We found that trained\nencoders from these models yield embeddings that can modestly improve argument\ndetections and labeling but only slightly enhance event-level tasks, albeit\ntrade-offs in information helpful for coherence and event-type prediction. We\nfurther found that encoder models struggle with document length and\ncross-sentence discourse.",
            "author": [
                "Barry Wang",
                "Xinya Du",
                "Claire Cardie"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15316v1",
                "http://arxiv.org/pdf/2310.15316v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15314v1",
            "title": "Combining linear-scaling quantum transport and machine-learning\n  molecular dynamics to study thermal and electronic transports in complex\n  materials",
            "updated": "2023-10-23T19:31:01Z",
            "published": "2023-10-23T19:31:01Z",
            "summary": "We propose an efficient approach for simultaneous prediction of thermal and\nelectronic transport properties in complex materials. Firstly, a highly\nefficient machine-learned neuroevolution potential is trained using reference\ndata from quantum-mechanical density-functional theory calculations. This\ntrained potential is then applied in large-scale molecular dynamics\nsimulations, enabling the generation of realistic structures and accurate\ncharacterization of thermal transport properties. In addition, molecular\ndynamics simulations of atoms and linear-scaling quantum transport calculations\nof electrons are coupled to account for the electron-phonon scattering and\nother disorders that affect the charge carriers governing the electronic\ntransport properties. We demonstrate the usefulness of this unified approach by\nstudying thermoelectric transport properties of a graphene antidot lattice.",
            "author": [
                "Zheyong Fan",
                "Yang Xiao",
                "Yanzhou Wang",
                "Penghua Ying",
                "Shunda Chen",
                "Haikuan Dong"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15314v1",
                "http://arxiv.org/pdf/2310.15314v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15308v2",
            "title": "SAM-CLIP: Merging Vision Foundation Models towards Semantic and Spatial\n  Understanding",
            "updated": "2023-11-20T00:56:15Z",
            "published": "2023-10-23T19:21:57Z",
            "summary": "The landscape of publicly available vision foundation models (VFMs), such as\nCLIP and Segment Anything Model (SAM), is expanding rapidly. VFMs are endowed\nwith distinct capabilities stemming from their pre-training objectives. For\ninstance, CLIP excels in semantic understanding, while SAM specializes in\nspatial understanding for segmentation. In this work, we introduce a simple\nrecipe to efficiently merge VFMs into a unified model that absorbs their\nexpertise. Our method integrates techniques of multi-task learning, continual\nlearning, and distillation. Further, it demands significantly less\ncomputational cost compared to traditional multi-task training from scratch,\nand it only needs a small fraction of the pre-training datasets that were\ninitially used to train individual models. By applying our method to SAM and\nCLIP, we obtain SAM-CLIP: a unified model that combines the capabilities of SAM\nand CLIP into a single vision transformer. Compared with deploying SAM and CLIP\nindependently, our merged model, SAM-CLIP, reduces storage and compute costs\nfor inference, making it well-suited for edge device applications. We show that\nSAM-CLIP not only retains the foundational strengths of SAM and CLIP, but also\nintroduces synergistic functionalities, notably in zero-shot semantic\nsegmentation, where SAM-CLIP establishes new state-of-the-art results on 5\nbenchmarks. It outperforms previous models that are specifically designed for\nthis task by a large margin, including +6.8% and +5.9% mean IoU improvement on\nPascal-VOC and COCO-Stuff datasets, respectively.",
            "author": [
                "Haoxiang Wang",
                "Pavan Kumar Anasosalu Vasu",
                "Fartash Faghri",
                "Raviteja Vemulapalli",
                "Mehrdad Farajtabar",
                "Sachin Mehta",
                "Mohammad Rastegari",
                "Oncel Tuzel",
                "Hadi Pouransari"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15308v2",
                "http://arxiv.org/pdf/2310.15308v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15301v1",
            "title": "ADMarker: A Multi-Modal Federated Learning System for Monitoring Digital\n  Biomarkers of Alzheimer's Disease",
            "updated": "2023-10-23T19:07:33Z",
            "published": "2023-10-23T19:07:33Z",
            "summary": "Alzheimer's Disease (AD) and related dementia are a growing global health\nchallenge due to the aging population. In this paper, we present ADMarker, the\nfirst end-to-end system that integrates multi-modal sensors and new federated\nlearning algorithms for detecting multidimensional AD digital biomarkers in\nnatural living environments. ADMarker features a novel three-stage multi-modal\nfederated learning architecture that can accurately detect digital biomarkers\nin a privacy-preserving manner. Our approach collectively addresses several\nmajor real-world challenges, such as limited data labels, data heterogeneity,\nand limited computing resources. We built a compact multi-modality hardware\nsystem and deployed it in a four-week clinical trial involving 91 elderly\nparticipants. The results indicate that ADMarker can accurately detect a\ncomprehensive set of digital biomarkers with up to 93.8% accuracy and identify\nearly AD with an average of 88.9% accuracy. ADMarker offers a new platform that\ncan allow AD clinicians to characterize and track the complex correlation\nbetween multidimensional interpretable digital biomarkers, demographic factors\nof patients, and AD diagnosis in a longitudinal manner.",
            "author": [
                "Xiaomin Ouyang",
                "Xian Shuai",
                "Yang Li",
                "Li Pan",
                "Xifan Zhang",
                "Heming Fu",
                "Xinyan Wang",
                "Shihua Cao",
                "Jiang Xin",
                "Hazel Mok",
                "Zhenyu Yan",
                "Doris Sau Fung Yu",
                "Timothy Kwok",
                "Guoliang Xing"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15301v1",
                "http://arxiv.org/pdf/2310.15301v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15299v1",
            "title": "Neural Network with Local Converging Input (NNLCI) for Supersonic Flow\n  Problems with Unstructured Grids",
            "updated": "2023-10-23T19:03:37Z",
            "published": "2023-10-23T19:03:37Z",
            "summary": "In recent years, surrogate models based on deep neural networks (DNN) have\nbeen widely used to solve partial differential equations, which were\ntraditionally handled by means of numerical simulations. This kind of surrogate\nmodels, however, focuses on global interpolation of the training dataset, and\nthus requires a large network structure. The process is both time consuming and\ncomputationally costly, thereby restricting their use for high-fidelity\nprediction of complex physical problems. In the present study, we develop a\nneural network with local converging input (NNLCI) for high-fidelity prediction\nusing unstructured data. The framework utilizes the local domain of dependence\nwith converging coarse solutions as input, which greatly reduces computational\nresource and training time. As a validation case, the NNLCI method is applied\nto study inviscid supersonic flows in channels with bumps. Different bump\ngeometries and locations are considered to benchmark the effectiveness and\nversability of the proposed approach. Detailed flow structures, including\nshock-wave interactions, are examined systematically.",
            "author": [
                "Weiming Ding",
                "Haoxiang Huang",
                "Tzu Jung Lee",
                "Yingjie Liu",
                "Vigor Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15299v1",
                "http://arxiv.org/pdf/2310.15299v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.AI",
                "cs.LG",
                "cs.NA",
                "physics.flu-dyn",
                "35Q31"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15294v1",
            "title": "Adaptive End-to-End Metric Learning for Zero-Shot Cross-Domain Slot\n  Filling",
            "updated": "2023-10-23T19:01:16Z",
            "published": "2023-10-23T19:01:16Z",
            "summary": "Recently slot filling has witnessed great development thanks to deep learning\nand the availability of large-scale annotated data. However, it poses a\ncritical challenge to handle a novel domain whose samples are never seen during\ntraining. The recognition performance might be greatly degraded due to severe\ndomain shifts. Most prior works deal with this problem in a two-pass pipeline\nmanner based on metric learning. In practice, these dominant pipeline models\nmay be limited in computational efficiency and generalization capacity because\nof non-parallel inference and context-free discrete label embeddings. To this\nend, we re-examine the typical metric-based methods, and propose a new adaptive\nend-to-end metric learning scheme for the challenging zero-shot slot filling.\nConsidering simplicity, efficiency and generalizability, we present a\ncascade-style joint learning framework coupled with context-aware soft label\nrepresentations and slot-level contrastive representation learning to mitigate\nthe data and label shift problems effectively. Extensive experiments on public\nbenchmarks demonstrate the superiority of the proposed approach over a series\nof competitive baselines.",
            "author": [
                "Yuanjun Shi",
                "Linzhi Wu",
                "Minglai Shao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15294v1",
                "http://arxiv.org/pdf/2310.15294v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15290v2",
            "title": "Reliable Generation of EHR Time Series via Diffusion Models",
            "updated": "2023-11-21T22:19:09Z",
            "published": "2023-10-23T18:56:01Z",
            "summary": "Electronic Health Records (EHRs) are rich sources of patient-level data,\nincluding laboratory tests, medications, and diagnoses, offering valuable\nresources for medical data analysis. However, concerns about privacy often\nrestrict access to EHRs, hindering downstream analysis. Researchers have\nexplored various methods for generating privacy-preserving EHR data. In this\nstudy, we introduce a new method for generating diverse and realistic synthetic\nEHR time series data using Denoising Diffusion Probabilistic Models (DDPM). We\nconducted experiments on six datasets, comparing our proposed method with eight\nexisting methods. Our results demonstrate that our approach significantly\noutperforms all existing methods in terms of data utility while requiring less\ntraining effort. Our approach also enhances downstream medical data analysis by\nproviding diverse and realistic synthetic EHR data.",
            "author": [
                "Muhang Tian",
                "Bernie Chen",
                "Allan Guo",
                "Shiyi Jiang",
                "Anru R. Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15290v2",
                "http://arxiv.org/pdf/2310.15290v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15288v1",
            "title": "Active teacher selection for reinforcement learning from human feedback",
            "updated": "2023-10-23T18:54:43Z",
            "published": "2023-10-23T18:54:43Z",
            "summary": "Reinforcement learning from human feedback (RLHF) enables machine learning\nsystems to learn objectives from human feedback. A core limitation of these\nsystems is their assumption that all feedback comes from a single human\nteacher, despite querying a range of distinct teachers. We propose the Hidden\nUtility Bandit (HUB) framework to model differences in teacher rationality,\nexpertise, and costliness, formalizing the problem of learning from multiple\nteachers. We develop a variety of solution algorithms and apply them to two\nreal-world domains: paper recommendation systems and COVID-19 vaccine testing.\nWe find that the Active Teacher Selection (ATS) algorithm outperforms baseline\nalgorithms by actively selecting when and which teacher to query. The HUB\nframework and ATS algorithm demonstrate the importance of leveraging\ndifferences between teachers to learn accurate reward models, facilitating\nfuture research on active teacher selection for robust reward modeling.",
            "author": [
                "Rachel Freedman",
                "Justin Svegliato",
                "Kyle Wray",
                "Stuart Russell"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15288v1",
                "http://arxiv.org/pdf/2310.15288v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15286v1",
            "title": "A Doubly Robust Approach to Sparse Reinforcement Learning",
            "updated": "2023-10-23T18:52:17Z",
            "published": "2023-10-23T18:52:17Z",
            "summary": "We propose a new regret minimization algorithm for episodic sparse linear\nMarkov decision process (SMDP) where the state-transition distribution is a\nlinear function of observed features. The only previously known algorithm for\nSMDP requires the knowledge of the sparsity parameter and oracle access to an\nunknown policy. We overcome these limitations by combining the doubly robust\nmethod that allows one to use feature vectors of \\emph{all} actions with a\nnovel analysis technique that enables the algorithm to use data from all\nperiods in all episodes. The regret of the proposed algorithm is\n$\\tilde{O}(\\sigma^{-1}_{\\min} s_{\\star} H \\sqrt{N})$, where $\\sigma_{\\min}$\ndenotes the restrictive the minimum eigenvalue of the average Gram matrix of\nfeature vectors, $s_\\star$ is the sparsity parameter, $H$ is the length of an\nepisode, and $N$ is the number of rounds. We provide a lower regret bound that\nmatches the upper bound up to logarithmic factors on a newly identified\nsubclass of SMDPs. Our numerical experiments support our theoretical results\nand demonstrate the superior performance of our algorithm.",
            "author": [
                "Wonyoung Kim",
                "Garud Iyengar",
                "Assaf Zeevi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15286v1",
                "http://arxiv.org/pdf/2310.15286v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15285v1",
            "title": "On the Dimensionality of Sentence Embeddings",
            "updated": "2023-10-23T18:51:00Z",
            "published": "2023-10-23T18:51:00Z",
            "summary": "Learning sentence embeddings is a fundamental problem in natural language\nprocessing. While existing research primarily focuses on enhancing the quality\nof sentence embeddings, the exploration of sentence embedding dimensions is\nlimited. Here we present a comprehensive and empirical analysis of the\ndimensionality of sentence embeddings. First, we demonstrate that the optimal\ndimension of sentence embeddings is usually smaller than the default value.\nSubsequently, to compress the dimension of sentence embeddings with minimum\nperformance degradation, we identify two components contributing to the overall\nperformance loss: the encoder's performance loss and the pooler's performance\nloss. Therefore, we propose a two-step training method for sentence\nrepresentation learning models, wherein the encoder and the pooler are\noptimized separately to mitigate the overall performance loss in low-dimension\nscenarios. Experimental results on seven STS tasks and seven sentence\nclassification tasks demonstrate that our method significantly improves the\nperformance of low-dimensional sentence embeddings.",
            "author": [
                "Hongwei Wang",
                "Hongming Zhang",
                "Dong Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15285v1",
                "http://arxiv.org/pdf/2310.15285v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15281v1",
            "title": "UncertaintyPlayground: A Fast and Simplified Python Library for\n  Uncertainty Estimation",
            "updated": "2023-10-23T18:36:54Z",
            "published": "2023-10-23T18:36:54Z",
            "summary": "This paper introduces UncertaintyPlayground, a Python library built on\nPyTorch and GPyTorch for uncertainty estimation in supervised learning tasks.\nThe library offers fast training for Gaussian and multi-modal outcome\ndistributions through Sparse and Variational Gaussian Process Regressions\n(SVGPRs) for normally distributed outcomes and Mixed Density Networks (MDN) for\nmixed distributions. In addition to model training with various\nhyperparameters, UncertaintyPlayground can visualize the prediction intervals\nof one or more instances. Due to using tensor operations, the library can be\ntrained both on CPU and GPU and offers various PyTorch-specific techniques for\nspeed optimization. The library contains unit tests for each module and ensures\nmulti-platform continuous integration with GitHub Workflows (online\nintegration) and Tox (local integration). Finally, the code is documented with\nGoogle-style docstrings and offers a documentation website created with MkDocs\nand MkDocStrings.",
            "author": [
                "Ilia Azizi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15281v1",
                "http://arxiv.org/pdf/2310.15281v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15275v1",
            "title": "Triple Simplex Matrix Completion for Expense Forecasting",
            "updated": "2023-10-23T18:25:33Z",
            "published": "2023-10-23T18:25:33Z",
            "summary": "Forecasting project expenses is a crucial step for businesses to avoid budget\noverruns and project failures. Traditionally, this has been done by financial\nanalysts or data science techniques such as time-series analysis. However,\nthese approaches can be uncertain and produce results that differ from the\nplanned budget, especially at the start of a project with limited data points.\nThis paper proposes a constrained non-negative matrix completion model that\npredicts expenses by learning the likelihood of the project correlating with\ncertain expense patterns in the latent space. The model is constrained on three\nprobability simplexes, two of which are on the factor matrices and the third on\nthe missing entries. Additionally, the predicted expense values are guaranteed\nto meet the budget constraint without the need of post-processing. An inexact\nalternating optimization algorithm is developed to solve the associated\noptimization problem and is proven to converge to a stationary point. Results\nfrom two real datasets demonstrate the effectiveness of the proposed method in\ncomparison to state-of-the-art algorithms.",
            "author": [
                "Cheng Qian",
                "Lucas Glass",
                "Nikos Sidiropoulos"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15275v1",
                "http://arxiv.org/pdf/2310.15275v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15274v1",
            "title": "Systematic AI Approach for AGI: Addressing Alignment, Energy, and AGI\n  Grand Challenges",
            "updated": "2023-10-23T18:20:54Z",
            "published": "2023-10-23T18:20:54Z",
            "summary": "AI faces a trifecta of grand challenges the Energy Wall, the Alignment\nProblem and the Leap from Narrow AI to AGI. Contemporary AI solutions consume\nunsustainable amounts of energy during model training and daily\noperations.Making things worse, the amount of computation required to train\neach new AI model has been doubling every 2 months since 2020, directly\ntranslating to increases in energy consumption.The leap from AI to AGI requires\nmultiple functional subsystems operating in a balanced manner, which requires a\nsystem architecture. However, the current approach to artificial intelligence\nlacks system design; even though system characteristics play a key role in the\nhuman brain from the way it processes information to how it makes decisions.\nSimilarly, current alignment and AI ethics approaches largely ignore system\ndesign, yet studies show that the brains system architecture plays a critical\nrole in healthy moral decisions.In this paper, we argue that system design is\ncritically important in overcoming all three grand challenges. We posit that\nsystem design is the missing piece in overcoming the grand challenges.We\npresent a Systematic AI Approach for AGI that utilizes system design principles\nfor AGI, while providing ways to overcome the energy wall and the alignment\nchallenges.",
            "author": [
                "Eren Kurshan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15274v1",
                "http://arxiv.org/pdf/2310.15274v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15269v1",
            "title": "GradSim: Gradient-Based Language Grouping for Effective Multilingual\n  Training",
            "updated": "2023-10-23T18:13:37Z",
            "published": "2023-10-23T18:13:37Z",
            "summary": "Most languages of the world pose low-resource challenges to natural language\nprocessing models. With multilingual training, knowledge can be shared among\nlanguages. However, not all languages positively influence each other and it is\nan open research question how to select the most suitable set of languages for\nmultilingual training and avoid negative interference among languages whose\ncharacteristics or data distributions are not compatible. In this paper, we\npropose GradSim, a language grouping method based on gradient similarity. Our\nexperiments on three diverse multilingual benchmark datasets show that it leads\nto the largest performance gains compared to other similarity measures and it\nis better correlated with cross-lingual model performance. As a result, we set\nthe new state of the art on AfriSenti, a benchmark dataset for sentiment\nanalysis on low-resource African languages. In our extensive analysis, we\nfurther reveal that besides linguistic features, the topics of the datasets\nplay an important role for language grouping and that lower layers of\ntransformer models encode language-specific features while higher layers\ncapture task-specific information.",
            "author": [
                "Mingyang Wang",
                "Heike Adel",
                "Lukas Lange",
                "Jannik Str\u00f6tgen",
                "Hinrich Sch\u00fctze"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15269v1",
                "http://arxiv.org/pdf/2310.15269v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15263v1",
            "title": "One-hot Generalized Linear Model for Switching Brain State Discovery",
            "updated": "2023-10-23T18:10:22Z",
            "published": "2023-10-23T18:10:22Z",
            "summary": "Exposing meaningful and interpretable neural interactions is critical to\nunderstanding neural circuits. Inferred neural interactions from neural signals\nprimarily reflect functional interactions. In a long experiment, subject\nanimals may experience different stages defined by the experiment, stimuli, or\nbehavioral states, and hence functional interactions can change over time. To\nmodel dynamically changing functional interactions, prior work employs\nstate-switching generalized linear models with hidden Markov models (i.e.,\nHMM-GLMs). However, we argue they lack biological plausibility, as functional\ninteractions are shaped and confined by the underlying anatomical connectome.\nHere, we propose a novel prior-informed state-switching GLM. We introduce both\na Gaussian prior and a one-hot prior over the GLM in each state. The priors are\nlearnable. We will show that the learned prior should capture the\nstate-constant interaction, shedding light on the underlying anatomical\nconnectome and revealing more likely physical neuron interactions. The\nstate-dependent interaction modeled by each GLM offers traceability to capture\nfunctional variations across multiple brain states. Our methods effectively\nrecover true interaction structures in simulated data, achieve the highest\npredictive likelihood with real neural datasets, and render interaction\nstructures and hidden states more interpretable when applied to real neural\ndata.",
            "author": [
                "Chengrui Li",
                "Soon Ho Kim",
                "Chris Rodgers",
                "Hannah Choi",
                "Anqi Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15263v1",
                "http://arxiv.org/pdf/2310.15263v1"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15261v1",
            "title": "Modality Dropout for Multimodal Device Directed Speech Detection using\n  Verbal and Non-Verbal Features",
            "updated": "2023-10-23T18:09:31Z",
            "published": "2023-10-23T18:09:31Z",
            "summary": "Device-directed speech detection (DDSD) is the binary classification task of\ndistinguishing between queries directed at a voice assistant versus side\nconversation or background speech. State-of-the-art DDSD systems use verbal\ncues, e.g acoustic, text and/or automatic speech recognition system (ASR)\nfeatures, to classify speech as device-directed or otherwise, and often have to\ncontend with one or more of these modalities being unavailable when deployed in\nreal-world settings. In this paper, we investigate fusion schemes for DDSD\nsystems that can be made more robust to missing modalities. Concurrently, we\nstudy the use of non-verbal cues, specifically prosody features, in addition to\nverbal cues for DDSD. We present different approaches to combine scores and\nembeddings from prosody with the corresponding verbal cues, finding that\nprosody improves DDSD performance by upto 8.5% in terms of false acceptance\nrate (FA) at a given fixed operating point via non-linear intermediate fusion,\nwhile our use of modality dropout techniques improves the performance of these\nmodels by 7.4% in terms of FA when evaluated with missing modalities during\ninference time.",
            "author": [
                "Gautam Krishna",
                "Sameer Dharur",
                "Oggi Rudovic",
                "Pranay Dighe",
                "Saurabh Adya",
                "Ahmed Hussen Abdelaziz",
                "Ahmed H Tewfik"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15261v1",
                "http://arxiv.org/pdf/2310.15261v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.HC",
                "cs.LG",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15259v1",
            "title": "Reference Free Domain Adaptation for Translation of Noisy Questions with\n  Question Specific Rewards",
            "updated": "2023-10-23T18:08:01Z",
            "published": "2023-10-23T18:08:01Z",
            "summary": "Community Question-Answering (CQA) portals serve as a valuable tool for\nhelping users within an organization. However, making them accessible to\nnon-English-speaking users continues to be a challenge. Translating questions\ncan broaden the community's reach, benefiting individuals with similar\ninquiries in various languages. Translating questions using Neural Machine\nTranslation (NMT) poses more challenges, especially in noisy environments,\nwhere the grammatical correctness of the questions is not monitored. These\nquestions may be phrased as statements by non-native speakers, with incorrect\nsubject-verb order and sometimes even missing question marks. Creating a\nsynthetic parallel corpus from such data is also difficult due to its noisy\nnature. To address this issue, we propose a training methodology that\nfine-tunes the NMT system only using source-side data. Our approach balances\nadequacy and fluency by utilizing a loss function that combines BERTScore and\nMasked Language Model (MLM) Score. Our method surpasses the conventional\nMaximum Likelihood Estimation (MLE) based fine-tuning approach, which relies on\nsynthetic target data, by achieving a 1.9 BLEU score improvement. Our model\nexhibits robustness while we add noise to our baseline, and still achieve 1.1\nBLEU improvement and large improvements on TER and BLEURT metrics. Our proposed\nmethodology is model-agnostic and is only necessary during the training phase.\nWe make the codes and datasets publicly available at\n\\url{https://www.iitp.ac.in/~ai-nlp-ml/resources.html#DomainAdapt} for\nfacilitating further research.",
            "author": [
                "Baban Gain",
                "Ramakrishna Appicharla",
                "Soumya Chennabasavaraj",
                "Nikesh Garera",
                "Asif Ekbal",
                "Muthusamy Chelliah"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15259v1",
                "http://arxiv.org/pdf/2310.15259v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15258v1",
            "title": "Breaking the Language Barrier: Improving Cross-Lingual Reasoning with\n  Structured Self-Attention",
            "updated": "2023-10-23T18:06:38Z",
            "published": "2023-10-23T18:06:38Z",
            "summary": "In this work, we study whether multilingual language models (MultiLMs) can\ntransfer logical reasoning abilities to other languages when they are\nfine-tuned for reasoning in a different language. We evaluate the cross-lingual\nreasoning abilities of MultiLMs in two schemes: (1) where the language of the\ncontext and the question remain the same in the new languages that are tested\n(i.e., the reasoning is still monolingual, but the model must transfer the\nlearned reasoning ability across languages), and (2) where the language of the\ncontext and the question is different (which we term code-switched reasoning).\nOn two logical reasoning datasets, RuleTaker and LeapOfThought, we demonstrate\nthat although MultiLMs can transfer reasoning ability across languages in a\nmonolingual setting, they struggle to transfer reasoning abilities in a\ncode-switched setting. Following this observation, we propose a novel attention\nmechanism that uses a dedicated set of parameters to encourage cross-lingual\nattention in code-switched sequences, which improves the reasoning performance\nby up to 14% and 4% on the RuleTaker and LeapOfThought datasets, respectively.",
            "author": [
                "Negar Foroutan",
                "Mohammadreza Banaei",
                "Karl Aberer",
                "Antoine Bosselut"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15258v1",
                "http://arxiv.org/pdf/2310.15258v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15256v1",
            "title": "SimBIG: Field-level Simulation-Based Inference of Galaxy Clustering",
            "updated": "2023-10-23T18:05:32Z",
            "published": "2023-10-23T18:05:32Z",
            "summary": "We present the first simulation-based inference (SBI) of cosmological\nparameters from field-level analysis of galaxy clustering. Standard galaxy\nclustering analyses rely on analyzing summary statistics, such as the power\nspectrum, $P_\\ell$, with analytic models based on perturbation theory.\nConsequently, they do not fully exploit the non-linear and non-Gaussian\nfeatures of the galaxy distribution. To address these limitations, we use the\n{\\sc SimBIG} forward modelling framework to perform SBI using normalizing\nflows. We apply SimBIG to a subset of the BOSS CMASS galaxy sample using a\nconvolutional neural network with stochastic weight averaging to perform\nmassive data compression of the galaxy field. We infer constraints on $\\Omega_m\n= 0.267^{+0.033}_{-0.029}$ and $\\sigma_8=0.762^{+0.036}_{-0.035}$. While our\nconstraints on $\\Omega_m$ are in-line with standard $P_\\ell$ analyses, those on\n$\\sigma_8$ are $2.65\\times$ tighter. Our analysis also provides constraints on\nthe Hubble constant $H_0=64.5 \\pm 3.8 \\ {\\rm km / s / Mpc}$ from galaxy\nclustering alone. This higher constraining power comes from additional\nnon-Gaussian cosmological information, inaccessible with $P_\\ell$. We\ndemonstrate the robustness of our analysis by showcasing our ability to infer\nunbiased cosmological constraints from a series of test simulations that are\nconstructed using different forward models than the one used in our training\ndataset. This work not only presents competitive cosmological constraints but\nalso introduces novel methods for leveraging additional cosmological\ninformation in upcoming galaxy surveys like DESI, PFS, and Euclid.",
            "author": [
                "Pablo Lemos",
                "Liam Parker",
                "ChangHoon Hahn",
                "Shirley Ho",
                "Michael Eickenberg",
                "Jiamin Hou",
                "Elena Massara",
                "Chirag Modi",
                "Azadeh Moradinezhad Dizgah",
                "Bruno Regaldo-Saint Blancard",
                "David Spergel"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15256v1",
                "http://arxiv.org/pdf/2310.15256v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15247v1",
            "title": "SyncFusion: Multimodal Onset-synchronized Video-to-Audio Foley Synthesis",
            "updated": "2023-10-23T18:01:36Z",
            "published": "2023-10-23T18:01:36Z",
            "summary": "Sound design involves creatively selecting, recording, and editing sound\neffects for various media like cinema, video games, and virtual/augmented\nreality. One of the most time-consuming steps when designing sound is\nsynchronizing audio with video. In some cases, environmental recordings from\nvideo shoots are available, which can aid in the process. However, in video\ngames and animations, no reference audio exists, requiring manual annotation of\nevent timings from the video. We propose a system to extract repetitive actions\nonsets from a video, which are then used - in conjunction with audio or textual\nembeddings - to condition a diffusion model trained to generate a new\nsynchronized sound effects audio track. In this way, we leave complete creative\ncontrol to the sound designer while removing the burden of synchronization with\nvideo. Furthermore, editing the onset track or changing the conditioning\nembedding requires much less effort than editing the audio track itself,\nsimplifying the sonification process. We provide sound examples, source code,\nand pretrained models to faciliate reproducibility",
            "author": [
                "Marco Comunit\u00e0",
                "Riccardo F. Gramaccioni",
                "Emilian Postolache",
                "Emanuele Rodol\u00e0",
                "Danilo Comminiello",
                "Joshua D. Reiss"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15247v1",
                "http://arxiv.org/pdf/2310.15247v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.CV",
                "cs.LG",
                "cs.MM",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15246v1",
            "title": "${\\rm S{\\scriptsize IM}BIG}$: The First Cosmological Constraints from\n  Non-Gaussian and Non-Linear Galaxy Clustering",
            "updated": "2023-10-23T18:01:07Z",
            "published": "2023-10-23T18:01:07Z",
            "summary": "The 3D distribution of galaxies encodes detailed cosmological information on\nthe expansion and growth history of the Universe. We present the first\ncosmological constraints that exploit non-Gaussian cosmological information on\nnon-linear scales from galaxy clustering, inaccessible with current standard\nanalyses. We analyze a subset of the BOSS galaxy survey using ${\\rm\nS{\\scriptsize IM}BIG}$, a new framework for cosmological inference that\nleverages high-fidelity simulations and deep generative models. We use two\nclustering statistics beyond the standard power spectrum: the bispectrum and a\nconvolutional neural network based summary of the galaxy field. We infer\nconstraints on $\\Lambda$CDM parameters, $\\Omega_b$, $h$, $n_s$, $\\Omega_m$, and\n$\\sigma_8$, that are 1.6, 1.5, 1.7, 1.2, and 2.3$\\times$ tighter than power\nspectrum analyses. With this increased precision, we derive constraints on the\nHubble constant, $H_0$, and $S_8 = \\sigma_8 \\sqrt{\\Omega_m/0.3}$ that are\ncompetitive with other cosmological probes, even with a sample that only spans\n10% of the full BOSS volume. Our $H_0$ constraints, imposing the Big Bang\nNucleosynthesis prior on the baryon density, are consistent with the early time\nconstraints from the cosmic microwave background (CMB). Meanwhile, our $S_8$\nconstraints are consistent with weak lensing experiments and similarly lie\nbelow CMB constraints. Lastly, we present forecasts to show that future work\nextending ${\\rm S{\\scriptsize IM}BIG}$ to upcoming spectroscopic galaxy surveys\n(DESI, PFS, Euclid) will produce leading $H_0$ and $S_8$ constraints that\nbridge the gap between early and late time measurements and shed light on\ncurrent cosmic tensions.",
            "author": [
                "ChangHoon Hahn",
                "Pablo Lemos",
                "Liam Parker",
                "Bruno R\u00e9galdo-Saint Blancard",
                "Michael Eickenberg",
                "Shirley Ho",
                "Jiamin Hou",
                "Elena Massara",
                "Chirag Modi",
                "Azadeh Moradinezhad Dizgah",
                "David Spergel"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15246v1",
                "http://arxiv.org/pdf/2310.15246v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15240v2",
            "title": "Predictions for Electromagnetic Counterparts to Neutron Star Mergers\n  Discovered during LIGO-Virgo-KAGRA Observing Runs 4 and 5",
            "updated": "2023-11-28T23:07:35Z",
            "published": "2023-10-23T18:00:25Z",
            "summary": "We present a comprehensive, configurable open-source framework for estimating\nthe rate of electromagnetic detection of kilonovae (KNe) associated with\ngravitational wave detections of binary neutron star (BNS) mergers. We simulate\nthe current LIGO-Virgo-KAGRA (LVK) observing run (O4) using up-to-date\nsensitivity and up-time values as well as the next observing run (O5) using\npredicted sensitivities. We find the number of discoverable kilonovae during\nLVK O4 to be ${ 1}_{- 1}^{+ 4}$ or ${ 2 }_{- 2 }^{+ 3 }$, (at 90% confidence)\ndepending on the distribution of NS masses in coalescing binaries, with the\nnumber increasing by an order of magnitude during O5 to ${ 19 }_{- 11 }^{+ 24\n}$. Regardless of mass model, we predict at most five detectable KNe (at 95%\nconfidence) in O4. We also produce optical and near-infrared light curves that\ncorrespond to the physical properties of each merging system. We have collated\nimportant information for allocating observing resources and directing search\nand follow-up observations including distributions of peak magnitudes in\nseveral broad bands and timescales for which specific facilities can detect\neach KN. The framework is easily adaptable, and new simulations can quickly be\nproduced as input information such as merger rates and NS mass distributions\nare refined. Finally, we compare our suite of simulations to the thus-far\ncompleted portion of O4 (as of October 14, 2023), finding a median number of\ndiscoverable KNe of 0 and a 95-percentile upper limit of 2, consistent with no\ndetection so far in O4.",
            "author": [
                "Ved G. Shah",
                "Gautham Narayan",
                "Haille M. L. Perkins",
                "Ryan J. Foley",
                "Deep Chatterjee",
                "Bryce Cousins",
                "Phillip Macias"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15240v2",
                "http://arxiv.org/pdf/2310.15240v2"
            ],
            "primary_category": "astro-ph.HE",
            "category": [
                "astro-ph.HE",
                "astro-ph.IM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15234v1",
            "title": "Field-level simulation-based inference with galaxy catalogs: the impact\n  of systematic effects",
            "updated": "2023-10-23T18:00:07Z",
            "published": "2023-10-23T18:00:07Z",
            "summary": "It has been recently shown that a powerful way to constrain cosmological\nparameters from galaxy redshift surveys is to train graph neural networks to\nperform field-level likelihood-free inference without imposing cuts on scale.\nIn particular, de Santi et al. (2023) developed models that could accurately\ninfer the value of $\\Omega_{\\rm m}$ from catalogs that only contain the\npositions and radial velocities of galaxies that are robust to uncertainties in\nastrophysics and subgrid models. However, observations are affected by many\neffects, including 1) masking, 2) uncertainties in peculiar velocities and\nradial distances, and 3) different galaxy selections. Moreover, observations\nonly allow us to measure redshift, intertwining galaxies' radial positions and\nvelocities. In this paper we train and test our models on galaxy catalogs,\ncreated from thousands of state-of-the-art hydrodynamic simulations run with\ndifferent codes from the CAMELS project, that incorporate these observational\neffects. We find that, although the presence of these effects degrades the\nprecision and accuracy of the models, and increases the fraction of catalogs\nwhere the model breaks down, the fraction of galaxy catalogs where the model\nperforms well is over 90 %, demonstrating the potential of these models to\nconstrain cosmological parameters even when applied to real data.",
            "author": [
                "Natal\u00ed S. M. de Santi",
                "Francisco Villaescusa-Navarro",
                "L. Raul Abramo",
                "Helen Shao",
                "Lucia A. Perez",
                "Tiago Castro",
                "Yueying Ni",
                "Christopher C. Lovell",
                "Elena Hernandez-Martinez",
                "Federico Marinacci",
                "David N. Spergel",
                "Klaus Dolag",
                "Lars Hernquist",
                "Mark Vogelsberger"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15234v1",
                "http://arxiv.org/pdf/2310.15234v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO",
                "astro-ph.GA",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15233v1",
            "title": "A new approach to template banks of gravitational waves with higher\n  harmonics: reducing matched-filtering cost by over an order of magnitude",
            "updated": "2023-10-23T18:00:06Z",
            "published": "2023-10-23T18:00:06Z",
            "summary": "Searches for gravitational wave events use models, or templates, for the\nsignals of interest. The templates used in current searches in the\nLIGO-Virgo-Kagra (LVK) data model the dominant quadrupole mode $(\\ell,m)=(2,2)$\nof the signals, and omit sub-dominant higher-order modes (HM) such as\n$(\\ell,m)=(3,3)$, $(4,4)$, which are predicted by general relativity. Hence,\nthese searches could lose sensitivity to black hole mergers in interesting\nparts of parameter space, such as systems with high-masses and asymmetric mass\nratios. We develop a new strategy to include HM in template banks that exploits\nthe natural connection between the modes. We use a combination of\npost-Newtonian formulae and machine learning tools to model aligned-spin\n$(3,3)$, $(4,4)$ waveforms corresponding to a given $(2,2)$ waveform. Each of\nthese modes can be individually filtered against the data to yield separate\ntimeseries of signal-to-noise ratios (SNR), which can be combined in a\nrelatively inexpensive way to marginalize over extrinsic parameters of the\nsignals. This leads to a HM search pipeline whose matched-filtering cost is\njust $\\approx 3\\times$ that of a quadrupole-only search (in contrast to being\n$\\approx\\! 100 \\times$, as in previously proposed HM search methods). Our\nmethod is effectual and is generally applicable for template banks constructed\nwith either stochastic or geometric placement techniques. Additionally, we\ndiscuss compression of $(2,2)$-only geometric-placement template banks using\nmachine learning algorithms.",
            "author": [
                "Digvijay Wadekar",
                "Tejaswi Venumadhav",
                "Ajit Kumar Mehta",
                "Javier Roulet",
                "Seth Olsen",
                "Jonathan Mushkin",
                "Barak Zackay",
                "Matias Zaldarriaga"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15233v1",
                "http://arxiv.org/pdf/2310.15233v1"
            ],
            "primary_category": "gr-qc",
            "category": [
                "gr-qc",
                "astro-ph.HE",
                "astro-ph.IM",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15227v1",
            "title": "Machine Learning Classification of Sphalerons and Black Holes at the LHC",
            "updated": "2023-10-23T18:00:03Z",
            "published": "2023-10-23T18:00:03Z",
            "summary": "In models with large extra dimensions, \"miniature\" black holes (BHs) might be\nproduced in high-energy proton-proton collisions at the Large Hadron Collider\n(LHC). In the semi-classical regime, those BHs thermally decay, giving rise to\nlarge-multiplicity final states with jets and leptons. On the other hand,\nsimilar final states are also expected in the production of electroweak\nsphaleron/instanton-induced processes. We investigate whether one can\ndiscriminate these scenarios when BH or sphaleron-like events are observed in\nthe LHC using Machine Learning (ML) methods. Classification among several BH\nscenarios with different numbers of extra dimensions and the minimal BH masses\nis also examined. In this study we consider three ML models: XGBoost algorithms\nwith (1) high- and (2) low-level inputs, and (3) a Residual Convolutional\nNeural Network. In the latter case, the low-level detector information is\nconverted into an input format of three-layer binned event images, where the\nvalue of each bin corresponds to the energy deposited in various detector\nsubsystems. We demonstrate that only a few detected events are sufficient to\neffectively discriminate between the sphaleron and BH processes. Separation\namong BH scenarios with different minimal BH masses is also possible with a\nreasonable number of events, that can be collected in the LHC Run-2, -3 and the\nhigh-luminosity LHC (HL-LHC). We find, however, that a large number of events\nis needed to discriminate between BH hypotheses with the same minimal BH mass,\nbut different numbers of extra dimensions.",
            "author": [
                "Aurora Singstad Grefsrud",
                "Trygve Buanes",
                "Fotis Koutroulis",
                "Anna Lipniacka",
                "Rafa\u0142 Mase\u0142ek",
                "Andreas Papaefstathiou",
                "Kazuki Sakurai",
                "Therese B. Sjursen",
                "Igor Slazyk"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15227v1",
                "http://arxiv.org/pdf/2310.15227v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15171v1",
            "title": "RoboDepth: Robust Out-of-Distribution Depth Estimation under Corruptions",
            "updated": "2023-10-23T17:59:59Z",
            "published": "2023-10-23T17:59:59Z",
            "summary": "Depth estimation from monocular images is pivotal for real-world visual\nperception systems. While current learning-based depth estimation models train\nand test on meticulously curated data, they often overlook out-of-distribution\n(OoD) situations. Yet, in practical settings -- especially safety-critical ones\nlike autonomous driving -- common corruptions can arise. Addressing this\noversight, we introduce a comprehensive robustness test suite, RoboDepth,\nencompassing 18 corruptions spanning three categories: i) weather and lighting\nconditions; ii) sensor failures and movement; and iii) data processing\nanomalies. We subsequently benchmark 42 depth estimation models across indoor\nand outdoor scenes to assess their resilience to these corruptions. Our\nfindings underscore that, in the absence of a dedicated robustness evaluation\nframework, many leading depth estimation models may be susceptible to typical\ncorruptions. We delve into design considerations for crafting more robust depth\nestimation models, touching upon pre-training, augmentation, modality, model\ncapacity, and learning paradigms. We anticipate our benchmark will establish a\nfoundational platform for advancing robust OoD depth estimation.",
            "author": [
                "Lingdong Kong",
                "Shaoyuan Xie",
                "Hanjiang Hu",
                "Lai Xing Ng",
                "Benoit R. Cottereau",
                "Wei Tsang Ooi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15171v1",
                "http://arxiv.org/pdf/2310.15171v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15168v2",
            "title": "Ghost on the Shell: An Expressive Representation of General 3D Shapes",
            "updated": "2023-10-24T03:21:22Z",
            "published": "2023-10-23T17:59:52Z",
            "summary": "The creation of photorealistic virtual worlds requires the accurate modeling\nof 3D surface geometry for a wide range of objects. For this, meshes are\nappealing since they 1) enable fast physics-based rendering with realistic\nmaterial and lighting, 2) support physical simulation, and 3) are\nmemory-efficient for modern graphics pipelines. Recent work on reconstructing\nand statistically modeling 3D shape, however, has critiqued meshes as being\ntopologically inflexible. To capture a wide range of object shapes, any 3D\nrepresentation must be able to model solid, watertight, shapes as well as thin,\nopen, surfaces. Recent work has focused on the former, and methods for\nreconstructing open surfaces do not support fast reconstruction with material\nand lighting or unconditional generative modelling. Inspired by the observation\nthat open surfaces can be seen as islands floating on watertight surfaces, we\nparameterize open surfaces by defining a manifold signed distance field on\nwatertight templates. With this parameterization, we further develop a\ngrid-based and differentiable representation that parameterizes both watertight\nand non-watertight meshes of arbitrary topology. Our new representation, called\nGhost-on-the-Shell (G-Shell), enables two important applications:\ndifferentiable rasterization-based reconstruction from multiview images and\ngenerative modelling of non-watertight meshes. We empirically demonstrate that\nG-Shell achieves state-of-the-art performance on non-watertight mesh\nreconstruction and generation tasks, while also performing effectively for\nwatertight meshes.",
            "author": [
                "Zhen Liu",
                "Yao Feng",
                "Yuliang Xiu",
                "Weiyang Liu",
                "Liam Paull",
                "Michael J. Black",
                "Bernhard Sch\u00f6lkopf"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15168v2",
                "http://arxiv.org/pdf/2310.15168v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15166v1",
            "title": "Large Language Models are Visual Reasoning Coordinators",
            "updated": "2023-10-23T17:59:31Z",
            "published": "2023-10-23T17:59:31Z",
            "summary": "Visual reasoning requires multimodal perception and commonsense cognition of\nthe world. Recently, multiple vision-language models (VLMs) have been proposed\nwith excellent commonsense reasoning ability in various domains. However, how\nto harness the collective power of these complementary VLMs is rarely explored.\nExisting methods like ensemble still struggle to aggregate these models with\nthe desired higher-order communications. In this work, we propose Cola, a novel\nparadigm that coordinates multiple VLMs for visual reasoning. Our key insight\nis that a large language model (LLM) can efficiently coordinate multiple VLMs\nby facilitating natural language communication that leverages their distinct\nand complementary capabilities. Extensive experiments demonstrate that our\ninstruction tuning variant, Cola-FT, achieves state-of-the-art performance on\nvisual question answering (VQA), outside knowledge VQA, visual entailment, and\nvisual spatial reasoning tasks. Moreover, we show that our in-context learning\nvariant, Cola-Zero, exhibits competitive performance in zero and few-shot\nsettings, without finetuning. Through systematic ablation studies and\nvisualizations, we validate that a coordinator LLM indeed comprehends the\ninstruction prompts as well as the separate functionalities of VLMs; it then\ncoordinates them to enable impressive visual reasoning capabilities.",
            "author": [
                "Liangyu Chen",
                "Bo Li",
                "Sheng Shen",
                "Jingkang Yang",
                "Chunyuan Li",
                "Kurt Keutzer",
                "Trevor Darrell",
                "Ziwei Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15166v1",
                "http://arxiv.org/pdf/2310.15166v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15165v1",
            "title": "Handling Data Heterogeneity via Architectural Design for Federated\n  Visual Recognition",
            "updated": "2023-10-23T17:59:16Z",
            "published": "2023-10-23T17:59:16Z",
            "summary": "Federated Learning (FL) is a promising research paradigm that enables the\ncollaborative training of machine learning models among various parties without\nthe need for sensitive information exchange. Nonetheless, retaining data in\nindividual clients introduces fundamental challenges to achieving performance\non par with centrally trained models. Our study provides an extensive review of\nfederated learning applied to visual recognition. It underscores the critical\nrole of thoughtful architectural design choices in achieving optimal\nperformance, a factor often neglected in the FL literature. Many existing FL\nsolutions are tested on shallow or simple networks, which may not accurately\nreflect real-world applications. This practice restricts the transferability of\nresearch findings to large-scale visual recognition models. Through an in-depth\nanalysis of diverse cutting-edge architectures such as convolutional neural\nnetworks, transformers, and MLP-mixers, we experimentally demonstrate that\narchitectural choices can substantially enhance FL systems' performance,\nparticularly when handling heterogeneous data. We study 19 visual recognition\nmodels from five different architectural families on four challenging FL\ndatasets. We also re-investigate the inferior performance of convolution-based\narchitectures in the FL setting and analyze the influence of normalization\nlayers on the FL performance. Our findings emphasize the importance of\narchitectural design for computer vision tasks in practical scenarios,\neffectively narrowing the performance gap between federated and centralized\nlearning. Our source code is available at\nhttps://github.com/sarapieri/fed_het.git.",
            "author": [
                "Sara Pieri",
                "Jose Renato Restom",
                "Samuel Horvath",
                "Hisham Cholakkal"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15165v1",
                "http://arxiv.org/pdf/2310.15165v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15163v2",
            "title": "Bitrate Ladder Prediction Methods for Adaptive Video Streaming: A Review\n  and Benchmark",
            "updated": "2023-10-30T19:11:04Z",
            "published": "2023-10-23T17:58:24Z",
            "summary": "HTTP adaptive streaming (HAS) has emerged as a widely adopted approach for\nover-the-top (OTT) video streaming services, due to its ability to deliver a\nseamless streaming experience. A key component of HAS is the bitrate ladder,\nwhich provides the encoding parameters (e.g., bitrate-resolution pairs) to\nencode the source video. The representations in the bitrate ladder allow the\nclient's player to dynamically adjust the quality of the video stream based on\nnetwork conditions by selecting the most appropriate representation from the\nbitrate ladder. The most straightforward and lowest complexity approach\ninvolves using a fixed bitrate ladder for all videos, consisting of\npre-determined bitrate-resolution pairs known as one-size-fits-all. Conversely,\nthe most reliable technique relies on intensively encoding all resolutions over\na wide range of bitrates to build the convex hull, thereby optimizing the\nbitrate ladder for each specific video. Several techniques have been proposed\nto predict content-based ladders without performing a costly exhaustive search\nencoding. This paper provides a comprehensive review of various methods,\nincluding both conventional and learning-based approaches. Furthermore, we\nconduct a benchmark study focusing exclusively on various learning-based\napproaches for predicting content-optimized bitrate ladders across multiple\ncodec settings. The considered methods are evaluated on our proposed\nlarge-scale dataset, which includes 300 UHD video shots encoded with software\nand hardware encoders using three state-of-the-art encoders, including\nAVC/H.264, HEVC/H.265, and VVC/H.266, at various bitrate points. Our analysis\nprovides baseline methods and insights, which will be valuable for future\nresearch in the field of bitrate ladder prediction. The source code of the\nproposed benchmark and the dataset will be made publicly available upon\nacceptance of the paper.",
            "author": [
                "Ahmed Telili",
                "Wassim Hamidouche",
                "Hadi Amirpour",
                "Sid Ahmed Fezza",
                "Luce Morin",
                "Christian Timmerer"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15163v2",
                "http://arxiv.org/pdf/2310.15163v2"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15159v1",
            "title": "Probing Transverse Momentum Dependent Structures with Azimuthal\n  Dependence of Energy Correlators",
            "updated": "2023-10-23T17:57:23Z",
            "published": "2023-10-23T17:57:23Z",
            "summary": "We study the azimuthal angle dependence of the energy-energy correlators\n$\\langle \\mathcal{E}(\\hat{n}_1)\\mathcal{E}(\\hat{n}_2)\\rangle$ in the\nback-to-back region for $e^+e^-$ annihilation and deep inelastic scattering\n(DIS) processes with general polarization of the proton beam. We demonstrate\nthat the polarization information of the beam and the underlying partons from\nthe hard scattering is propagated into the azimuthal angle dependence of the\nenergy-energy correlators. In the process, we define the Collins-type EEC jet\nfunctions and introduce a new EEC observable using the lab-frame angles in the\nDIS process. Furthermore, we extend our formalism to explore the two-point\nenergy correlation between hadrons with different quantum numbers\n$\\mathbb{S}_i$ in the back-to-back limit $\\langle\n\\mathcal{E}_{\\mathbb{S}_1}(\\hat{n}_1)\\mathcal{E}_{\\mathbb{S}_2}(\\hat{n}_2)\\rangle$.\nWe find that in the Operator Product Expansion (OPE) region the nonperturbative\ninformation is entirely encapsulated by a single number. Using our formalism,\nwe present several phenomenological studies that showcase how energy\ncorrelators can be used to probe transverse momentum dependent structures.",
            "author": [
                "Zhong-Bo Kang",
                "Kyle Lee",
                "Ding Yu Shao",
                "Fanyi Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15159v1",
                "http://arxiv.org/pdf/2310.15159v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "hep-ex",
                "nucl-ex",
                "nucl-th"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15154v1",
            "title": "Linear Representations of Sentiment in Large Language Models",
            "updated": "2023-10-23T17:55:31Z",
            "published": "2023-10-23T17:55:31Z",
            "summary": "Sentiment is a pervasive feature in natural language text, yet it is an open\nquestion how sentiment is represented within Large Language Models (LLMs). In\nthis study, we reveal that across a range of models, sentiment is represented\nlinearly: a single direction in activation space mostly captures the feature\nacross a range of tasks with one extreme for positive and the other for\nnegative. Through causal interventions, we isolate this direction and show it\nis causally relevant in both toy tasks and real world datasets such as Stanford\nSentiment Treebank. Through this case study we model a thorough investigation\nof what a single direction means on a broad data distribution.\n  We further uncover the mechanisms that involve this direction, highlighting\nthe roles of a small subset of attention heads and neurons. Finally, we\ndiscover a phenomenon which we term the summarization motif: sentiment is not\nsolely represented on emotionally charged words, but is additionally summarized\nat intermediate positions without inherent sentiment, such as punctuation and\nnames. We show that in Stanford Sentiment Treebank zero-shot classification,\n76% of above-chance classification accuracy is lost when ablating the sentiment\ndirection, nearly half of which (36%) is due to ablating the summarized\nsentiment direction exclusively at comma positions.",
            "author": [
                "Curt Tigges",
                "Oskar John Hollinsworth",
                "Atticus Geiger",
                "Neel Nanda"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15154v1",
                "http://arxiv.org/pdf/2310.15154v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15153v1",
            "title": "Accelerate Microstructure Evolution Simulation Using Graph Neural\n  Networks with Adaptive Spatiotemporal Resolution",
            "updated": "2023-10-23T17:55:30Z",
            "published": "2023-10-23T17:55:30Z",
            "summary": "Surrogate models driven by sizeable datasets and scientific machine-learning\nmethods have emerged as an attractive microstructure simulation tool with the\npotential to deliver predictive microstructure evolution dynamics with huge\nsavings in computational costs. Taking 2D and 3D grain growth simulations as an\nexample, we present a completely overhauled computational framework based on\ngraph neural networks with not only excellent agreement to both the ground\ntruth phase-field methods and theoretical predictions, but enhanced accuracy\nand efficiency compared to previous works based on convolutional neural\nnetworks. These improvements can be attributed to the graph representation,\nboth improved predictive power and a more flexible data structure amenable to\nadaptive mesh refinement. As the simulated microstructures coarsen, our method\ncan adaptively adopt remeshed grids and larger timesteps to achieve further\nspeedup. The data-to-model pipeline with training procedures together with the\nsource codes are provided.",
            "author": [
                "Shaoxun Fan",
                "Andrew L. Hitt",
                "Ming Tang",
                "Babak Sadigh",
                "Fei Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15153v1",
                "http://arxiv.org/pdf/2310.15153v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15213v1",
            "title": "Function Vectors in Large Language Models",
            "updated": "2023-10-23T17:55:24Z",
            "published": "2023-10-23T17:55:24Z",
            "summary": "We report the presence of a simple neural mechanism that represents an\ninput-output function as a vector within autoregressive transformer language\nmodels (LMs). Using causal mediation analysis on a diverse range of\nin-context-learning (ICL) tasks, we find that a small number attention heads\ntransport a compact representation of the demonstrated task, which we call a\nfunction vector (FV). FVs are robust to changes in context, i.e., they trigger\nexecution of the task on inputs such as zero-shot and natural text settings\nthat do not resemble the ICL contexts from which they are collected. We test\nFVs across a range of tasks, models, and layers and find strong causal effects\nacross settings in middle layers. We investigate the internal structure of FVs\nand find while that they often contain information that encodes the output\nspace of the function, this information alone is not sufficient to reconstruct\nan FV. Finally, we test semantic vector composition in FVs, and find that to\nsome extent they can be summed to create vectors that trigger new complex\ntasks. Taken together, our findings suggest that LLMs contain internal\nabstractions of general-purpose functions that can be invoked in a variety of\ncontexts.",
            "author": [
                "Eric Todd",
                "Millicent L. Li",
                "Arnab Sen Sharma",
                "Aaron Mueller",
                "Byron C. Wallace",
                "David Bau"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15213v1",
                "http://arxiv.org/pdf/2310.15213v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15151v1",
            "title": "Verb Conjugation in Transformers Is Determined by Linear Encodings of\n  Subject Number",
            "updated": "2023-10-23T17:53:47Z",
            "published": "2023-10-23T17:53:47Z",
            "summary": "Deep architectures such as Transformers are sometimes criticized for having\nuninterpretable \"black-box\" representations. We use causal intervention\nanalysis to show that, in fact, some linguistic features are represented in a\nlinear, interpretable format. Specifically, we show that BERT's ability to\nconjugate verbs relies on a linear encoding of subject number that can be\nmanipulated with predictable effects on conjugation accuracy. This encoding is\nfound in the subject position at the first layer and the verb position at the\nlast layer, but distributed across positions at middle layers, particularly\nwhen there are multiple cues to subject number.",
            "author": [
                "Sophie Hao",
                "Tal Linzen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15151v1",
                "http://arxiv.org/pdf/2310.15151v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15150v1",
            "title": "Online Detection of AI-Generated Images",
            "updated": "2023-10-23T17:53:14Z",
            "published": "2023-10-23T17:53:14Z",
            "summary": "With advancements in AI-generated images coming on a continuous basis, it is\nincreasingly difficult to distinguish traditionally-sourced images (e.g.,\nphotos, artwork) from AI-generated ones. Previous detection methods study the\ngeneralization from a single generator to another in isolation. However, in\nreality, new generators are released on a streaming basis. We study\ngeneralization in this setting, training on N models and testing on the next\n(N+k), following the historical release dates of well-known generation methods.\nFurthermore, images increasingly consist of both real and generated components,\nfor example through image inpainting. Thus, we extend this approach to pixel\nprediction, demonstrating strong performance using automatically-generated\ninpainted data. In addition, for settings where commercial models are not\npublicly available for automatic data generation, we evaluate if pixel\ndetectors can be trained solely on whole synthetic images.",
            "author": [
                "David C. Epstein",
                "Ishan Jain",
                "Oliver Wang",
                "Richard Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15150v1",
                "http://arxiv.org/pdf/2310.15150v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15149v1",
            "title": "Unlocking the Transferability of Tokens in Deep Models for Tabular Data",
            "updated": "2023-10-23T17:53:09Z",
            "published": "2023-10-23T17:53:09Z",
            "summary": "Fine-tuning a pre-trained deep neural network has become a successful\nparadigm in various machine learning tasks. However, such a paradigm becomes\nparticularly challenging with tabular data when there are discrepancies between\nthe feature sets of pre-trained models and the target tasks. In this paper, we\npropose TabToken, a method aims at enhancing the quality of feature tokens\n(i.e., embeddings of tabular features). TabToken allows for the utilization of\npre-trained models when the upstream and downstream tasks share overlapping\nfeatures, facilitating model fine-tuning even with limited training examples.\nSpecifically, we introduce a contrastive objective that regularizes the tokens,\ncapturing the semantics within and across features. During the pre-training\nstage, the tokens are learned jointly with top-layer deep models such as\ntransformer. In the downstream task, tokens of the shared features are kept\nfixed while TabToken efficiently fine-tunes the remaining parts of the model.\nTabToken not only enables knowledge transfer from a pre-trained model to tasks\nwith heterogeneous features, but also enhances the discriminative ability of\ndeep tabular models in standard classification and regression tasks.",
            "author": [
                "Qi-Le Zhou",
                "Han-Jia Ye",
                "Le-Ye Wang",
                "De-Chuan Zhan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15149v1",
                "http://arxiv.org/pdf/2310.15149v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15148v1",
            "title": "Physics informed neural networks learning a two-qubit Hamiltonian",
            "updated": "2023-10-23T17:52:58Z",
            "published": "2023-10-23T17:52:58Z",
            "summary": "Machine learning techniques are employed to perform the full characterization\nof a quantum system. The particular artificial intelligence technique used to\nlearn the Hamiltonian is called physics informed neural network (PINN). The\nidea behind PINN is the universal approximation theorem, which claims that any\nfunction can be approximate by a neural network if it contains enough\ncomplexity. Consequently, a neural network can be a solution of a physical\nmodel. Moreover, by means of extra data provided by the user, intrinsic\nphysical parameters can be extracted from the approach called inverse-PINN.\nHere, we apply inverse-PINN with the goal of extracting all the physical\nparameters that constitutes a two qubit Hamiltonian. We find that this approach\nis very efficient. To probe the robustness of the inverse-PINN to learn the\nHamiltonian of a two-qubit system, we use the IBM quantum computers as\nexperimental platforms to obtain the data that is plugged in the PINN. We found\nthat our method is able to predict the two-qubit parameters with 5% of accuracy\non average.",
            "author": [
                "Leonardo K. Castelano",
                "Iann Cunha",
                "Fabricio S. Luiz",
                "Marcelo V. de Souza Prado",
                "Felipe F. Fanchini"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15148v1",
                "http://arxiv.org/pdf/2310.15148v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15145v1",
            "title": "Robot Fine-Tuning Made Easy: Pre-Training Rewards and Policies for\n  Autonomous Real-World Reinforcement Learning",
            "updated": "2023-10-23T17:50:08Z",
            "published": "2023-10-23T17:50:08Z",
            "summary": "The pre-train and fine-tune paradigm in machine learning has had dramatic\nsuccess in a wide range of domains because the use of existing data or\npre-trained models on the internet enables quick and easy learning of new\ntasks. We aim to enable this paradigm in robotic reinforcement learning,\nallowing a robot to learn a new task with little human effort by leveraging\ndata and models from the Internet. However, reinforcement learning often\nrequires significant human effort in the form of manual reward specification or\nenvironment resets, even if the policy is pre-trained. We introduce RoboFuME, a\nreset-free fine-tuning system that pre-trains a multi-task manipulation policy\nfrom diverse datasets of prior experiences and self-improves online to learn a\ntarget task with minimal human intervention. Our insights are to utilize\ncalibrated offline reinforcement learning techniques to ensure efficient online\nfine-tuning of a pre-trained policy in the presence of distribution shifts and\nleverage pre-trained vision language models (VLMs) to build a robust reward\nclassifier for autonomously providing reward signals during the online\nfine-tuning process. In a diverse set of five real robot manipulation tasks, we\nshow that our method can incorporate data from an existing robot dataset\ncollected at a different institution and improve on a target task within as\nlittle as 3 hours of autonomous real-world experience. We also demonstrate in\nsimulation experiments that our method outperforms prior works that use\ndifferent RL algorithms or different approaches for predicting rewards. Project\nwebsite: https://robofume.github.io",
            "author": [
                "Jingyun Yang",
                "Max Sobol Mark",
                "Brandon Vu",
                "Archit Sharma",
                "Jeannette Bohg",
                "Chelsea Finn"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15145v1",
                "http://arxiv.org/pdf/2310.15145v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15143v1",
            "title": "Hyperparameter optimization of hp-greedy reduced basis for gravitational\n  wave surrogates",
            "updated": "2023-10-23T17:48:11Z",
            "published": "2023-10-23T17:48:11Z",
            "summary": "In a previous work we introduced, in the context of gravitational wave\nscience, an initial study on an automated domain-decomposition approach for\nreduced basis through hp-greedy refinement. The approach constructs local\nreduced bases of lower dimensionality than global ones, with the same or higher\naccuracy. These ``light'' local bases should imply both faster evaluations when\npredicting new waveforms and faster data analysis, in particular faster\nstatistical inference (the forward and inverse problems, respectively). In this\napproach, however, we have previously found important dependence on several\nhyperparameters, which do not appear in global reduced basis. This naturally\nleads to the problem of hyperparameter optimization (HPO), which is the subject\nof this paper. We tackle the problem through a Bayesian optimization, and show\nits superiority when compared to grid or random searches. We find that for\ngravitational waves from the collision of two spinning but non-precessing black\nholes, for the same accuracy, local hp-greedy reduced bases with HPO have a\nlower dimensionality of up to $4 \\times$ for the cases here studied, depending\non the desired accuracy. This factor should directly translate in a parameter\nestimation speedup, for instance. Such acceleration might help in the near\nreal-time requirements for electromagnetic counterparts of gravitational waves\nfrom compact binary coalescences. In addition, we find that the Bayesian\napproach used in this paper for HPO is two orders of magnitude faster than, for\nexample, a grid search, with about a $100 \\times$ acceleration. The code\ndeveloped for this project is available as open source from public\nrepositories.",
            "author": [
                "Franco Cerino",
                "Andr\u00e9s Diaz-Pace",
                "Emmanuel Tassone",
                "Manuel Tiglio",
                "Atuel Villegas"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15143v1",
                "http://arxiv.org/pdf/2310.15143v1"
            ],
            "primary_category": "gr-qc",
            "category": [
                "gr-qc",
                "astro-ph.IM",
                "cs.LG",
                "math-ph",
                "math.MP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15141v1",
            "title": "SpecTr: Fast Speculative Decoding via Optimal Transport",
            "updated": "2023-10-23T17:47:34Z",
            "published": "2023-10-23T17:47:34Z",
            "summary": "Autoregressive sampling from large language models has led to\nstate-of-the-art results in several natural language tasks. However,\nautoregressive sampling generates tokens one at a time making it slow, and even\nprohibitive in certain tasks. One way to speed up sampling is\n$\\textit{speculative decoding}$: use a small model to sample a $\\textit{draft}$\n(block or sequence of tokens), and then score all tokens in the draft by the\nlarge language model in parallel. A subset of the tokens in the draft are\naccepted (and the rest rejected) based on a statistical method to guarantee\nthat the final output follows the distribution of the large model. In this\nwork, we provide a principled understanding of speculative decoding through the\nlens of optimal transport (OT) with $\\textit{membership cost}$. This framework\ncan be viewed as an extension of the well-known $\\textit{maximal-coupling}$\nproblem. This new formulation enables us to generalize the speculative decoding\nmethod to allow for a set of $k$ candidates at the token-level, which leads to\nan improved optimal membership cost. We show that the optimal draft selection\nalgorithm (transport plan) can be computed via linear programming, whose\nbest-known runtime is exponential in $k$. We then propose a valid draft\nselection algorithm whose acceptance probability is $(1-1/e)$-optimal\nmultiplicatively. Moreover, it can be computed in time almost linear with size\nof domain of a single token. Using this $new draft selection$ algorithm, we\ndevelop a new autoregressive sampling algorithm called $\\textit{SpecTr}$, which\nprovides speedup in decoding while ensuring that there is no quality\ndegradation in the decoded output. We experimentally demonstrate that for\nstate-of-the-art large language models, the proposed approach achieves a wall\nclock speedup of 2.13X, a further 1.37X speedup over speculative decoding on\nstandard benchmarks.",
            "author": [
                "Ziteng Sun",
                "Ananda Theertha Suresh",
                "Jae Hun Ro",
                "Ahmad Beirami",
                "Himanshu Jain",
                "Felix Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15141v1",
                "http://arxiv.org/pdf/2310.15141v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL",
                "cs.DS",
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15140v1",
            "title": "AutoDAN: Automatic and Interpretable Adversarial Attacks on Large\n  Language Models",
            "updated": "2023-10-23T17:46:07Z",
            "published": "2023-10-23T17:46:07Z",
            "summary": "Safety alignment of Large Language Models (LLMs) can be compromised with\nmanual jailbreak attacks and (automatic) adversarial attacks. Recent work\nsuggests that patching LLMs against these attacks is possible: manual jailbreak\nattacks are human-readable but often limited and public, making them easy to\nblock; adversarial attacks generate gibberish prompts that can be detected\nusing perplexity-based filters. In this paper, we show that these solutions may\nbe too optimistic. We propose an interpretable adversarial attack,\n\\texttt{AutoDAN}, that combines the strengths of both types of attacks. It\nautomatically generates attack prompts that bypass perplexity-based filters\nwhile maintaining a high attack success rate like manual jailbreak attacks.\nThese prompts are interpretable and diverse, exhibiting strategies commonly\nused in manual jailbreak attacks, and transfer better than their non-readable\ncounterparts when using limited training data or a single proxy model. We also\ncustomize \\texttt{AutoDAN}'s objective to leak system prompts, another\njailbreak application not addressed in the adversarial attack literature. Our\nwork provides a new way to red-team LLMs and to understand the mechanism of\njailbreak attacks.",
            "author": [
                "Sicheng Zhu",
                "Ruiyi Zhang",
                "Bang An",
                "Gang Wu",
                "Joe Barrow",
                "Zichao Wang",
                "Furong Huang",
                "Ani Nenkova",
                "Tong Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15140v1",
                "http://arxiv.org/pdf/2310.15140v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15135v1",
            "title": "Quantifying the Dialect Gap and its Correlates Across Languages",
            "updated": "2023-10-23T17:42:01Z",
            "published": "2023-10-23T17:42:01Z",
            "summary": "Historically, researchers and consumers have noticed a decrease in quality\nwhen applying NLP tools to minority variants of languages (i.e. Puerto Rican\nSpanish or Swiss German), but studies exploring this have been limited to a\nselect few languages. Additionally, past studies have mainly been conducted in\na monolingual context, so cross-linguistic trends have not been identified and\ntied to external factors. In this work, we conduct a comprehensive evaluation\nof the most influential, state-of-the-art large language models (LLMs) across\ntwo high-use applications, machine translation and automatic speech\nrecognition, to assess their functionality on the regional dialects of several\nhigh- and low-resource languages. Additionally, we analyze how the regional\ndialect gap is correlated with economic, social, and linguistic factors. The\nimpact of training data, including related factors like dataset size and its\nconstruction procedure, is shown to be significant but not consistent across\nmodels or languages, meaning a one-size-fits-all approach cannot be taken in\nsolving the dialect gap. This work will lay the foundation for furthering the\nfield of dialectal NLP by laying out evident disparities and identifying\npossible pathways for addressing them through mindful data collection.",
            "author": [
                "Anjali Kantharuban",
                "Ivan Vuli\u0107",
                "Anna Korhonen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15135v1",
                "http://arxiv.org/pdf/2310.15135v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15129v1",
            "title": "Location-Aware Visual Question Generation with Lightweight Models",
            "updated": "2023-10-23T17:33:31Z",
            "published": "2023-10-23T17:33:31Z",
            "summary": "This work introduces a novel task, location-aware visual question generation\n(LocaVQG), which aims to generate engaging questions from data relevant to a\nparticular geographical location. Specifically, we represent such\nlocation-aware information with surrounding images and a GPS coordinate. To\ntackle this task, we present a dataset generation pipeline that leverages GPT-4\nto produce diverse and sophisticated questions. Then, we aim to learn a\nlightweight model that can address the LocaVQG task and fit on an edge device,\nsuch as a mobile phone. To this end, we propose a method which can reliably\ngenerate engaging questions from location-aware information. Our proposed\nmethod outperforms baselines regarding human evaluation (e.g., engagement,\ngrounding, coherence) and automatic evaluation metrics (e.g., BERTScore,\nROUGE-2). Moreover, we conduct extensive ablation studies to justify our\nproposed techniques for both generating the dataset and solving the task.",
            "author": [
                "Nicholas Collin Suwono",
                "Justin Chih-Yao Chen",
                "Tun Min Hung",
                "Ting-Hao Kenneth Huang",
                "I-Bin Liao",
                "Yung-Hui Li",
                "Lun-Wei Ku",
                "Shao-Hua Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15129v1",
                "http://arxiv.org/pdf/2310.15129v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15128v1",
            "title": "Projected Stochastic Gradient Descent with Quantum Annealed Binary\n  Gradients",
            "updated": "2023-10-23T17:32:38Z",
            "published": "2023-10-23T17:32:38Z",
            "summary": "We present, QP-SBGD, a novel layer-wise stochastic optimiser tailored towards\ntraining neural networks with binary weights, known as binary neural networks\n(BNNs), on quantum hardware. BNNs reduce the computational requirements and\nenergy consumption of deep learning models with minimal loss in accuracy.\nHowever, training them in practice remains to be an open challenge. Most known\nBNN-optimisers either rely on projected updates or binarise weights\npost-training. Instead, QP-SBGD approximately maps the gradient onto binary\nvariables, by solving a quadratic constrained binary optimisation. Under\npractically reasonable assumptions, we show that this update rule converges\nwith a rate of $\\mathcal{O}(1 / \\sqrt{T})$. Moreover, we show how the\n$\\mathcal{NP}$-hard projection can be effectively executed on an adiabatic\nquantum annealer, harnessing recent advancements in quantum computation. We\nalso introduce a projected version of this update rule and prove that if a\nfixed point exists in the binary variable space, the modified updates will\nconverge to it. Last but not least, our algorithm is implemented layer-wise,\nmaking it suitable to train larger networks on resource-limited quantum\nhardware. Through extensive evaluations, we show that QP-SBGD outperforms or is\non par with competitive and well-established baselines such as BinaryConnect,\nsignSGD and ProxQuant when optimising the Rosenbrock function, training BNNs as\nwell as binary graph neural networks.",
            "author": [
                "Maximilian Krahn",
                "Michelle Sasdelli",
                "Fengyi Yang",
                "Vladislav Golyanik",
                "Juho Kannala",
                "Tat-Jun Chin",
                "Tolga Birdal"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15128v1",
                "http://arxiv.org/pdf/2310.15128v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15127v2",
            "title": "Open-Ended Instructable Embodied Agents with Memory-Augmented Large\n  Language Models",
            "updated": "2023-11-20T18:51:29Z",
            "published": "2023-10-23T17:31:55Z",
            "summary": "Pre-trained and frozen large language models (LLMs) can effectively map\nsimple scene rearrangement instructions to programs over a robot's visuomotor\nfunctions through appropriate few-shot example prompting. To parse open-domain\nnatural language and adapt to a user's idiosyncratic procedures, not known\nduring prompt engineering time, fixed prompts fall short. In this paper, we\nintroduce HELPER, an embodied agent equipped with an external memory of\nlanguage-program pairs that parses free-form human-robot dialogue into action\nprograms through retrieval-augmented LLM prompting: relevant memories are\nretrieved based on the current dialogue, instruction, correction, or VLM\ndescription, and used as in-context prompt examples for LLM querying. The\nmemory is expanded during deployment to include pairs of user's language and\naction plans, to assist future inferences and personalize them to the user's\nlanguage and routines. HELPER sets a new state-of-the-art in the TEACh\nbenchmark in both Execution from Dialog History (EDH) and Trajectory from\nDialogue (TfD), with a 1.7x improvement over the previous state-of-the-art for\nTfD. Our models, code, and video results can be found in our project's website:\nhttps://helper-agent-llm.github.io.",
            "author": [
                "Gabriel Sarch",
                "Yue Wu",
                "Michael J. Tarr",
                "Katerina Fragkiadaki"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15127v2",
                "http://arxiv.org/pdf/2310.15127v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.LG",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15124v1",
            "title": "Mixed-Variable Global Sensitivity Analysis For Knowledge Discovery And\n  Efficient Combinatorial Materials Design",
            "updated": "2023-10-23T17:29:53Z",
            "published": "2023-10-23T17:29:53Z",
            "summary": "Global Sensitivity Analysis (GSA) is the study of the influence of any given\ninputs on the outputs of a model. In the context of engineering design, GSA has\nbeen widely used to understand both individual and collective contributions of\ndesign variables on the design objectives. So far, global sensitivity studies\nhave often been limited to design spaces with only quantitative (numerical)\ndesign variables. However, many engineering systems also contain, if not only,\nqualitative (categorical) design variables in addition to quantitative design\nvariables. In this paper, we integrate Latent Variable Gaussian Process (LVGP)\nwith Sobol' analysis to develop the first metamodel-based mixed-variable GSA\nmethod. Through numerical case studies, we validate and demonstrate the\neffectiveness of our proposed method for mixed-variable problems. Furthermore,\nwhile the proposed GSA method is general enough to benefit various engineering\ndesign applications, we integrate it with multi-objective Bayesian optimization\n(BO) to create a sensitivity-aware design framework in accelerating the Pareto\nfront design exploration for metal-organic framework (MOF) materials with\nmany-level combinatorial design spaces. Although MOFs are constructed only from\nqualitative variables that are notoriously difficult to design, our method can\nutilize sensitivity analysis to navigate the optimization in the many-level\nlarge combinatorial design space, greatly expediting the exploration of novel\nMOF candidates.",
            "author": [
                "Yigitcan Comlek",
                "Liwei Wang",
                "Wei Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15124v1",
                "http://arxiv.org/pdf/2310.15124v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cond-mat.mtrl-sci",
                "cs.LG",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15123v1",
            "title": "Branch-Solve-Merge Improves Large Language Model Evaluation and\n  Generation",
            "updated": "2023-10-23T17:29:48Z",
            "published": "2023-10-23T17:29:48Z",
            "summary": "Large Language Models (LLMs) are frequently used for multi-faceted language\ngeneration and evaluation tasks that involve satisfying intricate user\nconstraints or taking into account multiple aspects and criteria. However,\ntheir performance can fall short, due to the model's lack of coherence and\ninability to plan and decompose the problem. We propose Branch-Solve-Merge\n(BSM), a Large Language Model program (Schlag et al., 2023) for tackling such\nchallenging natural language tasks. It consists of branch, solve, and merge\nmodules that are parameterized with specific prompts to the base LLM. These\nthree modules plan a decomposition of the task into multiple parallel\nsub-tasks, independently solve them, and fuse the solutions to the sub-tasks.\nWe apply our method to the tasks of LLM response evaluation and constrained\ntext generation and evaluate its effectiveness with multiple LLMs, including\nVicuna, LLaMA-2-chat, and GPT-4. BSM improves the evaluation correctness and\nconsistency for each LLM by enhancing human-LLM agreement by up to 26%,\nreducing length and pairwise position biases by up to 50%, and allowing\nLLaMA-2-chat to match or outperform GPT-4 on most domains. On the constraint\nstory generation task, BSM improves the coherence of the stories while also\nimproving constraint satisfaction by 12%.",
            "author": [
                "Swarnadeep Saha",
                "Omer Levy",
                "Asli Celikyilmaz",
                "Mohit Bansal",
                "Jason Weston",
                "Xian Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15123v1",
                "http://arxiv.org/pdf/2310.15123v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15211v2",
            "title": "Modeling Path Importance for Effective Alzheimer's Disease Drug\n  Repurposing",
            "updated": "2023-10-27T16:29:44Z",
            "published": "2023-10-23T17:24:11Z",
            "summary": "Recently, drug repurposing has emerged as an effective and resource-efficient\nparadigm for AD drug discovery. Among various methods for drug repurposing,\nnetwork-based methods have shown promising results as they are capable of\nleveraging complex networks that integrate multiple interaction types, such as\nprotein-protein interactions, to more effectively identify candidate drugs.\nHowever, existing approaches typically assume paths of the same length in the\nnetwork have equal importance in identifying the therapeutic effect of drugs.\nOther domains have found that same length paths do not necessarily have the\nsame importance. Thus, relying on this assumption may be deleterious to drug\nrepurposing attempts. In this work, we propose MPI (Modeling Path Importance),\na novel network-based method for AD drug repurposing. MPI is unique in that it\nprioritizes important paths via learned node embeddings, which can effectively\ncapture a network's rich structural information. Thus, leveraging learned\nembeddings allows MPI to effectively differentiate the importance among paths.\nWe evaluate MPI against a commonly used baseline method that identifies anti-AD\ndrug candidates primarily based on the shortest paths between drugs and AD in\nthe network. We observe that among the top-50 ranked drugs, MPI prioritizes\n20.0% more drugs with anti-AD evidence compared to the baseline. Finally, Cox\nproportional-hazard models produced from insurance claims data aid us in\nidentifying the use of etodolac, nicotine, and BBB-crossing ACE-INHs as having\na reduced risk of AD, suggesting such drugs may be viable candidates for\nrepurposing and should be explored further in future studies.",
            "author": [
                "Shunian Xiang",
                "Patrick J. Lawrence",
                "Bo Peng",
                "ChienWei Chiang",
                "Dokyoon Kim",
                "Li Shen",
                "Xia Ning"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15211v2",
                "http://arxiv.org/pdf/2310.15211v2"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM",
                "cs.AI",
                "cs.LG",
                "q-bio.MN"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15111v1",
            "title": "Matryoshka Diffusion Models",
            "updated": "2023-10-23T17:20:01Z",
            "published": "2023-10-23T17:20:01Z",
            "summary": "Diffusion models are the de facto approach for generating high-quality images\nand videos, but learning high-dimensional models remains a formidable task due\nto computational and optimization challenges. Existing methods often resort to\ntraining cascaded models in pixel space or using a downsampled latent space of\na separately trained auto-encoder. In this paper, we introduce Matryoshka\nDiffusion Models(MDM), an end-to-end framework for high-resolution image and\nvideo synthesis. We propose a diffusion process that denoises inputs at\nmultiple resolutions jointly and uses a NestedUNet architecture where features\nand parameters for small-scale inputs are nested within those of large scales.\nIn addition, MDM enables a progressive training schedule from lower to higher\nresolutions, which leads to significant improvements in optimization for\nhigh-resolution generation. We demonstrate the effectiveness of our approach on\nvarious benchmarks, including class-conditioned image generation,\nhigh-resolution text-to-image, and text-to-video applications. Remarkably, we\ncan train a single pixel-space model at resolutions of up to 1024x1024 pixels,\ndemonstrating strong zero-shot generalization using the CC12M dataset, which\ncontains only 12 million images.",
            "author": [
                "Jiatao Gu",
                "Shuangfei Zhai",
                "Yizhe Zhang",
                "Josh Susskind",
                "Navdeep Jaitly"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15111v1",
                "http://arxiv.org/pdf/2310.15111v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15109v1",
            "title": "GRENADE: Graph-Centric Language Model for Self-Supervised Representation\n  Learning on Text-Attributed Graphs",
            "updated": "2023-10-23T17:18:35Z",
            "published": "2023-10-23T17:18:35Z",
            "summary": "Self-supervised representation learning on text-attributed graphs, which aims\nto create expressive and generalizable representations for various downstream\ntasks, has received increasing research attention lately. However, existing\nmethods either struggle to capture the full extent of structural context\ninformation or rely on task-specific training labels, which largely hampers\ntheir effectiveness and generalizability in practice. To solve the problem of\nself-supervised representation learning on text-attributed graphs, we develop a\nnovel Graph-Centric Language model -- GRENADE. Specifically, GRENADE exploits\nthe synergistic effect of both pre-trained language model and graph neural\nnetwork by optimizing with two specialized self-supervised learning algorithms:\ngraph-centric contrastive learning and graph-centric knowledge alignment. The\nproposed graph-centric self-supervised learning algorithms effectively help\nGRENADE to capture informative textual semantics as well as structural context\ninformation on text-attributed graphs. Through extensive experiments, GRENADE\nshows its superiority over state-of-the-art methods. Implementation is\navailable at \\url{https://github.com/bigheiniu/GRENADE}.",
            "author": [
                "Yichuan Li",
                "Kaize Ding",
                "Kyumin Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15109v1",
                "http://arxiv.org/pdf/2310.15109v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15108v1",
            "title": "Evaluating machine learning models in non-standard settings: An overview\n  and new findings",
            "updated": "2023-10-23T17:15:11Z",
            "published": "2023-10-23T17:15:11Z",
            "summary": "Estimating the generalization error (GE) of machine learning models is\nfundamental, with resampling methods being the most common approach. However,\nin non-standard settings, particularly those where observations are not\nindependently and identically distributed, resampling using simple random data\ndivisions may lead to biased GE estimates. This paper strives to present\nwell-grounded guidelines for GE estimation in various such non-standard\nsettings: clustered data, spatial data, unequal sampling probabilities, concept\ndrift, and hierarchically structured outcomes. Our overview combines\nwell-established methodologies with other existing methods that, to our\nknowledge, have not been frequently considered in these particular settings. A\nunifying principle among these techniques is that the test data used in each\niteration of the resampling procedure should reflect the new observations to\nwhich the model will be applied, while the training data should be\nrepresentative of the entire data set used to obtain the final model. Beyond\nproviding an overview, we address literature gaps by conducting simulation\nstudies. These studies assess the necessity of using GE-estimation methods\ntailored to the respective setting. Our findings corroborate the concern that\nstandard resampling methods often yield biased GE estimates in non-standard\nsettings, underscoring the importance of tailored GE estimation.",
            "author": [
                "Roman Hornung",
                "Malte Nalenz",
                "Lennart Schneider",
                "Andreas Bender",
                "Ludwig Bothmann",
                "Bernd Bischl",
                "Thomas Augustin",
                "Anne-Laure Boulesteix"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15108v1",
                "http://arxiv.org/pdf/2310.15108v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "stat.AP",
                "stat.CO",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15107v1",
            "title": "Assembling a high-precision abundance catalogue of solar twins in GALAH\n  for phylogenetic studies",
            "updated": "2023-10-23T17:14:43Z",
            "published": "2023-10-23T17:14:43Z",
            "summary": "Stellar chemical abundances have proved themselves a key source of\ninformation for understanding the evolution of the Milky Way, and the scale of\nmajor stellar surveys such as GALAH have massively increased the amount of\nchemical data available. However, progress is hampered by the level of\nprecision in chemical abundance data as well as the visualization methods for\ncomparing the multidimensional outputs of chemical evolution models to stellar\nabundance data. Machine learning methods have greatly improved the former;\nwhile the application of tree-building or phylogenetic methods borrowed from\nbiology are beginning to show promise with the latter. Here we analyse a sample\nof GALAH solar twins to address these issues. We apply The Cannon algorithm\n(Ness et al. (2015)) to generate a catalogue of about 40,000 solar twins with\n14 high precision abundances which we use to perform a phylogenetic analysis on\na selection of stars that have two different ranges of eccentricities. From our\nanalyses we are able to find a group with mostly stars on circular orbits and\nsome old stars with eccentric orbits whose age-[Y/Mg] relation agrees\nremarkably well with the chemical clocks published by previous high precision\nabundance studies. Our results show the power of combining survey data with\nmachine learning and phylogenetics to reconstruct the history of the Milky Way.",
            "author": [
                "Kurt Walsen",
                "Paula Jofr\u00e9",
                "Sven Buder",
                "Keaghan Yaxley",
                "Payel Das",
                "Robert Yates",
                "Xia Hua",
                "Theosamuele Signor",
                "Camilla Eldridge",
                "Alvaro Rojas-Arriagada",
                "Patricia Tissera",
                "Evelyn Johnston",
                "Claudia Aguilera-G\u00f3mez",
                "Manuela Zoccali",
                "Gerry Gilmore",
                "Robert Foley"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15107v1",
                "http://arxiv.org/pdf/2310.15107v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15105v4",
            "title": "FD-Align: Feature Discrimination Alignment for Fine-tuning Pre-Trained\n  Models in Few-Shot Learning",
            "updated": "2023-11-17T07:27:34Z",
            "published": "2023-10-23T17:12:01Z",
            "summary": "Due to the limited availability of data, existing few-shot learning methods\ntrained from scratch fail to achieve satisfactory performance. In contrast,\nlarge-scale pre-trained models such as CLIP demonstrate remarkable few-shot and\nzero-shot capabilities. To enhance the performance of pre-trained models for\ndownstream tasks, fine-tuning the model on downstream data is frequently\nnecessary. However, fine-tuning the pre-trained model leads to a decrease in\nits generalizability in the presence of distribution shift, while the limited\nnumber of samples in few-shot learning makes the model highly susceptible to\noverfitting. Consequently, existing methods for fine-tuning few-shot learning\nprimarily focus on fine-tuning the model's classification head or introducing\nadditional structure. In this paper, we introduce a fine-tuning approach termed\nFeature Discrimination Alignment (FD-Align). Our method aims to bolster the\nmodel's generalizability by preserving the consistency of spurious features\nacross the fine-tuning process. Extensive experimental results validate the\nefficacy of our approach for both ID and OOD tasks. Once fine-tuned, the model\ncan seamlessly integrate with existing methods, leading to performance\nimprovements. Our code can be found in https://github.com/skingorz/FD-Align.",
            "author": [
                "Kun Song",
                "Huimin Ma",
                "Bochao Zou",
                "Huishuai Zhang",
                "Weiran Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15105v4",
                "http://arxiv.org/pdf/2310.15105v4"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15100v1",
            "title": "LLM-in-the-loop: Leveraging Large Language Model for Thematic Analysis",
            "updated": "2023-10-23T17:05:59Z",
            "published": "2023-10-23T17:05:59Z",
            "summary": "Thematic analysis (TA) has been widely used for analyzing qualitative data in\nmany disciplines and fields. To ensure reliable analysis, the same piece of\ndata is typically assigned to at least two human coders. Moreover, to produce\nmeaningful and useful analysis, human coders develop and deepen their data\ninterpretation and coding over multiple iterations, making TA labor-intensive\nand time-consuming. Recently the emerging field of large language models (LLMs)\nresearch has shown that LLMs have the potential replicate human-like behavior\nin various tasks: in particular, LLMs outperform crowd workers on\ntext-annotation tasks, suggesting an opportunity to leverage LLMs on TA. We\npropose a human-LLM collaboration framework (i.e., LLM-in-the-loop) to conduct\nTA with in-context learning (ICL). This framework provides the prompt to frame\ndiscussions with a LLM (e.g., GPT-3.5) to generate the final codebook for TA.\nWe demonstrate the utility of this framework using survey datasets on the\naspects of the music listening experience and the usage of a password manager.\nResults of the two case studies show that the proposed framework yields similar\ncoding quality to that of human coders but reduces TA's labor and time demands.",
            "author": [
                "Shih-Chieh Dai",
                "Aiping Xiong",
                "Lun-Wei Ku"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15100v1",
                "http://arxiv.org/pdf/2310.15100v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15099v1",
            "title": "Dual-path convolutional neural network using micro-FTIR imaging to\n  predict breast cancer subtypes and biomarkers levels: estrogen receptor,\n  progesterone receptor, HER2 and Ki67",
            "updated": "2023-10-23T17:05:53Z",
            "published": "2023-10-23T17:05:53Z",
            "summary": "Breast cancer molecular subtypes classification plays an import role to sort\npatients with divergent prognosis. The biomarkers used are Estrogen Receptor\n(ER), Progesterone Receptor (PR), HER2, and Ki67. Based on these biomarkers\nexpression levels, subtypes are classified as Luminal A (LA), Luminal B (LB),\nHER2 subtype, and Triple-Negative Breast Cancer (TNBC). Immunohistochemistry is\nused to classify subtypes, although interlaboratory and interobserver\nvariations can affect its accuracy, besides being a time-consuming technique.\nThe Fourier transform infrared micro-spectroscopy may be coupled with deep\nlearning for cancer evaluation, where there is still a lack of studies for\nsubtypes and biomarker levels prediction. This study presents a novel 2D deep\nlearning approach to achieve these predictions. Sixty micro-FTIR images of\n320x320 pixels were collected from a human breast biopsies microarray. Data\nwere clustered by K-means, preprocessed and 32x32 patches were generated using\na fully automated approach. CaReNet-V2, a novel convolutional neural network,\nwas developed to classify breast cancer (CA) vs adjacent tissue (AT) and\nmolecular subtypes, and to predict biomarkers level. The clustering method\nenabled to remove non-tissue pixels. Test accuracies for CA vs AT and subtype\nwere above 0.84. The model enabled the prediction of ER, PR, and HER2 levels,\nwhere borderline values showed lower performance (minimum accuracy of 0.54).\nKi67 percentage regression demonstrated a mean error of 3.6%. Thus, CaReNet-V2\nis a potential technique for breast cancer biopsies evaluation, standing out as\na screening analysis technique and helping to prioritize patients.",
            "author": [
                "Matheus del-Valle",
                "Emerson Soares Bernardes",
                "Denise Maria Zezell"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15099v1",
                "http://arxiv.org/pdf/2310.15099v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV",
                "I.2; I.4"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15098v1",
            "title": "Acquiring Weak Annotations for Tumor Localization in Temporal and\n  Volumetric Data",
            "updated": "2023-10-23T17:03:02Z",
            "published": "2023-10-23T17:03:02Z",
            "summary": "Creating large-scale and well-annotated datasets to train AI algorithms is\ncrucial for automated tumor detection and localization. However, with limited\nresources, it is challenging to determine the best type of annotations when\nannotating massive amounts of unlabeled data. To address this issue, we focus\non polyps in colonoscopy videos and pancreatic tumors in abdominal CT scans;\nboth applications require significant effort and time for pixel-wise annotation\ndue to the high dimensional nature of the data, involving either temporary or\nspatial dimensions. In this paper, we develop a new annotation strategy, termed\nDrag&Drop, which simplifies the annotation process to drag and drop. This\nannotation strategy is more efficient, particularly for temporal and volumetric\nimaging, than other types of weak annotations, such as per-pixel, bounding\nboxes, scribbles, ellipses, and points. Furthermore, to exploit our Drag&Drop\nannotations, we develop a novel weakly supervised learning method based on the\nwatershed algorithm. Experimental results show that our method achieves better\ndetection and localization performance than alternative weak annotations and,\nmore importantly, achieves similar performance to that trained on detailed\nper-pixel annotations. Interestingly, we find that, with limited resources,\nallocating weak annotations from a diverse patient population can foster models\nmore robust to unseen images than allocating per-pixel annotations for a small\nset of images. In summary, this research proposes an efficient annotation\nstrategy for tumor detection and localization that is less accurate than\nper-pixel annotations but useful for creating large-scale datasets for\nscreening tumors in various medical modalities.",
            "author": [
                "Yu-Cheng Chou",
                "Bowen Li",
                "Deng-Ping Fan",
                "Alan Yuille",
                "Zongwei Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15098v1",
                "http://arxiv.org/pdf/2310.15098v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15097v1",
            "title": "A Canonical Data Transformation for Achieving Inter- and Within-group\n  Fairness",
            "updated": "2023-10-23T17:00:20Z",
            "published": "2023-10-23T17:00:20Z",
            "summary": "Increases in the deployment of machine learning algorithms for applications\nthat deal with sensitive data have brought attention to the issue of fairness\nin machine learning. Many works have been devoted to applications that require\ndifferent demographic groups to be treated fairly. However, algorithms that aim\nto satisfy inter-group fairness (also called group fairness) may inadvertently\ntreat individuals within the same demographic group unfairly. To address this\nissue, we introduce a formal definition of within-group fairness that maintains\nfairness among individuals from within the same group. We propose a\npre-processing framework to meet both inter- and within-group fairness criteria\nwith little compromise in accuracy. The framework maps the feature vectors of\nmembers from different groups to an inter-group-fair canonical domain before\nfeeding them into a scoring function. The mapping is constructed to preserve\nthe relative relationship between the scores obtained from the unprocessed\nfeature vectors of individuals from the same demographic group, guaranteeing\nwithin-group fairness. We apply this framework to the COMPAS risk assessment\nand Law School datasets and compare its performance in achieving inter-group\nand within-group fairness to two regularization-based methods.",
            "author": [
                "Zachary McBride Lazri",
                "Ivan Brugere",
                "Xin Tian",
                "Dana Dachman-Soled",
                "Antigoni Polychroniadou",
                "Danial Dervovic",
                "Min Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15097v1",
                "http://arxiv.org/pdf/2310.15097v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15094v1",
            "title": "One-dimensional convolutional neural network model for breast cancer\n  subtypes classification and biochemical content evaluation using micro-FTIR\n  hyperspectral images",
            "updated": "2023-10-23T16:58:34Z",
            "published": "2023-10-23T16:58:34Z",
            "summary": "Breast cancer treatment still remains a challenge, where molecular subtypes\nclassification plays a crucial role in selecting appropriate and specific\ntherapy. The four subtypes are Luminal A (LA), Luminal B (LB), HER2 subtype,\nand Triple-Negative Breast Cancer (TNBC). Immunohistochemistry is the\ngold-standard evaluation, although interobserver variations are reported and\nmolecular signatures identification is time-consuming. Fourier transform\ninfrared micro-spectroscopy with machine learning approaches have been used to\nevaluate cancer samples, presenting biochemical-related explainability.\nHowever, this explainability is harder when using deep learning. This study\ncreated a 1D deep learning tool for breast cancer subtype evaluation and\nbiochemical contribution. Sixty hyperspectral images were acquired from a human\nbreast cancer microarray. K-Means clustering was applied to select tissue and\nparaffin spectra. CaReNet-V1, a novel 1D convolutional neural network, was\ndeveloped to classify breast cancer (CA) and adjacent tissue (AT), and\nmolecular subtypes. A 1D adaptation of Grad-CAM was applied to assess the\nbiochemical impact to the classifications. CaReNet-V1 effectively classified CA\nand AT (test accuracy of 0.89), as well as HER2 and TNBC subtypes (0.83 and\n0.86), with greater difficulty for LA and LB (0.74 and 0.68). The model enabled\nthe evaluation of the most contributing wavenumbers to the predictions,\nproviding a direct relationship with the biochemical content. Therefore,\nCaReNet-V1 and hyperspectral images is a potential approach for breast cancer\nbiopsies assessment, providing additional information to the pathology report.\nBiochemical content impact feature may be used for other studies, such as\ntreatment efficacy evaluation and development new diagnostics and therapeutic\nmethods.",
            "author": [
                "Matheus del-Valle",
                "Emerson Soares Bernardes",
                "Denise Maria Zezell"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15094v1",
                "http://arxiv.org/pdf/2310.15094v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "I.2"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15085v1",
            "title": "On the Detection of Image-Scaling Attacks in Machine Learning",
            "updated": "2023-10-23T16:46:28Z",
            "published": "2023-10-23T16:46:28Z",
            "summary": "Image scaling is an integral part of machine learning and computer vision\nsystems. Unfortunately, this preprocessing step is vulnerable to so-called\nimage-scaling attacks where an attacker makes unnoticeable changes to an image\nso that it becomes a new image after scaling. This opens up new ways for\nattackers to control the prediction or to improve poisoning and backdoor\nattacks. While effective techniques exist to prevent scaling attacks, their\ndetection has not been rigorously studied yet. Consequently, it is currently\nnot possible to reliably spot these attacks in practice.\n  This paper presents the first in-depth systematization and analysis of\ndetection methods for image-scaling attacks. We identify two general detection\nparadigms and derive novel methods from them that are simple in design yet\nsignificantly outperform previous work. We demonstrate the efficacy of these\nmethods in a comprehensive evaluation with all major learning platforms and\nscaling algorithms. First, we show that image-scaling attacks modifying the\nentire scaled image can be reliably detected even under an adaptive adversary.\nSecond, we find that our methods provide strong detection performance even if\nonly minor parts of the image are manipulated. As a result, we can introduce a\nnovel protection layer against image-scaling attacks.",
            "author": [
                "Erwin Quiring",
                "Andreas M\u00fcller",
                "Konrad Rieck"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15085v1",
                "http://arxiv.org/pdf/2310.15085v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15084v1",
            "title": "Quantum Federated Learning With Quantum Networks",
            "updated": "2023-10-23T16:45:29Z",
            "published": "2023-10-23T16:45:29Z",
            "summary": "A major concern of deep learning models is the large amount of data that is\nrequired to build and train them, much of which is reliant on sensitive and\npersonally identifiable information that is vulnerable to access by third\nparties. Ideas of using the quantum internet to address this issue have been\npreviously proposed, which would enable fast and completely secure online\ncommunications. Previous work has yielded a hybrid quantum-classical transfer\nlearning scheme for classical data and communication with a hub-spoke topology.\nWhile quantum communication is secure from eavesdrop attacks and no\nmeasurements from quantum to classical translation, due to no cloning theorem,\nhub-spoke topology is not ideal for quantum communication without quantum\nmemory. Here we seek to improve this model by implementing a decentralized ring\ntopology for the federated learning scheme, where each client is given a\nportion of the entire dataset and only performs training on that set. We also\ndemonstrate the first successful use of quantum weights for quantum federated\nlearning, which allows us to perform our training entirely in quantum.",
            "author": [
                "Tyler Wang",
                "Huan-Hsin Tseng",
                "Shinjae Yoo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15084v1",
                "http://arxiv.org/pdf/2310.15084v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15083v1",
            "title": "Mass uptake during oxidation of metallic alloys: literature data\n  collection, analysis, and FAIR sharing",
            "updated": "2023-10-23T16:44:43Z",
            "published": "2023-10-23T16:44:43Z",
            "summary": "The area-normalized change of mass ($\\Delta$m/A) with time during the\noxidation of metallic alloys is commonly used to assess oxidation resistance.\nAnalyses of such data can also aid in evaluating underlying oxidation\nmechanisms. We performed an exhaustive literature search and digitized\nnormalized mass change vs. time data for 407 alloys. To maximize the impact of\nthese and future mass uptake data, we developed and published an open, online,\ncomputational workflow that fits the data to various models of oxidation\nkinetics, uses Bayesian statistics for model selection, and makes the raw data\nand model parameters available via a queryable database. The tool, Refractory\nOxidation Database (https://nanohub.org/tools/refoxdb/), uses nanoHUB's Sim2Ls\nto make the workflow and data (including metadata) findable, accessible,\ninteroperable, and reusable (FAIR). We find that the models selected by the\noriginal authors do not match the most likely one according to the Bayesian\ninformation criterion (BIC) in 71% of the cases. Further, in 56% of the cases,\nthe published model was not even in the top 3 models according to the BIC.\nThese numbers were obtained assuming an experimental noise of 2.5% of the mass\ngain range, a smaller noise leads to more discrepancies. The RefOxDB tool is\nopen access and researchers can add their own raw data (those to be included in\nfuture publications, as well as negative results) for analysis and to share\ntheir work with the community. Such consistent and systematic analysis of open,\ncommunity generated data can significantly accelerate the development of\nmachine-learning models for oxidation behavior and assist in the understanding\nand improvement of oxidation resistance.",
            "author": [
                "Saswat Mishra",
                "Sharmila Karumuri",
                "Vincent Mika",
                "Collin Scott",
                "Chadwick Choy",
                "Kenneth H. Sandhage",
                "Ilias Bilionis",
                "Michael S. Titus",
                "Alejandro Strachan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15083v1",
                "http://arxiv.org/pdf/2310.15083v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15080v2",
            "title": "Federated Learning of Large Language Models with Parameter-Efficient\n  Prompt Tuning and Adaptive Optimization",
            "updated": "2023-10-29T07:17:45Z",
            "published": "2023-10-23T16:37:59Z",
            "summary": "Federated learning (FL) is a promising paradigm to enable collaborative model\ntraining with decentralized data. However, the training process of Large\nLanguage Models (LLMs) generally incurs the update of significant parameters,\nwhich limits the applicability of FL techniques to tackle the LLMs in real\nscenarios. Prompt tuning can significantly reduce the number of parameters to\nupdate, but it either incurs performance degradation or low training\nefficiency. The straightforward utilization of prompt tuning in the FL often\nraises non-trivial communication costs and dramatically degrades performance.\nIn addition, the decentralized data is generally non-Independent and\nIdentically Distributed (non-IID), which brings client drift problems and thus\npoor performance. This paper proposes a Parameter-efficient prompt Tuning\napproach with Adaptive Optimization, i.e., FedPepTAO, to enable efficient and\neffective FL of LLMs. First, an efficient partial prompt tuning approach is\nproposed to improve performance and efficiency simultaneously. Second, a novel\nadaptive optimization method is developed to address the client drift problems\non both the device and server sides to enhance performance further. Extensive\nexperiments based on 10 datasets demonstrate the superb performance (up to\n60.8\\% in terms of accuracy) and efficiency (up to 97.59\\% in terms of training\ntime) of FedPepTAO compared with 9 baseline approaches. Our code is available\nat https://github.com/llm-eff/FedPepTAO.",
            "author": [
                "Tianshi Che",
                "Ji Liu",
                "Yang Zhou",
                "Jiaxiang Ren",
                "Jiwen Zhou",
                "Victor S. Sheng",
                "Huaiyu Dai",
                "Dejing Dou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15080v2",
                "http://arxiv.org/pdf/2310.15080v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15074v2",
            "title": "MGAS: Multi-Granularity Architecture Search for Effective and Efficient\n  Neural Networks",
            "updated": "2023-10-25T06:50:49Z",
            "published": "2023-10-23T16:32:18Z",
            "summary": "Differentiable architecture search (DAS) revolutionizes neural architecture\nsearch (NAS) with time-efficient automation, transitioning from discrete\ncandidate sampling and evaluation to differentiable super-net optimization and\ndiscretization. However, existing DAS methods either only conduct\ncoarse-grained operation-level search or manually define the remaining ratios\nfor fine-grained kernel-level and weight-level units, which fail to\nsimultaneously optimize model size and model performance. Furthermore, these\nmethods compromise search quality to reduce memory consumption. To tackle these\nissues, we introduce multi-granularity architecture search (MGAS), a unified\nframework which aims to comprehensively and memory-efficiently explore the\nmulti-granularity search space to discover both effective and efficient neural\nnetworks. Specifically, we learn discretization functions specific to each\ngranularity level to adaptively determine the remaining ratios according to the\nevolving architecture. This ensures an optimal balance among units of different\ngranularity levels for different target model sizes. Considering the memory\ndemands, we break down the super-net optimization and discretization into\nmultiple sub-net stages. Nevertheless, the greedy nature of this approach may\nintroduce bias in the early stages. To compensate for the bias, we propose\nprogressive re-evaluation to allow for re-pruning and regrowing of previous\nunits during subsequent stages. Extensive experiments on CIFAR-10, CIFAR-100\nand ImageNet demonstrate that MGAS outperforms other state-of-the-art methods\nin achieving a better trade-off between model performance and model size.",
            "author": [
                "Xiaoyun Liu",
                "Divya Saxena",
                "Jiannong Cao",
                "Yuqing Zhao",
                "Penghui Ruan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15074v2",
                "http://arxiv.org/pdf/2310.15074v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18353v1",
            "title": "Supporting Custom Instructions with the LLVM Compiler for RISC-V\n  Processor",
            "updated": "2023-10-23T16:19:01Z",
            "published": "2023-10-23T16:19:01Z",
            "summary": "The rise of hardware accelerators with custom instructions necessitates\ncustom compiler backends supporting these accelerators. This study provides\ndetailed analyses of LLVM and its RISC-V backend, supplemented with case\nstudies providing end-to-end overview of the mentioned transformations.\n  We discuss that instruction design should consider both hardware and software\ndesign space. The necessary compiler modifications may mean that the\ninstruction is not well designed and need to be reconsidered. We discuss that\nRISC-V standard extensions provide exemplary instructions that can guide\ninstruction designers.\n  In this study, the process of adding a custom instruction to compiler is\nsplit into two parts as Assembler support and pattern matching support. Without\npattern matching support, conventional software requires manual entries of\ninline Assembly for the accelerator which is not scalable. While it is trivial\nto add Assembler support regardless of the instruction semantics, pattern\nmatching support is on the contrary. Pattern matching support and choosing the\nright stage for the modification, requires the knowledge of the internal\ntransformations in the compiler. This study delves deep into pattern matching\nand presents multiple ways to approach the problem of pattern matching support.\nIt is discussed that depending on the pattern's complexity, higher level\ntransformations, e.g. IR level, can be more maintainable compared to\nInstruction Selection phase.",
            "author": [
                "Eymen \u00dcnay",
                "Bora \u0130nan",
                "Emrecan Yi\u011fit"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18353v1",
                "http://arxiv.org/pdf/2310.18353v1"
            ],
            "primary_category": "cs.AR",
            "category": [
                "cs.AR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15066v1",
            "title": "Localizing Active Objects from Egocentric Vision with Symbolic World\n  Knowledge",
            "updated": "2023-10-23T16:14:05Z",
            "published": "2023-10-23T16:14:05Z",
            "summary": "The ability to actively ground task instructions from an egocentric view is\ncrucial for AI agents to accomplish tasks or assist humans virtually. One\nimportant step towards this goal is to localize and track key active objects\nthat undergo major state change as a consequence of human actions/interactions\nto the environment without being told exactly what/where to ground (e.g.,\nlocalizing and tracking the `sponge` in video from the instruction \"Dip the\n`sponge` into the bucket.\"). While existing works approach this problem from a\npure vision perspective, we investigate to which extent the textual modality\n(i.e., task instructions) and their interaction with visual modality can be\nbeneficial. Specifically, we propose to improve phrase grounding models'\nability on localizing the active objects by: (1) learning the role of `objects\nundergoing change` and extracting them accurately from the instructions, (2)\nleveraging pre- and post-conditions of the objects during actions, and (3)\nrecognizing the objects more robustly with descriptional knowledge. We leverage\nlarge language models (LLMs) to extract the aforementioned action-object\nknowledge, and design a per-object aggregation masking technique to effectively\nperform joint inference on object phrases and symbolic knowledge. We evaluate\nour framework on Ego4D and Epic-Kitchens datasets. Extensive experiments\ndemonstrate the effectiveness of our proposed framework, which leads to>54%\nimprovements in all standard metrics on the TREK-150-OPE-Det localization +\ntracking task, >7% improvements in all standard metrics on the TREK-150-OPE\ntracking task, and >3% improvements in average precision (AP) on the Ego4D SCOD\ntask.",
            "author": [
                "Te-Lin Wu",
                "Yu Zhou",
                "Nanyun Peng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15066v1",
                "http://arxiv.org/pdf/2310.15066v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15065v2",
            "title": "Synergizing Human-AI Agency: A Guide of 23 Heuristics for Service\n  Co-Creation with LLM-Based Agents",
            "updated": "2023-11-29T22:37:21Z",
            "published": "2023-10-23T16:11:48Z",
            "summary": "This empirical study serves as a primer for interested service providers to\ndetermine if and how Large Language Models (LLMs) technology will be integrated\nfor their practitioners and the broader community. We investigate the mutual\nlearning journey of non-AI experts and AI through CoAGent, a service\nco-creation tool with LLM-based agents. Engaging in a three-stage participatory\ndesign processes, we work with with 23 domain experts from public libraries\nacross the U.S., uncovering their fundamental challenges of integrating AI into\nhuman workflows. Our findings provide 23 actionable \"heuristics for service\nco-creation with AI\", highlighting the nuanced shared responsibilities between\nhumans and AI. We further exemplar 9 foundational agency aspects for AI,\nemphasizing essentials like ownership, fair treatment, and freedom of\nexpression. Our innovative approach enriches the participatory design model by\nincorporating AI as crucial stakeholders and utilizing AI-AI interaction to\nidentify blind spots. Collectively, these insights pave the way for synergistic\nand ethical human-AI co-creation in service contexts, preparing for workforce\necosystems where AI coexists.",
            "author": [
                "Qingxiao Zheng",
                "Zhongwei Xu",
                "Abhinav Choudhry",
                "Yuting Chen",
                "Yongming Li",
                "Yun Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15065v2",
                "http://arxiv.org/pdf/2310.15065v2"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15061v1",
            "title": "The BLA Benchmark: Investigating Basic Language Abilities of Pre-Trained\n  Multimodal Models",
            "updated": "2023-10-23T16:05:13Z",
            "published": "2023-10-23T16:05:13Z",
            "summary": "Despite the impressive performance achieved by pre-trained\nlanguage-and-vision models in downstream tasks, it remains an open question\nwhether this reflects a proper understanding of image-text interaction. In this\nwork, we explore to what extent they handle basic linguistic constructions --\nactive-passive voice, coordination, and relative clauses -- that even preschool\nchildren can typically master. We present BLA, a novel, automatically\nconstructed benchmark to evaluate multimodal models on these Basic Language\nAbilities. We show that different types of Transformer-based systems, such as\nCLIP, ViLBERT, and BLIP2, generally struggle with BLA in a zero-shot setting,\nin line with previous findings. Our experiments, in particular, show that most\nof the tested models only marginally benefit when fine-tuned or prompted with\nconstruction-specific samples. Yet, the generative BLIP2 shows promising\ntrends, especially in an in-context learning setting. This opens the door to\nusing BLA not only as an evaluation benchmark but also to improve models' basic\nlanguage abilities.",
            "author": [
                "Xinyi Chen",
                "Raquel Fern\u00e1ndez",
                "Sandro Pezzelle"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15061v1",
                "http://arxiv.org/pdf/2310.15061v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15059v1",
            "title": "Robot Skill Generalization via Keypoint Integrated Soft Actor-Critic\n  Gaussian Mixture Models",
            "updated": "2023-10-23T16:03:23Z",
            "published": "2023-10-23T16:03:23Z",
            "summary": "A long-standing challenge for a robotic manipulation system operating in\nreal-world scenarios is adapting and generalizing its acquired motor skills to\nunseen environments. We tackle this challenge employing hybrid skill models\nthat integrate imitation and reinforcement paradigms, to explore how the\nlearning and adaptation of a skill, along with its core grounding in the scene\nthrough a learned keypoint, can facilitate such generalization. To that end, we\ndevelop Keypoint Integrated Soft Actor-Critic Gaussian Mixture Models (KIS-GMM)\napproach that learns to predict the reference of a dynamical system within the\nscene as a 3D keypoint, leveraging visual observations obtained by the robot's\nphysical interactions during skill learning. Through conducting comprehensive\nevaluations in both simulated and real-world environments, we show that our\nmethod enables a robot to gain a significant zero-shot generalization to novel\nenvironments and to refine skills in the target environments faster than\nlearning from scratch. Importantly, this is achieved without the need for new\nground truth data. Moreover, our method effectively copes with scene\ndisplacements.",
            "author": [
                "Iman Nematollahi",
                "Kirill Yankov",
                "Wolfram Burgard",
                "Tim Welschehold"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15059v1",
                "http://arxiv.org/pdf/2310.15059v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15057v2",
            "title": "Shareable Driving Style Learning and Analysis with a Hierarchical Latent\n  Model",
            "updated": "2023-10-24T06:46:13Z",
            "published": "2023-10-23T16:01:54Z",
            "summary": "Driving style is usually used to characterize driving behavior for a driver\nor a group of drivers. However, it remains unclear how one individual's driving\nstyle shares certain common grounds with other drivers. Our insight is that\ndriving behavior is a sequence of responses to the weighted mixture of latent\ndriving styles that are shareable within and between individuals. To this end,\nthis paper develops a hierarchical latent model to learn the relationship\nbetween driving behavior and driving styles. We first propose a fragment-based\napproach to represent complex sequential driving behavior, allowing for\nsufficiently representing driving behavior in a low-dimension feature space.\nThen, we provide an analytical formulation for the interaction of driving\nbehavior and shareable driving style with a hierarchical latent model by\nintroducing the mechanism of Dirichlet allocation. Our developed model is\nfinally validated and verified with 100 drivers in naturalistic driving\nsettings with urban and highways. Experimental results reveal that individuals\nshare driving styles within and between them. We also analyzed the influence of\npersonalities (e.g., age, gender, and driving experience) on driving styles and\nfound that a naturally aggressive driver would not always keep driving\naggressively (i.e., could behave calmly sometimes) but with a higher proportion\nof aggressiveness than other types of drivers.",
            "author": [
                "Chaopeng Zhang",
                "Wenshuo Wang",
                "Zhaokun Chen",
                "Jian Zhang",
                "Lijun Sun",
                "Junqiang Xi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15057v2",
                "http://arxiv.org/pdf/2310.15057v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15054v1",
            "title": "Coordinated Replay Sample Selection for Continual Federated Learning",
            "updated": "2023-10-23T15:56:39Z",
            "published": "2023-10-23T15:56:39Z",
            "summary": "Continual Federated Learning (CFL) combines Federated Learning (FL), the\ndecentralized learning of a central model on a number of client devices that\nmay not communicate their data, and Continual Learning (CL), the learning of a\nmodel from a continual stream of data without keeping the entire history. In\nCL, the main challenge is \\textit{forgetting} what was learned from past data.\nWhile replay-based algorithms that keep a small pool of past training data are\neffective to reduce forgetting, only simple replay sample selection strategies\nhave been applied to CFL in prior work, and no previous work has explored\ncoordination among clients for better sample selection. To bridge this gap, we\nadapt a replay sample selection objective based on loss gradient diversity to\nCFL and propose a new relaxation-based selection of samples to optimize the\nobjective. Next, we propose a practical algorithm to coordinate gradient-based\nreplay sample selection across clients without communicating private data. We\nbenchmark our coordinated and uncoordinated replay sample selection algorithms\nagainst random sampling-based baselines with language models trained on a large\nscale de-identified real-world text dataset. We show that gradient-based sample\nselection methods both boost performance and reduce forgetting compared to\nrandom sampling methods, with our coordination method showing gains early in\nthe low replay size regime (when the budget for storing past data is small).",
            "author": [
                "Jack Good",
                "Jimit Majmudar",
                "Christophe Dupuy",
                "Jixuan Wang",
                "Charith Peris",
                "Clement Chung",
                "Richard Zemel",
                "Rahul Gupta"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15054v1",
                "http://arxiv.org/pdf/2310.15054v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15051v1",
            "title": "TeleQnA: A Benchmark Dataset to Assess Large Language Models\n  Telecommunications Knowledge",
            "updated": "2023-10-23T15:55:15Z",
            "published": "2023-10-23T15:55:15Z",
            "summary": "We introduce TeleQnA, the first benchmark dataset designed to evaluate the\nknowledge of Large Language Models (LLMs) in telecommunications. Comprising\n10,000 questions and answers, this dataset draws from diverse sources,\nincluding standards and research articles. This paper outlines the automated\nquestion generation framework responsible for creating this dataset, along with\nhow human input was integrated at various stages to ensure the quality of the\nquestions. Afterwards, using the provided dataset, an evaluation is conducted\nto assess the capabilities of LLMs, including GPT-3.5 and GPT-4. The results\nhighlight that these models struggle with complex standards related questions\nbut exhibit proficiency in addressing general telecom-related inquiries.\nAdditionally, our results showcase how incorporating telecom knowledge context\nsignificantly enhances their performance, thus shedding light on the need for a\nspecialized telecom foundation model. Finally, the dataset is shared with\nactive telecom professionals, whose performance is subsequently benchmarked\nagainst that of the LLMs. The findings illustrate that LLMs can rival the\nperformance of active professionals in telecom knowledge, thanks to their\ncapacity to process vast amounts of information, underscoring the potential of\nLLMs within this domain. The dataset has been made publicly accessible on\nGitHub.",
            "author": [
                "Ali Maatouk",
                "Fadhel Ayed",
                "Nicola Piovesan",
                "Antonio De Domenico",
                "Merouane Debbah",
                "Zhi-Quan Luo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15051v1",
                "http://arxiv.org/pdf/2310.15051v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "cs.AI",
                "cs.LG",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15047v2",
            "title": "Meta- (out-of-context) learning in neural networks",
            "updated": "2023-10-24T14:22:28Z",
            "published": "2023-10-23T15:50:08Z",
            "summary": "Brown et al. (2020) famously introduced the phenomenon of in-context learning\nin large language models (LLMs). We establish the existence of a phenomenon we\ncall meta-out-of-context learning (meta-OCL) via carefully designed synthetic\nexperiments with LLMs. Our results suggest that meta-OCL leads LLMs to more\nreadily \"internalize\" the semantic content of text that is, or appears to be,\nbroadly useful (such as true statements, or text from authoritative sources)\nand use it in appropriate circumstances. We further demonstrate meta-OCL in a\nsynthetic computer vision setting, and propose two hypotheses for the emergence\nof meta-OCL: one relying on the way models store knowledge in their parameters,\nand another suggesting that the implicit gradient alignment bias of\ngradient-descent-based optimizers may be responsible. Finally, we reflect on\nwhat our results might imply about capabilities of future AI systems, and\ndiscuss potential risks. Our code can be found at\nhttps://github.com/krasheninnikov/internalization.",
            "author": [
                "Dmitrii Krasheninnikov",
                "Egor Krasheninnikov",
                "Bruno Mlodozeniec",
                "David Krueger"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15047v2",
                "http://arxiv.org/pdf/2310.15047v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15043v1",
            "title": "CalibrationPhys: Self-supervised Video-based Heart and Respiratory Rate\n  Measurements by Calibrating Between Multiple Cameras",
            "updated": "2023-10-23T15:46:39Z",
            "published": "2023-10-23T15:46:39Z",
            "summary": "Video-based heart and respiratory rate measurements using facial videos are\nmore useful and user-friendly than traditional contact-based sensors. However,\nmost of the current deep learning approaches require ground-truth pulse and\nrespiratory waves for model training, which are expensive to collect. In this\npaper, we propose CalibrationPhys, a self-supervised video-based heart and\nrespiratory rate measurement method that calibrates between multiple cameras.\nCalibrationPhys trains deep learning models without supervised labels by using\nfacial videos captured simultaneously by multiple cameras. Contrastive learning\nis performed so that the pulse and respiratory waves predicted from the\nsynchronized videos using multiple cameras are positive and those from\ndifferent videos are negative. CalibrationPhys also improves the robustness of\nthe models by means of a data augmentation technique and successfully leverages\na pre-trained model for a particular camera. Experimental results utilizing two\ndatasets demonstrate that CalibrationPhys outperforms state-of-the-art heart\nand respiratory rate measurement methods. Since we optimize camera-specific\nmodels using only videos from multiple cameras, our approach makes it easy to\nuse arbitrary cameras for heart and respiratory rate measurements.",
            "author": [
                "Yusuke Akamatsu",
                "Terumi Umematsu",
                "Hitoshi Imaoka"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15043v1",
                "http://arxiv.org/pdf/2310.15043v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19819v1",
            "title": "Machine Learning and Knowledge: Why Robustness Matters",
            "updated": "2023-10-23T15:45:27Z",
            "published": "2023-10-23T15:45:27Z",
            "summary": "Trusting machine learning algorithms requires having confidence in their\noutputs. Confidence is typically interpreted in terms of model reliability,\nwhere a model is reliable if it produces a high proportion of correct outputs.\nHowever, model reliability does not address concerns about the robustness of\nmachine learning models, such as models relying on the wrong features or\nvariations in performance based on context. I argue that the epistemic\ndimension of trust can instead be understood through the concept of knowledge,\nwhere the trustworthiness of an algorithm depends on whether its users are in\nthe position to know that its outputs are correct. Knowledge requires beliefs\nto be formed for the right reasons and to be robust to error, so machine\nlearning algorithms can only provide knowledge if they work well across\ncounterfactual scenarios and if they make decisions based on the right\nfeatures. This, I argue, can explain why we should care about model properties\nlike interpretability, causal shortcut independence, and distribution shift\nrobustness even if such properties are not required for model reliability.",
            "author": [
                "Jonathan Vandenburgh"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19819v1",
                "http://arxiv.org/pdf/2310.19819v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15041v1",
            "title": "Manipulation Mask Generator: High-Quality Image Manipulation Mask\n  Generation Method Based on Modified Total Variation Noise Reduction",
            "updated": "2023-10-23T15:40:00Z",
            "published": "2023-10-23T15:40:00Z",
            "summary": "In artificial intelligence, any model that wants to achieve a good result is\ninseparable from a large number of high-quality data. It is especially true in\nthe field of tamper detection. This paper proposes a modified total variation\nnoise reduction method to acquire high-quality tampered images. We\nautomatically crawl original and tampered images from the Baidu PS Bar. Baidu\nPS Bar is a website where net friends post countless tampered images.\nSubtracting the original image with the tampered image can highlight the\ntampered area. However, there is also substantial noise on the final print, so\nthese images can't be directly used in the deep learning model. Our modified\ntotal variation noise reduction method is aimed at solving this problem.\nBecause a lot of text is slender, it is easy to lose text information after the\nopening and closing operation. We use MSER (Maximally Stable Extremal Regions)\nand NMS (Non-maximum Suppression) technology to extract text information. And\nthen use the modified total variation noise reduction technology to process the\nsubtracted image. Finally, we can obtain an image with little noise by adding\nthe image and text information. And the idea also largely retains the text\ninformation. Datasets generated in this way can be used in deep learning\nmodels, and they will help the model achieve better results.",
            "author": [
                "Xinyu Yang",
                "Jizhe Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15041v1",
                "http://arxiv.org/pdf/2310.15041v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15037v1",
            "title": "Engineered dissipation to mitigate barren plateaus",
            "updated": "2023-10-23T15:36:00Z",
            "published": "2023-10-23T15:36:00Z",
            "summary": "Variational quantum algorithms represent a powerful approach for solving\noptimization problems on noisy quantum computers, with a broad spectrum of\npotential applications ranging from chemistry to machine learning. However,\ntheir performances in practical implementations crucially depend on the\neffectiveness of quantum circuit training, which can be severely limited by\nphenomena such as barren plateaus. While, in general, dissipation is\ndetrimental for quantum algorithms, and noise itself can actually induce barren\nplateaus, here we describe how the inclusion of properly engineered Markovian\nlosses after each unitary quantum circuit layer can restore the trainability of\nquantum models. We identify the required form of the dissipation processes and\nestablish that their optimization is efficient. We benchmark our proposal in\nboth a synthetic and a practical quantum chemistry example, demonstrating its\neffectiveness and potential impact across different domains.",
            "author": [
                "Antonio Sannia",
                "Francesco Tacchino",
                "Ivano Tavernelli",
                "Gian Luca Giorgi",
                "Roberta Zambrini"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15037v1",
                "http://arxiv.org/pdf/2310.15037v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15027v1",
            "title": "Deep Autoencoder-based Z-Interference Channels with Perfect and\n  Imperfect CSI",
            "updated": "2023-10-23T15:23:42Z",
            "published": "2023-10-23T15:23:42Z",
            "summary": "A deep autoencoder (DAE)-based structure for endto-end communication over the\ntwo-user Z-interference channel (ZIC) with finite-alphabet inputs is designed\nin this paper. The proposed structure jointly optimizes the two encoder/decoder\npairs and generates interference-aware constellations that dynamically adapt\ntheir shape based on interference intensity to minimize the bit error rate\n(BER). An in-phase/quadrature-phase (I/Q) power allocation layer is introduced\nin the DAE to guarantee an average power constraint and enable the architecture\nto generate constellations with nonuniform shapes. This brings further gain\ncompared to standard uniform constellations such as quadrature amplitude\nmodulation. The proposed structure is then extended to work with imperfect\nchannel state information (CSI). The CSI imperfection due to both the\nestimation and quantization errors are examined. The performance of the DAEZIC\nis compared with two baseline methods, i.e., standard and rotated\nconstellations. The proposed structure significantly enhances the performance\nof the ZIC both for the perfect and imperfect CSI. Simulation results show that\nthe improvement is achieved in all interference regimes (weak, moderate, and\nstrong) and consistently increases with the signal-to-noise ratio (SNR). For\nexample, more than an order of magnitude BER reduction is obtained with respect\nto the most competitive conventional method at weak interference when SNR>15dB\nand two bits per symbol are transmitted. The improvements reach about two\norders of magnitude when quantization error exists, indicating that the DAE-ZIC\nis more robust to the interference compared to the conventional methods.",
            "author": [
                "Xinliang Zhang",
                "Mojtaba Vaezi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15027v1",
                "http://arxiv.org/pdf/2310.15027v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "cs.AI",
                "cs.LG",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15026v1",
            "title": "Fast 2D Bicephalous Convolutional Autoencoder for Compressing 3D Time\n  Projection Chamber Data",
            "updated": "2023-10-23T15:23:32Z",
            "published": "2023-10-23T15:23:32Z",
            "summary": "High-energy large-scale particle colliders produce data at high speed in the\norder of 1 terabytes per second in nuclear physics and petabytes per second in\nhigh-energy physics. Developing real-time data compression algorithms to reduce\nsuch data at high throughput to fit permanent storage has drawn increasing\nattention. Specifically, at the newly constructed sPHENIX experiment at the\nRelativistic Heavy Ion Collider (RHIC), a time projection chamber is used as\nthe main tracking detector, which records particle trajectories in a volume of\na three-dimensional (3D) cylinder. The resulting data are usually very sparse\nwith occupancy around 10.8%. Such sparsity presents a challenge to conventional\nlearning-free lossy compression algorithms, such as SZ, ZFP, and MGARD. The 3D\nconvolutional neural network (CNN)-based approach, Bicephalous Convolutional\nAutoencoder (BCAE), outperforms traditional methods both in compression rate\nand reconstruction accuracy. BCAE can also utilize the computation power of\ngraphical processing units suitable for deployment in a modern heterogeneous\nhigh-performance computing environment. This work introduces two BCAE variants:\nBCAE++ and BCAE-2D. BCAE++ achieves a 15% better compression ratio and a 77%\nbetter reconstruction accuracy measured in mean absolute error compared with\nBCAE. BCAE-2D treats the radial direction as the channel dimension of an image,\nresulting in a 3x speedup in compression throughput. In addition, we\ndemonstrate an unbalanced autoencoder with a larger decoder can improve\nreconstruction accuracy without significantly sacrificing throughput. Lastly,\nwe observe both the BCAE++ and BCAE-2D can benefit more from using\nhalf-precision mode in throughput (76-79% increase) without loss in\nreconstruction accuracy. The source code and links to data and pretrained\nmodels can be found at https://github.com/BNL-DAQ-LDRD/NeuralCompression_v2.",
            "author": [
                "Yi Huang",
                "Yihui Ren",
                "Shinjae Yoo",
                "Jin Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15026v1",
                "http://arxiv.org/pdf/2310.15026v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "hep-ex",
                "nucl-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15024v1",
            "title": "From Proprietary to High-Level Trigger-Action Programming Rules: A\n  Natural Language Processing Approach",
            "updated": "2023-10-23T15:23:25Z",
            "published": "2023-10-23T15:23:25Z",
            "summary": "With the rise of popular task automation or IoT platforms such as 'If This\nThen That (IFTTT)', users can define rules to enable interactions between smart\ndevices in their environment and thereby improve their daily lives. However,\nthe rules authored via these platforms are usually tied to the platforms and\nsometimes even to the specific devices for which they have been defined.\nTherefore, when a user wishes to move to a different environment controlled by\na different platform and/or devices, they need to recreate their rules for the\nnew environment. The rise in the number of smart devices further adds to the\ncomplexity of rule authoring since users will have to navigate an ever-changing\nlandscape of IoT devices. In order to address this problem, we need\nhuman-computer interaction that works across the boundaries of specific IoT\nplatforms and devices. A step towards this human-computer interaction across\nplatforms and devices is the introduction of a high-level semantic model for\nend-user IoT development, enabling users to create rules at a higher level of\nabstraction. However, many users who already got used to the rule\nrepresentation in their favourite tool might be unwilling to learn and adapt to\na new representation. We present a method for translating proprietary rules to\na high-level semantic model by using natural language processing techniques.\nOur translation enables users to work with their familiar rule representation\nlanguage and tool, and at the same time apply their rules across different IoT\nplatforms and devices.",
            "author": [
                "Ekene Attoh",
                "Beat Signer"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15024v1",
                "http://arxiv.org/pdf/2310.15024v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "H.5.m"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15023v1",
            "title": "SONIC: Sonar Image Correspondence using Pose Supervised Learning for\n  Imaging Sonars",
            "updated": "2023-10-23T15:21:46Z",
            "published": "2023-10-23T15:21:46Z",
            "summary": "In this paper, we address the challenging problem of data association for\nunderwater SLAM through a novel method for sonar image correspondence using\nlearned features. We introduce SONIC (SONar Image Correspondence), a\npose-supervised network designed to yield robust feature correspondence capable\nof withstanding viewpoint variations. The inherent complexity of the underwater\nenvironment stems from the dynamic and frequently limited visibility\nconditions, restricting vision to a few meters of often featureless expanses.\nThis makes camera-based systems suboptimal in most open water application\nscenarios. Consequently, multibeam imaging sonars emerge as the preferred\nchoice for perception sensors. However, they too are not without their\nlimitations. While imaging sonars offer superior long-range visibility compared\nto cameras, their measurements can appear different from varying viewpoints.\nThis inherent variability presents formidable challenges in data association,\nparticularly for feature-based methods. Our method demonstrates significantly\nbetter performance in generating correspondences for sonar images which will\npave the way for more accurate loop closure constraints and sonar-based place\nrecognition. Code as well as simulated and real-world datasets will be made\npublic to facilitate further development in the field.",
            "author": [
                "Samiran Gode",
                "Akshay Hinduja",
                "Michael Kaess"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15023v1",
                "http://arxiv.org/pdf/2310.15023v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15021v1",
            "title": "Efficient Data Learning for Open Information Extraction with Pre-trained\n  Language Models",
            "updated": "2023-10-23T15:19:24Z",
            "published": "2023-10-23T15:19:24Z",
            "summary": "Open Information Extraction (OpenIE) is a fundamental yet challenging task in\nNatural Language Processing, which involves extracting all triples (subject,\npredicate, object) from a given sentence. While labeling-based methods have\ntheir merits, generation-based techniques offer unique advantages, such as the\nability to generate tokens not present in the original sentence. However, these\ngeneration-based methods often require a significant amount of training data to\nlearn the task form of OpenIE and substantial training time to overcome slow\nmodel convergence due to the order penalty. In this paper, we introduce a novel\nframework, OK-IE, that ingeniously transforms the task form of OpenIE into the\npre-training task form of the T5 model, thereby reducing the need for extensive\ntraining data. Furthermore, we introduce an innovative concept of Anchor to\ncontrol the sequence of model outputs, effectively eliminating the impact of\norder penalty on model convergence and significantly reducing training time.\nExperimental results indicate that, compared to previous SOTA methods, OK-IE\nrequires only 1/100 of the training data (900 instances) and 1/120 of the\ntraining time (3 minutes) to achieve comparable results.",
            "author": [
                "Zhiyuan Fan",
                "Shizhu He"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15021v1",
                "http://arxiv.org/pdf/2310.15021v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15020v2",
            "title": "Invariance is Key to Generalization: Examining the Role of\n  Representation in Sim-to-Real Transfer for Visual Navigation",
            "updated": "2023-12-04T03:48:06Z",
            "published": "2023-10-23T15:15:19Z",
            "summary": "The data-driven approach to robot control has been gathering pace rapidly,\nyet generalization to unseen task domains remains a critical challenge. We\nargue that the key to generalization is representations that are (i) rich\nenough to capture all task-relevant information and (ii) invariant to\nsuperfluous variability between the training and the test domains. We\nexperimentally study such a representation -- containing both depth and\nsemantic information -- for visual navigation and show that it enables a\ncontrol policy trained entirely in simulated indoor scenes to generalize to\ndiverse real-world environments, both indoors and outdoors. Further, we show\nthat our representation reduces the A-distance between the training and test\ndomains, improving the generalization error bound as a result. Our proposed\napproach is scalable: the learned policy improves continuously, as the\nfoundation models that it exploits absorb more diverse data during\npre-training.",
            "author": [
                "Bo Ai",
                "Zhanxin Wu",
                "David Hsu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15020v2",
                "http://arxiv.org/pdf/2310.15020v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.CV",
                "cs.LG",
                "I.2.9; I.2.6; I.2.10"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15019v2",
            "title": "Meta learning with language models: Challenges and opportunities in the\n  classification of imbalanced text",
            "updated": "2023-10-24T15:15:38Z",
            "published": "2023-10-23T15:14:55Z",
            "summary": "Detecting out of policy speech (OOPS) content is important but difficult.\nWhile machine learning is a powerful tool to tackle this challenging task, it\nis hard to break the performance ceiling due to factors like quantity and\nquality limitations on training data and inconsistencies in OOPS definition and\ndata labeling. To realize the full potential of available limited resources, we\npropose a meta learning technique (MLT) that combines individual models built\nwith different text representations. We analytically show that the resulting\ntechnique is numerically stable and produces reasonable combining weights. We\ncombine the MLT with a threshold-moving (TM) technique to further improve the\nperformance of the combined predictor on highly-imbalanced in-distribution and\nout-of-distribution datasets. We also provide computational results to show the\nstatistically significant advantages of the proposed MLT approach.\n  All authors contributed equally to this work.",
            "author": [
                "Apostol Vassilev",
                "Honglan Jin",
                "Munawar Hasan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15019v2",
                "http://arxiv.org/pdf/2310.15019v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15017v1",
            "title": "The primacy bias in Model-based RL",
            "updated": "2023-10-23T15:12:20Z",
            "published": "2023-10-23T15:12:20Z",
            "summary": "The primacy bias in deep reinforcement learning (DRL), which refers to the\nagent's tendency to overfit early data and lose the ability to learn from new\ndata, can significantly decrease the performance of DRL algorithms. Previous\nstudies have shown that employing simple techniques, such as resetting the\nagent's parameters, can substantially alleviate the primacy bias. However, we\nobserve that resetting the agent's parameters harms its performance in the\ncontext of model-based reinforcement learning (MBRL). In fact, on further\ninvestigation, we find that the primacy bias in MBRL differs from that in\nmodel-free RL. In this work, we focus on investigating the primacy bias in MBRL\nand propose world model resetting, which works in MBRL. We apply our method to\ntwo different MBRL algorithms, MBPO and DreamerV2. We validate the\neffectiveness of our method on multiple continuous control tasks on MuJoCo and\nDeepMind Control Suite, as well as discrete control tasks on Atari 100k\nbenchmark. The results show that world model resetting can significantly\nalleviate the primacy bias in model-based setting and improve algorithm's\nperformance. We also give a guide on how to perform world model resetting\neffectively.",
            "author": [
                "Zhongjian Qiao",
                "Jiafei Lyu",
                "Xiu Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15017v1",
                "http://arxiv.org/pdf/2310.15017v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15015v4",
            "title": "Leveraging Deep Learning for Abstractive Code Summarization of\n  Unofficial Documentation",
            "updated": "2023-12-03T20:11:11Z",
            "published": "2023-10-23T15:10:37Z",
            "summary": "Usually, programming languages have official documentation to guide\ndevelopers with APIs, methods, and classes. However, researchers identified\ninsufficient or inadequate documentation examples and flaws with the API's\ncomplex structure as barriers to learning an API. As a result, developers may\nconsult other sources (StackOverflow, GitHub, etc.) to learn more about an API.\nRecent research studies have shown that unofficial documentation is a valuable\nsource of information for generating code summaries. We, therefore, have been\nmotivated to leverage such a type of documentation along with deep learning\ntechniques towards generating high-quality summaries for APIs discussed in\ninformal documentation. This paper proposes an automatic approach using the\nBART algorithm, a state-of-the-art transformer model, to generate summaries for\nAPIs discussed in StackOverflow. We built an oracle of human-generated\nsummaries to evaluate our approach against it using ROUGE and BLEU metrics\nwhich are the most widely used evaluation metrics in text summarization.\nFurthermore, we evaluated our summaries empirically against a previous work in\nterms of quality. Our findings demonstrate that using deep learning algorithms\ncan improve summaries' quality and outperform the previous work by an average\nof %57 for Precision, %66 for Recall, and %61 for F-measure, and it runs 4.4\ntimes faster.",
            "author": [
                "AmirHossein Naghshzan",
                "Latifa Guerrouj",
                "Olga Baysal"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15015v4",
                "http://arxiv.org/pdf/2310.15015v4"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15012v1",
            "title": "Elemantra: An End-to-End Automated Framework Empowered with AI and IoT\n  for Tackling Human-Elephant Conflict in Elephant-Range Countries",
            "updated": "2023-10-23T15:07:37Z",
            "published": "2023-10-23T15:07:37Z",
            "summary": "The cohabitation of elephants and humans has evolved into a human-elephant\nconflict (HEC) due to the increasing loss of historical elephant habitations.\nSince HEC is a substantial threat to both species, advanced sensing methods are\nutilized to develop HEC prevention frameworks which still lack unification.\nHere, we propose an end-to-end automated framework for HEC prevention\nconsisting of three main modules: a distributed deep learning-assisted elephant\ndetection module using infrared and seismic sensing, an on-site repelling\nsystem with time-varying acoustic and light deterrents and a mesh network for\ndevice communication. The framework is equipped with novel decision-making\npipelines and algorithms such that it has the potential to operate with no\nhuman intervention. The preliminary results from each module confirm that the\nproposed framework is effective in performing their individual tasks towards\ncollaboratively achieving the prevention of HEC. The codes are publicly\navailable at https://github.com/nuwansribandara/elemantra.",
            "author": [
                "Nuwan Sriyantha Bandara",
                "Dilshan Pramudith Bandara"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15012v1",
                "http://arxiv.org/pdf/2310.15012v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15011v1",
            "title": "Interference Management by Harnessing Multi-Domain Resources in\n  Spectrum-Sharing Aided Satellite-Ground Integrated Networks",
            "updated": "2023-10-23T15:02:57Z",
            "published": "2023-10-23T15:02:57Z",
            "summary": "A spectrum-sharing satellite-ground integrated network is conceived,\nconsisting of a pair of non-geostationary orbit (NGSO) constellations and\nmultiple terrestrial base stations, which impose the co-frequency interference\n(CFI) on each other. The CFI may increase upon increasing the number of\nsatellites. To manage the potentially severe interference, we propose to rely\non joint multi-domain resource aided interference management (JMDR-IM).\nSpecifically, the coverage overlap of the constellations considered is\nanalyzed. Then, multi-domain resources - including both the beam-domain and\npower-domain - are jointly utilized for managing the CFI in an overlapping\ncoverage region. This joint resource utilization is performed by relying on our\nspecifically designed beam-shut-off and switching based beam scheduling, as\nwell as on long short-term memory based joint autoregressive moving average\nassisted deep Q network aided power scheduling. Moreover, the outage\nprobability (OP) of the proposed JMDR-IM scheme is derived, and the asymptotic\nanalysis of the OP is also provided. Our performance evaluations demonstrate\nthe superiority of the proposed JMDR-IM scheme in terms of its increased\nthroughput and reduced OP.",
            "author": [
                "Xiaojin Ding",
                "Yue Lei",
                "Yulong Zou",
                "Gengxin Zhang",
                "Lajos Hanzo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15011v1",
                "http://arxiv.org/pdf/2310.15011v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15010v1",
            "title": "Statistical Depth for Ranking and Characterizing Transformer-Based Text\n  Embeddings",
            "updated": "2023-10-23T15:02:44Z",
            "published": "2023-10-23T15:02:44Z",
            "summary": "The popularity of transformer-based text embeddings calls for better\nstatistical tools for measuring distributions of such embeddings. One such tool\nwould be a method for ranking texts within a corpus by centrality, i.e.\nassigning each text a number signifying how representative that text is of the\ncorpus as a whole. However, an intrinsic center-outward ordering of\nhigh-dimensional text representations is not trivial. A statistical depth is a\nfunction for ranking k-dimensional objects by measuring centrality with respect\nto some observed k-dimensional distribution. We adopt a statistical depth to\nmeasure distributions of transformer-based text embeddings, transformer-based\ntext embedding (TTE) depth, and introduce the practical use of this depth for\nboth modeling and distributional inference in NLP pipelines. We first define\nTTE depth and an associated rank sum test for determining whether two corpora\ndiffer significantly in embedding space. We then use TTE depth for the task of\nin-context learning prompt selection, showing that this approach reliably\nimproves performance over statistical baseline approaches across six text\nclassification tasks. Finally, we use TTE depth and the associated rank sum\ntest to characterize the distributions of synthesized and human-generated\ncorpora, showing that five recent synthetic data augmentation processes cause a\nmeasurable distributional shift away from associated human-generated text.",
            "author": [
                "Parker Seegmiller",
                "Sarah Masud Preum"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15010v1",
                "http://arxiv.org/pdf/2310.15010v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15007v1",
            "title": "Did the Neurons Read your Book? Document-level Membership Inference for\n  Large Language Models",
            "updated": "2023-10-23T15:00:46Z",
            "published": "2023-10-23T15:00:46Z",
            "summary": "With large language models (LLMs) poised to become embedded in our daily\nlives, questions are starting to be raised about the dataset(s) they learned\nfrom. These questions range from potential bias or misinformation LLMs could\nretain from their training data to questions of copyright and fair use of\nhuman-generated text. However, while these questions emerge, developers of the\nrecent state-of-the-art LLMs become increasingly reluctant to disclose details\non their training corpus. We here introduce the task of document-level\nmembership inference for real-world LLMs, i.e. inferring whether the LLM has\nseen a given document during training or not. First, we propose a procedure for\nthe development and evaluation of document-level membership inference for LLMs\nby leveraging commonly used data sources for training and the model release\ndate. We then propose a practical, black-box method to predict document-level\nmembership and instantiate it on OpenLLaMA-7B with both books and academic\npapers. We show our methodology to perform very well, reaching an impressive\nAUC of 0.856 for books and 0.678 for papers. We then show our approach to\noutperform the sentence-level membership inference attacks used in the privacy\nliterature for the document-level membership task. We finally evaluate whether\nsmaller models might be less sensitive to document-level inference and show\nOpenLLaMA-3B to be approximately as sensitive as OpenLLaMA-7B to our approach.\nTaken together, our results show that accurate document-level membership can be\ninferred for LLMs, increasing the transparency of technology poised to change\nour lives.",
            "author": [
                "Matthieu Meeus",
                "Shubham Jain",
                "Marek Rei",
                "Yves-Alexandre de Montjoye"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15007v1",
                "http://arxiv.org/pdf/2310.15007v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15004v1",
            "title": "When Language Models Fall in Love: Animacy Processing in Transformer\n  Language Models",
            "updated": "2023-10-23T14:57:52Z",
            "published": "2023-10-23T14:57:52Z",
            "summary": "Animacy - whether an entity is alive and sentient - is fundamental to\ncognitive processing, impacting areas such as memory, vision, and language.\nHowever, animacy is not always expressed directly in language: in English it\noften manifests indirectly, in the form of selectional constraints on verbs and\nadjectives. This poses a potential issue for transformer language models (LMs):\nthey often train only on text, and thus lack access to extralinguistic\ninformation from which humans learn about animacy. We ask: how does this impact\nLMs' animacy processing - do they still behave as humans do? We answer this\nquestion using open-source LMs. Like previous studies, we find that LMs behave\nmuch like humans when presented with entities whose animacy is typical.\nHowever, we also show that even when presented with stories about atypically\nanimate entities, such as a peanut in love, LMs adapt: they treat these\nentities as animate, though they do not adapt as well as humans. Even when the\ncontext indicating atypical animacy is very short, LMs pick up on subtle clues\nand change their behavior. We conclude that despite the limited signal through\nwhich LMs can learn about animacy, they are indeed sensitive to the relevant\nlexical semantic nuances available in English.",
            "author": [
                "Michael Hanna",
                "Yonatan Belinkov",
                "Sandro Pezzelle"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15004v1",
                "http://arxiv.org/pdf/2310.15004v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15003v1",
            "title": "Neural Snowflakes: Universal Latent Graph Inference via Trainable Latent\n  Geometries",
            "updated": "2023-10-23T14:57:26Z",
            "published": "2023-10-23T14:57:26Z",
            "summary": "The inductive bias of a graph neural network (GNN) is largely encoded in its\nspecified graph. Latent graph inference relies on latent geometric\nrepresentations to dynamically rewire or infer a GNN's graph to maximize the\nGNN's predictive downstream performance, but it lacks solid theoretical\nfoundations in terms of embedding-based representation guarantees. This paper\naddresses this issue by introducing a trainable deep learning architecture,\ncoined neural snowflake, that can adaptively implement fractal-like metrics on\n$\\mathbb{R}^d$. We prove that any given finite weights graph can be\nisometrically embedded by a standard MLP encoder. Furthermore, when the latent\ngraph can be represented in the feature space of a sufficiently regular kernel,\nwe show that the combined neural snowflake and MLP encoder do not succumb to\nthe curse of dimensionality by using only a low-degree polynomial number of\nparameters in the number of nodes. This implementation enables a\nlow-dimensional isometric embedding of the latent graph. We conduct synthetic\nexperiments to demonstrate the superior metric learning capabilities of neural\nsnowflakes when compared to more familiar spaces like Euclidean space.\nAdditionally, we carry out latent graph inference experiments on graph\nbenchmarks. Consistently, the neural snowflake model achieves predictive\nperformance that either matches or surpasses that of the state-of-the-art\nlatent graph inference models. Importantly, this performance improvement is\nachieved without requiring random search for optimal latent geometry. Instead,\nthe neural snowflake model achieves this enhancement in a differentiable\nmanner.",
            "author": [
                "Haitz S\u00e1ez de Oc\u00e1riz Borde",
                "Anastasis Kratsios"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15003v1",
                "http://arxiv.org/pdf/2310.15003v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DM",
                "cs.NE",
                "math.MG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14997v1",
            "title": "Simple Hardware-Efficient PCFGs with Independent Left and Right\n  Productions",
            "updated": "2023-10-23T14:48:51Z",
            "published": "2023-10-23T14:48:51Z",
            "summary": "Scaling dense PCFGs to thousands of nonterminals via a low-rank\nparameterization of the rule probability tensor has been shown to be beneficial\nfor unsupervised parsing. However, PCFGs scaled this way still perform poorly\nas a language model, and even underperform similarly-sized HMMs. This work\nintroduces \\emph{SimplePCFG}, a simple PCFG formalism with independent left and\nright productions. Despite imposing a stronger independence assumption than the\nlow-rank approach, we find that this formalism scales more effectively both as\na language model and as an unsupervised parser. As an unsupervised parser, our\nsimple PCFG obtains an average F1 of 65.1 on the English PTB, and as a language\nmodel, it obtains a perplexity of 119.0, outperforming similarly-sized low-rank\nPCFGs. We further introduce \\emph{FlashInside}, a hardware IO-aware\nimplementation of the inside algorithm for efficiently scaling simple PCFGs.",
            "author": [
                "Wei Liu",
                "Songlin Yang",
                "Yoon Kim",
                "Kewei Tu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14997v1",
                "http://arxiv.org/pdf/2310.14997v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14993v1",
            "title": "Understanding the Inner Workings of Language Models Through\n  Representation Dissimilarity",
            "updated": "2023-10-23T14:46:20Z",
            "published": "2023-10-23T14:46:20Z",
            "summary": "As language models are applied to an increasing number of real-world\napplications, understanding their inner workings has become an important issue\nin model trust, interpretability, and transparency. In this work we show that\nrepresentation dissimilarity measures, which are functions that measure the\nextent to which two model's internal representations differ, can be a valuable\ntool for gaining insight into the mechanics of language models. Among our\ninsights are: (i) an apparent asymmetry in the internal representations of\nmodel using SoLU and GeLU activation functions, (ii) evidence that\ndissimilarity measures can identify and locate generalization properties of\nmodels that are invisible via in-distribution test set performance, and (iii)\nnew evaluations of how language model features vary as width and depth are\nincreased. Our results suggest that dissimilarity measures are a promising set\nof tools for shedding light on the inner workings of language models.",
            "author": [
                "Davis Brown",
                "Charles Godfrey",
                "Nicholas Konz",
                "Jonathan Tu",
                "Henry Kvinge"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14993v1",
                "http://arxiv.org/pdf/2310.14993v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14992v1",
            "title": "Bayesian Regression Markets",
            "updated": "2023-10-23T14:45:51Z",
            "published": "2023-10-23T14:45:51Z",
            "summary": "Machine learning tasks are vulnerable to the quality of data used as input.\nYet, it is often challenging for firms to obtain adequate datasets, with them\nbeing naturally distributed amongst owners, that in practice, may be\ncompetitors in a downstream market and reluctant to share information. Focusing\non supervised learning for regression tasks, we develop a \\textit{regression\nmarket} to provide a monetary incentive for data sharing. Our proposed\nmechanism adopts a Bayesian framework, allowing us to consider a more general\nclass of regression tasks. We present a thorough exploration of the market\nproperties, and show that similar proposals in current literature expose the\nmarket agents to sizeable financial risks, which can be mitigated in our\nprobabilistic setting.",
            "author": [
                "Thomas Falconer",
                "Jalal Kazempour",
                "Pierre Pinson"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14992v1",
                "http://arxiv.org/pdf/2310.14992v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15209v1",
            "title": "DeepOrientation: convolutional neural network for fringe pattern\n  orientation map estimation",
            "updated": "2023-10-23T14:36:03Z",
            "published": "2023-10-23T14:36:03Z",
            "summary": "Fringe pattern based measurement techniques are the state-of-the-art in\nfull-field optical metrology. They are crucial both in macroscale, e.g., fringe\nprojection profilometry, and microscale, e.g., label-free quantitative phase\nmicroscopy. Accurate estimation of the local fringe orientation map can\nsignificantly facilitate the measurement process on various ways, e.g., fringe\nfiltering (denoising), fringe pattern boundary padding, fringe skeletoning\n(contouring/following/tracking), local fringe spatial frequency (fringe period)\nestimation and fringe pattern phase demodulation. Considering all of that the\naccurate, robust and preferably automatic estimation of local fringe\norientation map is of high importance. In this paper we propose novel numerical\nsolution for local fringe orientation map estimation based on convolutional\nneural network and deep learning called DeepOrientation. Numerical simulations\nand experimental results corroborate the effectiveness of the proposed\nDeepOrientation comparing it with the representative of the classical approach\nto orientation estimation called combined plane fitting/gradient method. The\nexample proving the effectiveness of DeepOrientation in fringe pattern\nanalysis, which we present in this paper is the application of DeepOrientation\nfor guiding the phase demodulation process in Hilbert spiral transform. In\nparticular, living HeLa cells quantitative phase imaging outcomes verify the\nmethod as an important asset in label-free microscopy.",
            "author": [
                "Maria Cywinska",
                "Mikolaj Rogalski",
                "Filip Brzeski",
                "Krzysztof Patorski",
                "Maciej Trusiak"
            ],
            "link": [
                "http://dx.doi.org/10.1364/OE.465094",
                "http://arxiv.org/abs/2310.15209v1",
                "http://arxiv.org/pdf/2310.15209v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "physics.optics"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14982v1",
            "title": "Delayed Memory Unit: Modelling Temporal Dependency Through Delay Gate",
            "updated": "2023-10-23T14:29:48Z",
            "published": "2023-10-23T14:29:48Z",
            "summary": "Recurrent Neural Networks (RNNs) are renowned for their adeptness in modeling\ntemporal dependencies, a trait that has driven their widespread adoption for\nsequential data processing. Nevertheless, vanilla RNNs are confronted with the\nwell-known issue of gradient vanishing and exploding, posing a significant\nchallenge for learning and establishing long-range dependencies. Additionally,\ngated RNNs tend to be over-parameterized, resulting in poor network\ngeneralization. To address these challenges, we propose a novel Delayed Memory\nUnit (DMU) in this paper, wherein a delay line structure, coupled with delay\ngates, is introduced to facilitate temporal interaction and temporal credit\nassignment, so as to enhance the temporal modeling capabilities of vanilla\nRNNs. Particularly, the DMU is designed to directly distribute the input\ninformation to the optimal time instant in the future, rather than aggregating\nand redistributing it over time through intricate network dynamics. Our\nproposed DMU demonstrates superior temporal modeling capabilities across a\nbroad range of sequential modeling tasks, utilizing considerably fewer\nparameters than other state-of-the-art gated RNN models in applications such as\nspeech recognition, radar gesture recognition, ECG waveform segmentation, and\npermuted sequential image classification.",
            "author": [
                "Pengfei Sun",
                "Jibin Wu",
                "Malu Zhang",
                "Paul Devos",
                "Dick Botteldooren"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14982v1",
                "http://arxiv.org/pdf/2310.14982v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE",
                "cs.LG",
                "eess.AS",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14979v1",
            "title": "ACTOR: Active Learning with Annotator-specific Classification Heads to\n  Embrace Human Label Variation",
            "updated": "2023-10-23T14:26:43Z",
            "published": "2023-10-23T14:26:43Z",
            "summary": "Label aggregation such as majority voting is commonly used to resolve\nannotator disagreement in dataset creation. However, this may disregard\nminority values and opinions. Recent studies indicate that learning from\nindividual annotations outperforms learning from aggregated labels, though they\nrequire a considerable amount of annotation. Active learning, as an annotation\ncost-saving strategy, has not been fully explored in the context of learning\nfrom disagreement. We show that in the active learning setting, a multi-head\nmodel performs significantly better than a single-head model in terms of\nuncertainty estimation. By designing and evaluating acquisition functions with\nannotator-specific heads on two datasets, we show that group-level entropy\nworks generally well on both datasets. Importantly, it achieves performance in\nterms of both prediction and uncertainty estimation comparable to full-scale\ntraining from disagreement, while saving up to 70% of the annotation budget.",
            "author": [
                "Xinpeng Wang",
                "Barbara Plank"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14979v1",
                "http://arxiv.org/pdf/2310.14979v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14976v1",
            "title": "Reinforcement learning in large, structured action spaces: A simulation\n  study of decision support for spinal cord injury rehabilitation",
            "updated": "2023-10-23T14:25:55Z",
            "published": "2023-10-23T14:25:55Z",
            "summary": "Reinforcement learning (RL) has helped improve decision-making in several\napplications. However, applying traditional RL is challenging in some\napplications, such as rehabilitation of people with a spinal cord injury (SCI).\nAmong other factors, using RL in this domain is difficult because there are\nmany possible treatments (i.e., large action space) and few patients (i.e.,\nlimited training data). Treatments for SCIs have natural groupings, so we\npropose two approaches to grouping treatments so that an RL agent can learn\neffectively from limited data. One relies on domain knowledge of SCI\nrehabilitation and the other learns similarities among treatments using an\nembedding technique. We then use Fitted Q Iteration to train an agent that\nlearns optimal treatments. Through a simulation study designed to reflect the\nproperties of SCI rehabilitation, we find that both methods can help improve\nthe treatment decisions of physiotherapists, but the approach based on domain\nknowledge offers better performance. Our findings provide a \"proof of concept\"\nthat RL can be used to help improve the treatment of those with an SCI and\nindicates that continued efforts to gather data and apply RL to this domain are\nworthwhile.",
            "author": [
                "Nathan Phelps",
                "Stephanie Marrocco",
                "Stephanie Cornell",
                "Dalton L. Wolfe",
                "Daniel J. Lizotte"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14976v1",
                "http://arxiv.org/pdf/2310.14976v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14968v1",
            "title": "The Fundamental Dilemma of Bayesian Active Meta-learning",
            "updated": "2023-10-23T14:13:27Z",
            "published": "2023-10-23T14:13:27Z",
            "summary": "Many applications involve estimation of parameters that generalize across\nmultiple diverse, but related, data-scarce task environments. Bayesian active\nmeta-learning, a form of sequential optimal experimental design, provides a\nframework for solving such problems. The active meta-learner's goal is to gain\ntransferable knowledge (estimate the transferable parameters) in the presence\nof idiosyncratic characteristics of the current task (task-specific\nparameters). We show that in such a setting, greedy pursuit of this goal can\nactually hurt estimation of the transferable parameters (induce so-called\nnegative transfer). The learner faces a dilemma akin to but distinct from the\nexploration--exploitation dilemma: should they spend their acquisition budget\npursuing transferable knowledge, or identifying the current task-specific\nparameters? We show theoretically that some tasks pose an inevitable and\narbitrarily large threat of negative transfer, and that task identification is\ncritical to reducing this threat. Our results generalize to analysis of prior\nmisspecification over nuisance parameters. Finally, we empirically illustrate\ncircumstances that lead to negative transfer.",
            "author": [
                "Sabina J. Sloman",
                "Ayush Bharti",
                "Samuel Kaski"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14968v1",
                "http://arxiv.org/pdf/2310.14968v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14963v1",
            "title": "Adam through a Second-Order Lens",
            "updated": "2023-10-23T14:06:46Z",
            "published": "2023-10-23T14:06:46Z",
            "summary": "Research into optimisation for deep learning is characterised by a tension\nbetween the computational efficiency of first-order, gradient-based methods\n(such as SGD and Adam) and the theoretical efficiency of second-order,\ncurvature-based methods (such as quasi-Newton methods and K-FAC). We seek to\ncombine the benefits of both approaches into a single computationally-efficient\nalgorithm. Noting that second-order methods often depend on stabilising\nheuristics (such as Levenberg-Marquardt damping), we propose AdamQLR: an\noptimiser combining damping and learning rate selection techniques from K-FAC\n(Martens and Grosse, 2015) with the update directions proposed by Adam,\ninspired by considering Adam through a second-order lens. We evaluate AdamQLR\non a range of regression and classification tasks at various scales, achieving\ncompetitive generalisation performance vs runtime.",
            "author": [
                "Ross M. Clarke",
                "Baiyu Su",
                "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14963v1",
                "http://arxiv.org/pdf/2310.14963v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14961v1",
            "title": "StenUNet: Automatic Stenosis Detection from X-ray Coronary Angiography",
            "updated": "2023-10-23T14:04:18Z",
            "published": "2023-10-23T14:04:18Z",
            "summary": "Coronary angiography continues to serve as the primary method for diagnosing\ncoronary artery disease (CAD), which is the leading global cause of mortality.\nThe severity of CAD is quantified by the location, degree of narrowing\n(stenosis), and number of arteries involved. In current practice, this\nquantification is performed manually using visual inspection and thus suffers\nfrom poor inter- and intra-rater reliability. The MICCAI grand challenge:\nAutomatic Region-based Coronary Artery Disease diagnostics using the X-ray\nangiography imagEs (ARCADE) curated a dataset with stenosis annotations, with\nthe goal of creating an automated stenosis detection algorithm. Using a\ncombination of machine learning and other computer vision techniques, we\npropose the architecture and algorithm StenUNet to accurately detect stenosis\nfrom X-ray Coronary Angiography. Our submission to the ARCADE challenge placed\n3rd among all teams. We achieved an F1 score of 0.5348 on the test set, 0.0005\nlower than the 2nd place.",
            "author": [
                "Hui Lin",
                "Tom Liu",
                "Aggelos Katsaggelos",
                "Adrienne Kline"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14961v1",
                "http://arxiv.org/pdf/2310.14961v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14958v1",
            "title": "Learning Real-World Image De-Weathering with Imperfect Supervision",
            "updated": "2023-10-23T14:02:57Z",
            "published": "2023-10-23T14:02:57Z",
            "summary": "Real-world image de-weathering aims at removing various undesirable\nweather-related artifacts. Owing to the impossibility of capturing image pairs\nconcurrently, existing real-world de-weathering datasets often exhibit\ninconsistent illumination, position, and textures between the ground-truth\nimages and the input degraded images, resulting in imperfect supervision. Such\nnon-ideal supervision negatively affects the training process of learning-based\nde-weathering methods. In this work, we attempt to address the problem with a\nunified solution for various inconsistencies. Specifically, inspired by\ninformation bottleneck theory, we first develop a Consistent Label Constructor\n(CLC) to generate a pseudo-label as consistent as possible with the input\ndegraded image while removing most weather-related degradations. In particular,\nmultiple adjacent frames of the current input are also fed into CLC to enhance\nthe pseudo-label. Then we combine the original imperfect labels and\npseudo-labels to jointly supervise the de-weathering model by the proposed\nInformation Allocation Strategy (IAS). During testing, only the de-weathering\nmodel is used for inference. Experiments on two real-world de-weathering\ndatasets show that our method helps existing de-weathering models achieve\nbetter performance. Codes are available at\nhttps://github.com/1180300419/imperfect-deweathering.",
            "author": [
                "Xiaohui Liu",
                "Zhilu Zhang",
                "Xiaohe Wu",
                "Chaoyu Feng",
                "Xiaotao Wang",
                "LEI LEI",
                "Wangmeng Zuo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14958v1",
                "http://arxiv.org/pdf/2310.14958v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14957v1",
            "title": "XTSC-Bench: Quantitative Benchmarking for Explainers on Time Series\n  Classification",
            "updated": "2023-10-23T14:00:02Z",
            "published": "2023-10-23T14:00:02Z",
            "summary": "Despite the growing body of work on explainable machine learning in time\nseries classification (TSC), it remains unclear how to evaluate different\nexplainability methods. Resorting to qualitative assessment and user studies to\nevaluate explainers for TSC is difficult since humans have difficulties\nunderstanding the underlying information contained in time series data.\nTherefore, a systematic review and quantitative comparison of explanation\nmethods to confirm their correctness becomes crucial. While steps to\nstandardized evaluations were taken for tabular, image, and textual data,\nbenchmarking explainability methods on time series is challenging due to a)\ntraditional metrics not being directly applicable, b) implementation and\nadaption of traditional metrics for time series in the literature vary, and c)\nvarying baseline implementations. This paper proposes XTSC-Bench, a\nbenchmarking tool providing standardized datasets, models, and metrics for\nevaluating explanation methods on TSC. We analyze 3 perturbation-, 6 gradient-\nand 2 example-based explanation methods to TSC showing that improvements in the\nexplainers' robustness and reliability are necessary, especially for\nmultivariate data.",
            "author": [
                "Jacqueline H\u00f6llig",
                "Steffen Thoma",
                "Florian Grimm"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14957v1",
                "http://arxiv.org/pdf/2310.14957v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14940v1",
            "title": "Comparison of path following in ships using modern and traditional\n  controllers",
            "updated": "2023-10-23T13:37:51Z",
            "published": "2023-10-23T13:37:51Z",
            "summary": "Vessel navigation is difficult in restricted waterways and in the presence of\nstatic and dynamic obstacles. This difficulty can be attributed to the\nhigh-level decisions taken by humans during these maneuvers, which is evident\nfrom the fact that 85% of the reported marine accidents are traced back to\nhuman errors. Artificial intelligence-based methods offer us a way to eliminate\nhuman intervention in vessel navigation. Newer methods like Deep Reinforcement\nLearning (DRL) can optimize multiple objectives like path following and\ncollision avoidance at the same time while being computationally cheaper to\nimplement in comparison to traditional approaches. Before addressing the\nchallenge of collision avoidance along with path following, the performance of\nDRL-based controllers on the path following task alone must be established.\nTherefore, this study trains a DRL agent using Proximal Policy Optimization\n(PPO) algorithm and tests it against a traditional PD controller guided by an\nIntegral Line of Sight (ILOS) guidance system. The Krisco Container Ship (KCS)\nis chosen to test the different controllers. The ship dynamics are\nmathematically simulated using the Maneuvering Modelling Group (MMG) model\ndeveloped by the Japanese. The simulation environment is used to train the deep\nreinforcement learning-based controller and is also used to tune the gains of\nthe traditional PD controller. The effectiveness of the controllers in the\npresence of wind is also investigated.",
            "author": [
                "Sanjeev Kumar Ramkumar Sudha",
                "Md Shadab Alam",
                "Bindusara Reddy",
                "Abhilash Sharma Somayajula"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14940v1",
                "http://arxiv.org/pdf/2310.14940v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14938v1",
            "title": "AI on the Water: Applying DRL to Autonomous Vessel Navigation",
            "updated": "2023-10-23T13:36:31Z",
            "published": "2023-10-23T13:36:31Z",
            "summary": "Human decision-making errors cause a majority of globally reported marine\naccidents. As a result, automation in the marine industry has been gaining more\nattention in recent years. Obstacle avoidance becomes very challenging for an\nautonomous surface vehicle in an unknown environment. We explore the\nfeasibility of using Deep Q-Learning (DQN), a deep reinforcement learning\napproach, for controlling an underactuated autonomous surface vehicle to follow\na known path while avoiding collisions with static and dynamic obstacles. The\nship's motion is described using a three-degree-of-freedom (3-DOF) dynamic\nmodel. The KRISO container ship (KCS) is chosen for this study because it is a\nbenchmark hull used in several studies, and its hydrodynamic coefficients are\nreadily available for numerical modelling. This study shows that Deep\nReinforcement Learning (DRL) can achieve path following and collision avoidance\nsuccessfully and can be a potential candidate that may be investigated further\nto achieve human-level or even better decision-making for autonomous marine\nvehicles.",
            "author": [
                "Md Shadab Alam",
                "Sanjeev Kumar Ramkumar Sudha",
                "Abhilash Somayajula"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14938v1",
                "http://arxiv.org/pdf/2310.14938v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14935v1",
            "title": "Causal machine learning for single-cell genomics",
            "updated": "2023-10-23T13:35:24Z",
            "published": "2023-10-23T13:35:24Z",
            "summary": "Advances in single-cell omics allow for unprecedented insights into the\ntranscription profiles of individual cells. When combined with large-scale\nperturbation screens, through which specific biological mechanisms can be\ntargeted, these technologies allow for measuring the effect of targeted\nperturbations on the whole transcriptome. These advances provide an opportunity\nto better understand the causative role of genes in complex biological\nprocesses such as gene regulation, disease progression or cellular development.\nHowever, the high-dimensional nature of the data, coupled with the intricate\ncomplexity of biological systems renders this task nontrivial. Within the\nmachine learning community, there has been a recent increase of interest in\ncausality, with a focus on adapting established causal techniques and\nalgorithms to handle high-dimensional data. In this perspective, we delineate\nthe application of these methodologies within the realm of single-cell genomics\nand their challenges. We first present the model that underlies most of current\ncausal approaches to single-cell biology and discuss and challenge the\nassumptions it entails from the biological point of view. We then identify open\nproblems in the application of causal approaches to single-cell data:\ngeneralising to unseen environments, learning interpretable models, and\nlearning causal models of dynamics. For each problem, we discuss how various\nresearch directions - including the development of computational approaches and\nthe adaptation of experimental protocols - may offer ways forward, or on the\ncontrary pose some difficulties. With the advent of single cell atlases and\nincreasing perturbation data, we expect causal models to become a crucial tool\nfor informed experimental design.",
            "author": [
                "Alejandro Tejada-Lapuerta",
                "Paul Bertin",
                "Stefan Bauer",
                "Hananeh Aliee",
                "Yoshua Bengio",
                "Fabian J. Theis"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14935v1",
                "http://arxiv.org/pdf/2310.14935v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "q-bio.GN"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14934v1",
            "title": "Robust Depth Linear Error Decomposition with Double Total Variation and\n  Nuclear Norm for Dynamic MRI Reconstruction",
            "updated": "2023-10-23T13:34:59Z",
            "published": "2023-10-23T13:34:59Z",
            "summary": "Compressed Sensing (CS) significantly speeds up Magnetic Resonance Image\n(MRI) processing and achieves accurate MRI reconstruction from under-sampled\nk-space data. According to the current research, there are still several\nproblems with dynamic MRI k-space reconstruction based on CS. 1) There are\ndifferences between the Fourier domain and the Image domain, and the\ndifferences between MRI processing of different domains need to be considered.\n2) As three-dimensional data, dynamic MRI has its spatial-temporal\ncharacteristics, which need to calculate the difference and consistency of\nsurface textures while preserving structural integrity and uniqueness. 3)\nDynamic MRI reconstruction is time-consuming and computationally\nresource-dependent. In this paper, we propose a novel robust low-rank dynamic\nMRI reconstruction optimization model via highly under-sampled and Discrete\nFourier Transform (DFT) called the Robust Depth Linear Error Decomposition\nModel (RDLEDM). Our method mainly includes linear decomposition, double Total\nVariation (TV), and double Nuclear Norm (NN) regularizations. By adding linear\nimage domain error analysis, the noise is reduced after under-sampled and DFT\nprocessing, and the anti-interference ability of the algorithm is enhanced.\nDouble TV and NN regularizations can utilize both spatial-temporal\ncharacteristics and explore the complementary relationship between different\ndimensions in dynamic MRI sequences. In addition, Due to the non-smoothness and\nnon-convexity of TV and NN terms, it is difficult to optimize the unified\nobjective model. To address this issue, we utilize a fast algorithm by solving\na primal-dual form of the original problem. Compared with five state-of-the-art\nmethods, extensive experiments on dynamic MRI data demonstrate the superior\nperformance of the proposed method in terms of both reconstruction accuracy and\ntime complexity.",
            "author": [
                "Junpeng Tan",
                "Chunmei Qing",
                "Xiangmin Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14934v1",
                "http://arxiv.org/pdf/2310.14934v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14932v1",
            "title": "Navigating the Ocean with DRL: Path following for marine vessels",
            "updated": "2023-10-23T13:34:29Z",
            "published": "2023-10-23T13:34:29Z",
            "summary": "Human error is a substantial factor in marine accidents, accounting for 85%\nof all reported incidents. By reducing the need for human intervention in\nvessel navigation, AI-based methods can potentially reduce the risk of\naccidents. AI techniques, such as Deep Reinforcement Learning (DRL), have the\npotential to improve vessel navigation in challenging conditions, such as in\nrestricted waterways and in the presence of obstacles. This is because DRL\nalgorithms can optimize multiple objectives, such as path following and\ncollision avoidance, while being more efficient to implement compared to\ntraditional methods. In this study, a DRL agent is trained using the Deep\nDeterministic Policy Gradient (DDPG) algorithm for path following and waypoint\ntracking. Furthermore, the trained agent is evaluated against a traditional PD\ncontroller with an Integral Line of Sight (ILOS) guidance system for the same.\nThis study uses the Kriso Container Ship (KCS) as a test case for evaluating\nthe performance of different controllers. The ship's dynamics are modeled using\nthe maneuvering Modelling Group (MMG) model. This mathematical simulation is\nused to train a DRL-based controller and to tune the gains of a traditional PD\ncontroller. The simulation environment is also used to assess the controller's\neffectiveness in the presence of wind.",
            "author": [
                "Joel Jose",
                "Md Shadab Alam",
                "Abhilash Sharma Somayajula"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14932v1",
                "http://arxiv.org/pdf/2310.14932v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14914v1",
            "title": "Object Pose Estimation Annotation Pipeline for Multi-view Monocular\n  Camera Systems in Industrial Settings",
            "updated": "2023-10-23T13:21:44Z",
            "published": "2023-10-23T13:21:44Z",
            "summary": "Object localization, and more specifically object pose estimation, in large\nindustrial spaces such as warehouses and production facilities, is essential\nfor material flow operations. Traditional approaches rely on artificial\nartifacts installed in the environment or excessively expensive equipment, that\nis not suitable at scale. A more practical approach is to utilize existing\ncameras in such spaces in order to address the underlying pose estimation\nproblem and to localize objects of interest. In order to leverage\nstate-of-the-art methods in deep learning for object pose estimation, large\namounts of data need to be collected and annotated. In this work, we provide an\napproach to the annotation of large datasets of monocular images without the\nneed for manual labor. Our approach localizes cameras in space, unifies their\nlocation with a motion capture system, and uses a set of linear mappings to\nproject 3D models of objects of interest at their ground truth 6D pose\nlocations. We test our pipeline on a custom dataset collected from a system of\neight cameras in an industrial setting that mimics the intended area of\noperation. Our approach was able to provide consistent quality annotations for\nour dataset with 26, 482 object instances at a fraction of the time required by\nhuman annotators.",
            "author": [
                "Hazem Youssef",
                "Frederik Polachowski",
                "J\u00e9r\u00f4me Rutinowski",
                "Moritz Roidl",
                "Christopher Reining"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14914v1",
                "http://arxiv.org/pdf/2310.14914v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14909v1",
            "title": "Linking Surface Facts to Large-Scale Knowledge Graphs",
            "updated": "2023-10-23T13:18:49Z",
            "published": "2023-10-23T13:18:49Z",
            "summary": "Open Information Extraction (OIE) methods extract facts from natural language\ntext in the form of (\"subject\"; \"relation\"; \"object\") triples. These facts are,\nhowever, merely surface forms, the ambiguity of which impedes their downstream\nusage; e.g., the surface phrase \"Michael Jordan\" may refer to either the former\nbasketball player or the university professor. Knowledge Graphs (KGs), on the\nother hand, contain facts in a canonical (i.e., unambiguous) form, but their\ncoverage is limited by a static schema (i.e., a fixed set of entities and\npredicates). To bridge this gap, we need the best of both worlds: (i) high\ncoverage of free-text OIEs, and (ii) semantic precision (i.e., monosemy) of\nKGs. In order to achieve this goal, we propose a new benchmark with novel\nevaluation protocols that can, for example, measure fact linking performance on\na granular triple slot level, while also measuring if a system has the ability\nto recognize that a surface form has no match in the existing KG. Our extensive\nevaluation of several baselines show that detection of out-of-KG entities and\npredicates is more difficult than accurate linking to existing ones, thus\ncalling for more research efforts on this difficult task. We publicly release\nall resources (data, benchmark and code) on\nhttps://github.com/nec-research/fact-linking.",
            "author": [
                "Gorjan Radevski",
                "Kiril Gashteovski",
                "Chia-Chien Hung",
                "Carolin Lawrence",
                "Goran Glava\u0161"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14909v1",
                "http://arxiv.org/pdf/2310.14909v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14907v1",
            "title": "Orientation-Aware Leg Movement Learning for Action-Driven Human Motion\n  Prediction",
            "updated": "2023-10-23T13:16:51Z",
            "published": "2023-10-23T13:16:51Z",
            "summary": "The task of action-driven human motion prediction aims to forecast future\nhuman motion from the observed sequence while respecting the given action\nlabel. It requires modeling not only the stochasticity within human motion but\nthe smooth yet realistic transition between multiple action labels. However,\nthe fact that most of the datasets do not contain such transition data\ncomplicates this task. Existing work tackles this issue by learning a\nsmoothness prior to simply promote smooth transitions, yet doing so can result\nin unnatural transitions especially when the history and predicted motions\ndiffer significantly in orientations. In this paper, we argue that valid human\nmotion transitions should incorporate realistic leg movements to handle\norientation changes, and cast it as an action-conditioned in-betweening (ACB)\nlearning task to encourage transition naturalness. Because modeling all\npossible transitions is virtually unreasonable, our ACB is only performed on\nvery few selected action classes with active gait motions, such as Walk or Run.\nSpecifically, we follow a two-stage forecasting strategy by first employing the\nmotion diffusion model to generate the target motion with a specified future\naction, and then producing the in-betweening to smoothly connect the\nobservation and prediction to eventually address motion prediction. Our method\nis completely free from the labeled motion transition data during training. To\nshow the robustness of our approach, we generalize our trained in-betweening\nlearning model on one dataset to two unseen large-scale motion datasets to\nproduce natural transitions. Extensive methods on three benchmark datasets\ndemonstrate that our method yields the state-of-the-art performance in terms of\nvisual quality, prediction accuracy, and action faithfulness.",
            "author": [
                "Chunzhi Gu",
                "Chao Zhang",
                "Shigeru Kuriyama"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14907v1",
                "http://arxiv.org/pdf/2310.14907v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14901v1",
            "title": "Series of Hessian-Vector Products for Tractable Saddle-Free Newton\n  Optimisation of Neural Networks",
            "updated": "2023-10-23T13:11:30Z",
            "published": "2023-10-23T13:11:30Z",
            "summary": "Despite their popularity in the field of continuous optimisation,\nsecond-order quasi-Newton methods are challenging to apply in machine learning,\nas the Hessian matrix is intractably large. This computational burden is\nexacerbated by the need to address non-convexity, for instance by modifying the\nHessian's eigenvalues as in Saddle-Free Newton methods. We propose an\noptimisation algorithm which addresses both of these concerns - to our\nknowledge, the first efficiently-scalable optimisation algorithm to\nasymptotically use the exact (eigenvalue-modified) inverse Hessian. Our method\nframes the problem as a series which principally square-roots and inverts the\nsquared Hessian, then uses it to precondition a gradient vector, all without\nexplicitly computing or eigendecomposing the Hessian. A truncation of this\ninfinite series provides a new optimisation algorithm which is scalable and\ncomparable to other first- and second-order optimisation methods in both\nruntime and optimisation performance. We demonstrate this in a variety of\nsettings, including a ResNet-18 trained on CIFAR-10.",
            "author": [
                "Elre T. Oldewage",
                "Ross M. Clarke",
                "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14901v1",
                "http://arxiv.org/pdf/2310.14901v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14899v1",
            "title": "Universal Knowledge Graph Embeddings",
            "updated": "2023-10-23T13:07:46Z",
            "published": "2023-10-23T13:07:46Z",
            "summary": "A variety of knowledge graph embedding approaches have been developed. Most\nof them obtain embeddings by learning the structure of the knowledge graph\nwithin a link prediction setting. As a result, the embeddings reflect only the\nsemantics of a single knowledge graph, and embeddings for different knowledge\ngraphs are not aligned, e.g., they cannot be used to find similar entities\nacross knowledge graphs via nearest neighbor search. However, knowledge graph\nembedding applications such as entity disambiguation require a more global\nrepresentation, i.e., a representation that is valid across multiple sources.\nWe propose to learn universal knowledge graph embeddings from large-scale\ninterlinked knowledge sources. To this end, we fuse large knowledge graphs\nbased on the owl:sameAs relation such that every entity is represented by a\nunique identity. We instantiate our idea by computing universal embeddings\nbased on DBpedia and Wikidata yielding embeddings for about 180 million\nentities, 15 thousand relations, and 1.2 billion triples. Moreover, we develop\na convenient API to provide embeddings as a service. Experiments on link\nprediction show that universal knowledge graph embeddings encode better\nsemantics compared to embeddings computed on a single knowledge graph. For\nreproducibility purposes, we provide our source code and datasets open access\nat https://github.com/dice-group/Universal_Embeddings",
            "author": [
                "N'Dah Jean Kouagou",
                "Caglar Demir",
                "Hamada M. Zahera",
                "Adrian Wilke",
                "Stefan Heindorf",
                "Jiayi Li",
                "Axel-Cyrille Ngonga Ngomo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14899v1",
                "http://arxiv.org/pdf/2310.14899v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14894v1",
            "title": "Local Universal Rule-based Explanations",
            "updated": "2023-10-23T13:04:15Z",
            "published": "2023-10-23T13:04:15Z",
            "summary": "Explainable artificial intelligence (XAI) is one of the most intensively\ndeveloped are of AI in recent years. It is also one of the most fragmented one\nwith multiple methods that focus on different aspects of explanations. This\nmakes difficult to obtain the full spectrum of explanation at once in a compact\nand consistent way. To address this issue, we present Local Universal Explainer\n(LUX) that is a rule-based explainer which can generate factual, counterfactual\nand visual explanations. It is based on a modified version of decision tree\nalgorithms that allows for oblique splits and integration with feature\nimportance XAI methods such as SHAP or LIME. It does not use data generation in\nopposite to other algorithms, but is focused on selecting local concepts in a\nform of high-density clusters of real data that have the highest impact on\nforming the decision boundary of the explained model. We tested our method on\nreal and synthetic datasets and compared it with state-of-the-art rule-based\nexplainers such as LORE, EXPLAN and Anchor. Our method outperforms currently\nexisting approaches in terms of simplicity, global fidelity and\nrepresentativeness.",
            "author": [
                "Szymon Bobek",
                "Grzegorz J. Nalepa"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14894v1",
                "http://arxiv.org/pdf/2310.14894v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14888v1",
            "title": "Beyond Bayesian Model Averaging over Paths in Probabilistic Programs\n  with Stochastic Support",
            "updated": "2023-10-23T12:57:03Z",
            "published": "2023-10-23T12:57:03Z",
            "summary": "The posterior in probabilistic programs with stochastic support decomposes as\na weighted sum of the local posterior distributions associated with each\npossible program path. We show that making predictions with this full posterior\nimplicitly performs a Bayesian model averaging (BMA) over paths. This is\npotentially problematic, as model misspecification can cause the BMA weights to\nprematurely collapse onto a single path, leading to sub-optimal predictions in\nturn. To remedy this issue, we propose alternative mechanisms for path\nweighting: one based on stacking and one based on ideas from PAC-Bayes. We show\nhow both can be implemented as a cheap post-processing step on top of existing\ninference engines. In our experiments, we find them to be more robust and lead\nto better predictions compared to the default BMA weights.",
            "author": [
                "Tim Reichelt",
                "Luke Ong",
                "Tom Rainforth"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14888v1",
                "http://arxiv.org/pdf/2310.14888v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10736v1",
            "title": "Systematic Evaluation of Applying Space-Filling Curves to Automotive\n  Maneuver Detection",
            "updated": "2023-10-23T12:56:09Z",
            "published": "2023-10-23T12:56:09Z",
            "summary": "Identifying driving maneuvers plays an essential role on-board vehicles to\nmonitor driving and driver states, as well as off-board to train and evaluate\nmachine learning algorithms for automated driving for example. Maneuvers can be\ncharacterized by vehicle kinematics or data from its surroundings including\nother traffic participants. Extracting relevant maneuvers therefore requires\nanalyzing time-series of (i) structured, multi-dimensional kinematic data, and\n(ii) unstructured, large data samples for video, radar, or LiDAR sensors.\nHowever, such data analysis requires scalable and computationally efficient\napproaches, especially for non-annotated data. In this paper, we are presenting\na maneuver detection approach based on two variants of space-filling curves\n(Z-order and Hilbert) to detect maneuvers when passing roundabouts that do not\nuse GPS data. We systematically evaluate their respective performance by\nincluding permutations of selections of kinematic signals at varying\nfrequencies and compare them with two alternative baselines: All manually\nidentified roundabouts, and roundabouts that are marked by geofences. We find\nthat encoding just longitudinal and lateral accelerations sampled at 10Hz using\na Hilbert space-filling curve is already successfully identifying roundabout\nmaneuvers, which allows to avoid the use of potentially sensitive signals such\nas GPS locations to comply with data protection and privacy regulations like\nGDPR.",
            "author": [
                "Christian Berger",
                "Beatriz Cabrero-Daniel",
                "M. Cagri Kaya",
                "Maryam Esmaeili Darestani",
                "Hannah Shiels"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10736v1",
                "http://arxiv.org/pdf/2311.10736v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14884v2",
            "title": "Budgeted Embedding Table For Recommender Systems",
            "updated": "2023-11-21T05:28:30Z",
            "published": "2023-10-23T12:53:22Z",
            "summary": "At the heart of contemporary recommender systems (RSs) are latent factor\nmodels that provide quality recommendation experience to users. These models\nuse embedding vectors, which are typically of a uniform and fixed size, to\nrepresent users and items. As the number of users and items continues to grow,\nthis design becomes inefficient and hard to scale. Recent lightweight embedding\nmethods have enabled different users and items to have diverse embedding sizes,\nbut are commonly subject to two major drawbacks. Firstly, they limit the\nembedding size search to optimizing a heuristic balancing the recommendation\nquality and the memory complexity, where the trade-off coefficient needs to be\nmanually tuned for every memory budget requested. The implicitly enforced\nmemory complexity term can even fail to cap the parameter usage, making the\nresultant embedding table fail to meet the memory budget strictly. Secondly,\nmost solutions, especially reinforcement learning based ones derive and\noptimize the embedding size for each each user/item on an instance-by-instance\nbasis, which impedes the search efficiency. In this paper, we propose Budgeted\nEmbedding Table (BET), a novel method that generates table-level actions (i.e.,\nembedding sizes for all users and items) that is guaranteed to meet\npre-specified memory budgets. Furthermore, by leveraging a set-based action\nformulation and engaging set representation learning, we present an innovative\naction search strategy powered by an action fitness predictor that efficiently\nevaluates each table-level action. Experiments have shown state-of-the-art\nperformance on two real-world datasets when BET is paired with three popular\nrecommender models under different memory budgets.",
            "author": [
                "Yunke Qu",
                "Tong Chen",
                "Quoc Viet Hung Nguyen",
                "Hongzhi Yin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14884v2",
                "http://arxiv.org/pdf/2310.14884v2"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14866v1",
            "title": "A Study on Knowledge Graph Embeddings and Graph Neural Networks for Web\n  Of Things",
            "updated": "2023-10-23T12:36:33Z",
            "published": "2023-10-23T12:36:33Z",
            "summary": "Graph data structures are widely used to store relational information between\nseveral entities. With data being generated worldwide on a large scale, we see\na significant growth in the generation of knowledge graphs. Thing in the future\nis Orange's take on a knowledge graph in the domain of the Web Of Things (WoT),\nwhere the main objective of the platform is to provide a digital representation\nof the physical world and enable cross-domain applications to be built upon\nthis massive and highly connected graph of things. In this context, as the\nknowledge graph grows in size, it is prone to have noisy and messy data. In\nthis paper, we explore state-of-the-art knowledge graph embedding (KGE) methods\nto learn numerical representations of the graph entities and, subsequently,\nexplore downstream tasks like link prediction, node classification, and triple\nclassification. We also investigate Graph neural networks (GNN) alongside KGEs\nand compare their performance on the same downstream tasks. Our evaluation\nhighlights the encouraging performance of both KGE and GNN-based methods on\nnode classification, and the superiority of GNN approaches in the link\nprediction task. Overall, we show that state-of-the-art approaches are relevant\nin a WoT context, and this preliminary work provides insights to implement and\nevaluate them in this context.",
            "author": [
                "Rohith Teja Mittakola",
                "Thomas Hassan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14866v1",
                "http://arxiv.org/pdf/2310.14866v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14864v1",
            "title": "Diverse Priors for Deep Reinforcement Learning",
            "updated": "2023-10-23T12:33:59Z",
            "published": "2023-10-23T12:33:59Z",
            "summary": "In Reinforcement Learning (RL), agents aim at maximizing cumulative rewards\nin a given environment. During the learning process, RL agents face the dilemma\nof exploitation and exploration: leveraging existing knowledge to acquire\nrewards or seeking potentially higher ones. Using uncertainty as a guiding\nprinciple provides an active and effective approach to solving this dilemma and\nensemble-based methods are one of the prominent avenues for quantifying\nuncertainty. Nevertheless, conventional ensemble-based uncertainty estimation\nlacks an explicit prior, deviating from Bayesian principles. Besides, this\nmethod requires diversity among members to generate less biased uncertainty\nestimation results. To address the above problems, previous research has\nincorporated random functions as priors. Building upon these foundational\nefforts, our work introduces an innovative approach with delicately designed\nprior NNs, which can incorporate maximal diversity in the initial value\nfunctions of RL. Our method has demonstrated superior performance compared with\nthe random prior approaches in solving classic control problems and general\nexploration tasks, significantly improving sample efficiency.",
            "author": [
                "Chenfan Weng",
                "Zhongguo Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14864v1",
                "http://arxiv.org/pdf/2310.14864v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00709v1",
            "title": "Enhancing Chemistry Learning with ChatGPT, Bing Chat, Bard, and Claude\n  as Agents-to-Think-With: A Comparative Case Study",
            "updated": "2023-10-23T12:33:53Z",
            "published": "2023-10-23T12:33:53Z",
            "summary": "This research delves into the comparative advantages of Generative AI\nchatbots (GenAIbots) -- ChatGPT, Bing Chat, Bard, and Claude -- in the context\nof Chemistry education, framed within a constructivist perspective. Our primary\nobjective was to identify which of these four AI tools is more effective for\nenhancing Chemistry learning. Employing a single-case study approach, we\nscrutinised interaction logs between the AI systems and a simulated student\npersona during Chemistry learning simulations, incorporating Content Analysis\nmethodology to delve deeper into the discourse. Our findings underscore these\ntools' potential as \"agents-to-think-with\", enhancing critical thinking,\nproblem-solving, comprehension, creativity, and tailored learning. Especially\nnoteworthy is their ability to stimulate learners through Socratic-like\nquestioning, aligning with constructionist principles. The research emphasises\nthe pivotal role of prompt crafting to coax desired responses from GenAIbots,\nengendering iterative reflections. It also highlights the need for robust\neducator training to infuse these technologies into educational settings.\nConclusively, while ChatGPT, Bing Chat, Bard, and Claude are poised to enrich\nChemistry education by fostering dynamic, inclusive learning experiences,\nChatGPT stood out, decisively surpassing Bing Chat in its performance. Bard and\nClaude trailed closely, with all three showcasing a more in-depth, precise, and\nnuanced understanding, underscoring ChatGPT's adeptness at contextual\ncomprehension.",
            "author": [
                "Renato P. dos Santos"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00709v1",
                "http://arxiv.org/pdf/2311.00709v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "J.4; K.3"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14860v2",
            "title": "Adaptive Tuning of Robotic Polishing Skills based on Force Feedback\n  Model",
            "updated": "2023-11-22T07:56:39Z",
            "published": "2023-10-23T12:30:01Z",
            "summary": "Acquiring human skills offers an efficient approach to tackle complex task\nplanning challenges. When performing a learned skill model for a continuous\ncontact task, such as robot polishing in an uncertain environment, the robot\nneeds to be able to adaptively modify the skill model to suit the environment\nand perform the desired task. The environmental perturbation of the polishing\ntask is mainly reflected in the variation of contact force. Therefore,\nadjusting the task skill model by providing feedback on the contact force\ndeviation is an effective way to meet the task requirements. In this study, a\nphase-modulated diagonal recurrent neural network (PMDRNN) is proposed for\nforce feedback model learning in the robotic polishing task. The contact\nbetween the tool and the workpiece in the polishing task can be considered a\ndynamic system. In comparison to the existing feedforward neural network\nphase-modulated neural network (PMNN), PMDRNN combines the diagonal recurrent\nnetwork structure with the phase-modulated neural network layer to improve the\nlearning performance of the feedback model for dynamic systems. Specifically,\ndata from real-world robot polishing experiments are used to learn the feedback\nmodel. PMDRNN demonstrates a significant reduction in the training error of the\nfeedback model when compared to PMNN. Building upon this, the combination of\nPMDRNN and dynamic movement primitives (DMPs) can be used for real-time\nadjustment of skills for polishing tasks and effectively improve the robustness\nof the task skill model. Finally, real-world robotic polishing experiments are\nconducted to demonstrate the effectiveness of the approach.",
            "author": [
                "Yu Wang",
                "Zhouyi Zheng",
                "Chen Chen",
                "Zezheng Wang",
                "Zhitao Gao",
                "Fangyu Peng",
                "Xiaowei Tang",
                "Rong Yan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14860v2",
                "http://arxiv.org/pdf/2310.14860v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14858v2",
            "title": "Dynamically Weighted Federated k-Means",
            "updated": "2023-11-17T10:35:48Z",
            "published": "2023-10-23T12:28:21Z",
            "summary": "Federated clustering, an integral aspect of federated machine learning,\nenables multiple data sources to collaboratively cluster their data,\nmaintaining decentralization and preserving privacy. In this paper, we\nintroduce a novel federated clustering algorithm named Dynamically Weighted\nFederated k-means (DWF k-means) based on Lloyd's method for k-means clustering,\nto address the challenges associated with distributed data sources and\nheterogeneous data. Our proposed algorithm combines the benefits of traditional\nclustering techniques with the privacy and scalability benefits offered by\nfederated learning. The algorithm facilitates collaborative clustering among\nmultiple data owners, allowing them to cluster their local data collectively\nwhile exchanging minimal information with the central coordinator. The\nalgorithm optimizes the clustering process by adaptively aggregating cluster\nassignments and centroids from each data source, thereby learning a global\nclustering solution that reflects the collective knowledge of the entire\nfederated network. We address the issue of empty clusters, which commonly\narises in the context of federated clustering. We conduct experiments on\nmultiple datasets and data distribution settings to evaluate the performance of\nour algorithm in terms of clustering score, accuracy, and v-measure. The\nresults demonstrate that our approach can match the performance of the\ncentralized classical k-means baseline, and outperform existing federated\nclustering methods like k-FED in realistic scenarios.",
            "author": [
                "Patrick Holzer",
                "Tania Jacob",
                "Shubham Kavane"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14858v2",
                "http://arxiv.org/pdf/2310.14858v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14849v1",
            "title": "Universal Domain Adaptation for Robust Handling of Distributional Shifts\n  in NLP",
            "updated": "2023-10-23T12:15:25Z",
            "published": "2023-10-23T12:15:25Z",
            "summary": "When deploying machine learning systems to the wild, it is highly desirable\nfor them to effectively leverage prior knowledge to the unfamiliar domain while\nalso firing alarms to anomalous inputs. In order to address these requirements,\nUniversal Domain Adaptation (UniDA) has emerged as a novel research area in\ncomputer vision, focusing on achieving both adaptation ability and robustness\n(i.e., the ability to detect out-of-distribution samples). While UniDA has led\nsignificant progress in computer vision, its application on language input\nstill needs to be explored despite its feasibility. In this paper, we propose a\ncomprehensive benchmark for natural language that offers thorough viewpoints of\nthe model's generalizability and robustness. Our benchmark encompasses multiple\ndatasets with varying difficulty levels and characteristics, including temporal\nshifts and diverse domains. On top of our testbed, we validate existing UniDA\nmethods from computer vision and state-of-the-art domain adaptation techniques\nfrom NLP literature, yielding valuable findings: We observe that UniDA methods\noriginally designed for image input can be effectively transferred to the\nnatural language domain while also underscoring the effect of adaptation\ndifficulty in determining the model's performance.",
            "author": [
                "Hyuhng Joon Kim",
                "Hyunsoo Cho",
                "Sang-Woo Lee",
                "Junyeob Kim",
                "Choonghyun Park",
                "Sang-goo Lee",
                "Kang Min Yoo",
                "Taeuk Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14849v1",
                "http://arxiv.org/pdf/2310.14849v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14848v1",
            "title": "Zero-knowledge Proof Meets Machine Learning in Verifiability: A Survey",
            "updated": "2023-10-23T12:15:23Z",
            "published": "2023-10-23T12:15:23Z",
            "summary": "With the rapid advancement of artificial intelligence technology, the usage\nof machine learning models is gradually becoming part of our daily lives.\nHigh-quality models rely not only on efficient optimization algorithms but also\non the training and learning processes built upon vast amounts of data and\ncomputational power. However, in practice, due to various challenges such as\nlimited computational resources and data privacy concerns, users in need of\nmodels often cannot train machine learning models locally. This has led them to\nexplore alternative approaches such as outsourced learning and federated\nlearning. While these methods address the feasibility of model training\neffectively, they introduce concerns about the trustworthiness of the training\nprocess since computations are not performed locally. Similarly, there are\ntrustworthiness issues associated with outsourced model inference. These two\nproblems can be summarized as the trustworthiness problem of model\ncomputations: How can one verify that the results computed by other\nparticipants are derived according to the specified algorithm, model, and input\ndata? To address this challenge, verifiable machine learning (VML) has emerged.\nThis paper presents a comprehensive survey of zero-knowledge proof-based\nverifiable machine learning (ZKP-VML) technology. We first analyze the\npotential verifiability issues that may exist in different machine learning\nscenarios. Subsequently, we provide a formal definition of ZKP-VML. We then\nconduct a detailed analysis and classification of existing works based on their\ntechnical approaches. Finally, we discuss the key challenges and future\ndirections in the field of ZKP-based VML.",
            "author": [
                "Zhibo Xing",
                "Zijian Zhang",
                "Jiamou Liu",
                "Ziang Zhang",
                "Meng Li",
                "Liehuang Zhu",
                "Giovanni Russello"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14848v1",
                "http://arxiv.org/pdf/2310.14848v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14845v1",
            "title": "ULTRA-DP: Unifying Graph Pre-training with Multi-task Graph Dual Prompt",
            "updated": "2023-10-23T12:11:13Z",
            "published": "2023-10-23T12:11:13Z",
            "summary": "Recent research has demonstrated the efficacy of pre-training graph neural\nnetworks (GNNs) to capture the transferable graph semantics and enhance the\nperformance of various downstream tasks. However, the semantic knowledge\nlearned from pretext tasks might be unrelated to the downstream task, leading\nto a semantic gap that limits the application of graph pre-training. To reduce\nthis gap, traditional approaches propose hybrid pre-training to combine various\npretext tasks together in a multi-task learning fashion and learn multi-grained\nknowledge, which, however, cannot distinguish tasks and results in some\ntransferable task-specific knowledge distortion by each other. Moreover, most\nGNNs cannot distinguish nodes located in different parts of the graph, making\nthem fail to learn position-specific knowledge and lead to suboptimal\nperformance. In this work, inspired by the prompt-based tuning in natural\nlanguage processing, we propose a unified framework for graph hybrid\npre-training which injects the task identification and position identification\ninto GNNs through a prompt mechanism, namely multi-task graph dual prompt\n(ULTRA-DP). Based on this framework, we propose a prompt-based transferability\ntest to find the most relevant pretext task in order to reduce the semantic\ngap. To implement the hybrid pre-training tasks, beyond the classical edge\nprediction task (node-node level), we further propose a novel pre-training\nparadigm based on a group of $k$-nearest neighbors (node-group level). The\ncombination of them across different scales is able to comprehensively express\nmore structural semantics and derive richer multi-grained knowledge. Extensive\nexperiments show that our proposed ULTRA-DP can significantly enhance the\nperformance of hybrid pre-training methods and show the generalizability to\nother pre-training tasks and backbone architectures.",
            "author": [
                "Mouxiang Chen",
                "Zemin Liu",
                "Chenghao Liu",
                "Jundong Li",
                "Qiheng Mao",
                "Jianling Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14845v1",
                "http://arxiv.org/pdf/2310.14845v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14840v1",
            "title": "Transparency at the Source: Evaluating and Interpreting Language Models\n  With Access to the True Distribution",
            "updated": "2023-10-23T12:03:01Z",
            "published": "2023-10-23T12:03:01Z",
            "summary": "We present a setup for training, evaluating and interpreting neural language\nmodels, that uses artificial, language-like data. The data is generated using a\nmassive probabilistic grammar (based on state-split PCFGs), that is itself\nderived from a large natural language corpus, but also provides us complete\ncontrol over the generative process. We describe and release both grammar and\ncorpus, and test for the naturalness of our generated data. This approach\nallows us to define closed-form expressions to efficiently compute exact lower\nbounds on obtainable perplexity using both causal and masked language\nmodelling. Our results show striking differences between neural language\nmodelling architectures and training objectives in how closely they allow\napproximating the lower bound on perplexity. Our approach also allows us to\ndirectly compare learned representations to symbolic rules in the underlying\nsource. We experiment with various techniques for interpreting model behaviour\nand learning dynamics. With access to the underlying true source, our results\nshow striking differences and outcomes in learning dynamics between different\nclasses of words.",
            "author": [
                "Jaap Jumelet",
                "Willem Zuidema"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14840v1",
                "http://arxiv.org/pdf/2310.14840v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14838v1",
            "title": "Calibration of Time-Series Forecasting Transformers: Detecting and\n  Adapting Context-Driven Distribution Shift",
            "updated": "2023-10-23T11:58:01Z",
            "published": "2023-10-23T11:58:01Z",
            "summary": "Recent years have witnessed the success of introducing Transformers to time\nseries forecasting. From a data generation perspective, we illustrate that\nexisting Transformers are susceptible to distribution shifts driven by temporal\ncontexts, whether observed or unobserved. Such context-driven distribution\nshift (CDS) introduces biases in predictions within specific contexts and poses\nchallenges for conventional training paradigm. In this paper, we introduce a\nuniversal calibration methodology for the detection and adaptation of CDS with\na trained Transformer model. To this end, we propose a novel CDS detector,\ntermed the \"residual-based CDS detector\" or \"Reconditionor\", which quantifies\nthe model's vulnerability to CDS by evaluating the mutual information between\nprediction residuals and their corresponding contexts. A high Reconditionor\nscore indicates a severe susceptibility, thereby necessitating model\nadaptation. In this circumstance, we put forth a straightforward yet potent\nadapter framework for model calibration, termed the \"sample-level\ncontextualized adapter\" or \"SOLID\". This framework involves the curation of a\ncontextually similar dataset to the provided test sample and the subsequent\nfine-tuning of the model's prediction layer with a limited number of steps. Our\ntheoretical analysis demonstrates that this adaptation strategy is able to\nachieve an optimal equilibrium between bias and variance. Notably, our proposed\nReconditionor and SOLID are model-agnostic and readily adaptable to a wide\nrange of Transformers. Extensive experiments show that SOLID consistently\nenhances the performance of current SOTA Transformers on real-world datasets,\nespecially on cases with substantial CDS detected by the proposed\nReconditionor, thus validate the effectiveness of the calibration approach.",
            "author": [
                "Mouxiang Chen",
                "Lefei Shen",
                "Han Fu",
                "Zhuo Li",
                "Jianling Sun",
                "Chenghao Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14838v1",
                "http://arxiv.org/pdf/2310.14838v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14837v1",
            "title": "Harnessing Attention Mechanisms: Efficient Sequence Reduction using\n  Attention-based Autoencoders",
            "updated": "2023-10-23T11:57:44Z",
            "published": "2023-10-23T11:57:44Z",
            "summary": "Many machine learning models use the manipulation of dimensions as a driving\nforce to enable models to identify and learn important features in data. In the\ncase of sequential data this manipulation usually happens on the token\ndimension level. Despite the fact that many tasks require a change in sequence\nlength itself, the step of sequence length reduction usually happens out of\nnecessity and in a single step. As far as we are aware, no model uses the\nsequence length reduction step as an additional opportunity to tune the models\nperformance. In fact, sequence length manipulation as a whole seems to be an\noverlooked direction. In this study we introduce a novel attention-based method\nthat allows for the direct manipulation of sequence lengths. To explore the\nmethod's capabilities, we employ it in an autoencoder model. The autoencoder\nreduces the input sequence to a smaller sequence in latent space. It then aims\nto reproduce the original sequence from this reduced form. In this setting, we\nexplore the methods reduction performance for different input and latent\nsequence lengths. We are able to show that the autoencoder retains all the\nsignificant information when reducing the original sequence to half its\noriginal size. When reducing down to as low as a quarter of its original size,\nthe autoencoder is still able to reproduce the original sequence with an\naccuracy of around 90%.",
            "author": [
                "Daniel Biermann",
                "Fabrizio Palumbo",
                "Morten Goodwin",
                "Ole-Christoffer Granmo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14837v1",
                "http://arxiv.org/pdf/2310.14837v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14826v1",
            "title": "Sharp error bounds for imbalanced classification: how many examples in\n  the minority class?",
            "updated": "2023-10-23T11:45:34Z",
            "published": "2023-10-23T11:45:34Z",
            "summary": "When dealing with imbalanced classification data, reweighting the loss\nfunction is a standard procedure allowing to equilibrate between the true\npositive and true negative rates within the risk measure. Despite significant\ntheoretical work in this area, existing results do not adequately address a\nmain challenge within the imbalanced classification framework, which is the\nnegligible size of one class in relation to the full sample size and the need\nto rescale the risk function by a probability tending to zero. To address this\ngap, we present two novel contributions in the setting where the rare class\nprobability approaches zero: (1) a non asymptotic fast rate probability bound\nfor constrained balanced empirical risk minimization, and (2) a consistent\nupper bound for balanced nearest neighbors estimates. Our findings provide a\nclearer understanding of the benefits of class-weighting in realistic settings,\nopening new avenues for further research in this field.",
            "author": [
                "Anass Aghbalou",
                "Fran\u00e7ois Portier",
                "Anne Sabourin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14826v1",
                "http://arxiv.org/pdf/2310.14826v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14817v1",
            "title": "Text2Topic: Multi-Label Text Classification System for Efficient Topic\n  Detection in User Generated Content with Zero-Shot Capabilities",
            "updated": "2023-10-23T11:33:24Z",
            "published": "2023-10-23T11:33:24Z",
            "summary": "Multi-label text classification is a critical task in the industry. It helps\nto extract structured information from large amount of textual data. We propose\nText to Topic (Text2Topic), which achieves high multi-label classification\nperformance by employing a Bi-Encoder Transformer architecture that utilizes\nconcatenation, subtraction, and multiplication of embeddings on both text and\ntopic. Text2Topic also supports zero-shot predictions, produces domain-specific\ntext embeddings, and enables production-scale batch-inference with high\nthroughput. The final model achieves accurate and comprehensive results\ncompared to state-of-the-art baselines, including large language models (LLMs).\n  In this study, a total of 239 topics are defined, and around 1.6 million\ntext-topic pairs annotations (in which 200K are positive) are collected on\napproximately 120K texts from 3 main data sources on Booking.com. The data is\ncollected with optimized smart sampling and partial labeling. The final\nText2Topic model is deployed on a real-world stream processing platform, and it\noutperforms other models with 92.9% micro mAP, as well as a 75.8% macro mAP\nscore. We summarize the modeling choices which are extensively tested through\nablation studies, and share detailed in-production decision-making steps.",
            "author": [
                "Fengjun Wang",
                "Moran Beladev",
                "Ofri Kleinfeld",
                "Elina Frayerman",
                "Tal Shachar",
                "Eran Fainman",
                "Karen Lastmann Assaraf",
                "Sarai Mizrachi",
                "Benjamin Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14817v1",
                "http://arxiv.org/pdf/2310.14817v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14815v1",
            "title": "Deep learning denoiser assisted roughness measurements extraction from\n  thin resists with low Signal-to-Noise Ratio(SNR) SEM images: analysis with\n  SMILE",
            "updated": "2023-10-23T11:30:54Z",
            "published": "2023-10-23T11:30:54Z",
            "summary": "The technological advance of High Numerical Aperture Extreme Ultraviolet\nLithography (High NA EUVL) has opened the gates to extensive researches on\nthinner photoresists (below 30nm), necessary for the industrial implementation\nof High NA EUVL. Consequently, images from Scanning Electron Microscopy (SEM)\nsuffer from reduced imaging contrast and low Signal-to-Noise Ratio (SNR),\nimpacting the measurement of unbiased Line Edge Roughness (uLER) and Line Width\nRoughness (uLWR). Thus, the aim of this work is to enhance the SNR of SEM\nimages by using a Deep Learning denoiser and enable robust roughness extraction\nof the thin resist. For this study, we acquired SEM images of Line-Space (L/S)\npatterns with a Chemically Amplified Resist (CAR) with different thicknesses\n(15nm, 20nm, 25nm, 30nm), underlayers (Spin-On-Glass-SOG, Organic\nUnderlayer-OUL) and frames of averaging (4, 8, 16, 32, and 64 Fr). After\ndenoising, a systematic analysis has been carried out on both noisy and\ndenoised images using an open-source metrology software, SMILE 2.3.2, for\ninvestigating mean CD, SNR improvement factor, biased and unbiased LWR/LER\nPower Spectral Density (PSD). Denoised images with lower number of frames\npresent unaltered Critical Dimensions (CDs), enhanced SNR (especially for low\nnumber of integration frames), and accurate measurements of uLER and uLWR, with\nthe same accuracy as for noisy images with a consistent higher number of\nframes. Therefore, images with a small number of integration frames and with\nSNR < 2 can be successfully denoised, and advantageously used in improving\nmetrology throughput while maintaining reliable roughness measurements for the\nthin resist.",
            "author": [
                "Sara Sacchi",
                "Bappaditya Dey",
                "Iacopo Mochi",
                "Sandip Halder",
                "Philippe Leray"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14815v1",
                "http://arxiv.org/pdf/2310.14815v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14814v2",
            "title": "Leveraging Ensemble Diversity for Robust Self-Training in the Presence\n  of Sample Selection Bias",
            "updated": "2023-10-26T15:02:41Z",
            "published": "2023-10-23T11:30:06Z",
            "summary": "Self-training is a well-known approach for semi-supervised learning. It\nconsists of iteratively assigning pseudo-labels to unlabeled data for which the\nmodel is confident and treating them as labeled examples. For neural networks,\nsoftmax prediction probabilities are often used as a confidence measure,\ndespite the fact that they are known to be overconfident, even for wrong\npredictions. This phenomenon is particularly intensified in the presence of\nsample selection bias, i.e., when data labeling is subject to some constraint.\nTo address this issue, we propose a novel confidence measure, called\n$\\mathcal{T}$-similarity, built upon the prediction diversity of an ensemble of\nlinear classifiers. We provide the theoretical analysis of our approach by\nstudying stationary points and describing the relationship between the\ndiversity of the individual members and their performance. We empirically\ndemonstrate the benefit of our confidence measure for three different\npseudo-labeling policies on classification datasets of various data modalities.",
            "author": [
                "Ambroise Odonnat",
                "Vasilii Feofanov",
                "Ievgen Redko"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14814v2",
                "http://arxiv.org/pdf/2310.14814v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14810v1",
            "title": "Neural representation in active inference: using generative models to\n  interact with -- and understand -- the lived world",
            "updated": "2023-10-23T11:19:56Z",
            "published": "2023-10-23T11:19:56Z",
            "summary": "This paper considers neural representation through the lens of active\ninference, a normative framework for understanding brain function. It delves\ninto how living organisms employ generative models to minimize the discrepancy\nbetween predictions and observations (as scored with variational free energy).\nThe ensuing analysis suggests that the brain learns generative models to\nnavigate the world adaptively, not (or not solely) to understand it. Different\nliving organisms may possess an array of generative models, spanning from those\nthat support action-perception cycles to those that underwrite planning and\nimagination; namely, from \"explicit\" models that entail variables for\npredicting concurrent sensations, like objects, faces, or people - to\n\"action-oriented models\" that predict action outcomes. It then elucidates how\ngenerative models and belief dynamics might link to neural representation and\nthe implications of different types of generative models for understanding an\nagent's cognitive capabilities in relation to its ecological niche. The paper\nconcludes with open questions regarding the evolution of generative models and\nthe development of advanced cognitive abilities - and the gradual transition\nfrom \"pragmatic\" to \"detached\" neural representations. The analysis on offer\nforegrounds the diverse roles that generative models play in cognitive\nprocesses and the evolution of neural representation.",
            "author": [
                "Giovanni Pezzulo",
                "Leo D'Amato",
                "Francesco Mannella",
                "Matteo Priorelli",
                "Toon Van de Maele",
                "Ivilin Peev Stoianov",
                "Karl Friston"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14810v1",
                "http://arxiv.org/pdf/2310.14810v1"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14809v1",
            "title": "Learning spatio-temporal patterns with Neural Cellular Automata",
            "updated": "2023-10-23T11:16:32Z",
            "published": "2023-10-23T11:16:32Z",
            "summary": "Neural Cellular Automata (NCA) are a powerful combination of machine learning\nand mechanistic modelling. We train NCA to learn complex dynamics from time\nseries of images and PDE trajectories. Our method is designed to identify\nunderlying local rules that govern large scale dynamic emergent behaviours.\nPrevious work on NCA focuses on learning rules that give stationary emergent\nstructures. We extend NCA to capture both transient and stable structures\nwithin the same system, as well as learning rules that capture the dynamics of\nTuring pattern formation in nonlinear Partial Differential Equations (PDEs). We\ndemonstrate that NCA can generalise very well beyond their PDE training data,\nwe show how to constrain NCA to respect given symmetries, and we explore the\neffects of associated hyperparameters on model performance and stability. Being\nable to learn arbitrary dynamics gives NCA great potential as a data driven\nmodelling framework, especially for modelling biological pattern formation.",
            "author": [
                "Alex D. Richardson",
                "Tibor Antal",
                "Richard A. Blythe",
                "Linus J. Schumacher"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14809v1",
                "http://arxiv.org/pdf/2310.14809v1"
            ],
            "primary_category": "nlin.PS",
            "category": [
                "nlin.PS",
                "cs.LG",
                "cs.NE",
                "math.DS",
                "nlin.AO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14808v1",
            "title": "The evolving of Data Science and the Saudi Arabia case. How much have we\n  changed in 13 years?",
            "updated": "2023-10-23T11:09:38Z",
            "published": "2023-10-23T11:09:38Z",
            "summary": "A comprehensive examination of data science vocabulary usage over the past 13\nyears in this work is conducted. The investigation commences with a dataset\ncomprising 16,018 abstracts that feature the term \"data science\" in either the\ntitle, abstract, or keywords. The study involves the identification of\ndocuments that introduce novel vocabulary and subsequently explores how this\nvocabulary has been incorporated into scientific literature. To achieve these\nobjectives, I employ techniques such as Exploratory Data Analysis, Latent\nSemantic Analysis, Latent Dirichlet Analysis, and N-grams Analysis. A\ncomparison of scientific publications between overall results and those\nspecific to Saudi Arabia is presented. Based on how the vocabulary is utilized,\nrepresentative articles are identified.",
            "author": [
                "Igor Barahona"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14808v1",
                "http://arxiv.org/pdf/2310.14808v1"
            ],
            "primary_category": "stat.AP",
            "category": [
                "stat.AP",
                "stat.CO",
                "stat.ML",
                "stat.OT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14805v1",
            "title": "Cross-Modal Conceptualization in Bottleneck Models",
            "updated": "2023-10-23T11:00:19Z",
            "published": "2023-10-23T11:00:19Z",
            "summary": "Concept Bottleneck Models (CBMs) assume that training examples (e.g., x-ray\nimages) are annotated with high-level concepts (e.g., types of abnormalities),\nand perform classification by first predicting the concepts, followed by\npredicting the label relying on these concepts. The main difficulty in using\nCBMs comes from having to choose concepts that are predictive of the label and\nthen having to label training examples with these concepts. In our approach, we\nadopt a more moderate assumption and instead use text descriptions (e.g.,\nradiology reports), accompanying the images in training, to guide the induction\nof concepts. Our cross-modal approach treats concepts as discrete latent\nvariables and promotes concepts that (1) are predictive of the label, and (2)\ncan be predicted reliably from both the image and text. Through experiments\nconducted on datasets ranging from synthetic datasets (e.g., synthetic images\nwith generated descriptions) to realistic medical imaging datasets, we\ndemonstrate that cross-modal learning encourages the induction of interpretable\nconcepts while also facilitating disentanglement. Our results also suggest that\nthis guidance leads to increased robustness by suppressing the reliance on\nshortcut features.",
            "author": [
                "Danis Alukaev",
                "Semen Kiselev",
                "Ilya Pershin",
                "Bulat Ibragimov",
                "Vladimir Ivanov",
                "Alexey Kornaev",
                "Ivan Titov"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14805v1",
                "http://arxiv.org/pdf/2310.14805v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14793v1",
            "title": "What do Deck Chairs and Sun Hats Have in Common? Uncovering Shared\n  Properties in Large Concept Vocabularies",
            "updated": "2023-10-23T10:53:25Z",
            "published": "2023-10-23T10:53:25Z",
            "summary": "Concepts play a central role in many applications. This includes settings\nwhere concepts have to be modelled in the absence of sentence context. Previous\nwork has therefore focused on distilling decontextualised concept embeddings\nfrom language models. But concepts can be modelled from different perspectives,\nwhereas concept embeddings typically mostly capture taxonomic structure. To\naddress this issue, we propose a strategy for identifying what different\nconcepts, from a potentially large concept vocabulary, have in common with\nothers. We then represent concepts in terms of the properties they share with\nthe other concepts. To demonstrate the practical usefulness of this way of\nmodelling concepts, we consider the task of ultra-fine entity typing, which is\na challenging multi-label classification problem. We show that by augmenting\nthe label set with shared properties, we can improve the performance of the\nstate-of-the-art models for this task.",
            "author": [
                "Amit Gajbhiye",
                "Zied Bouraoui",
                "Na Li",
                "Usashi Chatterjee",
                "Luis Espinosa Anke",
                "Steven Schockaert"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14793v1",
                "http://arxiv.org/pdf/2310.14793v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14785v1",
            "title": "Vision-Enhanced Semantic Entity Recognition in Document Images via\n  Visually-Asymmetric Consistency Learning",
            "updated": "2023-10-23T10:37:22Z",
            "published": "2023-10-23T10:37:22Z",
            "summary": "Extracting meaningful entities belonging to predefined categories from\nVisually-rich Form-like Documents (VFDs) is a challenging task. Visual and\nlayout features such as font, background, color, and bounding box location and\nsize provide important cues for identifying entities of the same type. However,\nexisting models commonly train a visual encoder with weak cross-modal\nsupervision signals, resulting in a limited capacity to capture these\nnon-textual features and suboptimal performance. In this paper, we propose a\nnovel \\textbf{V}isually-\\textbf{A}symmetric co\\textbf{N}sisten\\textbf{C}y\n\\textbf{L}earning (\\textsc{Vancl}) approach that addresses the above limitation\nby enhancing the model's ability to capture fine-grained visual and layout\nfeatures through the incorporation of color priors. Experimental results on\nbenchmark datasets show that our approach substantially outperforms the strong\nLayoutLM series baseline, demonstrating the effectiveness of our approach.\nAdditionally, we investigate the effects of different color schemes on our\napproach, providing insights for optimizing model performance. We believe our\nwork will inspire future research on multimodal information extraction.",
            "author": [
                "Hao Wang",
                "Xiahua Chen",
                "Rui Wang",
                "Chenhui Chu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14785v1",
                "http://arxiv.org/pdf/2310.14785v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14784v2",
            "title": "An Efficient Imbalance-Aware Federated Learning Approach for Wearable\n  Healthcare with Autoregressive Ratio Observation",
            "updated": "2023-10-30T09:17:55Z",
            "published": "2023-10-23T10:36:52Z",
            "summary": "Widely available healthcare services are now getting popular because of\nadvancements in wearable sensing techniques and mobile edge computing. People's\nhealth information is collected by edge devices such as smartphones and\nwearable bands for further analysis on servers, then send back suggestions and\nalerts for abnormal conditions. The recent emergence of federated learning\nallows users to train private data on local devices while updating models\ncollaboratively. However, the heterogeneous distribution of the health\ncondition data may lead to significant risks to model performance due to class\nimbalance. Meanwhile, as FL training is powered by sharing gradients only with\nthe server, training data is almost inaccessible. The conventional solutions to\nclass imbalance do not work for federated learning. In this work, we propose a\nnew federated learning framework FedImT, dedicated to addressing the challenges\nof class imbalance in federated learning scenarios. FedImT contains an online\nscheme that can estimate the data composition during each round of aggregation,\nthen introduces a self-attenuating iterative equivalent to track variations of\nmultiple estimations and promptly tweak the balance of the loss computing for\nminority classes. Experiments demonstrate the effectiveness of FedImT in\nsolving the imbalance problem without extra energy consumption and avoiding\nprivacy risks.",
            "author": [
                "Wenhao Yan",
                "He Li",
                "Kaoru Ota",
                "Mianxiong Dong"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14784v2",
                "http://arxiv.org/pdf/2310.14784v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14778v1",
            "title": "Audio-Visual Speaker Tracking: Progress, Challenges, and Future\n  Directions",
            "updated": "2023-10-23T10:29:33Z",
            "published": "2023-10-23T10:29:33Z",
            "summary": "Audio-visual speaker tracking has drawn increasing attention over the past\nfew years due to its academic values and wide application. Audio and visual\nmodalities can provide complementary information for localization and tracking.\nWith audio and visual information, the Bayesian-based filter can solve the\nproblem of data association, audio-visual fusion and track management. In this\npaper, we conduct a comprehensive overview of audio-visual speaker tracking. To\nour knowledge, this is the first extensive survey over the past five years. We\nintroduce the family of Bayesian filters and summarize the methods for\nobtaining audio-visual measurements. In addition, the existing trackers and\ntheir performance on AV16.3 dataset are summarized. In the past few years, deep\nlearning techniques have thrived, which also boosts the development of audio\nvisual speaker tracking. The influence of deep learning techniques in terms of\nmeasurement extraction and state estimation is also discussed. At last, we\ndiscuss the connections between audio-visual speaker tracking and other areas\nsuch as speech separation and distributed speaker tracking.",
            "author": [
                "Jinzheng Zhao",
                "Yong Xu",
                "Xinyuan Qian",
                "Davide Berghi",
                "Peipei Wu",
                "Meng Cui",
                "Jianyuan Sun",
                "Philip J. B. Jackson",
                "Wenwu Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14778v1",
                "http://arxiv.org/pdf/2310.14778v1"
            ],
            "primary_category": "cs.MM",
            "category": [
                "cs.MM",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14777v1",
            "title": "Geographical Erasure in Language Generation",
            "updated": "2023-10-23T10:26:14Z",
            "published": "2023-10-23T10:26:14Z",
            "summary": "Large language models (LLMs) encode vast amounts of world knowledge. However,\nsince these models are trained on large swaths of internet data, they are at\nrisk of inordinately capturing information about dominant groups. This\nimbalance can propagate into generated language. In this work, we study and\noperationalise a form of geographical erasure, wherein language models\nunderpredict certain countries. We demonstrate consistent instances of erasure\nacross a range of LLMs. We discover that erasure strongly correlates with low\nfrequencies of country mentions in the training corpus. Lastly, we mitigate\nerasure by finetuning using a custom objective.",
            "author": [
                "Pola Schw\u00f6bel",
                "Jacek Golebiowski",
                "Michele Donini",
                "C\u00e9dric Archambeau",
                "Danish Pruthi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14777v1",
                "http://arxiv.org/pdf/2310.14777v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15204v1",
            "title": "Mid-Long Term Daily Electricity Consumption Forecasting Based on\n  Piecewise Linear Regression and Dilated Causal CNN",
            "updated": "2023-10-23T10:22:38Z",
            "published": "2023-10-23T10:22:38Z",
            "summary": "Daily electricity consumption forecasting is a classical problem. Existing\nforecasting algorithms tend to have decreased accuracy on special dates like\nholidays. This study decomposes the daily electricity consumption series into\nthree components: trend, seasonal, and residual, and constructs a two-stage\nprediction method using piecewise linear regression as a filter and Dilated\nCausal CNN as a predictor. The specific steps involve setting breakpoints on\nthe time axis and fitting the piecewise linear regression model with one-hot\nencoded information such as month, weekday, and holidays. For the challenging\nprediction of the Spring Festival, distance is introduced as a variable using a\nthird-degree polynomial form in the model. The residual sequence obtained in\nthe previous step is modeled using Dilated Causal CNN, and the final prediction\nof daily electricity consumption is the sum of the two-stage predictions.\nExperimental results demonstrate that this method achieves higher accuracy\ncompared to existing approaches.",
            "author": [
                "Zhou Lan",
                "Ben Liu",
                "Yi Feng",
                "Danhuang Dong",
                "Peng Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15204v1",
                "http://arxiv.org/pdf/2310.15204v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14774v1",
            "title": "Principled Approaches for Learning to Defer with Multiple Experts",
            "updated": "2023-10-23T10:19:09Z",
            "published": "2023-10-23T10:19:09Z",
            "summary": "We present a study of surrogate losses and algorithms for the general problem\nof learning to defer with multiple experts. We first introduce a new family of\nsurrogate losses specifically tailored for the multiple-expert setting, where\nthe prediction and deferral functions are learned simultaneously. We then prove\nthat these surrogate losses benefit from strong $H$-consistency bounds. We\nillustrate the application of our analysis through several examples of\npractical surrogate losses, for which we give explicit guarantees. These loss\nfunctions readily lead to the design of new learning to defer algorithms based\non their minimization. While the main focus of this work is a theoretical\nanalysis, we also report the results of several experiments on SVHN and\nCIFAR-10 datasets.",
            "author": [
                "Anqi Mao",
                "Mehryar Mohri",
                "Yutao Zhong"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14774v1",
                "http://arxiv.org/pdf/2310.14774v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14772v1",
            "title": "Predictor-Rejector Multi-Class Abstention: Theoretical Analysis and\n  Algorithms",
            "updated": "2023-10-23T10:16:27Z",
            "published": "2023-10-23T10:16:27Z",
            "summary": "We study the key framework of learning with abstention in the multi-class\nclassification setting. In this setting, the learner can choose to abstain from\nmaking a prediction with some pre-defined cost. We present a series of new\ntheoretical and algorithmic results for this learning problem in the\npredictor-rejector framework. We introduce several new families of surrogate\nlosses for which we prove strong non-asymptotic and hypothesis set-specific\nconsistency guarantees, thereby resolving positively two existing open\nquestions. These guarantees provide upper bounds on the estimation error of the\nabstention loss function in terms of that of the surrogate loss. We analyze\nboth a single-stage setting where the predictor and rejector are learned\nsimultaneously and a two-stage setting crucial in applications, where the\npredictor is learned in a first stage using a standard surrogate loss such as\ncross-entropy. These guarantees suggest new multi-class abstention algorithms\nbased on minimizing these surrogate losses. We also report the results of\nextensive experiments comparing these algorithms to the current\nstate-of-the-art algorithms on CIFAR-10, CIFAR-100 and SVHN datasets. Our\nresults demonstrate empirically the benefit of our new surrogate losses and\nshow the remarkable performance of our broadly applicable two-stage abstention\nalgorithm.",
            "author": [
                "Anqi Mao",
                "Mehryar Mohri",
                "Yutao Zhong"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14772v1",
                "http://arxiv.org/pdf/2310.14772v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14770v1",
            "title": "Theoretically Grounded Loss Functions and Algorithms for Score-Based\n  Multi-Class Abstention",
            "updated": "2023-10-23T10:13:35Z",
            "published": "2023-10-23T10:13:35Z",
            "summary": "Learning with abstention is a key scenario where the learner can abstain from\nmaking a prediction at some cost. In this paper, we analyze the score-based\nformulation of learning with abstention in the multi-class classification\nsetting. We introduce new families of surrogate losses for the abstention loss\nfunction, which include the state-of-the-art surrogate losses in the\nsingle-stage setting and a novel family of loss functions in the two-stage\nsetting. We prove strong non-asymptotic and hypothesis set-specific consistency\nguarantees for these surrogate losses, which upper-bound the estimation error\nof the abstention loss function in terms of the estimation error of the\nsurrogate loss. Our bounds can help compare different score-based surrogates\nand guide the design of novel abstention algorithms by minimizing the proposed\nsurrogate losses. We experimentally evaluate our new algorithms on CIFAR-10,\nCIFAR-100, and SVHN datasets and the practical significance of our new\nsurrogate losses and two-stage abstention algorithms. Our results also show\nthat the relative performance of the state-of-the-art score-based surrogate\nlosses can vary across datasets.",
            "author": [
                "Anqi Mao",
                "Mehryar Mohri",
                "Yutao Zhong"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14770v1",
                "http://arxiv.org/pdf/2310.14770v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14769v1",
            "title": "An introduction to radar Automatic Target Recognition (ATR) technology\n  in ground-based radar systems",
            "updated": "2023-10-23T10:13:02Z",
            "published": "2023-10-23T10:13:02Z",
            "summary": "This paper presents a brief examination of Automatic Target Recognition (ATR)\ntechnology within ground-based radar systems. It offers a lucid comprehension\nof the ATR concept, delves into its historical milestones, and categorizes ATR\nmethods according to different scattering regions. By incorporating ATR\nsolutions into radar systems, this study demonstrates the expansion of radar\ndetection ranges and the enhancement of tracking capabilities, leading to\nsuperior situational awareness. Drawing insights from the Russo-Ukrainian War,\nthe paper highlights three pressing radar applications that urgently\nnecessitate ATR technology: detecting stealth aircraft, countering small\ndrones, and implementing anti-jamming measures. Anticipating the next wave of\nradar ATR research, the study predicts a surge in cognitive radar and machine\nlearning (ML)-driven algorithms. These emerging methodologies aspire to\nconfront challenges associated with system adaptation, real-time recognition,\nand environmental adaptability. Ultimately, ATR stands poised to revolutionize\nconventional radar systems, ushering in an era of 4D sensing capabilities.",
            "author": [
                "Jiangkun Gong",
                "Jun Yan",
                "Deyong Kong",
                "Deren Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14769v1",
                "http://arxiv.org/pdf/2310.14769v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14768v2",
            "title": "Policy Gradient with Kernel Quadrature",
            "updated": "2023-12-05T11:43:54Z",
            "published": "2023-10-23T10:12:23Z",
            "summary": "Reward evaluation of episodes becomes a bottleneck in a broad range of\nreinforcement learning tasks. Our aim in this paper is to select a small but\nrepresentative subset of a large batch of episodes, only on which we actually\ncompute rewards for more efficient policy gradient iterations. We build a\nGaussian process modeling of discounted returns or rewards to derive a positive\ndefinite kernel on the space of episodes, run an ``episodic\" kernel quadrature\nmethod to compress the information of sample episodes, and pass the reduced\nepisodes to the policy network for gradient updates. We present the theoretical\nbackground of this procedure as well as its numerical illustrations in MuJoCo\ntasks.",
            "author": [
                "Satoshi Hayakawa",
                "Tetsuro Morimura"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14768v2",
                "http://arxiv.org/pdf/2310.14768v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14766v1",
            "title": "End-to-End Learning of Behavioural Inputs for Autonomous Driving in\n  Dense Traffic",
            "updated": "2023-10-23T10:06:13Z",
            "published": "2023-10-23T10:06:13Z",
            "summary": "Trajectory sampling in the Frenet(road-aligned) frame, is one of the most\npopular methods for motion planning of autonomous vehicles. It operates by\nsampling a set of behavioural inputs, such as lane offset and forward speed,\nbefore solving a trajectory optimization problem conditioned on the sampled\ninputs. The sampling is handcrafted based on simple heuristics, does not adapt\nto driving scenarios, and is oblivious to the capabilities of downstream\ntrajectory planners. In this paper, we propose an end-to-end learning of\nbehavioural input distribution from expert demonstrations or in a\nself-supervised manner. Our core novelty lies in embedding a custom\ndifferentiable trajectory optimizer as a layer in neural networks, allowing us\nto update behavioural inputs by considering the optimizer's feedback. Moreover,\nour end-to-end approach also ensures that the learned behavioural inputs aid\nthe convergence of the optimizer. We improve the state-of-the-art in the\nfollowing aspects. First, we show that learned behavioural inputs substantially\ndecrease collision rate while improving driving efficiency over handcrafted\napproaches. Second, our approach outperforms model predictive control methods\nbased on sampling-based optimization.",
            "author": [
                "Jatan Shrestha",
                "Simon Idoko",
                "Basant Sharma",
                "Arun Kumar Singh"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14766v1",
                "http://arxiv.org/pdf/2310.14766v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14764v1",
            "title": "Improved K-mer Based Prediction of Protein-Protein Interactions With\n  Chaos Game Representation, Deep Learning and Reduced Representation Bias",
            "updated": "2023-10-23T10:02:23Z",
            "published": "2023-10-23T10:02:23Z",
            "summary": "Protein-protein interactions drive many biological processes, including the\ndetection of phytopathogens by plants' R-Proteins and cell surface receptors.\nMany machine learning studies have attempted to predict protein-protein\ninteractions but performance is highly dependent on training data; models have\nbeen shown to accurately predict interactions when the proteins involved are\nincluded in the training data, but achieve consistently poorer results when\napplied to previously unseen proteins. In addition, models that are trained\nusing proteins that take part in multiple interactions can suffer from\nrepresentation bias, where predictions are driven not by learned biological\nfeatures but by learning of the structure of the interaction dataset.\n  We present a method for extracting unique pairs from an interaction dataset,\ngenerating non-redundant paired data for unbiased machine learning. After\napplying the method to datasets containing _Arabidopsis thaliana_ and pathogen\neffector interations, we developed a convolutional neural network model capable\nof learning and predicting interactions from Chaos Game Representations of\nproteins' coding genes.",
            "author": [
                "Ruth Veevers",
                "Dan MacLean"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14764v1",
                "http://arxiv.org/pdf/2310.14764v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14763v1",
            "title": "Externally Valid Policy Evaluation Combining Trial and Observational\n  Data",
            "updated": "2023-10-23T10:01:50Z",
            "published": "2023-10-23T10:01:50Z",
            "summary": "Randomized trials are widely considered as the gold standard for evaluating\nthe effects of decision policies. Trial data is, however, drawn from a\npopulation which may differ from the intended target population and this raises\na problem of external validity (aka. generalizability). In this paper we seek\nto use trial data to draw valid inferences about the outcome of a policy on the\ntarget population. Additional covariate data from the target population is used\nto model the sampling of individuals in the trial study. We develop a method\nthat yields certifiably valid trial-based policy evaluations under any\nspecified range of model miscalibrations. The method is nonparametric and the\nvalidity is assured even with finite samples. The certified policy evaluations\nare illustrated using both simulated and real data.",
            "author": [
                "Sofia Ek",
                "Dave Zachariah"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14763v1",
                "http://arxiv.org/pdf/2310.14763v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14753v1",
            "title": "Rethinking Tokenizer and Decoder in Masked Graph Modeling for Molecules",
            "updated": "2023-10-23T09:40:30Z",
            "published": "2023-10-23T09:40:30Z",
            "summary": "Masked graph modeling excels in the self-supervised representation learning\nof molecular graphs. Scrutinizing previous studies, we can reveal a common\nscheme consisting of three key components: (1) graph tokenizer, which breaks a\nmolecular graph into smaller fragments (i.e., subgraphs) and converts them into\ntokens; (2) graph masking, which corrupts the graph with masks; (3) graph\nautoencoder, which first applies an encoder on the masked graph to generate the\nrepresentations, and then employs a decoder on the representations to recover\nthe tokens of the original graph. However, the previous MGM studies focus\nextensively on graph masking and encoder, while there is limited understanding\nof tokenizer and decoder. To bridge the gap, we first summarize popular\nmolecule tokenizers at the granularity of node, edge, motif, and Graph Neural\nNetworks (GNNs), and then examine their roles as the MGM's reconstruction\ntargets. Further, we explore the potential of adopting an expressive decoder in\nMGM. Our results show that a subgraph-level tokenizer and a sufficiently\nexpressive decoder with remask decoding have a large impact on the encoder's\nrepresentation learning. Finally, we propose a novel MGM method SimSGT,\nfeaturing a Simple GNN-based Tokenizer (SGT) and an effective decoding\nstrategy. We empirically validate that our method outperforms the existing\nmolecule self-supervised learning methods. Our codes and checkpoints are\navailable at https://github.com/syr-cn/SimSGT.",
            "author": [
                "Zhiyuan Liu",
                "Yaorui Shi",
                "An Zhang",
                "Enzhi Zhang",
                "Kenji Kawaguchi",
                "Xiang Wang",
                "Tat-Seng Chua"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14753v1",
                "http://arxiv.org/pdf/2310.14753v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14751v1",
            "title": "Efficient and Interpretable Bandit Algorithms",
            "updated": "2023-10-23T09:36:13Z",
            "published": "2023-10-23T09:36:13Z",
            "summary": "Motivated by the importance of explainability in modern machine learning, we\ndesign bandit algorithms that are \\emph{efficient} and \\emph{interpretable}. A\nbandit algorithm is interpretable if it explores with the objective of reducing\nuncertainty in the unknown model parameter. To quantify the interpretability,\nwe introduce a novel metric of \\textit{uncertainty loss}, which compares the\nrate of the uncertainty reduction to the theoretical optimum. We propose CODE,\na bandit algorithm based on a \\textbf{C}onstrained \\textbf{O}ptimal\n\\textbf{DE}sign, that is interpretable and maximally reduces the uncertainty.\nThe key idea in \\code is to explore among all plausible actions, determined by\na statistical constraint, to achieve interpretability. We implement CODE\nefficiently in both multi-armed and linear bandits and derive near-optimal\nregret bounds by leveraging the optimality criteria of the approximate optimal\ndesign. CODE can be also viewed as removing phases in conventional phased\nelimination, which makes it more practical and general. We demonstrate the\nadvantage of \\code by numerical experiments on both synthetic and real-world\nproblems. CODE outperforms other state-of-the-art interpretable designs while\nmatching the performance of popular but uninterpretable designs, such as upper\nconfidence bound algorithms.",
            "author": [
                "Subhojyoti Mukherjee",
                "Ruihao Zhu",
                "Branislav Kveton"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14751v1",
                "http://arxiv.org/pdf/2310.14751v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14749v1",
            "title": "Exploring hierarchical framework of nonlinear sparse Bayesian learning\n  algorithm through numerical investigations",
            "updated": "2023-10-23T09:34:45Z",
            "published": "2023-10-23T09:34:45Z",
            "summary": "Sparse Bayesian learning (SBL) has been extensively utilized in data-driven\nmodeling to combat the issue of overfitting. While SBL excels in\nlinear-in-parameter models, its direct applicability is limited in models where\nobservations possess nonlinear relationships with unknown parameters. Recently,\na semi-analytical Bayesian framework known as nonlinear sparse Bayesian\nlearning (NSBL) was introduced by the authors to induce sparsity among model\nparameters during the Bayesian inversion of nonlinear-in-parameter models. NSBL\nrelies on optimally selecting the hyperparameters of sparsity-inducing Gaussian\npriors. It is inherently an approximate method since the uncertainty in the\nhyperparameter posterior is disregarded as we instead seek the maximum a\nposteriori (MAP) estimate of the hyperparameters (type-II MAP estimate). This\npaper aims to investigate the hierarchical structure that forms the basis of\nNSBL and validate its accuracy through a comparison with a one-level\nhierarchical Bayesian inference as a benchmark in the context of three\nnumerical experiments: (i) a benchmark linear regression example with Gaussian\nprior and Gaussian likelihood, (ii) the same regression problem with a highly\nnon-Gaussian prior, and (iii) an example of a dynamical system with a\nnon-Gaussian prior and a highly non-Gaussian likelihood function, to explore\nthe performance of the algorithm in these new settings. Through these numerical\nexamples, it can be shown that NSBL is well-suited for physics-based models as\nit can be readily applied to models with non-Gaussian prior distributions and\nnon-Gaussian likelihood functions. Moreover, we illustrate the accuracy of the\nNSBL algorithm as an approximation to the one-level hierarchical Bayesian\ninference and its ability to reduce the computational cost while adequately\nexploring the parameter posteriors.",
            "author": [
                "Nastaran Dabiran",
                "Brandon Robinson",
                "Rimple Sandhu",
                "Mohammad Khalil",
                "Chris L. Pettit",
                "Dominique Poirel",
                "Abhijit Sarkar"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14749v1",
                "http://arxiv.org/pdf/2310.14749v1"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14748v1",
            "title": "A Comparative Study of Portfolio Optimization Methods for the Indian\n  Stock Market",
            "updated": "2023-10-23T09:33:40Z",
            "published": "2023-10-23T09:33:40Z",
            "summary": "This chapter presents a comparative study of the three portfolio optimization\nmethods, MVP, HRP, and HERC, on the Indian stock market, particularly focusing\non the stocks chosen from 15 sectors listed on the National Stock Exchange of\nIndia. The top stocks of each cluster are identified based on their free-float\nmarket capitalization from the report of the NSE published on July 1, 2022 (NSE\nWebsite). For each sector, three portfolios are designed on stock prices from\nJuly 1, 2019, to June 30, 2022, following three portfolio optimization\napproaches. The portfolios are tested over the period from July 1, 2022, to\nJune 30, 2023. For the evaluation of the performances of the portfolios, three\nmetrics are used. These three metrics are cumulative returns, annual\nvolatilities, and Sharpe ratios. For each sector, the portfolios that yield the\nhighest cumulative return, the lowest volatility, and the maximum Sharpe Ratio\nover the training and the test periods are identified.",
            "author": [
                "Jaydip Sen",
                "Arup Dasgupta",
                "Partha Pratim Sengupta",
                "Sayantani Roy Choudhury"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14748v1",
                "http://arxiv.org/pdf/2310.14748v1"
            ],
            "primary_category": "q-fin.PM",
            "category": [
                "q-fin.PM",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14743v1",
            "title": "The Safety Challenges of Deep Learning in Real-World Type 1 Diabetes\n  Management",
            "updated": "2023-10-23T09:25:50Z",
            "published": "2023-10-23T09:25:50Z",
            "summary": "Blood glucose simulation allows the effectiveness of type 1 diabetes (T1D)\nmanagement strategies to be evaluated without patient harm. Deep learning\nalgorithms provide a promising avenue for extending simulator capabilities;\nhowever, these algorithms are limited in that they do not necessarily learn\nphysiologically correct glucose dynamics and can learn incorrect and\npotentially dangerous relationships from confounders in training data. This is\nlikely to be more important in real-world scenarios, as data is not collected\nunder strict research protocol. This work explores the implications of using\ndeep learning algorithms trained on real-world data to model glucose dynamics.\nFree-living data was processed from the OpenAPS Data Commons and supplemented\nwith patient-reported tags of challenging diabetes events, constituting one of\nthe most detailed real-world T1D datasets. This dataset was used to train and\nevaluate state-of-the-art glucose simulators, comparing their prediction error\nacross safety critical scenarios and assessing the physiological\nappropriateness of the learned dynamics using Shapley Additive Explanations\n(SHAP). While deep learning prediction accuracy surpassed the widely-used\nmathematical simulator approach, the model deteriorated in safety critical\nscenarios and struggled to leverage self-reported meal and exercise\ninformation. SHAP value analysis also indicated the model had fundamentally\nconfused the roles of insulin and carbohydrates, which is one of the most basic\nT1D management principles. This work highlights the importance of considering\nphysiological appropriateness when using deep learning to model real-world\nsystems in T1D and healthcare more broadly, and provides recommendations for\nbuilding models that are robust to real-world data constraints.",
            "author": [
                "Harry Emerson",
                "Ryan McConville",
                "Matthew Guy"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14743v1",
                "http://arxiv.org/pdf/2310.14743v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15859v1",
            "title": "A Fermi-LAT Study of Globular Cluster Dynamical Evolution in Milky Way\n  Galaxy: Millisecond Pulsars as the Probe",
            "updated": "2023-10-23T09:24:55Z",
            "published": "2023-10-23T09:24:55Z",
            "summary": "Using archival {\\it Fermi}-LAT data with a time span of $\\sim12$ years, we\nstudy the population of Millisecond Pulsars (MSPs) in Globular Clusters (GlCs)\nand investigate their dependence on cluster dynamical evolution in the Milky\nWay Galaxy. We show that the $\\gamma$-ray luminosity ($L_{\\gamma}$) and\nemissivity ($\\epsilon_{\\gamma}=L_{\\gamma}/M$) are good indicators of the\npopulation and abundance of MSPs in GlCs, and they are highly dependent on the\ndynamical evolution history of the host clusters. Specifically speaking, the\ndynamically older GlCs with more compact structures are more likely to have\nlarger $L_{\\gamma}$ and $\\epsilon_{\\gamma}$, and these trends can be summarized\nas strong correlations with cluster stellar encounter rate $\\Gamma$ and the\nspecific encounter rate ($\\Lambda=\\Gamma/M$), with $L_{\\gamma}\\propto\n\\Gamma^{0.70\\pm0.11}$ and $\\epsilon_{\\gamma}\\propto \\Lambda^{0.73\\pm0.13}$ for\ndynamically normal GlCs. However, as GlCs evolve into deep core collapse, these\ntrends are found to be reversed, implying that strong encounters may have lead\nto the ejection of MSPs from core-collapsed Systems. Besides, the GlCs are\nfound to exhibit larger $\\epsilon_{\\gamma}$ with increasing stellar mass\nfunction slope, decreasing tidal radius and distances from the Galactic Center\n(GC). These correlations indicate that, as GlCs losing kinetic energy and\nspiral in towards GC, tidal stripping and mass segregation have a preference in\nleading to the loss of normal stars from GlCs, while MSPs are more likely to\nconcentrate to cluster center and be deposited into the GC. Moreover, we gauge\n$\\epsilon_{\\gamma}$ of GlCs is $\\sim10-1000$ times larger than the Galactic\nbulge, the latter is thought to reside thousands of unresolved MSPs and may\nresponsible for the GC $\\gamma$-ray excess, which support that GlCs are\ngenerous contributors to the population of MSPs in the GC.",
            "author": [
                "Li Feng",
                "Zhongqun Cheng",
                "Wei Wang",
                "Zhiyuan Li",
                "Yang Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15859v1",
                "http://arxiv.org/pdf/2310.15859v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA",
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14736v2",
            "title": "SAMCLR: Contrastive pre-training on complex scenes using SAM for view\n  sampling",
            "updated": "2023-10-29T03:57:18Z",
            "published": "2023-10-23T09:16:04Z",
            "summary": "In Computer Vision, self-supervised contrastive learning enforces similar\nrepresentations between different views of the same image. The pre-training is\nmost often performed on image classification datasets, like ImageNet, where\nimages mainly contain a single class of objects. However, when dealing with\ncomplex scenes with multiple items, it becomes very unlikely for several views\nof the same image to represent the same object category. In this setting, we\npropose SAMCLR, an add-on to SimCLR which uses SAM to segment the image into\nsemantic regions, then sample the two views from the same region. Preliminary\nresults show empirically that when pre-training on Cityscapes and ADE20K, then\nevaluating on classification on CIFAR-10, STL10 and ImageNette, SAMCLR performs\nat least on par with, and most often significantly outperforms not only SimCLR,\nbut also DINO and MoCo.",
            "author": [
                "Benjamin Missaoui",
                "Chongbin Yuan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14736v2",
                "http://arxiv.org/pdf/2310.14736v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15202v1",
            "title": "Predicting Transcription Factor Binding Sites using Transformer based\n  Capsule Network",
            "updated": "2023-10-23T09:08:57Z",
            "published": "2023-10-23T09:08:57Z",
            "summary": "Prediction of binding sites for transcription factors is important to\nunderstand how they regulate gene expression and how this regulation can be\nmodulated for therapeutic purposes. Although in the past few years there are\nsignificant works addressing this issue, there is still space for improvement.\nIn this regard, a transformer based capsule network viz. DNABERT-Cap is\nproposed in this work to predict transcription factor binding sites mining\nChIP-seq datasets. DNABERT-Cap is a bidirectional encoder pre-trained with\nlarge number of genomic DNA sequences, empowered with a capsule layer\nresponsible for the final prediction. The proposed model builds a predictor for\ntranscription factor binding sites using the joint optimisation of features\nencompassing both bidirectional encoder and capsule layer, along with\nconvolutional and bidirectional long-short term memory layers. To evaluate the\nefficiency of the proposed approach, we use a benchmark ChIP-seq datasets of\nfive cell lines viz. A549, GM12878, Hep-G2, H1-hESC and Hela, available in the\nENCODE repository. The results show that the average area under the receiver\noperating characteristic curve score exceeds 0.91 for all such five cell lines.\nDNABERT-Cap is also compared with existing state-of-the-art deep learning based\npredictors viz. DeepARC, DeepTF, CNN-Zeng and DeepBind, and is seen to\noutperform them.",
            "author": [
                "Nimisha Ghosh",
                "Daniele Santoni",
                "Indrajit Saha",
                "Giovanni Felici"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15202v1",
                "http://arxiv.org/pdf/2310.15202v1"
            ],
            "primary_category": "q-bio.GN",
            "category": [
                "q-bio.GN",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14732v1",
            "title": "Generating Prototypes for Contradiction Detection Using Large Language\n  Models and Linguistic Rules",
            "updated": "2023-10-23T09:07:27Z",
            "published": "2023-10-23T09:07:27Z",
            "summary": "We introduce a novel data generation method for contradiction detection,\nwhich leverages the generative power of large language models as well as\nlinguistic rules. Our vision is to provide a condensed corpus of prototypical\ncontradictions, allowing for in-depth linguistic analysis as well as efficient\nlanguage model fine-tuning. To this end, we instruct the generative models to\ncreate contradicting statements with respect to descriptions of specific\ncontradiction types. In addition, the model is also instructed to come up with\ncompletely new contradiction typologies. As an auxiliary approach, we use\nlinguistic rules to construct simple contradictions such as those arising from\nnegation, antonymy and numeric mismatch. We find that our methods yield\npromising results in terms of coherence and variety of the data. Further\nstudies, as well as manual refinement are necessary to make use of this data in\na machine learning setup.",
            "author": [
                "Maren Pielka",
                "Svetlana Schmidt",
                "Rafet Sifa"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14732v1",
                "http://arxiv.org/pdf/2310.14732v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14725v1",
            "title": "On Learning Polynomial Recursive Programs",
            "updated": "2023-10-23T09:02:11Z",
            "published": "2023-10-23T09:02:11Z",
            "summary": "We introduce the class of P-finite automata. These are a generalisation of\nweighted automata, in which the weights of transitions can depend polynomially\non the length of the input word. P-finite automata can also be viewed as simple\ntail-recursive programs in which the arguments of recursive calls can\nnon-linearly refer to a variable that counts the number of recursive calls. The\nnomenclature is motivated by the fact that over a unary alphabet P-finite\nautomata compute so-called P-finite sequences, that is, sequences that satisfy\na linear recurrence with polynomial coefficients. Our main result shows that\nP-finite automata can be learned in polynomial time in Angluin's MAT exact\nlearning model. This generalises the classical results that deterministic\nfinite automata and weighted automata over a field are respectively\npolynomial-time learnable in the MAT model.",
            "author": [
                "Alex Buna-Marginean",
                "Vincent Cheval",
                "Mahsa Shirmohammadi",
                "James Worrell"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14725v1",
                "http://arxiv.org/pdf/2310.14725v1"
            ],
            "primary_category": "cs.LO",
            "category": [
                "cs.LO",
                "cs.FL",
                "cs.PL",
                "F.3.1; F.4.3; F.4.1; F.1.1"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14724v2",
            "title": "A Survey on LLM-generated Text Detection: Necessity, Methods, and Future\n  Directions",
            "updated": "2023-10-24T11:31:38Z",
            "published": "2023-10-23T09:01:13Z",
            "summary": "The powerful ability to understand, follow, and generate complex language\nemerging from large language models (LLMs) makes LLM-generated text flood many\nareas of our daily lives at an incredible speed and is widely accepted by\nhumans. As LLMs continue to expand, there is an imperative need to develop\ndetectors that can detect LLM-generated text. This is crucial to mitigate\npotential misuse of LLMs and safeguard realms like artistic expression and\nsocial networks from harmful influence of LLM-generated content. The\nLLM-generated text detection aims to discern if a piece of text was produced by\nan LLM, which is essentially a binary classification task. The detector\ntechniques have witnessed notable advancements recently, propelled by\ninnovations in watermarking techniques, zero-shot methods, fine-turning LMs\nmethods, adversarial learning methods, LLMs as detectors, and human-assisted\nmethods. In this survey, we collate recent research breakthroughs in this area\nand underscore the pressing need to bolster detector research. We also delve\ninto prevalent datasets, elucidating their limitations and developmental\nrequirements. Furthermore, we analyze various LLM-generated text detection\nparadigms, shedding light on challenges like out-of-distribution problems,\npotential attacks, and data ambiguity. Conclusively, we highlight interesting\ndirections for future research in LLM-generated text detection to advance the\nimplementation of responsible artificial intelligence (AI). Our aim with this\nsurvey is to provide a clear and comprehensive introduction for newcomers while\nalso offering seasoned researchers a valuable update in the field of\nLLM-generated text detection. The useful resources are publicly available at:\nhttps://github.com/NLP2CT/LLM-generated-Text-Detection.",
            "author": [
                "Junchao Wu",
                "Shu Yang",
                "Runzhe Zhan",
                "Yulin Yuan",
                "Derek F. Wong",
                "Lidia S. Chao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14724v2",
                "http://arxiv.org/pdf/2310.14724v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14720v1",
            "title": "Extended Deep Adaptive Input Normalization for Preprocessing Time Series\n  Data for Neural Networks",
            "updated": "2023-10-23T08:56:01Z",
            "published": "2023-10-23T08:56:01Z",
            "summary": "Data preprocessing is a crucial part of any machine learning pipeline, and it\ncan have a significant impact on both performance and training efficiency. This\nis especially evident when using deep neural networks for time series\nprediction and classification: real-world time series data often exhibit\nirregularities such as multi-modality, skewness and outliers, and the model\nperformance can degrade rapidly if these characteristics are not adequately\naddressed. In this work, we propose the EDAIN (Extended Deep Adaptive Input\nNormalization) layer, a novel adaptive neural layer that learns how to\nappropriately normalize irregular time series data for a given task in an\nend-to-end fashion, instead of using a fixed normalization scheme. This is\nachieved by optimizing its unknown parameters simultaneously with the deep\nneural network using back-propagation. Our experiments, conducted using\nsynthetic data, a credit default prediction dataset, and a large-scale limit\norder book benchmark dataset, demonstrate the superior performance of the EDAIN\nlayer when compared to conventional normalization methods and existing adaptive\ntime series preprocessing layers.",
            "author": [
                "Marcus A. K. September",
                "Francesco Sanna Passino",
                "Leonie Goldmann",
                "Anton Hinel"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14720v1",
                "http://arxiv.org/pdf/2310.14720v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14718v1",
            "title": "Rethinking Scale Imbalance in Semi-supervised Object Detection for\n  Aerial Images",
            "updated": "2023-10-23T08:55:10Z",
            "published": "2023-10-23T08:55:10Z",
            "summary": "This paper focuses on the scale imbalance problem of semi-supervised object\ndetection(SSOD) in aerial images. Compared to natural images, objects in aerial\nimages show smaller sizes and larger quantities per image, increasing the\ndifficulty of manual annotation. Meanwhile, the advanced SSOD technique can\ntrain superior detectors by leveraging limited labeled data and massive\nunlabeled data, saving annotation costs. However, as an understudied task in\naerial images, SSOD suffers from a drastic performance drop when facing a large\nproportion of small objects. By analyzing the predictions between small and\nlarge objects, we identify three imbalance issues caused by the scale bias,\ni.e., pseudo-label imbalance, label assignment imbalance, and negative learning\nimbalance. To tackle these issues, we propose a novel Scale-discriminative\nSemi-Supervised Object Detection (S^3OD) learning pipeline for aerial images.\nIn our S^3OD, three key components, Size-aware Adaptive Thresholding (SAT),\nSize-rebalanced Label Assignment (SLA), and Teacher-guided Negative Learning\n(TNL), are proposed to warrant scale unbiased learning. Specifically, SAT\nadaptively selects appropriate thresholds to filter pseudo-labels for objects\nat different scales. SLA balances positive samples of objects at different\nscales through resampling and reweighting. TNL alleviates the imbalance in\nnegative samples by leveraging information generated by a teacher model.\nExtensive experiments conducted on the DOTA-v1.5 benchmark demonstrate the\nsuperiority of our proposed methods over state-of-the-art competitors. Codes\nwill be released soon.",
            "author": [
                "Ruixiang Zhang",
                "Chang Xu",
                "Fang Xu",
                "Wen Yang",
                "Guangjun He",
                "Huai Yu",
                "Gui-Song Xia"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14718v1",
                "http://arxiv.org/pdf/2310.14718v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14714v3",
            "title": "BatteryML:An Open-source platform for Machine Learning on Battery\n  Degradation",
            "updated": "2023-12-04T13:23:46Z",
            "published": "2023-10-23T08:51:05Z",
            "summary": "Battery degradation remains a pivotal concern in the energy storage domain,\nwith machine learning emerging as a potent tool to drive forward insights and\nsolutions. However, this intersection of electrochemical science and machine\nlearning poses complex challenges. Machine learning experts often grapple with\nthe intricacies of battery science, while battery researchers face hurdles in\nadapting intricate models tailored to specific datasets. Beyond this, a\ncohesive standard for battery degradation modeling, inclusive of data formats\nand evaluative benchmarks, is conspicuously absent. Recognizing these\nimpediments, we present BatteryML - a one-step, all-encompass, and open-source\nplatform designed to unify data preprocessing, feature extraction, and the\nimplementation of both traditional and state-of-the-art models. This\nstreamlined approach promises to enhance the practicality and efficiency of\nresearch applications. BatteryML seeks to fill this void, fostering an\nenvironment where experts from diverse specializations can collaboratively\ncontribute, thus elevating the collective understanding and advancement of\nbattery research.The code for our project is publicly available on GitHub at\nhttps://github.com/microsoft/BatteryML.",
            "author": [
                "Han Zhang",
                "Xiaofan Gui",
                "Shun Zheng",
                "Ziheng Lu",
                "Yuqi Li",
                "Jiang Bian"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14714v3",
                "http://arxiv.org/pdf/2310.14714v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "68T05"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14710v2",
            "title": "Random Forest Kernel for High-Dimension Low Sample Size Classification",
            "updated": "2023-11-17T08:01:34Z",
            "published": "2023-10-23T08:49:39Z",
            "summary": "High dimension, low sample size (HDLSS) problems are numerous among\nreal-world applications of machine learning. From medical images to text\nprocessing, traditional machine learning algorithms are usually unsuccessful in\nlearning the best possible concept from such data. In a previous work, we\nproposed a dissimilarity-based approach for multi-view classification, the\nRandom Forest Dissimilarity (RFD), that perfoms state-of-the-art results for\nsuch problems. In this work, we transpose the core principle of this approach\nto solving HDLSS classification problems, by using the RF similarity measure as\na learned precomputed SVM kernel (RFSVM). We show that such a learned\nsimilarity measure is particularly suited and accurate for this classification\ncontext. Experiments conducted on 40 public HDLSS classification datasets,\nsupported by rigorous statistical analyses, show that the RFSVM method\noutperforms existing methods for the majority of HDLSS problems and remains at\nthe same time very competitive for low or non-HDLSS problems.",
            "author": [
                "Lucca Portes Cavalheiro",
                "Simon Bernard",
                "Jean Paul Barddal",
                "Laurent Heutte"
            ],
            "link": [
                "http://dx.doi.org/10.1007/s11222-023-10309-0",
                "http://arxiv.org/abs/2310.14710v2",
                "http://arxiv.org/pdf/2310.14710v2"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14707v1",
            "title": "A Hybrid GNN approach for predicting node data for 3D meshes",
            "updated": "2023-10-23T08:47:27Z",
            "published": "2023-10-23T08:47:27Z",
            "summary": "Metal forging is used to manufacture dies. We require the best set of input\nparameters for the process to be efficient. Currently, we predict the best\nparameters using the finite element method by generating simulations for the\ndifferent initial conditions, which is a time-consuming process. In this paper,\nintroduce a hybrid approach that helps in processing and generating new data\nsimulations using a surrogate graph neural network model based on graph\nconvolutions, having a cheaper time cost. We also introduce a hybrid approach\nthat helps in processing and generating new data simulations using the model.\nGiven a dataset representing meshes, our focus is on the conversion of the\navailable information into a graph or point cloud structure. This new\nrepresentation enables deep learning. The predicted result is similar, with a\nlow error when compared to that produced using the finite element method. The\nnew models have outperformed existing PointNet and simple graph neural network\nmodels when applied to produce the simulations.",
            "author": [
                "Shwetha Salimath",
                "Francesca Bugiotti",
                "Frederic Magoules"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14707v1",
                "http://arxiv.org/pdf/2310.14707v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NA",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14702v2",
            "title": "BM2CP: Efficient Collaborative Perception with LiDAR-Camera Modalities",
            "updated": "2023-12-07T04:42:07Z",
            "published": "2023-10-23T08:45:12Z",
            "summary": "Collaborative perception enables agents to share complementary perceptual\ninformation with nearby agents. This would improve the perception performance\nand alleviate the issues of single-view perception, such as occlusion and\nsparsity. Most existing approaches mainly focus on single modality (especially\nLiDAR), and not fully exploit the superiority of multi-modal perception. We\npropose a collaborative perception paradigm, BM2CP, which employs LiDAR and\ncamera to achieve efficient multi-modal perception. It utilizes LiDAR-guided\nmodal fusion, cooperative depth generation and modality-guided intermediate\nfusion to acquire deep interactions among modalities of different agents,\nMoreover, it is capable to cope with the special case where one of the sensors,\nsame or different type, of any agent is missing. Extensive experiments validate\nthat our approach outperforms the state-of-the-art methods with 50X lower\ncommunication volumes in both simulated and real-world autonomous driving\nscenarios. Our code is available at https://github.com/byzhaoAI/BM2CP.",
            "author": [
                "Binyu Zhao",
                "Wei Zhang",
                "Zhaonian Zou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14702v2",
                "http://arxiv.org/pdf/2310.14702v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14695v1",
            "title": "CAwa-NeRF: Instant Learning of Compression-Aware NeRF Features",
            "updated": "2023-10-23T08:40:44Z",
            "published": "2023-10-23T08:40:44Z",
            "summary": "Modeling 3D scenes by volumetric feature grids is one of the promising\ndirections of neural approximations to improve Neural Radiance Fields (NeRF).\nInstant-NGP (INGP) introduced multi-resolution hash encoding from a lookup\ntable of trainable feature grids which enabled learning high-quality neural\ngraphics primitives in a matter of seconds. However, this improvement came at\nthe cost of higher storage size. In this paper, we address this challenge by\nintroducing instant learning of compression-aware NeRF features (CAwa-NeRF),\nthat allows exporting the zip compressed feature grids at the end of the model\ntraining with a negligible extra time overhead without changing neither the\nstorage architecture nor the parameters used in the original INGP paper.\nNonetheless, the proposed method is not limited to INGP but could also be\nadapted to any model. By means of extensive simulations, our proposed instant\nlearning pipeline can achieve impressive results on different kinds of static\nscenes such as single object masked background scenes and real-life scenes\ncaptured in our studio. In particular, for single object masked background\nscenes CAwa-NeRF compresses the feature grids down to 6% (1.2 MB) of the\noriginal size without any loss in the PSNR (33 dB) or down to 2.4% (0.53 MB)\nwith a slight virtual loss (32.31 dB).",
            "author": [
                "Omnia Mahmoud",
                "Th\u00e9o Ladune",
                "Matthieu Gendrin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14695v1",
                "http://arxiv.org/pdf/2310.14695v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14693v1",
            "title": "Federated learning compression designed for lightweight communications",
            "updated": "2023-10-23T08:36:21Z",
            "published": "2023-10-23T08:36:21Z",
            "summary": "Federated Learning (FL) is a promising distributed method for edge-level\nmachine learning, particularly for privacysensitive applications such as those\nin military and medical domains, where client data cannot be shared or\ntransferred to a cloud computing server. In many use-cases, communication cost\nis a major challenge in FL due to its natural intensive network usage. Client\ndevices, such as smartphones or Internet of Things (IoT) nodes, have limited\nresources in terms of energy, computation, and memory. To address these\nhardware constraints, lightweight models and compression techniques such as\npruning and quantization are commonly adopted in centralised paradigms. In this\npaper, we investigate the impact of compression techniques on FL for a typical\nimage classification task. Going further, we demonstrate that a straightforward\nmethod can compresses messages up to 50% while having less than 1% of accuracy\nloss, competing with state-of-the-art techniques.",
            "author": [
                "Lucas Grativol Ribeiro",
                "Mathieu Leonardon",
                "Guillaume Muller",
                "Virginie Fresse",
                "Matthieu Arzel"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14693v1",
                "http://arxiv.org/pdf/2310.14693v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14692v1",
            "title": "On Partial Shape Correspondence and Functional Maps",
            "updated": "2023-10-23T08:32:50Z",
            "published": "2023-10-23T08:32:50Z",
            "summary": "While dealing with matching shapes to their parts, we often utilize an\ninstrument known as functional maps. The idea is to translate the shape\nmatching problem into ``convenient'' spaces by which matching is performed\nalgebraically by solving a least squares problem. Here, we argue that such\nformulations, though popular in this field, introduce errors in the estimated\nmatch when partiality is invoked. Such errors are unavoidable even when\nconsidering advanced feature extraction networks, and they can be shown to\nescalate with increasing degrees of shape partiality, adversely affecting the\nlearning capability of such systems. To circumvent these limitations, we\npropose a novel approach for partial shape matching.\n  Our study of functional maps led us to a novel method that establishes direct\ncorrespondence between partial and full shapes through feature matching\nbypassing the need for functional map intermediate spaces. The Gromov distance\nbetween metric spaces leads to the construction of the first part of our loss\nfunctions. For regularization we use two options: a term based on the area\npreserving property of the mapping, and a relaxed version of it without the\nneed to compute a functional map.\n  The proposed approach shows superior performance on the SHREC'16 dataset,\noutperforming existing unsupervised methods for partial shape matching. In\nparticular, it achieves state-of-the-art result on the SHREC'16 HOLES\nbenchmark, superior also compared to supervised methods.",
            "author": [
                "Amit Bracha",
                "Thomas Dag\u00e8s",
                "Ron Kimmel"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14692v1",
                "http://arxiv.org/pdf/2310.14692v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14685v1",
            "title": "Multi-Agent Learning in Contextual Games under Unknown Constraints",
            "updated": "2023-10-23T08:25:14Z",
            "published": "2023-10-23T08:25:14Z",
            "summary": "We consider the problem of learning to play a repeated contextual game with\nunknown reward and unknown constraints functions. Such games arise in\napplications where each agent's action needs to belong to a feasible set, but\nthe feasible set is a priori unknown. For example, in constrained multi-agent\nreinforcement learning, the constraints on the agents' policies are a function\nof the unknown dynamics and hence, are themselves unknown. Under kernel-based\nregularity assumptions on the unknown functions, we develop a no-regret,\nno-violation approach which exploits similarities among different reward and\nconstraint outcomes. The no-violation property ensures that the time-averaged\nsum of constraint violations converges to zero as the game is repeated. We show\nthat our algorithm, referred to as c.z.AdaNormalGP, obtains kernel-dependent\nregret bounds and that the cumulative constraint violations have sublinear\nkernel-dependent upper bounds. In addition we introduce the notion of\nconstrained contextual coarse correlated equilibria (c.z.CCE) and show that\n$\\epsilon$-c.z.CCEs can be approached whenever players' follow a no-regret\nno-violation strategy. Finally, we experimentally demonstrate the effectiveness\nof c.z.AdaNormalGP on an instance of multi-agent reinforcement learning.",
            "author": [
                "Anna M. Maddux",
                "Maryam Kamgarpour"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14685v1",
                "http://arxiv.org/pdf/2310.14685v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14677v1",
            "title": "CLEAR Space Weather Center of Excellence: All-Clear Solar Energetic\n  Particle Prediction",
            "updated": "2023-10-23T08:15:53Z",
            "published": "2023-10-23T08:15:53Z",
            "summary": "The CLEAR Space Weather Center of Excellence (CLEAR center) is a five year\nproject that is funded by the NASA Space Weather Center of Excellence program.\nThe CLEAR center will build a comprehensive prediction framework for solar\nenergetic particles (SEPs) focusing on the timely and accurate prediction of\nlow radiation periods (``all clear forecast\") and the occurrence and\ncharacteristics of elevated periods. This will be accomplished by integrating\nempirical, first-principles based and machine learning (ML)-trained prediction\nmodels. In this paper, the motivation, overview, and tools of the CLEAR center\nwill be discussed.",
            "author": [
                "Lulu Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14677v1",
                "http://arxiv.org/pdf/2310.14677v1"
            ],
            "primary_category": "astro-ph.SR",
            "category": [
                "astro-ph.SR",
                "astro-ph.IM",
                "physics.space-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14675v1",
            "title": "Online Out-of-Domain Detection for Automated Driving",
            "updated": "2023-10-23T08:15:29Z",
            "published": "2023-10-23T08:15:29Z",
            "summary": "Ensuring safety in automated driving is a major challenge for the automotive\nindustry. Special attention is paid to artificial intelligence, in particular\nto Deep Neural Networks (DNNs), which is considered a key technology in the\nrealization of highly automated driving. DNNs learn from training data, which\nmeans that they only achieve good accuracy within the underlying data\ndistribution of the training data. When leaving the training domain, a\ndistributional shift is caused, which can lead to a drastic reduction of\naccuracy. In this work, we present a proof of concept for a safety mechanism\nthat can detect the leaving of the domain online, i.e. at runtime. In our\nexperiments with the Synthia data set we can show that a 100 % correct\ndetection of whether the input data is inside or outside the domain is\nachieved. The ability to detect when the vehicle leaves the domain can be an\nimportant requirement for certification.",
            "author": [
                "Timo S\u00e4mann",
                "Horst-Michael Gro\u00df"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14675v1",
                "http://arxiv.org/pdf/2310.14675v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14671v1",
            "title": "Population Descent: A Natural-Selection Based Hyper-Parameter Tuning\n  Framework",
            "updated": "2023-10-23T08:11:17Z",
            "published": "2023-10-23T08:11:17Z",
            "summary": "First-order gradient descent has been the base of the most successful\noptimization algorithms ever implemented. On supervised learning problems with\nvery high dimensionality, such as neural network optimization, it is almost\nalways the algorithm of choice, mainly due to its memory and computational\nefficiency. However, it is a classical result in optimization that gradient\ndescent converges to local minima on non-convex functions. Even more\nimportantly, in certain high-dimensional cases, escaping the plateaus of large\nsaddle points becomes intractable. On the other hand, black-box optimization\nmethods are not sensitive to the local structure of a loss function's landscape\nbut suffer the curse of dimensionality. Instead, memetic algorithms aim to\ncombine the benefits of both. Inspired by this, we present Population Descent,\na memetic algorithm focused on hyperparameter optimization. We show that an\nadaptive m-elitist selection approach combined with a normalized-fitness-based\nrandomization scheme outperforms more complex state-of-the-art algorithms by up\nto 13% on common benchmark tasks.",
            "author": [
                "Abhinav Pomalapally",
                "Bassel El Mabsout",
                "Renato Mansuco"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14671v1",
                "http://arxiv.org/pdf/2310.14671v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14670v2",
            "title": "Dataset Bias Mitigation in Multiple-Choice Visual Question Answering and\n  Beyond",
            "updated": "2023-10-31T20:49:11Z",
            "published": "2023-10-23T08:09:42Z",
            "summary": "Vision-language (VL) understanding tasks evaluate models' comprehension of\ncomplex visual scenes through multiple-choice questions. However, we have\nidentified two dataset biases that models can exploit as shortcuts to resolve\nvarious VL tasks correctly without proper understanding. The first type of\ndataset bias is \\emph{Unbalanced Matching} bias, where the correct answer\noverlaps the question and image more than the incorrect answers. The second\ntype of dataset bias is \\emph{Distractor Similarity} bias, where incorrect\nanswers are overly dissimilar to the correct answer but significantly similar\nto other incorrect answers within the same sample. To address these dataset\nbiases, we first propose Adversarial Data Synthesis (ADS) to generate synthetic\ntraining and debiased evaluation data. We then introduce Intra-sample\nCounterfactual Training (ICT) to assist models in utilizing the synthesized\ntraining data, particularly the counterfactual data, via focusing on\nintra-sample differentiation. Extensive experiments demonstrate the\neffectiveness of ADS and ICT in consistently improving model performance across\ndifferent benchmarks, even in domain-shifted scenarios.",
            "author": [
                "Zhecan Wang",
                "Long Chen",
                "Haoxuan You",
                "Keyang Xu",
                "Yicheng He",
                "Wenhao Li",
                "Noel Codella",
                "Kai-Wei Chang",
                "Shih-Fu Chang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14670v2",
                "http://arxiv.org/pdf/2310.14670v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL",
                "cs.LG",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14669v1",
            "title": "B^2SFL: A Bi-level Blockchained Architecture for Secure Federated\n  Learning-based Traffic Prediction",
            "updated": "2023-10-23T08:06:05Z",
            "published": "2023-10-23T08:06:05Z",
            "summary": "Federated Learning (FL) is a privacy-preserving machine learning (ML)\ntechnology that enables collaborative training and learning of a global ML\nmodel based on aggregating distributed local model updates. However, security\nand privacy guarantees could be compromised due to malicious participants and\nthe centralized FL server. This article proposed a bi-level blockchained\narchitecture for secure federated learning-based traffic prediction. The bottom\nand top layer blockchain store the local model and global aggregated parameters\naccordingly, and the distributed homomorphic-encrypted federated averaging\n(DHFA) scheme addresses the secure computation problems. We propose the partial\nprivate key distribution protocol and a partially homomorphic\nencryption/decryption scheme to achieve the distributed privacy-preserving\nfederated averaging model. We conduct extensive experiments to measure the\nrunning time of DHFA operations, quantify the read and write performance of the\nblockchain network, and elucidate the impacts of varying regional group sizes\nand model complexities on the resulting prediction accuracy for the online\ntraffic flow prediction task. The results indicate that the proposed system can\nfacilitate secure and decentralized federated learning for real-world traffic\nprediction tasks.",
            "author": [
                "Hao Guo",
                "Collin Meese",
                "Wanxin Li",
                "Chien-Chung Shen",
                "Mark Nejad"
            ],
            "link": [
                "http://dx.doi.org/10.1109/TSC.2023.3318990",
                "http://arxiv.org/abs/2310.14669v1",
                "http://arxiv.org/pdf/2310.14669v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14666v1",
            "title": "SeLeP: Learning Based Semantic Prefetching for Exploratory Database\n  Workloads",
            "updated": "2023-10-23T08:01:58Z",
            "published": "2023-10-23T08:01:58Z",
            "summary": "Prefetching is a crucial technique employed in traditional databases to\nenhance interactivity, particularly in the context of data exploitation. Data\nexploration is a query processing paradigm in which users search for insights\nburied in the data, often not knowing what exactly they are looking for. Data\nexploratory tools deal with multiple challenges such as the need for\ninteractivity with no a priori knowledge being present to help with the system\ntuning. The state-of-the-art prefetchers are specifically designed for\nnavigational workloads only, where the number of possible actions is limited.\nThe prefetchers that work with SQL-based workloads, on the other hand, mainly\nrely on data logical addresses rather than the data semantics. They fail to\npredict complex access patterns in cases where the database size is\nsubstantial, resulting in an extensive address space, or when there is frequent\nco-accessing of data. In this paper, we propose SeLeP, a semantic prefetcher\nthat makes prefetching decisions for both types of workloads, based on the\nencoding of the data values contained inside the accessed blocks. Following the\npopular path of using machine learning approaches to automatically learn the\nhidden patterns, we formulate the prefetching task as a time-series forecasting\nproblem and use an encoder-decoder LSTM architecture to learn the data access\npattern. Our extensive experiments, across real-life exploratory workloads,\ndemonstrate that SeLeP improves the hit ratio up to 40% and reduces I/O time up\nto 45% compared to the state-of-the-art, attaining impressive 95% hit ratio and\n80% I/O reduction on average.",
            "author": [
                "Farzaneh Zirak",
                "Farhana Choudhury",
                "Renata Borovica-Gajic"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14666v1",
                "http://arxiv.org/pdf/2310.14666v1"
            ],
            "primary_category": "cs.DB",
            "category": [
                "cs.DB"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14664v2",
            "title": "Data Pruning via Moving-one-Sample-out",
            "updated": "2023-10-25T06:19:05Z",
            "published": "2023-10-23T08:00:03Z",
            "summary": "In this paper, we propose a novel data-pruning approach called\nmoving-one-sample-out (MoSo), which aims to identify and remove the least\ninformative samples from the training set. The core insight behind MoSo is to\ndetermine the importance of each sample by assessing its impact on the optimal\nempirical risk. This is achieved by measuring the extent to which the empirical\nrisk changes when a particular sample is excluded from the training set.\nInstead of using the computationally expensive leaving-one-out-retraining\nprocedure, we propose an efficient first-order approximator that only requires\ngradient information from different training stages. The key idea behind our\napproximation is that samples with gradients that are consistently aligned with\nthe average gradient of the training set are more informative and should\nreceive higher scores, which could be intuitively understood as follows: if the\ngradient from a specific sample is consistent with the average gradient vector,\nit implies that optimizing the network using the sample will yield a similar\neffect on all remaining samples. Experimental results demonstrate that MoSo\neffectively mitigates severe performance degradation at high pruning ratios and\nachieves satisfactory performance across various settings.",
            "author": [
                "Haoru Tan",
                "Sitong Wu",
                "Fei Du",
                "Yukang Chen",
                "Zhibin Wang",
                "Fan Wang",
                "Xiaojuan Qi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14664v2",
                "http://arxiv.org/pdf/2310.14664v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14663v1",
            "title": "DPP-TTS: Diversifying prosodic features of speech via determinantal\n  point processes",
            "updated": "2023-10-23T07:59:46Z",
            "published": "2023-10-23T07:59:46Z",
            "summary": "With the rapid advancement in deep generative models, recent neural\nText-To-Speech(TTS) models have succeeded in synthesizing human-like speech.\nThere have been some efforts to generate speech with various prosody beyond\nmonotonous prosody patterns. However, previous works have several limitations.\nFirst, typical TTS models depend on the scaled sampling temperature for\nboosting the diversity of prosody. Speech samples generated at high sampling\ntemperatures often lack perceptual prosodic diversity, which can adversely\naffect the naturalness of the speech. Second, the diversity among samples is\nneglected since the sampling procedure often focuses on a single speech sample\nrather than multiple ones. In this paper, we propose DPP-TTS: a text-to-speech\nmodel based on Determinantal Point Processes (DPPs) with a prosody diversifying\nmodule. Our TTS model is capable of generating speech samples that\nsimultaneously consider perceptual diversity in each sample and among multiple\nsamples. We demonstrate that DPP-TTS generates speech samples with more\ndiversified prosody than baselines in the side-by-side comparison test\nconsidering the naturalness of speech at the same time.",
            "author": [
                "Seongho Joo",
                "Hyukhun Koh",
                "Kyomin Jung"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14663v1",
                "http://arxiv.org/pdf/2310.14663v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14662v2",
            "title": "Estimation of forest height and biomass from open-access multi-sensor\n  satellite imagery and GEDI Lidar data: high-resolution maps of metropolitan\n  France",
            "updated": "2023-11-09T09:24:05Z",
            "published": "2023-10-23T07:58:49Z",
            "summary": "Mapping forest resources and carbon is important for improving forest\nmanagement and meeting the objectives of storing carbon and preserving the\nenvironment. Spaceborne remote sensing approaches have considerable potential\nto support forest height monitoring by providing repeated observations at high\nspatial resolution over large areas. This study uses a machine learning\napproach that was previously developed to produce local maps of forest\nparameters (basal area, height, diameter, etc.). The aim of this paper is to\npresent the extension of the approach to much larger scales such as the French\nnational coverage. We used the GEDI Lidar mission as reference height data, and\nthe satellite images from Sentinel-1, Sentinel-2 and ALOS-2 PALSA-2 to estimate\nforest height and produce a map of France for the year 2020. The height map is\nthen derived into volume and aboveground biomass (AGB) using allometric\nequations. The validation of the height map with local maps from ALS data shows\nan accuracy close to the state of the art, with a mean absolute error (MAE) of\n4.3 m. Validation on inventory plots representative of French forests shows an\nMAE of 3.7 m for the height. Estimates are slightly better for coniferous than\nfor broadleaved forests. Volume and AGB maps derived from height shows MAEs of\n75 tons/ha and 93 m${}^3$/ha respectively. The results aggregated by\nsylvo-ecoregion and forest types (owner and species) are further improved, with\nMAEs of 23 tons/ha and 30 m${}^3$/ha. The precision of these maps allows to\nmonitor forests locally, as well as helping to analyze forest resources and\ncarbon on a territorial scale or on specific types of forests by combining the\nmaps with geolocated information (administrative area, species, type of owner,\nprotected areas, environmental conditions, etc.). Height, volume and AGB maps\nproduced in this study are made freely available.",
            "author": [
                "David Morin",
                "Milena Planells",
                "St\u00e9phane Mermoz",
                "Florian Mouret"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14662v2",
                "http://arxiv.org/pdf/2310.14662v2"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14661v1",
            "title": "Tractable MCMC for Private Learning with Pure and Gaussian Differential\n  Privacy",
            "updated": "2023-10-23T07:54:39Z",
            "published": "2023-10-23T07:54:39Z",
            "summary": "Posterior sampling, i.e., exponential mechanism to sample from the posterior\ndistribution, provides $\\varepsilon$-pure differential privacy (DP) guarantees\nand does not suffer from potentially unbounded privacy breach introduced by\n$(\\varepsilon,\\delta)$-approximate DP. In practice, however, one needs to apply\napproximate sampling methods such as Markov chain Monte Carlo (MCMC), thus\nre-introducing the unappealing $\\delta$-approximation error into the privacy\nguarantees. To bridge this gap, we propose the Approximate SAample Perturbation\n(abbr. ASAP) algorithm which perturbs an MCMC sample with noise proportional to\nits Wasserstein-infinity ($W_\\infty$) distance from a reference distribution\nthat satisfies pure DP or pure Gaussian DP (i.e., $\\delta=0$). We then leverage\na Metropolis-Hastings algorithm to generate the sample and prove that the\nalgorithm converges in W$_\\infty$ distance. We show that by combining our new\ntechniques with a careful localization step, we obtain the first nearly\nlinear-time algorithm that achieves the optimal rates in the DP-ERM problem\nwith strongly convex and smooth losses.",
            "author": [
                "Yingyu Lin",
                "Yian Ma",
                "Yu-Xiang Wang",
                "Rachel Redberg"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14661v1",
                "http://arxiv.org/pdf/2310.14661v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14659v1",
            "title": "Predicting Accurate Lagrangian Multipliers for Mixed Integer Linear\n  Programs",
            "updated": "2023-10-23T07:53:47Z",
            "published": "2023-10-23T07:53:47Z",
            "summary": "Lagrangian relaxation stands among the most efficient approaches for solving\na Mixed Integer Linear Programs (MILP) with difficult constraints. Given any\nduals for these constraints, called Lagrangian Multipliers (LMs), it returns a\nbound on the optimal value of the MILP, and Lagrangian methods seek the LMs\ngiving the best such bound. But these methods generally rely on iterative\nalgorithms resembling gradient descent to maximize the concave piecewise linear\ndual function: the computational burden grows quickly with the number of\nrelaxed constraints. We introduce a deep learning approach that bypasses the\ndescent, effectively amortizing the local, per instance, optimization. A\nprobabilistic encoder based on a graph convolutional network computes\nhigh-dimensional representations of relaxed constraints in MILP instances. A\ndecoder then turns these representations into LMs. We train the encoder and\ndecoder jointly by directly optimizing the bound obtained from the predicted\nmultipliers. Numerical experiments show that our approach closes up to 85~\\% of\nthe gap between the continuous relaxation and the best Lagrangian bound, and\nprovides a high quality warm-start for descent based Lagrangian methods.",
            "author": [
                "Francesco Demelas",
                "Joseph Le Roux",
                "Mathieu Lacroix",
                "Axel Parmentier"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14659v1",
                "http://arxiv.org/pdf/2310.14659v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14652v1",
            "title": "Invariant Feature Regularization for Fair Face Recognition",
            "updated": "2023-10-23T07:44:12Z",
            "published": "2023-10-23T07:44:12Z",
            "summary": "Fair face recognition is all about learning invariant feature that\ngeneralizes to unseen faces in any demographic group. Unfortunately, face\ndatasets inevitably capture the imbalanced demographic attributes that are\nubiquitous in real-world observations, and the model learns biased feature that\ngeneralizes poorly in the minority group. We point out that the bias arises due\nto the confounding demographic attributes, which mislead the model to capture\nthe spurious demographic-specific feature. The confounding effect can only be\nremoved by causal intervention, which requires the confounder annotations.\nHowever, such annotations can be prohibitively expensive due to the diversity\nof the demographic attributes. To tackle this, we propose to generate diverse\ndata partitions iteratively in an unsupervised fashion. Each data partition\nacts as a self-annotated confounder, enabling our Invariant Feature\nRegularization (INV-REG) to deconfound. INV-REG is orthogonal to existing\nmethods, and combining INV-REG with two strong baselines (Arcface and CIFP)\nleads to new state-of-the-art that improves face recognition on a variety of\ndemographic groups. Code is available at\nhttps://github.com/PanasonicConnect/InvReg.",
            "author": [
                "Jiali Ma",
                "Zhongqi Yue",
                "Kagaya Tomoyuki",
                "Suzuki Tomoki",
                "Karlekar Jayashree",
                "Sugiri Pranata",
                "Hanwang Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14652v1",
                "http://arxiv.org/pdf/2310.14652v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14651v1",
            "title": "$\u039b$-Split: A Privacy-Preserving Split Computing Framework for\n  Cloud-Powered Generative AI",
            "updated": "2023-10-23T07:44:04Z",
            "published": "2023-10-23T07:44:04Z",
            "summary": "In the wake of the burgeoning expansion of generative artificial intelligence\n(AI) services, the computational demands inherent to these technologies\nfrequently necessitate cloud-powered computational offloading, particularly for\nresource-constrained mobile devices. These services commonly employ prompts to\nsteer the generative process, and both the prompts and the resultant content,\nsuch as text and images, may harbor privacy-sensitive or confidential\ninformation, thereby elevating security and privacy risks. To mitigate these\nconcerns, we introduce $\\Lambda$-Split, a split computing framework to\nfacilitate computational offloading while simultaneously fortifying data\nprivacy against risks such as eavesdropping and unauthorized access. In\n$\\Lambda$-Split, a generative model, usually a deep neural network (DNN), is\npartitioned into three sub-models and distributed across the user's local\ndevice and a cloud server: the input-side and output-side sub-models are\nallocated to the local, while the intermediate, computationally-intensive\nsub-model resides on the cloud server. This architecture ensures that only the\nhidden layer outputs are transmitted, thereby preventing the external\ntransmission of privacy-sensitive raw input and output data. Given the\nblack-box nature of DNNs, estimating the original input or output from\nintercepted hidden layer outputs poses a significant challenge for malicious\neavesdroppers. Moreover, $\\Lambda$-Split is orthogonal to traditional\nencryption-based security mechanisms, offering enhanced security when deployed\nin conjunction. We empirically validate the efficacy of the $\\Lambda$-Split\nframework using Llama 2 and Stable Diffusion XL, representative large language\nand diffusion models developed by Meta and Stability AI, respectively. Our\n$\\Lambda$-Split implementation is publicly accessible at\nhttps://github.com/nishio-laboratory/lambda_split.",
            "author": [
                "Shoki Ohta",
                "Takayuki Nishio"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14651v1",
                "http://arxiv.org/pdf/2310.14651v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.DC",
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14648v1",
            "title": "Reconfigurable Multifunctional van der Waals Ferroelectric Devices and\n  Logic Circuits",
            "updated": "2023-10-23T07:40:48Z",
            "published": "2023-10-23T07:40:48Z",
            "summary": "In this work, we demonstrate the suitability of Reconfigurable Ferroelectric\nField-Effect- Transistors (Re-FeFET) for designing non-volatile reconfigurable\nlogic-in-memory circuits with multifunctional capabilities. Modulation of the\nenergy landscape within a homojunction of a 2D tungsten diselenide (WSe$_2$)\nlayer is achieved by independently controlling two split-gate electrodes made\nof a ferroelectric 2D copper indium thiophosphate (CuInP$_2$S$_6$) layer.\nControlling the state encoded in the Program Gate enables switching between p,\nn and ambipolar FeFET operating modes. The transistors exhibit on-off ratios\nexceeding 10$^6$ and hysteresis windows of up to 10 V width. The homojunction\ncan change from ohmic-like to diode behavior, with a large rectification ratio\nof 10$^4$. When programmed in the diode mode, the large built-in p-n junction\nelectric field enables efficient separation of photogenerated carriers, making\nthe device attractive for energy harvesting applications. The implementation of\nthe Re-FeFET for reconfigurable logic functions shows how a circuit can be\nreconfigured to emulate either polymorphic ferroelectric NAND/AND\nlogic-in-memory or electronic XNOR logic with long retention time exceeding\n10$^4$ seconds. We also illustrate how a circuit design made of just two\nRe-FeFETs exhibits high logic expressivity with reconfigurability at runtime to\nimplement several key non-volatile 2-input logic functions. Moreover, the\nRe-FeFET circuit demonstrates remarkable compactness, with an up to 80%\nreduction in transistor count compared to standard CMOS design. The 2D van de\nWaals Re-FeFET devices therefore exhibit groundbreaking potential for both\nMore-than-Moore and beyond-Moore future of electronics, in particular for an\nenergy-efficient implementation of in-memory computing and machine learning\nhardware, due to their multifunctionality and design compactness.",
            "author": [
                "Ankita Ram",
                "Krishna Maity",
                "C\u00e9dric Marchand",
                "Aymen Mahmoudi",
                "Aseem Rajan Kshirsagar",
                "Mohamed Soliman",
                "Takashi Taniguchi",
                "Kenji Watanabe",
                "Bernard Doudin",
                "Abdelkarim Ouerghi",
                "Sven Reichardt",
                "Ian O'Connor",
                "Jean-Francois Dayen"
            ],
            "link": [
                "http://dx.doi.org/10.1021/acsnano.3c07952",
                "http://arxiv.org/abs/2310.14648v1",
                "http://arxiv.org/pdf/2310.14648v1"
            ],
            "primary_category": "cond-mat.mes-hall",
            "category": [
                "cond-mat.mes-hall"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14642v1",
            "title": "Relit-NeuLF: Efficient Relighting and Novel View Synthesis via Neural 4D\n  Light Field",
            "updated": "2023-10-23T07:29:51Z",
            "published": "2023-10-23T07:29:51Z",
            "summary": "In this paper, we address the problem of simultaneous relighting and novel\nview synthesis of a complex scene from multi-view images with a limited number\nof light sources. We propose an analysis-synthesis approach called Relit-NeuLF.\nFollowing the recent neural 4D light field network (NeuLF), Relit-NeuLF first\nleverages a two-plane light field representation to parameterize each ray in a\n4D coordinate system, enabling efficient learning and inference. Then, we\nrecover the spatially-varying bidirectional reflectance distribution function\n(SVBRDF) of a 3D scene in a self-supervised manner. A DecomposeNet learns to\nmap each ray to its SVBRDF components: albedo, normal, and roughness. Based on\nthe decomposed BRDF components and conditioning light directions, a RenderNet\nlearns to synthesize the color of the ray. To self-supervise the SVBRDF\ndecomposition, we encourage the predicted ray color to be close to the\nphysically-based rendering result using the microfacet model. Comprehensive\nexperiments demonstrate that the proposed method is efficient and effective on\nboth synthetic data and real-world human face data, and outperforms the\nstate-of-the-art results. We publicly released our code on GitHub. You can find\nit here: https://github.com/oppo-us-research/RelitNeuLF",
            "author": [
                "Zhong Li",
                "Liangchen Song",
                "Zhang Chen",
                "Xiangyu Du",
                "Lele Chen",
                "Junsong Yuan",
                "Yi Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14642v1",
                "http://arxiv.org/pdf/2310.14642v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14637v1",
            "title": "Semantic-Aware Adversarial Training for Reliable Deep Hashing Retrieval",
            "updated": "2023-10-23T07:21:40Z",
            "published": "2023-10-23T07:21:40Z",
            "summary": "Deep hashing has been intensively studied and successfully applied in\nlarge-scale image retrieval systems due to its efficiency and effectiveness.\nRecent studies have recognized that the existence of adversarial examples poses\na security threat to deep hashing models, that is, adversarial vulnerability.\nNotably, it is challenging to efficiently distill reliable semantic\nrepresentatives for deep hashing to guide adversarial learning, and thereby it\nhinders the enhancement of adversarial robustness of deep hashing-based\nretrieval models. Moreover, current researches on adversarial training for deep\nhashing are hard to be formalized into a unified minimax structure. In this\npaper, we explore Semantic-Aware Adversarial Training (SAAT) for improving the\nadversarial robustness of deep hashing models. Specifically, we conceive a\ndiscriminative mainstay features learning (DMFL) scheme to construct semantic\nrepresentatives for guiding adversarial learning in deep hashing. Particularly,\nour DMFL with the strict theoretical guarantee is adaptively optimized in a\ndiscriminative learning manner, where both discriminative and semantic\nproperties are jointly considered. Moreover, adversarial examples are\nfabricated by maximizing the Hamming distance between the hash codes of\nadversarial samples and mainstay features, the efficacy of which is validated\nin the adversarial attack trials. Further, we, for the first time, formulate\nthe formalized adversarial training of deep hashing into a unified minimax\noptimization under the guidance of the generated mainstay codes. Extensive\nexperiments on benchmark datasets show superb attack performance against the\nstate-of-the-art algorithms, meanwhile, the proposed adversarial training can\neffectively eliminate adversarial perturbations for trustworthy deep\nhashing-based retrieval. Our code is available at\nhttps://github.com/xandery-geek/SAAT.",
            "author": [
                "Xu Yuan",
                "Zheng Zhang",
                "Xunguang Wang",
                "Lin Wu"
            ],
            "link": [
                "http://dx.doi.org/10.1109/TIFS.2023.3297791",
                "http://arxiv.org/abs/2310.14637v1",
                "http://arxiv.org/pdf/2310.14637v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14636v1",
            "title": "Multilevel Perception Boundary-guided Network for Breast Lesion\n  Segmentation in Ultrasound Images",
            "updated": "2023-10-23T07:21:02Z",
            "published": "2023-10-23T07:21:02Z",
            "summary": "Automatic segmentation of breast tumors from the ultrasound images is\nessential for the subsequent clinical diagnosis and treatment plan. Although\nthe existing deep learning-based methods have achieved significant progress in\nautomatic segmentation of breast tumor, their performance on tumors with\nsimilar intensity to the normal tissues is still not pleasant, especially for\nthe tumor boundaries. To address this issue, we propose a PBNet composed by a\nmultilevel global perception module (MGPM) and a boundary guided module (BGM)\nto segment breast tumors from ultrasound images. Specifically, in MGPM, the\nlong-range spatial dependence between the voxels in a single level feature maps\nare modeled, and then the multilevel semantic information is fused to promote\nthe recognition ability of the model for non-enhanced tumors. In BGM, the tumor\nboundaries are extracted from the high-level semantic maps using the dilation\nand erosion effects of max pooling, such boundaries are then used to guide the\nfusion of low and high-level features. Moreover, to improve the segmentation\nperformance for tumor boundaries, a multi-level boundary-enhanced segmentation\n(BS) loss is proposed. The extensive comparison experiments on both publicly\navailable dataset and in-house dataset demonstrate that the proposed PBNet\noutperforms the state-of-the-art methods in terms of both qualitative\nvisualization results and quantitative evaluation metrics, with the Dice score,\nJaccard coefficient, Specificity and HD95 improved by 0.70%, 1.1%, 0.1% and\n2.5% respectively. In addition, the ablation experiments validate that the\nproposed MGPM is indeed beneficial for distinguishing the non-enhanced tumors\nand the BGM as well as the BS loss are also helpful for refining the\nsegmentation contours of the tumor.",
            "author": [
                "Xing Yang",
                "Jian Zhang",
                "Qijian Chen",
                "Li Wang",
                "Lihui Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14636v1",
                "http://arxiv.org/pdf/2310.14636v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14633v2",
            "title": "Extending Input Contexts of Language Models through Training on\n  Segmented Sequences",
            "updated": "2023-10-28T04:14:38Z",
            "published": "2023-10-23T07:13:31Z",
            "summary": "Effectively training language models on long inputs poses many technical\nchallenges. As a cost consideration, languages models are pretrained on a fixed\nsequence length before being adapted to longer sequences. We explore various\nmethods for adapting models to longer inputs by training on segmented sequences\nand an interpolation-based method for extending absolute positional embeddings.\nWe develop a training procedure to extend the input context size of pretrained\nmodels with no architectural changes and no additional memory costs than\ntraining on the original input lengths. By sub-sampling segments from long\ninputs while maintaining their original position the model is able to learn new\npositional interactions. Our method benefits both models trained with absolute\npositional embeddings, by extending their input contexts, as well as popular\nrelative positional embedding methods showing a reduced perplexity on sequences\nlonger than they were trained on. We demonstrate our method can extend input\ncontexts by a factor of 4x while improving perplexity.",
            "author": [
                "Petros Karypis",
                "Julian McAuley",
                "George Karypis"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14633v2",
                "http://arxiv.org/pdf/2310.14633v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14629v1",
            "title": "Making informed decisions in cutting tool maintenance in milling: A KNN\n  based model agnostic approach",
            "updated": "2023-10-23T07:02:30Z",
            "published": "2023-10-23T07:02:30Z",
            "summary": "In machining processes, monitoring the condition of the tool is a crucial\naspect to ensure high productivity and quality of the product. Using different\nmachine learning techniques in Tool Condition Monitoring TCM enables a better\nanalysis of the large amount of data of different signals acquired during the\nmachining processes. The real time force signals encountered during the process\nwere acquired by performing numerous experiments. Different tool wear\nconditions were considered during the experimentation. A comprehensive\nstatistical analysis of the data and feature selection using decision trees was\nconducted, and the KNN algorithm was used to perform classification.\nHyperparameter tuning of the model was done to improve the models performance.\nMuch research has been done to employ machine learning approaches in tool\ncondition monitoring systems, however, a model agnostic approach to increase\nthe interpretability of the process and get an in depth understanding of how\nthe decision making is done is not implemented by many. This research paper\npresents a KNN based white box model, which allows us to dive deep into how the\nmodel performs the classification and how it prioritizes the different features\nincluded. This approach helps in detecting why the tool is in a certain\ncondition and allows the manufacturer to make an informed decision about the\ntools maintenance.",
            "author": [
                "Aditya M. Rahalkar",
                "Om M. Khare",
                "Abhishek D. Patange"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14629v1",
                "http://arxiv.org/pdf/2310.14629v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14627v1",
            "title": "CrisisMatch: Semi-Supervised Few-Shot Learning for Fine-Grained Disaster\n  Tweet Classification",
            "updated": "2023-10-23T07:01:09Z",
            "published": "2023-10-23T07:01:09Z",
            "summary": "The shared real-time information about natural disasters on social media\nplatforms like Twitter and Facebook plays a critical role in informing\nvolunteers, emergency managers, and response organizations. However, supervised\nlearning models for monitoring disaster events require large amounts of\nannotated data, making them unrealistic for real-time use in disaster events.\nTo address this challenge, we present a fine-grained disaster tweet\nclassification model under the semi-supervised, few-shot learning setting where\nonly a small number of annotated data is required. Our model, CrisisMatch,\neffectively classifies tweets into fine-grained classes of interest using few\nlabeled data and large amounts of unlabeled data, mimicking the early stage of\na disaster. Through integrating effective semi-supervised learning ideas and\nincorporating TextMixUp, CrisisMatch achieves performance improvement on two\ndisaster datasets of 11.2\\% on average. Further analyses are also provided for\nthe influence of the number of labeled data and out-of-domain results.",
            "author": [
                "Henry Peng Zou",
                "Yue Zhou",
                "Cornelia Caragea",
                "Doina Caragea"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14627v1",
                "http://arxiv.org/pdf/2310.14627v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14626v1",
            "title": "Conversational Recommender System and Large Language Model Are Made for\n  Each Other in E-commerce Pre-sales Dialogue",
            "updated": "2023-10-23T07:00:51Z",
            "published": "2023-10-23T07:00:51Z",
            "summary": "E-commerce pre-sales dialogue aims to understand and elicit user needs and\npreferences for the items they are seeking so as to provide appropriate\nrecommendations. Conversational recommender systems (CRSs) learn user\nrepresentation and provide accurate recommendations based on dialogue context,\nbut rely on external knowledge. Large language models (LLMs) generate responses\nthat mimic pre-sales dialogues after fine-tuning, but lack domain-specific\nknowledge for accurate recommendations. Intuitively, the strengths of LLM and\nCRS in E-commerce pre-sales dialogues are complementary, yet no previous work\nhas explored this. This paper investigates the effectiveness of combining LLM\nand CRS in E-commerce pre-sales dialogues, proposing two collaboration methods:\nCRS assisting LLM and LLM assisting CRS. We conduct extensive experiments on a\nreal-world dataset of Ecommerce pre-sales dialogues. We analyze the impact of\ntwo collaborative approaches with two CRSs and two LLMs on four tasks of\nEcommerce pre-sales dialogue. We find that collaborations between CRS and LLM\ncan be very effective in some cases.",
            "author": [
                "Yuanxing Liu",
                "Wei-Nan Zhang",
                "Yifan Chen",
                "Yuchi Zhang",
                "Haopeng Bai",
                "Fan Feng",
                "Hengbin Cui",
                "Yongbin Li",
                "Wanxiang Che"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14626v1",
                "http://arxiv.org/pdf/2310.14626v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14623v1",
            "title": "CoF-CoT: Enhancing Large Language Models with Coarse-to-Fine\n  Chain-of-Thought Prompting for Multi-domain NLU Tasks",
            "updated": "2023-10-23T06:54:51Z",
            "published": "2023-10-23T06:54:51Z",
            "summary": "While Chain-of-Thought prompting is popular in reasoning tasks, its\napplication to Large Language Models (LLMs) in Natural Language Understanding\n(NLU) is under-explored. Motivated by multi-step reasoning of LLMs, we propose\nCoarse-to-Fine Chain-of-Thought (CoF-CoT) approach that breaks down NLU tasks\ninto multiple reasoning steps where LLMs can learn to acquire and leverage\nessential concepts to solve tasks from different granularities. Moreover, we\npropose leveraging semantic-based Abstract Meaning Representation (AMR)\nstructured knowledge as an intermediate step to capture the nuances and diverse\nstructures of utterances, and to understand connections between their varying\nlevels of granularity. Our proposed approach is demonstrated effective in\nassisting the LLMs adapt to the multi-grained NLU tasks under both zero-shot\nand few-shot multi-domain settings.",
            "author": [
                "Hoang H. Nguyen",
                "Ye Liu",
                "Chenwei Zhang",
                "Tao Zhang",
                "Philip S. Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14623v1",
                "http://arxiv.org/pdf/2310.14623v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14621v1",
            "title": "Spiking mode-based neural networks",
            "updated": "2023-10-23T06:54:17Z",
            "published": "2023-10-23T06:54:17Z",
            "summary": "Spiking neural networks play an important role in brain-like neuromorphic\ncomputations and in studying working mechanisms of neural circuits. One\ndrawback of training a large scale spiking neural network is that an expensive\ncost of updating all weights is required. Furthermore, after training, all\ninformation related to the computational task is hidden into the weight matrix,\nprohibiting us from a transparent understanding of circuit mechanisms.\nTherefore, in this work, we address these challenges by proposing a spiking\nmode-based training protocol. The first advantage is that the weight is\ninterpreted by input and output modes and their associated scores\ncharacterizing importance of each decomposition term. The number of modes is\nthus adjustable, allowing more degrees of freedom for modeling the experimental\ndata. This reduces a sizable training cost because of significantly reduced\nspace complexity for learning. The second advantage is that one can project the\nhigh dimensional neural activity in the ambient space onto the mode space which\nis typically of a low dimension, e.g., a few modes are sufficient to capture\nthe shape of the underlying neural manifolds. We analyze our framework in two\ncomputational tasks -- digit classification and selective sensory integration\ntasks. Our work thus derives a mode-based learning rule for spiking neural\nnetworks.",
            "author": [
                "Zhanghan Lin",
                "Haiping Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14621v1",
                "http://arxiv.org/pdf/2310.14621v1"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC",
                "cond-mat.dis-nn",
                "cs.AI",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14616v1",
            "title": "Rethinking SIGN Training: Provable Nonconvex Acceleration without First-\n  and Second-Order Gradient Lipschitz",
            "updated": "2023-10-23T06:48:43Z",
            "published": "2023-10-23T06:48:43Z",
            "summary": "Sign-based stochastic methods have gained attention due to their ability to\nachieve robust performance despite using only the sign information for\nparameter updates. However, the current convergence analysis of sign-based\nmethods relies on the strong assumptions of first-order gradient Lipschitz and\nsecond-order gradient Lipschitz, which may not hold in practical tasks like\ndeep neural network training that involve high non-smoothness. In this paper,\nwe revisit sign-based methods and analyze their convergence under more\nrealistic assumptions of first- and second-order smoothness. We first establish\nthe convergence of the sign-based method under weak first-order Lipschitz.\nMotivated by the weak first-order Lipschitz, we propose a relaxed second-order\ncondition that still allows for nonconvex acceleration in sign-based methods.\nBased on our theoretical results, we gain insights into the computational\nadvantages of the recently developed LION algorithm. In distributed settings,\nwe prove that this nonconvex acceleration persists with linear speedup in the\nnumber of nodes, when utilizing fast communication compression gossip\nprotocols. The novelty of our theoretical results lies in that they are derived\nunder much weaker assumptions, thereby expanding the provable applicability of\nsign-based algorithms to a wider range of problems.",
            "author": [
                "Tao Sun",
                "Congliang Chen",
                "Peng Qiao",
                "Li Shen",
                "Xinwang Liu",
                "Dongsheng Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14616v1",
                "http://arxiv.org/pdf/2310.14616v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14614v1",
            "title": "Efficient Cross-Task Prompt Tuning for Few-Shot Conversational Emotion\n  Recognition",
            "updated": "2023-10-23T06:46:03Z",
            "published": "2023-10-23T06:46:03Z",
            "summary": "Emotion Recognition in Conversation (ERC) has been widely studied due to its\nimportance in developing emotion-aware empathetic machines. The rise of\npre-trained language models (PLMs) has further pushed the limit of ERC\nperformance. However, most recent works on ERC using PLMs are heavily\ndata-driven, and requires fine-tuning the entire PLMs. To improve both sample\nand computational efficiency, we propose a derivative-free optimization method\ncalled Cross-Task Prompt Tuning (CTPT) for few-shot conversational emotion\nrecognition. Unlike existing methods that learn independent knowledge from\nindividual tasks, CTPT leverages sharable cross-task knowledge by exploiting\nexternal knowledge from other source tasks to improve learning performance\nunder the few-shot setting. Moreover, CTPT only needs to optimize a vector\nunder the low intrinsic dimensionality without gradient, which is highly\nparameter-efficient compared with existing approaches. Experiments on five\ndifferent contextual conversation datasets demonstrate that our CTPT method has\nsuperior results on both few-shot scenarios and zero-shot transfers.",
            "author": [
                "Yige Xu",
                "Zhiwei Zeng",
                "Zhiqi Shen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14614v1",
                "http://arxiv.org/pdf/2310.14614v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17664v1",
            "title": "Cascaded Multi-task Adaptive Learning Based on Neural Architecture\n  Search",
            "updated": "2023-10-23T06:43:50Z",
            "published": "2023-10-23T06:43:50Z",
            "summary": "Cascading multiple pre-trained models is an effective way to compose an\nend-to-end system. However, fine-tuning the full cascaded model is parameter\nand memory inefficient and our observations reveal that only applying adapter\nmodules on cascaded model can not achieve considerable performance as\nfine-tuning. We propose an automatic and effective adaptive learning method to\noptimize end-to-end cascaded multi-task models based on Neural Architecture\nSearch (NAS) framework. The candidate adaptive operations on each specific\nmodule consist of frozen, inserting an adapter and fine-tuning. We further add\na penalty item on the loss to limit the learned structure which takes the\namount of trainable parameters into account. The penalty item successfully\nrestrict the searched architecture and the proposed approach is able to search\nsimilar tuning scheme with hand-craft, compressing the optimizing parameters to\n8.7% corresponding to full fine-tuning on SLURP with an even better\nperformance.",
            "author": [
                "Yingying Gao",
                "Shilei Zhang",
                "Zihao Cui",
                "Chao Deng",
                "Junlan Feng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17664v1",
                "http://arxiv.org/pdf/2310.17664v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "eess.AS",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.12854v1",
            "title": "Enhancing Robotic Manipulation: Harnessing the Power of Multi-Task\n  Reinforcement Learning and Single Life Reinforcement Learning in Meta-World",
            "updated": "2023-10-23T06:35:44Z",
            "published": "2023-10-23T06:35:44Z",
            "summary": "At present, robots typically require extensive training to successfully\naccomplish a single task. However, to truly enhance their usefulness in\nreal-world scenarios, robots should possess the capability to perform multiple\ntasks effectively. To address this need, various multi-task reinforcement\nlearning (RL) algorithms have been developed, including multi-task proximal\npolicy optimization (PPO), multi-task trust region policy optimization (TRPO),\nand multi-task soft-actor critic (SAC). Nevertheless, these algorithms\ndemonstrate optimal performance only when operating within an environment or\nobservation space that exhibits a similar distribution. In reality, such\nconditions are often not the norm, as robots may encounter scenarios or\nobservations that differ from those on which they were trained. Addressing this\nchallenge, algorithms like Q-Weighted Adversarial Learning (QWALE) attempt to\ntackle the issue by training the base algorithm (generating prior data) solely\nfor a particular task, rendering it unsuitable for generalization across tasks.\nSo, the aim of this research project is to enable a robotic arm to successfully\nexecute seven distinct tasks within the Meta World environment. To achieve\nthis, a multi-task soft actor-critic (MT-SAC) is employed to train the robotic\narm. Subsequently, the trained model will serve as a source of prior data for\nthe single-life RL algorithm. The effectiveness of this MT-QWALE algorithm will\nbe assessed by conducting tests on various target positions (novel positions).\nIn the end, a comparison is provided between the trained MT-SAC and the\nMT-QWALE algorithm where the MT-QWALE performs better. An ablation study\ndemonstrates that MT-QWALE successfully completes tasks with a slightly larger\nnumber of steps even after hiding the final goal position.",
            "author": [
                "Ghadi Nehme",
                "Ishan Sabane",
                "Tejas Y. Deo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12854v1",
                "http://arxiv.org/pdf/2311.12854v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14608v1",
            "title": "CAD-DA: Controllable Anomaly Detection after Domain Adaptation by\n  Statistical Inference",
            "updated": "2023-10-23T06:34:33Z",
            "published": "2023-10-23T06:34:33Z",
            "summary": "We propose a novel statistical method for testing the results of anomaly\ndetection (AD) under domain adaptation (DA), which we call CAD-DA --\ncontrollable AD under DA. The distinct advantage of the CAD-DA lies in its\nability to control the probability of misidentifying anomalies under a\npre-specified level $\\alpha$ (e.g., 0.05). The challenge within this DA setting\nis the necessity to account for the influence of DA to ensure the validity of\nthe inference results. Our solution to this challenge leverages the concept of\nconditional Selective Inference to handle the impact of DA. To our knowledge,\nthis is the first work capable of conducting a valid statistical inference\nwithin the context of DA. We evaluate the performance of the CAD-DA method on\nboth synthetic and real-world datasets.",
            "author": [
                "Vo Nguyen Le Duy",
                "Hsuan-Tien Lin",
                "Ichiro Takeuchi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14608v1",
                "http://arxiv.org/pdf/2310.14608v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14607v1",
            "title": "Investigating the Fairness of Large Language Models for Predictions on\n  Tabular Data",
            "updated": "2023-10-23T06:31:28Z",
            "published": "2023-10-23T06:31:28Z",
            "summary": "Recent literature has suggested the potential of using large language models\n(LLMs) to make predictions for tabular tasks. However, LLMs have been shown to\nexhibit harmful social biases that reflect the stereotypes and inequalities\npresent in the society. To this end, as well as the widespread use of tabular\ndata in many high-stake applications, it is imperative to explore the following\nquestions: what sources of information do LLMs draw upon when making\npredictions for tabular tasks; whether and to what extent are LLM predictions\nfor tabular tasks influenced by social biases and stereotypes; and what are the\nconsequential implications for fairness? Through a series of experiments, we\ndelve into these questions and show that LLMs tend to inherit social biases\nfrom their training data which significantly impact their fairness in tabular\nprediction tasks. Furthermore, our investigations show that in the context of\nbias mitigation, though in-context learning and fine-tuning have a moderate\neffect, the fairness metric gap between different subgroups is still larger\nthan that in traditional machine learning models, such as Random Forest and\nshallow Neural Networks. This observation emphasizes that the social biases are\ninherent within the LLMs themselves and inherited from their pre-training\ncorpus, not only from the downstream task datasets. Besides, we demonstrate\nthat label-flipping of in-context examples can significantly reduce biases,\nfurther highlighting the presence of inherent bias within LLMs.",
            "author": [
                "Yanchen Liu",
                "Srishti Gautam",
                "Jiaqi Ma",
                "Himabindu Lakkaraju"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14607v1",
                "http://arxiv.org/pdf/2310.14607v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14605v1",
            "title": "M2DF: Multi-grained Multi-curriculum Denoising Framework for Multimodal\n  Aspect-based Sentiment Analysis",
            "updated": "2023-10-23T06:22:39Z",
            "published": "2023-10-23T06:22:39Z",
            "summary": "Multimodal Aspect-based Sentiment Analysis (MABSA) is a fine-grained\nSentiment Analysis task, which has attracted growing research interests\nrecently. Existing work mainly utilizes image information to improve the\nperformance of MABSA task. However, most of the studies overestimate the\nimportance of images since there are many noise images unrelated to the text in\nthe dataset, which will have a negative impact on model learning. Although some\nwork attempts to filter low-quality noise images by setting thresholds, relying\non thresholds will inevitably filter out a lot of useful image information.\nTherefore, in this work, we focus on whether the negative impact of noisy\nimages can be reduced without modifying the data. To achieve this goal, we\nborrow the idea of Curriculum Learning and propose a Multi-grained\nMulti-curriculum Denoising Framework (M2DF), which can achieve denoising by\nadjusting the order of training data. Extensive experimental results show that\nour framework consistently outperforms state-of-the-art work on three sub-tasks\nof MABSA.",
            "author": [
                "Fei Zhao",
                "Chunhui Li",
                "Zhen Wu",
                "Yawen Ouyang",
                "Jianbing Zhang",
                "Xinyu Dai"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14605v1",
                "http://arxiv.org/pdf/2310.14605v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14596v1",
            "title": "Learning to Correct Noisy Labels for Fine-Grained Entity Typing via\n  Co-Prediction Prompt Tuning",
            "updated": "2023-10-23T06:04:07Z",
            "published": "2023-10-23T06:04:07Z",
            "summary": "Fine-grained entity typing (FET) is an essential task in natural language\nprocessing that aims to assign semantic types to entities in text. However, FET\nposes a major challenge known as the noise labeling problem, whereby current\nmethods rely on estimating noise distribution to identify noisy labels but are\nconfused by diverse noise distribution deviation. To address this limitation,\nwe introduce Co-Prediction Prompt Tuning for noise correction in FET, which\nleverages multiple prediction results to identify and correct noisy labels.\nSpecifically, we integrate prediction results to recall labeled labels and\nutilize a differentiated margin to identify inaccurate labels. Moreover, we\ndesign an optimization objective concerning divergent co-predictions during\nfine-tuning, ensuring that the model captures sufficient information and\nmaintains robustness in noise identification. Experimental results on three\nwidely-used FET datasets demonstrate that our noise correction approach\nsignificantly enhances the quality of various types of training samples,\nincluding those annotated using distant supervision, ChatGPT, and\ncrowdsourcing.",
            "author": [
                "Minghao Tang",
                "Yongquan He",
                "Yongxiu Xu",
                "Hongbo Xu",
                "Wenyuan Zhang",
                "Yang Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14596v1",
                "http://arxiv.org/pdf/2310.14596v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14595v1",
            "title": "Online Auditing of Information Flow",
            "updated": "2023-10-23T06:03:55Z",
            "published": "2023-10-23T06:03:55Z",
            "summary": "Modern social media platforms play an important role in facilitating rapid\ndissemination of information through their massive user networks. Fake news,\nmisinformation, and unverifiable facts on social media platforms propagate\ndisharmony and affect society. In this paper, we consider the problem of online\nauditing of information flow/propagation with the goal of classifying news\nitems as fake or genuine. Specifically, driven by experiential studies on\nreal-world social media platforms, we propose a probabilistic Markovian\ninformation spread model over networks modeled by graphs. We then formulate our\ninference task as a certain sequential detection problem with the goal of\nminimizing the combination of the error probability and the time it takes to\nachieve correct decision. For this model, we find the optimal detection\nalgorithm minimizing the aforementioned risk and prove several statistical\nguarantees. We then test our algorithm over real-world datasets. To that end,\nwe first construct an offline algorithm for learning the probabilistic\ninformation spreading model, and then apply our optimal detection algorithm.\nExperimental study show that our algorithm outperforms state-of-the-art\nmisinformation detection algorithms in terms of accuracy and detection time.",
            "author": [
                "Mor Oren-Loberman",
                "Vered Azar",
                "Wasim Huleihel"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14595v1",
                "http://arxiv.org/pdf/2310.14595v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14592v1",
            "title": "Pre-Training LiDAR-Based 3D Object Detectors Through Colorization",
            "updated": "2023-10-23T06:00:24Z",
            "published": "2023-10-23T06:00:24Z",
            "summary": "Accurate 3D object detection and understanding for self-driving cars heavily\nrelies on LiDAR point clouds, necessitating large amounts of labeled data to\ntrain. In this work, we introduce an innovative pre-training approach, Grounded\nPoint Colorization (GPC), to bridge the gap between data and labels by teaching\nthe model to colorize LiDAR point clouds, equipping it with valuable semantic\ncues. To tackle challenges arising from color variations and selection bias, we\nincorporate color as \"context\" by providing ground-truth colors as hints during\ncolorization. Experimental results on the KITTI and Waymo datasets demonstrate\nGPC's remarkable effectiveness. Even with limited labeled data, GPC\nsignificantly improves fine-tuning performance; notably, on just 20% of the\nKITTI dataset, GPC outperforms training from scratch with the entire dataset.\nIn sum, we introduce a fresh perspective on pre-training for 3D object\ndetection, aligning the objective with the model's intended role and ultimately\nadvancing the accuracy and efficiency of 3D object detection for autonomous\nvehicles.",
            "author": [
                "Tai-Yu Pan",
                "Chenyang Ma",
                "Tianle Chen",
                "Cheng Perng Phoo",
                "Katie Z Luo",
                "Yurong You",
                "Mark Campbell",
                "Kilian Q. Weinberger",
                "Bharath Hariharan",
                "Wei-Lun Chao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14592v1",
                "http://arxiv.org/pdf/2310.14592v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14586v2",
            "title": "GNNEvaluator: Evaluating GNN Performance On Unseen Graphs Without Labels",
            "updated": "2023-10-26T23:08:52Z",
            "published": "2023-10-23T05:51:59Z",
            "summary": "Evaluating the performance of graph neural networks (GNNs) is an essential\ntask for practical GNN model deployment and serving, as deployed GNNs face\nsignificant performance uncertainty when inferring on unseen and unlabeled test\ngraphs, due to mismatched training-test graph distributions. In this paper, we\nstudy a new problem, GNN model evaluation, that aims to assess the performance\nof a specific GNN model trained on labeled and observed graphs, by precisely\nestimating its performance (e.g., node classification accuracy) on unseen\ngraphs without labels. Concretely, we propose a two-stage GNN model evaluation\nframework, including (1) DiscGraph set construction and (2) GNNEvaluator\ntraining and inference. The DiscGraph set captures wide-range and diverse graph\ndata distribution discrepancies through a discrepancy measurement function,\nwhich exploits the outputs of GNNs related to latent node embeddings and node\nclass predictions. Under the effective training supervision from the DiscGraph\nset, GNNEvaluator learns to precisely estimate node classification accuracy of\nthe to-be-evaluated GNN model and makes an accurate inference for evaluating\nGNN model performance. Extensive experiments on real-world unseen and unlabeled\ntest graphs demonstrate the effectiveness of our proposed method for GNN model\nevaluation.",
            "author": [
                "Xin Zheng",
                "Miao Zhang",
                "Chunyang Chen",
                "Soheila Molaei",
                "Chuan Zhou",
                "Shirui Pan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14586v2",
                "http://arxiv.org/pdf/2310.14586v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14583v1",
            "title": "JointMatch: A Unified Approach for Diverse and Collaborative\n  Pseudo-Labeling to Semi-Supervised Text Classification",
            "updated": "2023-10-23T05:43:35Z",
            "published": "2023-10-23T05:43:35Z",
            "summary": "Semi-supervised text classification (SSTC) has gained increasing attention\ndue to its ability to leverage unlabeled data. However, existing approaches\nbased on pseudo-labeling suffer from the issues of pseudo-label bias and error\naccumulation. In this paper, we propose JointMatch, a holistic approach for\nSSTC that addresses these challenges by unifying ideas from recent\nsemi-supervised learning and the task of learning with noise. JointMatch\nadaptively adjusts classwise thresholds based on the learning status of\ndifferent classes to mitigate model bias towards current easy classes.\nAdditionally, JointMatch alleviates error accumulation by utilizing two\ndifferently initialized networks to teach each other in a cross-labeling\nmanner. To maintain divergence between the two networks for mutual learning, we\nintroduce a strategy that weighs more disagreement data while also allowing the\nutilization of high-quality agreement data for training. Experimental results\non benchmark datasets demonstrate the superior performance of JointMatch,\nachieving a significant 5.13% improvement on average. Notably, JointMatch\ndelivers impressive results even in the extremely-scarce-label setting,\nobtaining 86% accuracy on AG News with only 5 labels per class. We make our\ncode available at https://github.com/HenryPengZou/JointMatch.",
            "author": [
                "Henry Peng Zou",
                "Cornelia Caragea"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14583v1",
                "http://arxiv.org/pdf/2310.14583v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14581v1",
            "title": "Leveraging Image-Text Similarity and Caption Modification for the\n  DataComp Challenge: Filtering Track and BYOD Track",
            "updated": "2023-10-23T05:40:43Z",
            "published": "2023-10-23T05:40:43Z",
            "summary": "Large web crawl datasets have already played an important role in learning\nmultimodal features with high generalization capabilities. However, there are\nstill very limited studies investigating the details or improvements of data\ndesign. Recently, a DataComp challenge has been designed to propose the best\ntraining data with the fixed models. This paper presents our solution to both\nfiltering track and BYOD track of the DataComp challenge. Our solution adopts\nlarge multimodal models CLIP and BLIP-2 to filter and modify web crawl data,\nand utilize external datasets along with a bag of tricks to improve the data\nquality. Experiments show our solution significantly outperforms DataComp\nbaselines (filtering track: 6.6% improvement, BYOD track: 48.5% improvement).",
            "author": [
                "Shuhei Yokoo",
                "Peifei Zhu",
                "Yuchi Ishikawa",
                "Mikihiro Tanaka",
                "Masayoshi Kondo",
                "Hirokatsu Kataoka"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14581v1",
                "http://arxiv.org/pdf/2310.14581v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14580v3",
            "title": "Acoustic BPE for Speech Generation with Discrete Tokens",
            "updated": "2023-12-06T23:34:04Z",
            "published": "2023-10-23T05:38:41Z",
            "summary": "Discrete audio tokens derived from self-supervised learning models have\ngained widespread usage in speech generation. However, current practice of\ndirectly utilizing audio tokens poses challenges for sequence modeling due to\nthe length of the token sequence. Additionally, this approach places the burden\non the model to establish correlations between tokens, further complicating the\nmodeling process. To address this issue, we propose acoustic BPE which encodes\nfrequent audio token patterns by utilizing byte-pair encoding. Acoustic BPE\neffectively reduces the sequence length and leverages the prior morphological\ninformation present in token sequence, which alleviates the modeling challenges\nof token correlation. Through comprehensive investigations on a speech language\nmodel trained with acoustic BPE, we confirm the notable advantages it offers,\nincluding faster inference and improved syntax capturing capabilities. In\naddition, we propose a novel rescore method to select the optimal synthetic\nspeech among multiple candidates generated by rich-diversity TTS system.\nExperiments prove that rescore selection aligns closely with human preference,\nwhich highlights acoustic BPE's potential to other speech generation tasks.",
            "author": [
                "Feiyu Shen",
                "Yiwei Guo",
                "Chenpeng Du",
                "Xie Chen",
                "Kai Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14580v3",
                "http://arxiv.org/pdf/2310.14580v3"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14579v1",
            "title": "FedSplitX: Federated Split Learning for Computationally-Constrained\n  Heterogeneous Clients",
            "updated": "2023-10-23T05:34:31Z",
            "published": "2023-10-23T05:34:31Z",
            "summary": "Foundation models (FMs) have demonstrated remarkable performance in machine\nlearning but demand extensive training data and computational resources.\nFederated learning (FL) addresses the challenges posed by FMs, especially\nrelated to data privacy and computational burdens. However, FL on FMs faces\nchallenges in situations with heterogeneous clients possessing varying\ncomputing capabilities, as clients with limited capabilities may struggle to\ntrain the computationally intensive FMs. To address these challenges, we\npropose FedSplitX, a novel FL framework that tackles system heterogeneity.\nFedSplitX splits a large model into client-side and server-side components at\nmultiple partition points to accommodate diverse client capabilities. This\napproach enables clients to collaborate while leveraging the server's\ncomputational power, leading to improved model performance compared to\nbaselines that limit model size to meet the requirement of the poorest client.\nFurthermore, FedSplitX incorporates auxiliary networks at each partition point\nto reduce communication costs and delays while enhancing model performance. Our\nexperiments demonstrate that FedSplitX effectively utilizes server capabilities\nto train large models, outperforming baseline approaches.",
            "author": [
                "Jiyun Shin",
                "Jinhyun Ahn",
                "Honggu Kang",
                "Joonhyuk Kang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14579v1",
                "http://arxiv.org/pdf/2310.14579v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14577v1",
            "title": "DeCrisisMB: Debiased Semi-Supervised Learning for Crisis Tweet\n  Classification via Memory Bank",
            "updated": "2023-10-23T05:25:51Z",
            "published": "2023-10-23T05:25:51Z",
            "summary": "During crisis events, people often use social media platforms such as Twitter\nto disseminate information about the situation, warnings, advice, and support.\nEmergency relief organizations leverage such information to acquire timely\ncrisis circumstances and expedite rescue operations. While existing works\nutilize such information to build models for crisis event analysis,\nfully-supervised approaches require annotating vast amounts of data and are\nimpractical due to limited response time. On the other hand, semi-supervised\nmodels can be biased, performing moderately well for certain classes while\nperforming extremely poorly for others, resulting in substantially negative\neffects on disaster monitoring and rescue. In this paper, we first study two\nrecent debiasing methods on semi-supervised crisis tweet classification. Then\nwe propose a simple but effective debiasing method, DeCrisisMB, that utilizes a\nMemory Bank to store and perform equal sampling for generated pseudo-labels\nfrom each class at each training iteration. Extensive experiments are conducted\nto compare different debiasing methods' performance and generalization ability\nin both in-distribution and out-of-distribution settings. The results\ndemonstrate the superior performance of our proposed method. Our code is\navailable at https://github.com/HenryPengZou/DeCrisisMB.",
            "author": [
                "Henry Peng Zou",
                "Yue Zhou",
                "Weizhi Zhang",
                "Cornelia Caragea"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14577v1",
                "http://arxiv.org/pdf/2310.14577v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14576v1",
            "title": "Tensor Decomposition Based Attention Module for Spiking Neural Networks",
            "updated": "2023-10-23T05:25:49Z",
            "published": "2023-10-23T05:25:49Z",
            "summary": "The attention mechanism has been proven to be an effective way to improve\nspiking neural network (SNN). However, based on the fact that the current SNN\ninput data flow is split into tensors to process on GPUs, none of the previous\nworks consider the properties of tensors to implement an attention module. This\ninspires us to rethink current SNN from the perspective of tensor-relevant\ntheories. Using tensor decomposition, we design the \\textit{projected full\nattention} (PFA) module, which demonstrates excellent results with linearly\ngrowing parameters. Specifically, PFA is composed by the \\textit{linear\nprojection of spike tensor} (LPST) module and \\textit{attention map composing}\n(AMC) module. In LPST, we start by compressing the original spike tensor into\nthree projected tensors using a single property-preserving strategy with\nlearnable parameters for each dimension. Then, in AMC, we exploit the inverse\nprocedure of the tensor decomposition process to combine the three tensors into\nthe attention map using a so-called connecting factor. To validate the\neffectiveness of the proposed PFA module, we integrate it into the widely used\nVGG and ResNet architectures for classification tasks. Our method achieves\nstate-of-the-art performance on both static and dynamic benchmark datasets,\nsurpassing the existing SNN models with Transformer-based and CNN-based\nbackbones.",
            "author": [
                "Haoyu Deng",
                "Ruijie Zhu",
                "Xuerui Qiu",
                "Yule Duan",
                "Malu Zhang",
                "Liangjian Deng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14576v1",
                "http://arxiv.org/pdf/2310.14576v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14573v1",
            "title": "Exploring the Boundaries of GPT-4 in Radiology",
            "updated": "2023-10-23T05:13:03Z",
            "published": "2023-10-23T05:13:03Z",
            "summary": "The recent success of general-domain large language models (LLMs) has\nsignificantly changed the natural language processing paradigm towards a\nunified foundation model across domains and applications. In this paper, we\nfocus on assessing the performance of GPT-4, the most capable LLM so far, on\nthe text-based applications for radiology reports, comparing against\nstate-of-the-art (SOTA) radiology-specific models. Exploring various prompting\nstrategies, we evaluated GPT-4 on a diverse range of common radiology tasks and\nwe found GPT-4 either outperforms or is on par with current SOTA radiology\nmodels. With zero-shot prompting, GPT-4 already obtains substantial gains\n($\\approx$ 10% absolute improvement) over radiology models in temporal sentence\nsimilarity classification (accuracy) and natural language inference ($F_1$).\nFor tasks that require learning dataset-specific style or schema (e.g. findings\nsummarisation), GPT-4 improves with example-based prompting and matches\nsupervised SOTA. Our extensive error analysis with a board-certified\nradiologist shows GPT-4 has a sufficient level of radiology knowledge with only\noccasional errors in complex context that require nuanced domain knowledge. For\nfindings summarisation, GPT-4 outputs are found to be overall comparable with\nexisting manually-written impressions.",
            "author": [
                "Qianchu Liu",
                "Stephanie Hyland",
                "Shruthi Bannur",
                "Kenza Bouzid",
                "Daniel C. Castro",
                "Maria Teodora Wetscherek",
                "Robert Tinn",
                "Harshita Sharma",
                "Fernando P\u00e9rez-Garc\u00eda",
                "Anton Schwaighofer",
                "Pranav Rajpurkar",
                "Sameer Tajdin Khanna",
                "Hoifung Poon",
                "Naoto Usuyama",
                "Anja Thieme",
                "Aditya V. Nori",
                "Matthew P. Lungren",
                "Ozan Oktay",
                "Javier Alvarez-Valle"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14573v1",
                "http://arxiv.org/pdf/2310.14573v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18348v3",
            "title": "Meaning Representations from Trajectories in Autoregressive Models",
            "updated": "2023-11-29T05:32:24Z",
            "published": "2023-10-23T04:35:58Z",
            "summary": "We propose to extract meaning representations from autoregressive language\nmodels by considering the distribution of all possible trajectories extending\nan input text. This strategy is prompt-free, does not require fine-tuning, and\nis applicable to any pre-trained autoregressive model. Moreover, unlike\nvector-based representations, distribution-based representations can also model\nasymmetric relations (e.g., direction of logical entailment, hypernym/hyponym\nrelations) by using algebraic operations between likelihood functions. These\nideas are grounded in distributional perspectives on semantics and are\nconnected to standard constructions in automata theory, but to our knowledge\nthey have not been applied to modern language models. We empirically show that\nthe representations obtained from large models align well with human\nannotations, outperform other zero-shot and prompt-free methods on semantic\nsimilarity tasks, and can be used to solve more complex entailment and\ncontainment tasks that standard embeddings cannot handle. Finally, we extend\nour method to represent data from different modalities (e.g., image and text)\nusing multimodal autoregressive models. Our code is available at:\nhttps://github.com/tianyu139/meaning-as-trajectories",
            "author": [
                "Tian Yu Liu",
                "Matthew Trager",
                "Alessandro Achille",
                "Pramuditha Perera",
                "Luca Zancato",
                "Stefano Soatto"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18348v3",
                "http://arxiv.org/pdf/2310.18348v3"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14561v1",
            "title": "F$^2$AT: Feature-Focusing Adversarial Training via Disentanglement of\n  Natural and Perturbed Patterns",
            "updated": "2023-10-23T04:31:42Z",
            "published": "2023-10-23T04:31:42Z",
            "summary": "Deep neural networks (DNNs) are vulnerable to adversarial examples crafted by\nwell-designed perturbations. This could lead to disastrous results on critical\napplications such as self-driving cars, surveillance security, and medical\ndiagnosis. At present, adversarial training is one of the most effective\ndefenses against adversarial examples. However, traditional adversarial\ntraining makes it difficult to achieve a good trade-off between clean accuracy\nand robustness since spurious features are still learned by DNNs. The intrinsic\nreason is that traditional adversarial training makes it difficult to fully\nlearn core features from adversarial examples when adversarial noise and clean\nexamples cannot be disentangled. In this paper, we disentangle the adversarial\nexamples into natural and perturbed patterns by bit-plane slicing. We assume\nthe higher bit-planes represent natural patterns and the lower bit-planes\nrepresent perturbed patterns, respectively. We propose a Feature-Focusing\nAdversarial Training (F$^2$AT), which differs from previous work in that it\nenforces the model to focus on the core features from natural patterns and\nreduce the impact of spurious features from perturbed patterns. The\nexperimental results demonstrated that F$^2$AT outperforms state-of-the-art\nmethods in clean accuracy and adversarial robustness.",
            "author": [
                "Yaguan Qian",
                "Chenyu Zhao",
                "Zhaoquan Gu",
                "Bin Wang",
                "Shouling Ji",
                "Wei Wang",
                "Boyang Zhou",
                "Pan Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14561v1",
                "http://arxiv.org/pdf/2310.14561v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10735v1",
            "title": "Safe Navigation: Training Autonomous Vehicles using Deep Reinforcement\n  Learning in CARLA",
            "updated": "2023-10-23T04:23:07Z",
            "published": "2023-10-23T04:23:07Z",
            "summary": "Autonomous vehicles have the potential to revolutionize transportation, but\nthey must be able to navigate safely in traffic before they can be deployed on\npublic roads. The goal of this project is to train autonomous vehicles to make\ndecisions to navigate in uncertain environments using deep reinforcement\nlearning techniques using the CARLA simulator. The simulator provides a\nrealistic and urban environment for training and testing self-driving models.\nDeep Q-Networks (DQN) are used to predict driving actions. The study involves\nthe integration of collision sensors, segmentation, and depth camera for better\nobject detection and distance estimation. The model is tested on 4 different\ntrajectories in presence of different types of 4-wheeled vehicles and\npedestrians. The segmentation and depth cameras were utilized to ensure\naccurate localization of objects and distance measurement. Our proposed method\nsuccessfully navigated the self-driving vehicle to its final destination with a\nhigh success rate without colliding with other vehicles, pedestrians, or going\non the sidewalk. To ensure the optimal performance of our reinforcement\nlearning (RL) models in navigating complex traffic scenarios, we implemented a\npre-processing step to reduce the state space. This involved processing the\nimages and sensor output before feeding them into the model. Despite\nsignificantly decreasing the state space, our approach yielded robust models\nthat successfully navigated through traffic with high levels of safety and\naccuracy.",
            "author": [
                "Ghadi Nehme",
                "Tejas Y. Deo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10735v1",
                "http://arxiv.org/pdf/2311.10735v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14557v1",
            "title": "The Skipped Beat: A Study of Sociopragmatic Understanding in LLMs for 64\n  Languages",
            "updated": "2023-10-23T04:22:44Z",
            "published": "2023-10-23T04:22:44Z",
            "summary": "Instruction tuned large language models (LLMs), such as ChatGPT, demonstrate\nremarkable performance in a wide range of tasks. Despite numerous recent\nstudies that examine the performance of instruction-tuned LLMs on various NLP\nbenchmarks, there remains a lack of comprehensive investigation into their\nability to understand cross-lingual sociopragmatic meaning (SM), i.e., meaning\nembedded within social and interactive contexts. This deficiency arises partly\nfrom SM not being adequately represented in any of the existing benchmarks. To\naddress this gap, we present SPARROW, an extensive multilingual benchmark\nspecifically designed for SM understanding. SPARROW comprises 169 datasets\ncovering 13 task types across six primary categories (e.g., anti-social\nlanguage detection, emotion recognition). SPARROW datasets encompass 64\ndifferent languages originating from 12 language families representing 16\nwriting scripts. We evaluate the performance of various multilingual pretrained\nlanguage models (e.g., mT5) and instruction-tuned LLMs (e.g., BLOOMZ, ChatGPT)\non SPARROW through fine-tuning, zero-shot, and/or few-shot learning. Our\ncomprehensive analysis reveals that existing open-source instruction tuned LLMs\nstill struggle to understand SM across various languages, performing close to a\nrandom baseline in some cases. We also find that although ChatGPT outperforms\nmany LLMs, it still falls behind task-specific finetuned models with a gap of\n12.19 SPARROW score. Our benchmark is available at:\nhttps://github.com/UBC-NLP/SPARROW",
            "author": [
                "Chiyu Zhang",
                "Khai Duy Doan",
                "Qisheng Liao",
                "Muhammad Abdul-Mageed"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14557v1",
                "http://arxiv.org/pdf/2310.14557v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14555v1",
            "title": "Modeling groundwater levels in California's Central Valley by\n  hierarchical Gaussian process and neural network regression",
            "updated": "2023-10-23T04:21:26Z",
            "published": "2023-10-23T04:21:26Z",
            "summary": "Modeling groundwater levels continuously across California's Central Valley\n(CV) hydrological system is challenging due to low-quality well data which is\nsparsely and noisily sampled across time and space. A novel machine learning\nmethod is proposed for modeling groundwater levels by learning from a 3D\nlithological texture model of the CV aquifer. The proposed formulation performs\nmultivariate regression by combining Gaussian processes (GP) and deep neural\nnetworks (DNN). Proposed hierarchical modeling approach constitutes training\nthe DNN to learn a lithologically informed latent space where non-parametric\nregression with GP is performed. The methodology is applied for modeling\ngroundwater levels across the CV during 2015 - 2020. We demonstrate the\nefficacy of GP-DNN regression for modeling non-stationary features in the well\ndata with fast and reliable uncertainty quantification. Our results indicate\nthat the 2017 and 2019 wet years in California were largely ineffective in\nreplenishing the groundwater loss caused during previous drought years.",
            "author": [
                "Anshuman Pradhan",
                "Kyra H. Adams",
                "Venkat Chandrasekaran",
                "Zhen Liu",
                "John T. Reager",
                "Andrew M. Stuart",
                "Michael J. Turmon"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14555v1",
                "http://arxiv.org/pdf/2310.14555v1"
            ],
            "primary_category": "physics.geo-ph",
            "category": [
                "physics.geo-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14554v1",
            "title": "Making RL with Preference-based Feedback Efficient via Randomization",
            "updated": "2023-10-23T04:19:35Z",
            "published": "2023-10-23T04:19:35Z",
            "summary": "Reinforcement Learning algorithms that learn from human feedback (RLHF) need\nto be efficient in terms of statistical complexity, computational complexity,\nand query complexity. In this work, we consider the RLHF setting where the\nfeedback is given in the format of preferences over pairs of trajectories. In\nthe linear MDP model, by using randomization in algorithm design, we present an\nalgorithm that is sample efficient (i.e., has near-optimal worst-case regret\nbounds) and has polynomial running time (i.e., computational complexity is\npolynomial with respect to relevant parameters). Our algorithm further\nminimizes the query complexity through a novel randomized active learning\nprocedure. In particular, our algorithm demonstrates a near-optimal tradeoff\nbetween the regret bound and the query complexity. To extend the results to\nmore general nonlinear function approximation, we design a model-based\nrandomized algorithm inspired by the idea of Thompson sampling. Our algorithm\nminimizes Bayesian regret bound and query complexity, again achieving a\nnear-optimal tradeoff between these two quantities. Computation-wise, similar\nto the prior Thompson sampling algorithms under the regular RL setting, the\nmain computation primitives of our algorithm are Bayesian supervised learning\noracles which have been heavily investigated on the empirical side when\napplying Thompson sampling algorithms to RL benchmark problems.",
            "author": [
                "Runzhe Wu",
                "Wen Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14554v1",
                "http://arxiv.org/pdf/2310.14554v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14553v1",
            "title": "Denoising Opponents Position in Partial Observation Environment",
            "updated": "2023-10-23T04:16:52Z",
            "published": "2023-10-23T04:16:52Z",
            "summary": "The RoboCup competitions hold various leagues, and the Soccer Simulation 2D\nLeague is a major among them. Soccer Simulation 2D (SS2D) match involves two\nteams, including 11 players and a coach for each team, competing against each\nother. The players can only communicate with the Soccer Simulation Server\nduring the game. Several code bases are released publicly to simplify team\ndevelopment. So researchers can easily focus on decision-making and\nimplementing machine learning methods. SS2D actions and behaviors are only\npartially accurate due to different challenges, such as noise and partial\nobservation. Therefore, one strategy is to implement alternative denoising\nmethods to tackle observation inaccuracy. Our idea is to predict opponent\npositions while they have yet to be seen in a finite number of cycles using\nmachine learning methods to make more accurate actions such as pass. We will\nexplain our position prediction idea powered by Long Short-Term Memory models\n(LSTM) and Deep Neural Networks (DNN). The results show that the LSTM and DNN\npredict the opponents' position more accurately than the standard algorithm,\nsuch as the last-seen method.",
            "author": [
                "Aref Sayareh",
                "Aria Sardari",
                "Vahid Khoddami",
                "Nader Zare",
                "Vinicius Prado da Fonseca",
                "Amilcar Soares"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14553v1",
                "http://arxiv.org/pdf/2310.14553v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14552v1",
            "title": "KindMed: Knowledge-Induced Medicine Prescribing Network for Medication\n  Recommendation",
            "updated": "2023-10-23T04:15:39Z",
            "published": "2023-10-23T04:15:39Z",
            "summary": "Extensive adoption of electronic health records (EHRs) offers opportunities\nfor its use in various clinical analyses. We could acquire more comprehensive\ninsights by enriching an EHR cohort with external knowledge (e.g., standardized\nmedical ontology and wealthy semantics curated on the web) as it divulges a\nspectrum of informative relations between observed medical codes. This paper\nproposes a novel Knowledge-Induced Medicine Prescribing Network (KindMed)\nframework to recommend medicines by inducing knowledge from myriad\nmedical-related external sources upon the EHR cohort, rendering them as medical\nknowledge graphs (KGs). On top of relation-aware graph representation learning\nto unravel an adequate embedding of such KGs, we leverage hierarchical sequence\nlearning to discover and fuse clinical and medicine temporal dynamics across\npatients' historical admissions for encouraging personalized recommendations.\nIn predicting safe, precise, and personalized medicines, we devise an attentive\nprescribing that accounts for and associates three essential aspects, i.e., a\nsummary of joint historical medical records, clinical condition progression,\nand the current clinical state of patients. We exhibited the effectiveness of\nour KindMed on the augmented real-world EHR cohorts, etching leading\nperformances against graph-driven competing baselines.",
            "author": [
                "Ahmad Wisnu Mulyadi",
                "Heung-Il Suk"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14552v1",
                "http://arxiv.org/pdf/2310.14552v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14550v2",
            "title": "Corruption-Robust Offline Reinforcement Learning with General Function\n  Approximation",
            "updated": "2023-11-14T06:52:17Z",
            "published": "2023-10-23T04:07:26Z",
            "summary": "We investigate the problem of corruption robustness in offline reinforcement\nlearning (RL) with general function approximation, where an adversary can\ncorrupt each sample in the offline dataset, and the corruption level\n$\\zeta\\geq0$ quantifies the cumulative corruption amount over $n$ episodes and\n$H$ steps. Our goal is to find a policy that is robust to such corruption and\nminimizes the suboptimality gap with respect to the optimal policy for the\nuncorrupted Markov decision processes (MDPs). Drawing inspiration from the\nuncertainty-weighting technique from the robust online RL setting\n\\citep{he2022nearly,ye2022corruptionrobust}, we design a new uncertainty weight\niteration procedure to efficiently compute on batched samples and propose a\ncorruption-robust algorithm for offline RL. Notably, under the assumption of\nsingle policy coverage and the knowledge of $\\zeta$, our proposed algorithm\nachieves a suboptimality bound that is worsened by an additive factor of\n$\\mathcal O(\\zeta \\cdot (\\text{CC}(\\lambda,\\hat{\\mathcal F},\\mathcal\nZ_n^H))^{1/2} (C(\\hat{\\mathcal F},\\mu))^{-1/2} n^{-1})$ due to the corruption.\nHere $\\text{CC}(\\lambda,\\hat{\\mathcal F},\\mathcal Z_n^H)$ is the coverage\ncoefficient that depends on the regularization parameter $\\lambda$, the\nconfidence set $\\hat{\\mathcal F}$, and the dataset $\\mathcal Z_n^H$, and\n$C(\\hat{\\mathcal F},\\mu)$ is a coefficient that depends on $\\hat{\\mathcal F}$\nand the underlying data distribution $\\mu$. When specialized to linear MDPs,\nthe corruption-dependent error term reduces to $\\mathcal O(\\zeta d n^{-1})$\nwith $d$ being the dimension of the feature map, which matches the existing\nlower bound for corrupted linear MDPs. This suggests that our analysis is tight\nin terms of the corruption-dependent term.",
            "author": [
                "Chenlu Ye",
                "Rui Yang",
                "Quanquan Gu",
                "Tong Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14550v2",
                "http://arxiv.org/pdf/2310.14550v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14549v1",
            "title": "Multimodal Graph Learning for Modeling Emerging Pandemics with Big Data",
            "updated": "2023-10-23T04:05:19Z",
            "published": "2023-10-23T04:05:19Z",
            "summary": "Accurate forecasting and analysis of emerging pandemics play a crucial role\nin effective public health management and decision-making. Traditional\napproaches primarily rely on epidemiological data, overlooking other valuable\nsources of information that could act as sensors or indicators of pandemic\npatterns. In this paper, we propose a novel framework called MGL4MEP that\nintegrates temporal graph neural networks and multi-modal data for learning and\nforecasting. We incorporate big data sources, including social media content,\nby utilizing specific pre-trained language models and discovering the\nunderlying graph structure among users. This integration provides rich\nindicators of pandemic dynamics through learning with temporal graph neural\nnetworks. Extensive experiments demonstrate the effectiveness of our framework\nin pandemic forecasting and analysis, outperforming baseline methods across\ndifferent areas, pandemic situations, and prediction horizons. The fusion of\ntemporal graph learning and multi-modal data enables a comprehensive\nunderstanding of the pandemic landscape with less time lag, cheap cost, and\nmore potential information indicators.",
            "author": [
                "Khanh-Tung Tran",
                "Truong Son Hy",
                "Lili Jiang",
                "Xuan-Son Vu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14549v1",
                "http://arxiv.org/pdf/2310.14549v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14544v1",
            "title": "Trigonometric Quadrature Fourier Features for Scalable Gaussian Process\n  Regression",
            "updated": "2023-10-23T03:53:09Z",
            "published": "2023-10-23T03:53:09Z",
            "summary": "Fourier feature approximations have been successfully applied in the\nliterature for scalable Gaussian Process (GP) regression. In particular,\nQuadrature Fourier Features (QFF) derived from Gaussian quadrature rules have\ngained popularity in recent years due to their improved approximation accuracy\nand better calibrated uncertainty estimates compared to Random Fourier Feature\n(RFF) methods. However, a key limitation of QFF is that its performance can\nsuffer from well-known pathologies related to highly oscillatory quadrature,\nresulting in mediocre approximation with limited features. We address this\ncritical issue via a new Trigonometric Quadrature Fourier Feature (TQFF)\nmethod, which uses a novel non-Gaussian quadrature rule specifically tailored\nfor the desired Fourier transform. We derive an exact quadrature rule for TQFF,\nalong with kernel approximation error bounds for the resulting feature map. We\nthen demonstrate the improved performance of our method over RFF and Gaussian\nQFF in a suite of numerical experiments and applications, and show the TQFF\nenjoys accurate GP approximations over a broad range of length-scales using\nfewer features.",
            "author": [
                "Kevin Li",
                "Max Balakirsky",
                "Simon Mak"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14544v1",
                "http://arxiv.org/pdf/2310.14544v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14541v1",
            "title": "Continual Named Entity Recognition without Catastrophic Forgetting",
            "updated": "2023-10-23T03:45:30Z",
            "published": "2023-10-23T03:45:30Z",
            "summary": "Continual Named Entity Recognition (CNER) is a burgeoning area, which\ninvolves updating an existing model by incorporating new entity types\nsequentially. Nevertheless, continual learning approaches are often severely\nafflicted by catastrophic forgetting. This issue is intensified in CNER due to\nthe consolidation of old entity types from previous steps into the non-entity\ntype at each step, leading to what is known as the semantic shift problem of\nthe non-entity type. In this paper, we introduce a pooled feature distillation\nloss that skillfully navigates the trade-off between retaining knowledge of old\nentity types and acquiring new ones, thereby more effectively mitigating the\nproblem of catastrophic forgetting. Additionally, we develop a confidence-based\npseudo-labeling for the non-entity type, \\emph{i.e.,} predicting entity types\nusing the old model to handle the semantic shift of the non-entity type.\nFollowing the pseudo-labeling process, we suggest an adaptive re-weighting\ntype-balanced learning strategy to handle the issue of biased type\ndistribution. We carried out comprehensive experiments on ten CNER settings\nusing three different datasets. The results illustrate that our method\nsignificantly outperforms prior state-of-the-art approaches, registering an\naverage improvement of $6.3$\\% and $8.0$\\% in Micro and Macro F1 scores,\nrespectively.",
            "author": [
                "Duzhen Zhang",
                "Wei Cong",
                "Jiahua Dong",
                "Yahan Yu",
                "Xiuyi Chen",
                "Yonggang Zhang",
                "Zhen Fang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14541v1",
                "http://arxiv.org/pdf/2310.14541v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14536v1",
            "title": "Co-Training Realized Volatility Prediction Model with Neural\n  Distributional Transformation",
            "updated": "2023-10-23T03:37:45Z",
            "published": "2023-10-23T03:37:45Z",
            "summary": "This paper shows a novel machine learning model for realized volatility (RV)\nprediction using a normalizing flow, an invertible neural network. Since RV is\nknown to be skewed and have a fat tail, previous methods transform RV into\nvalues that follow a latent distribution with an explicit shape and then apply\na prediction model. However, knowing that shape is non-trivial, and the\ntransformation result influences the prediction model. This paper proposes to\njointly train the transformation and the prediction model. The training process\nfollows a maximum-likelihood objective function that is derived from the\nassumption that the prediction residuals on the transformed RV time series are\nhomogeneously Gaussian. The objective function is further approximated using an\nexpectation-maximum algorithm. On a dataset of 100 stocks, our method\nsignificantly outperforms other methods using analytical or naive\nneural-network transformations.",
            "author": [
                "Xin Du",
                "Kai Moriyama",
                "Kumiko Tanaka-Ishii"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3604237.3626870",
                "http://arxiv.org/abs/2310.14536v1",
                "http://arxiv.org/pdf/2310.14536v1"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE",
                "q-fin.ST"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14533v1",
            "title": "Context-Aware Prediction of User Engagement on Online Social Platforms",
            "updated": "2023-10-23T03:36:35Z",
            "published": "2023-10-23T03:36:35Z",
            "summary": "The success of online social platforms hinges on their ability to predict and\nunderstand user behavior at scale. Here, we present data suggesting that\ncontext-aware modeling approaches may offer a holistic yet lightweight and\npotentially privacy-preserving representation of user engagement on online\nsocial platforms. Leveraging deep LSTM neural networks to analyze more than 100\nmillion Snapchat sessions from almost 80.000 users, we demonstrate that\npatterns of active and passive use are predictable from past behavior\n(R2=0.345) and that the integration of context information substantially\nimproves predictive performance compared to the behavioral baseline model\n(R2=0.522). Features related to smartphone connectivity status, location,\ntemporal context, and weather were found to capture non-redundant variance in\nuser engagement relative to features derived from histories of in-app\nbehaviors. Further, we show that a large proportion of variance can be\naccounted for with minimal behavioral histories if momentary context\ninformation is considered (R2=0.44). These results indicate the potential of\ncontext-aware approaches for making models more efficient and\nprivacy-preserving by reducing the need for long data histories. Finally, we\nemploy model explainability techniques to glean preliminary insights into the\nunderlying behavioral mechanisms. Our findings are consistent with the notion\nof context-contingent, habit-driven patterns of active and passive use,\nunderscoring the value of contextualized representations of user behavior for\npredicting user engagement on social platforms.",
            "author": [
                "Heinrich Peters",
                "Yozen Liu",
                "Francesco Barbieri",
                "Raiyan A. Baten",
                "Sandra C. Matz",
                "Maarten W. Bos"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14533v1",
                "http://arxiv.org/pdf/2310.14533v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.HC",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14532v1",
            "title": "Practical Deep Dispersed Watermarking with Synchronization and Fusion",
            "updated": "2023-10-23T03:34:05Z",
            "published": "2023-10-23T03:34:05Z",
            "summary": "Deep learning based blind watermarking works have gradually emerged and\nachieved impressive performance. However, previous deep watermarking studies\nmainly focus on fixed low-resolution images while paying less attention to\narbitrary resolution images, especially widespread high-resolution images\nnowadays. Moreover, most works usually demonstrate robustness against typical\nnon-geometric attacks (\\textit{e.g.}, JPEG compression) but ignore common\ngeometric attacks (\\textit{e.g.}, Rotate) and more challenging combined\nattacks. To overcome the above limitations, we propose a practical deep\n\\textbf{D}ispersed \\textbf{W}atermarking with \\textbf{S}ynchronization and\n\\textbf{F}usion, called \\textbf{\\proposed}. Specifically, given an\narbitrary-resolution cover image, we adopt a dispersed embedding scheme which\nsparsely and randomly selects several fixed small-size cover blocks to embed a\nconsistent watermark message by a well-trained encoder. In the extraction\nstage, we first design a watermark synchronization module to locate and rectify\nthe encoded blocks in the noised watermarked image. We then utilize a decoder\nto obtain messages embedded in these blocks, and propose a message fusion\nstrategy based on similarity to make full use of the consistency among\nmessages, thus determining a reliable message. Extensive experiments conducted\non different datasets convincingly demonstrate the effectiveness of our\nproposed {\\proposed}. Compared with state-of-the-art approaches, our blind\nwatermarking can achieve better performance: averagely improve the bit accuracy\nby 5.28\\% and 5.93\\% against single and combined attacks, respectively, and\nshow less file size increment and better visual quality. Our code is available\nat https://github.com/bytedance/DWSF.",
            "author": [
                "Hengchang Guo",
                "Qilong Zhang",
                "Junwei Luo",
                "Feng Guo",
                "Wenbin Zhang",
                "Xiaodong Su",
                "Minglei Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14532v1",
                "http://arxiv.org/pdf/2310.14532v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14527v1",
            "title": "Marginal Nodes Matter: Towards Structure Fairness in Graphs",
            "updated": "2023-10-23T03:20:32Z",
            "published": "2023-10-23T03:20:32Z",
            "summary": "In social network, a person located at the periphery region (marginal node)\nis likely to be treated unfairly when compared with the persons at the center.\nWhile existing fairness works on graphs mainly focus on protecting sensitive\nattributes (e.g., age and gender), the fairness incurred by the graph structure\nshould also be given attention. On the other hand, the information aggregation\nmechanism of graph neural networks amplifies such structure unfairness, as\nmarginal nodes are often far away from other nodes. In this paper, we focus on\nnovel fairness incurred by the graph structure on graph neural networks, named\n\\emph{structure fairness}. Specifically, we first analyzed multiple graphs and\nobserved that marginal nodes in graphs have a worse performance of downstream\ntasks than others in graph neural networks. Motivated by the observation, we\npropose \\textbf{S}tructural \\textbf{Fair} \\textbf{G}raph \\textbf{N}eural\n\\textbf{N}etwork (SFairGNN), which combines neighborhood expansion based\nstructure debiasing with hop-aware attentive information aggregation to achieve\nstructure fairness. Our experiments show \\SFairGNN can significantly improve\nstructure fairness while maintaining overall performance in the downstream\ntasks.",
            "author": [
                "Xiaotian Han",
                "Kaixiong Zhou",
                "Ting-Hsiang Wang",
                "Jundong Li",
                "Fei Wang",
                "Na Zou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14527v1",
                "http://arxiv.org/pdf/2310.14527v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14526v1",
            "title": "Towards Zero Shot Learning in Restless Multi-armed Bandits",
            "updated": "2023-10-23T03:16:32Z",
            "published": "2023-10-23T03:16:32Z",
            "summary": "Restless multi-arm bandits (RMABs), a class of resource allocation problems\nwith broad application in areas such as healthcare, online advertising, and\nanti-poaching, have recently been studied from a multi-agent reinforcement\nlearning perspective. Prior RMAB research suffers from several limitations,\ne.g., it fails to adequately address continuous states, and requires retraining\nfrom scratch when arms opt-in and opt-out over time, a common challenge in many\nreal world applications. We address these limitations by developing a neural\nnetwork-based pre-trained model (PreFeRMAB) that has general zero-shot ability\non a wide range of previously unseen RMABs, and which can be fine-tuned on\nspecific instances in a more sample-efficient way than retraining from scratch.\nOur model also accommodates general multi-action settings and discrete or\ncontinuous state spaces. To enable fast generalization, we learn a novel single\npolicy network model that utilizes feature information and employs a training\nprocedure in which arms opt-in and out over time. We derive a new update rule\nfor a crucial $\\lambda$-network with theoretical convergence guarantees and\nempirically demonstrate the advantages of our approach on several challenging,\nreal-world inspired problems.",
            "author": [
                "Yunfan Zhao",
                "Nikhil Behari",
                "Edward Hughes",
                "Edwin Zhang",
                "Dheeraj Nagaraj",
                "Karl Tuyls",
                "Aparna Taneja",
                "Milind Tambe"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14526v1",
                "http://arxiv.org/pdf/2310.14526v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14525v1",
            "title": "Do We Really Need Contrastive Learning for Graph Representation?",
            "updated": "2023-10-23T03:15:57Z",
            "published": "2023-10-23T03:15:57Z",
            "summary": "In recent years, contrastive learning has emerged as a dominant\nself-supervised paradigm, attracting numerous research interests in the field\nof graph learning. Graph contrastive learning (GCL) aims to embed augmented\nanchor samples close to each other while pushing the embeddings of other\nsamples (negative samples) apart. However, existing GCL methods require large\nand diverse negative samples to ensure the quality of embeddings, and recent\nstudies typically leverage samples excluding the anchor and positive samples as\nnegative samples, potentially introducing false negative samples (negatives\nthat share the same class as the anchor). Additionally, this practice can\nresult in heavy computational burden and high time complexity of $O(N^2)$,\nwhich is particularly unaffordable for large graphs. To address these\ndeficiencies, we leverage rank learning and propose a simple yet effective\nmodel, GraphRank. Specifically, we first generate two graph views through\ncorruption. Then, we compute the similarity of pairwise nodes (anchor node and\npositive node) in both views, an arbitrary node in the latter view is selected\nas a negative node, and its similarity with the anchor node is computed. Based\non this, we introduce rank-based learning to measure similarity scores which\nsuccessfully relieve the false negative provlem and decreases the time\ncomplexity from $O(N^2)$ to $O(N)$. Moreover, we conducted extensive\nexperiments across multiple graph tasks, demonstrating that GraphRank performs\nfavorably against other cutting-edge GCL methods in various tasks.",
            "author": [
                "Yulan Hu",
                "Sheng Ouyang",
                "Jingyu Liu",
                "Ge Chen",
                "Zhirui Yang",
                "Junchen Wan",
                "Fuzheng Zhang",
                "Zhongyuan Wang",
                "Yong Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14525v1",
                "http://arxiv.org/pdf/2310.14525v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18347v1",
            "title": "PRCA: Fitting Black-Box Large Language Models for Retrieval Question\n  Answering via Pluggable Reward-Driven Contextual Adapter",
            "updated": "2023-10-23T03:12:00Z",
            "published": "2023-10-23T03:12:00Z",
            "summary": "The Retrieval Question Answering (ReQA) task employs the retrieval-augmented\nframework, composed of a retriever and generator. The generator formulates the\nanswer based on the documents retrieved by the retriever. Incorporating Large\nLanguage Models (LLMs) as generators is beneficial due to their advanced QA\ncapabilities, but they are typically too large to be fine-tuned with budget\nconstraints while some of them are only accessible via APIs. To tackle this\nissue and further improve ReQA performance, we propose a trainable Pluggable\nReward-Driven Contextual Adapter (PRCA), keeping the generator as a black box.\nPositioned between the retriever and generator in a Pluggable manner, PRCA\nrefines the retrieved information by operating in a token-autoregressive\nstrategy via maximizing rewards of the reinforcement learning phase. Our\nexperiments validate PRCA's effectiveness in enhancing ReQA performance on\nthree datasets by up to 20% improvement to fit black-box LLMs into existing\nframeworks, demonstrating its considerable potential in the LLMs era.",
            "author": [
                "Haoyan Yang",
                "Zhitao Li",
                "Yong Zhang",
                "Jianzong Wang",
                "Ning Cheng",
                "Ming Li",
                "Jing Xiao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18347v1",
                "http://arxiv.org/pdf/2310.18347v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14522v2",
            "title": "A kernel-based method for Schr\u00f6dinger bridges",
            "updated": "2023-11-29T06:14:20Z",
            "published": "2023-10-23T03:09:53Z",
            "summary": "We characterize the Schr\\\"odinger bridge problems by a family of\nMckean-Vlasov stochastic control problems with no terminal time distribution\nconstraint. In doing so, we use the theory of Hilbert space embeddings of\nprobability measures and then describe the constraint as penalty terms defined\nby the maximum mean discrepancy in the control problems. A sequence of the\nprobability laws of the state processes resulting from $\\epsilon$-optimal\ncontrols converges to a unique solution of the Schr\\\"odinger's problem under\nmild conditions on given initial and terminal time distributions and an\nunderlying diffusion process. We propose a neural SDE based deep learning\nalgorithm for the Mckean-Vlasov stochastic control problems. Several numerical\nexperiments validate our methods.",
            "author": [
                "Yumiharu Nakano"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14522v2",
                "http://arxiv.org/pdf/2310.14522v2"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.NA",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14521v1",
            "title": "K-Nearest-Neighbors Induced Topological PCA for scRNA Sequence Data\n  Analysis",
            "updated": "2023-10-23T03:07:50Z",
            "published": "2023-10-23T03:07:50Z",
            "summary": "Single-cell RNA sequencing (scRNA-seq) is widely used to reveal heterogeneity\nin cells, which has given us insights into cell-cell communication, cell\ndifferentiation, and differential gene expression. However, analyzing scRNA-seq\ndata is a challenge due to sparsity and the large number of genes involved.\nTherefore, dimensionality reduction and feature selection are important for\nremoving spurious signals and enhancing downstream analysis. Traditional PCA, a\nmain workhorse in dimensionality reduction, lacks the ability to capture\ngeometrical structure information embedded in the data, and previous graph\nLaplacian regularizations are limited by the analysis of only a single scale.\nWe propose a topological Principal Components Analysis (tPCA) method by the\ncombination of persistent Laplacian (PL) technique and L$_{2,1}$ norm\nregularization to address multiscale and multiclass heterogeneity issues in\ndata. We further introduce a k-Nearest-Neighbor (kNN) persistent Laplacian\ntechnique to improve the robustness of our persistent Laplacian method. The\nproposed kNN-PL is a new algebraic topology technique which addresses the many\nlimitations of the traditional persistent homology. Rather than inducing\nfiltration via the varying of a distance threshold, we introduced kNN-tPCA,\nwhere filtrations are achieved by varying the number of neighbors in a kNN\nnetwork at each step, and find that this framework has significant implications\nfor hyper-parameter tuning. We validate the efficacy of our proposed tPCA and\nkNN-tPCA methods on 11 diverse benchmark scRNA-seq datasets, and showcase that\nour methods outperform other unsupervised PCA enhancements from the literature,\nas well as popular Uniform Manifold Approximation (UMAP), t-Distributed\nStochastic Neighbor Embedding (tSNE), and Projection Non-Negative Matrix\nFactorization (NMF) by significant margins.",
            "author": [
                "Sean Cottrell",
                "Yuta Hozumi",
                "Guo-Wei Wei"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14521v1",
                "http://arxiv.org/pdf/2310.14521v1"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM",
                "cs.LG",
                "math.AT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14516v1",
            "title": "Foundations of Quantum Federated Learning Over Classical and Quantum\n  Networks",
            "updated": "2023-10-23T02:56:00Z",
            "published": "2023-10-23T02:56:00Z",
            "summary": "Quantum federated learning (QFL) is a novel framework that integrates the\nadvantages of classical federated learning (FL) with the computational power of\nquantum technologies. This includes quantum computing and quantum machine\nlearning (QML), enabling QFL to handle high-dimensional complex data. QFL can\nbe deployed over both classical and quantum communication networks in order to\nbenefit from information-theoretic security levels surpassing traditional FL\nframeworks. In this paper, we provide the first comprehensive investigation of\nthe challenges and opportunities of QFL. We particularly examine the key\ncomponents of QFL and identify the unique challenges that arise when deploying\nit over both classical and quantum networks. We then develop novel solutions\nand articulate promising research directions that can help address the\nidentified challenges. We also provide actionable recommendations to advance\nthe practical realization of QFL.",
            "author": [
                "Mahdi Chehimi",
                "Samuel Yen-Chi Chen",
                "Walid Saad",
                "Don Towsley",
                "M\u00e9rouane Debbah"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14516v1",
                "http://arxiv.org/pdf/2310.14516v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14513v1",
            "title": "Turn-Level Active Learning for Dialogue State Tracking",
            "updated": "2023-10-23T02:53:46Z",
            "published": "2023-10-23T02:53:46Z",
            "summary": "Dialogue state tracking (DST) plays an important role in task-oriented\ndialogue systems. However, collecting a large amount of turn-by-turn annotated\ndialogue data is costly and inefficient. In this paper, we propose a novel\nturn-level active learning framework for DST to actively select turns in\ndialogues to annotate. Given the limited labelling budget, experimental results\ndemonstrate the effectiveness of selective annotation of dialogue turns.\nAdditionally, our approach can effectively achieve comparable DST performance\nto traditional training approaches with significantly less annotated data,\nwhich provides a more efficient way to annotate new dialogue data.",
            "author": [
                "Zihan Zhang",
                "Meng Fang",
                "Fanghua Ye",
                "Ling Chen",
                "Mohammad-Reza Namazi-Rad"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14513v1",
                "http://arxiv.org/pdf/2310.14513v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14511v1",
            "title": "Poster: Real-Time Object Substitution for Mobile Diminished Reality with\n  Edge Computing",
            "updated": "2023-10-23T02:47:25Z",
            "published": "2023-10-23T02:47:25Z",
            "summary": "Diminished Reality (DR) is considered as the conceptual counterpart to\nAugmented Reality (AR), and has recently gained increasing attention from both\nindustry and academia. Unlike AR which adds virtual objects to the real world,\nDR allows users to remove physical content from the real world. When combined\nwith object replacement technology, it presents an further exciting avenue for\nexploration within the metaverse. Although a few researches have been conducted\non the intersection of object substitution and DR, there is no real-time object\nsubstitution for mobile diminished reality architecture with high quality. In\nthis paper, we propose an end-to-end architecture to facilitate immersive and\nreal-time scene construction for mobile devices with edge computing.",
            "author": [
                "Hongyu Ke",
                "Haoxin Wang"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3583740.3628422",
                "http://arxiv.org/abs/2310.14511v1",
                "http://arxiv.org/pdf/2310.14511v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14510v1",
            "title": "CITB: A Benchmark for Continual Instruction Tuning",
            "updated": "2023-10-23T02:42:32Z",
            "published": "2023-10-23T02:42:32Z",
            "summary": "Continual learning (CL) is a paradigm that aims to replicate the human\nability to learn and accumulate knowledge continually without forgetting\nprevious knowledge and transferring it to new tasks. Recent instruction tuning\n(IT) involves fine-tuning models to make them more adaptable to solving NLP\ntasks in general. However, it is still uncertain how instruction tuning works\nin the context of CL tasks. This challenging yet practical problem is\nformulated as Continual Instruction Tuning (CIT). In this work, we establish a\nCIT benchmark consisting of learning and evaluation protocols. We curate two\nlong dialogue task streams of different types, InstrDialog and InstrDialog++,\nto study various CL methods systematically. Our experiments show that existing\nCL methods do not effectively leverage the rich natural language instructions,\nand fine-tuning an instruction-tuned model sequentially can yield similar or\nbetter results. We further explore different aspects that might affect the\nlearning of CIT. We hope this benchmark will facilitate more research in this\ndirection.",
            "author": [
                "Zihan Zhang",
                "Meng Fang",
                "Ling Chen",
                "Mohammad-Reza Namazi-Rad"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14510v1",
                "http://arxiv.org/pdf/2310.14510v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14509v1",
            "title": "Iteratively Learn Diverse Strategies with State Distance Information",
            "updated": "2023-10-23T02:41:34Z",
            "published": "2023-10-23T02:41:34Z",
            "summary": "In complex reinforcement learning (RL) problems, policies with similar\nrewards may have substantially different behaviors. It remains a fundamental\nchallenge to optimize rewards while also discovering as many diverse strategies\nas possible, which can be crucial in many practical applications. Our study\nexamines two design choices for tackling this challenge, i.e., diversity\nmeasure and computation framework. First, we find that with existing diversity\nmeasures, visually indistinguishable policies can still yield high diversity\nscores. To accurately capture the behavioral difference, we propose to\nincorporate the state-space distance information into the diversity measure. In\naddition, we examine two common computation frameworks for this problem, i.e.,\npopulation-based training (PBT) and iterative learning (ITR). We show that\nalthough PBT is the precise problem formulation, ITR can achieve comparable\ndiversity scores with higher computation efficiency, leading to improved\nsolution quality in practice. Based on our analysis, we further combine ITR\nwith two tractable realizations of the state-distance-based diversity measures\nand develop a novel diversity-driven RL algorithm, State-based Intrinsic-reward\nPolicy Optimization (SIPO), with provable convergence properties. We\nempirically examine SIPO across three domains from robot locomotion to\nmulti-agent games. In all of our testing environments, SIPO consistently\nproduces strategically diverse and human-interpretable policies that cannot be\ndiscovered by existing baselines.",
            "author": [
                "Wei Fu",
                "Weihua Du",
                "Jingwei Li",
                "Sunli Chen",
                "Jingzhao Zhang",
                "Yi Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14509v1",
                "http://arxiv.org/pdf/2310.14509v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14505v2",
            "title": "Sentiment analysis with adaptive multi-head attention in Transformer",
            "updated": "2023-11-27T14:23:16Z",
            "published": "2023-10-23T02:32:30Z",
            "summary": "We propose a novel framework based on the attention mechanism to identify the\nsentiment of a movie review document. Previous efforts on deep neural networks\nwith attention mechanisms focus on encoder and decoder with fixed numbers of\nmulti-head attention. Therefore, we need a mechanism to stop the attention\nprocess automatically if no more useful information can be read from the\nmemory.In this paper, we propose an adaptive multi-head attention architecture\n(AdaptAttn) which varies the number of attention heads based on length of\nsentences. AdaptAttn has a data preprocessing step where each document is\nclassified into any one of the three bins small, medium or large based on\nlength of the sentence. The document classified as small goes through two heads\nin each layer, the medium group passes four heads and the large group is\nprocessed by eight heads. We examine the merit of our model on the Stanford\nlarge movie review dataset. The experimental results show that the F1 score\nfrom our model is on par with the baseline model.",
            "author": [
                "Fanfei Meng",
                "David Demeter"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14505v2",
                "http://arxiv.org/pdf/2310.14505v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14504v1",
            "title": "ADoPT: LiDAR Spoofing Attack Detection Based on Point-Level Temporal\n  Consistency",
            "updated": "2023-10-23T02:31:31Z",
            "published": "2023-10-23T02:31:31Z",
            "summary": "Deep neural networks (DNNs) are increasingly integrated into LiDAR (Light\nDetection and Ranging)-based perception systems for autonomous vehicles (AVs),\nrequiring robust performance under adversarial conditions. We aim to address\nthe challenge of LiDAR spoofing attacks, where attackers inject fake objects\ninto LiDAR data and fool AVs to misinterpret their environment and make\nerroneous decisions. However, current defense algorithms predominantly depend\non perception outputs (i.e., bounding boxes) thus face limitations in detecting\nattackers given the bounding boxes are generated by imperfect perception models\nprocessing limited points, acquired based on the ego vehicle's viewpoint. To\novercome these limitations, we propose a novel framework, named ADoPT (Anomaly\nDetection based on Point-level Temporal consistency), which quantitatively\nmeasures temporal consistency across consecutive frames and identifies abnormal\nobjects based on the coherency of point clusters. In our evaluation using the\nnuScenes dataset, our algorithm effectively counters various LiDAR spoofing\nattacks, achieving a low (< 10%) false positive ratio (FPR) and high (> 85%)\ntrue positive ratio (TPR), outperforming existing state-of-the-art defense\nmethods, CARLO and 3D-TC2. Furthermore, our evaluation demonstrates the\npromising potential for accurate attack detection across various road\nenvironments.",
            "author": [
                "Minkyoung Cho",
                "Yulong Cao",
                "Zixiang Zhou",
                "Z. Morley Mao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14504v1",
                "http://arxiv.org/pdf/2310.14504v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14503v1",
            "title": "Diversify Question Generation with Retrieval-Augmented Style Transfer",
            "updated": "2023-10-23T02:27:31Z",
            "published": "2023-10-23T02:27:31Z",
            "summary": "Given a textual passage and an answer, humans are able to ask questions with\nvarious expressions, but this ability is still challenging for most question\ngeneration (QG) systems. Existing solutions mainly focus on the internal\nknowledge within the given passage or the semantic word space for diverse\ncontent planning. These methods, however, have not considered the potential of\nexternal knowledge for expression diversity. To bridge this gap, we propose\nRAST, a framework for Retrieval-Augmented Style Transfer, where the objective\nis to utilize the style of diverse templates for question generation. For\ntraining RAST, we develop a novel Reinforcement Learning (RL) based approach\nthat maximizes a weighted combination of diversity reward and consistency\nreward. Here, the consistency reward is computed by a Question-Answering (QA)\nmodel, whereas the diversity reward measures how much the final output mimics\nthe retrieved template. Experimental results show that our method outperforms\nprevious diversity-driven baselines on diversity while being comparable in\nterms of consistency scores. Our code is available at\nhttps://github.com/gouqi666/RAST.",
            "author": [
                "Qi Gou",
                "Zehua Xia",
                "Bowen Yu",
                "Haiyang Yu",
                "Fei Huang",
                "Yongbin Li",
                "Nguyen Cam-Tu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14503v1",
                "http://arxiv.org/pdf/2310.14503v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14497v1",
            "title": "Counterfactual Explanation Generation with s(CASP)",
            "updated": "2023-10-23T02:05:42Z",
            "published": "2023-10-23T02:05:42Z",
            "summary": "Machine learning models that automate decision-making are increasingly being\nused in consequential areas such as loan approvals, pretrial bail, hiring, and\nmany more. Unfortunately, most of these models are black-boxes, i.e., they are\nunable to reveal how they reach these prediction decisions. A need for\ntransparency demands justification for such predictions. An affected individual\nmight desire explanations to understand why a decision was made. Ethical and\nlegal considerations may further require informing the individual of changes in\nthe input attribute that could be made to produce a desirable outcome. This\npaper focuses on the latter problem of automatically generating counterfactual\nexplanations. Our approach utilizes answer set programming and the s(CASP)\ngoal-directed ASP system. Answer Set Programming (ASP) is a well-known\nknowledge representation and reasoning paradigm. s(CASP) is a goal-directed ASP\nsystem that executes answer-set programs top-down without grounding them. The\nquery-driven nature of s(CASP) allows us to provide justifications as proof\ntrees, which makes it possible to analyze the generated counterfactual\nexplanations. We show how counterfactual explanations are computed and\njustified by imagining multiple possible worlds where some or all factual\nassumptions are untrue and, more importantly, how we can navigate between these\nworlds. We also show how our algorithm can be used to find the Craig\nInterpolant for a class of answer set programs for a failing query.",
            "author": [
                "Sopam Dasgupta",
                "Farhad Shakerin",
                "Joaqu\u00edn Arias",
                "Elmer Salazar",
                "Gopal Gupta"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14497v1",
                "http://arxiv.org/pdf/2310.14497v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14496v1",
            "title": "Redundancy-Adaptive Multimodal Learning for Imperfect Data",
            "updated": "2023-10-23T02:05:35Z",
            "published": "2023-10-23T02:05:35Z",
            "summary": "Multimodal models trained on complete modality data often exhibit a\nsubstantial decrease in performance when faced with imperfect data containing\ncorruptions or missing modalities. To address this robustness challenge, prior\nmethods have explored various approaches from aspects of augmentation,\nconsistency or uncertainty, but these approaches come with associated drawbacks\nrelated to data complexity, representation, and learning, potentially\ndiminishing their overall effectiveness. In response to these challenges, this\nstudy introduces a novel approach known as the Redundancy-Adaptive Multimodal\nLearning (RAML). RAML efficiently harnesses information redundancy across\nmultiple modalities to combat the issues posed by imperfect data while\nremaining compatible with the complete modality. Specifically, RAML achieves\nredundancy-lossless information extraction through separate unimodal\ndiscriminative tasks and enforces a proper norm constraint on each unimodal\nfeature representation. Furthermore, RAML explicitly enhances multimodal fusion\nby leveraging fine-grained redundancy among unimodal features to learn\ncorrespondences between corrupted and untainted information. Extensive\nexperiments on various benchmark datasets under diverse conditions have\nconsistently demonstrated that RAML outperforms state-of-the-art methods by a\nsignificant margin.",
            "author": [
                "Mengxi Chen",
                "Jiangchao Yao",
                "Linyu Xing",
                "Yu Wang",
                "Ya Zhang",
                "Yanfeng Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14496v1",
                "http://arxiv.org/pdf/2310.14496v1"
            ],
            "primary_category": "cs.MM",
            "category": [
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14492v1",
            "title": "Robotic Arm Manipulation to Perform Rock Skipping in Simulation",
            "updated": "2023-10-23T01:55:43Z",
            "published": "2023-10-23T01:55:43Z",
            "summary": "Rock skipping is a highly dynamic and relatively complex task that can easily\nbe performed by humans. This project aims to bring rock skipping into a robotic\nsetting, utilizing the lessons we learned in Robotic Manipulation.\nSpecifically, this project implements a system consisting of a robotic arm and\ndynamic environment to perform rock skipping in simulation. By varying\nimportant parameters such as release velocity, we hope to use our system to\ngain insight into the most important factors for maximizing the total number of\nskips. In addition, by implementing the system in simulation, we have a more\nrigorous and precise testing approach over these varied test parameters.\nHowever, this project experienced some limitations due to gripping\ninefficiencies and problems with release height trajectories which is further\ndiscussed in our report.",
            "author": [
                "Nicholas Ramirez",
                "Michael Burgess"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14492v1",
                "http://arxiv.org/pdf/2310.14492v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14489v1",
            "title": "MSFormer: A Skeleton-multiview Fusion Method For Tooth Instance\n  Segmentation",
            "updated": "2023-10-23T01:46:22Z",
            "published": "2023-10-23T01:46:22Z",
            "summary": "Recently, deep learning-based tooth segmentation methods have been limited by\nthe expensive and time-consuming processes of data collection and labeling.\nAchieving high-precision segmentation with limited datasets is critical. A\nviable solution to this entails fine-tuning pre-trained multiview-based models,\nthereby enhancing performance with limited data. However, relying solely on\ntwo-dimensional (2D) images for three-dimensional (3D) tooth segmentation can\nproduce suboptimal outcomes because of occlusion and deformation, i.e.,\nincomplete and distorted shape perception. To improve this fine-tuning-based\nsolution, this paper advocates 2D-3D joint perception. The fundamental\nchallenge in employing 2D-3D joint perception with limited data is that the\n3D-related inputs and modules must follow a lightweight policy instead of using\nhuge 3D data and parameter-rich modules that require extensive training data.\nFollowing this lightweight policy, this paper selects skeletons as the 3D\ninputs and introduces MSFormer, a novel method for tooth segmentation. MSFormer\nincorporates two lightweight modules into existing multiview-based models: a\n3D-skeleton perception module to extract 3D perception from skeletons and a\nskeleton-image contrastive learning module to obtain the 2D-3D joint perception\nby fusing both multiview and skeleton perceptions. The experimental results\nreveal that MSFormer paired with large pre-trained multiview models achieves\nstate-of-the-art performance, requiring only 100 training meshes. Furthermore,\nthe segmentation accuracy is improved by 2.4%-5.5% with the increasing volume\nof training data.",
            "author": [
                "Yuan Li",
                "Huan Liu",
                "Yubo Tao",
                "Xiangyang He",
                "Haifeng Li",
                "Xiaohu Guo",
                "Hai Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14489v1",
                "http://arxiv.org/pdf/2310.14489v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14485v1",
            "title": "Intelligent Escape of Robotic Systems: A Survey of Methodologies,\n  Applications, and Challenges",
            "updated": "2023-10-23T01:34:34Z",
            "published": "2023-10-23T01:34:34Z",
            "summary": "Intelligent escape is an interdisciplinary field that employs artificial\nintelligence (AI) techniques to enable robots with the capacity to\nintelligently react to potential dangers in dynamic, intricate, and\nunpredictable scenarios. As the emphasis on safety becomes increasingly\nparamount and advancements in robotic technologies continue to advance, a wide\nrange of intelligent escape methodologies has been developed in recent years.\nThis paper presents a comprehensive survey of state-of-the-art research work on\nintelligent escape of robotic systems. Four main methods of intelligent escape\nare reviewed, including planning-based methodologies, partitioning-based\nmethodologies, learning-based methodologies, and bio-inspired methodologies.\nThe strengths and limitations of existing methods are summarized. In addition,\npotential applications of intelligent escape are discussed in various domains,\nsuch as search and rescue, evacuation, military security, and healthcare. In an\neffort to develop new approaches to intelligent escape, this survey identifies\ncurrent research challenges and provides insights into future research trends\nin intelligent escape.",
            "author": [
                "Junfei Li",
                "Simon X. Yang"
            ],
            "link": [
                "http://dx.doi.org/10.1007/s10846-023-01996-y",
                "http://arxiv.org/abs/2310.14485v1",
                "http://arxiv.org/pdf/2310.14485v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14483v1",
            "title": "\"Why Should I Review This Paper?\" Unifying Semantic, Topic, and Citation\n  Factors for Paper-Reviewer Matching",
            "updated": "2023-10-23T01:29:18Z",
            "published": "2023-10-23T01:29:18Z",
            "summary": "As many academic conferences are overwhelmed by a rapidly increasing number\nof paper submissions, automatically finding appropriate reviewers for each\nsubmission becomes a more urgent need than ever. Various factors have been\nconsidered by previous attempts on this task to measure the expertise relevance\nbetween a paper and a reviewer, including whether the paper is semantically\nclose to, shares topics with, and cites previous papers of the reviewer.\nHowever, the majority of previous studies take only one of these factors into\naccount, leading to an incomprehensive evaluation of paper-reviewer relevance.\nTo bridge this gap, in this paper, we propose a unified model for\npaper-reviewer matching that jointly captures semantic, topic, and citation\nfactors. In the unified model, a contextualized language model backbone is\nshared by all factors to learn common knowledge, while instruction tuning is\nintroduced to characterize the uniqueness of each factor by producing\nfactor-aware paper embeddings. Experiments on four datasets (one of which is\nnewly contributed by us) across different fields, including machine learning,\ncomputer vision, information retrieval, and data mining, consistently validate\nthe effectiveness of our proposed UniPR model in comparison with\nstate-of-the-art paper-reviewer matching methods and scientific pre-trained\nlanguage models.",
            "author": [
                "Yu Zhang",
                "Yanzhen Shen",
                "Xiusi Chen",
                "Bowen Jin",
                "Jiawei Han"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14483v1",
                "http://arxiv.org/pdf/2310.14483v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.CL",
                "cs.DL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14481v1",
            "title": "Efficient Heterogeneous Graph Learning via Random Projection",
            "updated": "2023-10-23T01:25:44Z",
            "published": "2023-10-23T01:25:44Z",
            "summary": "Heterogeneous Graph Neural Networks (HGNNs) are powerful tools for deep\nlearning on heterogeneous graphs. Typical HGNNs require repetitive message\npassing during training, limiting efficiency for large-scale real-world graphs.\nRecent pre-computation-based HGNNs use one-time message passing to transform a\nheterogeneous graph into regular-shaped tensors, enabling efficient mini-batch\ntraining. Existing pre-computation-based HGNNs can be mainly categorized into\ntwo styles, which differ in how much information loss is allowed and\nefficiency. We propose a hybrid pre-computation-based HGNN, named Random\nProjection Heterogeneous Graph Neural Network (RpHGNN), which combines the\nbenefits of one style's efficiency with the low information loss of the other\nstyle. To achieve efficiency, the main framework of RpHGNN consists of\npropagate-then-update iterations, where we introduce a Random Projection\nSquashing step to ensure that complexity increases only linearly. To achieve\nlow information loss, we introduce a Relation-wise Neighbor Collection\ncomponent with an Even-odd Propagation Scheme, which aims to collect\ninformation from neighbors in a finer-grained way. Experimental results\nindicate that our approach achieves state-of-the-art results on seven small and\nlarge benchmark datasets while also being 230% faster compared to the most\neffective baseline. Surprisingly, our approach not only surpasses\npre-processing-based baselines but also outperforms end-to-end methods.",
            "author": [
                "Jun Hu",
                "Bryan Hooi",
                "Bingsheng He"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14481v1",
                "http://arxiv.org/pdf/2310.14481v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14480v2",
            "title": "Attention-Enhancing Backdoor Attacks Against BERT-based Models",
            "updated": "2023-10-25T00:45:53Z",
            "published": "2023-10-23T01:24:56Z",
            "summary": "Recent studies have revealed that \\textit{Backdoor Attacks} can threaten the\nsafety of natural language processing (NLP) models. Investigating the\nstrategies of backdoor attacks will help to understand the model's\nvulnerability. Most existing textual backdoor attacks focus on generating\nstealthy triggers or modifying model weights. In this paper, we directly target\nthe interior structure of neural networks and the backdoor mechanism. We\npropose a novel Trojan Attention Loss (TAL), which enhances the Trojan behavior\nby directly manipulating the attention patterns. Our loss can be applied to\ndifferent attacking methods to boost their attack efficacy in terms of attack\nsuccessful rates and poisoning rates. It applies to not only traditional\ndirty-label attacks, but also the more challenging clean-label attacks. We\nvalidate our method on different backbone models (BERT, RoBERTa, and\nDistilBERT) and various tasks (Sentiment Analysis, Toxic Detection, and Topic\nClassification).",
            "author": [
                "Weimin Lyu",
                "Songzhu Zheng",
                "Lu Pang",
                "Haibin Ling",
                "Chao Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14480v2",
                "http://arxiv.org/pdf/2310.14480v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14478v1",
            "title": "GeoLM: Empowering Language Models for Geospatially Grounded Language\n  Understanding",
            "updated": "2023-10-23T01:20:01Z",
            "published": "2023-10-23T01:20:01Z",
            "summary": "Humans subconsciously engage in geospatial reasoning when reading articles.\nWe recognize place names and their spatial relations in text and mentally\nassociate them with their physical locations on Earth. Although pretrained\nlanguage models can mimic this cognitive process using linguistic context, they\ndo not utilize valuable geospatial information in large, widely available\ngeographical databases, e.g., OpenStreetMap. This paper introduces GeoLM, a\ngeospatially grounded language model that enhances the understanding of\ngeo-entities in natural language. GeoLM leverages geo-entity mentions as\nanchors to connect linguistic information in text corpora with geospatial\ninformation extracted from geographical databases. GeoLM connects the two types\nof context through contrastive learning and masked language modeling. It also\nincorporates a spatial coordinate embedding mechanism to encode distance and\ndirection relations to capture geospatial context. In the experiment, we\ndemonstrate that GeoLM exhibits promising capabilities in supporting toponym\nrecognition, toponym linking, relation extraction, and geo-entity typing, which\nbridge the gap between natural language processing and geospatial sciences. The\ncode is publicly available at https://github.com/knowledge-computing/geolm.",
            "author": [
                "Zekun Li",
                "Wenxuan Zhou",
                "Yao-Yi Chiang",
                "Muhao Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14478v1",
                "http://arxiv.org/pdf/2310.14478v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14469v1",
            "title": "Player Re-Identification Using Body Part Appearences",
            "updated": "2023-10-23T00:52:23Z",
            "published": "2023-10-23T00:52:23Z",
            "summary": "We propose a neural network architecture that learns body part appearances\nfor soccer player re-identification. Our model consists of a two-stream network\n(one stream for appearance map extraction and the other for body part map\nextraction) and a bilinear-pooling layer that generates and spatially pools the\nbody part map. Each local feature of the body part map is obtained by a\nbilinear mapping of the corresponding local appearance and body part\ndescriptors. Our novel representation yields a robust image-matching feature\nmap, which results from combining the local similarities of the relevant body\nparts with the weighted appearance similarity. Our model does not require any\npart annotation on the SoccerNet-V3 re-identification dataset to train the\nnetwork. Instead, we use a sub-network of an existing pose estimation network\n(OpenPose) to initialize the part substream and then train the entire network\nto minimize the triplet loss. The appearance stream is pre-trained on the\nImageNet dataset, and the part stream is trained from scratch for the\nSoccerNet-V3 dataset. We demonstrate the validity of our model by showing that\nit outperforms state-of-the-art models such as OsNet and InceptionNet.",
            "author": [
                "Mahesh Bhosale",
                "Abhishek Kumar",
                "David Doermann"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14469v1",
                "http://arxiv.org/pdf/2310.14469v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14468v2",
            "title": "Revisiting Implicit Differentiation for Learning Problems in Optimal\n  Control",
            "updated": "2023-10-24T13:06:57Z",
            "published": "2023-10-23T00:51:24Z",
            "summary": "This paper proposes a new method for differentiating through optimal\ntrajectories arising from non-convex, constrained discrete-time optimal control\n(COC) problems using the implicit function theorem (IFT). Previous works solve\na differential Karush-Kuhn-Tucker (KKT) system for the trajectory derivative,\nand achieve this efficiently by solving an auxiliary Linear Quadratic Regulator\n(LQR) problem. In contrast, we directly evaluate the matrix equations which\narise from applying variable elimination on the Lagrange multiplier terms in\nthe (differential) KKT system. By appropriately accounting for the structure of\nthe terms within the resulting equations, we show that the trajectory\nderivatives scale linearly with the number of timesteps. Furthermore, our\napproach allows for easy parallelization, significantly improved scalability\nwith model size, direct computation of vector-Jacobian products and improved\nnumerical stability compared to prior works. As an additional contribution, we\nunify prior works, addressing claims that computing trajectory derivatives\nusing IFT scales quadratically with the number of timesteps. We evaluate our\nmethod on a both synthetic benchmark and four challenging, learning from\ndemonstration benchmarks including a 6-DoF maneuvering quadrotor and 6-DoF\nrocket powered landing.",
            "author": [
                "Ming Xu",
                "Timothy Molloy",
                "Stephen Gould"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14468v2",
                "http://arxiv.org/pdf/2310.14468v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.RO",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14466v1",
            "title": "Inferring Relational Potentials in Interacting Systems",
            "updated": "2023-10-23T00:44:17Z",
            "published": "2023-10-23T00:44:17Z",
            "summary": "Systems consisting of interacting agents are prevalent in the world, ranging\nfrom dynamical systems in physics to complex biological networks. To build\nsystems which can interact robustly in the real world, it is thus important to\nbe able to infer the precise interactions governing such systems. Existing\napproaches typically discover such interactions by explicitly modeling the\nfeed-forward dynamics of the trajectories. In this work, we propose Neural\nInteraction Inference with Potentials (NIIP) as an alternative approach to\ndiscover such interactions that enables greater flexibility in trajectory\nmodeling: it discovers a set of relational potentials, represented as energy\nfunctions, which when minimized reconstruct the original trajectory. NIIP\nassigns low energy to the subset of trajectories which respect the relational\nconstraints observed. We illustrate that with these representations NIIP\ndisplays unique capabilities in test-time. First, it allows trajectory\nmanipulation, such as interchanging interaction types across separately trained\nmodels, as well as trajectory forecasting. Additionally, it allows adding\nexternal hand-crafted potentials at test-time. Finally, NIIP enables the\ndetection of out-of-distribution samples and anomalies without explicit\ntraining. Website: https://energy-based-model.github.io/interaction-potentials.",
            "author": [
                "Armand Comas-Massagu\u00e9",
                "Yilun Du",
                "Christian Fernandez",
                "Sandesh Ghimire",
                "Mario Sznaier",
                "Joshua B. Tenenbaum",
                "Octavia Camps"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14466v1",
                "http://arxiv.org/pdf/2310.14466v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14458v1",
            "title": "Diffusion-Model-Assisted Supervised Learning of Generative Models for\n  Density Estimation",
            "updated": "2023-10-22T23:56:19Z",
            "published": "2023-10-22T23:56:19Z",
            "summary": "We present a supervised learning framework of training generative models for\ndensity estimation. Generative models, including generative adversarial\nnetworks, normalizing flows, variational auto-encoders, are usually considered\nas unsupervised learning models, because labeled data are usually unavailable\nfor training. Despite the success of the generative models, there are several\nissues with the unsupervised training, e.g., requirement of reversible\narchitectures, vanishing gradients, and training instability. To enable\nsupervised learning in generative models, we utilize the score-based diffusion\nmodel to generate labeled data. Unlike existing diffusion models that train\nneural networks to learn the score function, we develop a training-free score\nestimation method. This approach uses mini-batch-based Monte Carlo estimators\nto directly approximate the score function at any spatial-temporal location in\nsolving an ordinary differential equation (ODE), corresponding to the\nreverse-time stochastic differential equation (SDE). This approach can offer\nboth high accuracy and substantial time savings in neural network training.\nOnce the labeled data are generated, we can train a simple fully connected\nneural network to learn the generative model in the supervised manner. Compared\nwith existing normalizing flow models, our method does not require to use\nreversible neural networks and avoids the computation of the Jacobian matrix.\nCompared with existing diffusion models, our method does not need to solve the\nreverse-time SDE to generate new samples. As a result, the sampling efficiency\nis significantly improved. We demonstrate the performance of our method by\napplying it to a set of 2D datasets as well as real data from the UCI\nrepository.",
            "author": [
                "Yanfang Liu",
                "Minglei Yang",
                "Zezhong Zhang",
                "Feng Bao",
                "Yanzhao Cao",
                "Guannan Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14458v1",
                "http://arxiv.org/pdf/2310.14458v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NA",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14456v1",
            "title": "Mobile Traffic Prediction at the Edge through Distributed and Transfer\n  Learning",
            "updated": "2023-10-22T23:48:13Z",
            "published": "2023-10-22T23:48:13Z",
            "summary": "Traffic prediction represents one of the crucial tasks for smartly optimizing\nthe mobile network. The research in this topic concentrated in making\npredictions in a centralized fashion, i.e., by collecting data from the\ndifferent network elements. This translates to a considerable amount of energy\nfor data transmission and processing. In this work, we propose a novel\nprediction framework based on edge computing which uses datasets obtained on\nthe edge through a large measurement campaign. Two main Deep Learning\narchitectures are designed, based on Convolutional Neural Networks (CNNs) and\nRecurrent Neural Networks (RNNs), and tested under different training\nconditions. In addition, Knowledge Transfer Learning (KTL) techniques are\nemployed to improve the performance of the models while reducing the required\ncomputational resources. Simulation results show that the CNN architectures\noutperform the RNNs. An estimation for the needed training energy is provided,\nhighlighting KTL ability to reduce the energy footprint of the models of 60%\nand 90% for CNNs and RNNs, respectively. Finally, two cutting-edge explainable\nArtificial Intelligence techniques are employed to interpret the derived\nlearning models.",
            "author": [
                "Alfredo Petrella",
                "Marco Miozzo",
                "Paolo Dini"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14456v1",
                "http://arxiv.org/pdf/2310.14456v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "cs.AI",
                "I.2.11, I.6.4, I.6.5"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14450v2",
            "title": "TATA: Stance Detection via Topic-Agnostic and Topic-Aware Embeddings",
            "updated": "2023-11-13T03:22:32Z",
            "published": "2023-10-22T23:23:44Z",
            "summary": "Stance detection is important for understanding different attitudes and\nbeliefs on the Internet. However, given that a passage's stance toward a given\ntopic is often highly dependent on that topic, building a stance detection\nmodel that generalizes to unseen topics is difficult. In this work, we propose\nusing contrastive learning as well as an unlabeled dataset of news articles\nthat cover a variety of different topics to train topic-agnostic/TAG and\ntopic-aware/TAW embeddings for use in downstream stance detection. Combining\nthese embeddings in our full TATA model, we achieve state-of-the-art\nperformance across several public stance detection datasets (0.771 $F_1$-score\non the Zero-shot VAST dataset). We release our code and data at\nhttps://github.com/hanshanley/tata.",
            "author": [
                "Hans W. A. Hanley",
                "Zakir Durumeric"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14450v2",
                "http://arxiv.org/pdf/2310.14450v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CY",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14444v1",
            "title": "URegM: a unified prediction model of resource consumption for\n  refactoring software smells in open source cloud",
            "updated": "2023-10-22T23:03:35Z",
            "published": "2023-10-22T23:03:35Z",
            "summary": "The low cost and rapid provisioning capabilities have made the cloud a\ndesirable platform to launch complex scientific applications. However, resource\nutilization optimization is a significant challenge for cloud service\nproviders, since the earlier focus is provided on optimizing resources for the\napplications that run on the cloud, with a low emphasis being provided on\noptimizing resource utilization of the cloud computing internal processes. Code\nrefactoring has been associated with improving the maintenance and\nunderstanding of software code. However, analyzing the impact of the\nrefactoring source code of the cloud and studying its impact on cloud resource\nusage require further analysis. In this paper, we propose a framework called\nUnified Regression Modelling (URegM) which predicts the impact of code smell\nrefactoring on cloud resource usage. We test our experiments in a real-life\ncloud environment using a complex scientific application as a workload. Results\nshow that URegM is capable of accurately predicting resource consumption due to\ncode smell refactoring. This will permit cloud service providers with advanced\nknowledge about the impact of refactoring code smells on resource consumption,\nthus allowing them to plan their resource provisioning and code refactoring\nmore effectively.",
            "author": [
                "Asif Imran",
                "Tevfik Kosar"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14444v1",
                "http://arxiv.org/pdf/2310.14444v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14441v2",
            "title": "EDGE++: Improved Training and Sampling of EDGE",
            "updated": "2023-10-28T16:53:48Z",
            "published": "2023-10-22T22:54:20Z",
            "summary": "Recently developed deep neural models like NetGAN, CELL, and Variational\nGraph Autoencoders have made progress but face limitations in replicating key\ngraph statistics on generating large graphs. Diffusion-based methods have\nemerged as promising alternatives, however, most of them present challenges in\ncomputational efficiency and generative performance. EDGE is effective at\nmodeling large networks, but its current denoising approach can be inefficient,\noften leading to wasted computational resources and potential mismatches in its\ngeneration process. In this paper, we propose enhancements to the EDGE model to\naddress these issues. Specifically, we introduce a degree-specific noise\nschedule that optimizes the number of active nodes at each timestep,\nsignificantly reducing memory consumption. Additionally, we present an improved\nsampling scheme that fine-tunes the generative process, allowing for better\ncontrol over the similarity between the synthesized and the true network. Our\nexperimental results demonstrate that the proposed modifications not only\nimprove the efficiency but also enhance the accuracy of the generated graphs,\noffering a robust and scalable solution for graph generation tasks.",
            "author": [
                "Mingyang Wu",
                "Xiaohui Chen",
                "Li-Ping Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14441v2",
                "http://arxiv.org/pdf/2310.14441v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14435v1",
            "title": "Retrieval-Augmented Chain-of-Thought in Semi-structured Domains",
            "updated": "2023-10-22T22:45:14Z",
            "published": "2023-10-22T22:45:14Z",
            "summary": "Applying existing question answering (QA) systems to specialized domains like\nlaw and finance presents challenges that necessitate domain expertise. Although\nlarge language models (LLMs) have shown impressive language comprehension and\nin-context learning capabilities, their inability to handle very long\ninputs/contexts is well known. Tasks specific to these domains need significant\nbackground knowledge, leading to contexts that can often exceed the maximum\nlength that existing LLMs can process. This study explores leveraging the\nsemi-structured nature of legal and financial data to efficiently retrieve\nrelevant context, enabling the use of LLMs for domain-specialized QA. The\nresulting system outperforms contemporary models and also provides useful\nexplanations for the answers, encouraging the integration of LLMs into legal\nand financial NLP systems for future research.",
            "author": [
                "Vaibhav Mavi",
                "Abulhair Saparov",
                "Chen Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14435v1",
                "http://arxiv.org/pdf/2310.14435v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14434v1",
            "title": "Enhancing Accuracy-Privacy Trade-off in Differentially Private Split\n  Learning",
            "updated": "2023-10-22T22:45:13Z",
            "published": "2023-10-22T22:45:13Z",
            "summary": "Split learning (SL) aims to protect user data privacy by distributing deep\nmodels between client-server and keeping private data locally. Only processed\nor `smashed' data can be transmitted from the clients to the server during the\nSL process. However, recently proposed model inversion attacks can recover the\noriginal data from the smashed data. In order to enhance privacy protection\nagainst such attacks, a strategy is to adopt differential privacy (DP), which\ninvolves safeguarding the smashed data at the expense of some accuracy loss.\nThis paper presents the first investigation into the impact on accuracy when\ntraining multiple clients in SL with various privacy requirements.\nSubsequently, we propose an approach that reviews the DP noise distributions of\nother clients during client training to address the identified accuracy\ndegradation. We also examine the application of DP to the local model of SL to\ngain insights into the trade-off between accuracy and privacy. Specifically,\nfindings reveal that introducing noise in the later local layers offers the\nmost favorable balance between accuracy and privacy. Drawing from our insights\nin the shallower layers, we propose an approach to reduce the size of smashed\ndata to minimize data leakage while maintaining higher accuracy, optimizing the\naccuracy-privacy trade-off. Additionally, a smaller size of smashed data\nreduces communication overhead on the client side, mitigating one of the\nnotable drawbacks of SL. Experiments with popular datasets demonstrate that our\nproposed approaches provide an optimal trade-off for incorporating DP into SL,\nultimately enhancing training accuracy for multi-client SL with varying privacy\nrequirements.",
            "author": [
                "Ngoc Duy Pham",
                "Khoa Tran Phan",
                "Naveen Chilamkurti"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14434v1",
                "http://arxiv.org/pdf/2310.14434v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14432v1",
            "title": "Fairness-aware Optimal Graph Filter Design",
            "updated": "2023-10-22T22:40:40Z",
            "published": "2023-10-22T22:40:40Z",
            "summary": "Graphs are mathematical tools that can be used to represent complex\nreal-world interconnected systems, such as financial markets and social\nnetworks. Hence, machine learning (ML) over graphs has attracted significant\nattention recently. However, it has been demonstrated that ML over graphs\namplifies the already existing bias towards certain under-represented groups in\nvarious decision-making problems due to the information aggregation over biased\ngraph structures. Faced with this challenge, here we take a fresh look at the\nproblem of bias mitigation in graph-based learning by borrowing insights from\ngraph signal processing. Our idea is to introduce predesigned graph filters\nwithin an ML pipeline to reduce a novel unsupervised bias measure, namely the\ncorrelation between sensitive attributes and the underlying graph connectivity.\nWe show that the optimal design of said filters can be cast as a convex problem\nin the graph spectral domain. We also formulate a linear programming (LP)\nproblem informed by a theoretical bias analysis, which attains a closed-form\nsolution and leads to a more efficient fairness-aware graph filter. Finally,\nfor a design whose degrees of freedom are independent of the input graph size,\nwe minimize the bias metric over the family of polynomial graph convolutional\nfilters. Our optimal filter designs offer complementary strengths to explore\nfavorable fairness-utility-complexity tradeoffs. For performance evaluation, we\nconduct extensive and reproducible node classification experiments over\nreal-world networks. Our results show that the proposed framework leads to\nbetter fairness measures together with similar utility compared to\nstate-of-the-art fairness-aware baselines.",
            "author": [
                "O. Deniz Kose",
                "Yanning Shen",
                "Gonzalo Mateos"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14432v1",
                "http://arxiv.org/pdf/2310.14432v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14430v1",
            "title": "Clustering Students Based on Gamification User Types and Learning Styles",
            "updated": "2023-10-22T22:30:35Z",
            "published": "2023-10-22T22:30:35Z",
            "summary": "The aim of this study is clustering students according to their gamification\nuser types and learning styles with the purpose of providing instructors with a\nnew perspective of grouping students in case of clustering which cannot be done\nby hand when there are multiple scales in data. The data used consists of 251\nstudents who were enrolled at a Turkish state university. When grouping\nstudents, K-means algorithm has been utilized as clustering algorithm. As for\ndetermining the gamification user types and learning styles of students,\nGamification User Type Hexad Scale and Grasha-Riechmann Student Learning Style\nScale have been used respectively. Silhouette coefficient is utilized as\nclustering quality measure. After fitting the algorithm in several ways,\nhighest Silhouette coefficient obtained was 0.12 meaning that results are\nneutral but not satisfactory. All the statistical operations and data\nvisualizations were made using Python programming language.",
            "author": [
                "Emre Arslan",
                "Atilla \u00d6zkaymak",
                "Nesrin \u00d6zdener D\u00f6nmez"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14430v1",
                "http://arxiv.org/pdf/2310.14430v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14423v1",
            "title": "A Quadratic Synchronization Rule for Distributed Deep Learning",
            "updated": "2023-10-22T21:38:57Z",
            "published": "2023-10-22T21:38:57Z",
            "summary": "In distributed deep learning with data parallelism, synchronizing gradients\nat each training step can cause a huge communication overhead, especially when\nmany nodes work together to train large models. Local gradient methods, such as\nLocal SGD, address this issue by allowing workers to compute locally for $H$\nsteps without synchronizing with others, hence reducing communication\nfrequency. While $H$ has been viewed as a hyperparameter to trade optimization\nefficiency for communication cost, recent research indicates that setting a\nproper $H$ value can lead to generalization improvement. Yet, selecting a\nproper $H$ is elusive. This work proposes a theory-grounded method for\ndetermining $H$, named the Quadratic Synchronization Rule (QSR), which\nrecommends dynamically setting $H$ in proportion to $\\frac{1}{\\eta^2}$ as the\nlearning rate $\\eta$ decays over time. Extensive ImageNet experiments on ResNet\nand ViT show that local gradient methods with QSR consistently improve the test\naccuracy over other synchronization strategies. Compared with the standard data\nparallel training, QSR enables Local AdamW on ViT-B to cut the training time on\n16 or 64 GPUs down from 26.7 to 20.2 hours or from 8.6 to 5.5 hours and, at the\nsame time, achieves $1.16\\%$ or $0.84\\%$ higher top-1 validation accuracy.",
            "author": [
                "Xinran Gu",
                "Kaifeng Lyu",
                "Sanjeev Arora",
                "Jingzhao Zhang",
                "Longbo Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14423v1",
                "http://arxiv.org/pdf/2310.14423v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14422v1",
            "title": "Large Language Models are biased to overestimate profoundness",
            "updated": "2023-10-22T21:33:50Z",
            "published": "2023-10-22T21:33:50Z",
            "summary": "Recent advancements in natural language processing by large language models\n(LLMs), such as GPT-4, have been suggested to approach Artificial General\nIntelligence. And yet, it is still under dispute whether LLMs possess similar\nreasoning abilities to humans. This study evaluates GPT-4 and various other\nLLMs in judging the profoundness of mundane, motivational, and pseudo-profound\nstatements. We found a significant statement-to-statement correlation between\nthe LLMs and humans, irrespective of the type of statements and the prompting\ntechnique used. However, LLMs systematically overestimate the profoundness of\nnonsensical statements, with the exception of Tk-instruct, which uniquely\nunderestimates the profoundness of statements. Only few-shot learning prompts,\nas opposed to chain-of-thought prompting, draw LLMs ratings closer to humans.\nFurthermore, this work provides insights into the potential biases induced by\nReinforcement Learning from Human Feedback (RLHF), inducing an increase in the\nbias to overestimate the profoundness of statements.",
            "author": [
                "Eugenio Herrera-Berg",
                "Tom\u00e1s Vergara Browne",
                "Pablo Le\u00f3n-Villagr\u00e1",
                "Marc-Llu\u00eds Vives",
                "Cristian Buc Calderon"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14422v1",
                "http://arxiv.org/pdf/2310.14422v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14416v1",
            "title": "ConViViT -- A Deep Neural Network Combining Convolutions and Factorized\n  Self-Attention for Human Activity Recognition",
            "updated": "2023-10-22T21:13:43Z",
            "published": "2023-10-22T21:13:43Z",
            "summary": "The Transformer architecture has gained significant popularity in computer\nvision tasks due to its capacity to generalize and capture long-range\ndependencies. This characteristic makes it well-suited for generating\nspatiotemporal tokens from videos. On the other hand, convolutions serve as the\nfundamental backbone for processing images and videos, as they efficiently\naggregate information within small local neighborhoods to create spatial tokens\nthat describe the spatial dimension of a video. While both CNN-based\narchitectures and pure transformer architectures are extensively studied and\nutilized by researchers, the effective combination of these two backbones has\nnot received comparable attention in the field of activity recognition. In this\nresearch, we propose a novel approach that leverages the strengths of both CNNs\nand Transformers in an hybrid architecture for performing activity recognition\nusing RGB videos. Specifically, we suggest employing a CNN network to enhance\nthe video representation by generating a 128-channel video that effectively\nseparates the human performing the activity from the background. Subsequently,\nthe output of the CNN module is fed into a transformer to extract\nspatiotemporal tokens, which are then used for classification purposes. Our\narchitecture has achieved new SOTA results with 90.05 \\%, 99.6\\%, and 95.09\\%\non HMDB51, UCF101, and ETRI-Activity3D respectively.",
            "author": [
                "Rachid Reda Dokkar",
                "Faten Chaieb",
                "Hassen Drira",
                "Arezki Aberkane"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14416v1",
                "http://arxiv.org/pdf/2310.14416v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14413v1",
            "title": "Data Augmentation: a Combined Inductive-Deductive Approach featuring\n  Answer Set Programming",
            "updated": "2023-10-22T21:02:26Z",
            "published": "2023-10-22T21:02:26Z",
            "summary": "Although the availability of a large amount of data is usually given for\ngranted, there are relevant scenarios where this is not the case; for instance,\nin the biomedical/healthcare domain, some applications require to build huge\ndatasets of proper images, but the acquisition of such images is often hard for\ndifferent reasons (e.g., accessibility, costs, pathology-related variability),\nthus causing limited and usually imbalanced datasets. Hence, the need for\nsynthesizing photo-realistic images via advanced Data Augmentation techniques\nis crucial. In this paper we propose a hybrid inductive-deductive approach to\nthe problem; in particular, starting from a limited set of real labeled images,\nthe proposed framework makes use of logic programs for declaratively specifying\nthe structure of new images, that is guaranteed to comply with both a set of\nconstraints coming from the domain knowledge and some specific desiderata. The\nresulting labeled images undergo a dedicated process based on Deep Learning in\ncharge of creating photo-realistic images that comply with the generated label.",
            "author": [
                "Pierangela Bruno",
                "Francesco Calimeri",
                "Cinzia Marte",
                "Simona Perri"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14413v1",
                "http://arxiv.org/pdf/2310.14413v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14409v1",
            "title": "Combining Learning and Control in Linear Systems",
            "updated": "2023-10-22T20:47:34Z",
            "published": "2023-10-22T20:47:34Z",
            "summary": "In this paper, we provide a theoretical framework that separates the control\nand learning tasks in a linear system. This separation allows us to combine\noffline model-based control with online learning approaches and thus circumvent\ncurrent challenges in deriving optimal control strategies in applications where\na large volume of data is added to the system gradually in real time and not\naltogether in advance. We provide an analytical example to illustrate the\nframework.",
            "author": [
                "Andreas A. Malikopoulos"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14409v1",
                "http://arxiv.org/pdf/2310.14409v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14404v1",
            "title": "Be Selfish, But Wisely: Investigating the Impact of Agent Personality in\n  Mixed-Motive Human-Agent Interactions",
            "updated": "2023-10-22T20:31:35Z",
            "published": "2023-10-22T20:31:35Z",
            "summary": "A natural way to design a negotiation dialogue system is via self-play RL:\ntrain an agent that learns to maximize its performance by interacting with a\nsimulated user that has been designed to imitate human-human dialogue data.\nAlthough this procedure has been adopted in prior work, we find that it results\nin a fundamentally flawed system that fails to learn the value of compromise in\na negotiation, which can often lead to no agreements (i.e., the partner walking\naway without a deal), ultimately hurting the model's overall performance. We\ninvestigate this observation in the context of the DealOrNoDeal task, a\nmulti-issue negotiation over books, hats, and balls. Grounded in negotiation\ntheory from Economics, we modify the training procedure in two novel ways to\ndesign agents with diverse personalities and analyze their performance with\nhuman partners. We find that although both techniques show promise, a selfish\nagent, which maximizes its own performance while also avoiding walkaways,\nperforms superior to other variants by implicitly learning to generate value\nfor both itself and the negotiation partner. We discuss the implications of our\nfindings for what it means to be a successful negotiation dialogue system and\nhow these systems should be designed in the future.",
            "author": [
                "Kushal Chawla",
                "Ian Wu",
                "Yu Rong",
                "Gale M. Lucas",
                "Jonathan Gratch"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14404v1",
                "http://arxiv.org/pdf/2310.14404v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14403v1",
            "title": "O3D: Offline Data-driven Discovery and Distillation for Sequential\n  Decision-Making with Large Language Models",
            "updated": "2023-10-22T20:28:33Z",
            "published": "2023-10-22T20:28:33Z",
            "summary": "Recent advancements in large language models (LLMs) have exhibited promising\nperformance in solving sequential decision-making problems. By imitating\nfew-shot examples provided in the prompts (i.e., in-context learning), an LLM\nagent can interact with an external environment and complete given tasks\nwithout additional training. However, such few-shot examples are often\ninsufficient to generate high-quality solutions for complex and long-horizon\ntasks, while the limited context length cannot consume larger-scale\ndemonstrations. To this end, we propose an offline learning framework that\nutilizes offline data at scale (e.g, logs of human interactions) to facilitate\nthe in-context learning performance of LLM agents. We formally define\nLLM-powered policies with both text-based approaches and code-based approaches.\nWe then introduce an Offline Data-driven Discovery and Distillation (O3D)\nframework to improve LLM-powered policies without finetuning. O3D automatically\ndiscovers reusable skills and distills generalizable knowledge across multiple\ntasks based on offline interaction data, advancing the capability of solving\ndownstream tasks. Empirical results under two interactive decision-making\nbenchmarks (ALFWorld and WebShop) demonstrate that O3D can notably enhance the\ndecision-making capabilities of LLMs through the offline discovery and\ndistillation process, and consistently outperform baselines across various LLMs\nwith both text-based-policy and code-based-policy.",
            "author": [
                "Yuchen Xiao",
                "Yanchao Sun",
                "Mengda Xu",
                "Udari Madhushani",
                "Jared Vann",
                "Deepeka Garg",
                "Sumitra Ganesh"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14403v1",
                "http://arxiv.org/pdf/2310.14403v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14398v1",
            "title": "Learning to bag with a simulation-free reinforcement learning framework\n  for robots",
            "updated": "2023-10-22T20:19:43Z",
            "published": "2023-10-22T20:19:43Z",
            "summary": "Bagging is an essential skill that humans perform in their daily activities.\nHowever, deformable objects, such as bags, are complex for robots to\nmanipulate. This paper presents an efficient learning-based framework that\nenables robots to learn bagging. The novelty of this framework is its ability\nto perform bagging without relying on simulations. The learning process is\naccomplished through a reinforcement learning algorithm introduced in this\nwork, designed to find the best grasping points of the bag based on a set of\ncompact state representations. The framework utilizes a set of primitive\nactions and represents the task in five states. In our experiments, the\nframework reaches a 60 % and 80 % of success rate after around three hours of\ntraining in the real world when starting the bagging task from folded and\nunfolded, respectively. Finally, we test the trained model with two more bags\nof different sizes to evaluate its generalizability.",
            "author": [
                "Francisco Munguia-Galeano",
                "Jihong Zhu",
                "Juan David Hern\u00e1ndez",
                "Ze Ji"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14398v1",
                "http://arxiv.org/pdf/2310.14398v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14395v2",
            "title": "Universal representation by Boltzmann machines with Regularised Axons",
            "updated": "2023-11-30T23:14:44Z",
            "published": "2023-10-22T20:05:47Z",
            "summary": "It is widely known that Boltzmann machines are capable of representing\narbitrary probability distributions over the values of their visible neurons,\ngiven enough hidden ones. However, sampling -- and thus training -- these\nmodels can be numerically hard. Recently we proposed a regularisation of the\nconnections of Boltzmann machines, in order to control the energy landscape of\nthe model, paving a way for efficient sampling and training. Here we formally\nprove that such regularised Boltzmann machines preserve the ability to\nrepresent arbitrary distributions. This is in conjunction with controlling the\nnumber of energy local minima, thus enabling easy \\emph{guided} sampling and\ntraining. Furthermore, we explicitly show that regularised Boltzmann machines\ncan store exponentially many arbitrarily correlated visible patterns with\nperfect retrieval, and we connect them to the Dense Associative Memory\nnetworks.",
            "author": [
                "Przemys\u0142aw R. Grzybowski",
                "Antoni Jankiewicz",
                "Eloy Pi\u00f1ol",
                "David Cirauqui",
                "Dorota H. Grzybowska",
                "Pawe\u0142 M. Petrykowski",
                "Miguel \u00c1ngel Garc\u00eda-March",
                "Maciej Lewenstein",
                "Gorka Mu\u00f1oz-Gil",
                "Alejandro Pozas-Kerstjens"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14395v2",
                "http://arxiv.org/pdf/2310.14395v2"
            ],
            "primary_category": "cond-mat.stat-mech",
            "category": [
                "cond-mat.stat-mech",
                "cond-mat.dis-nn",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14390v1",
            "title": "Cross-Domain HAR: Few Shot Transfer Learning for Human Activity\n  Recognition",
            "updated": "2023-10-22T19:13:25Z",
            "published": "2023-10-22T19:13:25Z",
            "summary": "The ubiquitous availability of smartphones and smartwatches with integrated\ninertial measurement units (IMUs) enables straightforward capturing of human\nactivities. For specific applications of sensor based human activity\nrecognition (HAR), however, logistical challenges and burgeoning costs render\nespecially the ground truth annotation of such data a difficult endeavor,\nresulting in limited scale and diversity of datasets. Transfer learning, i.e.,\nleveraging publicly available labeled datasets to first learn useful\nrepresentations that can then be fine-tuned using limited amounts of labeled\ndata from a target domain, can alleviate some of the performance issues of\ncontemporary HAR systems. Yet they can fail when the differences between source\nand target conditions are too large and/ or only few samples from a target\napplication domain are available, each of which are typical challenges in\nreal-world human activity recognition scenarios. In this paper, we present an\napproach for economic use of publicly available labeled HAR datasets for\neffective transfer learning. We introduce a novel transfer learning framework,\nCross-Domain HAR, which follows the teacher-student self-training paradigm to\nmore effectively recognize activities with very limited label information. It\nbridges conceptual gaps between source and target domains, including sensor\nlocations and type of activities. Through our extensive experimental evaluation\non a range of benchmark datasets, we demonstrate the effectiveness of our\napproach for practically relevant few shot activity recognition scenarios. We\nalso present a detailed analysis into how the individual components of our\nframework affect downstream performance.",
            "author": [
                "Megha Thukral",
                "Harish Haresamudram",
                "Thomas Ploetz"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14390v1",
                "http://arxiv.org/pdf/2310.14390v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14386v1",
            "title": "Learning Generalizable Manipulation Policies with Object-Centric 3D\n  Representations",
            "updated": "2023-10-22T18:51:45Z",
            "published": "2023-10-22T18:51:45Z",
            "summary": "We introduce GROOT, an imitation learning method for learning robust policies\nwith object-centric and 3D priors. GROOT builds policies that generalize beyond\ntheir initial training conditions for vision-based manipulation. It constructs\nobject-centric 3D representations that are robust toward background changes and\ncamera views and reason over these representations using a transformer-based\npolicy. Furthermore, we introduce a segmentation correspondence model that\nallows policies to generalize to new objects at test time. Through\ncomprehensive experiments, we validate the robustness of GROOT policies against\nperceptual variations in simulated and real-world environments. GROOT's\nperformance excels in generalization over background changes, camera viewpoint\nshifts, and the presence of new object instances, whereas both state-of-the-art\nend-to-end learning methods and object proposal-based approaches fall short. We\nalso extensively evaluate GROOT policies on real robots, where we demonstrate\nthe efficacy under very wild changes in setup. More videos and model details\ncan be found in the appendix and the project website:\nhttps://ut-austin-rpl.github.io/GROOT .",
            "author": [
                "Yifeng Zhu",
                "Zhenyu Jiang",
                "Peter Stone",
                "Yuke Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14386v1",
                "http://arxiv.org/pdf/2310.14386v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18346v2",
            "title": "Data-Free Distillation Improves Efficiency and Privacy in Federated\n  Thorax Disease Analysis",
            "updated": "2023-10-31T09:13:18Z",
            "published": "2023-10-22T18:27:35Z",
            "summary": "Thorax disease analysis in large-scale, multi-centre, and multi-scanner\nsettings is often limited by strict privacy policies. Federated learning (FL)\noffers a potential solution, while traditional parameter-based FL can be\nlimited by issues such as high communication costs, data leakage, and\nheterogeneity. Distillation-based FL can improve efficiency, but it relies on a\nproxy dataset, which is often impractical in clinical practice. To address\nthese challenges, we introduce a data-free distillation-based FL approach\nFedKDF. In FedKDF, the server employs a lightweight generator to aggregate\nknowledge from different clients without requiring access to their private data\nor a proxy dataset. FedKDF combines the predictors from clients into a single,\nunified predictor, which is further optimized using the learned knowledge in\nthe lightweight generator. Our empirical experiments demonstrate that FedKDF\noffers a robust solution for efficient, privacy-preserving federated thorax\ndisease analysis.",
            "author": [
                "Ming Li",
                "Guang Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18346v2",
                "http://arxiv.org/pdf/2310.18346v2"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14374v1",
            "title": "OV-VG: A Benchmark for Open-Vocabulary Visual Grounding",
            "updated": "2023-10-22T17:54:53Z",
            "published": "2023-10-22T17:54:53Z",
            "summary": "Open-vocabulary learning has emerged as a cutting-edge research area,\nparticularly in light of the widespread adoption of vision-based foundational\nmodels. Its primary objective is to comprehend novel concepts that are not\nencompassed within a predefined vocabulary. One key facet of this endeavor is\nVisual Grounding, which entails locating a specific region within an image\nbased on a corresponding language description. While current foundational\nmodels excel at various visual language tasks, there's a noticeable absence of\nmodels specifically tailored for open-vocabulary visual grounding. This\nresearch endeavor introduces novel and challenging OV tasks, namely\nOpen-Vocabulary Visual Grounding and Open-Vocabulary Phrase Localization. The\noverarching aim is to establish connections between language descriptions and\nthe localization of novel objects. To facilitate this, we have curated a\ncomprehensive annotated benchmark, encompassing 7,272 OV-VG images and 1,000\nOV-PL images. In our pursuit of addressing these challenges, we delved into\nvarious baseline methodologies rooted in existing open-vocabulary object\ndetection, VG, and phrase localization frameworks. Surprisingly, we discovered\nthat state-of-the-art methods often falter in diverse scenarios. Consequently,\nwe developed a novel framework that integrates two critical components:\nText-Image Query Selection and Language-Guided Feature Attention. These modules\nare designed to bolster the recognition of novel categories and enhance the\nalignment between visual and linguistic information. Extensive experiments\ndemonstrate the efficacy of our proposed framework, which consistently attains\nSOTA performance across the OV-VG task. Additionally, ablation studies provide\nfurther evidence of the effectiveness of our innovative models. Codes and\ndatasets will be made publicly available at https://github.com/cv516Buaa/OV-VG.",
            "author": [
                "Chunlei Wang",
                "Wenquan Feng",
                "Xiangtai Li",
                "Guangliang Cheng",
                "Shuchang Lyu",
                "Binghao Liu",
                "Lijiang Chen",
                "Qi Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14374v1",
                "http://arxiv.org/pdf/2310.14374v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14369v1",
            "title": "MoPe: Model Perturbation-based Privacy Attacks on Language Models",
            "updated": "2023-10-22T17:33:19Z",
            "published": "2023-10-22T17:33:19Z",
            "summary": "Recent work has shown that Large Language Models (LLMs) can unintentionally\nleak sensitive information present in their training data. In this paper, we\npresent Model Perturbations (MoPe), a new method to identify with high\nconfidence if a given text is in the training data of a pre-trained language\nmodel, given white-box access to the models parameters. MoPe adds noise to the\nmodel in parameter space and measures the drop in log-likelihood at a given\npoint $x$, a statistic we show approximates the trace of the Hessian matrix\nwith respect to model parameters. Across language models ranging from $70$M to\n$12$B parameters, we show that MoPe is more effective than existing loss-based\nattacks and recently proposed perturbation-based methods. We also examine the\nrole of training point order and model size in attack success, and empirically\ndemonstrate that MoPe accurately approximate the trace of the Hessian in\npractice. Our results show that the loss of a point alone is insufficient to\ndetermine extractability -- there are training points we can recover using our\nmethod that have average loss. This casts some doubt on prior works that use\nthe loss of a point as evidence of memorization or unlearning.",
            "author": [
                "Marvin Li",
                "Jason Wang",
                "Jeffrey Wang",
                "Seth Neel"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14369v1",
                "http://arxiv.org/pdf/2310.14369v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14366v1",
            "title": "Bi-Encoders based Species Normalization -- Pairwise Sentence Learning to\n  Rank",
            "updated": "2023-10-22T17:30:16Z",
            "published": "2023-10-22T17:30:16Z",
            "summary": "Motivation: Biomedical named-entity normalization involves connecting\nbiomedical entities with distinct database identifiers in order to facilitate\ndata integration across various fields of biology. Existing systems for\nbiomedical named entity normalization heavily rely on dictionaries, manually\ncreated rules, and high-quality representative features such as lexical or\nmorphological characteristics. However, recent research has investigated the\nuse of neural network-based models to reduce dependence on dictionaries,\nmanually crafted rules, and features. Despite these advancements, the\nperformance of these models is still limited due to the lack of sufficiently\nlarge training datasets. These models have a tendency to overfit small training\ncorpora and exhibit poor generalization when faced with previously unseen\nentities, necessitating the redesign of rules and features. Contribution: We\npresent a novel deep learning approach for named entity normalization, treating\nit as a pair-wise learning to rank problem. Our method utilizes the widely-used\ninformation retrieval algorithm Best Matching 25 to generate candidate\nconcepts, followed by the application of bi-directional encoder representation\nfrom the encoder (BERT) to re-rank the candidate list. Notably, our approach\neliminates the need for feature-engineering or rule creation. We conduct\nexperiments on species entity types and evaluate our method against\nstate-of-the-art techniques using LINNAEUS and S800 biomedical corpora. Our\nproposed approach surpasses existing methods in linking entities to the NCBI\ntaxonomy. To the best of our knowledge, there is no existing neural\nnetwork-based approach for species normalization in the literature.",
            "author": [
                "Zainab Awan",
                "Tim Kahlke",
                "Peter Ralph",
                "Paul Kennedy"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14366v1",
                "http://arxiv.org/pdf/2310.14366v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14360v3",
            "title": "Is ChatGPT a game changer for geocoding -- a benchmark for geocoding\n  address parsing techniques",
            "updated": "2023-11-18T18:10:34Z",
            "published": "2023-10-22T17:03:56Z",
            "summary": "The remarkable success of GPT models across various tasks, including toponymy\nrecognition motivates us to assess the performance of the GPT-3 model in the\ngeocoding address parsing task. To ensure that the evaluation more accurately\nmirrors performance in real-world scenarios with diverse user input qualities\nand resolve the pressing need for a 'gold standard' evaluation dataset for\ngeocoding systems, we introduce a benchmark dataset of low-quality address\ndescriptions synthesized based on human input patterns mining from actual input\nlogs of a geocoding system in production. This dataset has 21 different input\nerrors and variations; contains over 239,000 address records that are uniquely\nselected from streets across all U.S. 50 states and D.C.; and consists of three\nsubsets to be used as training, validation, and testing sets. Building on this,\nwe train and gauge the performance of the GPT-3 model in extracting address\ncomponents, contrasting its performance with transformer-based and LSTM-based\nmodels. The evaluation results indicate that Bidirectional LSTM-CRF model has\nachieved the best performance over these transformer-based models and GPT-3\nmodel. Transformer-based models demonstrate very comparable results compared to\nthe Bidirectional LSTM-CRF model. The GPT-3 model, though trailing in\nperformance, showcases potential in the address parsing task with few-shot\nexamples, exhibiting room for improvement with additional fine-tuning. We open\nsource the code and data of this presented benchmark so that researchers can\nutilize it for future model development or extend it to evaluate similar tasks,\nsuch as document geocoding.",
            "author": [
                "Zhengcong Yin",
                "Diya Li",
                "Daniel W. Goldberg"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14360v3",
                "http://arxiv.org/pdf/2310.14360v3"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14355v1",
            "title": "A global product of fine-scale urban building height based on spaceborne\n  lidar",
            "updated": "2023-10-22T16:51:15Z",
            "published": "2023-10-22T16:51:15Z",
            "summary": "Characterizing urban environments with broad coverages and high precision is\nmore important than ever for achieving the UN's Sustainable Development Goals\n(SDGs) as half of the world's populations are living in cities. Urban building\nheight as a fundamental 3D urban structural feature has far-reaching\napplications. However, so far, producing readily available datasets of recent\nurban building heights with fine spatial resolutions and global coverages\nremains a challenging task. Here, we provide an up-to-date global product of\nurban building heights based on a fine grid size of 150 m around 2020 by\ncombining the spaceborne lidar instrument of GEDI and multi-sourced data\nincluding remotely sensed images (i.e., Landsat-8, Sentinel-2, and Sentinel-1)\nand topographic data. Our results revealed that the estimated method of\nbuilding height samples based on the GEDI data was effective with 0.78 of\nPearson's r and 3.67 m of RMSE in comparison to the reference data. The mapping\nproduct also demonstrated good performance as indicated by its strong\ncorrelation with the reference data (i.e., Pearson's r = 0.71, RMSE = 4.60 m).\nCompared with the currently existing products, our global urban building height\nmap holds the ability to provide a higher spatial resolution (i.e., 150 m) with\na great level of inherent details about the spatial heterogeneity and\nflexibility of updating using the GEDI samples as inputs. This work will boost\nfuture urban studies across many fields including climate, environmental,\necological, and social sciences.",
            "author": [
                "Xiao Ma",
                "Guang Zheng",
                "Chi Xu",
                "L. Monika Moskal",
                "Peng Gong",
                "Qinghua Guo",
                "Huabing Huang",
                "Xuecao Li",
                "Yong Pang",
                "Cheng Wang",
                "Huan Xie",
                "Bailang Yu",
                "Bo Zhao",
                "Yuyu Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14355v1",
                "http://arxiv.org/pdf/2310.14355v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14354v1",
            "title": "Toward Flare-Free Images: A Survey",
            "updated": "2023-10-22T16:46:12Z",
            "published": "2023-10-22T16:46:12Z",
            "summary": "Lens flare is a common image artifact that can significantly degrade image\nquality and affect the performance of computer vision systems due to a strong\nlight source pointing at the camera. This survey provides a comprehensive\noverview of the multifaceted domain of lens flare, encompassing its underlying\nphysics, influencing factors, types, and characteristics. It delves into the\ncomplex optics of flare formation, arising from factors like internal\nreflection, scattering, diffraction, and dispersion within the camera lens\nsystem. The diverse categories of flare are explored, including scattering,\nreflective, glare, orb, and starburst types. Key properties such as shape,\ncolor, and localization are analyzed. The numerous factors impacting flare\nappearance are discussed, spanning light source attributes, lens features,\ncamera settings, and scene content. The survey extensively covers the wide\nrange of methods proposed for flare removal, including hardware optimization\nstrategies, classical image processing techniques, and learning-based methods\nusing deep learning. It not only describes pioneering flare datasets created\nfor training and evaluation purposes but also how they were created. Commonly\nemployed performance metrics such as PSNR, SSIM, and LPIPS are explored.\nChallenges posed by flare's complex and data-dependent characteristics are\nhighlighted. The survey provides insights into best practices, limitations, and\npromising future directions for flare removal research. Reviewing the\nstate-of-the-art enables an in-depth understanding of the inherent complexities\nof the flare phenomenon and the capabilities of existing solutions. This can\ninform and inspire new innovations for handling lens flare artifacts and\nimproving visual quality across various applications.",
            "author": [
                "Yousef Kotp",
                "Marwan Torki"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14354v1",
                "http://arxiv.org/pdf/2310.14354v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14348v1",
            "title": "DePAint: A Decentralized Safe Multi-Agent Reinforcement Learning\n  Algorithm considering Peak and Average Constraints",
            "updated": "2023-10-22T16:36:03Z",
            "published": "2023-10-22T16:36:03Z",
            "summary": "The field of safe multi-agent reinforcement learning, despite its potential\napplications in various domains such as drone delivery and vehicle automation,\nremains relatively unexplored. Training agents to learn optimal policies that\nmaximize rewards while considering specific constraints can be challenging,\nparticularly in scenarios where having a central controller to coordinate the\nagents during the training process is not feasible. In this paper, we address\nthe problem of multi-agent policy optimization in a decentralized setting,\nwhere agents communicate with their neighbors to maximize the sum of their\ncumulative rewards while also satisfying each agent's safety constraints. We\nconsider both peak and average constraints. In this scenario, there is no\ncentral controller coordinating the agents and both the rewards and constraints\nare only known to each agent locally/privately. We formulate the problem as a\ndecentralized constrained multi-agent Markov Decision Problem and propose a\nmomentum-based decentralized policy gradient method, DePAint, to solve it. To\nthe best of our knowledge, this is the first privacy-preserving fully\ndecentralized multi-agent reinforcement learning algorithm that considers both\npeak and average constraints. We also provide theoretical analysis and\nempirical evaluation of our algorithm in various scenarios and compare its\nperformance to centralized algorithms that consider similar constraints.",
            "author": [
                "Raheeb Hassan",
                "K. M. Shadman Wadith",
                "Md. Mamun or Rashid",
                "Md. Mosaddek Khan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14348v1",
                "http://arxiv.org/pdf/2310.14348v1"
            ],
            "primary_category": "cs.MA",
            "category": [
                "cs.MA",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14347v1",
            "title": "Self-Assistant: Portable Progressive Muscle Relaxation Training\n  Interface for Anxiety Reduction in Office Workers",
            "updated": "2023-10-22T16:35:52Z",
            "published": "2023-10-22T16:35:52Z",
            "summary": "Workload often triggers anxiety for office workers. While a variety of stress\nintervention and management techniques have been explored, there exist only a\nfew of portable tangible interfaces for anxiety reduction. Contributing to the\nbody of work, we introduce Self-Assistant, a portable anxiety intervention\ntraining interface. This is based on progressive muscle relaxation training\nwhich is an effective way for reducing stress and raise awareness of tension,\nand provide feelings of deep relaxation. This interface incorporates a stress\nball with a pressure sensor and visual indicators which help track the user's\nanxiety level through squeeze actions. This is designed to help improve\nself-awareness of anxiety and stress, in turn self-regulating bodily functions,\noffering rapid and low-sensory stimulus training for anxiety relief. Finally,\nwe discuss application scenarios and future work with Self-Assistant.",
            "author": [
                "Lingqian Yang",
                "Katherine Wang",
                "Youngjun Cho"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14347v1",
                "http://arxiv.org/pdf/2310.14347v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14344v1",
            "title": "What's in a Prior? Learned Proximal Networks for Inverse Problems",
            "updated": "2023-10-22T16:31:01Z",
            "published": "2023-10-22T16:31:01Z",
            "summary": "Proximal operators are ubiquitous in inverse problems, commonly appearing as\npart of algorithmic strategies to regularize problems that are otherwise\nill-posed. Modern deep learning models have been brought to bear for these\ntasks too, as in the framework of plug-and-play or deep unrolling, where they\nloosely resemble proximal operators. Yet, something essential is lost in\nemploying these purely data-driven approaches: there is no guarantee that a\ngeneral deep network represents the proximal operator of any function, nor is\nthere any characterization of the function for which the network might provide\nsome approximate proximal. This not only makes guaranteeing convergence of\niterative schemes challenging but, more fundamentally, complicates the analysis\nof what has been learned by these networks about their training data. Herein we\nprovide a framework to develop learned proximal networks (LPN), prove that they\nprovide exact proximal operators for a data-driven nonconvex regularizer, and\nshow how a new training strategy, dubbed proximal matching, provably promotes\nthe recovery of the log-prior of the true data distribution. Such LPN provide\ngeneral, unsupervised, expressive proximal operators that can be used for\ngeneral inverse problems with convergence guarantees. We illustrate our results\nin a series of cases of increasing complexity, demonstrating that these models\nnot only result in state-of-the-art performance, but provide a window into the\nresulting priors learned from data.",
            "author": [
                "Zhenghan Fang",
                "Sam Buchanan",
                "Jeremias Sulam"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14344v1",
                "http://arxiv.org/pdf/2310.14344v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15197v1",
            "title": "Can strong structural encoding reduce the importance of Message Passing?",
            "updated": "2023-10-22T16:29:44Z",
            "published": "2023-10-22T16:29:44Z",
            "summary": "The most prevalent class of neural networks operating on graphs are message\npassing neural networks (MPNNs), in which the representation of a node is\nupdated iteratively by aggregating information in the 1-hop neighborhood. Since\nthis paradigm for computing node embeddings may prevent the model from learning\ncoarse topological structures, the initial features are often augmented with\nstructural information of the graph, typically in the form of Laplacian\neigenvectors or Random Walk transition probabilities. In this work, we explore\nthe contribution of message passing when strong structural encodings are\nprovided. We introduce a novel way of modeling the interaction between feature\nand structural information based on their tensor product rather than the\nstandard concatenation. The choice of interaction is compared in common\nscenarios and in settings where the capacity of the message-passing layer is\nseverely reduced and ultimately the message-passing phase is removed\naltogether. Our results indicate that using tensor-based encodings is always at\nleast on par with the concatenation-based encoding and that it makes the model\nmuch more robust when the message passing layers are removed, on some tasks\nincurring almost no drop in performance. This suggests that the importance of\nmessage passing is limited when the model can construct strong structural\nencodings.",
            "author": [
                "Floor Eijkelboom",
                "Erik Bekkers",
                "Michael Bronstein",
                "Francesco Di Giovanni"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15197v1",
                "http://arxiv.org/pdf/2310.15197v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14341v1",
            "title": "Pyramidal Hidden Markov Model For Multivariate Time Series Forecasting",
            "updated": "2023-10-22T16:17:24Z",
            "published": "2023-10-22T16:17:24Z",
            "summary": "The Hidden Markov Model (HMM) can predict the future value of a time series\nbased on its current and previous values, making it a powerful algorithm for\nhandling various types of time series. Numerous studies have explored the\nimprovement of HMM using advanced techniques, leading to the development of\nseveral variations of HMM. Despite these studies indicating the increased\ncompetitiveness of HMM compared to other advanced algorithms, few have\nrecognized the significance and impact of incorporating multistep stochastic\nstates into its performance. In this work, we propose a Pyramidal Hidden Markov\nModel (PHMM) that can capture multiple multistep stochastic states. Initially,\na multistep HMM is designed for extracting short multistep stochastic states.\nNext, a novel time series forecasting structure is proposed based on PHMM,\nwhich utilizes pyramid-like stacking to adaptively identify long multistep\nstochastic states. By employing these two schemes, our model can effectively\nhandle non-stationary and noisy data, while also establishing long-term\ndependencies for more accurate and comprehensive forecasting. The experimental\nresults on diverse multivariate time series datasets convincingly demonstrate\nthe superior performance of our proposed PHMM compared to its competitive peers\nin time series forecasting.",
            "author": [
                "YeXin Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14341v1",
                "http://arxiv.org/pdf/2310.14341v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14338v2",
            "title": "From Chaos to Clarity: Claim Normalization to Empower Fact-Checking",
            "updated": "2023-11-13T13:23:44Z",
            "published": "2023-10-22T16:07:06Z",
            "summary": "With the rise of social media, users are exposed to many misleading claims.\nHowever, the pervasive noise inherent in these posts presents a challenge in\nidentifying precise and prominent claims that require verification. Extracting\nthe important claims from such posts is arduous and time-consuming, yet it is\nan underexplored problem. Here, we aim to bridge this gap. We introduce a novel\ntask, Claim Normalization (aka ClaimNorm), which aims to decompose complex and\nnoisy social media posts into more straightforward and understandable forms,\ntermed normalized claims. We propose CACN, a pioneering approach that leverages\nchain-of-thought and claim check-worthiness estimation, mimicking human\nreasoning processes, to comprehend intricate claims. Moreover, we capitalize on\nthe in-context learning capabilities of large language models to provide\nguidance and to improve claim normalization. To evaluate the effectiveness of\nour proposed model, we meticulously compile a comprehensive real-world dataset,\nCLAN, comprising more than 6k instances of social media posts alongside their\nrespective normalized claims. Our experiments demonstrate that CACN outperforms\nseveral baselines across various evaluation measures. Finally, our rigorous\nerror analysis validates CACN's capabilities and pitfalls.",
            "author": [
                "Megha Sundriyal",
                "Tanmoy Chakraborty",
                "Preslav Nakov"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14338v2",
                "http://arxiv.org/pdf/2310.14338v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14337v1",
            "title": "PPFL: A Personalized Federated Learning Framework for Heterogeneous\n  Population",
            "updated": "2023-10-22T16:06:27Z",
            "published": "2023-10-22T16:06:27Z",
            "summary": "Personalization aims to characterize individual preferences and is widely\napplied across many fields. However, conventional personalized methods operate\nin a centralized manner and potentially expose the raw data when pooling\nindividual information. In this paper, with privacy considerations, we develop\na flexible and interpretable personalized framework within the paradigm of\nFederated Learning, called PPFL (Population Personalized Federated Learning).\nBy leveraging canonical models to capture fundamental characteristics among the\nheterogeneous population and employing membership vectors to reveal clients'\npreferences, it models the heterogeneity as clients' varying preferences for\nthese characteristics and provides substantial insights into client\ncharacteristics, which is lacking in existing Personalized Federated Learning\n(PFL) methods. Furthermore, we explore the relationship between our method and\nthree main branches of PFL methods: multi-task PFL, clustered FL, and\ndecoupling PFL, and demonstrate the advantages of PPFL. To solve PPFL (a\nnon-convex constrained optimization problem), we propose a novel random block\ncoordinate descent algorithm and present the convergence property. We conduct\nexperiments on both pathological and practical datasets, and the results\nvalidate the effectiveness of PPFL.",
            "author": [
                "Hao Di",
                "Yi Yang",
                "Haishan Ye",
                "Xiangyu Chang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14337v1",
                "http://arxiv.org/pdf/2310.14337v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14336v2",
            "title": "Learning Interpretable Rules for Scalable Data Representation and\n  Classification",
            "updated": "2023-10-30T14:03:15Z",
            "published": "2023-10-22T15:55:58Z",
            "summary": "Rule-based models, e.g., decision trees, are widely used in scenarios\ndemanding high model interpretability for their transparent inner structures\nand good model expressivity. However, rule-based models are hard to optimize,\nespecially on large data sets, due to their discrete parameters and structures.\nEnsemble methods and fuzzy/soft rules are commonly used to improve performance,\nbut they sacrifice the model interpretability. To obtain both good scalability\nand interpretability, we propose a new classifier, named Rule-based\nRepresentation Learner (RRL), that automatically learns interpretable non-fuzzy\nrules for data representation and classification. To train the\nnon-differentiable RRL effectively, we project it to a continuous space and\npropose a novel training method, called Gradient Grafting, that can directly\noptimize the discrete model using gradient descent. A novel design of logical\nactivation functions is also devised to increase the scalability of RRL and\nenable it to discretize the continuous features end-to-end. Exhaustive\nexperiments on ten small and four large data sets show that RRL outperforms the\ncompetitive interpretable approaches and can be easily adjusted to obtain a\ntrade-off between classification accuracy and model complexity for different\nscenarios. Our code is available at: https://github.com/12wang3/rrl.",
            "author": [
                "Zhuo Wang",
                "Wei Zhang",
                "Ning Liu",
                "Jianyong Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14336v2",
                "http://arxiv.org/pdf/2310.14336v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14334v2",
            "title": "MOND as manifestation of modified inertia",
            "updated": "2023-11-16T17:57:24Z",
            "published": "2023-10-22T15:41:51Z",
            "summary": "Practically all the full-fledged MOND theories propounded to date are of the\nmodified-gravity (MG) type: they modify only the Newtonian, Poisson action of\nthe gravitational potential, or the general-relativistic Einstein-Hilbert\naction, leaving other terms (inertia) intact. Here, I discuss the\ninterpretation of MOND as modified inertia (MI). My main aim is threefold: (a)\nto advocate exploring MOND theories beyond MG, and appreciating their\nidiosyncrasies, (b) to highlight the fact that secondary predictions of such\ntheories can differ materially from those of MG theories, (c) to demonstrate\nsome of this with specific MI models. I discuss some definitions and\ngeneralities concerning MI. I then present instances of MI in physics, and the\nlessons we can learn from them for MOND. I then concentrate on a specific class\nof nonrelativistic, MOND, MI models, and contrast their predictions with those\nof the two workhorse, MG theories -- AQUAL and QUMOND. The MI models predict\npossibly a stronger external-field effect -- e.g. on low acceleration systems\nin the solar neighborhood -- such as very wide binary stars -- and on vertical\nmotions in disc galaxies. More generally, the workings of the effect are rather\ndifferent, and depend in different ways on dimensionless characteristics of the\nsystem, such as frequency ratios of the external and internal fields,\neccentricity of trajectories, etc. These models predict a {\\it much} weaker\neffect of the Galactic field in the inner Solar System than is predicted by\nAQUAL/QUMOND. I also show how noncircular motions -- such as those\nperpendicular to the disc -- modify the standard, algebraic\nmass-discrepancy-acceleration relation (aka RAR) that is predicted by MI for\nexactly circular orbits. These differences, and more that are discussed, can\npotentially offer ways to distinguish between theories.",
            "author": [
                "Mordehai Milgrom"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14334v2",
                "http://arxiv.org/pdf/2310.14334v2"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA",
                "astro-ph.CO",
                "gr-qc",
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02084v1",
            "title": "ITEm: Unsupervised Image-Text Embedding Learning for eCommerce",
            "updated": "2023-10-22T15:39:44Z",
            "published": "2023-10-22T15:39:44Z",
            "summary": "Product embedding serves as a cornerstone for a wide range of applications in\neCommerce. The product embedding learned from multiple modalities shows\nsignificant improvement over that from a single modality, since different\nmodalities provide complementary information. However, some modalities are more\ninformatively dominant than others. How to teach a model to learn embedding\nfrom different modalities without neglecting information from the less dominant\nmodality is challenging. We present an image-text embedding model (ITEm), an\nunsupervised learning method that is designed to better attend to image and\ntext modalities. We extend BERT by (1) learning an embedding from text and\nimage without knowing the regions of interest; (2) training a global\nrepresentation to predict masked words and to construct masked image patches\nwithout their individual representations. We evaluate the pre-trained ITEm on\ntwo tasks: the search for extremely similar products and the prediction of\nproduct categories, showing substantial gains compared to strong baseline\nmodels.",
            "author": [
                "Baohao Liao",
                "Michael Kozielski",
                "Sanjika Hewavitharana",
                "Jiangbo Yuan",
                "Shahram Khadivi",
                "Tomer Lancewicki"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02084v1",
                "http://arxiv.org/pdf/2311.02084v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14331v1",
            "title": "Multi-fidelity Deep Learning-based methodology for epistemic uncertainty\n  quantification of turbulence models",
            "updated": "2023-10-22T15:29:23Z",
            "published": "2023-10-22T15:29:23Z",
            "summary": "Computational Fluid Dynamics (CFD) simulations using turbulence models are\ncommonly used in engineering design. Of the different turbulence modeling\napproaches that are available, eddy viscosity based models are the most common\nfor their computational economy. Eddy viscosity based models utilize many\nsimplifications for this economy such as the gradient diffusion and the\nisotropic eddy viscosity hypotheses. These simplifications limit the degree to\nwhich eddy viscosity models can replicate turbulence physics and lead to model\nform uncertainty. The Eigenspace Perturbation Method (EPM) has been developed\nfor purely physics based estimates of this model form uncertainty in turbulence\nmodel predictions. Due to its physics based nature, the EPM weighs all\nphysically possible outcomes equally leading to overly conservative uncertainty\nestimates in many cases. In this investigation we use data driven Machine\nLearning (ML) approaches to address this limitation. Using ML models, we can\nweigh the physically possible outcomes by their likelihood leading to better\ncalibration of the uncertainty estimates. Specifically, we use ML models to\npredict the degree of perturbations in the EPM over the flow domain. This work\nfocuses on a Convolutional Neural Network (CNN) based model to learn the\ndiscrepancy between Reynolds Averaged Navier Stokes (RANS) and Direct Numerical\nSimulation (DNS) predictions. This model acts as a marker function, modulating\nthe degree of perturbations in the EPM. We show that this physics constrained\nmachine learning framework performs better than the purely physics or purely ML\nalternatives, and leads to less conservative uncertainty bounds with improved\ncalibration.",
            "author": [
                "Minghan Chu",
                "Weicheng Qian"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14331v1",
                "http://arxiv.org/pdf/2310.14331v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14328v2",
            "title": "Quantum Key Leasing for PKE and FHE with a Classical Lessor",
            "updated": "2023-11-12T02:49:32Z",
            "published": "2023-10-22T15:25:29Z",
            "summary": "In this work, we consider the problem of secure key leasing, also known as\nrevocable cryptography (Agarwal et. al. Eurocrypt' 23, Ananth et. al. TCC' 23),\nas a strengthened security notion of its predecessor put forward in Ananth et.\nal. Eurocrypt' 21. This problem aims to leverage unclonable nature of quantum\ninformation to allow a lessor to lease a quantum key with reusability for\nevaluating a classical functionality. Later, the lessor can request the lessee\nto provably delete the key and then the lessee will be completely deprived of\nthe capability to evaluate.\n  In this work, we construct a secure key leasing scheme to lease a decryption\nkey of a (classical) public-key, homomorphic encryption scheme from standard\nlattice assumptions. We achieve strong form of security where:\n  * The entire protocol uses only classical communication between a classical\nlessor (client) and a quantum lessee (server).\n  * Assuming standard assumptions, our security definition ensures that every\ncomputationally bounded quantum adversary could not simultaneously provide a\nvalid classical deletion certificate and yet distinguish ciphertexts.\n  Our security relies on the hardness of learning with errors assumption. Our\nscheme is the first scheme to be based on a standard assumption and satisfying\nthe two properties above.",
            "author": [
                "Orestis Chardouvelis",
                "Vipul Goyal",
                "Aayush Jain",
                "Jiahui Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14328v2",
                "http://arxiv.org/pdf/2310.14328v2"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14326v1",
            "title": "CLMSM: A Multi-Task Learning Framework for Pre-training on Procedural\n  Text",
            "updated": "2023-10-22T15:20:11Z",
            "published": "2023-10-22T15:20:11Z",
            "summary": "In this paper, we propose CLMSM, a domain-specific, continual pre-training\nframework, that learns from a large set of procedural recipes. CLMSM uses a\nMulti-Task Learning Framework to optimize two objectives - a) Contrastive\nLearning using hard triplets to learn fine-grained differences across entities\nin the procedures, and b) a novel Mask-Step Modelling objective to learn\nstep-wise context of a procedure. We test the performance of CLMSM on the\ndownstream tasks of tracking entities and aligning actions between two\nprocedures on three datasets, one of which is an open-domain dataset not\nconforming with the pre-training dataset. We show that CLMSM not only\noutperforms baselines on recipes (in-domain) but is also able to generalize to\nopen-domain procedural NLP tasks.",
            "author": [
                "Abhilash Nandy",
                "Manav Nitin Kapadnis",
                "Pawan Goyal",
                "Niloy Ganguly"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14326v1",
                "http://arxiv.org/pdf/2310.14326v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18344v1",
            "title": "Chainpoll: A high efficacy method for LLM hallucination detection",
            "updated": "2023-10-22T14:45:14Z",
            "published": "2023-10-22T14:45:14Z",
            "summary": "Large language models (LLMs) have experienced notable advancements in\ngenerating coherent and contextually relevant responses. However,\nhallucinations - incorrect or unfounded claims - are still prevalent, prompting\nthe creation of automated metrics to detect these in LLM outputs. Our\ncontributions include: introducing ChainPoll, an innovative hallucination\ndetection method that excels compared to its counterparts, and unveiling\nRealHall, a refined collection of benchmark datasets to assess hallucination\ndetection metrics from recent studies. While creating RealHall, we assessed\ntasks and datasets from previous hallucination detection studies and observed\nthat many are not suitable for the potent LLMs currently in use. Overcoming\nthis, we opted for four datasets challenging for modern LLMs and pertinent to\nreal-world scenarios. Using RealHall, we conducted a comprehensive comparison\nof ChainPoll with numerous hallucination metrics from recent studies. Our\nfindings indicate that ChainPoll outperforms in all RealHall benchmarks,\nachieving an overall AUROC of 0.781. This surpasses the next best theoretical\nmethod by 11% and exceeds industry standards by over 23%. Additionally,\nChainPoll is cost-effective and offers greater transparency than other metrics.\nWe introduce two novel metrics to assess LLM hallucinations: Adherence and\nCorrectness. Adherence is relevant to Retrieval Augmented Generation workflows,\nevaluating an LLM's analytical capabilities within given documents and\ncontexts. In contrast, Correctness identifies logical and reasoning errors.",
            "author": [
                "Robert Friel",
                "Atindriyo Sanyal"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18344v1",
                "http://arxiv.org/pdf/2310.18344v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14318v3",
            "title": "Intent Contrastive Learning with Cross Subsequences for Sequential\n  Recommendation",
            "updated": "2023-11-25T06:02:47Z",
            "published": "2023-10-22T14:41:10Z",
            "summary": "The user purchase behaviors are mainly influenced by their intentions (e.g.,\nbuying clothes for decoration, buying brushes for painting, etc.). Modeling a\nuser's latent intention can significantly improve the performance of\nrecommendations. Previous works model users' intentions by considering the\npredefined label in auxiliary information or introducing stochastic data\naugmentation to learn purposes in the latent space. However, the auxiliary\ninformation is sparse and not always available for recommender systems, and\nintroducing stochastic data augmentation may introduce noise and thus change\nthe intentions hidden in the sequence. Therefore, leveraging user intentions\nfor sequential recommendation (SR) can be challenging because they are\nfrequently varied and unobserved. In this paper, Intent contrastive learning\nwith Cross Subsequences for sequential Recommendation (ICSRec) is proposed to\nmodel users' latent intentions. Specifically, ICSRec first segments a user's\nsequential behaviors into multiple subsequences by using a dynamic sliding\noperation and takes these subsequences into the encoder to generate the\nrepresentations for the user's intentions. To tackle the problem of no explicit\nlabels for purposes, ICSRec assumes different subsequences with the same target\nitem may represent the same intention and proposes a coarse-grain intent\ncontrastive learning to push these subsequences closer. Then, fine-grain intent\ncontrastive learning is mentioned to capture the fine-grain intentions of\nsubsequences in sequential behaviors. Extensive experiments conducted on four\nreal-world datasets demonstrate the superior performance of the proposed ICSRec\nmodel compared with baseline methods.",
            "author": [
                "Xiuyuan Qin",
                "Huanhuan Yuan",
                "Pengpeng Zhao",
                "Guanfeng Liu",
                "Fuzhen Zhuang",
                "Victor S. Sheng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14318v3",
                "http://arxiv.org/pdf/2310.14318v3"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14304v1",
            "title": "One Model for All: Large Language Models are Domain-Agnostic\n  Recommendation Systems",
            "updated": "2023-10-22T13:56:14Z",
            "published": "2023-10-22T13:56:14Z",
            "summary": "The purpose of sequential recommendation is to utilize the interaction\nhistory of a user and predict the next item that the user is most likely to\ninteract with. While data sparsity and cold start are two challenges that most\nrecommender systems are still facing, many efforts are devoted to utilizing\ndata from other domains, called cross-domain methods. However, general\ncross-domain methods explore the relationship between two domains by designing\ncomplex model architecture, making it difficult to scale to multiple domains\nand utilize more data. Moreover, existing recommendation systems use IDs to\nrepresent item, which carry less transferable signals in cross-domain\nscenarios, and user cross-domain behaviors are also sparse, making it\nchallenging to learn item relationship from different domains. These problems\nhinder the application of multi-domain methods to sequential recommendation.\nRecently, large language models (LLMs) exhibit outstanding performance in world\nknowledge learning from text corpora and general-purpose question answering.\nInspired by these successes, we propose a simple but effective framework for\ndomain-agnostic recommendation by exploiting the pre-trained LLMs (namely\nLLM-Rec). We mix the user's behavior across different domains, and then\nconcatenate the title information of these items into a sentence and model the\nuser's behaviors with a pre-trained language model. We expect that by mixing\nthe user's behaviors across different domains, we can exploit the common\nknowledge encoded in the pre-trained language model to alleviate the problems\nof data sparsity and cold start problems. Furthermore, we are curious about\nwhether the latest technical advances in nature language processing (NLP) can\ntransfer to the recommendation scenarios.",
            "author": [
                "Zuoli Tang",
                "Zhaoxin Huan",
                "Zihao Li",
                "Xiaolu Zhang",
                "Jun Hu",
                "Chilin Fu",
                "Jun Zhou",
                "Chenliang Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14304v1",
                "http://arxiv.org/pdf/2310.14304v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14301v1",
            "title": "An overview of text-to-speech systems and media applications",
            "updated": "2023-10-22T13:52:06Z",
            "published": "2023-10-22T13:52:06Z",
            "summary": "Producing synthetic voice, similar to human-like sound, is an emerging\nnovelty of modern interactive media systems. Text-To-Speech (TTS) systems try\nto generate synthetic and authentic voices via text input. Besides, well known\nand familiar dubbing, announcing and narrating voices, as valuable possessions\nof any media organization, can be kept forever by utilizing TTS and Voice\nConversion (VC) algorithms . The emergence of deep learning approaches has made\nsuch TTS systems more accurate and accessible. To understand TTS systems\nbetter, this paper investigates the key components of such systems including\ntext analysis, acoustic modelling and vocoding. The paper then provides details\nof important state-of-the-art TTS systems based on deep learning. Finally, a\ncomparison is made between recently released systems in term of backbone\narchitecture, type of input and conversion, vocoder used and subjective\nassessment (MOS). Accordingly, Tacotron 2, Transformer TTS, WaveNet and\nFastSpeech 1 are among the most successful TTS systems ever released. In the\ndiscussion section, some suggestions are made to develop a TTS system with\nregard to the intended application.",
            "author": [
                "Mohammad Reza Hasanabadi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14301v1",
                "http://arxiv.org/pdf/2310.14301v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14300v1",
            "title": "MFCC-GAN Codec: A New AI-based Audio Coding",
            "updated": "2023-10-22T13:44:31Z",
            "published": "2023-10-22T13:44:31Z",
            "summary": "In this paper, we proposed AI-based audio coding using MFCC features in an\nadversarial setting. We combined a conventional encoder with an adversarial\nlearning decoder to better reconstruct the original waveform. Since GAN gives\nimplicit density estimation, therefore, such models are less prone to\noverfitting. We compared our work with five well-known codecs namely AAC, AC3,\nOpus, Vorbis, and Speex, performing on bitrates from 2kbps to 128kbps.\nMFCCGAN_36k achieved the state-of-the-art result in terms of SNR despite a\nlower bitrate in comparison to AC3_128k, AAC_112k, Vorbis_48k, Opus_48k, and\nSpeex_48K. On the other hand, MFCCGAN_13k also achieved high SNR=27 which is\nequal to that of AC3_128k, and AAC_112k while having a significantly lower\nbitrate (13 kbps). MFCCGAN_36k achieved higher NISQA-MOS results compared to\nAAC_48k while having a 20% lower bitrate. Furthermore, MFCCGAN_13k obtained\nNISQAMOS= 3.9 which is much higher than AAC_24k, AAC_32k, AC3_32k, and AAC_48k.\nFor future work, we finally suggest adopting loss functions optimizing\nintelligibility and perceptual metrics in the MFCCGAN structure to improve\nquality and intelligibility simultaneously.",
            "author": [
                "Mohammad Reza Hasanabadi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14300v1",
                "http://arxiv.org/pdf/2310.14300v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14298v1",
            "title": "Learning a General Model of Single Phase Flow in Complex 3D Porous Media",
            "updated": "2023-10-22T13:36:10Z",
            "published": "2023-10-22T13:36:10Z",
            "summary": "Modeling effective transport properties of 3D porous media, such as\npermeability, at multiple scales is challenging as a result of the combined\ncomplexity of the pore structures and fluid physics - in particular,\nconfinement effects which vary across the nanoscale to the microscale. While\nnumerical simulation is possible, the computational cost is prohibitive for\nrealistic domains, which are large and complex. Although machine learning\nmodels have been proposed to circumvent simulation, none so far has\nsimultaneously accounted for heterogeneous 3D structures, fluid confinement\neffects, and multiple simulation resolutions. By utilizing numerous computer\nscience techniques to improve the scalability of training, we have for the\nfirst time developed a general flow model that accounts for the pore-structure\nand corresponding physical phenomena at scales from Angstrom to the micrometer.\nUsing synthetic computational domains for training, our machine learning model\nexhibits strong performance (R$^2$=0.9) when tested on extremely diverse real\ndomains at multiple scales.",
            "author": [
                "Javier E. Santos",
                "Agnese Marcato",
                "Qinjun Kang",
                "Mohamed Mehana",
                "Daniel O'Malley",
                "Hari Viswanathan",
                "Nicholas Lubbers"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14298v1",
                "http://arxiv.org/pdf/2310.14298v1"
            ],
            "primary_category": "physics.geo-ph",
            "category": [
                "physics.geo-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14294v1",
            "title": "Deep MDP: A Modular Framework for Multi-Object Tracking",
            "updated": "2023-10-22T13:17:37Z",
            "published": "2023-10-22T13:17:37Z",
            "summary": "This paper presents a fast and modular framework for Multi-Object Tracking\n(MOT) based on the Markov descision process (MDP) tracking-by-detection\nparadigm. It is designed to allow its various functional components to be\nreplaced by custom-designed alternatives to suit a given application. An\ninteractive GUI with integrated object detection, segmentation, MOT and\nsemi-automated labeling is also provided to help make it easier to get started\nwith this framework. Though not breaking new ground in terms of performance,\nDeep MDP has a large code-base that should be useful for the community to try\nout new ideas or simply to have an easy-to-use and easy-to-adapt system for any\nMOT application. Deep MDP is available at\nhttps://github.com/abhineet123/deep_mdp.",
            "author": [
                "Abhineet Singh"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14294v1",
                "http://arxiv.org/pdf/2310.14294v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14290v1",
            "title": "Data-driven Morozov regularization of inverse problems",
            "updated": "2023-10-22T12:56:26Z",
            "published": "2023-10-22T12:56:26Z",
            "summary": "The solution of inverse problems is central to a wide range of applications\nincluding medicine, biology, and engineering. These problems require finding a\ndesired solution in the presence of noisy observations. A key feature of\ninverse problems is their ill-posedness, which leads to unstable behavior under\nnoise when standard solution methods are used. For this reason, regularization\nmethods have been developed that compromise between data fitting and prior\nstructure. Recently, data-driven variational regularization methods have been\nintroduced, where the prior in the form of a regularizer is derived from\nprovided ground truth data. However, these methods have mainly been analyzed\nfor Tikhonov regularization, referred to as Network Tikhonov Regularization\n(NETT). In this paper, we propose and analyze Morozov regularization in\ncombination with a learned regularizer. The regularizers, which can be adapted\nto the training data, are defined by neural networks and are therefore\nnon-convex. We give a convergence analysis in the non-convex setting allowing\nnoise-dependent regularizers, and propose a possible training strategy. We\npresent numerical results for attenuation correction in the context of\nphotoacoustic tomography.",
            "author": [
                "Markus Haltmeier",
                "Richard Kowar",
                "Markus Tiefentaler"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14290v1",
                "http://arxiv.org/pdf/2310.14290v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14289v1",
            "title": "Separating multiscale Battery dynamics and predicting multi-step ahead\n  voltage simultaneously through a data-driven approach",
            "updated": "2023-10-22T12:53:53Z",
            "published": "2023-10-22T12:53:53Z",
            "summary": "Accurate prediction of battery performance under various ageing conditions is\nnecessary for reliable and stable battery operations. Due to complex battery\ndegradation mechanisms, estimating the accurate ageing level and\nageing-dependent battery dynamics is difficult. This work presents a\nhealth-aware battery model that is capable of separating fast dynamics from\nslowly varying states of degradation and state of charge (SOC). The method is\nbased on a sequence-to-sequence learning-based encoder-decoder model, where the\nencoder infers the slowly varying states as the latent space variables in an\nunsupervised way, and the decoder provides health-aware multi-step ahead\nprediction conditioned on slowly varying states from the encoder. The proposed\napproach is verified on a Lithium-ion battery ageing dataset based on real\ndriving profiles of electric vehicles.",
            "author": [
                "Tushar Desai",
                "Riccardo M. G. Ferrari"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14289v1",
                "http://arxiv.org/pdf/2310.14289v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14286v1",
            "title": "Finite-Sample Analysis of the Temporal Difference Learning",
            "updated": "2023-10-22T12:37:25Z",
            "published": "2023-10-22T12:37:25Z",
            "summary": "In this paper we consider the problem of obtaining sharp bounds for the\nperformance of temporal difference (TD) methods with linear functional\napproximation for policy evaluation in discounted Markov Decision Processes. We\nshow that a simple algorithm with a universal and instance-independent step\nsize together with Polyak-Ruppert tail averaging is sufficient to obtain\nnear-optimal variance and bias terms. We also provide the respective sample\ncomplexity bounds. Our proof technique is based on refined error bounds for\nlinear stochastic approximation together with the novel stability result for\nthe product of random matrices that arise from the TD-type recurrence.",
            "author": [
                "Sergey Samsonov",
                "Daniil Tiapkin",
                "Alexey Naumov",
                "Eric Moulines"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14286v1",
                "http://arxiv.org/pdf/2310.14286v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "math.OC",
                "62L20, 60J20"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14278v1",
            "title": "Conversational Speech Recognition by Learning Audio-textual Cross-modal\n  Contextual Representation",
            "updated": "2023-10-22T11:57:33Z",
            "published": "2023-10-22T11:57:33Z",
            "summary": "Automatic Speech Recognition (ASR) in conversational settings presents unique\nchallenges, including extracting relevant contextual information from previous\nconversational turns. Due to irrelevant content, error propagation, and\nredundancy, existing methods struggle to extract longer and more effective\ncontexts. To address this issue, we introduce a novel Conversational ASR\nsystem, extending the Conformer encoder-decoder model with cross-modal\nconversational representation. Our approach leverages a cross-modal extractor\nthat combines pre-trained speech and text models through a specialized encoder\nand a modal-level mask input. This enables the extraction of richer historical\nspeech context without explicit error propagation. We also incorporate\nconditional latent variational modules to learn conversational level attributes\nsuch as role preference and topic coherence. By introducing both cross-modal\nand conversational representations into the decoder, our model retains context\nover longer sentences without information loss, achieving relative accuracy\nimprovements of 8.8% and 23% on Mandarin conversation datasets HKUST and\nMagicData-RAMC, respectively, compared to the standard Conformer model.",
            "author": [
                "Kun Wei",
                "Bei Li",
                "Hang Lv",
                "Quan Lu",
                "Ning Jiang",
                "Lei Xie"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14278v1",
                "http://arxiv.org/pdf/2310.14278v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.CL",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14277v1",
            "title": "A Survey on Continual Semantic Segmentation: Theory, Challenge, Method\n  and Application",
            "updated": "2023-10-22T11:53:56Z",
            "published": "2023-10-22T11:53:56Z",
            "summary": "Continual learning, also known as incremental learning or life-long learning,\nstands at the forefront of deep learning and AI systems. It breaks through the\nobstacle of one-way training on close sets and enables continuous adaptive\nlearning on open-set conditions. In the recent decade, continual learning has\nbeen explored and applied in multiple fields especially in computer vision\ncovering classification, detection and segmentation tasks. Continual semantic\nsegmentation (CSS), of which the dense prediction peculiarity makes it a\nchallenging, intricate and burgeoning task. In this paper, we present a review\nof CSS, committing to building a comprehensive survey on problem formulations,\nprimary challenges, universal datasets, neoteric theories and multifarious\napplications. Concretely, we begin by elucidating the problem definitions and\nprimary challenges. Based on an in-depth investigation of relevant approaches,\nwe sort out and categorize current CSS models into two main branches including\n\\textit{data-replay} and \\textit{data-free} sets. In each branch, the\ncorresponding approaches are similarity-based clustered and thoroughly\nanalyzed, following qualitative comparison and quantitative reproductions on\nrelevant datasets. Besides, we also introduce four CSS specialities with\ndiverse application scenarios and development tendencies. Furthermore, we\ndevelop a benchmark for CSS encompassing representative references, evaluation\nresults and reproductions, which is available\nat~\\url{https://github.com/YBIO/SurveyCSS}. We hope this survey can serve as a\nreference-worthy and stimulating contribution to the advancement of the\nlife-long learning field, while also providing valuable perspectives for\nrelated fields.",
            "author": [
                "Bo Yuan",
                "Danpei Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14277v1",
                "http://arxiv.org/pdf/2310.14277v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14274v1",
            "title": "Robust Visual Imitation Learning with Inverse Dynamics Representations",
            "updated": "2023-10-22T11:47:35Z",
            "published": "2023-10-22T11:47:35Z",
            "summary": "Imitation learning (IL) has achieved considerable success in solving complex\nsequential decision-making problems. However, current IL methods mainly assume\nthat the environment for learning policies is the same as the environment for\ncollecting expert datasets. Therefore, these methods may fail to work when\nthere are slight differences between the learning and expert environments,\nespecially for challenging problems with high-dimensional image observations.\nHowever, in real-world scenarios, it is rare to have the chance to collect\nexpert trajectories precisely in the target learning environment. To address\nthis challenge, we propose a novel robust imitation learning approach, where we\ndevelop an inverse dynamics state representation learning objective to align\nthe expert environment and the learning environment. With the abstract state\nrepresentation, we design an effective reward function, which thoroughly\nmeasures the similarity between behavior data and expert data not only\nelement-wise, but also from the trajectory level. We conduct extensive\nexperiments to evaluate the proposed approach under various visual\nperturbations and in diverse visual control tasks. Our approach can achieve a\nnear-expert performance in most environments, and significantly outperforms the\nstate-of-the-art visual IL methods and robust IL methods.",
            "author": [
                "Siyuan Li",
                "Xun Wang",
                "Rongchang Zuo",
                "Kewu Sun",
                "Lingfei Cui",
                "Jishiyu Ding",
                "Peng Liu",
                "Zhe Ma"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14274v1",
                "http://arxiv.org/pdf/2310.14274v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14270v2",
            "title": "Diffusion-Based Adversarial Purification for Speaker Verification",
            "updated": "2023-10-24T13:07:58Z",
            "published": "2023-10-22T11:34:30Z",
            "summary": "Recently, automatic speaker verification (ASV) based on deep learning is\neasily contaminated by adversarial attacks, which is a new type of attack that\ninjects imperceptible perturbations to audio signals so as to make ASV produce\nwrong decisions. This poses a significant threat to the security and\nreliability of ASV systems. To address this issue, we propose a Diffusion-Based\nAdversarial Purification (DAP) method that enhances the robustness of ASV\nsystems against such adversarial attacks. Our method leverages a conditional\ndenoising diffusion probabilistic model to effectively purify the adversarial\nexamples and mitigate the impact of perturbations. DAP first introduces\ncontrolled noise into adversarial examples, and then performs a reverse\ndenoising process to reconstruct clean audio. Experimental results demonstrate\nthe efficacy of the proposed DAP in enhancing the security of ASV and meanwhile\nminimizing the distortion of the purified audio signals.",
            "author": [
                "Yibo Bai",
                "Xiao-Lei Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14270v2",
                "http://arxiv.org/pdf/2310.14270v2"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14262v1",
            "title": "Boosting Unsupervised Machine Translation with Pseudo-Parallel Data",
            "updated": "2023-10-22T10:57:12Z",
            "published": "2023-10-22T10:57:12Z",
            "summary": "Even with the latest developments in deep learning and large-scale language\nmodeling, the task of machine translation (MT) of low-resource languages\nremains a challenge. Neural MT systems can be trained in an unsupervised way\nwithout any translation resources but the quality lags behind, especially in\ntruly low-resource conditions. We propose a training strategy that relies on\npseudo-parallel sentence pairs mined from monolingual corpora in addition to\nsynthetic sentence pairs back-translated from monolingual corpora. We\nexperiment with different training schedules and reach an improvement of up to\n14.5 BLEU points (English to Ukrainian) over a baseline trained on\nback-translated data only.",
            "author": [
                "Ivana Kvapil\u00edkov\u00e1",
                "Ond\u0159ej Bojar"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14262v1",
                "http://arxiv.org/pdf/2310.14262v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14261v1",
            "title": "RSM-NLP at BLP-2023 Task 2: Bangla Sentiment Analysis using Weighted and\n  Majority Voted Fine-Tuned Transformers",
            "updated": "2023-10-22T10:55:56Z",
            "published": "2023-10-22T10:55:56Z",
            "summary": "This paper describes our approach to submissions made at Shared Task 2 at BLP\nWorkshop - Sentiment Analysis of Bangla Social Media Posts. Sentiment Analysis\nis an action research area in the digital age. With the rapid and constant\ngrowth of online social media sites and services and the increasing amount of\ntextual data, the application of automatic Sentiment Analysis is on the rise.\nHowever, most of the research in this domain is based on the English language.\nDespite being the world's sixth most widely spoken language, little work has\nbeen done in Bangla. This task aims to promote work on Bangla Sentiment\nAnalysis while identifying the polarity of social media content by determining\nwhether the sentiment expressed in the text is Positive, Negative, or Neutral.\nOur approach consists of experimenting and finetuning various multilingual and\npre-trained BERT-based models on our downstream tasks and using a Majority\nVoting and Weighted ensemble model that outperforms individual baseline model\nscores. Our system scored 0.711 for the multiclass classification task and\nscored 10th place among the participants on the leaderboard for the shared\ntask. Our code is available at https://github.com/ptnv-s/RSM-NLP-BLP-Task2 .",
            "author": [
                "Pratinav Seth",
                "Rashi Goel",
                "Komal Mathur",
                "Swetha Vemulapalli"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14261v1",
                "http://arxiv.org/pdf/2310.14261v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14248v1",
            "title": "From Static to Dynamic: A Continual Learning Framework for Large\n  Language Models",
            "updated": "2023-10-22T10:18:53Z",
            "published": "2023-10-22T10:18:53Z",
            "summary": "The vast number of parameters in large language models (LLMs) endows them\nwith remarkable capabilities, allowing them to excel in a variety of natural\nlanguage processing tasks. However, this complexity also presents challenges,\nmaking LLMs difficult to train and inhibiting their ability to continuously\nassimilate new knowledge, which may lead to inaccuracies in their outputs. To\nmitigate these issues, this paper presents DynaMind, a novel continual learning\nframework designed for LLMs. DynaMind incorporates memory mechanisms to\nassimilate new knowledge and modular operators to enhance the model inference\nprocess with the newly assimilated knowledge, consequently improving the\naccuracies of LLMs' outputs. Benchmark experiments demonstrate DynaMind's\neffectiveness in overcoming these challenges. The code and demo of DynaMind are\navailable on GitHub: https://github.com/Elfsong/DynaMind.",
            "author": [
                "Mingzhe Du",
                "Anh Tuan Luu",
                "Bin Ji",
                "See-kiong Ng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14248v1",
                "http://arxiv.org/pdf/2310.14248v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14246v1",
            "title": "Shortcuts for causal discovery of nonlinear models by score matching",
            "updated": "2023-10-22T10:09:52Z",
            "published": "2023-10-22T10:09:52Z",
            "summary": "The use of simulated data in the field of causal discovery is ubiquitous due\nto the scarcity of annotated real data. Recently, Reisach et al., 2021\nhighlighted the emergence of patterns in simulated linear data, which displays\nincreasing marginal variance in the casual direction. As an ablation in their\nexperiments, Montagna et al., 2023 found that similar patterns may emerge in\nnonlinear models for the variance of the score vector $\\nabla \\log\np_{\\mathbf{X}}$, and introduced the ScoreSort algorithm. In this work, we\nformally define and characterize this score-sortability pattern of nonlinear\nadditive noise models. We find that it defines a class of identifiable\n(bivariate) causal models overlapping with nonlinear additive noise models. We\ntheoretically demonstrate the advantages of ScoreSort in terms of statistical\nefficiency compared to prior state-of-the-art score matching-based methods and\nempirically show the score-sortability of the most common synthetic benchmarks\nin the literature. Our findings remark (1) the lack of diversity in the data as\nan important limitation in the evaluation of nonlinear causal discovery\napproaches, (2) the importance of thoroughly testing different settings within\na problem class, and (3) the importance of analyzing statistical properties in\ncausal discovery, where research is often limited to defining identifiability\nconditions of the model.",
            "author": [
                "Francesco Montagna",
                "Nicoletta Noceti",
                "Lorenzo Rosasco",
                "Francesco Locatello"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14246v1",
                "http://arxiv.org/pdf/2310.14246v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.16118v1",
            "title": "Imperceptible CMOS camera dazzle for adversarial attacks on deep neural\n  networks",
            "updated": "2023-10-22T09:44:59Z",
            "published": "2023-10-22T09:44:59Z",
            "summary": "Despite the outstanding performance of deep neural networks, they are\nvulnerable to adversarial attacks. While there are many invisible attacks in\nthe digital domain, most physical world adversarial attacks are visible. Here\nwe present an invisible optical adversarial attack that uses a light source to\ndazzle a CMOS camera with a rolling shutter. We present the photopic conditions\nrequired to keep the attacking light source completely invisible while\nsufficiently jamming the captured image so that a deep neural network applied\nto it is deceived.",
            "author": [
                "Zvi Stein",
                "Adrian Stern"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16118v1",
                "http://arxiv.org/pdf/2311.16118v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14239v1",
            "title": "Guidance system for Visually Impaired Persons using Deep Learning and\n  Optical flow",
            "updated": "2023-10-22T09:24:57Z",
            "published": "2023-10-22T09:24:57Z",
            "summary": "Visually impaired persons find it difficult to know about their surroundings\nwhile walking on a road. Walking sticks used by them can only give them\ninformation about the obstacles in the stick's proximity. Moreover, it is\nmostly effective in static or very slow-paced environments. Hence, this paper\nintroduces a method to guide them in a busy street. To create such a system it\nis very important to know about the approaching object and its direction of\napproach. To achieve this objective we created a method in which the image\nframe received from the video is divided into three parts i.e. center, left,\nand right to know the direction of approach of the approaching object. Object\ndetection is done using YOLOv3. Lucas Kanade's optical flow estimation method\nis used for the optical flow estimation and Depth-net is used for depth\nestimation. Using the depth information, object motion trajectory, and object\ncategory information, the model provides necessary information/warning to the\nperson. This model has been tested in the real world to show its effectiveness.",
            "author": [
                "Shwetang Dubey",
                "Alok Ranjan Sahoo",
                "Pavan Chakraborty"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14239v1",
                "http://arxiv.org/pdf/2310.14239v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14237v1",
            "title": "High-Quality 3D Face Reconstruction with Affine Convolutional Networks",
            "updated": "2023-10-22T09:04:43Z",
            "published": "2023-10-22T09:04:43Z",
            "summary": "Recent works based on convolutional encoder-decoder architecture and 3DMM\nparameterization have shown great potential for canonical view reconstruction\nfrom a single input image. Conventional CNN architectures benefit from\nexploiting the spatial correspondence between the input and output pixels.\nHowever, in 3D face reconstruction, the spatial misalignment between the input\nimage (e.g. face) and the canonical/UV output makes the feature\nencoding-decoding process quite challenging. In this paper, to tackle this\nproblem, we propose a new network architecture, namely the Affine Convolution\nNetworks, which enables CNN based approaches to handle spatially\nnon-corresponding input and output images and maintain high-fidelity quality\noutput at the same time. In our method, an affine transformation matrix is\nlearned from the affine convolution layer for each spatial location of the\nfeature maps. In addition, we represent 3D human heads in UV space with\nmultiple components, including diffuse maps for texture representation,\nposition maps for geometry representation, and light maps for recovering more\ncomplex lighting conditions in the real world. All the components can be\ntrained without any manual annotations. Our method is parametric-free and can\ngenerate high-quality UV maps at resolution of 512 x 512 pixels, while previous\napproaches normally generate 256 x 256 pixels or smaller. Our code will be\nreleased once the paper got accepted.",
            "author": [
                "Zhiqian Lin",
                "Jiangke Lin",
                "Lincheng Li",
                "Yi Yuan",
                "Zhengxia Zou"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3503161.3548421",
                "http://arxiv.org/abs/2310.14237v1",
                "http://arxiv.org/pdf/2310.14237v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15196v1",
            "title": "Efficient Meta Neural Heuristic for Multi-Objective Combinatorial\n  Optimization",
            "updated": "2023-10-22T08:59:02Z",
            "published": "2023-10-22T08:59:02Z",
            "summary": "Recently, neural heuristics based on deep reinforcement learning have\nexhibited promise in solving multi-objective combinatorial optimization\nproblems (MOCOPs). However, they are still struggling to achieve high learning\nefficiency and solution quality. To tackle this issue, we propose an efficient\nmeta neural heuristic (EMNH), in which a meta-model is first trained and then\nfine-tuned with a few steps to solve corresponding single-objective\nsubproblems. Specifically, for the training process, a (partial)\narchitecture-shared multi-task model is leveraged to achieve parallel learning\nfor the meta-model, so as to speed up the training; meanwhile, a scaled\nsymmetric sampling method with respect to the weight vectors is designed to\nstabilize the training. For the fine-tuning process, an efficient hierarchical\nmethod is proposed to systematically tackle all the subproblems. Experimental\nresults on the multi-objective traveling salesman problem (MOTSP),\nmulti-objective capacitated vehicle routing problem (MOCVRP), and\nmulti-objective knapsack problem (MOKP) show that, EMNH is able to outperform\nthe state-of-the-art neural heuristics in terms of solution quality and\nlearning efficiency, and yield competitive solutions to the strong traditional\nheuristics while consuming much shorter time.",
            "author": [
                "Jinbiao Chen",
                "Jiahai Wang",
                "Zizhen Zhang",
                "Zhiguang Cao",
                "Te Ye",
                "Siyuan Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15196v1",
                "http://arxiv.org/pdf/2310.15196v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15195v1",
            "title": "Neural Multi-Objective Combinatorial Optimization with Diversity\n  Enhancement",
            "updated": "2023-10-22T08:50:57Z",
            "published": "2023-10-22T08:50:57Z",
            "summary": "Most of existing neural methods for multi-objective combinatorial\noptimization (MOCO) problems solely rely on decomposition, which often leads to\nrepetitive solutions for the respective subproblems, thus a limited Pareto set.\nBeyond decomposition, we propose a novel neural heuristic with diversity\nenhancement (NHDE) to produce more Pareto solutions from two perspectives. On\nthe one hand, to hinder duplicated solutions for different subproblems, we\npropose an indicator-enhanced deep reinforcement learning method to guide the\nmodel, and design a heterogeneous graph attention mechanism to capture the\nrelations between the instance graph and the Pareto front graph. On the other\nhand, to excavate more solutions in the neighborhood of each subproblem, we\npresent a multiple Pareto optima strategy to sample and preserve desirable\nsolutions. Experimental results on classic MOCO problems show that our NHDE is\nable to generate a Pareto front with higher diversity, thereby achieving\nsuperior overall performance. Moreover, our NHDE is generic and can be applied\nto different neural methods for MOCO.",
            "author": [
                "Jinbiao Chen",
                "Zizhen Zhang",
                "Zhiguang Cao",
                "Yaoxin Wu",
                "Yining Ma",
                "Te Ye",
                "Jiahai Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15195v1",
                "http://arxiv.org/pdf/2310.15195v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14230v2",
            "title": "A comprehensive survey on deep active learning and its applications in\n  medical image analysis",
            "updated": "2023-10-24T01:36:19Z",
            "published": "2023-10-22T08:46:40Z",
            "summary": "Deep learning has achieved widespread success in medical image analysis,\nleading to an increasing demand for large-scale expert-annotated medical image\ndatasets. Yet, the high cost of annotating medical images severely hampers the\ndevelopment of deep learning in this field. To reduce annotation costs, active\nlearning aims to select the most informative samples for annotation and train\nhigh-performance models with as few labeled samples as possible. In this\nsurvey, we review the core methods of active learning, including the evaluation\nof informativeness and sampling strategy. For the first time, we provide a\ndetailed summary of the integration of active learning with other\nlabel-efficient techniques, such as semi-supervised, self-supervised learning,\nand so on. Additionally, we also highlight active learning works that are\nspecifically tailored to medical image analysis. In the end, we offer our\nperspectives on the future trends and challenges of active learning and its\napplications in medical image analysis.",
            "author": [
                "Haoran Wang",
                "Qiuye Jin",
                "Shiman Li",
                "Siyu Liu",
                "Manning Wang",
                "Zhijian Song"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14230v2",
                "http://arxiv.org/pdf/2310.14230v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14228v1",
            "title": "Hierarchical Vector Quantized Transformer for Multi-class Unsupervised\n  Anomaly Detection",
            "updated": "2023-10-22T08:20:33Z",
            "published": "2023-10-22T08:20:33Z",
            "summary": "Unsupervised image Anomaly Detection (UAD) aims to learn robust and\ndiscriminative representations of normal samples. While separate solutions per\nclass endow expensive computation and limited generalizability, this paper\nfocuses on building a unified framework for multiple classes. Under such a\nchallenging setting, popular reconstruction-based networks with continuous\nlatent representation assumption always suffer from the \"identical shortcut\"\nissue, where both normal and abnormal samples can be well recovered and\ndifficult to distinguish. To address this pivotal issue, we propose a\nhierarchical vector quantized prototype-oriented Transformer under a\nprobabilistic framework. First, instead of learning the continuous\nrepresentations, we preserve the typical normal patterns as discrete iconic\nprototypes, and confirm the importance of Vector Quantization in preventing the\nmodel from falling into the shortcut. The vector quantized iconic prototype is\nintegrated into the Transformer for reconstruction, such that the abnormal data\npoint is flipped to a normal data point.Second, we investigate an exquisite\nhierarchical framework to relieve the codebook collapse issue and replenish\nfrail normal patterns. Third, a prototype-oriented optimal transport method is\nproposed to better regulate the prototypes and hierarchically evaluate the\nabnormal score. By evaluating on MVTec-AD and VisA datasets, our model\nsurpasses the state-of-the-art alternatives and possesses good\ninterpretability. The code is available at\nhttps://github.com/RuiyingLu/HVQ-Trans.",
            "author": [
                "Ruiying Lu",
                "YuJie Wu",
                "Long Tian",
                "Dongsheng Wang",
                "Bo Chen",
                "Xiyang Liu",
                "Ruimin Hu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14228v1",
                "http://arxiv.org/pdf/2310.14228v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14227v1",
            "title": "Revisiting Deep Ensemble for Out-of-Distribution Detection: A Loss\n  Landscape Perspective",
            "updated": "2023-10-22T08:11:51Z",
            "published": "2023-10-22T08:11:51Z",
            "summary": "Existing Out-of-Distribution (OoD) detection methods address to detect OoD\nsamples from In-Distribution data (InD) mainly by exploring differences in\nfeatures, logits and gradients in Deep Neural Networks (DNNs). We in this work\npropose a new perspective upon loss landscape and mode ensemble to investigate\nOoD detection. In the optimization of DNNs, there exist many local optima in\nthe parameter space, or namely modes. Interestingly, we observe that these\nindependent modes, which all reach low-loss regions with InD data (training and\ntest data), yet yield significantly different loss landscapes with OoD data.\nSuch an observation provides a novel view to investigate the OoD detection from\nthe loss landscape and further suggests significantly fluctuating OoD detection\nperformance across these modes. For instance, FPR values of the RankFeat method\ncan range from 46.58% to 84.70% among 5 modes, showing uncertain detection\nperformance evaluations across independent modes. Motivated by such diversities\non OoD loss landscape across modes, we revisit the deep ensemble method for OoD\ndetection through mode ensemble, leading to improved performance and benefiting\nthe OoD detector with reduced variances. Extensive experiments covering varied\nOoD detectors and network structures illustrate high variances across modes and\nalso validate the superiority of mode ensemble in boosting OoD detection. We\nhope this work could attract attention in the view of independent modes in the\nOoD loss landscape and more reliable evaluations on OoD detectors.",
            "author": [
                "Kun Fang",
                "Qinghua Tao",
                "Xiaolin Huang",
                "Jie Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14227v1",
                "http://arxiv.org/pdf/2310.14227v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14225v1",
            "title": "Customising General Large Language Models for Specialised Emotion\n  Recognition Tasks",
            "updated": "2023-10-22T08:09:13Z",
            "published": "2023-10-22T08:09:13Z",
            "summary": "The advent of large language models (LLMs) has gained tremendous attention\nover the past year. Previous studies have shown the astonishing performance of\nLLMs not only in other tasks but also in emotion recognition in terms of\naccuracy, universality, explanation, robustness, few/zero-shot learning, and\nothers. Leveraging the capability of LLMs inevitably becomes an essential\nsolution for emotion recognition. To this end, we further comprehensively\ninvestigate how LLMs perform in linguistic emotion recognition if we\nconcentrate on this specific task. Specifically, we exemplify a publicly\navailable and widely used LLM -- Chat General Language Model, and customise it\nfor our target by using two different modal adaptation techniques, i.e., deep\nprompt tuning and low-rank adaptation. The experimental results obtained on six\nwidely used datasets present that the adapted LLM can easily outperform other\nstate-of-the-art but specialised deep models. This indicates the strong\ntransferability and feasibility of LLMs in the field of emotion recognition.",
            "author": [
                "Liyizhe Peng",
                "Zixing Zhang",
                "Tao Pang",
                "Jing Han",
                "Huan Zhao",
                "Hao Chen",
                "Bj\u00f6rn W. Schuller"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14225v1",
                "http://arxiv.org/pdf/2310.14225v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14224v1",
            "title": "Detrive: Imitation Learning with Transformer Detection for End-to-End\n  Autonomous Driving",
            "updated": "2023-10-22T08:07:56Z",
            "published": "2023-10-22T08:07:56Z",
            "summary": "This Paper proposes a novel Transformer-based end-to-end autonomous driving\nmodel named Detrive. This model solves the problem that the past end-to-end\nmodels cannot detect the position and size of traffic participants. Detrive\nuses an end-to-end transformer based detection model as its perception module;\na multi-layer perceptron as its feature fusion network; a recurrent neural\nnetwork with gate recurrent unit for path planning; and two controllers for the\nvehicle's forward speed and turning angle. The model is trained with an on-line\nimitation learning method. In order to obtain a better training set, a\nreinforcement learning agent that can directly obtain a ground truth bird's-eye\nview map from the Carla simulator as a perceptual output, is used as teacher\nfor the imitation learning. The trained model is tested on the Carla's\nautonomous driving benchmark. The results show that the Transformer detector\nbased end-to-end model has obvious advantages in dynamic obstacle avoidance\ncompared with the traditional classifier based end-to-end model.",
            "author": [
                "Daoming Chen",
                "Ning Wang",
                "Feng Chen",
                "Tony Pipe"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14224v1",
                "http://arxiv.org/pdf/2310.14224v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14216v1",
            "title": "UniMAP: Universal SMILES-Graph Representation Learning",
            "updated": "2023-10-22T07:48:33Z",
            "published": "2023-10-22T07:48:33Z",
            "summary": "Molecular representation learning is fundamental for many drug related\napplications. Most existing molecular pre-training models are limited in using\nsingle molecular modality, either SMILES or graph representation. To\neffectively leverage both modalities, we argue that it is critical to capture\nthe fine-grained 'semantics' between SMILES and graph, because subtle\nsequence/graph differences may lead to contrary molecular properties. In this\npaper, we propose a universal SMILE-graph representation learning model, namely\nUniMAP. Firstly, an embedding layer is employed to obtain the token and\nnode/edge representation in SMILES and graph, respectively. A multi-layer\nTransformer is then utilized to conduct deep cross-modality fusion. Specially,\nfour kinds of pre-training tasks are designed for UniMAP, including Multi-Level\nCross-Modality Masking (CMM), SMILES-Graph Matching (SGM), Fragment-Level\nAlignment (FLA), and Domain Knowledge Learning (DKL). In this way, both global\n(i.e. SGM and DKL) and local (i.e. CMM and FLA) alignments are integrated to\nachieve comprehensive cross-modality fusion. We evaluate UniMAP on various\ndownstream tasks, i.e. molecular property prediction, drug-target affinity\nprediction and drug-drug interaction. Experimental results show that UniMAP\noutperforms current state-of-the-art pre-training methods.We also visualize the\nlearned representations to demonstrate the effect of multi-modality\nintegration.",
            "author": [
                "Shikun Feng",
                "Lixin Yang",
                "Weiying Ma",
                "Yanyan Lan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14216v1",
                "http://arxiv.org/pdf/2310.14216v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "q-bio.BM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14214v1",
            "title": "TransY-Net:Learning Fully Transformer Networks for Change Detection of\n  Remote Sensing Images",
            "updated": "2023-10-22T07:42:19Z",
            "published": "2023-10-22T07:42:19Z",
            "summary": "In the remote sensing field, Change Detection (CD) aims to identify and\nlocalize the changed regions from dual-phase images over the same places.\nRecently, it has achieved great progress with the advances of deep learning.\nHowever, current methods generally deliver incomplete CD regions and irregular\nCD boundaries due to the limited representation ability of the extracted visual\nfeatures. To relieve these issues, in this work we propose a novel\nTransformer-based learning framework named TransY-Net for remote sensing image\nCD, which improves the feature extraction from a global view and combines\nmulti-level visual features in a pyramid manner. More specifically, the\nproposed framework first utilizes the advantages of Transformers in long-range\ndependency modeling. It can help to learn more discriminative global-level\nfeatures and obtain complete CD regions. Then, we introduce a novel pyramid\nstructure to aggregate multi-level visual features from Transformers for\nfeature enhancement. The pyramid structure grafted with a Progressive Attention\nModule (PAM) can improve the feature representation ability with additional\ninter-dependencies through spatial and channel attentions. Finally, to better\ntrain the whole framework, we utilize the deeply-supervised learning with\nmultiple boundary-aware loss functions. Extensive experiments demonstrate that\nour proposed method achieves a new state-of-the-art performance on four optical\nand two SAR image CD benchmarks. The source code is released at\nhttps://github.com/Drchip61/TransYNet.",
            "author": [
                "Tianyu Yan",
                "Zifu Wan",
                "Pingping Zhang",
                "Gong Cheng",
                "Huchuan Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14214v1",
                "http://arxiv.org/pdf/2310.14214v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14211v1",
            "title": "LUNA: A Model-Based Universal Analysis Framework for Large Language\n  Models",
            "updated": "2023-10-22T07:26:21Z",
            "published": "2023-10-22T07:26:21Z",
            "summary": "Over the past decade, Artificial Intelligence (AI) has had great success\nrecently and is being used in a wide range of academic and industrial fields.\nMore recently, LLMs have made rapid advancements that have propelled AI to a\nnew level, enabling even more diverse applications and industrial domains with\nintelligence, particularly in areas like software engineering and natural\nlanguage processing. Nevertheless, a number of emerging trustworthiness\nconcerns and issues exhibited in LLMs have already recently received much\nattention, without properly solving which the widespread adoption of LLMs could\nbe greatly hindered in practice. The distinctive characteristics of LLMs, such\nas the self-attention mechanism, extremely large model scale, and\nautoregressive generation schema, differ from classic AI software based on CNNs\nand RNNs and present new challenges for quality analysis. Up to the present, it\nstill lacks universal and systematic analysis techniques for LLMs despite the\nurgent industrial demand. Towards bridging this gap, we initiate an early\nexploratory study and propose a universal analysis framework for LLMs, LUNA,\ndesigned to be general and extensible, to enable versatile analysis of LLMs\nfrom multiple quality perspectives in a human-interpretable manner. In\nparticular, we first leverage the data from desired trustworthiness\nperspectives to construct an abstract model as an auxiliary analysis asset,\nwhich is empowered by various abstract model construction methods. To assess\nthe quality of the abstract model, we collect and define a number of evaluation\nmetrics, aiming at both abstract model level and the semantics level. Then, the\nsemantics, which is the degree of satisfaction of the LLM w.r.t. the\ntrustworthiness perspective, is bound to and enriches the abstract model with\nsemantics, which enables more detailed analysis applications for diverse\npurposes.",
            "author": [
                "Da Song",
                "Xuan Xie",
                "Jiayang Song",
                "Derui Zhu",
                "Yuheng Huang",
                "Felix Juefei-Xu",
                "Lei Ma"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14211v1",
                "http://arxiv.org/pdf/2310.14211v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL",
                "cs.CR",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14209v1",
            "title": "SUT: Active Defects Probing for Transcompiler Models",
            "updated": "2023-10-22T07:16:02Z",
            "published": "2023-10-22T07:16:02Z",
            "summary": "Automatic Program translation has enormous application value and hence has\nbeen attracting significant interest from AI researchers. However, we observe\nthat current program translation models still make elementary syntax errors,\nparticularly, when the target language does not have syntax elements in the\nsource language. Metrics like BLUE, CodeBLUE and computation accuracy may not\nexpose these issues. In this paper we introduce a new metrics for programming\nlanguage translation and these metrics address these basic syntax errors. We\ndevelop a novel active defects probing suite called Syntactic Unit Tests (SUT)\nwhich includes a highly interpretable evaluation harness for accuracy and test\nscoring. Experiments have shown that even powerful models like ChatGPT still\nmake mistakes on these basic unit tests. Specifically, compared to previous\nprogram translation task evaluation dataset, its pass rate on our unit tests\nhas decreased by 26.15%. Further our evaluation harness reveal syntactic\nelement errors in which these models exhibit deficiencies.",
            "author": [
                "Mengnan Qi",
                "Yufan Huang",
                "Maoquan Wang",
                "Yongqiang Yao",
                "Zihan Liu",
                "Bin Gu",
                "Colin Clement",
                "Neel Sundaresan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14209v1",
                "http://arxiv.org/pdf/2310.14209v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14206v1",
            "title": "Manifold-Preserving Transformers are Effective for Short-Long Range\n  Encoding",
            "updated": "2023-10-22T06:58:28Z",
            "published": "2023-10-22T06:58:28Z",
            "summary": "Multi-head self-attention-based Transformers have shown promise in different\nlearning tasks. Albeit these models exhibit significant improvement in\nunderstanding short-term and long-term contexts from sequences, encoders of\nTransformers and their variants fail to preserve layer-wise contextual\ninformation. Transformers usually project tokens onto sparse manifolds and fail\nto preserve mathematical equivalence among the token representations. In this\nwork, we propose TransJect, an encoder model that guarantees a theoretical\nbound for layer-wise distance preservation between a pair of tokens. We propose\na simple alternative to dot-product attention to ensure Lipschitz continuity.\nThis allows TransJect to learn injective mappings to transform token\nrepresentations to different manifolds with similar topology and preserve\nEuclidean distance between every pair of tokens in subsequent layers.\nEvaluations across multiple benchmark short- and long-sequence classification\ntasks show maximum improvements of 6.8% and 5.9%, respectively, over the\nvariants of Transformers. Additionally, TransJect displays 79% better\nperformance than Transformer on the language modeling task. We further\nhighlight the shortcomings of multi-head self-attention from the statistical\nphysics viewpoint. Although multi-head self-attention was incepted to learn\ndifferent abstraction levels within the networks, our empirical analyses\nsuggest that different attention heads learn randomly and unorderly. In\ncontrast, TransJect adapts a mixture of experts for regularization; these\nexperts are more orderly and balanced and learn different sparse\nrepresentations from the input sequences. TransJect exhibits very low entropy\nand can be efficiently scaled to larger depths.",
            "author": [
                "Ayan Sengupta",
                "Md Shad Akhtar",
                "Tanmoy Chakraborty"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14206v1",
                "http://arxiv.org/pdf/2310.14206v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14205v1",
            "title": "Machine-learning-assisted analysis of transition metal dichalcogenide\n  thin-film growth",
            "updated": "2023-10-22T06:52:39Z",
            "published": "2023-10-22T06:52:39Z",
            "summary": "In situ reflective high-energy electron diffraction (RHEED) is widely used to\nmonitor the surface crystalline state during thin-film growth by molecular beam\nepitaxy (MBE) and pulsed laser deposition. With the recent development of\nmachine learning (ML), ML-assisted analysis of RHEED videos aids in\ninterpreting the complete RHEED data of oxide thin films. The quantitative\nanalysis of RHEED data allows us to characterize and categorize the growth\nmodes step by step, and extract hidden knowledge of the epitaxial film growth\nprocess. In this study, we employed the ML-assisted RHEED analysis method to\ninvestigate the growth of 2D thin films of transition metal dichalcogenides\n(ReSe2) on graphene substrates by MBE. Principal component analysis (PCA) and\nK-means clustering were used to separate statistically important patterns and\nvisualize the trend of pattern evolution without any notable loss of\ninformation. Using the modified PCA, we could monitor the diffraction intensity\nof solely the ReSe2 layers by filtering out the substrate contribution. These\nfindings demonstrate that ML analysis can be successfully employed to examine\nand understand the film-growth dynamics of 2D materials. Further, the ML-based\nmethod can pave the way for the development of advanced real-time monitoring\nand autonomous material synthesis techniques.",
            "author": [
                "Hyuk Jin Kim",
                "Minsu Chong",
                "Tae Gyu Rhee",
                "Yeong Gwang Khim",
                "Min-Hyoung Jung",
                "Young-Min Kim",
                "Hu Young Jeong",
                "Byoung Ki Choi",
                "Young Jun Chang"
            ],
            "link": [
                "http://dx.doi.org/10.1186/s40580-023-00359-5",
                "http://arxiv.org/abs/2310.14205v1",
                "http://arxiv.org/pdf/2310.14205v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14201v2",
            "title": "Prompt Engineering Through the Lens of Optimal Control",
            "updated": "2023-11-03T11:59:45Z",
            "published": "2023-10-22T06:34:09Z",
            "summary": "Prompt Engineering (PE) has emerged as a critical technique for guiding Large\nLanguage Models (LLMs) in solving intricate tasks. Its importance is\nhighlighted by its potential to significantly enhance the efficiency and\neffectiveness of human-machine interaction. As tasks grow increasingly complex,\nrecent advanced PE methods have extended beyond the limitations of single-round\ninteractions to embrace multi-round interactions, which allows for a deeper and\nmore nuanced engagement with LLMs. In this paper, we propose an optimal control\nframework tailored for multi-round interactions with LLMs. This framework\nprovides a unified mathematical structure that not only systematizes the\nexisting PE methods but also sets the stage for rigorous analytical\nimprovements. Furthermore, we extend this framework to include PE via ensemble\nmethods and multi-agent collaboration, thereby enlarging the scope of\napplicability. By adopting an optimal control perspective, we offer fresh\ninsights into existing PE methods and highlight theoretical challenges that\nwarrant future research. Besides, our work lays a foundation for the\ndevelopment of more effective and interpretable PE methods.",
            "author": [
                "Yifan Luo",
                "Yiming Tang",
                "Chengfeng Shen",
                "Zhennan Zhou",
                "Bin Dong"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14201v2",
                "http://arxiv.org/pdf/2310.14201v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14197v1",
            "title": "Diffusion-based Data Augmentation for Nuclei Image Segmentation",
            "updated": "2023-10-22T06:16:16Z",
            "published": "2023-10-22T06:16:16Z",
            "summary": "Nuclei segmentation is a fundamental but challenging task in the quantitative\nanalysis of histopathology images. Although fully-supervised deep\nlearning-based methods have made significant progress, a large number of\nlabeled images are required to achieve great segmentation performance.\nConsidering that manually labeling all nuclei instances for a dataset is\ninefficient, obtaining a large-scale human-annotated dataset is time-consuming\nand labor-intensive. Therefore, augmenting a dataset with only a few labeled\nimages to improve the segmentation performance is of significant research and\napplication value. In this paper, we introduce the first diffusion-based\naugmentation method for nuclei segmentation. The idea is to synthesize a large\nnumber of labeled images to facilitate training the segmentation model. To\nachieve this, we propose a two-step strategy. In the first step, we train an\nunconditional diffusion model to synthesize the Nuclei Structure that is\ndefined as the representation of pixel-level semantic and distance transform.\nEach synthetic nuclei structure will serve as a constraint on histopathology\nimage synthesis and is further post-processed to be an instance map. In the\nsecond step, we train a conditioned diffusion model to synthesize\nhistopathology images based on nuclei structures. The synthetic histopathology\nimages paired with synthetic instance maps will be added to the real dataset\nfor training the segmentation model. The experimental results show that by\naugmenting 10% labeled real dataset with synthetic samples, one can achieve\ncomparable segmentation results with the fully-supervised baseline.",
            "author": [
                "Xinyi Yu",
                "Guanbin Li",
                "Wei Lou",
                "Siqi Liu",
                "Xiang Wan",
                "Yan Chen",
                "Haofeng Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14197v1",
                "http://arxiv.org/pdf/2310.14197v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14196v1",
            "title": "Learning to Discern: Imitating Heterogeneous Human Demonstrations with\n  Preference and Representation Learning",
            "updated": "2023-10-22T06:08:55Z",
            "published": "2023-10-22T06:08:55Z",
            "summary": "Practical Imitation Learning (IL) systems rely on large human demonstration\ndatasets for successful policy learning. However, challenges lie in maintaining\nthe quality of collected data and addressing the suboptimal nature of some\ndemonstrations, which can compromise the overall dataset quality and hence the\nlearning outcome. Furthermore, the intrinsic heterogeneity in human behavior\ncan produce equally successful but disparate demonstrations, further\nexacerbating the challenge of discerning demonstration quality. To address\nthese challenges, this paper introduces Learning to Discern (L2D), an offline\nimitation learning framework for learning from demonstrations with diverse\nquality and style. Given a small batch of demonstrations with sparse quality\nlabels, we learn a latent representation for temporally embedded trajectory\nsegments. Preference learning in this latent space trains a quality evaluator\nthat generalizes to new demonstrators exhibiting different styles. Empirically,\nwe show that L2D can effectively assess and learn from varying demonstrations,\nthereby leading to improved policy performance across a range of tasks in both\nsimulations and on a physical robot.",
            "author": [
                "Sachit Kuhar",
                "Shuo Cheng",
                "Shivang Chopra",
                "Matthew Bronars",
                "Danfei Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14196v1",
                "http://arxiv.org/pdf/2310.14196v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14189v1",
            "title": "Improved Techniques for Training Consistency Models",
            "updated": "2023-10-22T05:33:38Z",
            "published": "2023-10-22T05:33:38Z",
            "summary": "Consistency models are a nascent family of generative models that can sample\nhigh quality data in one step without the need for adversarial training.\nCurrent consistency models achieve optimal sample quality by distilling from\npre-trained diffusion models and employing learned metrics such as LPIPS.\nHowever, distillation limits the quality of consistency models to that of the\npre-trained diffusion model, and LPIPS causes undesirable bias in evaluation.\nTo tackle these challenges, we present improved techniques for consistency\ntraining, where consistency models learn directly from data without\ndistillation. We delve into the theory behind consistency training and identify\na previously overlooked flaw, which we address by eliminating Exponential\nMoving Average from the teacher consistency model. To replace learned metrics\nlike LPIPS, we adopt Pseudo-Huber losses from robust statistics. Additionally,\nwe introduce a lognormal noise schedule for the consistency training objective,\nand propose to double total discretization steps every set number of training\niterations. Combined with better hyperparameter tuning, these modifications\nenable consistency models to achieve FID scores of 2.51 and 3.25 on CIFAR-10\nand ImageNet $64\\times 64$ respectively in a single sampling step. These scores\nmark a 3.5$\\times$ and 4$\\times$ improvement compared to prior consistency\ntraining approaches. Through two-step sampling, we further reduce FID scores to\n2.24 and 2.77 on these two datasets, surpassing those obtained via distillation\nin both one-step and two-step settings, while narrowing the gap between\nconsistency models and other state-of-the-art generative models.",
            "author": [
                "Yang Song",
                "Prafulla Dhariwal"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14189v1",
                "http://arxiv.org/pdf/2310.14189v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14188v1",
            "title": "A General Theory for Softmax Gating Multinomial Logistic Mixture of\n  Experts",
            "updated": "2023-10-22T05:32:19Z",
            "published": "2023-10-22T05:32:19Z",
            "summary": "Mixture-of-experts (MoE) model incorporates the power of multiple submodels\nvia gating functions to achieve greater performance in numerous regression and\nclassification applications. From a theoretical perspective, while there have\nbeen previous attempts to comprehend the behavior of that model under the\nregression settings through the convergence analysis of maximum likelihood\nestimation in the Gaussian MoE model, such analysis under the setting of a\nclassification problem has remained missing in the literature. We close this\ngap by establishing the convergence rates of density estimation and parameter\nestimation in the softmax gating multinomial logistic MoE model. Notably, when\npart of the expert parameters vanish, these rates are shown to be slower than\npolynomial rates owing to an inherent interaction between the softmax gating\nand expert functions via partial differential equations. To address this issue,\nwe propose using a novel class of modified softmax gating functions which\ntransform the input value before delivering them to the gating functions. As a\nresult, the previous interaction disappears and the parameter estimation rates\nare significantly improved.",
            "author": [
                "Huy Nguyen",
                "Pedram Akbarian",
                "TrungTin Nguyen",
                "Nhat Ho"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14188v1",
                "http://arxiv.org/pdf/2310.14188v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14184v1",
            "title": "Partition Speeds Up Learning Implicit Neural Representations Based on\n  Exponential-Increase Hypothesis",
            "updated": "2023-10-22T05:15:58Z",
            "published": "2023-10-22T05:15:58Z",
            "summary": "$\\textit{Implicit neural representations}$ (INRs) aim to learn a\n$\\textit{continuous function}$ (i.e., a neural network) to represent an image,\nwhere the input and output of the function are pixel coordinates and RGB/Gray\nvalues, respectively. However, images tend to consist of many objects whose\ncolors are not perfectly consistent, resulting in the challenge that image is\nactually a $\\textit{discontinuous piecewise function}$ and cannot be well\nestimated by a continuous function. In this paper, we empirically investigate\nthat if a neural network is enforced to fit a discontinuous piecewise function\nto reach a fixed small error, the time costs will increase exponentially with\nrespect to the boundaries in the spatial domain of the target signal. We name\nthis phenomenon the $\\textit{exponential-increase}$ hypothesis. Under the\n$\\textit{exponential-increase}$ hypothesis, learning INRs for images with many\nobjects will converge very slowly. To address this issue, we first prove that\npartitioning a complex signal into several sub-regions and utilizing piecewise\nINRs to fit that signal can significantly speed up the convergence. Based on\nthis fact, we introduce a simple partition mechanism to boost the performance\nof two INR methods for image reconstruction: one for learning INRs, and the\nother for learning-to-learn INRs. In both cases, we partition an image into\ndifferent sub-regions and dedicate smaller networks for each part. In addition,\nwe further propose two partition rules based on regular grids and semantic\nsegmentation maps, respectively. Extensive experiments validate the\neffectiveness of the proposed partitioning methods in terms of learning INR for\na single image (ordinary learning framework) and the learning-to-learn\nframework.",
            "author": [
                "Ke Liu",
                "Feng Liu",
                "Haishuai Wang",
                "Ning Ma",
                "Jiajun Bu",
                "Bo Han"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14184v1",
                "http://arxiv.org/pdf/2310.14184v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14176v1",
            "title": "Prompt-based Grouping Transformer for Nucleus Detection and\n  Classification",
            "updated": "2023-10-22T04:50:48Z",
            "published": "2023-10-22T04:50:48Z",
            "summary": "Automatic nuclei detection and classification can produce effective\ninformation for disease diagnosis. Most existing methods classify nuclei\nindependently or do not make full use of the semantic similarity between nuclei\nand their grouping features. In this paper, we propose a novel end-to-end\nnuclei detection and classification framework based on a grouping\ntransformer-based classifier. The nuclei classifier learns and updates the\nrepresentations of nuclei groups and categories via hierarchically grouping the\nnucleus embeddings. Then the cell types are predicted with the pairwise\ncorrelations between categorical embeddings and nucleus features. For the\nefficiency of the fully transformer-based framework, we take the nucleus group\nembeddings as the input prompts of backbone, which helps harvest grouping\nguided features by tuning only the prompts instead of the whole backbone.\nExperimental results show that the proposed method significantly outperforms\nthe existing models on three datasets.",
            "author": [
                "Junjia Huang",
                "Haofeng Li",
                "Weijun Sun",
                "Xiang Wan",
                "Guanbin Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14176v1",
                "http://arxiv.org/pdf/2310.14176v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14174v1",
            "title": "An In-Context Schema Understanding Method for Knowledge Base Question\n  Answering",
            "updated": "2023-10-22T04:19:17Z",
            "published": "2023-10-22T04:19:17Z",
            "summary": "The Knowledge Base Question Answering (KBQA) task aims to answer natural\nlanguage questions based on a given knowledge base. As a kind of common method\nfor this task, semantic parsing-based ones first convert natural language\nquestions to logical forms (e.g., SPARQL queries) and then execute them on\nknowledge bases to get answers. Recently, Large Language Models (LLMs) have\nshown strong abilities in language understanding and may be adopted as semantic\nparsers in such kinds of methods. However, in doing so, a great challenge for\nLLMs is to understand the schema of knowledge bases. Therefore, in this paper,\nwe propose an In-Context Schema Understanding (ICSU) method for facilitating\nLLMs to be used as a semantic parser in KBQA. Specifically, ICSU adopts the\nIn-context Learning mechanism to instruct LLMs to generate SPARQL queries with\nexamples. In order to retrieve appropriate examples from annotated\nquestion-query pairs, which contain comprehensive schema information related to\nquestions, ICSU explores four different retrieval strategies. Experimental\nresults on the largest KBQA benchmark, KQA Pro, show that ICSU with all these\nstrategies outperforms that with a random retrieval strategy significantly\n(from 12\\% to 78.76\\% in accuracy).",
            "author": [
                "Yantao Liu",
                "Zixuan Li",
                "Xiaolong Jin",
                "Long Bai",
                "Saiping Guan",
                "Jiafeng Guo",
                "Xueqi Cheng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14174v1",
                "http://arxiv.org/pdf/2310.14174v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14172v1",
            "title": "ASC: Appearance and Structure Consistency for Unsupervised Domain\n  Adaptation in Fetal Brain MRI Segmentation",
            "updated": "2023-10-22T04:12:06Z",
            "published": "2023-10-22T04:12:06Z",
            "summary": "Automatic tissue segmentation of fetal brain images is essential for the\nquantitative analysis of prenatal neurodevelopment. However, producing\nvoxel-level annotations of fetal brain imaging is time-consuming and expensive.\nTo reduce labeling costs, we propose a practical unsupervised domain adaptation\n(UDA) setting that adapts the segmentation labels of high-quality fetal brain\natlases to unlabeled fetal brain MRI data from another domain. To address the\ntask, we propose a new UDA framework based on Appearance and Structure\nConsistency, named ASC. We adapt the segmentation model to the appearances of\ndifferent domains by constraining the consistency before and after a\nfrequency-based image transformation, which is to swap the appearance between\nbrain MRI data and atlases. Consider that even in the same domain, the fetal\nbrain images of different gestational ages could have significant variations in\nthe anatomical structures. To make the model adapt to the structural variations\nin the target domain, we further encourage prediction consistency under\ndifferent structural perturbations. Extensive experiments on FeTA 2021\nbenchmark demonstrate the effectiveness of our ASC in comparison to\nregistration-based, semi-supervised learning-based, and existing UDA-based\nmethods.",
            "author": [
                "Zihang Xu",
                "Haifan Gong",
                "Xiang Wan",
                "Haofeng Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14172v1",
                "http://arxiv.org/pdf/2310.14172v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14170v1",
            "title": "Learning Invariant Molecular Representation in Latent Discrete Space",
            "updated": "2023-10-22T04:06:44Z",
            "published": "2023-10-22T04:06:44Z",
            "summary": "Molecular representation learning lays the foundation for drug discovery.\nHowever, existing methods suffer from poor out-of-distribution (OOD)\ngeneralization, particularly when data for training and testing originate from\ndifferent environments. To address this issue, we propose a new framework for\nlearning molecular representations that exhibit invariance and robustness\nagainst distribution shifts. Specifically, we propose a strategy called\n``first-encoding-then-separation'' to identify invariant molecule features in\nthe latent space, which deviates from conventional practices. Prior to the\nseparation step, we introduce a residual vector quantization module that\nmitigates the over-fitting to training data distributions while preserving the\nexpressivity of encoders. Furthermore, we design a task-agnostic\nself-supervised learning objective to encourage precise invariance\nidentification, which enables our method widely applicable to a variety of\ntasks, such as regression and multi-label classification. Extensive experiments\non 18 real-world molecular datasets demonstrate that our model achieves\nstronger generalization against state-of-the-art baselines in the presence of\nvarious distribution shifts. Our code is available at\nhttps://github.com/HICAI-ZJU/iMoLD.",
            "author": [
                "Xiang Zhuang",
                "Qiang Zhang",
                "Keyan Ding",
                "Yatao Bian",
                "Xiao Wang",
                "Jingsong Lv",
                "Hongyang Chen",
                "Huajun Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14170v1",
                "http://arxiv.org/pdf/2310.14170v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14168v2",
            "title": "Randomized Forward Mode of Automatic Differentiation for Optimization\n  Algorithms",
            "updated": "2023-10-24T04:20:24Z",
            "published": "2023-10-22T04:02:39Z",
            "summary": "Backpropagation within neural networks leverages a fundamental element of\nautomatic differentiation, which is referred to as the reverse mode\ndifferentiation, or vector Jacobian Product (VJP) or, in the context of\ndifferential geometry, known as the pull-back process. The computation of\ngradient is important as update of neural network parameters is performed using\ngradient descent method. In this study, we present a genric randomized method,\nwhich updates the parameters of neural networks by using directional\nderivatives of loss functions computed efficiently by using forward mode AD or\nJacobian vector Product (JVP). These JVP are computed along the random\ndirections sampled from different probability distributions e.g., Bernoulli,\nNormal, Wigner, Laplace and Uniform distributions. The computation of gradient\nis performed during the forward pass of the neural network. We also present a\nrigorous analysis of the presented methods providing the rate of convergence\nalong with the computational experiments deployed in scientific Machine\nlearning in particular physics-informed neural networks and Deep Operator\nNetworks.",
            "author": [
                "Khemraj Shukla",
                "Yeonjong Shin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14168v2",
                "http://arxiv.org/pdf/2310.14168v2"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.AI",
                "cs.LG",
                "65K05, 65B99, 26A33"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14166v1",
            "title": "Ensemble Learning for Graph Neural Networks",
            "updated": "2023-10-22T03:55:13Z",
            "published": "2023-10-22T03:55:13Z",
            "summary": "Graph Neural Networks (GNNs) have shown success in various fields for\nlearning from graph-structured data. This paper investigates the application of\nensemble learning techniques to improve the performance and robustness of Graph\nNeural Networks (GNNs). By training multiple GNN models with diverse\ninitializations or architectures, we create an ensemble model named ELGNN that\ncaptures various aspects of the data and uses the Tree-Structured Parzen\nEstimator algorithm to determine the ensemble weights. Combining the\npredictions of these models enhances overall accuracy, reduces bias and\nvariance, and mitigates the impact of noisy data. Our findings demonstrate the\nefficacy of ensemble learning in enhancing GNN capabilities for analyzing\ncomplex graph-structured data. The code is public at\nhttps://github.com/wongzhenhao/ELGNN.",
            "author": [
                "Zhen Hao Wong",
                "Ling Yue",
                "Quanming Yao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14166v1",
                "http://arxiv.org/pdf/2310.14166v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14165v1",
            "title": "Graph Convolutional Network with Connectivity Uncertainty for EEG-based\n  Emotion Recognition",
            "updated": "2023-10-22T03:47:11Z",
            "published": "2023-10-22T03:47:11Z",
            "summary": "Automatic emotion recognition based on multichannel Electroencephalography\n(EEG) holds great potential in advancing human-computer interaction. However,\nseveral significant challenges persist in existing research on algorithmic\nemotion recognition. These challenges include the need for a robust model to\neffectively learn discriminative node attributes over long paths, the\nexploration of ambiguous topological information in EEG channels and effective\nfrequency bands, and the mapping between intrinsic data qualities and provided\nlabels. To address these challenges, this study introduces the\ndistribution-based uncertainty method to represent spatial dependencies and\ntemporal-spectral relativeness in EEG signals based on Graph Convolutional\nNetwork (GCN) architecture that adaptively assigns weights to functional\naggregate node features, enabling effective long-path capturing while\nmitigating over-smoothing phenomena. Moreover, the graph mixup technique is\nemployed to enhance latent connected edges and mitigate noisy label issues.\nFurthermore, we integrate the uncertainty learning method with deep GCN weights\nin a one-way learning fashion, termed Connectivity Uncertainty GCN (CU-GCN). We\nevaluate our approach on two widely used datasets, namely SEED and SEEDIV, for\nemotion recognition tasks. The experimental results demonstrate the superiority\nof our methodology over previous methods, yielding positive and significant\nimprovements. Ablation studies confirm the substantial contributions of each\ncomponent to the overall performance.",
            "author": [
                "Hongxiang Gao",
                "Xiangyao Wang",
                "Zhenghua Chen",
                "Min Wu",
                "Zhipeng Cai",
                "Lulu Zhao",
                "Jianqing Li",
                "Chengyu Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14165v1",
                "http://arxiv.org/pdf/2310.14165v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14164v1",
            "title": "$\u03b1$-Fair Contextual Bandits",
            "updated": "2023-10-22T03:42:59Z",
            "published": "2023-10-22T03:42:59Z",
            "summary": "Contextual bandit algorithms are at the core of many applications, including\nrecommender systems, clinical trials, and optimal portfolio selection. One of\nthe most popular problems studied in the contextual bandit literature is to\nmaximize the sum of the rewards in each round by ensuring a sublinear regret\nagainst the best-fixed context-dependent policy. However, in many applications,\nthe cumulative reward is not the right objective - the bandit algorithm must be\nfair in order to avoid the echo-chamber effect and comply with the regulatory\nrequirements. In this paper, we consider the $\\alpha$-Fair Contextual Bandits\nproblem, where the objective is to maximize the global $\\alpha$-fair utility\nfunction - a non-decreasing concave function of the cumulative rewards in the\nadversarial setting. The problem is challenging due to the non-separability of\nthe objective across rounds. We design an efficient algorithm that guarantees\nan approximately sublinear regret in the full-information and bandit feedback\nsettings.",
            "author": [
                "Siddhant Chaudhary",
                "Abhishek Sinha"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14164v1",
                "http://arxiv.org/pdf/2310.14164v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14161v1",
            "title": "Promoting Generalization for Exact Solvers via Adversarial Instance\n  Augmentation",
            "updated": "2023-10-22T03:15:36Z",
            "published": "2023-10-22T03:15:36Z",
            "summary": "Machine learning has been successfully applied to improve the efficiency of\nMixed-Integer Linear Programming (MILP) solvers. However, the learning-based\nsolvers often suffer from severe performance degradation on unseen MILP\ninstances -- especially on large-scale instances from a perturbed environment\n-- due to the limited diversity of training distributions. To tackle this\nproblem, we propose a novel approach, which is called Adversarial Instance\nAugmentation and does not require to know the problem type for new instance\ngeneration, to promote data diversity for learning-based branching modules in\nthe branch-and-bound (B&B) Solvers (AdaSolver). We use the bipartite graph\nrepresentations for MILP instances and obtain various perturbed instances to\nregularize the solver by augmenting the graph structures with a learned\naugmentation policy. The major technical contribution of AdaSolver is that we\nformulate the non-differentiable instance augmentation as a contextual bandit\nproblem and adversarially train the learning-based solver and augmentation\npolicy, enabling efficient gradient-based training of the augmentation policy.\nTo the best of our knowledge, AdaSolver is the first general and effective\nframework for understanding and improving the generalization of both\nimitation-learning-based (IL-based) and reinforcement-learning-based (RL-based)\nB&B solvers. Extensive experiments demonstrate that by producing various\naugmented instances, AdaSolver leads to a remarkable efficiency improvement\nacross various distributions.",
            "author": [
                "Haoyang Liu",
                "Yufei Kuang",
                "Jie Wang",
                "Xijun Li",
                "Yongdong Zhang",
                "Feng Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14161v1",
                "http://arxiv.org/pdf/2310.14161v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14158v1",
            "title": "Visual-Attribute Prompt Learning for Progressive Mild Cognitive\n  Impairment Prediction",
            "updated": "2023-10-22T02:49:53Z",
            "published": "2023-10-22T02:49:53Z",
            "summary": "Deep learning (DL) has been used in the automatic diagnosis of Mild Cognitive\nImpairment (MCI) and Alzheimer's Disease (AD) with brain imaging data. However,\nprevious methods have not fully exploited the relation between brain image and\nclinical information that is widely adopted by experts in practice. To exploit\nthe heterogeneous features from imaging and tabular data simultaneously, we\npropose the Visual-Attribute Prompt Learning-based Transformer (VAP-Former), a\ntransformer-based network that efficiently extracts and fuses the multi-modal\nfeatures with prompt fine-tuning. Furthermore, we propose a Prompt fine-Tuning\n(PT) scheme to transfer the knowledge from AD prediction task for progressive\nMCI (pMCI) diagnosis. In details, we first pre-train the VAP-Former without\nprompts on the AD diagnosis task and then fine-tune the model on the pMCI\ndetection task with PT, which only needs to optimize a small amount of\nparameters while keeping the backbone frozen. Next, we propose a novel global\nprompt token for the visual prompts to provide global guidance to the\nmulti-modal representations. Extensive experiments not only show the\nsuperiority of our method compared with the state-of-the-art methods in pMCI\nprediction but also demonstrate that the global prompt can make the prompt\nlearning process more effective and stable. Interestingly, the proposed prompt\nlearning model even outperforms the fully fine-tuning baseline on transferring\nthe knowledge from AD to pMCI.",
            "author": [
                "Luoyao Kang",
                "Haifan Gong",
                "Xiang Wan",
                "Haofeng Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14158v1",
                "http://arxiv.org/pdf/2310.14158v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14157v1",
            "title": "Genetic Algorithms with Neural Cost Predictor for Solving Hierarchical\n  Vehicle Routing Problems",
            "updated": "2023-10-22T02:46:37Z",
            "published": "2023-10-22T02:46:37Z",
            "summary": "When vehicle routing decisions are intertwined with higher-level decisions,\nthe resulting optimization problems pose significant challenges for\ncomputation. Examples are the multi-depot vehicle routing problem (MDVRP),\nwhere customers are assigned to depots before delivery, and the capacitated\nlocation routing problem (CLRP), where the locations of depots should be\ndetermined first. A simple and straightforward approach for such hierarchical\nproblems would be to separate the higher-level decisions from the complicated\nvehicle routing decisions. For each higher-level decision candidate, we may\nevaluate the underlying vehicle routing problems to assess the candidate. As\nthis approach requires solving vehicle routing problems multiple times, it has\nbeen regarded as impractical in most cases. We propose a novel\ndeep-learning-based approach called Genetic Algorithm with Neural Cost\nPredictor (GANCP) to tackle the challenge and simplify algorithm developments.\nFor each higher-level decision candidate, we predict the objective function\nvalues of the underlying vehicle routing problems using a pre-trained graph\nneural network without actually solving the routing problems. In particular,\nour proposed neural network learns the objective values of the HGS-CVRP\nopen-source package that solves capacitated vehicle routing problems. Our\nnumerical experiments show that this simplified approach is effective and\nefficient in generating high-quality solutions for both MDVRP and CLRP and has\nthe potential to expedite algorithm developments for complicated hierarchical\nproblems. We provide computational results evaluated in the standard benchmark\ninstances used in the literature.",
            "author": [
                "Abhay Sobhanan",
                "Junyoung Park",
                "Jinkyoo Park",
                "Changhyun Kwon"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14157v1",
                "http://arxiv.org/pdf/2310.14157v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14155v1",
            "title": "Photoplethysmography based atrial fibrillation detection: an updated\n  review from July 2019",
            "updated": "2023-10-22T02:39:50Z",
            "published": "2023-10-22T02:39:50Z",
            "summary": "Atrial fibrillation (AF) is a prevalent cardiac arrhythmia associated with\nsignificant health ramifications, including an elevated susceptibility to\nischemic stroke, heart disease, and heightened mortality. Photoplethysmography\n(PPG) has emerged as a promising technology for continuous AF monitoring for\nits cost-effectiveness and widespread integration into wearable devices. Our\nteam previously conducted an exhaustive review on PPG-based AF detection before\nJune 2019. However, since then, more advanced technologies have emerged in this\nfield. This paper offers a comprehensive review of the latest advancements in\nPPG-based AF detection, utilizing digital health and artificial intelligence\n(AI) solutions, within the timeframe spanning from July 2019 to December 2022.\nThrough extensive exploration of scientific databases, we have identified 59\npertinent studies. Our comprehensive review encompasses an in-depth assessment\nof the statistical methodologies, traditional machine learning techniques, and\ndeep learning approaches employed in these studies. In addition, we address the\nchallenges encountered in the domain of PPG-based AF detection. Furthermore, we\nmaintain a dedicated website to curate the latest research in this area, with\nregular updates on a regular basis.",
            "author": [
                "Cheng Ding",
                "Ran Xiao",
                "Weijia Wang",
                "Elizabeth Holdsworth",
                "Xiao Hu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14155v1",
                "http://arxiv.org/pdf/2310.14155v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18340v1",
            "title": "When Urban Region Profiling Meets Large Language Models",
            "updated": "2023-10-22T02:32:53Z",
            "published": "2023-10-22T02:32:53Z",
            "summary": "Urban region profiling from web-sourced data is of utmost importance for\nurban planning and sustainable development. We are witnessing a rising trend of\nLLMs for various fields, especially dealing with multi-modal data research such\nas vision-language learning, where the text modality serves as a supplement\ninformation for the image. Since textual modality has never been introduced\ninto modality combinations in urban region profiling, we aim to answer two\nfundamental questions in this paper: i) Can textual modality enhance urban\nregion profiling? ii) and if so, in what ways and with regard to which aspects?\nTo answer the questions, we leverage the power of Large Language Models (LLMs)\nand introduce the first-ever LLM-enhanced framework that integrates the\nknowledge of textual modality into urban imagery profiling, named LLM-enhanced\nUrban Region Profiling with Contrastive Language-Image Pretraining (UrbanCLIP).\nSpecifically, it first generates a detailed textual description for each\nsatellite image by an open-source Image-to-Text LLM. Then, the model is trained\non the image-text pairs, seamlessly unifying natural language supervision for\nurban visual representation learning, jointly with contrastive loss and\nlanguage modeling loss. Results on predicting three urban indicators in four\nmajor Chinese metropolises demonstrate its superior performance, with an\naverage improvement of 6.1% on R^2 compared to the state-of-the-art methods.\nOur code and the image-language dataset will be released upon paper\nnotification.",
            "author": [
                "Yibo Yan",
                "Haomin Wen",
                "Siru Zhong",
                "Wei Chen",
                "Haodong Chen",
                "Qingsong Wen",
                "Roger Zimmermann",
                "Yuxuan Liang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18340v1",
                "http://arxiv.org/pdf/2310.18340v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14154v1",
            "title": "Affine-Consistent Transformer for Multi-Class Cell Nuclei Detection",
            "updated": "2023-10-22T02:27:02Z",
            "published": "2023-10-22T02:27:02Z",
            "summary": "Multi-class cell nuclei detection is a fundamental prerequisite in the\ndiagnosis of histopathology. It is critical to efficiently locate and identify\ncells with diverse morphology and distributions in digital pathological images.\nMost existing methods take complex intermediate representations as learning\ntargets and rely on inflexible post-refinements while paying less attention to\nvarious cell density and fields of view. In this paper, we propose a novel\nAffine-Consistent Transformer (AC-Former), which directly yields a sequence of\nnucleus positions and is trained collaboratively through two sub-networks, a\nglobal and a local network. The local branch learns to infer distorted input\nimages of smaller scales while the global network outputs the large-scale\npredictions as extra supervision signals. We further introduce an Adaptive\nAffine Transformer (AAT) module, which can automatically learn the key spatial\ntransformations to warp original images for local network training. The AAT\nmodule works by learning to capture the transformed image regions that are more\nvaluable for training the model. Experimental results demonstrate that the\nproposed method significantly outperforms existing state-of-the-art algorithms\non various benchmarks.",
            "author": [
                "Junjia Huang",
                "Haofeng Li",
                "Xiang Wan",
                "Guanbin Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14154v1",
                "http://arxiv.org/pdf/2310.14154v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14152v1",
            "title": "Orthogonal Subspace Learning for Language Model Continual Learning",
            "updated": "2023-10-22T02:23:44Z",
            "published": "2023-10-22T02:23:44Z",
            "summary": "Benefiting from massive corpora and advanced hardware, large language models\n(LLMs) exhibit remarkable capabilities in language understanding and\ngeneration. However, their performance degrades in scenarios where multiple\ntasks are encountered sequentially, also known as catastrophic forgetting. In\nthis paper, we propose orthogonal low-rank adaptation (O-LoRA), a simple and\nefficient approach for continual learning in language models, effectively\nmitigating catastrophic forgetting while learning new tasks. Specifically,\nO-LoRA learns tasks in different (low-rank) vector subspaces that are kept\northogonal to each other in order to minimize interference. Our method induces\nonly marginal additional parameter costs and requires no user data storage for\nreplay. Experimental results on continual learning benchmarks show that our\nmethod outperforms state-of-the-art methods. Furthermore, compared to previous\napproaches, our method excels in preserving the generalization ability of LLMs\non unseen tasks.",
            "author": [
                "Xiao Wang",
                "Tianze Chen",
                "Qiming Ge",
                "Han Xia",
                "Rong Bao",
                "Rui Zheng",
                "Qi Zhang",
                "Tao Gui",
                "Xuanjing Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14152v1",
                "http://arxiv.org/pdf/2310.14152v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08544v1",
            "title": "JOSA: Joint surface-based registration and atlas construction of brain\n  geometry and function",
            "updated": "2023-10-22T02:16:48Z",
            "published": "2023-10-22T02:16:48Z",
            "summary": "Surface-based cortical registration is an important topic in medical image\nanalysis and facilitates many downstream applications. Current approaches for\ncortical registration are mainly driven by geometric features, such as sulcal\ndepth and curvature, and often assume that registration of folding patterns\nleads to alignment of brain function. However, functional variability of\nanatomically corresponding areas across subjects has been widely reported,\nparticularly in higher-order cognitive areas. In this work, we present JOSA, a\nnovel cortical registration framework that jointly models the mismatch between\ngeometry and function while simultaneously learning an unbiased\npopulation-specific atlas. Using a semi-supervised training strategy, JOSA\nachieves superior registration performance in both geometry and function to the\nstate-of-the-art methods but without requiring functional data at inference.\nThis learning framework can be extended to any auxiliary data to guide\nspherical registration that is available during training but is difficult or\nimpossible to obtain during inference, such as parcellations, architectonic\nidentity, transcriptomic information, and molecular profiles. By recognizing\nthe mismatch between geometry and function, JOSA provides new insights into the\nfuture development of registration methods using joint analysis of the brain\nstructure and function.",
            "author": [
                "Jian Li",
                "Greta Tuckute",
                "Evelina Fedorenko",
                "Brian L. Edlow",
                "Adrian V. Dalca",
                "Bruce Fischl"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08544v1",
                "http://arxiv.org/pdf/2311.08544v1"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC",
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14146v1",
            "title": "Cocaine Use Prediction with Tensor-based Machine Learning on Multimodal\n  MRI Connectome Data",
            "updated": "2023-10-22T01:39:37Z",
            "published": "2023-10-22T01:39:37Z",
            "summary": "This paper considers the use of machine learning algorithms for predicting\ncocaine use based on magnetic resonance imaging (MRI) connectomic data. The\nstudy utilized functional MRI (fMRI) and diffusion MRI (dMRI) data collected\nfrom 275 individuals, which was then parcellated into 246 regions of interest\n(ROIs) using the Brainnetome atlas. After data preprocessing, the datasets were\ntransformed into tensor form. We developed a tensor-based unsupervised machine\nlearning algorithm to reduce the size of the data tensor from $275$\n(individuals) $\\times 2$ (fMRI and dMRI) $\\times 246$ (ROIs) $\\times 246$\n(ROIs) to $275$ (individuals) $\\times 2$ (fMRI and dMRI) $\\times 6$ (clusters)\n$\\times 6$ (clusters). This was achieved by applying the high-order Lloyd\nalgorithm to group the ROI data into 6 clusters. Features were extracted from\nthe reduced tensor and combined with demographic features (age, gender, race,\nand HIV status). The resulting dataset was used to train a Catboost model using\nsubsampling and nested cross-validation techniques, which achieved a prediction\naccuracy of 0.857 for identifying cocaine users. The model was also compared\nwith other models, and the feature importance of the model was presented.\n  Overall, this study highlights the potential for using tensor-based machine\nlearning algorithms to predict cocaine use based on MRI connectomic data and\npresents a promising approach for identifying individuals at risk of substance\nabuse.",
            "author": [
                "Anru R. Zhang",
                "Ryan P. Bell",
                "Chen An",
                "Runshi Tang",
                "Shana A. Hall",
                "Cliburn Chan",
                "Kareem Al-Khalil",
                "Christina S. Meade"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14146v1",
                "http://arxiv.org/pdf/2310.14146v1"
            ],
            "primary_category": "stat.AP",
            "category": [
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14143v1",
            "title": "MMTF-DES: A Fusion of Multimodal Transformer Models for Desire, Emotion,\n  and Sentiment Analysis of Social Media Data",
            "updated": "2023-10-22T00:43:06Z",
            "published": "2023-10-22T00:43:06Z",
            "summary": "Desire is a set of human aspirations and wishes that comprise verbal and\ncognitive aspects that drive human feelings and behaviors, distinguishing\nhumans from other animals. Understanding human desire has the potential to be\none of the most fascinating and challenging research domains. It is tightly\ncoupled with sentiment analysis and emotion recognition tasks. It is beneficial\nfor increasing human-computer interactions, recognizing human emotional\nintelligence, understanding interpersonal relationships, and making decisions.\nHowever, understanding human desire is challenging and under-explored because\nways of eliciting desire might be different among humans. The task gets more\ndifficult due to the diverse cultures, countries, and languages. Prior studies\noverlooked the use of image-text pairwise feature representation, which is\ncrucial for the task of human desire understanding. In this research, we have\nproposed a unified multimodal transformer-based framework with image-text pair\nsettings to identify human desire, sentiment, and emotion. The core of our\nproposed method lies in the encoder module, which is built using two\nstate-of-the-art multimodal transformer models. These models allow us to\nextract diverse features. To effectively extract visual and contextualized\nembedding features from social media image and text pairs, we conducted joint\nfine-tuning of two pre-trained multimodal transformer models:\nVision-and-Language Transformer (ViLT) and Vision-and-Augmented-Language\nTransformer (VAuLT). Subsequently, we use an early fusion strategy on these\nembedding features to obtain combined diverse feature representations of the\nimage-text pair. This consolidation incorporates diverse information about this\ntask, enabling us to robustly perceive the context and image pair from multiple\nperspectives.",
            "author": [
                "Abdul Aziz",
                "Nihad Karim Chowdhury",
                "Muhammad Ashad Kabir",
                "Abu Nowshed Chy",
                "Md. Jawad Siddique"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14143v1",
                "http://arxiv.org/pdf/2310.14143v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14139v1",
            "title": "Are LSTMs Good Few-Shot Learners?",
            "updated": "2023-10-22T00:16:30Z",
            "published": "2023-10-22T00:16:30Z",
            "summary": "Deep learning requires large amounts of data to learn new tasks well,\nlimiting its applicability to domains where such data is available.\nMeta-learning overcomes this limitation by learning how to learn. In 2001,\nHochreiter et al. showed that an LSTM trained with backpropagation across\ndifferent tasks is capable of meta-learning. Despite promising results of this\napproach on small problems, and more recently, also on reinforcement learning\nproblems, the approach has received little attention in the supervised few-shot\nlearning setting. We revisit this approach and test it on modern few-shot\nlearning benchmarks. We find that LSTM, surprisingly, outperform the popular\nmeta-learning technique MAML on a simple few-shot sine wave regression\nbenchmark, but that LSTM, expectedly, fall short on more complex few-shot image\nclassification benchmarks. We identify two potential causes and propose a new\nmethod called Outer Product LSTM (OP-LSTM) that resolves these issues and\ndisplays substantial performance gains over the plain LSTM. Compared to popular\nmeta-learning baselines, OP-LSTM yields competitive performance on\nwithin-domain few-shot image classification, and performs better in\ncross-domain settings by 0.5% to 1.9% in accuracy score. While these results\nalone do not set a new state-of-the-art, the advances of OP-LSTM are orthogonal\nto other advances in the field of meta-learning, yield new insights in how LSTM\nwork in image classification, allowing for a whole range of new research\ndirections. For reproducibility purposes, we publish all our research code\npublicly.",
            "author": [
                "Mike Huisman",
                "Thomas M. Moerland",
                "Aske Plaat",
                "Jan N. van Rijn"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14139v1",
                "http://arxiv.org/pdf/2310.14139v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14129v1",
            "title": "Optimal Batched Best Arm Identification",
            "updated": "2023-10-21T22:55:50Z",
            "published": "2023-10-21T22:55:50Z",
            "summary": "We study the batched best arm identification (BBAI) problem, where the\nlearner's goal is to identify the best arm while switching the policy as less\nas possible. In particular, we aim to find the best arm with probability\n$1-\\delta$ for some small constant $\\delta>0$ while minimizing both the sample\ncomplexity (total number of arm pulls) and the batch complexity (total number\nof batches). We propose the three-batch best arm identification (Tri-BBAI)\nalgorithm, which is the first batched algorithm that achieves the optimal\nsample complexity in the asymptotic setting (i.e., $\\delta\\rightarrow 0$) and\nruns only in at most $3$ batches. Based on Tri-BBAI, we further propose the\nalmost optimal batched best arm identification (Opt-BBAI) algorithm, which is\nthe first algorithm that achieves the near-optimal sample and batch complexity\nin the non-asymptotic setting (i.e., $\\delta>0$ is arbitrarily fixed), while\nenjoying the same batch and sample complexity as Tri-BBAI when $\\delta$ tends\nto zero. Moreover, in the non-asymptotic setting, the complexity of previous\nbatch algorithms is usually conditioned on the event that the best arm is\nreturned (with a probability of at least $1-\\delta$), which is potentially\nunbounded in cases where a sub-optimal arm is returned. In contrast, the\ncomplexity of Opt-BBAI does not rely on such an event. This is achieved through\na novel procedure that we design for checking whether the best arm is\neliminated, which is of independent interest.",
            "author": [
                "Tianyuan Jin",
                "Yu Yang",
                "Jing Tang",
                "Xiaokui Xiao",
                "Pan Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14129v1",
                "http://arxiv.org/pdf/2310.14129v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14126v1",
            "title": "Ask To The Point: Open-Domain Entity-Centric Question Generation",
            "updated": "2023-10-21T22:19:19Z",
            "published": "2023-10-21T22:19:19Z",
            "summary": "We introduce a new task called *entity-centric question generation* (ECQG),\nmotivated by real-world applications such as topic-specific learning, assisted\nreading, and fact-checking. The task aims to generate questions from an entity\nperspective. To solve ECQG, we propose a coherent PLM-based framework GenCONE\nwith two novel modules: content focusing and question verification. The content\nfocusing module first identifies a focus as \"what to ask\" to form draft\nquestions, and the question verification module refines the questions\nafterwards by verifying the answerability. We also construct a large-scale\nopen-domain dataset from SQuAD to support this task. Our extensive experiments\ndemonstrate that GenCONE significantly and consistently outperforms various\nbaselines, and two modules are effective and complementary in generating\nhigh-quality questions.",
            "author": [
                "Yuxiang Liu",
                "Jie Huang",
                "Kevin Chen-Chuan Chang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14126v1",
                "http://arxiv.org/pdf/2310.14126v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14120v1",
            "title": "Sentiment Analysis Across Multiple African Languages: A Current\n  Benchmark",
            "updated": "2023-10-21T21:38:06Z",
            "published": "2023-10-21T21:38:06Z",
            "summary": "Sentiment analysis is a fundamental and valuable task in NLP. However, due to\nlimitations in data and technological availability, research into sentiment\nanalysis of African languages has been fragmented and lacking. With the recent\nrelease of the AfriSenti-SemEval Shared Task 12, hosted as a part of The 17th\nInternational Workshop on Semantic Evaluation, an annotated sentiment analysis\nof 14 African languages was made available. We benchmarked and compared current\nstate-of-art transformer models across 12 languages and compared the\nperformance of training one-model-per-language versus\nsingle-model-all-languages. We also evaluated the performance of standard\nmultilingual models and their ability to learn and transfer cross-lingual\nrepresentation from non-African to African languages. Our results show that\ndespite work in low resource modeling, more data still produces better models\non a per-language basis. Models explicitly developed for African languages\noutperform other models on all tasks. Additionally, no one-model-fits-all\nsolution exists for a per-language evaluation of the models evaluated.\nMoreover, for some languages with a smaller sample size, a larger multilingual\nmodel may perform better than a dedicated per-language model for sentiment\nclassification.",
            "author": [
                "Saurav K. Aryal",
                "Howard Prioleau",
                "Surakshya Aryal"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14120v1",
                "http://arxiv.org/pdf/2310.14120v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14108v1",
            "title": "CLIP meets Model Zoo Experts: Pseudo-Supervision for Visual Enhancement",
            "updated": "2023-10-21T20:20:13Z",
            "published": "2023-10-21T20:20:13Z",
            "summary": "Contrastive language image pretraining (CLIP) is a standard method for\ntraining vision-language models. While CLIP is scalable, promptable, and robust\nto distribution shifts on image classification tasks, it lacks object\nlocalization capabilities. This paper studies the following question: Can we\naugment CLIP training with task-specific vision models from model zoos to\nimprove its visual representations? Towards this end, we leverage open-source\ntask-specific vision models to generate pseudo-labels for an uncurated and\nnoisy image-text dataset. Subsequently, we train CLIP models on these\npseudo-labels in addition to the contrastive training on image and text pairs.\nThis simple setup shows substantial improvements of up to 16.3% across\ndifferent vision tasks, including segmentation, detection, depth estimation,\nand surface normal estimation. Importantly, these enhancements are achieved\nwithout compromising CLIP's existing capabilities, including its proficiency in\npromptable zero-shot classification.",
            "author": [
                "Mohammadreza Salehi",
                "Mehrdad Farajtabar",
                "Maxwell Horton",
                "Fartash Faghri",
                "Hadi Pouransari",
                "Raviteja Vemulapalli",
                "Oncel Tuzel",
                "Ali Farhadi",
                "Mohammad Rastegari",
                "Sachin Mehta"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14108v1",
                "http://arxiv.org/pdf/2310.14108v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14107v1",
            "title": "On the Transferability of Visually Grounded PCFGs",
            "updated": "2023-10-21T20:19:51Z",
            "published": "2023-10-21T20:19:51Z",
            "summary": "There has been a significant surge of interest in visually grounded grammar\ninduction in recent times. While a variety of models have been developed for\nthe task and have demonstrated impressive performance, they have not been\nevaluated on text domains that are different from the training domain, so it is\nunclear if the improvements brought by visual groundings are transferable. Our\nstudy aims to fill this gap and assess the degree of transferability. We start\nby extending VC-PCFG (short for Visually-grounded Compound\nPCFG~\\citep{zhao-titov-2020-visually}) in such a way that it can transfer\nacross text domains. We consider a zero-shot transfer learning setting where a\nmodel is trained on the source domain and is directly applied to target\ndomains, without any further training. Our experimental results suggest that:\nthe benefits from using visual groundings transfer to text in a domain similar\nto the training domain but fail to transfer to remote domains. Further, we\nconduct data and result analysis; we find that the lexicon overlap between the\nsource domain and the target domain is the most important factor in the\ntransferability of VC-PCFG.",
            "author": [
                "Yanpeng Zhao",
                "Ivan Titov"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14107v1",
                "http://arxiv.org/pdf/2310.14107v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14105v1",
            "title": "Zero-shot Learning of Individualized Task Contrast Prediction from\n  Resting-state Functional Connectomes",
            "updated": "2023-10-21T20:12:22Z",
            "published": "2023-10-21T20:12:22Z",
            "summary": "Given sufficient pairs of resting-state and task-evoked fMRI scans from\nsubjects, it is possible to train ML models to predict subject-specific\ntask-evoked activity using resting-state functional MRI (rsfMRI) scans.\nHowever, while rsfMRI scans are relatively easy to collect, obtaining\nsufficient task fMRI scans is much harder as it involves more complex\nexperimental designs and procedures. Thus, the reliance on scarce paired data\nlimits the application of current techniques to only tasks seen during\ntraining. We show that this reliance can be reduced by leveraging group-average\ncontrasts, enabling zero-shot predictions for novel tasks. Our approach, named\nOPIC (short for Omni-Task Prediction of Individual Contrasts), takes as input a\nsubject's rsfMRI-derived connectome and a group-average contrast, to produce a\nprediction of the subject-specific contrast. Similar to zero-shot learning in\nlarge language models using special inputs to obtain answers for novel natural\nlanguage processing tasks, inputting group-average contrasts guides the OPIC\nmodel to generalize to novel tasks unseen in training. Experimental results\nshow that OPIC's predictions for novel tasks are not only better than simple\ngroup-averages, but are also competitive with a state-of-the-art model's\nin-domain predictions that was trained using in-domain tasks' data.",
            "author": [
                "Minh Nguyen",
                "Gia H. Ngo",
                "Mert R. Sabuncu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14105v1",
                "http://arxiv.org/pdf/2310.14105v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14103v1",
            "title": "Revisiting Instruction Fine-tuned Model Evaluation to Guide Industrial\n  Applications",
            "updated": "2023-10-21T20:04:55Z",
            "published": "2023-10-21T20:04:55Z",
            "summary": "Instruction Fine-Tuning (IFT) is a powerful paradigm that strengthens the\nzero-shot capabilities of Large Language Models (LLMs), but in doing so induces\nnew evaluation metric requirements. We show LLM-based metrics to be well\nadapted to these requirements, and leverage them to conduct an investigation of\ntask-specialization strategies, quantifying the trade-offs that emerge in\npractical industrial settings. Our findings offer practitioners actionable\ninsights for real-world IFT model deployment.",
            "author": [
                "Manuel Faysse",
                "Gautier Viaud",
                "C\u00e9line Hudelot",
                "Pierre Colombo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14103v1",
                "http://arxiv.org/pdf/2310.14103v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14098v1",
            "title": "Stabilizing reinforcement learning control: A modular framework for\n  optimizing over all stable behavior",
            "updated": "2023-10-21T19:32:11Z",
            "published": "2023-10-21T19:32:11Z",
            "summary": "We propose a framework for the design of feedback controllers that combines\nthe optimization-driven and model-free advantages of deep reinforcement\nlearning with the stability guarantees provided by using the Youla-Kucera\nparameterization to define the search domain. Recent advances in behavioral\nsystems allow us to construct a data-driven internal model; this enables an\nalternative realization of the Youla-Kucera parameterization based entirely on\ninput-output exploration data. Perhaps of independent interest, we formulate\nand analyze the stability of such data-driven models in the presence of noise.\nThe Youla-Kucera approach requires a stable \"parameter\" for controller design.\nFor the training of reinforcement learning agents, the set of all stable linear\noperators is given explicitly through a matrix factorization approach.\nMoreover, a nonlinear extension is given using a neural network to express a\nparameterized set of stable operators, which enables seamless integration with\nstandard deep learning libraries. Finally, we show how these ideas can also be\napplied to tune fixed-structure controllers.",
            "author": [
                "Nathan P. Lawrence",
                "Philip D. Loewen",
                "Shuyuan Wang",
                "Michael G. Forbes",
                "R. Bhushan Gopaluni"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14098v1",
                "http://arxiv.org/pdf/2310.14098v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.SY",
                "eess.SY",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14094v1",
            "title": "DispersioNET: Joint Inversion of Rayleigh-Wave Multimode Phase Velocity\n  Dispersion Curves using Convolutional Neural Networks",
            "updated": "2023-10-21T19:22:32Z",
            "published": "2023-10-21T19:22:32Z",
            "summary": "Rayleigh wave dispersion curves have been widely used in near-surface\nstudies, and are primarily inverted for the shear wave (S-wave) velocity\nprofiles. However, the inverse problem is ill-posed, non-unique and nonlinear.\nHere, we introduce DispersioNET, a deep learning model based on convolution\nneural networks (CNN) to perform the joint inversion of Rayleigh wave\nfundamental and higher order mode phase velocity dispersion curves.\nDispersioNET is trained and tested on both noise-free and noisy dispersion\ncurve datasets and predicts S-wave velocity profiles that match closely with\nthe true velocities. The architecture is agnostic to variations in S-wave\nvelocity profiles such as increasing velocity with depth and intermediate\nlow-velocity layers, while also ensuring that the output remains independent of\nthe number of layers.",
            "author": [
                "Rohan Sharma",
                "Divakar Vashisth",
                "Bharath Shekar"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14094v1",
                "http://arxiv.org/pdf/2310.14094v1"
            ],
            "primary_category": "physics.geo-ph",
            "category": [
                "physics.geo-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14092v1",
            "title": "Learning Reward for Physical Skills using Large Language Model",
            "updated": "2023-10-21T19:10:06Z",
            "published": "2023-10-21T19:10:06Z",
            "summary": "Learning reward functions for physical skills are challenging due to the vast\nspectrum of skills, the high-dimensionality of state and action space, and\nnuanced sensory feedback. The complexity of these tasks makes acquiring expert\ndemonstration data both costly and time-consuming. Large Language Models (LLMs)\ncontain valuable task-related knowledge that can aid in learning these reward\nfunctions. However, the direct application of LLMs for proposing reward\nfunctions has its limitations such as numerical instability and inability to\nincorporate the environment feedback. We aim to extract task knowledge from\nLLMs using environment feedback to create efficient reward functions for\nphysical skills. Our approach consists of two components. We first use the LLM\nto propose features and parameterization of the reward function. Next, we\nupdate the parameters of this proposed reward function through an iterative\nself-alignment process. In particular, this process minimizes the ranking\ninconsistency between the LLM and our learned reward functions based on the new\nobservations. We validated our method by testing it on three simulated physical\nskill learning tasks, demonstrating effective support for our design choices.",
            "author": [
                "Yuwei Zeng",
                "Yiqing Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14092v1",
                "http://arxiv.org/pdf/2310.14092v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14091v1",
            "title": "Deep hole lattices and isogenies of elliptic curves",
            "updated": "2023-10-21T19:09:31Z",
            "published": "2023-10-21T19:09:31Z",
            "summary": "Given a lattice $L$ in the plane, we define the affiliated deep hole lattice\n$H(L)$ to be spanned by a shortest vector of $L$ and a deep hole of $L$\ncontained in the triangle with sides corresponding to the shortest basis\nvectors. We study the geometric and arithmetic properties of deep hole\nlattices. In particular we investigate conditions on $L$ under which $H(L)$ is\nwell-rounded and prove that $H(L)$ is defined over the same field as $L$. For\nthe period lattice corresponding to an isomorphism class of elliptic curves, we\nproduce a finite sequence of deep hole lattices ending with a well-rounded\nlattice which corresponds to a point on the boundary arc of the fundamental\nstrip under the action of $\\operatorname{SL}_2(\\mathbb{Z})$ on the upper\nhalfplane. In the case of CM elliptic curves, we prove that all elliptic curves\ngenerated by this sequence are isogenous to each other and produce bounds on\nthe degree of isogeny. Finally, we produce a counting estimate for the planar\nlattices with a prescribed deep hole lattice.",
            "author": [
                "Lenny Fukshansky",
                "Pavel Guerzhoy",
                "Tanis Nielsen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14091v1",
                "http://arxiv.org/pdf/2310.14091v1"
            ],
            "primary_category": "math.NT",
            "category": [
                "math.NT",
                "11H06, 11G05, 11G50"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14087v1",
            "title": "A Specialized Semismooth Newton Method for Kernel-Based Optimal\n  Transport",
            "updated": "2023-10-21T18:48:45Z",
            "published": "2023-10-21T18:48:45Z",
            "summary": "Kernel-based optimal transport (OT) estimators offer an alternative,\nfunctional estimation procedure to address OT problems from samples. Recent\nworks suggest that these estimators are more statistically efficient than\nplug-in (linear programming-based) OT estimators when comparing probability\nmeasures in high-dimensions~\\citep{Vacher-2021-Dimension}. Unfortunately, that\nstatistical benefit comes at a very steep computational price: because their\ncomputation relies on the short-step interior-point method (SSIPM), which comes\nwith a large iteration count in practice, these estimators quickly become\nintractable w.r.t. sample size $n$. To scale these estimators to larger $n$, we\npropose a nonsmooth fixed-point model for the kernel-based OT problem, and show\nthat it can be efficiently solved via a specialized semismooth Newton (SSN)\nmethod: We show, exploring the problem's structure, that the per-iteration cost\nof performing one SSN step can be significantly reduced in practice. We prove\nthat our SSN method achieves a global convergence rate of $O(1/\\sqrt{k})$, and\na local quadratic convergence rate under standard regularity conditions. We\nshow substantial speedups over SSIPM on both synthetic and real datasets.",
            "author": [
                "Tianyi Lin",
                "Marco Cuturi",
                "Michael I. Jordan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14087v1",
                "http://arxiv.org/pdf/2310.14087v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14085v3",
            "title": "Adaptive, Doubly Optimal No-Regret Learning in Strongly Monotone and\n  Exp-Concave Games with Gradient Feedback",
            "updated": "2023-11-15T04:15:45Z",
            "published": "2023-10-21T18:38:13Z",
            "summary": "Online gradient descent (OGD) is well known to be doubly optimal under strong\nconvexity or monotonicity assumptions: (1) in the single-agent setting, it\nachieves an optimal regret of $\\Theta(\\log T)$ for strongly convex cost\nfunctions; and (2) in the multi-agent setting of strongly monotone games, with\neach agent employing OGD, we obtain last-iterate convergence of the joint\naction to a unique Nash equilibrium at an optimal rate of\n$\\Theta(\\frac{1}{T})$. While these finite-time guarantees highlight its merits,\nOGD has the drawback that it requires knowing the strong convexity/monotonicity\nparameters. In this paper, we design a fully adaptive OGD algorithm,\n\\textsf{AdaOGD}, that does not require a priori knowledge of these parameters.\nIn the single-agent setting, our algorithm achieves $O(\\log^2(T))$ regret under\nstrong convexity, which is optimal up to a log factor. Further, if each agent\nemploys \\textsf{AdaOGD} in strongly monotone games, the joint action converges\nin a last-iterate sense to a unique Nash equilibrium at a rate of\n$O(\\frac{\\log^3 T}{T})$, again optimal up to log factors. We illustrate our\nalgorithms in a learning version of the classical newsvendor problem, where due\nto lost sales, only (noisy) gradient feedback can be observed. Our results\nimmediately yield the first feasible and near-optimal algorithm for both the\nsingle-retailer and multi-retailer settings. We also extend our results to the\nmore general setting of exp-concave cost functions and games, using the online\nNewton step (ONS) algorithm.",
            "author": [
                "Michael I. Jordan",
                "Tianyi Lin",
                "Zhengyuan Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14085v3",
                "http://arxiv.org/pdf/2310.14085v3"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT",
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14084v1",
            "title": "Graph Neural Networks and Applied Linear Algebra",
            "updated": "2023-10-21T18:37:56Z",
            "published": "2023-10-21T18:37:56Z",
            "summary": "Sparse matrix computations are ubiquitous in scientific computing. With the\nrecent interest in scientific machine learning, it is natural to ask how sparse\nmatrix computations can leverage neural networks (NN). Unfortunately,\nmulti-layer perceptron (MLP) neural networks are typically not natural for\neither graph or sparse matrix computations. The issue lies with the fact that\nMLPs require fixed-sized inputs while scientific applications generally\ngenerate sparse matrices with arbitrary dimensions and a wide range of nonzero\npatterns (or matrix graph vertex interconnections). While convolutional NNs\ncould possibly address matrix graphs where all vertices have the same number of\nnearest neighbors, a more general approach is needed for arbitrary sparse\nmatrices, e.g. arising from discretized partial differential equations on\nunstructured meshes. Graph neural networks (GNNs) are one approach suitable to\nsparse matrices. GNNs define aggregation functions (e.g., summations) that\noperate on variable size input data to produce data of a fixed output size so\nthat MLPs can be applied. The goal of this paper is to provide an introduction\nto GNNs for a numerical linear algebra audience. Concrete examples are provided\nto illustrate how many common linear algebra tasks can be accomplished using\nGNNs. We focus on iterative methods that employ computational kernels such as\nmatrix-vector products, interpolation, relaxation methods, and\nstrength-of-connection measures. Our GNN examples include cases where\nparameters are determined a-priori as well as cases where parameters must be\nlearned. The intent with this article is to help computational scientists\nunderstand how GNNs can be used to adapt machine learning concepts to\ncomputational tasks associated with sparse matrices. It is hoped that this\nunderstanding will stimulate data-driven extensions of classical sparse linear\nalgebra tasks.",
            "author": [
                "Nicholas S. Moore",
                "Eric C. Cyr",
                "Peter Ohm",
                "Christopher M. Siefert",
                "Raymond S. Tuminaro"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14084v1",
                "http://arxiv.org/pdf/2310.14084v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.CE",
                "cs.LG",
                "cs.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14081v1",
            "title": "Unleashing Modified Deep Learning Models in Efficient COVID19 Detection",
            "updated": "2023-10-21T18:24:23Z",
            "published": "2023-10-21T18:24:23Z",
            "summary": "The COVID19 pandemic, a unique and devastating respiratory disease outbreak,\nhas affected global populations as the disease spreads rapidly. Recent Deep\nLearning breakthroughs may improve COVID19 prediction and forecasting as a tool\nof precise and fast detection, however, current methods are still being\nexamined to achieve higher accuracy and precision. This study analyzed the\ncollection contained 8055 CT image samples, 5427 of which were COVID cases and\n2628 non COVID. The 9544 Xray samples included 4044 COVID patients and 5500 non\nCOVID cases. The most accurate models are MobileNet V3 (97.872 percent),\nDenseNet201 (97.567 percent), and GoogleNet Inception V1 (97.643 percent). High\naccuracy indicates that these models can make many accurate predictions, as\nwell as others, are also high for MobileNetV3 and DenseNet201. An extensive\nevaluation using accuracy, precision, and recall allows a comprehensive\ncomparison to improve predictive models by combining loss optimization with\nscalable batch normalization in this study. Our analysis shows that these\ntactics improve model performance and resilience for advancing COVID19\nprediction and detection and shows how Deep Learning can improve disease\nhandling. The methods we suggest would strengthen healthcare systems,\npolicymakers, and researchers to make educated decisions to reduce COVID19 and\nother contagious diseases.\n  CCS CONCEPTS Covid,Deep Learning, Image Processing\n  KEYWORDS Covid, Deep Learning, DenseNet201, MobileNet, ResNet, DenseNet,\nGoogleNet, Image Processing, Disease Detection.",
            "author": [
                "Md Aminul Islam",
                "Shabbir Ahmed Shuvo",
                "Mohammad Abu Tareq Rony",
                "M Raihan",
                "Md Abu Sufian"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14081v1",
                "http://arxiv.org/pdf/2310.14081v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14079v1",
            "title": "To Copy, or not to Copy; That is a Critical Issue of the Output Softmax\n  Layer in Neural Sequential Recommenders",
            "updated": "2023-10-21T18:04:04Z",
            "published": "2023-10-21T18:04:04Z",
            "summary": "Recent studies suggest that the existing neural models have difficulty\nhandling repeated items in sequential recommendation tasks. However, our\nunderstanding of this difficulty is still limited. In this study, we\nsubstantially advance this field by identifying a major source of the problem:\nthe single hidden state embedding and static item embeddings in the output\nsoftmax layer. Specifically, the similarity structure of the global item\nembeddings in the softmax layer sometimes forces the single hidden state\nembedding to be close to new items when copying is a better choice, while\nsometimes forcing the hidden state to be close to the items from the input\ninappropriately. To alleviate the problem, we adapt the recently-proposed\nsoftmax alternatives such as softmax-CPR to sequential recommendation tasks and\ndemonstrate that the new softmax architectures unleash the capability of the\nneural encoder on learning when to copy and when to exclude the items from the\ninput sequence. By only making some simple modifications on the output softmax\nlayer for SASRec and GRU4Rec, softmax-CPR achieves consistent improvement in 12\ndatasets. With almost the same model size, our best method not only improves\nthe average NDCG@10 of GRU4Rec in 5 datasets with duplicated items by 10%\n(4%-17% individually) but also improves 7 datasets without duplicated items by\n24% (8%-39%)!",
            "author": [
                "Haw-Shiuan Chang",
                "Nikhil Agarwal",
                "Andrew McCallum"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14079v1",
                "http://arxiv.org/pdf/2310.14079v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14069v1",
            "title": "Convolutional Bidirectional Variational Autoencoder for Image Domain\n  Translation of Dotted Arabic Expiration",
            "updated": "2023-10-21T17:20:20Z",
            "published": "2023-10-21T17:20:20Z",
            "summary": "THIS paper proposes an approach of Ladder Bottom-up Convolutional\nBidirectional Variational Autoencoder (LCBVAE) architecture for the encoder and\ndecoder, which is trained on the image translation of the dotted Arabic\nexpiration dates by reconstructing the Arabic dotted expiration dates into\nfilled-in expiration dates. We employed a customized and adapted version of\nConvolutional Recurrent Neural Network CRNN model to meet our specific\nrequirements and enhance its performance in our context, and then trained the\ncustom CRNN model with the filled-in images from the year of 2019 to 2027 to\nextract the expiration dates and assess the model performance of LCBVAE on the\nexpiration date recognition. The pipeline of (LCBVAE+CRNN) can be then\nintegrated into an automated sorting systems for extracting the expiry dates\nand sorting the products accordingly during the manufacture stage.\nAdditionally, it can overcome the manual entry of expiration dates that can be\ntime-consuming and inefficient at the merchants. Due to the lack of the\navailability of the dotted Arabic expiration date images, we created an Arabic\ndot-matrix True Type Font (TTF) for the generation of the synthetic images. We\ntrained the model with unrealistic synthetic dates of 59902 images and\nperformed the testing on a realistic synthetic date of 3287 images from the\nyear of 2019 to 2027, represented as yyyy/mm/dd. In our study, we demonstrated\nthe significance of latent bottleneck layer with improving the generalization\nwhen the size is increased up to 1024 in downstream transfer learning tasks as\nfor image translation. The proposed approach achieved an accuracy of 97% on the\nimage translation with using the LCBVAE architecture that can be generalized\nfor any downstream learning tasks as for image translation and reconstruction.",
            "author": [
                "Ahmed Zidane",
                "Ghada Soliman"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14069v1",
                "http://arxiv.org/pdf/2310.14069v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18339v1",
            "title": "MOELoRA: An MOE-based Parameter Efficient Fine-Tuning Method for\n  Multi-task Medical Applications",
            "updated": "2023-10-21T17:18:09Z",
            "published": "2023-10-21T17:18:09Z",
            "summary": "The recent surge in the field of Large Language Models (LLMs) has gained\nsignificant attention in numerous domains. In order to tailor an LLM to a\nspecific domain such as a web-based healthcare system, fine-tuning with domain\nknowledge is necessary. However, two issues arise during fine-tuning LLMs for\nmedical applications. The first is the problem of task variety, where there are\nnumerous distinct tasks in real-world medical scenarios. This diversity often\nresults in suboptimal fine-tuning due to data imbalance and seesawing problems.\nAdditionally, the high cost of fine-tuning can be prohibitive, impeding the\napplication of LLMs. The large number of parameters in LLMs results in enormous\ntime and computational consumption during fine-tuning, which is difficult to\njustify. To address these two issues simultaneously, we propose a novel\nparameter-efficient fine-tuning framework for multi-task medical applications\ncalled MOELoRA. The framework aims to capitalize on the benefits of both MOE\nfor multi-task learning and LoRA for parameter-efficient fine-tuning. To unify\nMOE and LoRA, we devise multiple experts as the trainable parameters, where\neach expert consists of a pair of low-rank matrices to maintain a small number\nof trainable parameters. Additionally, we propose a task-motivated gate\nfunction for all MOELoRA layers that can regulate the contributions of each\nexpert and generate distinct parameters for various tasks. To validate the\neffectiveness and practicality of the proposed method, we conducted\ncomprehensive experiments on a public multi-task Chinese medical dataset. The\nexperimental results demonstrate that MOELoRA outperforms existing\nparameter-efficient fine-tuning methods. The implementation is available online\nfor convenient reproduction of our experiments.",
            "author": [
                "Qidong Liu",
                "Xian Wu",
                "Xiangyu Zhao",
                "Yuanshao Zhu",
                "Derong Xu",
                "Feng Tian",
                "Yefeng Zheng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18339v1",
                "http://arxiv.org/pdf/2310.18339v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14064v1",
            "title": "Counterfactual Prediction Under Selective Confounding",
            "updated": "2023-10-21T16:54:59Z",
            "published": "2023-10-21T16:54:59Z",
            "summary": "This research addresses the challenge of conducting interpretable causal\ninference between a binary treatment and its resulting outcome when not all\nconfounders are known. Confounders are factors that have an influence on both\nthe treatment and the outcome. We relax the requirement of knowing all\nconfounders under desired treatment, which we refer to as Selective\nConfounding, to enable causal inference in diverse real-world scenarios. Our\nproposed scheme is designed to work in situations where multiple\ndecision-makers with different policies are involved and where there is a\nre-evaluation mechanism after the initial decision to ensure consistency. These\nassumptions are more practical to fulfill compared to the availability of all\nconfounders under all treatments. To tackle the issue of Selective Confounding,\nwe propose the use of dual-treatment samples. These samples allow us to employ\ntwo-step procedures, such as Regression Adjustment or Doubly-Robust, to learn\ncounterfactual predictors. We provide both theoretical error bounds and\nempirical evidence of the effectiveness of our proposed scheme using synthetic\nand real-world child placement data. Furthermore, we introduce three evaluation\nmethods specifically tailored to assess the performance in child placement\nscenarios. By emphasizing transparency and interpretability, our approach aims\nto provide decision-makers with a valuable tool. The source code repository of\nthis work is located at https://github.com/sohaib730/CausalML.",
            "author": [
                "Sohaib Kiani",
                "Jared Barton",
                "Jon Sushinsky",
                "Lynda Heimbach",
                "Bo Luo"
            ],
            "link": [
                "http://dx.doi.org/10.3233/FAIA230403",
                "http://arxiv.org/abs/2310.14064v1",
                "http://arxiv.org/pdf/2310.14064v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14062v1",
            "title": "On the Neural Tangent Kernel of Equilibrium Models",
            "updated": "2023-10-21T16:47:18Z",
            "published": "2023-10-21T16:47:18Z",
            "summary": "This work studies the neural tangent kernel (NTK) of the deep equilibrium\n(DEQ) model, a practical ``infinite-depth'' architecture which directly\ncomputes the infinite-depth limit of a weight-tied network via root-finding.\nEven though the NTK of a fully-connected neural network can be stochastic if\nits width and depth both tend to infinity simultaneously, we show that\ncontrarily a DEQ model still enjoys a deterministic NTK despite its width and\ndepth going to infinity at the same time under mild conditions. Moreover, this\ndeterministic NTK can be found efficiently via root-finding.",
            "author": [
                "Zhili Feng",
                "J. Zico Kolter"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14062v1",
                "http://arxiv.org/pdf/2310.14062v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14053v1",
            "title": "Beyond Accuracy: Evaluating Self-Consistency of Code Large Language\n  Models with IdentityChain",
            "updated": "2023-10-21T16:14:56Z",
            "published": "2023-10-21T16:14:56Z",
            "summary": "Code Large Language Models (Code LLMs) are being increasingly employed in\nreal-life applications, so evaluating them is critical. While the general\naccuracy of Code LLMs on individual tasks has been extensively evaluated, their\nself-consistency across different tasks is overlooked. Intuitively, a\ntrustworthy model should be self-consistent when generating natural language\nspecifications for its own code and generating code for its own specifications.\nFailure to preserve self-consistency reveals a lack of understanding of the\nshared semantics underlying natural language and programming language, and\ntherefore undermines the trustworthiness of a model. In this paper, we first\nformally define the self-consistency of Code LLMs and then design a framework,\nIdentityChain, which effectively and efficiently evaluates the self-consistency\nand general accuracy of a model at the same time. We study eleven Code LLMs and\nshow that they fail to preserve self-consistency, which is indeed a distinct\naspect from general accuracy. Furthermore, we show that IdentityChain can be\nused as a model debugging tool to expose weaknesses of Code LLMs by\ndemonstrating three major weaknesses that we identify in current models using\nIdentityChain. Our code is available at\nhttps://github.com/marcusm117/IdentityChain.",
            "author": [
                "Marcus J. Min",
                "Yangruibo Ding",
                "Luca Buratti",
                "Saurabh Pujar",
                "Gail Kaiser",
                "Suman Jana",
                "Baishakhi Ray"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14053v1",
                "http://arxiv.org/pdf/2310.14053v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL",
                "cs.SE",
                "68",
                "I.2; D.2"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14047v1",
            "title": "MeaeQ: Mount Model Extraction Attacks with Efficient Queries",
            "updated": "2023-10-21T16:07:16Z",
            "published": "2023-10-21T16:07:16Z",
            "summary": "We study model extraction attacks in natural language processing (NLP) where\nattackers aim to steal victim models by repeatedly querying the open\nApplication Programming Interfaces (APIs). Recent works focus on limited-query\nbudget settings and adopt random sampling or active learning-based sampling\nstrategies on publicly available, unannotated data sources. However, these\nmethods often result in selected queries that lack task relevance and data\ndiversity, leading to limited success in achieving satisfactory results with\nlow query costs. In this paper, we propose MeaeQ (Model extraction attack with\nefficient Queries), a straightforward yet effective method to address these\nissues. Specifically, we initially utilize a zero-shot sequence inference\nclassifier, combined with API service information, to filter task-relevant data\nfrom a public text corpus instead of a problem domain-specific dataset.\nFurthermore, we employ a clustering-based data reduction technique to obtain\nrepresentative data as queries for the attack. Extensive experiments conducted\non four benchmark datasets demonstrate that MeaeQ achieves higher functional\nsimilarity to the victim model than baselines while requiring fewer queries.\nOur code is available at https://github.com/C-W-D/MeaeQ.",
            "author": [
                "Chengwei Dai",
                "Minxuan Lv",
                "Kun Li",
                "Wei Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14047v1",
                "http://arxiv.org/pdf/2310.14047v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14045v2",
            "title": "Training Image Derivatives: Increased Accuracy and Universal Robustness",
            "updated": "2023-11-27T19:43:36Z",
            "published": "2023-10-21T15:43:24Z",
            "summary": "Derivative training is a known method that significantly improves the\naccuracy of neural networks in some low-dimensional applications. In this\npaper, a similar improvement is obtained for an image analysis problem:\nreconstructing the vertices of a cube from its image. By training the\nderivatives with respect to the 6 degrees of freedom of the cube, we obtain 25\ntimes more accurate results for noiseless inputs. The derivatives also offer\ninsight into the robustness problem, which is currently understood in terms of\ntwo types of network vulnerabilities. The first type involves small\nperturbations that dramatically change the output, and the second type relates\nto substantial image changes that the network erroneously ignores. Defense\nagainst each is possible, but safeguarding against both while maintaining the\naccuracy defies conventional training methods. The first type is analyzed using\nthe network's gradient, while the second relies on human input evaluation,\nserving as an oracle substitute. For the task at hand, the nearest neighbor\noracle can be defined and expanded into Taylor series using image derivatives.\nThis allows for a robustness analysis that unifies both types of\nvulnerabilities and enables training where accuracy and universal robustness\nare limited only by network capacity.",
            "author": [
                "Vsevolod I. Avrutskiy"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14045v2",
                "http://arxiv.org/pdf/2310.14045v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14044v1",
            "title": "Composer Style-specific Symbolic Music Generation Using Vector Quantized\n  Discrete Diffusion Models",
            "updated": "2023-10-21T15:41:50Z",
            "published": "2023-10-21T15:41:50Z",
            "summary": "Emerging Denoising Diffusion Probabilistic Models (DDPM) have become\nincreasingly utilised because of promising results they have achieved in\ndiverse generative tasks with continuous data, such as image and sound\nsynthesis. Nonetheless, the success of diffusion models has not been fully\nextended to discrete symbolic music. We propose to combine a vector quantized\nvariational autoencoder (VQ-VAE) and discrete diffusion models for the\ngeneration of symbolic music with desired composer styles. The trained VQ-VAE\ncan represent symbolic music as a sequence of indexes that correspond to\nspecific entries in a learned codebook. Subsequently, a discrete diffusion\nmodel is used to model the VQ-VAE's discrete latent space. The diffusion model\nis trained to generate intermediate music sequences consisting of codebook\nindexes, which are then decoded to symbolic music using the VQ-VAE's decoder.\nThe results demonstrate our model can generate symbolic music with target\ncomposer styles that meet the given conditions with a high accuracy of 72.36%.",
            "author": [
                "Jincheng Zhang",
                "Jingjing Tang",
                "Charalampos Saitis",
                "Gy\u00f6rgy Fazekas"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14044v1",
                "http://arxiv.org/pdf/2310.14044v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.AI",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14037v1",
            "title": "Unlock Multi-Modal Capability of Dense Retrieval via Visual Module\n  Plugin",
            "updated": "2023-10-21T15:21:39Z",
            "published": "2023-10-21T15:21:39Z",
            "summary": "This paper proposes Multi-modAl Retrieval model via Visual modulE pLugin\n(MARVEL) to learn an embedding space for queries and multi-modal documents to\nconduct retrieval. MARVEL encodes queries and multi-modal documents with a\nunified encoder model, which helps to alleviate the modality gap between images\nand texts. Specifically, we enable the image understanding ability of a\nwell-trained dense retriever, T5-ANCE, by incorporating the image features\nencoded by the visual module as its inputs. To facilitate the multi-modal\nretrieval tasks, we build the ClueWeb22-MM dataset based on the ClueWeb22\ndataset, which regards anchor texts as queries, and exact the related texts and\nimage documents from anchor linked web pages. Our experiments show that MARVEL\nsignificantly outperforms the state-of-the-art methods on the multi-modal\nretrieval dataset WebQA and ClueWeb22-MM. Our further analyses show that the\nvisual module plugin method is tailored to enable the image understanding\nability for an existing dense retrieval model. Besides, we also show that the\nlanguage model has the ability to extract image semantics from image encoders\nand adapt the image features in the input space of language models. All codes\nare available at https://github.com/OpenMatch/MARVEL.",
            "author": [
                "Tianshuo Zhou",
                "Sen Mei",
                "Xinze Li",
                "Zhenghao Liu",
                "Chenyan Xiong",
                "Zhiyuan Liu",
                "Yu Gu",
                "Ge Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14037v1",
                "http://arxiv.org/pdf/2310.14037v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14036v1",
            "title": "On discretisation drift and smoothness regularisation in neural network\n  training",
            "updated": "2023-10-21T15:21:36Z",
            "published": "2023-10-21T15:21:36Z",
            "summary": "The deep learning recipe of casting real-world problems as mathematical\noptimisation and tackling the optimisation by training deep neural networks\nusing gradient-based optimisation has undoubtedly proven to be a fruitful one.\nThe understanding behind why deep learning works, however, has lagged behind\nits practical significance. We aim to make steps towards an improved\nunderstanding of deep learning with a focus on optimisation and model\nregularisation. We start by investigating gradient descent (GD), a\ndiscrete-time algorithm at the basis of most popular deep learning optimisation\nalgorithms. Understanding the dynamics of GD has been hindered by the presence\nof discretisation drift, the numerical integration error between GD and its\noften studied continuous-time counterpart, the negative gradient flow (NGF). To\nadd to the toolkit available to study GD, we derive novel continuous-time flows\nthat account for discretisation drift. Unlike the NGF, these new flows can be\nused to describe learning rate specific behaviours of GD, such as training\ninstabilities observed in supervised learning and two-player games. We then\ntranslate insights from continuous time into mitigation strategies for unstable\nGD dynamics, by constructing novel learning rate schedules and regularisers\nthat do not require additional hyperparameters. Like optimisation, smoothness\nregularisation is another pillar of deep learning's success with wide use in\nsupervised learning and generative modelling. Despite their individual\nsignificance, the interactions between smoothness regularisation and\noptimisation have yet to be explored. We find that smoothness regularisation\naffects optimisation across multiple deep learning domains, and that\nincorporating smoothness regularisation in reinforcement learning leads to a\nperformance boost that can be recovered using adaptions to optimisation\nmethods.",
            "author": [
                "Mihaela Claudia Rosca"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14036v1",
                "http://arxiv.org/pdf/2310.14036v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14034v1",
            "title": "Tree Prompting: Efficient Task Adaptation without Fine-Tuning",
            "updated": "2023-10-21T15:18:22Z",
            "published": "2023-10-21T15:18:22Z",
            "summary": "Prompting language models (LMs) is the main interface for applying them to\nnew tasks. However, for smaller LMs, prompting provides low accuracy compared\nto gradient-based finetuning. Tree Prompting is an approach to prompting which\nbuilds a decision tree of prompts, linking multiple LM calls together to solve\na task. At inference time, each call to the LM is determined by efficiently\nrouting the outcome of the previous call using the tree. Experiments on\nclassification datasets show that Tree Prompting improves accuracy over\ncompeting methods and is competitive with fine-tuning. We also show that\nvariants of Tree Prompting allow inspection of a model's decision-making\nprocess.",
            "author": [
                "John X. Morris",
                "Chandan Singh",
                "Alexander M. Rush",
                "Jianfeng Gao",
                "Yuntian Deng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14034v1",
                "http://arxiv.org/pdf/2310.14034v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14029v1",
            "title": "LLM-Prop: Predicting Physical And Electronic Properties Of Crystalline\n  Solids From Their Text Descriptions",
            "updated": "2023-10-21T14:49:58Z",
            "published": "2023-10-21T14:49:58Z",
            "summary": "The prediction of crystal properties plays a crucial role in the crystal\ndesign process. Current methods for predicting crystal properties focus on\nmodeling crystal structures using graph neural networks (GNNs). Although GNNs\nare powerful, accurately modeling the complex interactions between atoms and\nmolecules within a crystal remains a challenge. Surprisingly, predicting\ncrystal properties from crystal text descriptions is understudied, despite the\nrich information and expressiveness that text data offer. One of the main\nreasons is the lack of publicly available data for this task. In this paper, we\ndevelop and make public a benchmark dataset (called TextEdge) that contains\ntext descriptions of crystal structures with their properties. We then propose\nLLM-Prop, a method that leverages the general-purpose learning capabilities of\nlarge language models (LLMs) to predict the physical and electronic properties\nof crystals from their text descriptions. LLM-Prop outperforms the current\nstate-of-the-art GNN-based crystal property predictor by about 4% in predicting\nband gap, 3% in classifying whether the band gap is direct or indirect, and 66%\nin predicting unit cell volume. LLM-Prop also outperforms a finetuned MatBERT,\na domain-specific pre-trained BERT model, despite having 3 times fewer\nparameters. Our empirical results may highlight the current inability of GNNs\nto capture information pertaining to space group symmetry and Wyckoff sites for\naccurate crystal property prediction.",
            "author": [
                "Andre Niyongabo Rubungo",
                "Craig Arnold",
                "Barry P. Rand",
                "Adji Bousso Dieng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14029v1",
                "http://arxiv.org/pdf/2310.14029v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14025v1",
            "title": "Large Language Models and Multimodal Retrieval for Visual Word Sense\n  Disambiguation",
            "updated": "2023-10-21T14:35:42Z",
            "published": "2023-10-21T14:35:42Z",
            "summary": "Visual Word Sense Disambiguation (VWSD) is a novel challenging task with the\ngoal of retrieving an image among a set of candidates, which better represents\nthe meaning of an ambiguous word within a given context. In this paper, we make\na substantial step towards unveiling this interesting task by applying a\nvarying set of approaches. Since VWSD is primarily a text-image retrieval task,\nwe explore the latest transformer-based methods for multimodal retrieval.\nAdditionally, we utilize Large Language Models (LLMs) as knowledge bases to\nenhance the given phrases and resolve ambiguity related to the target word. We\nalso study VWSD as a unimodal problem by converting to text-to-text and\nimage-to-image retrieval, as well as question-answering (QA), to fully explore\nthe capabilities of relevant models. To tap into the implicit knowledge of\nLLMs, we experiment with Chain-of-Thought (CoT) prompting to guide explainable\nanswer generation. On top of all, we train a learn to rank (LTR) model in order\nto combine our different modules, achieving competitive ranking results.\nExtensive experiments on VWSD demonstrate valuable insights to effectively\ndrive future directions.",
            "author": [
                "Anastasia Kritharoula",
                "Maria Lymperaiou",
                "Giorgos Stamou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14025v1",
                "http://arxiv.org/pdf/2310.14025v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14021v1",
            "title": "Survey of Vector Database Management Systems",
            "updated": "2023-10-21T14:09:48Z",
            "published": "2023-10-21T14:09:48Z",
            "summary": "There are now over 20 commercial vector database management systems (VDBMSs),\nall produced within the past five years. But embedding-based retrieval has been\nstudied for over ten years, and similarity search a staggering half century and\nmore. Driving this shift from algorithms to systems are new data intensive\napplications, notably large language models, that demand vast stores of\nunstructured data coupled with reliable, secure, fast, and scalable query\nprocessing capability. A variety of new data management techniques now exist\nfor addressing these needs, however there is no comprehensive survey to\nthoroughly review these techniques and systems. We start by identifying five\nmain obstacles to vector data management, namely vagueness of semantic\nsimilarity, large size of vectors, high cost of similarity comparison, lack of\nnatural partitioning that can be used for indexing, and difficulty of\nefficiently answering hybrid queries that require both attributes and vectors.\nOvercoming these obstacles has led to new approaches to query processing,\nstorage and indexing, and query optimization and execution. For query\nprocessing, a variety of similarity scores and query types are now well\nunderstood; for storage and indexing, techniques include vector compression,\nnamely quantization, and partitioning based on randomization, learning\npartitioning, and navigable partitioning; for query optimization and execution,\nwe describe new operators for hybrid queries, as well as techniques for plan\nenumeration, plan selection, and hardware accelerated execution. These\ntechniques lead to a variety of VDBMSs across a spectrum of design and runtime\ncharacteristics, including native systems specialized for vectors and extended\nsystems that incorporate vector capabilities into existing systems. We then\ndiscuss benchmarks, and finally we outline research challenges and point the\ndirection for future work.",
            "author": [
                "James Jie Pan",
                "Jianguo Wang",
                "Guoliang Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14021v1",
                "http://arxiv.org/pdf/2310.14021v1"
            ],
            "primary_category": "cs.DB",
            "category": [
                "cs.DB"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14017v4",
            "title": "Contrast Everything: A Hierarchical Contrastive Framework for Medical\n  Time-Series",
            "updated": "2023-11-06T17:49:44Z",
            "published": "2023-10-21T13:59:31Z",
            "summary": "Contrastive representation learning is crucial in medical time series\nanalysis as it alleviates dependency on labor-intensive, domain-specific, and\nscarce expert annotations. However, existing contrastive learning methods\nprimarily focus on one single data level, which fails to fully exploit the\nintricate nature of medical time series. To address this issue, we present\nCOMET, an innovative hierarchical framework that leverages data consistencies\nat all inherent levels in medical time series. Our meticulously designed model\nsystematically captures data consistency from four potential levels:\nobservation, sample, trial, and patient levels. By developing contrastive loss\nat multiple levels, we can learn effective representations that preserve\ncomprehensive data consistency, maximizing information utilization in a\nself-supervised manner. We conduct experiments in the challenging\npatient-independent setting. We compare COMET against six baselines using three\ndiverse datasets, which include ECG signals for myocardial infarction and EEG\nsignals for Alzheimer's and Parkinson's diseases. The results demonstrate that\nCOMET consistently outperforms all baselines, particularly in setup with 10%\nand 1% labeled data fractions across all datasets. These results underscore the\nsignificant impact of our framework in advancing contrastive representation\nlearning techniques for medical time series. The source code is available at\nhttps://github.com/DL4mHealth/COMET.",
            "author": [
                "Yihe Wang",
                "Yu Han",
                "Haishuai Wang",
                "Xiang Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14017v4",
                "http://arxiv.org/pdf/2310.14017v4"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14016v1",
            "title": "SwG-former: Sliding-window Graph Convolutional Network Integrated with\n  Conformer for Sound Event Localization and Detection",
            "updated": "2023-10-21T13:56:23Z",
            "published": "2023-10-21T13:56:23Z",
            "summary": "Sound event localization and detection (SELD) is a joint task of sound event\ndetection (SED) and direction of arrival (DoA) estimation. SED mainly relies on\ntemporal dependencies to distinguish different sound classes, while DoA\nestimation depends on spatial correlations to estimate source directions. To\njointly optimize two subtasks, the SELD system should extract spatial\ncorrelations and model temporal dependencies simultaneously. However, numerous\nmodels mainly extract spatial correlations and model temporal dependencies\nseparately. In this paper, the interdependence of spatial-temporal information\nin audio signals is exploited for simultaneous extraction to enhance the model\nperformance. In response, a novel graph representation leveraging graph\nconvolutional network (GCN) in non-Euclidean space is developed to extract\nspatial-temporal information concurrently. A sliding-window graph (SwG) module\nis designed based on the graph representation. It exploits sliding-windows with\ndifferent sizes to learn temporal context information and dynamically\nconstructs graph vertices in the frequency-channel (F-C) domain to capture\nspatial correlations. Furthermore, as the cornerstone of message passing, a\nrobust Conv2dAgg function is proposed and embedded into the SwG module to\naggregate the features of neighbor vertices. To improve the performance of SELD\nin a natural spatial acoustic environment, a general and efficient SwG-former\nmodel is proposed by integrating the SwG module with the Conformer. It exhibits\nsuperior performance in comparison to recent advanced SELD models. To further\nvalidate the generality and efficiency of the SwG-former, it is seamlessly\nintegrated into the event-independent network version 2 (EINV2) called\nSwG-EINV2. The SwG-EINV2 surpasses the state-of-the-art (SOTA) methods under\nthe same acoustic environment.",
            "author": [
                "Weiming Huang",
                "Qinghua Huang",
                "Liyan Ma",
                "Zhengyu Chen",
                "Chuan Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14016v1",
                "http://arxiv.org/pdf/2310.14016v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14009v2",
            "title": "One is More: Diverse Perspectives within a Single Network for Efficient\n  DRL",
            "updated": "2023-10-29T02:46:30Z",
            "published": "2023-10-21T13:37:13Z",
            "summary": "Deep reinforcement learning has achieved remarkable performance in various\ndomains by leveraging deep neural networks for approximating value functions\nand policies. However, using neural networks to approximate value functions or\npolicy functions still faces challenges, including low sample efficiency and\noverfitting. In this paper, we introduce OMNet, a novel learning paradigm\nutilizing multiple subnetworks within a single network, offering diverse\noutputs efficiently. We provide a systematic pipeline, including\ninitialization, training, and sampling with OMNet. OMNet can be easily applied\nto various deep reinforcement learning algorithms with minimal additional\noverhead. Through comprehensive evaluations conducted on MuJoCo benchmark, our\nfindings highlight OMNet's ability to strike an effective balance between\nperformance and computational cost.",
            "author": [
                "Yiqin Tan",
                "Ling Pan",
                "Longbo Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14009v2",
                "http://arxiv.org/pdf/2310.14009v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14001v1",
            "title": "Toward Stronger Textual Attack Detectors",
            "updated": "2023-10-21T13:01:29Z",
            "published": "2023-10-21T13:01:29Z",
            "summary": "The landscape of available textual adversarial attacks keeps growing, posing\nsevere threats and raising concerns regarding the deep NLP system's integrity.\nHowever, the crucial problem of defending against malicious attacks has only\ndrawn the attention of the NLP community. The latter is nonetheless\ninstrumental in developing robust and trustworthy systems. This paper makes two\nimportant contributions in this line of search: (i) we introduce LAROUSSE, a\nnew framework to detect textual adversarial attacks and (ii) we introduce\nSTAKEOUT, a new benchmark composed of nine popular attack methods, three\ndatasets, and two pre-trained models. LAROUSSE is ready-to-use in production as\nit is unsupervised, hyperparameter-free, and non-differentiable, protecting it\nagainst gradient-based methods. Our new benchmark STAKEOUT allows for a robust\nevaluation framework: we conduct extensive numerical experiments which\ndemonstrate that LAROUSSE outperforms previous methods, and which allows to\nidentify interesting factors of detection rate variations.",
            "author": [
                "Pierre Colombo",
                "Marine Picot",
                "Nathan Noiry",
                "Guillaume Staerman",
                "Pablo Piantanida"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14001v1",
                "http://arxiv.org/pdf/2310.14001v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13998v1",
            "title": "Transductive Learning for Textual Few-Shot Classification in API-based\n  Embedding Models",
            "updated": "2023-10-21T12:47:10Z",
            "published": "2023-10-21T12:47:10Z",
            "summary": "Proprietary and closed APIs are becoming increasingly common to process\nnatural language, and are impacting the practical applications of natural\nlanguage processing, including few-shot classification. Few-shot classification\ninvolves training a model to perform a new classification task with a handful\nof labeled data. This paper presents three contributions. First, we introduce a\nscenario where the embedding of a pre-trained model is served through a gated\nAPI with compute-cost and data-privacy constraints. Second, we propose a\ntransductive inference, a learning paradigm that has been overlooked by the NLP\ncommunity. Transductive inference, unlike traditional inductive learning,\nleverages the statistics of unlabeled data. We also introduce a new\nparameter-free transductive regularizer based on the Fisher-Rao loss, which can\nbe used on top of the gated API embeddings. This method fully utilizes\nunlabeled data, does not share any label with the third-party API provider and\ncould serve as a baseline for future research. Third, we propose an improved\nexperimental setting and compile a benchmark of eight datasets involving\nmulticlass classification in four different languages, with up to 151 classes.\nWe evaluate our methods using eight backbone models, along with an episodic\nevaluation over 1,000 episodes, which demonstrate the superiority of\ntransductive inference over the standard inductive setting.",
            "author": [
                "Pierre Colombo",
                "Victor Pellegrain",
                "Malik Boudiaf",
                "Victor Storchan",
                "Myriam Tami",
                "Ismail Ben Ayed",
                "Celine Hudelot",
                "Pablo Piantanida"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13998v1",
                "http://arxiv.org/pdf/2310.13998v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13995v1",
            "title": "On Bilingual Lexicon Induction with Large Language Models",
            "updated": "2023-10-21T12:43:27Z",
            "published": "2023-10-21T12:43:27Z",
            "summary": "Bilingual Lexicon Induction (BLI) is a core task in multilingual NLP that\nstill, to a large extent, relies on calculating cross-lingual word\nrepresentations. Inspired by the global paradigm shift in NLP towards Large\nLanguage Models (LLMs), we examine the potential of the latest generation of\nLLMs for the development of bilingual lexicons. We ask the following research\nquestion: Is it possible to prompt and fine-tune multilingual LLMs (mLLMs) for\nBLI, and how does this approach compare against and complement current BLI\napproaches? To this end, we systematically study 1) zero-shot prompting for\nunsupervised BLI and 2) few-shot in-context prompting with a set of seed\ntranslation pairs, both without any LLM fine-tuning, as well as 3) standard\nBLI-oriented fine-tuning of smaller LLMs. We experiment with 18 open-source\ntext-to-text mLLMs of different sizes (from 0.3B to 13B parameters) on two\nstandard BLI benchmarks covering a range of typologically diverse languages.\nOur work is the first to demonstrate strong BLI capabilities of text-to-text\nmLLMs. The results reveal that few-shot prompting with in-context examples from\nnearest neighbours achieves the best performance, establishing new\nstate-of-the-art BLI scores for many language pairs. We also conduct a series\nof in-depth analyses and ablation studies, providing more insights on BLI with\n(m)LLMs, also along with their limitations.",
            "author": [
                "Yaoyiran Li",
                "Anna Korhonen",
                "Ivan Vuli\u0107"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13995v1",
                "http://arxiv.org/pdf/2310.13995v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13990v1",
            "title": "A Novel Information-Theoretic Objective to Disentangle Representations\n  for Fair Classification",
            "updated": "2023-10-21T12:35:48Z",
            "published": "2023-10-21T12:35:48Z",
            "summary": "One of the pursued objectives of deep learning is to provide tools that learn\nabstract representations of reality from the observation of multiple contextual\nsituations. More precisely, one wishes to extract disentangled representations\nwhich are (i) low dimensional and (ii) whose components are independent and\ncorrespond to concepts capturing the essence of the objects under consideration\n(Locatello et al., 2019b). One step towards this ambitious project consists in\nlearning disentangled representations with respect to a predefined (sensitive)\nattribute, e.g., the gender or age of the writer. Perhaps one of the main\napplication for such disentangled representations is fair classification.\nExisting methods extract the last layer of a neural network trained with a loss\nthat is composed of a cross-entropy objective and a disentanglement\nregularizer. In this work, we adopt an information-theoretic view of this\nproblem which motivates a novel family of regularizers that minimizes the\nmutual information between the latent representation and the sensitive\nattribute conditional to the target. The resulting set of losses, called\nCLINIC, is parameter free and thus, it is easier and faster to train. CLINIC\nlosses are studied through extensive numerical experiments by training over 2k\nneural networks. We demonstrate that our methods offer a better\ndisentanglement/accuracy trade-off than previous techniques, and generalize\nbetter than training with cross-entropy loss solely provided that the\ndisentanglement task is not too constraining.",
            "author": [
                "Pierre Colombo",
                "Nathan Noiry",
                "Guillaume Staerman",
                "Pablo Piantanida"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13990v1",
                "http://arxiv.org/pdf/2310.13990v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13981v2",
            "title": "Filling the Missing: Exploring Generative AI for Enhanced Federated\n  Learning over Heterogeneous Mobile Edge Devices",
            "updated": "2023-10-29T02:34:47Z",
            "published": "2023-10-21T12:07:04Z",
            "summary": "Distributed Artificial Intelligence (AI) model training over mobile edge\nnetworks encounters significant challenges due to the data and resource\nheterogeneity of edge devices. The former hampers the convergence rate of the\nglobal model, while the latter diminishes the devices' resource utilization\nefficiency. In this paper, we propose a generative AI-empowered federated\nlearning to address these challenges by leveraging the idea of FIlling the\nMIssing (FIMI) portion of local data. Specifically, FIMI can be considered as a\nresource-aware data augmentation method that effectively mitigates the data\nheterogeneity while ensuring efficient FL training. We first quantify the\nrelationship between the training data amount and the learning performance. We\nthen study the FIMI optimization problem with the objective of minimizing the\ndevice-side overall energy consumption subject to required learning performance\nconstraints. The decomposition-based analysis and the cross-entropy searching\nmethod are leveraged to derive the solution, where each device is assigned\nsuitable AI-synthesized data and resource utilization policy. Experiment\nresults demonstrate that FIMI can save up to 50% of the device-side energy to\nachieve the target global test accuracy in comparison with the existing\nmethods. Meanwhile, FIMI can significantly enhance the converged global\naccuracy under the non-independently-and-identically distribution (non-IID)\ndata.",
            "author": [
                "Peichun Li",
                "Hanwen Zhang",
                "Yuan Wu",
                "Liping Qian",
                "Rong Yu",
                "Dusit Niyato",
                "Xuemin Shen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13981v2",
                "http://arxiv.org/pdf/2310.13981v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13980v1",
            "title": "A multivariate Bayesian learning approach for improved detection of\n  doping in athletes using urinary steroid profiles",
            "updated": "2023-10-21T11:57:26Z",
            "published": "2023-10-21T11:57:26Z",
            "summary": "Biomarker analysis of athletes' urinary steroid profiles is crucial for the\nsuccess of anti-doping efforts. Current statistical analysis methods generate\npersonalised limits for each athlete based on univariate modelling of\nlongitudinal biomarker values from the urinary steroid profile. However,\nsimultaneous modelling of multiple biomarkers has the potential to further\nenhance abnormality detection. In this study, we propose a multivariate\nBayesian adaptive model for longitudinal data analysis, which extends the\nestablished single-biomarker model in forensic toxicology. The proposed\napproach employs Markov chain Monte Carlo sampling methods and addresses the\nscarcity of confirmed abnormal values through a one-class classification\nalgorithm. By adapting decision boundaries as new measurements are obtained,\nthe model provides robust and personalised detection thresholds for each\nathlete. We tested the proposed approach on a database of 229 athletes which\nincludes longitudinal steroid profiles classified as normal, atypical, or\nconfirmed abnormal. Our results demonstrate improved detection performance,\nhighlighting the potential value of a multivariate approach in doping\ndetection.",
            "author": [
                "Dimitra Eleftheriou",
                "Thomas Piper",
                "Mario Thevis",
                "Tereza Neocleous"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13980v1",
                "http://arxiv.org/pdf/2310.13980v1"
            ],
            "primary_category": "stat.AP",
            "category": [
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13977v1",
            "title": "Continual Invariant Risk Minimization",
            "updated": "2023-10-21T11:44:47Z",
            "published": "2023-10-21T11:44:47Z",
            "summary": "Empirical risk minimization can lead to poor generalization behavior on\nunseen environments if the learned model does not capture invariant feature\nrepresentations. Invariant risk minimization (IRM) is a recent proposal for\ndiscovering environment-invariant representations. IRM was introduced by\nArjovsky et al. (2019) and extended by Ahuja et al. (2020). IRM assumes that\nall environments are available to the learning system at the same time. With\nthis work, we generalize the concept of IRM to scenarios where environments are\nobserved sequentially. We show that existing approaches, including those\ndesigned for continual learning, fail to identify the invariant features and\nmodels across sequentially presented environments. We extend IRM under a\nvariational Bayesian and bilevel framework, creating a general approach to\ncontinual invariant risk minimization. We also describe a strategy to solve the\noptimization problems using a variant of the alternating direction method of\nmultiplier (ADMM). We show empirically using multiple datasets and with\nmultiple sequential environments that the proposed methods outperform or is\ncompetitive with prior approaches.",
            "author": [
                "Francesco Alesiani",
                "Shujian Yu",
                "Mathias Niepert"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13977v1",
                "http://arxiv.org/pdf/2310.13977v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13975v1",
            "title": "ASBART:Accelerated Soft Bayes Additive Regression Trees",
            "updated": "2023-10-21T11:27:42Z",
            "published": "2023-10-21T11:27:42Z",
            "summary": "Bayes additive regression trees(BART) is a nonparametric regression model\nwhich has gained wide-spread popularity in recent years due to its flexibility\nand high accuracy of estimation. Soft BART,one variation of BART,improves both\npractically and heoretically on existing Bayesian sum-of-trees models. One\nbottleneck for Soft BART is its slow speed in the long MCMC loop. Compared to\nBART,it use more than about 20 times to complete the calculation with the\ndefault setting. We proposed a variant of BART named accelerate Soft\nBART(ASBART). Simulation studies show that the new method is about 10 times\nfaster than the Soft BART with comparable accuracy. Our code is open-source and\navailable at https://github.com/richael008/XSBART.",
            "author": [
                "Hao Ran",
                "Yang Bai"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13975v1",
                "http://arxiv.org/pdf/2310.13975v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "stat.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13974v1",
            "title": "Automatic Pronunciation Assessment -- A Review",
            "updated": "2023-10-21T11:26:24Z",
            "published": "2023-10-21T11:26:24Z",
            "summary": "Pronunciation assessment and its application in computer-aided pronunciation\ntraining (CAPT) have seen impressive progress in recent years. With the rapid\ngrowth in language processing and deep learning over the past few years, there\nis a need for an updated review. In this paper, we review methods employed in\npronunciation assessment for both phonemic and prosodic. We categorize the main\nchallenges observed in prominent research trends, and highlight existing\nlimitations, and available resources. This is followed by a discussion of the\nremaining challenges and possible directions for future work.",
            "author": [
                "Yassine El Kheir",
                "Ahmed Ali",
                "Shammur Absar Chowdhury"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13974v1",
                "http://arxiv.org/pdf/2310.13974v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13969v1",
            "title": "Distributed Linear Regression with Compositional Covariates",
            "updated": "2023-10-21T11:09:37Z",
            "published": "2023-10-21T11:09:37Z",
            "summary": "With the availability of extraordinarily huge data sets, solving the problems\nof distributed statistical methodology and computing for such data sets has\nbecome increasingly crucial in the big data area. In this paper, we focus on\nthe distributed sparse penalized linear log-contrast model in massive\ncompositional data. In particular, two distributed optimization techniques\nunder centralized and decentralized topologies are proposed for solving the two\ndifferent constrained convex optimization problems. Both two proposed\nalgorithms are based on the frameworks of Alternating Direction Method of\nMultipliers (ADMM) and Coordinate Descent Method of Multipliers(CDMM, Lin et\nal., 2014, Biometrika). It is worth emphasizing that, in the decentralized\ntopology, we introduce a distributed coordinate-wise descent algorithm based on\nGroup ADMM(GADMM, Elgabli et al., 2020, Journal of Machine Learning Research)\nfor obtaining a communication-efficient regularized estimation.\nCorrespondingly, the convergence theories of the proposed algorithms are\nrigorously established under some regularity conditions. Numerical experiments\non both synthetic and real data are conducted to evaluate our proposed\nalgorithms.",
            "author": [
                "Yue Chao",
                "Lei Huang",
                "Xuejun Ma"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13969v1",
                "http://arxiv.org/pdf/2310.13969v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "62-08 62-08 62-08 62-08 62-08",
                "G.3"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13967v1",
            "title": "A self-supervised scheme for ground roll suppression",
            "updated": "2023-10-21T10:58:20Z",
            "published": "2023-10-21T10:58:20Z",
            "summary": "In recent years, self-supervised procedures have advanced the field of\nseismic noise attenuation, due to not requiring a massive amount of clean\nlabeled data in the training stage, an unobtainable requirement for seismic\ndata. However, current self-supervised methods usually suppress simple noise\ntypes, such as random and trace-wise noise, instead of the complicated, aliased\nground roll. Here, we propose an adaptation of a self-supervised procedure,\nnamely, blind-fan networks, to remove aliased ground roll within seismic shot\ngathers without any requirement for clean data. The self-supervised denoising\nprocedure is implemented by designing a noise mask with a predefined direction\nto avoid the coherency of the ground roll being learned by the network while\npredicting one pixel's value. Numerical experiments on synthetic and field\nseismic data demonstrate that our method can effectively attenuate aliased\nground roll.",
            "author": [
                "Sixiu Liu",
                "Claire Birnie",
                "Andrey Bakulin",
                "Ali Dawood",
                "Ilya Silvestrov",
                "Tariq Alkhalifah"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13967v1",
                "http://arxiv.org/pdf/2310.13967v1"
            ],
            "primary_category": "physics.geo-ph",
            "category": [
                "physics.geo-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15191v1",
            "title": "Application of deep and reinforcement learning to boundary control\n  problems",
            "updated": "2023-10-21T10:56:32Z",
            "published": "2023-10-21T10:56:32Z",
            "summary": "The boundary control problem is a non-convex optimization and control problem\nin many scientific domains, including fluid mechanics, structural engineering,\nand heat transfer optimization. The aim is to find the optimal values for the\ndomain boundaries such that the enclosed domain adhering to the governing\nequations attains the desired state values. Traditionally, non-linear\noptimization methods, such as the Interior-Point method (IPM), are used to\nsolve such problems.\n  This project explores the possibilities of using deep learning and\nreinforcement learning to solve boundary control problems. We adhere to the\nframework of iterative optimization strategies, employing a spatial neural\nnetwork to construct well-informed initial guesses, and a spatio-temporal\nneural network learns the iterative optimization algorithm using policy\ngradients. Synthetic data, generated from the problems formulated in the\nliterature, is used for training, testing and validation. The numerical\nexperiments indicate that the proposed method can rival the speed and accuracy\nof existing solvers. In our preliminary results, the network attains costs\nlower than IPOPT, a state-of-the-art non-linear IPM, in 51\\% cases. The overall\nnumber of floating point operations in the proposed method is similar to that\nof IPOPT. Additionally, the informed initial guess method and the learned\nmomentum-like behaviour in the optimizer method are incorporated to avoid\nconvergence to local minima.",
            "author": [
                "Zenin Easa Panthakkalakath",
                "Juraj Kardo\u0161",
                "Olaf Schenk"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15191v1",
                "http://arxiv.org/pdf/2310.15191v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13966v1",
            "title": "Minimax Optimal Transfer Learning for Kernel-based Nonparametric\n  Regression",
            "updated": "2023-10-21T10:55:31Z",
            "published": "2023-10-21T10:55:31Z",
            "summary": "In recent years, transfer learning has garnered significant attention in the\nmachine learning community. Its ability to leverage knowledge from related\nstudies to improve generalization performance in a target study has made it\nhighly appealing. This paper focuses on investigating the transfer learning\nproblem within the context of nonparametric regression over a reproducing\nkernel Hilbert space. The aim is to bridge the gap between practical\neffectiveness and theoretical guarantees. We specifically consider two\nscenarios: one where the transferable sources are known and another where they\nare unknown. For the known transferable source case, we propose a two-step\nkernel-based estimator by solely using kernel ridge regression. For the unknown\ncase, we develop a novel method based on an efficient aggregation algorithm,\nwhich can automatically detect and alleviate the effects of negative sources.\nThis paper provides the statistical properties of the desired estimators and\nestablishes the minimax optimal rate. Through extensive numerical experiments\non synthetic data and real examples, we validate our theoretical findings and\ndemonstrate the effectiveness of our proposed method.",
            "author": [
                "Chao Wang",
                "Caixing Wang",
                "Xin He",
                "Xingdong Feng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13966v1",
                "http://arxiv.org/pdf/2310.13966v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13965v1",
            "title": "Cloud-Connected Wireless Holter Monitor Machine with Neural Networks\n  Based ECG Analysis for Remote Health Monitoring",
            "updated": "2023-10-21T10:45:14Z",
            "published": "2023-10-21T10:45:14Z",
            "summary": "This study describes the creation of a wireless, transportable Holter monitor\nto improve the accuracy of cardiac disease diagnosis. The main goal of this\nstudy is to develop a low-cost cardiac screening system suited explicitly for\nunderprivileged areas, addressing the rising rates of cardiovascular death. The\nsuggested system includes a wireless Electrocardiogram (ECG) module for\nreal-time cardiac signal gathering using attached electrodes, with data\ntransfer made possible by WiFi to a cloud server for archival and analysis. The\nsystem uses a neural network model for automated ECG classification,\nconcentrating on the identification of cardiac anomalies. The diagnostic\nperformance of cardiologist-level ECG analysis is surpassed by our upgraded\ndeep neural network architecture, which underwent thorough evaluation and\nshowed a stunning accuracy rate of more than 88\\%. A quick, accurate, and\nreasonably priced option for cardiac screening is provided by this\nground-breaking technology, which smoothly merges wireless data transfer with\nAI-assisted diagnostics. In addition to providing a thorough overview of the\ndevelopment process, this paper also highlights methods used to improve model\naccuracy, such as data preparation, class imbalance correction using\noversampling, and model fine-tuning. The work shows the viability of a\ncomprehensive remote cardiac screening system powered by AI and maximising the\nuse of wearable and cloud computing resources. Such cutting-edge remote health\nmonitoring technologies have great promise for improved health outcomes and\nearly identification, especially in resource-constrained countries.",
            "author": [
                "Azlaan Ranjha",
                "Laiba Jabbar",
                "Osaid Ahmed"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13965v1",
                "http://arxiv.org/pdf/2310.13965v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18336v1",
            "title": "AITA Generating Moral Judgements of the Crowd with Reasoning",
            "updated": "2023-10-21T10:27:22Z",
            "published": "2023-10-21T10:27:22Z",
            "summary": "Morality is a fundamental aspect of human behavior and ethics, influencing\nhow we interact with each other and the world around us. When faced with a\nmoral dilemma, a person's ability to make clear moral judgments can be clouded.\nDue to many factors such as personal biases, emotions and situational factors\npeople can find it difficult to decide their best course of action. The\nAmITheAsshole (AITA) subreddit is a forum on the social media platform Reddit\nthat helps people get clarity and objectivity on their predicaments. In the\nforum people post anecdotes about moral dilemmas they are facing in their\nlives, seeking validation for their actions or advice on how to navigate the\nsituation from the community. The morality of the actions in each post is\nclassified based on the collective opinion of the community into mainly two\nlabels, \"Not The Asshole\" (NTA) and \"You Are The Asshole\" (YTA). This project\naims to generate comments with moral reasoning for stories with moral dilemmas\nusing the AITA subreddit as a dataset. While past literature has explored the\nclassification of posts into labels (Alhassan et al., 2022), the generation of\ncomments remains a novel and challenging task. It involves understanding the\ncomplex social and ethical considerations in each situation. To address this\nchallenge, we will leverage the vast amount of data on the forum with the goal\nof generating coherent comments that align with the norms and values of the\nAITA community. In this endeavor, we aim to evaluate state-of-the-art seq2seq\ntext generation models for their ability to make moral judgments similarly to\nhumans, ultimately producing concise comments providing clear moral stances and\nadvice for the poster.",
            "author": [
                "Osama Bsher",
                "Ameer Sabri"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18336v1",
                "http://arxiv.org/pdf/2310.18336v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13961v1",
            "title": "Ensemble-Instruct: Generating Instruction-Tuning Data with a\n  Heterogeneous Mixture of LMs",
            "updated": "2023-10-21T10:21:17Z",
            "published": "2023-10-21T10:21:17Z",
            "summary": "Using in-context learning (ICL) for data generation, techniques such as\nSelf-Instruct (Wang et al., 2023) or the follow-up Alpaca (Taori et al., 2023)\ncan train strong conversational agents with only a small amount of human\nsupervision. One limitation of these approaches is that they resort to very\nlarge language models (around 175B parameters) that are also proprietary and\nnon-public. Here we explore the application of such techniques to language\nmodels that are much smaller (around 10B--40B parameters) and have permissive\nlicenses. We find the Self-Instruct approach to be less effective at these\nsizes and propose new ICL methods that draw on two main ideas: (a)\nCategorization and simplification of the ICL templates to make prompt learning\neasier for the LM, and (b) Ensembling over multiple LM outputs to help select\nhigh-quality synthetic examples. Our algorithm leverages the 175 Self-Instruct\nseed tasks and employs separate pipelines for instructions that require an\ninput and instructions that do not. Empirical investigations with different LMs\nshow that: (1) Our proposed method yields higher-quality instruction tuning\ndata than Self-Instruct, (2) It improves performances of both vanilla and\ninstruction-tuned LMs by significant margins, and (3) Smaller instruction-tuned\nLMs generate more useful outputs than their larger un-tuned counterparts. Our\ncodebase is available at https://github.com/IBM/ensemble-instruct.",
            "author": [
                "Young-Suk Lee",
                "Md Arafat Sultan",
                "Yousef El-Kurdi",
                "Tahira Naseem Asim Munawar",
                "Radu Florian",
                "Salim Roukos",
                "Ram\u00f3n Fernandez Astudillo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13961v1",
                "http://arxiv.org/pdf/2310.13961v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13959v2",
            "title": "Bi-discriminator Domain Adversarial Neural Networks with Class-Level\n  Gradient Alignment",
            "updated": "2023-11-01T04:00:51Z",
            "published": "2023-10-21T09:53:17Z",
            "summary": "Unsupervised domain adaptation aims to transfer rich knowledge from the\nannotated source domain to the unlabeled target domain with the same label\nspace. One prevalent solution is the bi-discriminator domain adversarial\nnetwork, which strives to identify target domain samples outside the support of\nthe source domain distribution and enforces their classification to be\nconsistent on both discriminators. Despite being effective, agnostic accuracy\nand overconfident estimation for out-of-distribution samples hinder its further\nperformance improvement. To address the above challenges, we propose a novel\nbi-discriminator domain adversarial neural network with class-level gradient\nalignment, i.e. BACG. BACG resorts to gradient signals and second-order\nprobability estimation for better alignment of domain distributions.\nSpecifically, for accuracy-awareness, we first design an optimizable nearest\nneighbor algorithm to obtain pseudo-labels of samples in the target domain, and\nthen enforce the backward gradient approximation of the two discriminators at\nthe class level. Furthermore, following evidential learning theory, we\ntransform the traditional softmax-based optimization method into a Multinomial\nDirichlet hierarchical model to infer the class probability distribution as\nwell as samples uncertainty, thereby alleviating misestimation of\nout-of-distribution samples and guaranteeing high-quality classes alignment. In\naddition, inspired by contrastive learning, we develop a memory bank-based\nvariant, i.e. Fast-BACG, which can greatly shorten the training process at the\ncost of a minor decrease in accuracy. Extensive experiments and detailed\ntheoretical analysis on four benchmark data sets validate the effectiveness and\nrobustness of our algorithm.",
            "author": [
                "Chuang Zhao",
                "Hongke Zhao",
                "Hengshu Zhu",
                "Zhenya Huang",
                "Nan Feng",
                "Enhong Chen",
                "Hui Xiong"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13959v2",
                "http://arxiv.org/pdf/2310.13959v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13955v1",
            "title": "Competitive Ensembling Teacher-Student Framework for Semi-Supervised\n  Left Atrium MRI Segmentation",
            "updated": "2023-10-21T09:23:34Z",
            "published": "2023-10-21T09:23:34Z",
            "summary": "Semi-supervised learning has greatly advanced medical image segmentation\nsince it effectively alleviates the need of acquiring abundant annotations from\nexperts and utilizes unlabeled data which is much easier to acquire. Among\nexisting perturbed consistency learning methods, mean-teacher model serves as a\nstandard baseline for semi-supervised medical image segmentation. In this\npaper, we present a simple yet efficient competitive ensembling teacher student\nframework for semi-supervised for left atrium segmentation from 3D MR images,\nin which two student models with different task-level disturbances are\nintroduced to learn mutually, while a competitive ensembling strategy is\nperformed to ensemble more reliable information to teacher model. Different\nfrom the one-way transfer between teacher and student models, our framework\nfacilitates the collaborative learning procedure of different student models\nwith the guidance of teacher model and motivates different training networks\nfor a competitive learning and ensembling procedure to achieve better\nperformance. We evaluate our proposed method on the public Left Atrium (LA)\ndataset and it obtains impressive performance gains by exploiting the unlabeled\ndata effectively and outperforms several existing semi-supervised methods.",
            "author": [
                "Yuyan Shi",
                "Yichi Zhang",
                "Shasha Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13955v1",
                "http://arxiv.org/pdf/2310.13955v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13952v1",
            "title": "Breaking the Resolution limit in Photoacoustic Imaging using Positivity\n  and Sparsity",
            "updated": "2023-10-21T09:09:47Z",
            "published": "2023-10-21T09:09:47Z",
            "summary": "In this tutorial, we aim to directly recreate some of our \"aha\" moments when\nexploring the impact of heat diffusion on the spatial resolution limit of\nphotothermal imaging. Our objective is also to communicate how this physical\nlimit can nevertheless be overcome and include some concrete technological\napplications. Describing diffusion as a random walk, one insight is that such a\nstochastic process involves not only a Gaussian spread of the mean values in\nspace, with the variance proportional to the diffusion time, but also temporal\nand spatial fluctuations around these mean values. All these fluctuations\nstrongly influence the image reconstruction immediately after the short heating\npulse. The Gaussian spread of the mean values in space increases the entropy,\nwhile the fluctuations lead to a loss of information that blurs the\nreconstruction of the initial temperature distribution and can be described\nmathematically by a spatial convolution with a Gaussian thermal\npoint-spread-function (PSF). The information loss turns out to be equal to the\nmean entropy increase and limits the spatial resolution proportional to the\ndepth of the imaged subsurface structures. This principal resolution limit can\nonly be overcome by including additional information such as sparsity or\npositivity. Prior information can be also included by using a deep neural\nnetwork with a finite degrees of freedom and trained on a specific class of\nimage examples for image reconstruction",
            "author": [
                "Peter Burgholzer",
                "Johannes Bauer-Marschallinger",
                "Mike Hettich",
                "Markus Haltmeier"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13952v1",
                "http://arxiv.org/pdf/2310.13952v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13951v1",
            "title": "Fuzzy-NMS: Improving 3D Object Detection with Fuzzy Classification in\n  NMS",
            "updated": "2023-10-21T09:09:03Z",
            "published": "2023-10-21T09:09:03Z",
            "summary": "Non-maximum suppression (NMS) is an essential post-processing module used in\nmany 3D object detection frameworks to remove overlapping candidate bounding\nboxes. However, an overreliance on classification scores and difficulties in\ndetermining appropriate thresholds can affect the resulting accuracy directly.\nTo address these issues, we introduce fuzzy learning into NMS and propose a\nnovel generalized Fuzzy-NMS module to achieve finer candidate bounding box\nfiltering. The proposed Fuzzy-NMS module combines the volume and clustering\ndensity of candidate bounding boxes, refining them with a fuzzy classification\nmethod and optimizing the appropriate suppression thresholds to reduce\nuncertainty in the NMS process. Adequate validation experiments are conducted\nusing the mainstream KITTI and large-scale Waymo 3D object detection\nbenchmarks. The results of these tests demonstrate the proposed Fuzzy-NMS\nmodule can improve the accuracy of numerous recently NMS-based detectors\nsignificantly, including PointPillars, PV-RCNN, and IA-SSD, etc. This effect is\nparticularly evident for small objects such as pedestrians and bicycles. As a\nplug-and-play module, Fuzzy-NMS does not need to be retrained and produces no\nobvious increases in inference time.",
            "author": [
                "Li Wang",
                "Xinyu Zhang",
                "Fachuan Zhao",
                "Chuze Wu",
                "Yichen Wang",
                "Ziying Song",
                "Lei Yang",
                "Jun Li",
                "Huaping Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13951v1",
                "http://arxiv.org/pdf/2310.13951v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13950v1",
            "title": "Adversarial Image Generation by Spatial Transformation in Perceptual\n  Colorspaces",
            "updated": "2023-10-21T09:07:42Z",
            "published": "2023-10-21T09:07:42Z",
            "summary": "Deep neural networks are known to be vulnerable to adversarial perturbations.\nThe amount of these perturbations are generally quantified using $L_p$ metrics,\nsuch as $L_0$, $L_2$ and $L_\\infty$. However, even when the measured\nperturbations are small, they tend to be noticeable by human observers since\n$L_p$ distance metrics are not representative of human perception. On the other\nhand, humans are less sensitive to changes in colorspace. In addition, pixel\nshifts in a constrained neighborhood are hard to notice. Motivated by these\nobservations, we propose a method that creates adversarial examples by applying\nspatial transformations, which creates adversarial examples by changing the\npixel locations independently to chrominance channels of perceptual colorspaces\nsuch as $YC_{b}C_{r}$ and $CIELAB$, instead of making an additive perturbation\nor manipulating pixel values directly. In a targeted white-box attack setting,\nthe proposed method is able to obtain competitive fooling rates with very high\nconfidence. The experimental evaluations show that the proposed method has\nfavorable results in terms of approximate perceptual distance between benign\nand adversarially generated images. The source code is publicly available at\nhttps://github.com/ayberkydn/stadv-torch",
            "author": [
                "Ayberk Aydin",
                "Alptekin Temizel"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.patrec.2023.09.003",
                "http://arxiv.org/abs/2310.13950v1",
                "http://arxiv.org/pdf/2310.13950v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV",
                "I.5.0; I.4.0"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13948v1",
            "title": "Goal-oriented Communications for the IoT: System Design and Adaptive\n  Resource Optimization",
            "updated": "2023-10-21T09:05:36Z",
            "published": "2023-10-21T09:05:36Z",
            "summary": "Internet of Things (IoT) applications combine sensing, wireless\ncommunication, intelligence, and actuation, enabling the interaction among\nheterogeneous devices that collect and process considerable amounts of data.\nHowever, the effectiveness of IoT applications needs to face the limitation of\navailable resources, including spectrum, energy, computing, learning and\ninference capabilities. This paper challenges the prevailing approach to IoT\ncommunication, which prioritizes the usage of resources in order to guarantee\nperfect recovery, at the bit level, of the data transmitted by the sensors to\nthe central unit. We propose a novel approach, called goal-oriented (GO) IoT\nsystem design, that transcends traditional bit-related metrics and focuses\ndirectly on the fulfillment of the goal motivating the exchange of data. The\nimprovement is then achieved through a comprehensive system optimization,\nintegrating sensing, communication, computation, learning, and control. We\nprovide numerical results demonstrating the practical applications of our\nmethodology in compelling use cases such as edge inference, cooperative\nsensing, and federated learning. These examples highlight the effectiveness and\nreal-world implications of our proposed approach, with the potential to\nrevolutionize IoT systems.",
            "author": [
                "Paolo Di Lorenzo",
                "Mattia Merluzzi",
                "Francesco Binucci",
                "Claudio Battiloro",
                "Paolo Banelli",
                "Emilio Calvanese Strinati",
                "Sergio Barbarossa"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13948v1",
                "http://arxiv.org/pdf/2310.13948v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13947v2",
            "title": "Extreme Learning Machine-Assisted Solution of Biharmonic Equations via\n  Its Coupled Schemes",
            "updated": "2023-10-26T11:16:21Z",
            "published": "2023-10-21T09:04:24Z",
            "summary": "Obtaining the solutions of partial differential equations based on various\nmachine learning methods has drawn more and more attention in the fields of\nscientific computation and engineering applications. In this work, we first\npropose a coupled Extreme Learning Machine (called CELM) method incorporated\nwith the physical laws to solve a class of fourth-order biharmonic equations by\nreformulating it into two well-posed Poisson problems. In addition, some\nactivation functions including tangent, gauss, sine, and trigonometric\n(sin+cos) functions are introduced to assess our CELM method. Notably, the sine\nand trigonometric functions demonstrate a remarkable ability to effectively\nminimize the approximation error of the CELM model. In the end, several\nnumerical experiments are performed to study the initializing approaches for\nboth the weights and biases of the hidden units in our CELM model and explore\nthe required number of hidden units. Numerical results show the proposed CELM\nalgorithm is high-precision and efficient to address the biharmonic equation in\nboth regular and irregular domains.",
            "author": [
                "Xi'an Li",
                "Jinran Wu",
                "Jiaxin Deng",
                "Zhe Ding",
                "You-Gan Wang",
                "Xin Tai",
                "Liang Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13947v2",
                "http://arxiv.org/pdf/2310.13947v2"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA",
                "math-ph",
                "math.MP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13943v1",
            "title": "Heat diffusion blurs photothermal images with increasing depth",
            "updated": "2023-10-21T08:38:24Z",
            "published": "2023-10-21T08:38:24Z",
            "summary": "In this tutorial, we aim to directly recreate some of our \"aha\" moments when\nexploring the impact of heat diffusion on the spatial resolution limit of\nphotothermal imaging. Our objective is also to communicate how this physical\nlimit can nevertheless be overcome and include some concrete technological\napplications. Describing diffusion as a random walk, one insight is that such a\nstochastic process involves not only a Gaussian spread of the mean values in\nspace, with the variance proportional to the diffusion time, but also temporal\nand spatial fluctuations around these mean values. All these fluctuations\nstrongly influence the image reconstruction immediately after the short heating\npulse. The Gaussian spread of the mean values in space increases the entropy,\nwhile the fluctuations lead to a loss of information that blurs the\nreconstruction of the initial temperature distribution and can be described\nmathematically by a spatial convolution with a Gaussian thermal\npoint-spread-function (PSF). The information loss turns out to be equal to the\nmean entropy increase and limits the spatial resolution proportional to the\ndepth of the imaged subsurface structures. This principal resolution limit can\nonly be overcome by including additional information such as sparsity or\npositivity. Prior information can be also included by using a deep neural\nnetwork with a finite degrees of freedom and trained on a specific class of\nimage examples for image reconstruction.",
            "author": [
                "Peter Burgholzer",
                "G\u00fcnther Mayr",
                "Gregor Thummerer",
                "Markus Haltmeier"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13943v1",
                "http://arxiv.org/pdf/2310.13943v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13935v1",
            "title": "Toward Generative Data Augmentation for Traffic Classification",
            "updated": "2023-10-21T08:08:37Z",
            "published": "2023-10-21T08:08:37Z",
            "summary": "Data Augmentation (DA)-augmenting training data with synthetic samples-is\nwildly adopted in Computer Vision (CV) to improve models performance.\nConversely, DA has not been yet popularized in networking use cases, including\nTraffic Classification (TC). In this work, we present a preliminary study of 14\nhand-crafted DAs applied on the MIRAGE19 dataset. Our results (i) show that DA\ncan reap benefits previously unexplored in TC and (ii) foster a research agenda\non the use of generative models to automate DA design.",
            "author": [
                "Chao Wang",
                "Alessandro Finamore",
                "Pietro Michiardi",
                "Massimo Gallo",
                "Dario Rossi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13935v1",
                "http://arxiv.org/pdf/2310.13935v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13925v1",
            "title": "Meta-optimized Joint Generative and Contrastive Learning for Sequential\n  Recommendation",
            "updated": "2023-10-21T07:19:51Z",
            "published": "2023-10-21T07:19:51Z",
            "summary": "Sequential Recommendation (SR) has received increasing attention due to its\nability to capture user dynamic preferences. Recently, Contrastive Learning\n(CL) provides an effective approach for sequential recommendation by learning\ninvariance from different views of an input. However, most existing data or\nmodel augmentation methods may destroy semantic sequential interaction\ncharacteristics and often rely on the hand-crafted property of their\ncontrastive view-generation strategies. In this paper, we propose a\nMeta-optimized Seq2Seq Generator and Contrastive Learning (Meta-SGCL) for\nsequential recommendation, which applies the meta-optimized two-step training\nstrategy to adaptive generate contrastive views. Specifically, Meta-SGCL first\nintroduces a simple yet effective augmentation method called\nSequence-to-Sequence (Seq2Seq) generator, which treats the Variational\nAutoEncoders (VAE) as the view generator and can constitute contrastive views\nwhile preserving the original sequence's semantics. Next, the model employs a\nmeta-optimized two-step training strategy, which aims to adaptively generate\ncontrastive views without relying on manually designed view-generation\ntechniques. Finally, we evaluate our proposed method Meta-SGCL using three\npublic real-world datasets. Compared with the state-of-the-art methods, our\nexperimental results demonstrate the effectiveness of our model and the code is\navailable.",
            "author": [
                "Yongjing Hao",
                "Pengpeng Zhao",
                "Junhua Fang",
                "Jianfeng Qu",
                "Guanfeng Liu",
                "Fuzhen Zhuang",
                "Victor S. Sheng",
                "Xiaofang Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13925v1",
                "http://arxiv.org/pdf/2310.13925v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13923v2",
            "title": "Diversified Outlier Exposure for Out-of-Distribution Detection via\n  Informative Extrapolation",
            "updated": "2023-10-26T06:50:44Z",
            "published": "2023-10-21T07:16:09Z",
            "summary": "Out-of-distribution (OOD) detection is important for deploying reliable\nmachine learning models on real-world applications. Recent advances in outlier\nexposure have shown promising results on OOD detection via fine-tuning model\nwith informatively sampled auxiliary outliers. However, previous methods assume\nthat the collected outliers can be sufficiently large and representative to\ncover the boundary between ID and OOD data, which might be impractical and\nchallenging. In this work, we propose a novel framework, namely, Diversified\nOutlier Exposure (DivOE), for effective OOD detection via informative\nextrapolation based on the given auxiliary outliers. Specifically, DivOE\nintroduces a new learning objective, which diversifies the auxiliary\ndistribution by explicitly synthesizing more informative outliers for\nextrapolation during training. It leverages a multi-step optimization method to\ngenerate novel outliers beyond the original ones, which is compatible with many\nvariants of outlier exposure. Extensive experiments and analyses have been\nconducted to characterize and demonstrate the effectiveness of the proposed\nDivOE. The code is publicly available at: https://github.com/tmlr-group/DivOE.",
            "author": [
                "Jianing Zhu",
                "Geng Yu",
                "Jiangchao Yao",
                "Tongliang Liu",
                "Gang Niu",
                "Masashi Sugiyama",
                "Bo Han"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13923v2",
                "http://arxiv.org/pdf/2310.13923v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13922v1",
            "title": "Equivariant Map and Agent Geometry for Autonomous Driving Motion\n  Prediction",
            "updated": "2023-10-21T07:08:44Z",
            "published": "2023-10-21T07:08:44Z",
            "summary": "In autonomous driving, deep learning enabled motion prediction is a popular\ntopic. A critical gap in traditional motion prediction methodologies lies in\nensuring equivariance under Euclidean geometric transformations and maintaining\ninvariant interaction relationships. This research introduces a groundbreaking\nsolution by employing EqMotion, a theoretically geometric equivariant and\ninteraction invariant motion prediction model for particles and humans, plus\nintegrating agent-equivariant high-definition (HD) map features for context\naware motion prediction in autonomous driving. The use of EqMotion as backbone\nmarks a significant departure from existing methods by rigorously ensuring\nmotion equivariance and interaction invariance. Equivariance here implies that\nan output motion must be equally transformed under the same Euclidean\ntransformation as an input motion, while interaction invariance preserves the\nmanner in which agents interact despite transformations. These properties make\nthe network robust to arbitrary Euclidean transformations and contribute to\nmore accurate prediction. In addition, we introduce an equivariant method to\nprocess the HD map to enrich the spatial understanding of the network while\npreserving the overall network equivariance property. By applying these\ntechnologies, our model is able to achieve high prediction accuracy while\nmaintain a lightweight design and efficient data utilization.",
            "author": [
                "Yuping Wang",
                "Jier Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13922v1",
                "http://arxiv.org/pdf/2310.13922v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13921v1",
            "title": "UnifiedSSR: A Unified Framework of Sequential Search and Recommendation",
            "updated": "2023-10-21T06:56:01Z",
            "published": "2023-10-21T06:56:01Z",
            "summary": "In this work, we propose a Unified framework of Sequential Search and\nRecommendation (UnifiedSSR) for joint learning of user behavior history in both\nsearch and recommendation scenarios. Specifically, we consider user-interacted\nproducts in the recommendation scenario, user-interacted products and\nuser-issued queries in the search scenario as three distinct types of user\nbehaviors. We propose a dual-branch network to encode the pair of interacted\nproduct history and issued query history in the search scenario in parallel.\nThis allows for cross-scenario modeling by deactivating the query branch for\nthe recommendation scenario. Through the parameter sharing between dual\nbranches, as well as between product branches in two scenarios, we incorporate\ncross-view and cross-scenario associations of user behaviors, providing a\ncomprehensive understanding of user behavior patterns. To further enhance user\nbehavior modeling by capturing the underlying dynamic intent, an\nIntent-oriented Session Modeling module is designed for inferring\nintent-oriented semantic sessions from the contextual information in behavior\nsequences. In particular, we consider self-supervised learning signals from two\nperspectives for intent-oriented semantic session locating, which encourage\nsession discrimination within each behavior sequence and session alignment\nbetween dual behavior sequences. Extensive experiments on three public datasets\ndemonstrate that UnifiedSSR consistently outperforms state-of-the-art methods\nfor both search and recommendation.",
            "author": [
                "Jiayi Xie",
                "Shang Liu",
                "Gao Cong",
                "Zhenzhong Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13921v1",
                "http://arxiv.org/pdf/2310.13921v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13916v1",
            "title": "Southern Ocean Dynamics Under Climate Change: New Knowledge Through\n  Physics-Guided Machine Learning",
            "updated": "2023-10-21T06:13:19Z",
            "published": "2023-10-21T06:13:19Z",
            "summary": "Complex ocean systems such as the Antarctic Circumpolar Current play key\nroles in the climate, and current models predict shifts in their strength and\narea under climate change. However, the physical processes underlying these\nchanges are not well understood, in part due to the difficulty of\ncharacterizing and tracking changes in ocean physics in complex models. To\nunderstand changes in the Antarctic Circumpolar Current, we extend the method\nTracking global Heating with Ocean Regimes (THOR) to a mesoscale eddy\npermitting climate model and identify regions of the ocean characterized by\nsimilar physics, called dynamical regimes, using readily accessible fields from\nclimate models. To this end, we cluster grid cells into dynamical regimes and\ntrain an ensemble of neural networks to predict these regimes and track them\nunder climate change. Finally, we leverage this new knowledge to elucidate the\ndynamics of regime shifts. Here we illustrate the value of this high-resolution\nversion of THOR, which allows for mesoscale turbulence, with a case study of\nthe Antarctic Circumpolar Current and its interactions with the\nPacific-Antarctic Ridge. In this region, THOR specifically reveals a shift in\ndynamical regime under climate change driven by changes in wind stress and\ninteractions with bathymetry. Using this knowledge to guide further\nexploration, we find that as the Antarctic Circumpolar Current shifts north\nunder intensifying wind stress, the dominant dynamical role of bathymetry\nweakens and the flow strengthens.",
            "author": [
                "William Yik",
                "Maike Sonnewald",
                "Mariana C. A. Clare",
                "Redouane Lguensat"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13916v1",
                "http://arxiv.org/pdf/2310.13916v1"
            ],
            "primary_category": "physics.ao-ph",
            "category": [
                "physics.ao-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13914v1",
            "title": "Cold Diffusion on the Replay Buffer: Learning to Plan from Known Good\n  States",
            "updated": "2023-10-21T05:59:44Z",
            "published": "2023-10-21T05:59:44Z",
            "summary": "Learning from demonstrations (LfD) has successfully trained robots to exhibit\nremarkable generalization capabilities. However, many powerful imitation\ntechniques do not prioritize the feasibility of the robot behaviors they\ngenerate. In this work, we explore the feasibility of plans produced by LfD. As\nin prior work, we employ a temporal diffusion model with fixed start and goal\nstates to facilitate imitation through in-painting. Unlike previous studies, we\napply cold diffusion to ensure the optimization process is directed through the\nagent's replay buffer of previously visited states. This routing approach\nincreases the likelihood that the final trajectories will predominantly occupy\nthe feasible region of the robot's state space. We test this method in\nsimulated robotic environments with obstacles and observe a significant\nimprovement in the agent's ability to avoid these obstacles during planning.",
            "author": [
                "Zidan Wang",
                "Takeru Oba",
                "Takuma Yoneda",
                "Rui Shen",
                "Matthew Walter",
                "Bradly C. Stadie"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13914v1",
                "http://arxiv.org/pdf/2310.13914v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13913v2",
            "title": "Pre-Training on Large-Scale Generated Docking Conformations with\n  HelixDock to Unlock the Potential of Protein-ligand Structure Prediction\n  Models",
            "updated": "2023-11-15T02:29:25Z",
            "published": "2023-10-21T05:54:26Z",
            "summary": "Protein-ligand structure prediction is an essential task in drug discovery,\npredicting the binding interactions between small molecules (ligands) and\ntarget proteins (receptors). Although conventional physics-based docking tools\nare widely utilized, their accuracy is compromised by limited conformational\nsampling and imprecise scoring functions. Recent advances have incorporated\ndeep learning techniques to improve the accuracy of structure prediction.\nNevertheless, the experimental validation of docking conformations remains\ncostly, it raises concerns regarding the generalizability of these deep\nlearning-based methods due to the limited training data. In this work, we show\nthat by pre-training a geometry-aware SE(3)-Equivariant neural network on a\nlarge-scale docking conformation generated by traditional physics-based docking\ntools and then fine-tuning with a limited set of experimentally validated\nreceptor-ligand complexes, we can achieve outstanding performance. This process\ninvolved the generation of 100 million docking conformations, consuming roughly\n1 million CPU core days. The proposed model, HelixDock, aims to acquire the\nphysical knowledge encapsulated by the physics-based docking tools during the\npre-training phase. HelixDock has been benchmarked against both physics-based\nand deep learning-based baselines, showing that it outperforms its closest\ncompetitor by over 40% for RMSD. HelixDock also exhibits enhanced performance\non a dataset that poses a greater challenge, thereby highlighting its\nrobustness. Moreover, our investigation reveals the scaling laws governing\npre-trained structure prediction models, indicating a consistent enhancement in\nperformance with increases in model parameters and pre-training data. This\nstudy illuminates the strategic advantage of leveraging a vast and varied\nrepository of generated data to advance the frontiers of AI-driven drug\ndiscovery.",
            "author": [
                "Lihang Liu",
                "Donglong He",
                "Xianbin Ye",
                "Jingbo Zhou",
                "Shanzhuo Zhang",
                "Xiaonan Zhang",
                "Jun Li",
                "Hua Chai",
                "Fan Wang",
                "Jingzhou He",
                "Liang Zheng",
                "Yonghui Li",
                "Xiaomin Fang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13913v2",
                "http://arxiv.org/pdf/2310.13913v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CE",
                "q-bio.BM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13912v1",
            "title": "Learning Motion Refinement for Unsupervised Face Animation",
            "updated": "2023-10-21T05:52:25Z",
            "published": "2023-10-21T05:52:25Z",
            "summary": "Unsupervised face animation aims to generate a human face video based on the\nappearance of a source image, mimicking the motion from a driving video.\nExisting methods typically adopted a prior-based motion model (e.g., the local\naffine motion model or the local thin-plate-spline motion model). While it is\nable to capture the coarse facial motion, artifacts can often be observed\naround the tiny motion in local areas (e.g., lips and eyes), due to the limited\nability of these methods to model the finer facial motions. In this work, we\ndesign a new unsupervised face animation approach to learn simultaneously the\ncoarse and finer motions. In particular, while exploiting the local affine\nmotion model to learn the global coarse facial motion, we design a novel motion\nrefinement module to compensate for the local affine motion model for modeling\nfiner face motions in local areas. The motion refinement is learned from the\ndense correlation between the source and driving images. Specifically, we first\nconstruct a structure correlation volume based on the keypoint features of the\nsource and driving images. Then, we train a model to generate the tiny facial\nmotions iteratively from low to high resolution. The learned motion refinements\nare combined with the coarse motion to generate the new image. Extensive\nexperiments on widely used benchmarks demonstrate that our method achieves the\nbest results among state-of-the-art baselines.",
            "author": [
                "Jiale Tao",
                "Shuhang Gu",
                "Wen Li",
                "Lixin Duan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13912v1",
                "http://arxiv.org/pdf/2310.13912v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13901v1",
            "title": "Towards Hyperparameter-Agnostic DNN Training via Dynamical System\n  Insights",
            "updated": "2023-10-21T03:45:13Z",
            "published": "2023-10-21T03:45:13Z",
            "summary": "We present a stochastic first-order optimization method specialized for deep\nneural networks (DNNs), ECCO-DNN. This method models the optimization variable\ntrajectory as a dynamical system and develops a discretization algorithm that\nadaptively selects step sizes based on the trajectory's shape. This provides\ntwo key insights: designing the dynamical system for fast continuous-time\nconvergence and developing a time-stepping algorithm to adaptively select step\nsizes based on principles of numerical integration and neural network\nstructure. The result is an optimizer with performance that is insensitive to\nhyperparameter variations and that achieves comparable performance to\nstate-of-the-art optimizers including ADAM, SGD, RMSProp, and AdaGrad. We\ndemonstrate this in training DNN models and datasets, including CIFAR-10 and\nCIFAR-100 using ECCO-DNN and find that ECCO-DNN's single hyperparameter can be\nchanged by three orders of magnitude without affecting the trained models'\naccuracies. ECCO-DNN's insensitivity reduces the data and computation needed\nfor hyperparameter tuning, making it advantageous for rapid prototyping and for\napplications with new datasets. To validate the efficacy of our proposed\noptimizer, we train an LSTM architecture on a household power consumption\ndataset with ECCO-DNN and achieve an optimal mean-square-error without tuning\nhyperparameters.",
            "author": [
                "Carmel Fiscko",
                "Aayushya Agarwal",
                "Yihan Ruan",
                "Soummya Kar",
                "Larry Pileggi",
                "Bruno Sinopoli"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13901v1",
                "http://arxiv.org/pdf/2310.13901v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13897v1",
            "title": "Masked Hard-Attention Transformers and Boolean RASP Recognize Exactly\n  the Star-Free Languages",
            "updated": "2023-10-21T03:26:39Z",
            "published": "2023-10-21T03:26:39Z",
            "summary": "We consider transformer encoders with hard attention (in which all attention\nis focused on exactly one position) and strict future masking (in which each\nposition only attends to positions strictly to its left), and prove that the\nclass of languages recognized by these networks is exactly the star-free\nlanguages. Adding position embeddings increases the class of recognized\nlanguages to other well-studied classes. A key technique in these proofs is\nBoolean RASP, a variant of RASP that is restricted to Boolean values. Via the\nstar-free languages, we relate transformers to first-order logic, temporal\nlogic, and algebraic automata theory.",
            "author": [
                "Dana Angluin",
                "David Chiang",
                "Andy Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13897v1",
                "http://arxiv.org/pdf/2310.13897v1"
            ],
            "primary_category": "cs.FL",
            "category": [
                "cs.FL",
                "cs.LG",
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13895v1",
            "title": "RTSUM: Relation Triple-based Interpretable Summarization with\n  Multi-level Salience Visualization",
            "updated": "2023-10-21T02:46:03Z",
            "published": "2023-10-21T02:46:03Z",
            "summary": "In this paper, we present RTSUM, an unsupervised summarization framework that\nutilizes relation triples as the basic unit for summarization. Given an input\ndocument, RTSUM first selects salient relation triples via multi-level salience\nscoring and then generates a concise summary from the selected relation triples\nby using a text-to-text language model. On the basis of RTSUM, we also develop\na web demo for an interpretable summarizing tool, providing fine-grained\ninterpretations with the output summary. With support for customization\noptions, our tool visualizes the salience for textual units at three distinct\nlevels: sentences, relation triples, and phrases. The codes,are publicly\navailable.",
            "author": [
                "Seonglae Cho",
                "Yonggi Cho",
                "HoonJae Lee",
                "Myungha Jang",
                "Jinyoung Yeo",
                "Dongha Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13895v1",
                "http://arxiv.org/pdf/2310.13895v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13893v1",
            "title": "The Hidden Adversarial Vulnerabilities of Medical Federated Learning",
            "updated": "2023-10-21T02:21:39Z",
            "published": "2023-10-21T02:21:39Z",
            "summary": "In this paper, we delve into the susceptibility of federated medical image\nanalysis systems to adversarial attacks. Our analysis uncovers a novel\nexploitation avenue: using gradient information from prior global model\nupdates, adversaries can enhance the efficiency and transferability of their\nattacks. Specifically, we demonstrate that single-step attacks (e.g. FGSM),\nwhen aptly initialized, can outperform the efficiency of their iterative\ncounterparts but with reduced computational demand. Our findings underscore the\nneed to revisit our understanding of AI security in federated healthcare\nsettings.",
            "author": [
                "Erfan Darzi",
                "Florian Dubost",
                "Nanna. M. Sijtsema",
                "P. M. A van Ooijen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13893v1",
                "http://arxiv.org/pdf/2310.13893v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13892v1",
            "title": "Specify Robust Causal Representation from Mixed Observations",
            "updated": "2023-10-21T02:18:35Z",
            "published": "2023-10-21T02:18:35Z",
            "summary": "Learning representations purely from observations concerns the problem of\nlearning a low-dimensional, compact representation which is beneficial to\nprediction models. Under the hypothesis that the intrinsic latent factors\nfollow some casual generative models, we argue that by learning a causal\nrepresentation, which is the minimal sufficient causes of the whole system, we\ncan improve the robustness and generalization performance of machine learning\nmodels. In this paper, we develop a learning method to learn such\nrepresentation from observational data by regularizing the learning procedure\nwith mutual information measures, according to the hypothetical factored causal\ngraph. We theoretically and empirically show that the models trained with the\nlearned causal representations are more robust under adversarial attacks and\ndistribution shifts compared with baselines. The supplementary materials are\navailable at https://github.com/ymy $4323460 / \\mathrm{CaRI} /$.",
            "author": [
                "Mengyue Yang",
                "Xinyu Cai",
                "Furui Liu",
                "Weinan Zhang",
                "Jun Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13892v1",
                "http://arxiv.org/pdf/2310.13892v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13890v1",
            "title": "COVIDFakeExplainer: An Explainable Machine Learning based Web\n  Application for Detecting COVID-19 Fake News",
            "updated": "2023-10-21T02:11:39Z",
            "published": "2023-10-21T02:11:39Z",
            "summary": "Fake news has emerged as a critical global issue, magnified by the COVID-19\npandemic, underscoring the need for effective preventive tools. Leveraging\nmachine learning, including deep learning techniques, offers promise in\ncombatting fake news. This paper goes beyond by establishing BERT as the\nsuperior model for fake news detection and demonstrates its utility as a tool\nto empower the general populace. We have implemented a browser extension,\nenhanced with explainability features, enabling real-time identification of\nfake news and delivering easily interpretable explanations. To achieve this, we\nhave employed two publicly available datasets and created seven distinct data\nconfigurations to evaluate three prominent machine learning architectures. Our\ncomprehensive experiments affirm BERT's exceptional accuracy in detecting\nCOVID-19-related fake news. Furthermore, we have integrated an explainability\ncomponent into the BERT model and deployed it as a service through Amazon's\ncloud API hosting (AWS). We have developed a browser extension that interfaces\nwith the API, allowing users to select and transmit data from web pages,\nreceiving an intelligible classification in return. This paper presents a\npractical end-to-end solution, highlighting the feasibility of constructing a\nholistic system for fake news detection, which can significantly benefit\nsociety.",
            "author": [
                "Dylan Warman",
                "Muhammad Ashad Kabir"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13890v1",
                "http://arxiv.org/pdf/2310.13890v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "cs.AI",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13888v1",
            "title": "Towards a General Framework for Continual Learning with Pre-training",
            "updated": "2023-10-21T02:03:38Z",
            "published": "2023-10-21T02:03:38Z",
            "summary": "In this work, we present a general framework for continual learning of\nsequentially arrived tasks with the use of pre-training, which has emerged as a\npromising direction for artificial intelligence systems to accommodate\nreal-world dynamics. From a theoretical perspective, we decompose its objective\ninto three hierarchical components, including within-task prediction,\ntask-identity inference, and task-adaptive prediction. Then we propose an\ninnovative approach to explicitly optimize these components with\nparameter-efficient fine-tuning (PEFT) techniques and representation\nstatistics. We empirically demonstrate the superiority and generality of our\napproach in downstream continual learning, and further explore the\napplicability of PEFT techniques in upstream continual learning. We also\ndiscuss the biological basis of the proposed framework with recent advances in\nneuroscience.",
            "author": [
                "Liyuan Wang",
                "Jingyi Xie",
                "Xingxing Zhang",
                "Hang Su",
                "Jun Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13888v1",
                "http://arxiv.org/pdf/2310.13888v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13886v1",
            "title": "Optimal Transport-based Nonlinear Filtering in High-dimensional Settings",
            "updated": "2023-10-21T01:34:30Z",
            "published": "2023-10-21T01:34:30Z",
            "summary": "This paper addresses the problem of nonlinear filtering, i.e., computing the\nconditional distribution of the state of a stochastic dynamical system given a\nhistory of noisy partial observations. The primary focus is on scenarios\ninvolving degenerate likelihoods or high-dimensional states, where traditional\nsequential importance resampling (SIR) particle filters face the weight\ndegeneracy issue. Our proposed method builds on an optimal transport\ninterpretation of nonlinear filtering, leading to a simulation-based and\nlikelihood-free algorithm that estimates the Brenier optimal transport map from\nthe current distribution of the state to the distribution at the next time\nstep. Our formulation allows us to harness the approximation power of neural\nnetworks to model complex and multi-modal distributions and employ stochastic\noptimization algorithms to enhance scalability. Extensive numerical experiments\nare presented that compare our method to the SIR particle filter and the\nensemble Kalman filter, demonstrating the superior performance of our method in\nterms of sample efficiency, high-dimensional scalability, and the ability to\ncapture complex and multi-modal distributions.",
            "author": [
                "Mohammad Al-Jarrah",
                "Niyizhen Jin",
                "Bamdad Hosseini",
                "Amirhossein Taghvaei"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13886v1",
                "http://arxiv.org/pdf/2310.13886v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13876v1",
            "title": "Multimodal Transformer Using Cross-Channel attention for Object\n  Detection in Remote Sensing Images",
            "updated": "2023-10-21T00:56:11Z",
            "published": "2023-10-21T00:56:11Z",
            "summary": "Object detection in Remote Sensing Images (RSI) is a critical task for\nnumerous applications in Earth Observation (EO). Unlike general object\ndetection, object detection in RSI has specific challenges: 1) the scarcity of\nlabeled data in RSI compared to general object detection datasets, and 2) the\nsmall objects presented in a high-resolution image with a vast background. To\naddress these challenges, we propose a multimodal transformer exploring\nmulti-source remote sensing data for object detection. Instead of directly\ncombining the multimodal input through a channel-wise concatenation, which\nignores the heterogeneity of different modalities, we propose a cross-channel\nattention module. This module learns the relationship between different\nchannels, enabling the construction of a coherent multimodal input by aligning\nthe different modalities at the early stage. We also introduce a new\narchitecture based on the Swin transformer that incorporates convolution layers\nin non-shifting blocks while maintaining fixed dimensions, allowing for the\ngeneration of fine-to-coarse representations with a favorable\naccuracy-computation trade-off. The extensive experiments prove the\neffectiveness of the proposed multimodal fusion module and architecture,\ndemonstrating their applicability to multimodal aerial imagery.",
            "author": [
                "Bissmella Bahaduri",
                "Zuheng Ming",
                "Fangchen Feng",
                "Anissa Mokraou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13876v1",
                "http://arxiv.org/pdf/2310.13876v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13870v1",
            "title": "Fast Approximation of Similarity Graphs with Kernel Density Estimation",
            "updated": "2023-10-21T00:32:47Z",
            "published": "2023-10-21T00:32:47Z",
            "summary": "Constructing a similarity graph from a set $X$ of data points in\n$\\mathbb{R}^d$ is the first step of many modern clustering algorithms. However,\ntypical constructions of a similarity graph have high time complexity, and a\nquadratic space dependency with respect to $|X|$. We address this limitation\nand present a new algorithmic framework that constructs a sparse approximation\nof the fully connected similarity graph while preserving its cluster structure.\nOur presented algorithm is based on the kernel density estimation problem, and\nis applicable for arbitrary kernel functions. We compare our designed algorithm\nwith the well-known implementations from the scikit-learn library and the FAISS\nlibrary, and find that our method significantly outperforms the implementation\nfrom both libraries on a variety of datasets.",
            "author": [
                "Peter Macgregor",
                "He Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13870v1",
                "http://arxiv.org/pdf/2310.13870v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13863v1",
            "title": "Distributionally Robust Optimization with Bias and Variance Reduction",
            "updated": "2023-10-21T00:03:54Z",
            "published": "2023-10-21T00:03:54Z",
            "summary": "We consider the distributionally robust optimization (DRO) problem with\nspectral risk-based uncertainty set and $f$-divergence penalty. This\nformulation includes common risk-sensitive learning objectives such as\nregularized condition value-at-risk (CVaR) and average top-$k$ loss. We present\nProspect, a stochastic gradient-based algorithm that only requires tuning a\nsingle learning rate hyperparameter, and prove that it enjoys linear\nconvergence for smooth regularized losses. This contrasts with previous\nalgorithms that either require tuning multiple hyperparameters or potentially\nfail to converge due to biased gradient estimates or inadequate regularization.\nEmpirically, we show that Prospect can converge 2-3$\\times$ faster than\nbaselines such as stochastic gradient and stochastic saddle-point methods on\ndistribution shift and fairness benchmarks spanning tabular, vision, and\nlanguage domains.",
            "author": [
                "Ronak Mehta",
                "Vincent Roulet",
                "Krishna Pillutla",
                "Zaid Harchaoui"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13863v1",
                "http://arxiv.org/pdf/2310.13863v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13862v1",
            "title": "Competitive Advantage Attacks to Decentralized Federated Learning",
            "updated": "2023-10-20T23:57:57Z",
            "published": "2023-10-20T23:57:57Z",
            "summary": "Decentralized federated learning (DFL) enables clients (e.g., hospitals and\nbanks) to jointly train machine learning models without a central orchestration\nserver. In each global training round, each client trains a local model on its\nown training data and then they exchange local models for aggregation. In this\nwork, we propose SelfishAttack, a new family of attacks to DFL. In\nSelfishAttack, a set of selfish clients aim to achieve competitive advantages\nover the remaining non-selfish ones, i.e., the final learnt local models of the\nselfish clients are more accurate than those of the non-selfish ones. Towards\nthis goal, the selfish clients send carefully crafted local models to each\nremaining non-selfish one in each global training round. We formulate finding\nsuch local models as an optimization problem and propose methods to solve it\nwhen DFL uses different aggregation rules. Theoretically, we show that our\nmethods find the optimal solutions to the optimization problem. Empirically, we\nshow that SelfishAttack successfully increases the accuracy gap (i.e.,\ncompetitive advantage) between the final learnt local models of selfish clients\nand those of non-selfish ones. Moreover, SelfishAttack achieves larger accuracy\ngaps than poisoning attacks when extended to increase competitive advantages.",
            "author": [
                "Yuqi Jia",
                "Minghong Fang",
                "Neil Zhenqiang Gong"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13862v1",
                "http://arxiv.org/pdf/2310.13862v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16058v1",
            "title": "A Sparse Bayesian Learning for Diagnosis of Nonstationary and Spatially\n  Correlated Faults with Application to Multistation Assembly Systems",
            "updated": "2023-10-20T23:56:53Z",
            "published": "2023-10-20T23:56:53Z",
            "summary": "Sensor technology developments provide a basis for effective fault diagnosis\nin manufacturing systems. However, the limited number of sensors due to\nphysical constraints or undue costs hinders the accurate diagnosis in the\nactual process. In addition, time-varying operational conditions that generate\nnonstationary process faults and the correlation information in the process\nrequire to consider for accurate fault diagnosis in the manufacturing systems.\nThis article proposes a novel fault diagnosis method: clustering spatially\ncorrelated sparse Bayesian learning (CSSBL), and explicitly demonstrates its\napplicability in a multistation assembly system that is vulnerable to the above\nchallenges. Specifically, the method is based on a practical assumption that it\nwill likely have a few process faults (sparse). In addition, the hierarchical\nstructure of CSSBL has several parameterized prior distributions to address the\nabove challenges. As posterior distributions of process faults do not have\nclosed form, this paper derives approximate posterior distributions through\nVariational Bayes inference. The proposed method's efficacy is provided through\nnumerical and real-world case studies utilizing an actual autobody assembly\nsystem. The generalizability of the proposed method allows the technique to be\napplied in fault diagnosis in other domains, including communication and\nhealthcare systems.",
            "author": [
                "Jihoon Chung",
                "Zhenyu Kong"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16058v1",
                "http://arxiv.org/pdf/2310.16058v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15189v1",
            "title": "Towards Subject Agnostic Affective Emotion Recognition",
            "updated": "2023-10-20T23:44:34Z",
            "published": "2023-10-20T23:44:34Z",
            "summary": "This paper focuses on affective emotion recognition, aiming to perform in the\nsubject-agnostic paradigm based on EEG signals. However, EEG signals manifest\nsubject instability in subject-agnostic affective Brain-computer interfaces\n(aBCIs), which led to the problem of distributional shift. Furthermore, this\nproblem is alleviated by approaches such as domain generalisation and domain\nadaptation. Typically, methods based on domain adaptation confer comparatively\nbetter results than the domain generalisation methods but demand more\ncomputational resources given new subjects. We propose a novel framework,\nmeta-learning based augmented domain adaptation for subject-agnostic aBCIs. Our\ndomain adaptation approach is augmented through meta-learning, which consists\nof a recurrent neural network, a classifier, and a distributional shift\ncontroller based on a sum-decomposable function. Also, we present that a neural\nnetwork explicating a sum-decomposable function can effectively estimate the\ndivergence between varied domains. The network setting for augmented domain\nadaptation follows meta-learning and adversarial learning, where the controller\npromptly adapts to new domains employing the target data via a few\nself-adaptation steps in the test phase. Our proposed approach is shown to be\neffective in experiments on a public aBICs dataset and achieves similar\nperformance to state-of-the-art domain adaptation methods while avoiding the\nuse of additional computational resources.",
            "author": [
                "Amit Kumar Jaiswal",
                "Haiming Liu",
                "Prayag Tiwari"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15189v1",
                "http://arxiv.org/pdf/2310.15189v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.HC",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15188v1",
            "title": "Deep Learning Approaches for Dynamic Mechanical Analysis of Viscoelastic\n  Fiber Composites",
            "updated": "2023-10-20T23:33:27Z",
            "published": "2023-10-20T23:33:27Z",
            "summary": "The increased adoption of reinforced polymer (RP) composite materials, driven\nby eco-design standards, calls for a fine balance between lightness, stiffness,\nand effective vibration control. These materials are integral to enhancing\ncomfort, safety, and energy efficiency. Dynamic Mechanical Analysis (DMA)\ncharacterizes viscoelastic behavior, yet there's a growing interest in using\nMachine Learning (ML) to expedite the design and understanding of\nmicrostructures. In this paper we aim to map microstructures to their\nmechanical properties using deep neural networks, speeding up the process and\nallowing for the generation of microstructures from desired properties.",
            "author": [
                "Victor Hoffmann",
                "Ilias Nahmed",
                "Parisa Rastin",
                "Gu\u00e9na\u00ebl Cabanes",
                "Julien Boisse"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15188v1",
                "http://arxiv.org/pdf/2310.15188v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cond-mat.mtrl-sci",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13856v1",
            "title": "Implications of Annotation Artifacts in Edge Probing Test Datasets",
            "updated": "2023-10-20T23:19:35Z",
            "published": "2023-10-20T23:19:35Z",
            "summary": "Edge probing tests are classification tasks that test for grammatical\nknowledge encoded in token representations coming from contextual encoders such\nas large language models (LLMs). Many LLM encoders have shown high performance\nin EP tests, leading to conjectures about their ability to encode linguistic\nknowledge. However, a large body of research claims that the tests necessarily\ndo not measure the LLM's capacity to encode knowledge, but rather reflect the\nclassifiers' ability to learn the problem. Much of this criticism stems from\nthe fact that often the classifiers have very similar accuracy when an LLM vs a\nrandom encoder is used. Consequently, several modifications to the tests have\nbeen suggested, including information theoretic probes. We show that commonly\nused edge probing test datasets have various biases including memorization.\nWhen these biases are removed, the LLM encoders do show a significant\ndifference from the random ones, even with the simple non-information theoretic\nprobes.",
            "author": [
                "Sagnik Ray Choudhury",
                "Jushaan Kalra"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13856v1",
                "http://arxiv.org/pdf/2310.13856v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13854v1",
            "title": "Exponential weight averaging as damped harmonic motion",
            "updated": "2023-10-20T23:15:46Z",
            "published": "2023-10-20T23:15:46Z",
            "summary": "The exponential moving average (EMA) is a commonly used statistic for\nproviding stable estimates of stochastic quantities in deep learning\noptimization. Recently, EMA has seen considerable use in generative models,\nwhere it is computed with respect to the model weights, and significantly\nimproves the stability of the inference model during and after training. While\nthe practice of weight averaging at the end of training is well-studied and\nknown to improve estimates of local optima, the benefits of EMA over the course\nof training is less understood. In this paper, we derive an explicit connection\nbetween EMA and a damped harmonic system between two particles, where one\nparticle (the EMA weights) is drawn to the other (the model weights) via an\nidealized zero-length spring. We then leverage this physical analogy to analyze\nthe effectiveness of EMA, and propose an improved training algorithm, which we\ncall BELAY. Finally, we demonstrate theoretically and empirically several\nadvantages enjoyed by BELAY over standard EMA.",
            "author": [
                "Jonathan Patsenker",
                "Henry Li",
                "Yuval Kluger"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13854v1",
                "http://arxiv.org/pdf/2310.13854v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13852v1",
            "title": "Gradual Domain Adaptation: Theory and Algorithms",
            "updated": "2023-10-20T23:02:08Z",
            "published": "2023-10-20T23:02:08Z",
            "summary": "Unsupervised domain adaptation (UDA) adapts a model from a labeled source\ndomain to an unlabeled target domain in a one-off way. Though widely applied,\nUDA faces a great challenge whenever the distribution shift between the source\nand the target is large. Gradual domain adaptation (GDA) mitigates this\nlimitation by using intermediate domains to gradually adapt from the source to\nthe target domain. In this work, we first theoretically analyze gradual\nself-training, a popular GDA algorithm, and provide a significantly improved\ngeneralization bound compared with Kumar et al. (2020). Our theoretical\nanalysis leads to an interesting insight: to minimize the generalization error\non the target domain, the sequence of intermediate domains should be placed\nuniformly along the Wasserstein geodesic between the source and target domains.\nThe insight is particularly useful under the situation where intermediate\ndomains are missing or scarce, which is often the case in real-world\napplications. Based on the insight, we propose $\\textbf{G}$enerative Gradual\nD$\\textbf{O}$main $\\textbf{A}$daptation with Optimal $\\textbf{T}$ransport\n(GOAT), an algorithmic framework that can generate intermediate domains in a\ndata-dependent way. More concretely, we first generate intermediate domains\nalong the Wasserstein geodesic between two given consecutive domains in a\nfeature space, then apply gradual self-training to adapt the source-trained\nclassifier to the target along the sequence of intermediate domains.\nEmpirically, we demonstrate that our GOAT framework can improve the performance\nof standard GDA when the given intermediate domains are scarce, significantly\nbroadening the real-world application scenarios of GDA. Our code is available\nat https://github.com/yifei-he/GOAT.",
            "author": [
                "Yifei He",
                "Haoxiang Wang",
                "Bo Li",
                "Han Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13852v1",
                "http://arxiv.org/pdf/2310.13852v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13849v2",
            "title": "A Dual-Stream Neural Network Explains the Functional Segregation of\n  Dorsal and Ventral Visual Pathways in Human Brains",
            "updated": "2023-11-20T17:23:17Z",
            "published": "2023-10-20T22:47:40Z",
            "summary": "The human visual system uses two parallel pathways for spatial processing and\nobject recognition. In contrast, computer vision systems tend to use a single\nfeedforward pathway, rendering them less robust, adaptive, or efficient than\nhuman vision. To bridge this gap, we developed a dual-stream vision model\ninspired by the human eyes and brain. At the input level, the model samples two\ncomplementary visual patterns to mimic how the human eyes use magnocellular and\nparvocellular retinal ganglion cells to separate retinal inputs to the brain.\nAt the backend, the model processes the separate input patterns through two\nbranches of convolutional neural networks (CNN) to mimic how the human brain\nuses the dorsal and ventral cortical pathways for parallel visual processing.\nThe first branch (WhereCNN) samples a global view to learn spatial attention\nand control eye movements. The second branch (WhatCNN) samples a local view to\nrepresent the object around the fixation. Over time, the two branches interact\nrecurrently to build a scene representation from moving fixations. We compared\nthis model with the human brains processing the same movie and evaluated their\nfunctional alignment by linear transformation. The WhereCNN and WhatCNN\nbranches were found to differentially match the dorsal and ventral pathways of\nthe visual cortex, respectively, primarily due to their different learning\nobjectives. These model-based results lead us to speculate that the distinct\nresponses and representations of the ventral and dorsal streams are more\ninfluenced by their distinct goals in visual attention and object recognition\nthan by their specific bias or selectivity in retinal inputs. This dual-stream\nmodel takes a further step in brain-inspired computer vision, enabling parallel\nneural networks to actively explore and understand the visual surroundings.",
            "author": [
                "Minkyu Choi",
                "Kuan Han",
                "Xiaokai Wang",
                "Yizhen Zhang",
                "Zhongming Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13849v2",
                "http://arxiv.org/pdf/2310.13849v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13845v1",
            "title": "Augment with Care: Enhancing Graph Contrastive Learning with Selective\n  Spectrum Perturbation",
            "updated": "2023-10-20T22:39:07Z",
            "published": "2023-10-20T22:39:07Z",
            "summary": "In recent years, Graph Contrastive Learning (GCL) has shown remarkable\neffectiveness in learning representations on graphs. As a component of GCL,\ngood augmentation views are supposed to be invariant to the important\ninformation while discarding the unimportant part. Existing augmentation views\nwith perturbed graph structures are usually based on random topology corruption\nin the spatial domain; however, from perspectives of the spectral domain, this\napproach may be ineffective as it fails to pose tailored impacts on the\ninformation of different frequencies, thus weakening the agreement between the\naugmentation views. By a preliminary experiment, we show that the impacts\ncaused by spatial random perturbation are approximately evenly distributed\namong frequency bands, which may harm the invariance of augmentations required\nby contrastive learning frameworks. To address this issue, we argue that the\nperturbation should be selectively posed on the information concerning\ndifferent frequencies. In this paper, we propose GASSER which poses tailored\nperturbation on the specific frequencies of graph structures in spectral\ndomain, and the edge perturbation is selectively guided by the spectral hints.\nAs shown by extensive experiments and theoretical analysis, the augmentation\nviews are adaptive and controllable, as well as heuristically fitting the\nhomophily ratios and spectrum of graph structures.",
            "author": [
                "Kaiqi Yang",
                "Haoyu Han",
                "Wei Jin",
                "Hui Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13845v1",
                "http://arxiv.org/pdf/2310.13845v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13841v1",
            "title": "Fast hyperboloid decision tree algorithms",
            "updated": "2023-10-20T22:31:10Z",
            "published": "2023-10-20T22:31:10Z",
            "summary": "Hyperbolic geometry is gaining traction in machine learning for its\neffectiveness at capturing hierarchical structures in real-world data.\nHyperbolic spaces, where neighborhoods grow exponentially, offer substantial\nadvantages and consistently deliver state-of-the-art results across diverse\napplications. However, hyperbolic classifiers often grapple with computational\nchallenges. Methods reliant on Riemannian optimization frequently exhibit\nsluggishness, stemming from the increased computational demands of operations\non Riemannian manifolds. In response to these challenges, we present hyperDT, a\nnovel extension of decision tree algorithms into hyperbolic space. Crucially,\nhyperDT eliminates the need for computationally intensive Riemannian\noptimization, numerically unstable exponential and logarithmic maps, or\npairwise comparisons between points by leveraging inner products to adapt\nEuclidean decision tree algorithms to hyperbolic space. Our approach is\nconceptually straightforward and maintains constant-time decision complexity\nwhile mitigating the scalability issues inherent in high-dimensional Euclidean\nspaces. Building upon hyperDT we introduce hyperRF, a hyperbolic random forest\nmodel. Extensive benchmarking across diverse datasets underscores the superior\nperformance of these models, providing a swift, precise, accurate, and\nuser-friendly toolkit for hyperbolic data analysis.",
            "author": [
                "Philippe Chlenski",
                "Ethan Turok",
                "Antonio Moretti",
                "Itsik Pe'er"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13841v1",
                "http://arxiv.org/pdf/2310.13841v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13839v1",
            "title": "Dark matter distribution in Milky Way-analog galaxies",
            "updated": "2023-10-20T22:28:16Z",
            "published": "2023-10-20T22:28:16Z",
            "summary": "Our current understanding of how dark matter (DM) is distributed within the\nMilky Way (MW) halo, particularly in the solar neighborhood, is based on either\ncareful studies of the local stellar orbits or model assumptions on the global\nshape of the MW halo. In this work, we undertake a study of external galaxies,\nwith the intent of providing insight to the DM distribution in MW-analog\ngalaxies. For this, we carefully select a sample of galaxies similar to the MW,\nbased on maximum atomic hydrogen (HI) rotational velocity (v=200-280 km s^{-1})\nand morphological type (Sab-Sbc) criteria. With a need for deep,\nhighly-resolved HI, our resulting sample is composed of 5 galaxies from the\nVIVA and THINGS surveys. To perform our baryonic analysis, we use deep Spitzer\nmid-IR images at 3.6 and 4.5 {\\mu}m from the S4G survey. Based on the dynamical\nthree-dimensional modeling software 3D-Barolo, we construct RCs and derive the\ngas and stellar contributions from the galaxy\\'s gaseous- and stellar-disks\nmass surface density profiles. Through a careful decomposition of their\nrotation curves into their baryonic (stars, gas) and DM components, we isolate\nthe DM contribution by using an MCMC-based approach. Based on the Sun\\'s\nlocation and the MW\\'s R_{25}, we define the corresponding location of the\nsolar neighborhood in these systems. We put forward a window for the DM density\n(\\rho=0.21-0.46 GeV cm^{-3}) at these galactocentric distances in our MW analog\nsample, consistent with the values found for the MW\\'s local DM density, based\non more traditional approaches found in the literature.",
            "author": [
                "Natanael Gomes-Oliveira",
                "K. Men\u00e9ndez-Delmestre",
                "T. S. Gon\u00e7alves",
                "D. C. Rodrigues",
                "M. Grossi",
                "N. Garavito-Camargo",
                "A. Ara\u00fajo",
                "P. P. B. Beaklini",
                "Y. Cavalcante-Coelho",
                "A. Cortesi",
                "L. H. Queiroga-Nu\u00f1ez",
                "T. Randriamampandry"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13839v1",
                "http://arxiv.org/pdf/2310.13839v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA",
                "astro-ph.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13838v1",
            "title": "CNN-based Prediction of Partition Path for VVC Fast Inter Partitioning\n  Using Motion Fields",
            "updated": "2023-10-20T22:26:49Z",
            "published": "2023-10-20T22:26:49Z",
            "summary": "The Versatile Video Coding (VVC) standard has been recently finalized by the\nJoint Video Exploration Team (JVET). Compared to the High Efficiency Video\nCoding (HEVC) standard, VVC offers about 50% compression efficiency gain, in\nterms of Bjontegaard Delta-Rate (BD-rate), at the cost of a 10-fold increase in\nencoding complexity. In this paper, we propose a method based on Convolutional\nNeural Network (CNN) to speed up the inter partitioning process in VVC.\nFirstly, a novel representation for the quadtree with nested multi-type tree\n(QTMT) partition is introduced, derived from the partition path. Secondly, we\ndevelop a U-Net-based CNN taking a multi-scale motion vector field as input at\nthe Coding Tree Unit (CTU) level. The purpose of CNN inference is to predict\nthe optimal partition path during the Rate-Distortion Optimization (RDO)\nprocess. To achieve this, we divide CTU into grids and predict the Quaternary\nTree (QT) depth and Multi-type Tree (MT) split decisions for each cell of the\ngrid. Thirdly, an efficient partition pruning algorithm is introduced to employ\nthe CNN predictions at each partitioning level to skip RDO evaluations of\nunnecessary partition paths. Finally, an adaptive threshold selection scheme is\ndesigned, making the trade-off between complexity and efficiency scalable.\nExperiments show that the proposed method can achieve acceleration ranging from\n16.5% to 60.2% under the RandomAccess Group Of Picture 32 (RAGOP32)\nconfiguration with a reasonable efficiency drop ranging from 0.44% to 4.59% in\nterms of BD-rate, which surpasses other state-of-the-art solutions.\nAdditionally, our method stands out as one of the lightest approaches in the\nfield, which ensures its applicability to other encoders.",
            "author": [
                "Yiqun Liu",
                "Marc Riviere",
                "Thomas Guionnet",
                "Aline Roumy",
                "Christine Guillemot"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13838v1",
                "http://arxiv.org/pdf/2310.13838v1"
            ],
            "primary_category": "cs.MM",
            "category": [
                "cs.MM",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13836v1",
            "title": "Foundation Model's Embedded Representations May Detect Distribution\n  Shift",
            "updated": "2023-10-20T22:20:50Z",
            "published": "2023-10-20T22:20:50Z",
            "summary": "Distribution shifts between train and test datasets obscure our ability to\nunderstand the generalization capacity of neural network models. This topic is\nespecially relevant given the success of pre-trained foundation models as\nstarting points for transfer learning (TL) models across tasks and contexts. We\npresent a case study for TL on a pre-trained GPT-2 model onto the Sentiment140\ndataset for sentiment classification. We show that Sentiment140's test dataset\n$M$ is not sampled from the same distribution as the training dataset $P$, and\nhence training on $P$ and measuring performance on $M$ does not actually\naccount for the model's generalization on sentiment classification.",
            "author": [
                "Adam Tsou",
                "Max Vargas",
                "Andrew Engel",
                "Tony Chiang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13836v1",
                "http://arxiv.org/pdf/2310.13836v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13833v1",
            "title": "GraphMaker: Can Diffusion Models Generate Large Attributed Graphs?",
            "updated": "2023-10-20T22:12:46Z",
            "published": "2023-10-20T22:12:46Z",
            "summary": "Large-scale graphs with node attributes are fundamental in real-world\nscenarios, such as social and financial networks. The generation of synthetic\ngraphs that emulate real-world ones is pivotal in graph machine learning,\naiding network evolution understanding and data utility preservation when\noriginal data cannot be shared. Traditional models for graph generation suffer\nfrom limited model capacity. Recent developments in diffusion models have shown\npromise in merely graph structure generation or the generation of small\nmolecular graphs with attributes. However, their applicability to large\nattributed graphs remains unaddressed due to challenges in capturing intricate\npatterns and scalability. This paper introduces GraphMaker, a novel diffusion\nmodel tailored for generating large attributed graphs. We study the diffusion\nmodels that either couple or decouple graph structure and node attribute\ngeneration to address their complex correlation. We also employ node-level\nconditioning and adopt a minibatch strategy for scalability. We further propose\na new evaluation pipeline using models trained on generated synthetic graphs\nand tested on original graphs to evaluate the quality of synthetic data.\nEmpirical evaluations on real-world datasets showcase GraphMaker's superiority\nin generating realistic and diverse large-attributed graphs beneficial for\ndownstream tasks.",
            "author": [
                "Mufei Li",
                "Eleonora Krea\u010di\u0107",
                "Vamsi K. Potluru",
                "Pan Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13833v1",
                "http://arxiv.org/pdf/2310.13833v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13831v2",
            "title": "Transformers for Trajectory Optimization with Application to Spacecraft\n  Rendezvous",
            "updated": "2023-12-06T18:06:21Z",
            "published": "2023-10-20T22:10:00Z",
            "summary": "Reliable and efficient trajectory optimization methods are a fundamental need\nfor autonomous dynamical systems, effectively enabling applications including\nrocket landing, hypersonic reentry, spacecraft rendezvous, and docking. Within\nsuch safety-critical application areas, the complexity of the emerging\ntrajectory optimization problems has motivated the application of AI-based\ntechniques to enhance the performance of traditional approaches. However,\ncurrent AI-based methods either attempt to fully replace traditional control\nalgorithms, thus lacking constraint satisfaction guarantees and incurring in\nexpensive simulation, or aim to solely imitate the behavior of traditional\nmethods via supervised learning. To address these limitations, this paper\nproposes the Autonomous Rendezvous Transformer (ART) and assesses the\ncapability of modern generative models to solve complex trajectory optimization\nproblems, both from a forecasting and control standpoint. Specifically, this\nwork assesses the capabilities of Transformers to (i) learn near-optimal\npolicies from previously collected data, and (ii) warm-start a sequential\noptimizer for the solution of non-convex optimal control problems, thus\nguaranteeing hard constraint satisfaction. From a forecasting perspective,\nresults highlight how ART outperforms other learning-based architectures at\npredicting known fuel-optimal trajectories. From a control perspective,\nempirical analyses show how policies learned through Transformers are able to\ngenerate near-optimal warm-starts, achieving trajectories that are (i) more\nfuel-efficient, (ii) obtained in fewer sequential optimizer iterations, and\n(iii) computed with an overall runtime comparable to benchmarks based on convex\noptimization.",
            "author": [
                "Tommaso Guffanti",
                "Daniele Gammelli",
                "Simone D'Amico",
                "Marco Pavone"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13831v2",
                "http://arxiv.org/pdf/2310.13831v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13830v1",
            "title": "ML-Based Feedback-Free Adaptive MCS Selection for Massive Multi-User\n  MIMO",
            "updated": "2023-10-20T22:06:59Z",
            "published": "2023-10-20T22:06:59Z",
            "summary": "As wireless communication systems strive to improve spectral efficiency,\nthere has been a growing interest in employing machine learning (ML)-based\napproaches for adaptive modulation and coding scheme (MCS) selection. In this\npaper, we introduce a new adaptive MCS selection framework for massive MIMO\nsystems that operates without any feedback from users by solely relying on\ninstantaneous uplink channel estimates. Our proposed method can effectively\noperate in multi-user scenarios where user feedback imposes excessive delay and\nbandwidth overhead. To learn the mapping between the user channel matrices and\nthe optimal MCS level of each user, we develop a Convolutional Neural Network\n(CNN)-Long Short-Term Memory Network (LSTM)-based model and compare the\nperformance with the state-of-the-art methods. Finally, we validate the\neffectiveness of our algorithm by evaluating it experimentally using real-world\ndatasets collected from the RENEW massive MIMO platform.",
            "author": [
                "Qing An",
                "Mehdi Zafari",
                "Chris Dick",
                "Santiago Segarra",
                "Ashutosh Sabharwal",
                "Rahman Doost-Mohammady"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13830v1",
                "http://arxiv.org/pdf/2310.13830v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13829v1",
            "title": "Universal Representation of Permutation-Invariant Functions on Vectors\n  and Tensors",
            "updated": "2023-10-20T22:00:59Z",
            "published": "2023-10-20T22:00:59Z",
            "summary": "A main object of our study is multiset functions -- that is,\npermutation-invariant functions over inputs of varying sizes. Deep Sets,\nproposed by \\cite{zaheer2017deep}, provides a \\emph{universal representation}\nfor continuous multiset functions on scalars via a sum-decomposable model.\nRestricting the domain of the functions to finite multisets of $D$-dimensional\nvectors, Deep Sets also provides a \\emph{universal approximation} that requires\na latent space dimension of $O(N^D)$ -- where $N$ is an upper bound on the size\nof input multisets. In this paper, we strengthen this result by proving that\nuniversal representation is guaranteed for continuous and discontinuous\nmultiset functions though a latent space dimension of $O(N^D)$. We then\nintroduce \\emph{identifiable} multisets for which we can uniquely label their\nelements using an identifier function, namely, finite-precision vectors are\nidentifiable. Using our analysis on identifiable multisets, we prove that a\nsum-decomposable model for general continuous multiset functions only requires\na latent dimension of $2DN$. We further show that both encoder and decoder\nfunctions of the model are continuous -- our main contribution to the existing\nwork which lack such a guarantee. Also this provides a significant improvement\nover the aforementioned $O(N^D)$ bound which was derived for universal\nrepresentation of continuous and discontinuous multiset functions. We then\nextend our results and provide special sum-decomposition structures to\nuniversally represent permutation-invariant tensor functions on identifiable\ntensors. These families of sum-decomposition models enables us to design deep\nnetwork architectures and deploy them on a variety of learning tasks on\nsequences, images, and graphs.",
            "author": [
                "Puoya Tabaghi",
                "Yusu Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13829v1",
                "http://arxiv.org/pdf/2310.13829v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13828v1",
            "title": "Prompt-Specific Poisoning Attacks on Text-to-Image Generative Models",
            "updated": "2023-10-20T21:54:10Z",
            "published": "2023-10-20T21:54:10Z",
            "summary": "Data poisoning attacks manipulate training data to introduce unexpected\nbehaviors into machine learning models at training time. For text-to-image\ngenerative models with massive training datasets, current understanding of\npoisoning attacks suggests that a successful attack would require injecting\nmillions of poison samples into their training pipeline. In this paper, we show\nthat poisoning attacks can be successful on generative models. We observe that\ntraining data per concept can be quite limited in these models, making them\nvulnerable to prompt-specific poisoning attacks, which target a model's ability\nto respond to individual prompts.\n  We introduce Nightshade, an optimized prompt-specific poisoning attack where\npoison samples look visually identical to benign images with matching text\nprompts. Nightshade poison samples are also optimized for potency and can\ncorrupt an Stable Diffusion SDXL prompt in <100 poison samples. Nightshade\npoison effects \"bleed through\" to related concepts, and multiple attacks can\ncomposed together in a single prompt. Surprisingly, we show that a moderate\nnumber of Nightshade attacks can destabilize general features in a\ntext-to-image generative model, effectively disabling its ability to generate\nmeaningful images. Finally, we propose the use of Nightshade` and similar tools\nas a last defense for content creators against web scrapers that ignore\nopt-out/do-not-crawl directives, and discuss possible implications for model\ntrainers and content creators.",
            "author": [
                "Shawn Shan",
                "Wenxin Ding",
                "Josephine Passananti",
                "Haitao Zheng",
                "Ben Y. Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13828v1",
                "http://arxiv.org/pdf/2310.13828v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13822v1",
            "title": "Adversarial Attacks on Fairness of Graph Neural Networks",
            "updated": "2023-10-20T21:19:54Z",
            "published": "2023-10-20T21:19:54Z",
            "summary": "Fairness-aware graph neural networks (GNNs) have gained a surge of attention\nas they can reduce the bias of predictions on any demographic group (e.g.,\nfemale) in graph-based applications. Although these methods greatly improve the\nalgorithmic fairness of GNNs, the fairness can be easily corrupted by carefully\ndesigned adversarial attacks. In this paper, we investigate the problem of\nadversarial attacks on fairness of GNNs and propose G-FairAttack, a general\nframework for attacking various types of fairness-aware GNNs in terms of\nfairness with an unnoticeable effect on prediction utility. In addition, we\npropose a fast computation technique to reduce the time complexity of\nG-FairAttack. The experimental study demonstrates that G-FairAttack\nsuccessfully corrupts the fairness of different types of GNNs while keeping the\nattack unnoticeable. Our study on fairness attacks sheds light on potential\nvulnerabilities in fairness-aware GNNs and guides further research on the\nrobustness of GNNs in terms of fairness. The open-source code is available at\nhttps://github.com/zhangbinchi/G-FairAttack.",
            "author": [
                "Binchi Zhang",
                "Yushun Dong",
                "Chen Chen",
                "Yada Zhu",
                "Minnan Luo",
                "Jundong Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13822v1",
                "http://arxiv.org/pdf/2310.13822v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13821v1",
            "title": "Geometric Learning with Positively Decomposable Kernels",
            "updated": "2023-10-20T21:18:04Z",
            "published": "2023-10-20T21:18:04Z",
            "summary": "Kernel methods are powerful tools in machine learning. Classical kernel\nmethods are based on positive-definite kernels, which map data spaces into\nreproducing kernel Hilbert spaces (RKHS). For non-Euclidean data spaces,\npositive-definite kernels are difficult to come by. In this case, we propose\nthe use of reproducing kernel Krein space (RKKS) based methods, which require\nonly kernels that admit a positive decomposition. We show that one does not\nneed to access this decomposition in order to learn in RKKS. We then\ninvestigate the conditions under which a kernel is positively decomposable. We\nshow that invariant kernels admit a positive decomposition on homogeneous\nspaces under tractable regularity assumptions. This makes them much easier to\nconstruct than positive-definite kernels, providing a route for learning with\nkernels for non-Euclidean data. By the same token, this provides theoretical\nfoundations for RKKS-based methods in general.",
            "author": [
                "Nathael Da Costa",
                "Cyrus Mostajeran",
                "Juan-Pablo Ortega",
                "Salem Said"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13821v1",
                "http://arxiv.org/pdf/2310.13821v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.DG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13820v1",
            "title": "FERI: A Multitask-based Fairness Achieving Algorithm with Applications\n  to Fair Organ Transplantation",
            "updated": "2023-10-20T21:14:07Z",
            "published": "2023-10-20T21:14:07Z",
            "summary": "Liver transplantation often faces fairness challenges across subgroups\ndefined by sensitive attributes like age group, gender, and race/ethnicity.\nMachine learning models for outcome prediction can introduce additional biases.\nTo address these, we introduce Fairness through the Equitable Rate of\nImprovement in Multitask Learning (FERI) algorithm for fair predictions of\ngraft failure risk in liver transplant patients. FERI constrains subgroup loss\nby balancing learning rates and preventing subgroup dominance in the training\nprocess. Our experiments show that FERI maintains high predictive accuracy with\nAUROC and AUPRC comparable to baseline models. More importantly, FERI\ndemonstrates an ability to improve fairness without sacrificing accuracy.\nSpecifically, for gender, FERI reduces the demographic parity disparity by\n71.74%, and for the age group, it decreases the equalized odds disparity by\n40.46%. Therefore, the FERI algorithm advances fairness-aware predictive\nmodeling in healthcare and provides an invaluable tool for equitable healthcare\nsystems.",
            "author": [
                "Can Li",
                "Dejian Lai",
                "Xiaoqian Jiang",
                "Kai Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13820v1",
                "http://arxiv.org/pdf/2310.13820v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13819v1",
            "title": "LanPose: Language-Instructed 6D Object Pose Estimation for Robotic\n  Assembly",
            "updated": "2023-10-20T21:12:39Z",
            "published": "2023-10-20T21:12:39Z",
            "summary": "Comprehending natural language instructions is a critical skill for robots to\ncooperate effectively with humans. In this paper, we aim to learn 6D poses for\nroboticassembly by natural language instructions. For this purpose,\nLanguage-Instructed 6D Pose Regression Network (LanPose) is proposed to jointly\npredict the 6D poses of the observed object and the corresponding assembly\nposition. Our proposed approach is based on the fusion of geometric and\nlinguistic features, which allows us to finely integrate multi-modality input\nand map it to the 6D pose in SE(3) space by the cross-attention mechanism and\nthe language-integrated 6D pose mapping module, respectively. To validate the\neffectiveness of our approach, an integrated robotic system is established to\nprecisely and robustly perceive, grasp, manipulate and assemble blocks by\nlanguage commands. 98.09 and 93.55 in ADD(-S)-0.1d are derived for the\nprediction of 6D object pose and 6D assembly pose, respectively. Both\nquantitative and qualitative results demonstrate the effectiveness of our\nproposed language-instructed 6D pose estimation methodology and its potential\nto enable robots to better understand and execute natural language\ninstructions.",
            "author": [
                "Bowen Fu",
                "Sek Kun Leong",
                "Yan Di",
                "Jiwen Tang",
                "Xiangyang Ji"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13819v1",
                "http://arxiv.org/pdf/2310.13819v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13818v1",
            "title": "FATA-Trans: Field And Time-Aware Transformer for Sequential Tabular Data",
            "updated": "2023-10-20T21:12:11Z",
            "published": "2023-10-20T21:12:11Z",
            "summary": "Sequential tabular data is one of the most commonly used data types in\nreal-world applications. Different from conventional tabular data, where rows\nin a table are independent, sequential tabular data contains rich contextual\nand sequential information, where some fields are dynamically changing over\ntime and others are static. Existing transformer-based approaches analyzing\nsequential tabular data overlook the differences between dynamic and static\nfields by replicating and filling static fields into each transformer, and\nignore temporal information between rows, which leads to three major\ndisadvantages: (1) computational overhead, (2) artificially simplified data for\nmasked language modeling pre-training task that may yield less meaningful\nrepresentations, and (3) disregarding the temporal behavioral patterns implied\nby time intervals. In this work, we propose FATA-Trans, a model with two field\ntransformers for modeling sequential tabular data, where each processes static\nand dynamic field information separately. FATA-Trans is field- and time-aware\nfor sequential tabular data. The field-type embedding in the method enables\nFATA-Trans to capture differences between static and dynamic fields. The\ntime-aware position embedding exploits both order and time interval information\nbetween rows, which helps the model detect underlying temporal behavior in a\nsequence. Our experiments on three benchmark datasets demonstrate that the\nlearned representations from FATA-Trans consistently outperform\nstate-of-the-art solutions in the downstream tasks. We also present\nvisualization studies to highlight the insights captured by the learned\nrepresentations, enhancing our understanding of the underlying data. Our codes\nare available at https://github.com/zdy93/FATA-Trans.",
            "author": [
                "Dongyu Zhang",
                "Liang Wang",
                "Xin Dai",
                "Shubham Jain",
                "Junpeng Wang",
                "Yujie Fan",
                "Chin-Chia Michael Yeh",
                "Yan Zheng",
                "Zhongfang Zhuang",
                "Wei Zhang"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3583780.3614879",
                "http://arxiv.org/abs/2310.13818v1",
                "http://arxiv.org/pdf/2310.13818v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13817v1",
            "title": "Deep Learning Based Forecasting-Aided State Estimation in Active\n  Distribution Networks",
            "updated": "2023-10-20T21:10:42Z",
            "published": "2023-10-20T21:10:42Z",
            "summary": "Operating an active distribution network (ADN) in the absence of enough\nmeasurements, the presence of distributed energy resources, and poor knowledge\nof responsive demand behaviour is a huge challenge. This paper introduces\nsystematic modelling of demand response behaviour which is then included in\nForecasting Aided State Estimation (FASE) for better control of the network.\nThere are several innovative elements in tuning parameters of FASE-based,\ndemand profiling, and aggregation. The comprehensive case studies for three UK\nrepresentative demand scenarios in 2023, 2035, and 2050 demonstrated the\neffectiveness of the proposed approach.",
            "author": [
                "Malek Alduhaymi",
                "Ravindra Singh",
                "Firdous Ul Nazir",
                "Bikash C. Pal"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13817v1",
                "http://arxiv.org/pdf/2310.13817v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13810v2",
            "title": "A Better Match for Drivers and Riders: Reinforcement Learning at Lyft",
            "updated": "2023-11-14T02:30:34Z",
            "published": "2023-10-20T20:49:06Z",
            "summary": "To better match drivers to riders in our ridesharing application, we revised\nLyft's core matching algorithm. We use a novel online reinforcement learning\napproach that estimates the future earnings of drivers in real time and use\nthis information to find more efficient matches. This change was the first\ndocumented implementation of a ridesharing matching algorithm that can learn\nand improve in real time. We evaluated the new approach during weeks of\nswitchback experimentation in most Lyft markets, and estimated how it benefited\ndrivers, riders, and the platform. In particular, it enabled our drivers to\nserve millions of additional riders each year, leading to more than $30 million\nper year in incremental revenue. Lyft rolled out the algorithm globally in\n2021.",
            "author": [
                "Xabi Azagirre",
                "Akshay Balwally",
                "Guillaume Candeli",
                "Nicholas Chamandy",
                "Benjamin Han",
                "Alona King",
                "Hyungjun Lee",
                "Martin Loncaric",
                "Sebastien Martin",
                "Vijay Narasiman",
                "Zhiwei",
                "Qin",
                "Baptiste Richard",
                "Sara Smoot",
                "Sean Taylor",
                "Garrett van Ryzin",
                "Di Wu",
                "Fei Yu",
                "Alex Zamoshchin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13810v2",
                "http://arxiv.org/pdf/2310.13810v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13809v1",
            "title": "Enhanced Low-Dimensional Sensing Mapless Navigation of Terrestrial\n  Mobile Robots Using Double Deep Reinforcement Learning Techniques",
            "updated": "2023-10-20T20:47:07Z",
            "published": "2023-10-20T20:47:07Z",
            "summary": "In this study, we present two distinct approaches within the realm of Deep\nReinforcement Learning (Deep-RL) aimed at enhancing mapless navigation for a\nground-based mobile robot. The research methodology primarily involves a\ncomparative analysis between a Deep-RL strategy grounded in the foundational\nDeep Q-Network (DQN) algorithm, and an alternative approach based on the Double\nDeep Q-Network (DDQN) algorithm. The agents in these approaches leverage 24\nmeasurements from laser range sampling, coupled with the agent's positional\ndifferentials and orientation relative to the target. This amalgamation of data\ninfluences the agents' determinations regarding navigation, ultimately\ndictating the robot's velocities. By embracing this parsimonious sensory\nframework as proposed, we successfully showcase the training of an agent for\nproficiently executing navigation tasks and adeptly circumventing obstacles.\nNotably, this accomplishment is attained without a dependency on intricate\nsensory inputs like those inherent to image-centric methodologies. The proposed\nmethodology is evaluated in three different real environments, revealing that\nDouble Deep structures significantly enhance the navigation capabilities of\nmobile robots compared to simple Q structures.",
            "author": [
                "Linda Dotto de Moraes",
                "Victor Augusto Kich",
                "Alisson Henrique Kolling",
                "Jair Augusto Bottega",
                "Ricardo Bedin Grando",
                "Anselmo Rafael Cukla",
                "Daniel Fernando Tello Gamarra"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13809v1",
                "http://arxiv.org/pdf/2310.13809v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13807v1",
            "title": "Learning to (Learn at Test Time)",
            "updated": "2023-10-20T20:42:00Z",
            "published": "2023-10-20T20:42:00Z",
            "summary": "We reformulate the problem of supervised learning as learning to learn with\ntwo nested loops (i.e. learning problems). The inner loop learns on each\nindividual instance with self-supervision before final prediction. The outer\nloop learns the self-supervised task used by the inner loop, such that its\nfinal prediction improves. Our inner loop turns out to be equivalent to linear\nattention when the inner-loop learner is only a linear model, and to\nself-attention when it is a kernel estimator. For practical comparison with\nlinear or self-attention layers, we replace each of them in a transformer with\nan inner loop, so our outer loop is equivalent to training the architecture.\nWhen each inner-loop learner is a neural network, our approach vastly\noutperforms transformers with linear attention on ImageNet from 224 x 224 raw\npixels in both accuracy and FLOPs, while (regular) transformers cannot run.",
            "author": [
                "Yu Sun",
                "Xinhao Li",
                "Karan Dalal",
                "Chloe Hsu",
                "Sanmi Koyejo",
                "Carlos Guestrin",
                "Xiaolong Wang",
                "Tatsunori Hashimoto",
                "Xinlei Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13807v1",
                "http://arxiv.org/pdf/2310.13807v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03369v1",
            "title": "Can We Trust the Similarity Measurement in Federated Learning?",
            "updated": "2023-10-20T20:37:21Z",
            "published": "2023-10-20T20:37:21Z",
            "summary": "Is it secure to measure the reliability of local models by similarity in\nfederated learning (FL)? This paper delves into an unexplored security threat\nconcerning applying similarity metrics, such as the L_2 norm, Euclidean\ndistance, and cosine similarity, in protecting FL. We first uncover the\ndeficiencies of similarity metrics that high-dimensional local models,\nincluding benign and poisoned models, may be evaluated to have the same\nsimilarity while being significantly different in the parameter values. We then\nleverage this finding to devise a novel untargeted model poisoning attack,\nFaker, which launches the attack by simultaneously maximizing the evaluated\nsimilarity of the poisoned local model and the difference in the parameter\nvalues. Experimental results based on seven datasets and eight defenses show\nthat Faker outperforms the state-of-the-art benchmark attacks by 1.1-9.0X in\nreducing accuracy and 1.2-8.0X in saving time cost, which even holds for the\ncase of a single malicious client with limited knowledge about the FL system.\nMoreover, Faker can degrade the performance of the global model by attacking\nonly once. We also preliminarily explore extending Faker to other attacks, such\nas backdoor attacks and Sybil attacks. Lastly, we provide a model evaluation\nstrategy, called the similarity of partial parameters (SPP), to defend against\nFaker. Given that numerous mechanisms in FL utilize similarity metrics to\nassess local models, this work suggests that we should be vigilant regarding\nthe potential risks of using these metrics.",
            "author": [
                "Zhilin Wang",
                "Qin Hu",
                "Xukai Zou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03369v1",
                "http://arxiv.org/pdf/2311.03369v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13806v1",
            "title": "RoseNet: Predicting Energy Metrics of Double InDel Mutants Using Deep\n  Learning",
            "updated": "2023-10-20T20:36:13Z",
            "published": "2023-10-20T20:36:13Z",
            "summary": "An amino acid insertion or deletion, or InDel, can have profound and varying\nfunctional impacts on a protein's structure. InDel mutations in the\ntransmembrane conductor regulator protein for example give rise to cystic\nfibrosis. Unfortunately performing InDel mutations on physical proteins and\nstudying their effects is a time prohibitive process. Consequently, modeling\nInDels computationally can supplement and inform wet lab experiments. In this\nwork, we make use of our data sets of exhaustive double InDel mutations for\nthree proteins which we computationally generated using a robotics inspired\ninverse kinematics approach available in Rosetta. We develop and train a neural\nnetwork, RoseNet, on several structural and energetic metrics output by Rosetta\nduring the mutant generation process. We explore and present how RoseNet is\nable to emulate the exhaustive data set using deep learning methods, and show\nto what extent it can predict Rosetta metrics for unseen mutant sequences with\ntwo InDels. RoseNet achieves a Pearson correlation coefficient median accuracy\nof 0.775 over all Rosetta scores for the largest protein. Furthermore, a\nsensitivity analysis is performed to determine the necessary quantity of data\nrequired to accurately emulate the structural scores for computationally\ngenerated mutants. We show that the model can be trained on minimal data (<50%)\nand still retain a high level of accuracy.",
            "author": [
                "Sarah Coffland",
                "Katie Christensen",
                "Filip Jagodzinski",
                "Brian Hutchinson"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3584371.3612951",
                "http://arxiv.org/abs/2310.13806v1",
                "http://arxiv.org/pdf/2310.13806v1"
            ],
            "primary_category": "q-bio.BM",
            "category": [
                "q-bio.BM",
                "cs.AI",
                "cs.LG",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13805v1",
            "title": "Normalizing flow-based deep variational Bayesian network for seismic\n  multi-hazards and impacts estimation from InSAR imagery",
            "updated": "2023-10-20T20:32:43Z",
            "published": "2023-10-20T20:32:43Z",
            "summary": "Onsite disasters like earthquakes can trigger cascading hazards and impacts,\nsuch as landslides and infrastructure damage, leading to catastrophic losses;\nthus, rapid and accurate estimates are crucial for timely and effective\npost-disaster responses. Interferometric Synthetic aperture radar (InSAR) data\nis important in providing high-resolution onsite information for rapid hazard\nestimation. Most recent methods using InSAR imagery signals predict a single\ntype of hazard and thus often suffer low accuracy due to noisy and complex\nsignals induced by co-located hazards, impacts, and irrelevant environmental\nchanges (e.g., vegetation changes, human activities). We introduce a novel\nstochastic variational inference with normalizing flows derived to jointly\napproximate posteriors of multiple unobserved hazards and impacts from noisy\nInSAR imagery.",
            "author": [
                "Xuechun Li",
                "Paula M. Burgi",
                "Wei Ma",
                "Hae Young Noh",
                "David J. Wald",
                "Susu Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13805v1",
                "http://arxiv.org/pdf/2310.13805v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13802v1",
            "title": "Improving Molecular Properties Prediction Through Latent Space Fusion",
            "updated": "2023-10-20T20:29:32Z",
            "published": "2023-10-20T20:29:32Z",
            "summary": "Pre-trained Language Models have emerged as promising tools for predicting\nmolecular properties, yet their development is in its early stages,\nnecessitating further research to enhance their efficacy and address challenges\nsuch as generalization and sample efficiency. In this paper, we present a\nmulti-view approach that combines latent spaces derived from state-of-the-art\nchemical models. Our approach relies on two pivotal elements: the embeddings\nderived from MHG-GNN, which represent molecular structures as graphs, and\nMoLFormer embeddings rooted in chemical language. The attention mechanism of\nMoLFormer is able to identify relations between two atoms even when their\ndistance is far apart, while the GNN of MHG-GNN can more precisely capture\nrelations among multiple atoms closely located. In this work, we demonstrate\nthe superior performance of our proposed multi-view approach compared to\nexisting state-of-the-art methods, including MoLFormer-XL, which was trained on\n1.1 billion molecules, particularly in intricate tasks such as predicting\nclinical trial drug toxicity and inhibiting HIV replication. We assessed our\napproach using six benchmark datasets from MoleculeNet, where it outperformed\ncompetitors in five of them. Our study highlights the potential of latent space\nfusion and feature integration for advancing molecular property prediction. In\nthis work, we use small versions of MHG-GNN and MoLFormer, which opens up an\nopportunity for further improvement when our approach uses a larger-scale\ndataset.",
            "author": [
                "Eduardo Soares",
                "Akihiro Kishimoto",
                "Emilio Vital Brazil",
                "Seiji Takeda",
                "Hiroshi Kajino",
                "Renato Cerqueira"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13802v1",
                "http://arxiv.org/pdf/2310.13802v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CE",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13798v1",
            "title": "Specific versus General Principles for Constitutional AI",
            "updated": "2023-10-20T20:12:45Z",
            "published": "2023-10-20T20:12:45Z",
            "summary": "Human feedback can prevent overtly harmful utterances in conversational\nmodels, but may not automatically mitigate subtle problematic behaviors such as\na stated desire for self-preservation or power. Constitutional AI offers an\nalternative, replacing human feedback with feedback from AI models conditioned\nonly on a list of written principles. We find this approach effectively\nprevents the expression of such behaviors. The success of simple principles\nmotivates us to ask: can models learn general ethical behaviors from only a\nsingle written principle? To test this, we run experiments using a principle\nroughly stated as \"do what's best for humanity\". We find that the largest\ndialogue models can generalize from this short constitution, resulting in\nharmless assistants with no stated interest in specific motivations like power.\nA general principle may thus partially avoid the need for a long list of\nconstitutions targeting potentially harmful behaviors. However, more detailed\nconstitutions still improve fine-grained control over specific types of harms.\nThis suggests both general and specific principles have value for steering AI\nsafely.",
            "author": [
                "Sandipan Kundu",
                "Yuntao Bai",
                "Saurav Kadavath",
                "Amanda Askell",
                "Andrew Callahan",
                "Anna Chen",
                "Anna Goldie",
                "Avital Balwit",
                "Azalia Mirhoseini",
                "Brayden McLean",
                "Catherine Olsson",
                "Cassie Evraets",
                "Eli Tran-Johnson",
                "Esin Durmus",
                "Ethan Perez",
                "Jackson Kernion",
                "Jamie Kerr",
                "Kamal Ndousse",
                "Karina Nguyen",
                "Nelson Elhage",
                "Newton Cheng",
                "Nicholas Schiefer",
                "Nova DasSarma",
                "Oliver Rausch",
                "Robin Larson",
                "Shannon Yang",
                "Shauna Kravec",
                "Timothy Telleen-Lawton",
                "Thomas I. Liao",
                "Tom Henighan",
                "Tristan Hume",
                "Zac Hatfield-Dodds",
                "S\u00f6ren Mindermann",
                "Nicholas Joseph",
                "Sam McCandlish",
                "Jared Kaplan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13798v1",
                "http://arxiv.org/pdf/2310.13798v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13796v1",
            "title": "Faithful graphical representations of local independence",
            "updated": "2023-10-20T20:07:20Z",
            "published": "2023-10-20T20:07:20Z",
            "summary": "Graphical models use graphs to represent conditional independence structure\nin the distribution of a random vector. In stochastic processes, graphs may\nrepresent so-called local independence or conditional Granger causality. Under\nsome regularity conditions, a local independence graph implies a set of\nindependences using a graphical criterion known as $\\delta$-separation, or\nusing its generalization, $\\mu$-separation. This is a stochastic process\nanalogue of $d$-separation in DAGs. However, there may be more independences\nthan implied by this graph and this is a violation of so-called faithfulness.\nWe characterize faithfulness in local independence graphs and give a method to\nconstruct a faithful graph from any local independence model such that the\noutput equals the true graph when Markov and faithfulness assumptions hold. We\ndiscuss various assumptions that are weaker than faithfulness, and we explore\ndifferent structure learning algorithms and their properties under varying\nassumptions.",
            "author": [
                "S\u00f8ren Wengel Mogensen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13796v1",
                "http://arxiv.org/pdf/2310.13796v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13793v1",
            "title": "A Unified View of Evaluation Metrics for Structured Prediction",
            "updated": "2023-10-20T20:02:02Z",
            "published": "2023-10-20T20:02:02Z",
            "summary": "We present a conceptual framework that unifies a variety of evaluation\nmetrics for different structured prediction tasks (e.g. event and relation\nextraction, syntactic and semantic parsing). Our framework requires\nrepresenting the outputs of these tasks as objects of certain data types, and\nderives metrics through matching of common substructures, possibly followed by\nnormalization. We demonstrate how commonly used metrics for a number of tasks\ncan be succinctly expressed by this framework, and show that new metrics can be\nnaturally derived in a bottom-up way based on an output structure. We release a\nlibrary that enables this derivation to create new metrics. Finally, we\nconsider how specific characteristics of tasks motivate metric design\ndecisions, and suggest possible modifications to existing metrics in line with\nthose motivations.",
            "author": [
                "Yunmo Chen",
                "William Gantt",
                "Tongfei Chen",
                "Aaron Steven White",
                "Benjamin Van Durme"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13793v1",
                "http://arxiv.org/pdf/2310.13793v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13791v1",
            "title": "Comparative Analysis of Machine Learning Algorithms for Solar Irradiance\n  Forecasting in Smart Grids",
            "updated": "2023-10-20T19:52:37Z",
            "published": "2023-10-20T19:52:37Z",
            "summary": "The increasing global demand for clean and environmentally friendly energy\nresources has caused increased interest in harnessing solar power through\nphotovoltaic (PV) systems for smart grids and homes. However, the inherent\nunpredictability of PV generation poses problems associated with smart grid\nplanning and management, energy trading and market participation, demand\nresponse, reliability, etc. Therefore, solar irradiance forecasting is\nessential for optimizing PV system utilization. This study proposes the\nnext-generation machine learning algorithms such as random forests, Extreme\nGradient Boosting (XGBoost), Light Gradient Boosted Machine (lightGBM)\nensemble, CatBoost, and Multilayer Perceptron Artificial Neural Networks\n(MLP-ANNs) to forecast solar irradiance. Besides, Bayesian optimization is\napplied to hyperparameter tuning. Unlike tree-based ensemble algorithms that\nselect the features intrinsically, MLP-ANN needs feature selection as a\nseparate step. The simulation results indicate that the performance of the\nMLP-ANNs improves when feature selection is applied. Besides, the random forest\noutperforms the other learning algorithms.",
            "author": [
                "Saman Soleymani",
                "Shima Mohammadzadeh"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13791v1",
                "http://arxiv.org/pdf/2310.13791v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13787v1",
            "title": "Enhancing Illicit Activity Detection using XAI: A Multimodal Graph-LLM\n  Framework",
            "updated": "2023-10-20T19:33:44Z",
            "published": "2023-10-20T19:33:44Z",
            "summary": "Financial cybercrime prevention is an increasing issue with many\norganisations and governments. As deep learning models have progressed to\nidentify illicit activity on various financial and social networks, the\nexplainability behind the model decisions has been lacklustre with the\ninvestigative analyst at the heart of any deep learning platform. In our paper,\nwe present a state-of-the-art, novel multimodal proactive approach to\naddressing XAI in financial cybercrime detection.\n  We leverage a triad of deep learning models designed to distill essential\nrepresentations from transaction sequencing, subgraph connectivity, and\nnarrative generation to significantly streamline the analyst's investigative\nprocess. Our narrative generation proposal leverages LLM to ingest transaction\ndetails and output contextual narrative for an analyst to understand a\ntransaction and its metadata much further.",
            "author": [
                "Jack Nicholls",
                "Aditya Kuppa",
                "Nhien-An Le-Khac"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13787v1",
                "http://arxiv.org/pdf/2310.13787v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13786v2",
            "title": "Fundamental Limits of Membership Inference Attacks on Machine Learning\n  Models",
            "updated": "2023-10-27T14:09:43Z",
            "published": "2023-10-20T19:32:54Z",
            "summary": "Membership inference attacks (MIA) can reveal whether a particular data point\nwas part of the training dataset, potentially exposing sensitive information\nabout individuals. This article explores the fundamental statistical\nlimitations associated with MIAs on machine learning models. More precisely, we\nfirst derive the statistical quantity that governs the effectiveness and\nsuccess of such attacks. Then, we investigate several situations for which we\nprovide bounds on this quantity of interest. This allows us to infer the\naccuracy of potential attacks as a function of the number of samples and other\nstructural parameters of learning models, which in some cases can be directly\nestimated from the dataset.",
            "author": [
                "Eric Aubinais",
                "Elisabeth Gassiat",
                "Pablo Piantanida"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13786v2",
                "http://arxiv.org/pdf/2310.13786v2"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13778v1",
            "title": "Inferring Properties in Computation Tree Logic",
            "updated": "2023-10-20T19:23:32Z",
            "published": "2023-10-20T19:23:32Z",
            "summary": "We consider the problem of automatically inferring specifications in the\nbranching-time logic, Computation Tree Logic (CTL), from a given system.\nDesigning functional and usable specifications has always been one of the\nbiggest challenges of formal methods. While in recent years, works have focused\non automatically designing specifications in linear-time logics such as Linear\nTemporal Logic (LTL) and Signal Temporal Logic (STL), little attention has been\ngiven to branching-time logics despite its popularity in formal methods. We\nintend to infer concise (thus, interpretable) CTL formulas from a given finite\nstate model of the system in consideration. However, inferring specification\nonly from the given model (and, in general, from only positive examples) is an\nill-posed problem. As a result, we infer a CTL formula that, along with being\nconcise, is also language-minimal, meaning that it is rather specific to the\ngiven model. We design a counter-example guided algorithm to infer a concise\nand language-minimal CTL formula via the generation of undesirable models. In\nthe process, we also develop, for the first time, a passive learning algorithm\nto infer CTL formulas from a set of desirable and undesirable Kripke\nstructures. The passive learning algorithm involves encoding a popular CTL\nmodel-checking procedure in the Boolean Satisfiability problem.",
            "author": [
                "Rajarshi Roy",
                "Daniel Neider"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13778v1",
                "http://arxiv.org/pdf/2310.13778v1"
            ],
            "primary_category": "cs.LO",
            "category": [
                "cs.LO",
                "cs.FL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13772v1",
            "title": "TexFusion: Synthesizing 3D Textures with Text-Guided Image Diffusion\n  Models",
            "updated": "2023-10-20T19:15:29Z",
            "published": "2023-10-20T19:15:29Z",
            "summary": "We present TexFusion (Texture Diffusion), a new method to synthesize textures\nfor given 3D geometries, using large-scale text-guided image diffusion models.\nIn contrast to recent works that leverage 2D text-to-image diffusion models to\ndistill 3D objects using a slow and fragile optimization process, TexFusion\nintroduces a new 3D-consistent generation technique specifically designed for\ntexture synthesis that employs regular diffusion model sampling on different 2D\nrendered views. Specifically, we leverage latent diffusion models, apply the\ndiffusion model's denoiser on a set of 2D renders of the 3D object, and\naggregate the different denoising predictions on a shared latent texture map.\nFinal output RGB textures are produced by optimizing an intermediate neural\ncolor field on the decodings of 2D renders of the latent texture. We thoroughly\nvalidate TexFusion and show that we can efficiently generate diverse, high\nquality and globally coherent textures. We achieve state-of-the-art text-guided\ntexture synthesis performance using only image diffusion models, while avoiding\nthe pitfalls of previous distillation-based methods. The text-conditioning\noffers detailed control and we also do not rely on any ground truth 3D textures\nfor training. This makes our method versatile and applicable to a broad range\nof geometry and texture types. We hope that TexFusion will advance AI-based\ntexturing of 3D assets for applications in virtual reality, game design,\nsimulation, and more.",
            "author": [
                "Tianshi Cao",
                "Karsten Kreis",
                "Sanja Fidler",
                "Nicholas Sharp",
                "Kangxue Yin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13772v1",
                "http://arxiv.org/pdf/2310.13772v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "I.3.3"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13769v1",
            "title": "Compositional Deep Probabilistic Models of DNA Encoded Libraries",
            "updated": "2023-10-20T19:04:28Z",
            "published": "2023-10-20T19:04:28Z",
            "summary": "DNA-Encoded Library (DEL) has proven to be a powerful tool that utilizes\ncombinatorially constructed small molecules to facilitate highly-efficient\nscreening assays. These selection experiments, involving multiple stages of\nwashing, elution, and identification of potent binders via unique DNA barcodes,\noften generate complex data. This complexity can potentially mask the\nunderlying signals, necessitating the application of computational tools such\nas machine learning to uncover valuable insights. We introduce a compositional\ndeep probabilistic model of DEL data, DEL-Compose, which decomposes molecular\nrepresentations into their mono-synthon, di-synthon, and tri-synthon building\nblocks and capitalizes on the inherent hierarchical structure of these\nmolecules by modeling latent reactions between embedded synthons. Additionally,\nwe investigate methods to improve the observation models for DEL count data\nsuch as integrating covariate factors to more effectively account for data\nnoise. Across two popular public benchmark datasets (CA-IX and HRP), our model\ndemonstrates strong performance compared to count baselines, enriches the\ncorrect pharmacophores, and offers valuable insights via its intrinsic\ninterpretable structure, thereby providing a robust tool for the analysis of\nDEL data.",
            "author": [
                "Benson Chen",
                "Mohammad M. Sultan",
                "Theofanis Karaletsos"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13769v1",
                "http://arxiv.org/pdf/2310.13769v1"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13767v1",
            "title": "Graph AI in Medicine",
            "updated": "2023-10-20T19:01:01Z",
            "published": "2023-10-20T19:01:01Z",
            "summary": "In clinical artificial intelligence (AI), graph representation learning,\nmainly through graph neural networks (GNNs), stands out for its capability to\ncapture intricate relationships within structured clinical datasets. With\ndiverse data -- from patient records to imaging -- GNNs process data\nholistically by viewing modalities as nodes interconnected by their\nrelationships. Graph AI facilitates model transfer across clinical tasks,\nenabling models to generalize across patient populations without additional\nparameters or minimal re-training. However, the importance of human-centered\ndesign and model interpretability in clinical decision-making cannot be\noverstated. Since graph AI models capture information through localized neural\ntransformations defined on graph relationships, they offer both an opportunity\nand a challenge in elucidating model rationale. Knowledge graphs can enhance\ninterpretability by aligning model-driven insights with medical knowledge.\nEmerging graph models integrate diverse data modalities through pre-training,\nfacilitate interactive feedback loops, and foster human-AI collaboration,\npaving the way to clinically meaningful predictions.",
            "author": [
                "Ruth Johnson",
                "Michelle M. Li",
                "Ayush Noori",
                "Owen Queen",
                "Marinka Zitnik"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13767v1",
                "http://arxiv.org/pdf/2310.13767v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13756v1",
            "title": "Learning Interatomic Potentials at Multiple Scales",
            "updated": "2023-10-20T18:34:32Z",
            "published": "2023-10-20T18:34:32Z",
            "summary": "The need to use a short time step is a key limit on the speed of molecular\ndynamics (MD) simulations. Simulations governed by classical potentials are\noften accelerated by using a multiple-time-step (MTS) integrator that evaluates\ncertain potential energy terms that vary more slowly than others less\nfrequently. This approach is enabled by the simple but limiting analytic forms\nof classical potentials. Machine learning interatomic potentials (MLIPs), in\nparticular recent equivariant neural networks, are much more broadly applicable\nthan classical potentials and can faithfully reproduce the expensive but\naccurate reference electronic structure calculations used to train them. They\nstill, however, require the use of a single short time step, as they lack the\ninherent term-by-term scale separation of classical potentials. This work\nintroduces a method to learn a scale separation in complex interatomic\ninteractions by co-training two MLIPs. Initially, a small and efficient model\nis trained to reproduce short-time-scale interactions. Subsequently, a large\nand expressive model is trained jointly to capture the remaining interactions\nnot captured by the small model. When running MD, the MTS integrator then\nevaluates the smaller model for every time step and the larger model less\nfrequently, accelerating simulation. Compared to a conventionally trained MLIP,\nour approach can achieve a significant speedup (~3x in our experiments) without\na loss of accuracy on the potential energy or simulation-derived quantities.",
            "author": [
                "Xiang Fu",
                "Albert Musaelian",
                "Anders Johansson",
                "Tommi Jaakkola",
                "Boris Kozinsky"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13756v1",
                "http://arxiv.org/pdf/2310.13756v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph",
                "cs.LG",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13751v1",
            "title": "Nebular C IV 1550 Imaging of the Metal-Poor Starburst Mrk 71: Direct\n  Evidence of Catastrophic Cooling",
            "updated": "2023-10-20T18:25:08Z",
            "published": "2023-10-20T18:25:08Z",
            "summary": "We use the Hubble Space Telescope ACS camera to obtain the first spatially\nresolved, nebular imaging in the light of C IV 1548,1551 by using the F150LP\nand F165LP filters. These observations of the local starburst Mrk 71 in NGC\n2366 show emission apparently originating within the interior cavity around the\ndominant super star cluster (SSC), Knot A. Together with imaging in He II 4686\nand supporting STIS FUV spectroscopy, the morphology and intensity of the C IV\nnebular surface brightness and the C IV / He II ratio map provide direct\nevidence that the mechanical feedback is likely dominated by catastrophic\nradiative cooling, which strongly disrupts adiabatic superbubble evolution. The\nimplied extreme mass loading and low kinetic efficiency of the cluster wind are\nreasonably consistent with the wind energy budget, which is probably enhanced\nby radiation pressure. In contrast, the Knot B SSC lies within a well-defined\nsuperbubble with associated soft X-rays and He II 1640 emission, which are\nsignatures of adiabatic, energy-driven feedback from a supernova-driven\noutflow. This system lacks clear evidence of C IV from the limb-brightened\nshell, as expected for this model, but the observations may not be deep enough\nto confirm its presence. We also detect a small C IV-emitting object that is\nlikely an embedded compact H II region. Its C IV emission may indicate the\npresence of very massive stars (> 100 M_sun) or strongly pressure-confined\nstellar feedback.",
            "author": [
                "M. S. Oey",
                "Amit N. Sawant",
                "Ashkbiz Danehkar",
                "Sergiy Silich",
                "Linda J. Smith",
                "Jens Melinder",
                "Claus Leitherer",
                "Matthew Hayes",
                "Anne E. Jaskot",
                "Daniela Calzetti",
                "You-Hua Chu",
                "Bethan L. James",
                "Goeran Oestlin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13751v1",
                "http://arxiv.org/pdf/2310.13751v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13746v1",
            "title": "FairBranch: Fairness Conflict Correction on Task-group Branches for Fair\n  Multi-Task Learning",
            "updated": "2023-10-20T18:07:15Z",
            "published": "2023-10-20T18:07:15Z",
            "summary": "The generalization capacity of Multi-Task Learning (MTL) becomes limited when\nunrelated tasks negatively impact each other by updating shared parameters with\nconflicting gradients, resulting in negative transfer and a reduction in MTL\naccuracy compared to single-task learning (STL). Recently, there has been an\nincreasing focus on the fairness of MTL models, necessitating the optimization\nof both accuracy and fairness for individual tasks. Similarly to how negative\ntransfer affects accuracy, task-specific fairness considerations can adversely\ninfluence the fairness of other tasks when there is a conflict of fairness loss\ngradients among jointly learned tasks, termed bias transfer. To address both\nnegative and bias transfer in MTL, we introduce a novel method called\nFairBranch. FairBranch branches the MTL model by assessing the similarity of\nlearned parameters, grouping related tasks to mitigate negative transfer.\nAdditionally, it incorporates fairness loss gradient conflict correction\nbetween adjoining task-group branches to address bias transfer within these\ntask groups. Our experiments in tabular and visual MTL problems demonstrate\nthat FairBranch surpasses state-of-the-art MTL methods in terms of both\nfairness and accuracy.",
            "author": [
                "Arjun Roy",
                "Christos Koutlis",
                "Symeon Papadopoulos",
                "Eirini Ntoutsi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13746v1",
                "http://arxiv.org/pdf/2310.13746v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13745v1",
            "title": "NGDEEP Epoch 1: Spatially Resolved H$\u03b1$ Observations of Disk and\n  Bulge Growth in Star-Forming Galaxies at $z \\sim$ 0.6-2.2 from JWST NIRISS\n  Slitless Spectroscopy",
            "updated": "2023-10-20T18:03:09Z",
            "published": "2023-10-20T18:03:09Z",
            "summary": "We study the H$\\alpha$ equivalent width, EW(H$\\alpha$), maps of 19 galaxies\nat $0.6 < z < 2.2$ in the Hubble Ultra Deep Field (HUDF) derived from NIRISS\nslitless spectroscopy as part of the Next Generation Deep Extragalactic\nExploratory Public (NGDEEP) Survey. Our galaxies mostly lie on the\nstar-formation main sequence with a stellar mass range of $\\mathrm{10^9 -\n10^{11} M_\\odot}$, and are therefore characteristic of \"typical\" star-forming\ngalaxies at these redshifts. Leveraging deep HST and JWST broad-band images,\nspanning 0.4-4 $\\mu$m, we perform spatially-resolved fitting of the spectral\nenergy distributions (SEDs) for these galaxies and construct specific star\nformation rate (sSFR) and stellar-mass-weighted age maps. We compare these to\nthe EW(H$\\alpha$) maps with a spatial resolution of $\\sim$1 kpc. The\npixel-to-pixel EW(H$\\alpha$) increases with increasing sSFR and with decreasing\nage, with the average trend slightly different from the relations derived from\nintegrated fluxes of galaxies from the literature. Quantifying the radial\nprofiles of EW(H$\\alpha$), sSFR, and age, the majority (84%) of galaxies show\npositive EW(H$\\alpha$) gradients, positive sSFR gradients, and negative age\ngradients, in line with the the inside-out quenching scenario. A few galaxies\n(16%) show inverse (and flat) trends possibly due to merging or starbursts.\nComparing the distributions of EW(H$\\alpha$) and sSFR to the star formation\nhistory models as a function of galactocentric radius, the central region of\ngalaxies (e.g., their bulges) have experienced, at least one, rapid\nstar-formation episodes, which leads to the formation of bulge, while their\nouter regions (e.g., disks) grow in a more steady-state. These results\ndemonstrate the ability to study resolved star formation in distant galaxies\nwith JWST NIRISS.",
            "author": [
                "Lu Shen",
                "Casey Papovich",
                "Jasleen Matharu",
                "Nor Pirzkal",
                "Weida Hu",
                "Bren E. Backhaus",
                "Micaela B. Bagley",
                "Yingjie Cheng",
                "Nikko J. Cleri",
                "Steven L. Finkelstein",
                "Marc Huertas-Company",
                "Mauro Giavalisco",
                "Norman A. Grogin",
                "Intae Jung",
                "Jeyhan S. Kartaltepe",
                "Anton M. Koekemoer",
                "Jennifer M. Lotz",
                "Michael V. Maseda",
                "Pablo G. P\u00e9rez-Gonz\u00e1lez",
                "Barry Rothberg",
                "Raymond C. Simons",
                "Sandro Tacchella",
                "Christina C. Williams",
                "L. Y. Aaron Yung"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13745v1",
                "http://arxiv.org/pdf/2310.13745v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13737v1",
            "title": "Polarized $J/\u03c8$ production in semi-inclusive DIS at large $Q^2$:\n  Comparing quark fragmentation and photon-gluon fusion",
            "updated": "2023-10-20T18:00:02Z",
            "published": "2023-10-20T18:00:02Z",
            "summary": "We compare the relative importance of different mechanisms for polarized\n$J/\\psi$ production in semi-inclusive deep inelastic scattering processes at\nlarge $Q^2$. The transverse momentum dependent (TMD) factorization framework\nand non-relativistic quantum chromodynamics are used to study the leading\ncontributions from light quark fragmentation to polarized $J/\\psi$, and\ncompared to direct production via photon-gluon fusion, which can proceed\nthrough color-singlet as well as color-octet mechanisms. We identify kinematic\nregimes where light quark fragmentation dominates, allowing for the extraction\nof the $^3S_1^{[8]}$ matrix element, as well as regimes where photon gluon\nfusion dominates, suggesting that the gluon TMD parton distribution function\ncan be probed.",
            "author": [
                "Marston Copeland",
                "Sean Fleming",
                "Rohit Gupta",
                "Reed Hodges",
                "Thomas Mehen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13737v1",
                "http://arxiv.org/pdf/2310.13737v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13738v1",
            "title": "Deep-Learning-Based Radio-Frequency Side-Channel Attack on Quantum Key\n  Distribution",
            "updated": "2023-10-20T18:00:02Z",
            "published": "2023-10-20T18:00:02Z",
            "summary": "Quantum key distribution (QKD) protocols are proven secure based on\nfundamental physical laws, however, the proofs consider a well-defined setting\nand encoding of the sent quantum signals only. Side channels, where the encoded\nquantum state is correlated with properties of other degrees of freedom of the\nquantum channel, allow an eavesdropper to obtain information unnoticeably as\ndemonstrated in a number of hacking attacks on the quantum channel. Yet, also\nclassical radiation emitted by the devices may be correlated, leaking\ninformation on the potential key, especially when combined with novel data\nanalysis methods.\n  We here demonstrate a side-channel attack using a deep convolutional neural\nnetwork to analyze the recorded classical, radio-frequency electromagnetic\nemissions. Even at a distance of a few centimeters from the electronics of a\nQKD sender employing frequently used electronic components we are able to\nrecover virtually all information about the secret key. Yet, as shown here,\ncountermeasures can enable a significant reduction of both the emissions and\nthe amount of secret key information leaked to the attacker. Our analysis\nmethods are independent of the actual device and thus provide a starting point\nfor assessing the presence of classical side channels in QKD devices.",
            "author": [
                "Adomas Baliuka",
                "Markus St\u00f6cker",
                "Michael Auer",
                "Peter Freiwang",
                "Harald Weinfurter",
                "Lukas Knips"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13738v1",
                "http://arxiv.org/pdf/2310.13738v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13691v1",
            "title": "Neural-Base Music Generation for Intelligence Duplication",
            "updated": "2023-10-20T17:52:48Z",
            "published": "2023-10-20T17:52:48Z",
            "summary": "There are two aspects of machine learning and artificial intelligence: (1)\ninterpreting information, and (2) inventing new useful information. Much\nadvance has been made for (1) with a focus on pattern recognition techniques\n(e.g., interpreting visual data). This paper focuses on (2) with intelligent\nduplication (ID) for invention. We explore the possibility of learning a\nspecific individual's creative reasoning in order to leverage the learned\nexpertise and talent to invent new information. More specifically, we employ a\ndeep learning system to learn from the great composer Beethoven and capture his\ncomposition ability in a hash-based knowledge base. This new form of knowledge\nbase provides a reasoning facility to drive the music composition through a\nnovel music generation method.",
            "author": [
                "Jacob Galajda",
                "Kien Hua"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13691v1",
                "http://arxiv.org/pdf/2310.13691v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13684v1",
            "title": "Sloshing in containers with vertical walls: isoperimetric inequalities\n  for the fundamental eigenvalue",
            "updated": "2023-10-20T17:45:00Z",
            "published": "2023-10-20T17:45:00Z",
            "summary": "One isoperimetric inequality for the fundamental sloshing eigenvalue is\nderived under the assumption that containers have vertical side walls and\neither finite or infinite depth. It asserts that among all such containers,\nwhose free surfaces are convex, have two axes of symmetry and a given perimeter\nlength, this eigenvalue is maximized by infinitely deep ones provided the free\nsurface is either the square or the equilateral triangle. The proof is based on\nthe recent isoperimetric result obtained by A. Henrot, A. Lemenant and\nI.~Lucardesi for the first nonzero eigenvalue of the two-dimensional Neumann\nLaplacian under the perimeter constraint.\n  Another isoperimetric inequality for the fundamental eigenvalue, which\ndescribes sloshing in containers with vertical walls, is a consequence of the\nclassical result due to G. Szeg\\H o concerning the first nonzero eigenvalue of\nthe free membrane problem.",
            "author": [
                "Nikolay Kuznetsov"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13684v1",
                "http://arxiv.org/pdf/2310.13684v1"
            ],
            "primary_category": "math.AP",
            "category": [
                "math.AP",
                "math-ph",
                "math.MP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13683v2",
            "title": "CAPIVARA: Cost-Efficient Approach for Improving Multilingual CLIP\n  Performance on Low-Resource Languages",
            "updated": "2023-10-23T17:06:07Z",
            "published": "2023-10-20T17:44:25Z",
            "summary": "This work introduces CAPIVARA, a cost-efficient framework designed to enhance\nthe performance of multilingual CLIP models in low-resource languages. While\nCLIP has excelled in zero-shot vision-language tasks, the resource-intensive\nnature of model training remains challenging. Many datasets lack linguistic\ndiversity, featuring solely English descriptions for images. CAPIVARA addresses\nthis by augmenting text data using image captioning and machine translation to\ngenerate multiple synthetic captions in low-resource languages. We optimize the\ntraining pipeline with LiT, LoRA, and gradient checkpointing to alleviate the\ncomputational cost. Through extensive experiments, CAPIVARA emerges as state of\nthe art in zero-shot tasks involving images and Portuguese texts. We show the\npotential for significant improvements in other low-resource languages,\nachieved by fine-tuning the pre-trained multilingual CLIP using CAPIVARA on a\nsingle GPU for 2 hours. Our model and code is available at\nhttps://github.com/hiaac-nlp/CAPIVARA.",
            "author": [
                "Gabriel Oliveira dos Santos",
                "Diego A. B. Moreira",
                "Alef Iury Ferreira",
                "Jhessica Silva",
                "Luiz Pereira",
                "Pedro Bueno",
                "Thiago Sousa",
                "Helena Maia",
                "N\u00e1dia Da Silva",
                "Esther Colombini",
                "Helio Pedrini",
                "Sandra Avila"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13683v2",
                "http://arxiv.org/pdf/2310.13683v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13682v2",
            "title": "Optimizing Retrieval-augmented Reader Models via Token Elimination",
            "updated": "2023-11-05T06:31:55Z",
            "published": "2023-10-20T17:41:36Z",
            "summary": "Fusion-in-Decoder (FiD) is an effective retrieval-augmented language model\napplied across a variety of open-domain tasks, such as question answering, fact\nchecking, etc. In FiD, supporting passages are first retrieved and then\nprocessed using a generative model (Reader), which can cause a significant\nbottleneck in decoding time, particularly with long outputs. In this work, we\nanalyze the contribution and necessity of all the retrieved passages to the\nperformance of reader models, and propose eliminating some of the retrieved\ninformation, at the token level, that might not contribute essential\ninformation to the answer generation process. We demonstrate that our method\ncan reduce run-time by up to 62.2%, with only a 2% reduction in performance,\nand in some cases, even improve the performance results.",
            "author": [
                "Moshe Berchansky",
                "Peter Izsak",
                "Avi Caciularu",
                "Ido Dagan",
                "Moshe Wasserblat"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13682v2",
                "http://arxiv.org/pdf/2310.13682v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13681v1",
            "title": "RealFM: A Realistic Mechanism to Incentivize Data Contribution and\n  Device Participation",
            "updated": "2023-10-20T17:40:39Z",
            "published": "2023-10-20T17:40:39Z",
            "summary": "Edge device participation in federating learning (FL) has been typically\nstudied under the lens of device-server communication (e.g., device dropout)\nand assumes an undying desire from edge devices to participate in FL. As a\nresult, current FL frameworks are flawed when implemented in real-world\nsettings, with many encountering the free-rider problem. In a step to push FL\ntowards realistic settings, we propose RealFM: the first truly federated\nmechanism which (1) realistically models device utility, (2) incentivizes data\ncontribution and device participation, and (3) provably removes the free-rider\nphenomena. RealFM does not require data sharing and allows for a non-linear\nrelationship between model accuracy and utility, which improves the utility\ngained by the server and participating devices compared to non-participating\ndevices as well as devices participating in other FL mechanisms. On real-world\ndata, RealFM improves device and server utility, as well as data contribution,\nby up to 3 magnitudes and 7x respectively compared to baseline mechanisms.",
            "author": [
                "Marco Bornstein",
                "Amrit Singh Bedi",
                "Anit Kumar Sahu",
                "Furqan Khan",
                "Furong Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13681v1",
                "http://arxiv.org/pdf/2310.13681v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT",
                "cs.CY",
                "cs.DC",
                "cs.LG",
                "econ.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13678v2",
            "title": "Long-Form Speech Translation through Segmentation with Finite-State\n  Decoding Constraints on Large Language Models",
            "updated": "2023-10-23T15:25:55Z",
            "published": "2023-10-20T17:31:39Z",
            "summary": "One challenge in speech translation is that plenty of spoken content is\nlong-form, but short units are necessary for obtaining high-quality\ntranslations. To address this mismatch, we adapt large language models (LLMs)\nto split long ASR transcripts into segments that can be independently\ntranslated so as to maximize the overall translation quality. We overcome the\ntendency of hallucination in LLMs by incorporating finite-state constraints\nduring decoding; these eliminate invalid outputs without requiring additional\ntraining. We discover that LLMs are adaptable to transcripts containing ASR\nerrors through prompt-tuning or fine-tuning. Relative to a state-of-the-art\nautomatic punctuation baseline, our best LLM improves the average BLEU by 2.9\npoints for English-German, English-Spanish, and English-Arabic TED talk\ntranslation in 9 test sets, just by improving segmentation.",
            "author": [
                "Arya D. McCarthy",
                "Hao Zhang",
                "Shankar Kumar",
                "Felix Stahlberg",
                "Ke Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13678v2",
                "http://arxiv.org/pdf/2310.13678v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13674v1",
            "title": "Using Human-like Mechanism to Weaken Effect of Pre-training Weight Bias\n  in Face-Recognition Convolutional Neural Network",
            "updated": "2023-10-20T17:22:57Z",
            "published": "2023-10-20T17:22:57Z",
            "summary": "Convolutional neural network (CNN), as an important model in artificial\nintelligence, has been widely used and studied in different disciplines. The\ncomputational mechanisms of CNNs are still not fully revealed due to the their\ncomplex nature. In this study, we focused on 4 extensively studied CNNs\n(AlexNet, VGG11, VGG13, and VGG16) which has been analyzed as human-like models\nby neuroscientists with ample evidence. We trained these CNNs to emotion\nvalence classification task by transfer learning. Comparing their performance\nwith human data, the data unveiled that these CNNs would partly perform as\nhuman does. We then update the object-based AlexNet using self-attention\nmechanism based on neuroscience and behavioral data. The updated FE-AlexNet\noutperformed all the other tested CNNs and closely resembles human perception.\nThe results further unveil the computational mechanisms of these CNNs.\nMoreover, this study offers a new paradigm to better understand and improve CNN\nperformance via human data.",
            "author": [
                "Haojiang Ying",
                "Yi-Fan Li",
                "Yiyang Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13674v1",
                "http://arxiv.org/pdf/2310.13674v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14918v2",
            "title": "ARNIQA: Learning Distortion Manifold for Image Quality Assessment",
            "updated": "2023-11-04T18:51:11Z",
            "published": "2023-10-20T17:22:25Z",
            "summary": "No-Reference Image Quality Assessment (NR-IQA) aims to develop methods to\nmeasure image quality in alignment with human perception without the need for a\nhigh-quality reference image. In this work, we propose a self-supervised\napproach named ARNIQA (leArning distoRtion maNifold for Image Quality\nAssessment) for modeling the image distortion manifold to obtain quality\nrepresentations in an intrinsic manner. First, we introduce an image\ndegradation model that randomly composes ordered sequences of consecutively\napplied distortions. In this way, we can synthetically degrade images with a\nlarge variety of degradation patterns. Second, we propose to train our model by\nmaximizing the similarity between the representations of patches of different\nimages distorted equally, despite varying content. Therefore, images degraded\nin the same manner correspond to neighboring positions within the distortion\nmanifold. Finally, we map the image representations to the quality scores with\na simple linear regressor, thus without fine-tuning the encoder weights. The\nexperiments show that our approach achieves state-of-the-art performance on\nseveral datasets. In addition, ARNIQA demonstrates improved data efficiency,\ngeneralization capabilities, and robustness compared to competing methods. The\ncode and the model are publicly available at\nhttps://github.com/miccunifi/ARNIQA.",
            "author": [
                "Lorenzo Agnolucci",
                "Leonardo Galteri",
                "Marco Bertini",
                "Alberto Del Bimbo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14918v2",
                "http://arxiv.org/pdf/2310.14918v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13670v1",
            "title": "ManifoldNeRF: View-dependent Image Feature Supervision for Few-shot\n  Neural Radiance Fields",
            "updated": "2023-10-20T17:13:52Z",
            "published": "2023-10-20T17:13:52Z",
            "summary": "Novel view synthesis has recently made significant progress with the advent\nof Neural Radiance Fields (NeRF). DietNeRF is an extension of NeRF that aims to\nachieve this task from only a few images by introducing a new loss function for\nunknown viewpoints with no input images. The loss function assumes that a\npre-trained feature extractor should output the same feature even if input\nimages are captured at different viewpoints since the images contain the same\nobject. However, while that assumption is ideal, in reality, it is known that\nas viewpoints continuously change, also feature vectors continuously change.\nThus, the assumption can harm training. To avoid this harmful training, we\npropose ManifoldNeRF, a method for supervising feature vectors at unknown\nviewpoints using interpolated features from neighboring known viewpoints. Since\nthe method provides appropriate supervision for each unknown viewpoint by the\ninterpolated features, the volume representation is learned better than\nDietNeRF. Experimental results show that the proposed method performs better\nthan others in a complex scene. We also experimented with several subsets of\nviewpoints from a set of viewpoints and identified an effective set of\nviewpoints for real environments. This provided a basic policy of viewpoint\npatterns for real-world application. The code is available at\nhttps://github.com/haganelego/ManifoldNeRF_BMVC2023",
            "author": [
                "Daiju Kanaoka",
                "Motoharu Sonogashira",
                "Hakaru Tamukoh",
                "Yasutomo Kawanishi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13670v1",
                "http://arxiv.org/pdf/2310.13670v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.GR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13669v1",
            "title": "Automatic Unit Test Data Generation and Actor-Critic Reinforcement\n  Learning for Code Synthesis",
            "updated": "2023-10-20T17:13:16Z",
            "published": "2023-10-20T17:13:16Z",
            "summary": "The advent of large pre-trained language models in the domain of Code\nSynthesis has shown remarkable performance on various benchmarks, treating the\nproblem of Code Generation in a fashion similar to Natural Language Generation,\ntrained with a Language Modelling (LM) objective. In addition, the property of\nprogramming language code being precisely evaluable with respect to its\nsemantics -- through the use of Unit Tests to check its functional correctness\n-- lends itself to using Reinforcement Learning (RL) as a further training\nparadigm. Previous work has shown that RL can be applied as such to improve\nmodels' coding capabilities; however, such RL-based methods rely on a reward\nsignal based on defined Unit Tests, which are much harder to obtain compared to\nthe huge crawled code datasets used in LM objectives. In this work, we present\na novel approach to automatically obtain data consisting of function signatures\nand associated Unit Tests, suitable for RL training of Code Synthesis models.\nWe also introduce a straightforward, simple yet effective Actor-Critic RL\ntraining scheme and show that it, in conjunction with automatically generated\ntraining data, leads to improvement of a pre-trained code language model's\nperformance by up to 9.9% improvement over the original underlying code\nsynthesis LM, and up to 4.3% over RL-based models trained with standard PPO or\nCodeRL.",
            "author": [
                "Philip John Gorinski",
                "Matthieu Zimmer",
                "Gerasimos Lampouras",
                "Derrick Goh Xin Deik",
                "Ignacio Iacobacci"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13669v1",
                "http://arxiv.org/pdf/2310.13669v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL",
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13667v1",
            "title": "EXPLORA: AI/ML EXPLainability for the Open RAN",
            "updated": "2023-10-20T17:09:52Z",
            "published": "2023-10-20T17:09:52Z",
            "summary": "The Open Radio Access Network (RAN) paradigm is transforming cellular\nnetworks into a system of disaggregated, virtualized, and software-based\ncomponents. These self-optimize the network through programmable, closed-loop\ncontrol, leveraging Artificial Intelligence (AI) and Machine Learning (ML)\nroutines. In this context, Deep Reinforcement Learning (DRL) has shown great\npotential in addressing complex resource allocation problems. However, DRL\n-based solutions are inherently hard to explain, which hinders their deployment\nand use in practice. In this paper, we propose EXPLORA, a framework that\nprovides explainability of DRL-based control solutions for the Open RAN\necosystem. EXPLORA synthesizes network-oriented explanations based on an\nattributed graph that produces a link between the actions taken by a DRL agent\n(i.e., the nodes of the graph) and the input state space (i.e., the attributes\nof each node). This novel approach allows EXPLORA to explain models by\nproviding information on the wireless context in which the DRL agent operates.\nEXPLORA is also designed to be lightweight for real-time operation. We\nprototype EXPLORA and test it experimentally on an O-RAN-compliant\nnear-real-time RIC deployed on the Colosseum wireless network emulator. We\nevaluate EXPLORA for agents trained for different purposes and showcase how it\ngenerates clear network-oriented explanations. We also show how explanations\ncan be used to perform informative and targeted intent-based action steering\nand achieve median transmission bitrate improvements of 4% and tail\nimprovements of 10%.",
            "author": [
                "Claudio Fiandrino",
                "Leonardo Bonati",
                "Salvatore D'Oro",
                "Michele Polese",
                "Tommaso Melodia",
                "Joerg Widmer"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13667v1",
                "http://arxiv.org/pdf/2310.13667v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13664v2",
            "title": "Explainable Depression Symptom Detection in Social Media",
            "updated": "2023-10-23T08:31:50Z",
            "published": "2023-10-20T17:05:27Z",
            "summary": "Users of social platforms often perceive these sites as supportive spaces to\npost about their mental health issues. Those conversations contain important\ntraces about individuals' health risks. Recently, researchers have exploited\nthis online information to construct mental health detection models, which aim\nto identify users at risk on platforms like Twitter, Reddit or Facebook. Most\nof these models are centred on achieving good classification results, ignoring\nthe explainability and interpretability of the decisions. Recent research has\npointed out the importance of using clinical markers, such as the use of\nsymptoms, to improve trust in the computational models by health professionals.\nIn this paper, we propose using transformer-based architectures to detect and\nexplain the appearance of depressive symptom markers in the users' writings. We\npresent two approaches: i) train a model to classify, and another one to\nexplain the classifier's decision separately and ii) unify the two tasks\nsimultaneously using a single model. Additionally, for this latter manner, we\nalso investigated the performance of recent conversational LLMs when using\nin-context learning. Our natural language explanations enable clinicians to\ninterpret the models' decisions based on validated symptoms, enhancing trust in\nthe automated process. We evaluate our approach using recent symptom-based\ndatasets, employing both offline and expert-in-the-loop metrics to assess the\nquality of the explanations generated by our models. The experimental results\nshow that it is possible to achieve good classification results while\ngenerating interpretable symptom-based explanations.",
            "author": [
                "Eliseo Bao Souto",
                "Anxo P\u00e9rez",
                "Javier Parapar"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13664v2",
                "http://arxiv.org/pdf/2310.13664v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13655v1",
            "title": "Adaptive Robust Control Contraction Metrics: Transient Bounds in\n  Adaptive Control with Unmatched Uncertainties",
            "updated": "2023-10-20T16:59:20Z",
            "published": "2023-10-20T16:59:20Z",
            "summary": "This work presents a new sufficient condition for synthesizing nonlinear\ncontrollers that yield bounded closed-loop tracking error transients despite\nthe presence of unmatched uncertainties that are concurrently being learned\nonline. The approach utilizes contraction theory and addresses fundamental\nlimitations of existing approaches by allowing the contraction metric to depend\non the unknown model parameters. This allows the controller to incorporate new\nmodel estimates generated online without sacrificing its strong convergence and\nbounded transients guarantees. The approach is specifically designed for\ntrajectory tracking so the approach is more broadly applicable to adaptive\nmodel predictive control as well. Simulation results on a nonlinear system with\nunmatched uncertainties demonstrates the approach.",
            "author": [
                "Samuel G. Gessow",
                "Brett T. Lopez"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13655v1",
                "http://arxiv.org/pdf/2310.13655v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13654v1",
            "title": "An experimental study for early diagnosing Parkinson's disease using\n  machine learning",
            "updated": "2023-10-20T16:59:18Z",
            "published": "2023-10-20T16:59:18Z",
            "summary": "One of the most catastrophic neurological disorders worldwide is Parkinson's\nDisease. Along with it, the treatment is complicated and abundantly expensive.\nThe only effective action to control the progression is diagnosing it in the\nearly stage. However, this is challenging because early detection necessitates\na large and complex clinical study. This experimental work used Machine\nLearning techniques to automate the early detection of Parkinson's Disease from\nclinical characteristics, voice features and motor examination. In this study,\nwe develop ML models utilizing a public dataset of 130 individuals, 30 of whom\nare untreated Parkinson's Disease patients, 50 of whom are Rapid Eye Movement\nSleep Behaviour Disorder patients who are at a greater risk of contracting\nParkinson's Disease, and 50 of whom are Healthy Controls. We use MinMax Scaler\nto rescale the data points, Local Outlier Factor to remove outliers, and SMOTE\nto balance existing class frequency. Afterwards, apply a number of Machine\nLearning techniques. We implement the approaches in such a way that data\nleaking and overfitting are not possible. Finally, obtained 100% accuracy in\nclassifying PD and RBD patients, as well as 92% accuracy in classifying PD and\nHC individuals.",
            "author": [
                "Md. Taufiqul Haque Khan Tusar",
                "Md. Touhidul Islam",
                "Abul Hasnat Sakil"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13654v1",
                "http://arxiv.org/pdf/2310.13654v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13653v1",
            "title": "Optimal Transport for Measures with Noisy Tree Metric",
            "updated": "2023-10-20T16:56:08Z",
            "published": "2023-10-20T16:56:08Z",
            "summary": "We study optimal transport (OT) problem for probability measures supported on\na tree metric space. It is known that such OT problem (i.e., tree-Wasserstein\n(TW)) admits a closed-form expression, but depends fundamentally on the\nunderlying tree structure over supports of input measures. In practice, the\ngiven tree structure may be, however, perturbed due to noisy or adversarial\nmeasurements. In order to mitigate this issue, we follow the max-min robust OT\napproach which considers the maximal possible distances between two input\nmeasures over an uncertainty set of tree metrics. In general, this approach is\nhard to compute, even for measures supported in $1$-dimensional space, due to\nits non-convexity and non-smoothness which hinders its practical applications,\nespecially for large-scale settings. In this work, we propose \\emph{novel\nuncertainty sets of tree metrics} from the lens of edge deletion/addition which\ncovers a diversity of tree structures in an elegant framework. Consequently, by\nbuilding upon the proposed uncertainty sets, and leveraging the tree structure\nover supports, we show that the max-min robust OT also admits a closed-form\nexpression for a fast computation as its counterpart standard OT (i.e., TW).\nFurthermore, we demonstrate that the max-min robust OT satisfies the metric\nproperty and is negative definite. We then exploit its negative definiteness to\npropose \\emph{positive definite kernels} and test them in several simulations\non various real-world datasets on document classification and topological data\nanalysis for measures with noisy tree metric.",
            "author": [
                "Tam Le",
                "Truyen Nguyen",
                "Kenji Fukumizu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13653v1",
                "http://arxiv.org/pdf/2310.13653v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14790v2",
            "title": "Weighted Joint Maximum Mean Discrepancy Enabled\n  Multi-Source-Multi-Target Unsupervised Domain Adaptation Fault Diagnosis",
            "updated": "2023-11-23T16:27:37Z",
            "published": "2023-10-20T16:53:31Z",
            "summary": "Despite the remarkable results that can be achieved by data-driven\nintelligent fault diagnosis techniques, they presuppose the same distribution\nof training and test data as well as sufficient labeled data. Various operating\nstates often exist in practical scenarios, leading to the problem of domain\nshift that hinders the effectiveness of fault diagnosis. While recent\nunsupervised domain adaptation methods enable cross-domain fault diagnosis,\nthey struggle to effectively utilize information from multiple source domains\nand achieve effective diagnosis faults in multiple target domains\nsimultaneously. In this paper, we innovatively proposed a weighted joint\nmaximum mean discrepancy enabled multi-source-multi-target unsupervised domain\nadaptation (WJMMD-MDA), which realizes domain adaptation under\nmulti-source-multi-target scenarios in the field of fault diagnosis for the\nfirst time. The proposed method extracts sufficient information from multiple\nlabeled source domains and achieves domain alignment between source and target\ndomains through an improved weighted distance loss. As a result,\ndomain-invariant and discriminative features between multiple source and target\ndomains are learned with cross-domain fault diagnosis realized. The performance\nof the proposed method is evaluated in comprehensive comparative experiments on\nthree datasets, and the experimental results demonstrate the superiority of\nthis method.",
            "author": [
                "Zixuan Wang",
                "Haoran Tang",
                "Haibo Wang",
                "Bo Qin",
                "Mark D. Butala",
                "Weiming Shen",
                "Hongwei Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14790v2",
                "http://arxiv.org/pdf/2310.14790v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13648v1",
            "title": "Using ChatGPT throughout the Software Development Life Cycle by Novice\n  Developers",
            "updated": "2023-10-20T16:48:19Z",
            "published": "2023-10-20T16:48:19Z",
            "summary": "This study investigates the impact of ChatGPT -- a generative AI-based tool\n-- on undergraduate students' software development experiences. Through a\nthree-month project involving seven undergraduate students, ChatGPT was\nemployed as a supporting tool, and their experiences were systematically\nsurveyed before and after the projects. The research aims to answer four key\nquestions related to ChatGPT's effectiveness, advantages, limitations, impact\non learning, and challenges faced. The findings revealed significant skill gaps\namong undergraduate students, underscoring the importance of addressing\neducational deficiencies in software development. ChatGPT was found to have a\npositive influence on various phases of the software development life cycle,\nleading to enhanced efficiency, accuracy, and collaboration. ChatGPT also\nconsistently improved participants' foundational understanding and soft skills\nin software development. These findings underscore the significance of\nintegrating AI tools like ChatGPT into undergraduate students education,\nparticularly to bridge skill gaps and enhance productivity. However, a nuanced\napproach to technology reliance is essential, acknowledging the variability in\nopinions and the need for customization. Future research should explore\nstrategies to optimize ChatGPT's application across development contexts,\nensuring it maximizes learning while addressing specific challenges.",
            "author": [
                "Muhammad Waseem",
                "Teerath Das",
                "Aakash Ahmad",
                "Mahdi Fehmideh",
                "Peng Liang",
                "Tommi Mikkonen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13648v1",
                "http://arxiv.org/pdf/2310.13648v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13639v2",
            "title": "Contrastive Preference Learning: Learning from Human Feedback without RL",
            "updated": "2023-10-24T00:19:51Z",
            "published": "2023-10-20T16:37:56Z",
            "summary": "Reinforcement Learning from Human Feedback (RLHF) has emerged as a popular\nparadigm for aligning models with human intent. Typically RLHF algorithms\noperate in two phases: first, use human preferences to learn a reward function\nand second, align the model by optimizing the learned reward via reinforcement\nlearning (RL). This paradigm assumes that human preferences are distributed\naccording to reward, but recent work suggests that they instead follow the\nregret under the user's optimal policy. Thus, learning a reward function from\nfeedback is not only based on a flawed assumption of human preference, but also\nleads to unwieldy optimization challenges that stem from policy gradients or\nbootstrapping in the RL phase. Because of these optimization challenges,\ncontemporary RLHF methods restrict themselves to contextual bandit settings\n(e.g., as in large language models) or limit observation dimensionality (e.g.,\nstate-based robotics). We overcome these limitations by introducing a new\nfamily of algorithms for optimizing behavior from human feedback using the\nregret-based model of human preferences. Using the principle of maximum\nentropy, we derive Contrastive Preference Learning (CPL), an algorithm for\nlearning optimal policies from preferences without learning reward functions,\ncircumventing the need for RL. CPL is fully off-policy, uses only a simple\ncontrastive objective, and can be applied to arbitrary MDPs. This enables CPL\nto elegantly scale to high-dimensional and sequential RLHF problems while being\nsimpler than prior methods.",
            "author": [
                "Joey Hejna",
                "Rafael Rafailov",
                "Harshit Sikchi",
                "Chelsea Finn",
                "Scott Niekum",
                "W. Bradley Knox",
                "Dorsa Sadigh"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13639v2",
                "http://arxiv.org/pdf/2310.13639v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13637v1",
            "title": "Application Performance Benchmarks for Quantum Computers",
            "updated": "2023-10-20T16:37:03Z",
            "published": "2023-10-20T16:37:03Z",
            "summary": "Current technological advancements of quantum computers highlight the need\nfor application-driven, practical and well-defined methods of benchmarking\ntheir performance. As the existing NISQ device's quality of two-qubit gate\nerrors rate is even around one percent and the number of qubits is still\nlimited to a few or several dozen, naturally, we need to propose rather small\nalgorithms instances taken from key promising application areas, such as\nquantum chemistry, combinatorial optimisation or machine learning. While many\ntechniques for assessing the performance of logical components such as gate\nfidelity and qubit coherence exist, it is often challenging to extrapolate\nthose values onto the performance of different quantum algorithms and\nsubroutines. This work aims to introduce a series of initial quantum\napplication benchmarks together with a methodology of execution for measuring\nperformance and fidelity of the results. The proposed suite refers to several\nvariational algorithms, widely-used on current NISQ devices, but also includes\nexamples of quantum circuits designed for a fault-tolerant quantum computer.",
            "author": [
                "Krzysztof Kurowski",
                "Piotr Rydlichowski",
                "Konrad Wojciechowski",
                "Tomasz Pecyna",
                "Mateusz Slysz"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13637v1",
                "http://arxiv.org/pdf/2310.13637v1"
            ],
            "primary_category": "cs.PF",
            "category": [
                "cs.PF",
                "cs.ET"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13634v1",
            "title": "Optimising the exchange of Majorana zero modes in a quantum nanowire\n  network",
            "updated": "2023-10-20T16:32:17Z",
            "published": "2023-10-20T16:32:17Z",
            "summary": "Determination of optimal control protocols for Majorana zero modes during\ntheir exchange is a crucial step towards the realisation of the topological\nquantum computer. In this paper, we study the finite-time exchange process of\nMajorana zero modes on a network formed by coupled $p$-wave superconducting\none-dimensional nanowires. We provide scalable computational tools for\noptimising such an exchange process relying on deep learning techniques. To\naccomplish the scalability, we derive and implement an analytic formula for the\ngradient of the quantum infidelity which measures the error in the topological\nquantum gate generation in the Majorana zero modes exchange. Our optimisation\nstrategy relies on learning the optimised transport protocol via a neural net\nwhich is followed by direct gradient descent fine tuning. The optimised\nexchange protocols in the super-adiabatic regime discover the fact that the\nMajorana zero modes must necessarily stop before crossing a junction point in\nthe network. We explain that this is caused by fast changes in the energy gap\nof the system whenever one of the Majorana zero modes approaches a junction\npoint. In particular, the energy gap exhibits oscillations followed by a sharp\njump. We explain this phenomenon analytically in the regime where the Majorana\nzero modes are completely localised. Finally, we study how the disorder in the\nquantum nanowire affects the exchange protocols. This shows that understanding\nthe disorder pattern would allow one to improve quantum gate fidelity by one to\ntwo orders of magnitude.",
            "author": [
                "Tomasz Maciazek",
                "Aaron Conlon"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13634v1",
                "http://arxiv.org/pdf/2310.13634v1"
            ],
            "primary_category": "cond-mat.mes-hall",
            "category": [
                "cond-mat.mes-hall"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13627v1",
            "title": "Deep-Learning-based Change Detection with Spaceborne Hyperspectral\n  PRISMA data",
            "updated": "2023-10-20T16:22:53Z",
            "published": "2023-10-20T16:22:53Z",
            "summary": "Change detection (CD) methods have been applied to optical data for decades,\nwhile the use of hyperspectral data with a fine spectral resolution has been\nrarely explored. CD is applied in several sectors, such as environmental\nmonitoring and disaster management. Thanks to the PRecursore IperSpettrale\ndella Missione operativA (PRISMA), hyperspectral-from-space CD is now possible.\nIn this work, we apply standard and deep-learning (DL) CD methods to different\ntargets, from natural to urban areas. We propose a pipeline starting from\ncoregistration, followed by CD with a full-spectrum algorithm and by a DL\nnetwork developed for optical data. We find that changes in vegetation and\nbuilt environments are well captured. The spectral information is valuable to\nidentify subtle changes and the DL methods are less affected by noise compared\nto the statistical method, but atmospheric effects and the lack of reliable\nground truth represent a major challenge to hyperspectral CD.",
            "author": [
                "J. F. Amieva",
                "A. Austoni",
                "M. A. Brovelli",
                "L. Ansalone",
                "P. Naylor",
                "F. Serva",
                "B. Le Saux"
            ],
            "link": [
                "http://dx.doi.org/10.2760/46796",
                "http://arxiv.org/abs/2310.13627v1",
                "http://arxiv.org/pdf/2310.13627v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13622v1",
            "title": "What you see is what you get: Experience ranking with deep neural\n  dataset-to-dataset similarity for topological localisation",
            "updated": "2023-10-20T16:13:21Z",
            "published": "2023-10-20T16:13:21Z",
            "summary": "Recalling the most relevant visual memories for localisation or understanding\na priori the likely outcome of localisation effort against a particular visual\nmemory is useful for efficient and robust visual navigation. Solutions to this\nproblem should be divorced from performance appraisal against ground truth - as\nthis is not available at run-time - and should ideally be based on\ngeneralisable environmental observations. For this, we propose applying the\nrecently developed Visual DNA as a highly scalable tool for comparing datasets\nof images - in this work, sequences of map and live experiences. In the case of\nlocalisation, important dataset differences impacting performance are modes of\nappearance change, including weather, lighting, and season. Specifically, for\nany deep architecture which is used for place recognition by matching feature\nvolumes at a particular layer, we use distribution measures to compare\nneuron-wise activation statistics between live images and multiple previously\nrecorded past experiences, with a potentially large seasonal (winter/summer) or\ntime of day (day/night) shift. We find that differences in these statistics\ncorrelate to performance when localising using a past experience with the same\nappearance gap. We validate our approach over the Nordland cross-season dataset\nas well as data from Oxford's University Parks with lighting and mild seasonal\nchange, showing excellent ability of our system to rank actual localisation\nperformance across candidate experiences.",
            "author": [
                "Matthew Gadd",
                "Benjamin Ramtoula",
                "Daniele De Martini",
                "Paul Newman"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13622v1",
                "http://arxiv.org/pdf/2310.13622v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13615v1",
            "title": "Three Questions Concerning the Use of Large Language Models to\n  Facilitate Mathematics Learning",
            "updated": "2023-10-20T16:05:35Z",
            "published": "2023-10-20T16:05:35Z",
            "summary": "Due to the remarkable language understanding and generation abilities of\nlarge language models (LLMs), their use in educational applications has been\nexplored. However, little work has been done on investigating the pedagogical\nability of LLMs in helping students to learn mathematics. In this position\npaper, we discuss the challenges associated with employing LLMs to enhance\nstudents' mathematical problem-solving skills by providing adaptive feedback.\nApart from generating the wrong reasoning processes, LLMs can misinterpret the\nmeaning of the question, and also exhibit difficulty in understanding the given\nquestions' rationales when attempting to correct students' answers. Three\nresearch questions are formulated.",
            "author": [
                "An-Zi Yen",
                "Wei-Ling Hsu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13615v1",
                "http://arxiv.org/pdf/2310.13615v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13607v1",
            "title": "Analyzing the contribution of different passively collected data to\n  predict Stress and Depression",
            "updated": "2023-10-20T15:57:22Z",
            "published": "2023-10-20T15:57:22Z",
            "summary": "The possibility of recognizing diverse aspects of human behavior and\nenvironmental context from passively captured data motivates its use for mental\nhealth assessment. In this paper, we analyze the contribution of different\npassively collected sensor data types (WiFi, GPS, Social interaction, Phone\nLog, Physical Activity, Audio, and Academic features) to predict daily\nselfreport stress and PHQ-9 depression score. First, we compute 125 mid-level\nfeatures from the original raw data. These 125 features include groups of\nfeatures from the different sensor data types. Then, we evaluate the\ncontribution of each feature type by comparing the performance of Neural\nNetwork models trained with all features against Neural Network models trained\nwith specific feature groups. Our results show that WiFi features (which encode\nmobility patterns) and Phone Log features (which encode information correlated\nwith sleep patterns), provide significative information for stress and\ndepression prediction.",
            "author": [
                "Irene Bonafonte",
                "Cristina Bustos",
                "Abraham Larrazolo",
                "Gilberto Lorenzo Martinez Luna",
                "Adolfo Guzman Arenas",
                "Xavier Baro",
                "Isaac Tourgeman",
                "Mercedes Balcells",
                "Agata Lapedriza"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13607v1",
                "http://arxiv.org/pdf/2310.13607v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13605v1",
            "title": "FMRT: Learning Accurate Feature Matching with Reconciliatory Transformer",
            "updated": "2023-10-20T15:54:18Z",
            "published": "2023-10-20T15:54:18Z",
            "summary": "Local Feature Matching, an essential component of several computer vision\ntasks (e.g., structure from motion and visual localization), has been\neffectively settled by Transformer-based methods. However, these methods only\nintegrate long-range context information among keypoints with a fixed receptive\nfield, which constrains the network from reconciling the importance of features\nwith different receptive fields to realize complete image perception, hence\nlimiting the matching accuracy. In addition, these methods utilize a\nconventional handcrafted encoding approach to integrate the positional\ninformation of keypoints into the visual descriptors, which limits the\ncapability of the network to extract reliable positional encoding message. In\nthis study, we propose Feature Matching with Reconciliatory Transformer (FMRT),\na novel Transformer-based detector-free method that reconciles different\nfeatures with multiple receptive fields adaptively and utilizes parallel\nnetworks to realize reliable positional encoding. Specifically, FMRT proposes a\ndedicated Reconciliatory Transformer (RecFormer) that consists of a Global\nPerception Attention Layer (GPAL) to extract visual descriptors with different\nreceptive fields and integrate global context information under various scales,\nPerception Weight Layer (PWL) to measure the importance of various receptive\nfields adaptively, and Local Perception Feed-forward Network (LPFFN) to extract\ndeep aggregated multi-scale local feature representation. Extensive experiments\ndemonstrate that FMRT yields extraordinary performance on multiple benchmarks,\nincluding pose estimation, visual localization, homography estimation, and\nimage matching.",
            "author": [
                "Xinyu Zhang",
                "Li Wang",
                "Zhiqiang Jiang",
                "Kun Dai",
                "Tao Xie",
                "Lei Yang",
                "Wenhao Yu",
                "Yang Shen",
                "Jun Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13605v1",
                "http://arxiv.org/pdf/2310.13605v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13595v2",
            "title": "The History and Risks of Reinforcement Learning and Human Feedback",
            "updated": "2023-11-28T18:16:11Z",
            "published": "2023-10-20T15:45:16Z",
            "summary": "Reinforcement learning from human feedback (RLHF) has emerged as a powerful\ntechnique to make large language models (LLMs) easier to use and more\neffective. A core piece of the RLHF process is the training and utilization of\na model of human preferences that acts as a reward function for optimization.\nThis approach, which operates at the intersection of many stakeholders and\nacademic disciplines, remains poorly understood. RLHF reward models are often\ncited as being central to achieving performance, yet very few descriptors of\ncapabilities, evaluations, training methods, or open-source models exist. Given\nthis lack of information, further study and transparency is needed for learned\nRLHF reward models. In this paper, we illustrate the complex history of\noptimizing preferences, and articulate lines of inquiry to understand the\nsociotechnical context of reward models. In particular, we highlight the\nontological differences between costs, rewards, and preferences at stake in\nRLHF's foundations, related methodological tensions, and possible research\ndirections to improve general understanding of how reward models function.",
            "author": [
                "Nathan Lambert",
                "Thomas Krendl Gilbert",
                "Tom Zick"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13595v2",
                "http://arxiv.org/pdf/2310.13595v2"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13593v1",
            "title": "Longer-range Contextualized Masked Autoencoder",
            "updated": "2023-10-20T15:42:47Z",
            "published": "2023-10-20T15:42:47Z",
            "summary": "Masked image modeling (MIM) has emerged as a promising self-supervised\nlearning (SSL) strategy. The MIM pre-training facilitates learning powerful\nrepresentations using an encoder-decoder framework by randomly masking some\ninput pixels and reconstructing the masked pixels from the remaining ones.\nHowever, as the encoder is trained with partial pixels, the MIM pre-training\ncan suffer from a low capability of understanding long-range dependency. This\nlimitation may hinder its capability to fully understand multiple-range\ndependencies, resulting in narrow highlighted regions in the attention map that\nmay incur accuracy drops. To mitigate the limitation, We propose a\nself-supervised learning framework, named Longer-range Contextualized Masked\nAutoencoder (LC-MAE). LC-MAE effectively leverages a global context\nunderstanding of visual representations while simultaneously reducing the\nspatial redundancy of input at the same time. Our method steers the encoder to\nlearn from entire pixels in multiple views while also learning local\nrepresentation from sparse pixels. As a result, LC-MAE learns more\ndiscriminative representations, leading to a performance improvement of\nachieving 84.2% top-1 accuracy with ViT-B on ImageNet-1K with 0.6%p gain. We\nattribute the success to the enhanced pre-training method, as evidenced by the\nsingular value spectrum and attention analyses. Finally, LC-MAE achieves\nsignificant performance gains at the downstream semantic segmentation and\nfine-grained visual classification tasks; and on diverse robust evaluation\nmetrics. Our code will be publicly available.",
            "author": [
                "Taekyung Kim",
                "Sanghyuk Chun",
                "Byeongho Heo",
                "Dongyoon Han"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13593v1",
                "http://arxiv.org/pdf/2310.13593v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14782v1",
            "title": "Towards equilibrium molecular conformation generation with GFlowNets",
            "updated": "2023-10-20T15:41:50Z",
            "published": "2023-10-20T15:41:50Z",
            "summary": "Sampling diverse, thermodynamically feasible molecular conformations plays a\ncrucial role in predicting properties of a molecule. In this paper we propose\nto use GFlowNet for sampling conformations of small molecules from the\nBoltzmann distribution, as determined by the molecule's energy. The proposed\napproach can be used in combination with energy estimation methods of different\nfidelity and discovers a diverse set of low-energy conformations for highly\nflexible drug-like molecules. We demonstrate that GFlowNet can reproduce\nmolecular potential energy surfaces by sampling proportionally to the Boltzmann\ndistribution.",
            "author": [
                "Alexandra Volokhova",
                "Micha\u0142 Koziarski",
                "Alex Hern\u00e1ndez-Garc\u00eda",
                "Cheng-Hao Liu",
                "Santiago Miret",
                "Pablo Lemos",
                "Luca Thiede",
                "Zichao Yan",
                "Al\u00e1n Aspuru-Guzik",
                "Yoshua Bengio"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14782v1",
                "http://arxiv.org/pdf/2310.14782v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13590v1",
            "title": "ReLM: Leveraging Language Models for Enhanced Chemical Reaction\n  Prediction",
            "updated": "2023-10-20T15:33:23Z",
            "published": "2023-10-20T15:33:23Z",
            "summary": "Predicting chemical reactions, a fundamental challenge in chemistry, involves\nforecasting the resulting products from a given reaction process. Conventional\ntechniques, notably those employing Graph Neural Networks (GNNs), are often\nlimited by insufficient training data and their inability to utilize textual\ninformation, undermining their applicability in real-world applications. In\nthis work, we propose ReLM, a novel framework that leverages the chemical\nknowledge encoded in language models (LMs) to assist GNNs, thereby enhancing\nthe accuracy of real-world chemical reaction predictions. To further enhance\nthe model's robustness and interpretability, we incorporate the confidence\nscore strategy, enabling the LMs to self-assess the reliability of their\npredictions. Our experimental results demonstrate that ReLM improves the\nperformance of state-of-the-art GNN-based methods across various chemical\nreaction datasets, especially in out-of-distribution settings. Codes are\navailable at https://github.com/syr-cn/ReLM.",
            "author": [
                "Yaorui Shi",
                "An Zhang",
                "Enzhi Zhang",
                "Zhiyuan Liu",
                "Xiang Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13590v1",
                "http://arxiv.org/pdf/2310.13590v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13588v2",
            "title": "Simultaneous Machine Translation with Tailored Reference",
            "updated": "2023-10-26T03:17:37Z",
            "published": "2023-10-20T15:32:26Z",
            "summary": "Simultaneous machine translation (SiMT) generates translation while reading\nthe whole source sentence. However, existing SiMT models are typically trained\nusing the same reference disregarding the varying amounts of available source\ninformation at different latency. Training the model with ground-truth at low\nlatency may introduce forced anticipations, whereas utilizing reference\nconsistent with the source word order at high latency results in performance\ndegradation. Consequently, it is crucial to train the SiMT model with\nappropriate reference that avoids forced anticipations during training while\nmaintaining high quality. In this paper, we propose a novel method that\nprovides tailored reference for the SiMT models trained at different latency by\nrephrasing the ground-truth. Specifically, we introduce the tailor, induced by\nreinforcement learning, to modify ground-truth to the tailored reference. The\nSiMT model is trained with the tailored reference and jointly optimized with\nthe tailor to enhance performance. Importantly, our method is applicable to a\nwide range of current SiMT approaches. Experiments on three translation tasks\ndemonstrate that our method achieves state-of-the-art performance in both fixed\nand adaptive policies.",
            "author": [
                "Shoutao Guo",
                "Shaolei Zhang",
                "Yang Feng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13588v2",
                "http://arxiv.org/pdf/2310.13588v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13585v1",
            "title": "POTLoc: Pseudo-Label Oriented Transformer for Point-Supervised Temporal\n  Action Localization",
            "updated": "2023-10-20T15:28:06Z",
            "published": "2023-10-20T15:28:06Z",
            "summary": "This paper tackles the challenge of point-supervised temporal action\ndetection, wherein only a single frame is annotated for each action instance in\nthe training set. Most of the current methods, hindered by the sparse nature of\nannotated points, struggle to effectively represent the continuous structure of\nactions or the inherent temporal and semantic dependencies within action\ninstances. Consequently, these methods frequently learn merely the most\ndistinctive segments of actions, leading to the creation of incomplete action\nproposals. This paper proposes POTLoc, a Pseudo-label Oriented Transformer for\nweakly-supervised Action Localization utilizing only point-level annotation.\nPOTLoc is designed to identify and track continuous action structures via a\nself-training strategy. The base model begins by generating action proposals\nsolely with point-level supervision. These proposals undergo refinement and\nregression to enhance the precision of the estimated action boundaries, which\nsubsequently results in the production of `pseudo-labels' to serve as\nsupplementary supervisory signals. The architecture of the model integrates a\ntransformer with a temporal feature pyramid to capture video snippet\ndependencies and model actions of varying duration. The pseudo-labels,\nproviding information about the coarse locations and boundaries of actions,\nassist in guiding the transformer for enhanced learning of action dynamics.\nPOTLoc outperforms the state-of-the-art point-supervised methods on THUMOS'14\nand ActivityNet-v1.2 datasets, showing a significant improvement of 5% average\nmAP on the former.",
            "author": [
                "Elahe Vahdani",
                "Yingli Tian"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13585v1",
                "http://arxiv.org/pdf/2310.13585v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13583v1",
            "title": "Improving Cross-Lingual Transfer through Subtree-Aware Word Reordering",
            "updated": "2023-10-20T15:25:53Z",
            "published": "2023-10-20T15:25:53Z",
            "summary": "Despite the impressive growth of the abilities of multilingual language\nmodels, such as XLM-R and mT5, it has been shown that they still face\ndifficulties when tackling typologically-distant languages, particularly in the\nlow-resource setting. One obstacle for effective cross-lingual transfer is\nvariability in word-order patterns. It can be potentially mitigated via source-\nor target-side word reordering, and numerous approaches to reordering have been\nproposed. However, they rely on language-specific rules, work on the level of\nPOS tags, or only target the main clause, leaving subordinate clauses intact.\nTo address these limitations, we present a new powerful reordering method,\ndefined in terms of Universal Dependencies, that is able to learn fine-grained\nword-order patterns conditioned on the syntactic context from a small amount of\nannotated data and can be applied at all levels of the syntactic tree. We\nconduct experiments on a diverse set of tasks and show that our method\nconsistently outperforms strong baselines over different language pairs and\nmodel architectures. This performance advantage holds true in both zero-shot\nand few-shot scenarios.",
            "author": [
                "Ofir Arviv",
                "Dmitry Nikolaev",
                "Taelin Karidi",
                "Omri Abend"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13583v1",
                "http://arxiv.org/pdf/2310.13583v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13581v1",
            "title": "SPARE: A Single-Pass Neural Model for Relational Databases",
            "updated": "2023-10-20T15:23:17Z",
            "published": "2023-10-20T15:23:17Z",
            "summary": "While there has been extensive work on deep neural networks for images and\ntext, deep learning for relational databases (RDBs) is still a rather\nunexplored field.\n  One direction that recently gained traction is to apply Graph Neural Networks\n(GNNs) to RBDs. However, training GNNs on large relational databases (i.e.,\ndata stored in multiple database tables) is rather inefficient due to multiple\nrounds of training and potentially large and inefficient representations.\nHence, in this paper we propose SPARE (Single-Pass Relational models), a new\nclass of neural models that can be trained efficiently on RDBs while providing\nsimilar accuracies as GNNs. For enabling efficient training, different from\nGNNs, SPARE makes use of the fact that data in RDBs has a regular structure,\nwhich allows one to train these models in a single pass while exploiting\nsymmetries at the same time. Our extensive empirical evaluation demonstrates\nthat SPARE can significantly speedup both training and inference while offering\ncompetitive predictive performance over numerous baselines.",
            "author": [
                "Benjamin Hilprecht",
                "Kristian Kersting",
                "Carsten Binnig"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13581v1",
                "http://arxiv.org/pdf/2310.13581v1"
            ],
            "primary_category": "cs.DB",
            "category": [
                "cs.DB",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13577v1",
            "title": "Cooperative Multi-Agent Deep Reinforcement Learning for Adaptive\n  Decentralized Emergency Voltage Control",
            "updated": "2023-10-20T15:16:07Z",
            "published": "2023-10-20T15:16:07Z",
            "summary": "Under voltage load shedding (UVLS) for power grid emergency control builds\nthe last defensive perimeter to prevent cascade outages and blackouts in case\nof contingencies. This letter proposes a novel cooperative multi-agent deep\nreinforcement learning (MADRL)-based UVLS algorithm in an adaptive\ndecentralized way. With well-designed input signals reflecting the voltage\ndeviation, newly structured neural networks are developed as intelligent agents\nto obtain control actions and their probabilities to accommodate high\nuncertainties in volatile power system operations. Moreover, the interaction\namong the agents for coordinated control is implemented and refined by a\nstate-of-the-art attention mechanism, which helps agents concentratively learn\neffective interacted information. The proposed method realizes decentralized\ncoordinated control, adapting to extremely high uncertainties. Case studies on\nan IEEE benchmark system indicate the superior performance of the proposed\nalgorithm.",
            "author": [
                "Ying Zhang",
                "Meng Yue"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13577v1",
                "http://arxiv.org/pdf/2310.13577v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13576v1",
            "title": "Tree Search in DAG Space with Model-based Reinforcement Learning for\n  Causal Discovery",
            "updated": "2023-10-20T15:14:18Z",
            "published": "2023-10-20T15:14:18Z",
            "summary": "Identifying causal structure is central to many fields ranging from strategic\ndecision-making to biology and economics. In this work, we propose a\nmodel-based reinforcement learning method for causal discovery based on tree\nsearch, which builds directed acyclic graphs incrementally. We also formalize\nand prove the correctness of an efficient algorithm for excluding edges that\nwould introduce cycles, which enables deeper discrete search and sampling in\nDAG space. We evaluate our approach on two real-world tasks, achieving\nsubstantially better performance than the state-of-the-art model-free method\nand greedy search, constituting a promising advancement for combinatorial\nmethods.",
            "author": [
                "Victor-Alexandru Darvariu",
                "Stephen Hailes",
                "Mirco Musolesi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13576v1",
                "http://arxiv.org/pdf/2310.13576v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13574v1",
            "title": "Progressive Dual Priori Network for Generalized Breast Tumor\n  Segmentation",
            "updated": "2023-10-20T15:12:06Z",
            "published": "2023-10-20T15:12:06Z",
            "summary": "To promote the generalization ability of breast tumor segmentation models, as\nwell as to improve the segmentation performance for breast tumors with smaller\nsize, low-contrast amd irregular shape, we propose a progressive dual priori\nnetwork (PDPNet) to segment breast tumors from dynamic enhanced magnetic\nresonance images (DCE-MRI) acquired at different sites. The PDPNet first\ncropped tumor regions with a coarse-segmentation based localization module,\nthen the breast tumor mask was progressively refined by using the weak semantic\npriori and cross-scale correlation prior knowledge. To validate the\neffectiveness of PDPNet, we compared it with several state-of-the-art methods\non multi-center datasets. The results showed that, comparing against the\nsuboptimal method, the DSC, SEN, KAPPA and HD95 of PDPNet were improved 3.63\\%,\n8.19\\%, 5.52\\%, and 3.66\\% respectively. In addition, through ablations, we\ndemonstrated that the proposed localization module can decrease the influence\nof normal tissues and therefore improve the generalization ability of the\nmodel. The weak semantic priors allow focusing on tumor regions to avoid\nmissing small tumors and low-contrast tumors. The cross-scale correlation\npriors are beneficial for promoting the shape-aware ability for irregual\ntumors. Thus integrating them in a unified framework improved the multi-center\nbreast tumor segmentation performance.",
            "author": [
                "Li Wang",
                "Lihui Wang",
                "Zixiang Kuai",
                "Lei Tang",
                "Yingfeng Ou",
                "Chen Ye",
                "Yuemin Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13574v1",
                "http://arxiv.org/pdf/2310.13574v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13572v2",
            "title": "Unraveling the Enigma of Double Descent: An In-depth Analysis through\n  the Lens of Learned Feature Space",
            "updated": "2023-12-05T11:53:43Z",
            "published": "2023-10-20T15:10:16Z",
            "summary": "Double descent presents a counter-intuitive aspect within the machine\nlearning domain, and researchers have observed its manifestation in various\nmodels and tasks. While some theoretical explanations have been proposed for\nthis phenomenon in specific contexts, an accepted theory to account for its\noccurrence in deep learning remains yet to be established. In this study, we\nrevisit the phenomenon of double descent and demonstrate that its occurrence is\nstrongly influenced by the presence of noisy data. Through conducting a\ncomprehensive analysis of the feature space of learned representations, we\nunveil that double descent arises in imperfect models trained with noisy data.\nWe argue that double descent is a consequence of the model first learning the\nnoisy data until interpolation and then adding implicit regularization via\nover-parameterization acquiring therefore capability to separate the\ninformation from the noise.",
            "author": [
                "Yufei Gu",
                "Xiaoqing Zheng",
                "Tomaso Aste"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13572v2",
                "http://arxiv.org/pdf/2310.13572v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13570v2",
            "title": "A Simple Baseline for Knowledge-Based Visual Question Answering",
            "updated": "2023-10-24T13:24:25Z",
            "published": "2023-10-20T15:08:17Z",
            "summary": "This paper is on the problem of Knowledge-Based Visual Question Answering\n(KB-VQA). Recent works have emphasized the significance of incorporating both\nexplicit (through external databases) and implicit (through LLMs) knowledge to\nanswer questions requiring external knowledge effectively. A common limitation\nof such approaches is that they consist of relatively complicated pipelines and\noften heavily rely on accessing GPT-3 API. Our main contribution in this paper\nis to propose a much simpler and readily reproducible pipeline which, in a\nnutshell, is based on efficient in-context learning by prompting LLaMA (1 and\n2) using question-informative captions as contextual information. Contrary to\nrecent approaches, our method is training-free, does not require access to\nexternal databases or APIs, and yet achieves state-of-the-art accuracy on the\nOK-VQA and A-OK-VQA datasets. Finally, we perform several ablation studies to\nunderstand important aspects of our method. Our code is publicly available at\nhttps://github.com/alexandrosXe/ASimple-Baseline-For-Knowledge-Based-VQA",
            "author": [
                "Alexandros Xenos",
                "Themos Stafylakis",
                "Ioannis Patras",
                "Georgios Tzimiropoulos"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13570v2",
                "http://arxiv.org/pdf/2310.13570v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13565v1",
            "title": "Reward Shaping for Happier Autonomous Cyber Security Agents",
            "updated": "2023-10-20T15:04:42Z",
            "published": "2023-10-20T15:04:42Z",
            "summary": "As machine learning models become more capable, they have exhibited increased\npotential in solving complex tasks. One of the most promising directions uses\ndeep reinforcement learning to train autonomous agents in computer network\ndefense tasks. This work studies the impact of the reward signal that is\nprovided to the agents when training for this task. Due to the nature of\ncybersecurity tasks, the reward signal is typically 1) in the form of penalties\n(e.g., when a compromise occurs), and 2) distributed sparsely across each\ndefense episode. Such reward characteristics are atypical of classic\nreinforcement learning tasks where the agent is regularly rewarded for progress\n(cf. to getting occasionally penalized for failures). We investigate reward\nshaping techniques that could bridge this gap so as to enable agents to train\nmore sample-efficiently and potentially converge to a better performance. We\nfirst show that deep reinforcement learning algorithms are sensitive to the\nmagnitude of the penalties and their relative size. Then, we combine penalties\nwith positive external rewards and study their effect compared to penalty-only\ntraining. Finally, we evaluate intrinsic curiosity as an internal positive\nreward mechanism and discuss why it might not be as advantageous for high-level\nnetwork monitoring tasks.",
            "author": [
                "Elizabeth Bates",
                "Vasilios Mavroudis",
                "Chris Hicks"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13565v1",
                "http://arxiv.org/pdf/2310.13565v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13561v1",
            "title": "Cache & Distil: Optimising API Calls to Large Language Models",
            "updated": "2023-10-20T15:01:55Z",
            "published": "2023-10-20T15:01:55Z",
            "summary": "Large-scale deployment of generative AI tools often depends on costly API\ncalls to a Large Language Model (LLM) to fulfil user queries. To curtail the\nfrequency of these calls, one can employ a smaller language model -- a student\n-- which is continuously trained on the responses of the LLM. This student\ngradually gains proficiency in independently handling an increasing number of\nuser requests, a process we term neural caching. The crucial element in neural\ncaching is a policy that decides which requests should be processed by the\nstudent alone and which should be redirected to the LLM, subsequently aiding\nthe student's learning. In this study, we focus on classification tasks, and we\nconsider a range of classic active learning-based selection criteria as the\npolicy. Our experiments suggest that Margin Sampling and Query by Committee\nbring consistent benefits across tasks and budgets.",
            "author": [
                "Guillem Ram\u00edrez",
                "Matthias Lindemann",
                "Alexandra Birch",
                "Ivan Titov"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13561v1",
                "http://arxiv.org/pdf/2310.13561v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13553v1",
            "title": "On sample complexity of conditional independence testing with Von Mises\n  estimator with application to causal discovery",
            "updated": "2023-10-20T14:52:25Z",
            "published": "2023-10-20T14:52:25Z",
            "summary": "Motivated by conditional independence testing, an essential step in\nconstraint-based causal discovery algorithms, we study the nonparametric Von\nMises estimator for the entropy of multivariate distributions built on a kernel\ndensity estimator. We establish an exponential concentration inequality for\nthis estimator. We design a test for conditional independence (CI) based on our\nestimator, called VM-CI, which achieves optimal parametric rates under\nsmoothness assumptions. Leveraging the exponential concentration, we prove a\ntight upper bound for the overall error of VM-CI. This, in turn, allows us to\ncharacterize the sample complexity of any constraint-based causal discovery\nalgorithm that uses VM-CI for CI tests. To the best of our knowledge, this is\nthe first sample complexity guarantee for causal discovery for continuous\nvariables. Furthermore, we empirically show that VM-CI outperforms other\npopular CI tests in terms of either time or sample complexity (or both), which\ntranslates to a better performance in structure learning as well.",
            "author": [
                "Fateme Jamshidi",
                "Luca Ganassali",
                "Negar Kiyavash"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13553v1",
                "http://arxiv.org/pdf/2310.13553v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13552v2",
            "title": "Self-prompted Chain-of-Thought on Large Language Models for Open-domain\n  Multi-hop Reasoning",
            "updated": "2023-10-23T05:42:42Z",
            "published": "2023-10-20T14:51:10Z",
            "summary": "In open-domain question-answering (ODQA), most existing questions require\nsingle-hop reasoning on commonsense. To further extend this task, we officially\nintroduce open-domain multi-hop reasoning (ODMR) by answering multi-hop\nquestions with explicit reasoning steps in open-domain setting. Recently, large\nlanguage models (LLMs) have found significant utility in facilitating ODQA\nwithout external corpus. Furthermore, chain-of-thought (CoT) prompting boosts\nthe reasoning capability of LLMs to a greater extent with manual or automated\nparadigms. However, existing automated methods lack of quality assurance, while\nmanual approaches suffer from limited scalability and poor diversity, hindering\nthe capabilities of LLMs. In this paper, we propose Self-prompted\nChain-of-Thought (SP-CoT), an automated framework to mass-produce high quality\nCoTs of LLMs, by LLMs and for LLMs. SP-CoT introduces an automated generation\npipeline of high quality ODMR datasets, an adaptive sampler for in-context CoT\nselection and self-prompted inference via in-context learning. Extensive\nexperiments on four multi-hop question-answering benchmarks show that our\nproposed SP-CoT not only significantly surpasses the previous SOTA methods on\nlarge-scale (175B) LLMs, but also nearly doubles the zero-shot performance of\nsmall-scale (13B) LLMs. Further analysis reveals the remarkable capability of\nSP-CoT to elicit direct and concise intermediate reasoning steps by recalling\n$\\sim$50\\% of intermediate answers on MuSiQue-Ans dataset.",
            "author": [
                "Jinyuan Wang",
                "Junlong Li",
                "Hai Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13552v2",
                "http://arxiv.org/pdf/2310.13552v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13550v1",
            "title": "Provable Benefits of Multi-task RL under Non-Markovian Decision Making\n  Processes",
            "updated": "2023-10-20T14:50:28Z",
            "published": "2023-10-20T14:50:28Z",
            "summary": "In multi-task reinforcement learning (RL) under Markov decision processes\n(MDPs), the presence of shared latent structures among multiple MDPs has been\nshown to yield significant benefits to the sample efficiency compared to\nsingle-task RL. In this paper, we investigate whether such a benefit can extend\nto more general sequential decision making problems, such as partially\nobservable MDPs (POMDPs) and more general predictive state representations\n(PSRs). The main challenge here is that the large and complex model space makes\nit hard to identify what types of common latent structure of multi-task PSRs\ncan reduce the model complexity and improve sample efficiency. To this end, we\nposit a joint model class for tasks and use the notion of $\\eta$-bracketing\nnumber to quantify its complexity; this number also serves as a general metric\nto capture the similarity of tasks and thus determines the benefit of\nmulti-task over single-task RL. We first study upstream multi-task learning\nover PSRs, in which all tasks share the same observation and action spaces. We\npropose a provably efficient algorithm UMT-PSR for finding near-optimal\npolicies for all PSRs, and demonstrate that the advantage of multi-task\nlearning manifests if the joint model class of PSRs has a smaller\n$\\eta$-bracketing number compared to that of individual single-task learning.\nWe also provide several example multi-task PSRs with small $\\eta$-bracketing\nnumbers, which reap the benefits of multi-task learning. We further investigate\ndownstream learning, in which the agent needs to learn a new target task that\nshares some commonalities with the upstream tasks via a similarity constraint.\nBy exploiting the learned PSRs from the upstream, we develop a sample-efficient\nalgorithm that provably finds a near-optimal policy.",
            "author": [
                "Ruiquan Huang",
                "Yuan Cheng",
                "Jing Yang",
                "Vincent Tan",
                "Yingbin Liang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13550v1",
                "http://arxiv.org/pdf/2310.13550v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13549v1",
            "title": "The Perils & Promises of Fact-checking with Large Language Models",
            "updated": "2023-10-20T14:49:47Z",
            "published": "2023-10-20T14:49:47Z",
            "summary": "Autonomous fact-checking, using machine learning to verify claims, has grown\nvital as misinformation spreads beyond human fact-checking capacity. Large\nLanguage Models (LLMs) like GPT-4 are increasingly trusted to verify\ninformation and write academic papers, lawsuits, and news articles, emphasizing\ntheir role in discerning truth from falsehood and the importance of being able\nto verify their outputs. Here, we evaluate the use of LLM agents in\nfact-checking by having them phrase queries, retrieve contextual data, and make\ndecisions. Importantly, in our framework, agents explain their reasoning and\ncite the relevant sources from the retrieved context. Our results show the\nenhanced prowess of LLMs when equipped with contextual information. GPT-4\noutperforms GPT-3, but accuracy varies based on query language and claim\nveracity. While LLMs show promise in fact-checking, caution is essential due to\ninconsistent accuracy. Our investigation calls for further research, fostering\na deeper comprehension of when agents succeed and when they fail.",
            "author": [
                "Dorian Quelle",
                "Alexandre Bovet"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13549v1",
                "http://arxiv.org/pdf/2310.13549v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CY",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13548v3",
            "title": "Towards Understanding Sycophancy in Language Models",
            "updated": "2023-10-27T17:45:26Z",
            "published": "2023-10-20T14:46:48Z",
            "summary": "Human feedback is commonly utilized to finetune AI assistants. But human\nfeedback may also encourage model responses that match user beliefs over\ntruthful ones, a behaviour known as sycophancy. We investigate the prevalence\nof sycophancy in models whose finetuning procedure made use of human feedback,\nand the potential role of human preference judgments in such behavior. We first\ndemonstrate that five state-of-the-art AI assistants consistently exhibit\nsycophancy across four varied free-form text-generation tasks. To understand if\nhuman preferences drive this broadly observed behavior, we analyze existing\nhuman preference data. We find that when a response matches a user's views, it\nis more likely to be preferred. Moreover, both humans and preference models\n(PMs) prefer convincingly-written sycophantic responses over correct ones a\nnon-negligible fraction of the time. Optimizing model outputs against PMs also\nsometimes sacrifices truthfulness in favor of sycophancy. Overall, our results\nindicate that sycophancy is a general behavior of state-of-the-art AI\nassistants, likely driven in part by human preference judgments favoring\nsycophantic responses.",
            "author": [
                "Mrinank Sharma",
                "Meg Tong",
                "Tomasz Korbak",
                "David Duvenaud",
                "Amanda Askell",
                "Samuel R. Bowman",
                "Newton Cheng",
                "Esin Durmus",
                "Zac Hatfield-Dodds",
                "Scott R. Johnston",
                "Shauna Kravec",
                "Timothy Maxwell",
                "Sam McCandlish",
                "Kamal Ndousse",
                "Oliver Rausch",
                "Nicholas Schiefer",
                "Da Yan",
                "Miranda Zhang",
                "Ethan Perez"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13548v3",
                "http://arxiv.org/pdf/2310.13548v3"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG",
                "stat.ML",
                "I.2.6"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13543v1",
            "title": "Shedding Light on Low Surface Brightness Galaxies in Dark Energy Survey\n  with Transformers",
            "updated": "2023-10-20T14:40:45Z",
            "published": "2023-10-20T14:40:45Z",
            "summary": "Low surface brightness galaxies (LSBGs) which are defined as galaxies that\nare fainter than the night sky, play a crucial role in understanding galaxy\nevolution and cosmological models. Upcoming large-scale surveys like Rubin\nObservatory Legacy Survey of Space and Time (LSST) and Euclid are expected to\nobserve billions of astronomical objects. In this context, using semi-automatic\nmethods to identify LSBGs would be a highly challenging and time-consuming\nprocess and demand automated or machine learning-based methods to overcome this\nchallenge. We study the use of transformer models in separating LSBGs from\nartefacts in the data from the Dark Energy Survey (DES) data release 1. Using\nthe transformer models, we then search for new LSBGs from the DES that the\nprevious searches may have missed. Properties of the newly found LSBGs are\ninvestigated, along with an analysis of the properties of the total LSBG sample\nin DES. We identified 4,083 new LSBGs in DES, adding an additional $\\sim17\\% $\nto the LSBGs already known in DES. This also increased the number density of\nLSBGs in DES to 5.5 deg$^{-2}$. We performed a clustering analysis of the LSBGs\nin DES using an angular two-point auto-correlation function and found that\nLSBGs cluster more strongly than their high surface brightness counterparts. We\nassociated 1310 LSBGs with galaxy clusters and identified 317 among them as\nultra-diffuse galaxies (UDGs). We found that these cluster LSBGs are getting\nbluer and larger in size towards the edge of the clusters when compared with\nthose in the centre. Transformer models have the potential to be on par with\nconvolutional neural networks as state-of-the-art algorithms in analysing\nastronomical data.",
            "author": [
                "H. Thuruthipilly",
                "Junais",
                "A. Pollo",
                "U. Sureshkumar",
                "M. Grespan",
                "P. Sawant",
                "K. Malek",
                "A. Zadrozny"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13543v1",
                "http://arxiv.org/pdf/2310.13543v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA",
                "astro-ph.IM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13538v1",
            "title": "Positive-Unlabeled Node Classification with Structure-aware Graph\n  Learning",
            "updated": "2023-10-20T14:32:54Z",
            "published": "2023-10-20T14:32:54Z",
            "summary": "Node classification on graphs is an important research problem with many\napplications. Real-world graph data sets may not be balanced and accurate as\nassumed by most existing works. A challenging setting is positive-unlabeled\n(PU) node classification, where labeled nodes are restricted to positive nodes.\nIt has diverse applications, e.g., pandemic prediction or network anomaly\ndetection. Existing works on PU node classification overlook information in the\ngraph structure, which can be critical. In this paper, we propose to better\nutilize graph structure for PU node classification. We first propose a\ndistance-aware PU loss that uses homophily in graphs to introduce more accurate\nsupervision. We also propose a regularizer to align the model with graph\nstructure. Theoretical analysis shows that minimizing the proposed loss also\nleads to minimizing the expected loss with both positive and negative labels.\nExtensive empirical evaluation on diverse graph data sets demonstrates its\nsuperior performance over existing state-of-the-art methods.",
            "author": [
                "Hansi Yang",
                "Yongqi Zhang",
                "Quanming Yao",
                "James Kwok"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3583780.3615250",
                "http://arxiv.org/abs/2310.13538v1",
                "http://arxiv.org/pdf/2310.13538v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13533v1",
            "title": "Technical Report for ICCV 2023 Visual Continual Learning Challenge:\n  Continuous Test-time Adaptation for Semantic Segmentation",
            "updated": "2023-10-20T14:20:21Z",
            "published": "2023-10-20T14:20:21Z",
            "summary": "The goal of the challenge is to develop a test-time adaptation (TTA) method,\nwhich could adapt the model to gradually changing domains in video sequences\nfor semantic segmentation task. It is based on a synthetic driving video\ndataset - SHIFT. The source model is trained on images taken during daytime in\nclear weather. Domain changes at test-time are mainly caused by varying weather\nconditions and times of day. The TTA methods are evaluated in each image\nsequence (video) separately, meaning the model is reset to the source model\nstate before the next sequence. Images come one by one and a prediction has to\nbe made at the arrival of each frame. Each sequence is composed of 401 images\nand starts with the source domain, then gradually drifts to a different one\n(changing weather or time of day) until the middle of the sequence. In the\nsecond half of the sequence, the domain gradually shifts back to the source\none. Ground truth data is available only for the validation split of the SHIFT\ndataset, in which there are only six sequences that start and end with the\nsource domain. We conduct an analysis specifically on those sequences. Ground\ntruth data for test split, on which the developed TTA methods are evaluated for\nleader board ranking, are not publicly available.\n  The proposed solution secured a 3rd place in a challenge and received an\ninnovation award. Contrary to the solutions that scored better, we did not use\nany external pretrained models or specialized data augmentations, to keep the\nsolutions as general as possible. We have focused on analyzing the\ndistributional shift and developing a method that could adapt to changing data\ndynamics and generalize across different scenarios.",
            "author": [
                "Damian S\u00f3jka",
                "Yuyang Liu",
                "Dipam Goswami",
                "Sebastian Cygert",
                "Bart\u0142omiej Twardowski",
                "Joost van de Weijer"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13533v1",
                "http://arxiv.org/pdf/2310.13533v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13526v1",
            "title": "Controlled Randomness Improves the Performance of Transformer Models",
            "updated": "2023-10-20T14:12:55Z",
            "published": "2023-10-20T14:12:55Z",
            "summary": "During the pre-training step of natural language models, the main objective\nis to learn a general representation of the pre-training dataset, usually\nrequiring large amounts of textual data to capture the complexity and diversity\nof natural language. Contrasting this, in most cases, the size of the data\navailable to solve the specific downstream task is often dwarfed by the\naforementioned pre-training dataset, especially in domains where data is\nscarce. We introduce controlled randomness, i.e. noise, into the training\nprocess to improve fine-tuning language models and explore the performance of\ntargeted noise in addition to the parameters of these models. We find that\nadding such noise can improve the performance in our two downstream tasks of\njoint named entity recognition and relation extraction and text summarization.",
            "author": [
                "Tobias Deu\u00dfer",
                "Cong Zhao",
                "Wolfgang Kr\u00e4mer",
                "David Leonhard",
                "Christian Bauckhage",
                "Rafet Sifa"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13526v1",
                "http://arxiv.org/pdf/2310.13526v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13525v1",
            "title": "Latitudinal variations in methane abundance, aerosol opacity and aerosol\n  scattering efficiency in Neptune's atmosphere determined from VLT/MUSE",
            "updated": "2023-10-20T14:12:02Z",
            "published": "2023-10-20T14:12:02Z",
            "summary": "Spectral observations of Neptune made in 2019 with the MUSE instrument at the\nVery Large Telescope in Chile have been analysed to determine the spatial\nvariation of aerosol scattering properties and methane abundance in Neptune's\natmosphere. The darkening of the South Polar Wave (SPW) at $\\sim$ 60$^\\circ$S,\nand dark spots such as the Voyager 2 Great Dark Spot is concluded to be due to\na spectrally-dependent darkening ($\\lambda < 650$nm) of particles in a deep\naerosol layer at $\\sim$ 5 bar and presumed to be composed of a mixture of\nphotochemically-generated haze and H$_2$S ice. We also note a regular\nlatitudinal variation of reflectivity at wavelengths of very low methane\nabsorption longer than $\\sim$ 650 nm, with bright zones latitudinally separated\nby $\\sim$ 25$^\\circ$. This feature, similar to the spectral characteristics of\na discrete deep bright spot DBS-2019 found in our data, is found to be\nconsistent with a brightening of the particles in the same $\\sim$5-bar aerosol\nlayer at $\\lambda > 650 $ nm. We find the properties of an overlying\nmethane/haze aerosol layer at $\\sim$ 2 bar are, to first-order, invariant with\nlatitude, while variations in the opacity of an upper tropospheric haze layer\nreproduce the observed reflectivity at methane-absorbing wavelengths, with\nhigher abundances found at the equator and also in a narrow `zone' at\n$80^\\circ$S. Finally, we find the mean abundance of methane below its\ncondensation level to be 6--7% at the equator reducing to $\\sim$3% south of\n$\\sim$25$^\\circ$S, although the absolute abundances are model dependent.",
            "author": [
                "Patrick G. J. Irwin",
                "Jack Dobinson",
                "Arjuna James",
                "Michael H. Wong",
                "Leigh N. Fletcher",
                "Michael T. Roman",
                "Nicholas A. Teanby",
                "Daniel Toledo",
                "Glenn S. Orton",
                "Santiago Perez-Hoyos",
                "Agustin Sanchez-Lavega",
                "Amy Simon",
                "Raul Morales-Juberias",
                "Imke de Pater"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13525v1",
                "http://arxiv.org/pdf/2310.13525v1"
            ],
            "primary_category": "astro-ph.EP",
            "category": [
                "astro-ph.EP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13524v1",
            "title": "Variational measurement-based quantum computation for generative\n  modeling",
            "updated": "2023-10-20T14:11:58Z",
            "published": "2023-10-20T14:11:58Z",
            "summary": "Measurement-based quantum computation (MBQC) offers a fundamentally unique\nparadigm to design quantum algorithms. Indeed, due to the inherent randomness\nof quantum measurements, the natural operations in MBQC are not deterministic\nand unitary, but are rather augmented with probabilistic byproducts. Yet, the\nmain algorithmic use of MBQC so far has been to completely counteract this\nprobabilistic nature in order to simulate unitary computations expressed in the\ncircuit model. In this work, we propose designing MBQC algorithms that embrace\nthis inherent randomness and treat the random byproducts in MBQC as a resource\nfor computation. As a natural application where randomness can be beneficial,\nwe consider generative modeling, a task in machine learning centered around\ngenerating complex probability distributions. To address this task, we propose\na variational MBQC algorithm equipped with control parameters that allow to\ndirectly adjust the degree of randomness to be admitted in the computation. Our\nnumerical findings indicate that this additional randomness can lead to\nsignificant gains in learning performance in certain generative modeling tasks.\nThese results highlight the potential advantages in exploiting the inherent\nrandomness of MBQC and motivate further research into MBQC-based algorithms.",
            "author": [
                "Arunava Majumder",
                "Marius Krumm",
                "Tina Radkohl",
                "Hendrik Poulsen Nautrup",
                "Sofiene Jerbi",
                "Hans J. Briegel"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13524v1",
                "http://arxiv.org/pdf/2310.13524v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.AI",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13522v1",
            "title": "Teaching Language Models to Self-Improve through Interactive\n  Demonstrations",
            "updated": "2023-10-20T14:11:04Z",
            "published": "2023-10-20T14:11:04Z",
            "summary": "The self-improving ability of large language models (LLMs), enabled by\nprompting them to analyze and revise their own outputs, has garnered\nsignificant interest in recent research. However, this ability has been shown\nto be absent and difficult to learn for smaller models, thus widening the\nperformance gap between state-of-the-art LLMs and more cost-effective and\nfaster ones. To reduce this gap, we introduce TriPosT, a training algorithm\nthat endows smaller models with such self-improvement ability, and show that\nour approach can improve a LLaMA-7b's performance on math and reasoning tasks\nby up to 7.13%. In contrast to prior work, we achieve this by using the smaller\nmodel to interact with LLMs to collect feedback and improvements on its own\ngenerations. We then replay this experience to train the small model. Our\nexperiments on four math and reasoning datasets show that the interactive\nexperience of learning from and correcting its own mistakes is crucial for\nsmall models to improve their performance.",
            "author": [
                "Xiao Yu",
                "Baolin Peng",
                "Michel Galley",
                "Jianfeng Gao",
                "Zhou Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13522v1",
                "http://arxiv.org/pdf/2310.13522v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13515v1",
            "title": "RaceLens: A Machine Intelligence-Based Application for Racing Photo\n  Analysis",
            "updated": "2023-10-20T13:58:31Z",
            "published": "2023-10-20T13:58:31Z",
            "summary": "This paper presents RaceLens, a novel application utilizing advanced deep\nlearning and computer vision models for comprehensive analysis of racing\nphotos. The developed models have demonstrated their efficiency in a wide array\nof tasks, including detecting racing cars, recognizing car numbers, detecting\nand quantifying car details, and recognizing car orientations. We discuss the\nprocess of collecting a robust dataset necessary for training our models, and\ndescribe an approach we have designed to augment and improve this dataset\ncontinually. Our method leverages a feedback loop for continuous model\nimprovement, thus enhancing the performance and accuracy of RaceLens over time.\nA significant part of our study is dedicated to illustrating the practical\napplication of RaceLens, focusing on its successful deployment by NASCAR teams\nover four seasons. We provide a comprehensive evaluation of our system's\nperformance and its direct impact on the team's strategic decisions and\nperformance metrics. The results underscore the transformative potential of\nmachine intelligence in the competitive and dynamic world of car racing,\nsetting a precedent for future applications.",
            "author": [
                "Andrei Boiarov",
                "Dmitry Bleklov",
                "Pavlo Bredikhin",
                "Nikita Koritsky",
                "Sergey Ulasen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13515v1",
                "http://arxiv.org/pdf/2310.13515v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13514v1",
            "title": "Eat, Sleep, Code, Repeat: Tips for Early-Career Researchers in\n  Computational Science",
            "updated": "2023-10-20T13:57:56Z",
            "published": "2023-10-20T13:57:56Z",
            "summary": "This article is intended as a guide for new graduate students in the field of\ncomputational science. With the increasing influx of students from diverse\nbackgrounds joining the ever-popular field, this short guide aims to help\nstudents navigate through the various computational techniques that they are\nlikely to encounter during their studies. These techniques span from Bash\nscripting and scientific programming to machine learning, among other areas.\nThis paper is divided into ten sections, each introducing a different\ncomputational method. To enhance readability, we have adopted a casual and\ninstructive tone, and included code snippets where relevant. Please note that\ndue to the introductory nature of this article, it is not intended to be\nexhaustive; instead, we direct readers to a list of references to expand their\nknowledge of the techniques discussed within the paper. It is likely that this\narticle will continue to evolve with time, and as such, we advise readers to\nseek the latest version. Finally, readers should note this article serves as an\nextension to our student-led seminar series, with additional resources and\nvideos available at \\url{https://computationaltoolkit.github.io/} for\nreference.",
            "author": [
                "Idil Ismail",
                "Shayantan Chaudhuri",
                "Dylan Morgan",
                "Christopher D. Woodgate",
                "Ziad Fakhoury",
                "James M. Targett",
                "Charlie Pilgrim",
                "Carlo Maino"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13514v1",
                "http://arxiv.org/pdf/2310.13514v1"
            ],
            "primary_category": "physics.comp-ph",
            "category": [
                "physics.comp-ph",
                "physics.ed-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13505v2",
            "title": "Robust Training for Conversational Question Answering Models with\n  Reinforced Reformulation Generation",
            "updated": "2023-11-06T08:09:12Z",
            "published": "2023-10-20T13:51:08Z",
            "summary": "Models for conversational question answering (ConvQA) over knowledge graphs\n(KGs) are usually trained and tested on benchmarks of gold QA pairs. This\nimplies that training is limited to surface forms seen in the respective\ndatasets, and evaluation is on a small set of held-out questions. Through our\nproposed framework REIGN, we take several steps to remedy this restricted\nlearning setup. First, we systematically generate reformulations of training\nquestions to increase robustness of models to surface form variations. This is\na particularly challenging problem, given the incomplete nature of such\nquestions. Second, we guide ConvQA models towards higher performance by feeding\nit only those reformulations that help improve their answering quality, using\ndeep reinforcement learning. Third, we demonstrate the viability of training\nmajor model components on one benchmark and applying them zero-shot to another.\nFinally, for a rigorous evaluation of robustness for trained models, we use and\nrelease large numbers of diverse reformulations generated by prompting GPT for\nbenchmark test sets (resulting in 20x increase in sizes). Our findings show\nthat ConvQA models with robust training via reformulations, significantly\noutperform those with standard training from gold QA pairs only.",
            "author": [
                "Magdalena Kaiser",
                "Rishiraj Saha Roy",
                "Gerhard Weikum"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13505v2",
                "http://arxiv.org/pdf/2310.13505v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13499v2",
            "title": "DistillCSE: Distilled Contrastive Learning for Sentence Embeddings",
            "updated": "2023-10-30T09:23:36Z",
            "published": "2023-10-20T13:45:59Z",
            "summary": "This paper proposes the DistillCSE framework, which performs contrastive\nlearning under the self-training paradigm with knowledge distillation. The\npotential advantage of DistillCSE is its self-enhancing feature: using a base\nmodel to provide additional supervision signals, a stronger model may be\nlearned through knowledge distillation. However, the vanilla DistillCSE through\nthe standard implementation of knowledge distillation only achieves marginal\nimprovements due to severe overfitting. The further quantitative analyses\ndemonstrate the reason that the standard knowledge distillation exhibits a\nrelatively large variance of the teacher model's logits due to the essence of\ncontrastive learning. To mitigate the issue induced by high variance, this\npaper accordingly proposed two simple yet effective solutions for knowledge\ndistillation: a Group-P shuffling strategy as an implicit regularization and\nthe averaging logits from multiple teacher components. Experiments on standard\nbenchmarks demonstrate that the proposed DistillCSE outperforms many strong\nbaseline methods and yields a new state-of-the-art performance.",
            "author": [
                "Jiahao Xu",
                "Wei Shao",
                "Lihui Chen",
                "Lemao Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13499v2",
                "http://arxiv.org/pdf/2310.13499v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13490v1",
            "title": "Feature Selection and Hyperparameter Fine-tuning in Artificial Neural\n  Networks for Wood Quality Classification",
            "updated": "2023-10-20T13:32:45Z",
            "published": "2023-10-20T13:32:45Z",
            "summary": "Quality classification of wood boards is an essential task in the sawmill\nindustry, which is still usually performed by human operators in small to\nmedian companies in developing countries. Machine learning algorithms have been\nsuccessfully employed to investigate the problem, offering a more affordable\nalternative compared to other solutions. However, such approaches usually\npresent some drawbacks regarding the proper selection of their hyperparameters.\nMoreover, the models are susceptible to the features extracted from wood board\nimages, which influence the induction of the model and, consequently, its\ngeneralization power. Therefore, in this paper, we investigate the problem of\nsimultaneously tuning the hyperparameters of an artificial neural network (ANN)\nas well as selecting a subset of characteristics that better describes the wood\nboard quality. Experiments were conducted over a private dataset composed of\nimages obtained from a sawmill industry and described using different feature\ndescriptors. The predictive performance of the model was compared against five\nbaseline methods as well as a random search, performing either ANN\nhyperparameter tuning and feature selection. Experimental results suggest that\nhyperparameters should be adjusted according to the feature set, or the\nfeatures should be selected considering the hyperparameter values. In summary,\nthe best predictive performance, i.e., a balanced accuracy of $0.80$, was\nachieved in two distinct scenarios: (i) performing only feature selection, and\n(ii) performing both tasks concomitantly. Thus, we suggest that at least one of\nthe two approaches should be considered in the context of industrial\napplications.",
            "author": [
                "Mateus Roder",
                "Leandro Aparecido Passos",
                "Jo\u00e3o Paulo Papa",
                "Andr\u00e9 Luis Debiaso Rossi"
            ],
            "link": [
                "http://dx.doi.org/10.1007/978-3-031-45389-2_22",
                "http://arxiv.org/abs/2310.13490v1",
                "http://arxiv.org/pdf/2310.13490v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13486v1",
            "title": "Mind the instructions: a holistic evaluation of consistency and\n  interactions in prompt-based learning",
            "updated": "2023-10-20T13:25:24Z",
            "published": "2023-10-20T13:25:24Z",
            "summary": "Finding the best way of adapting pre-trained language models to a task is a\nbig challenge in current NLP. Just like the previous generation of task-tuned\nmodels (TT), models that are adapted to tasks via in-context-learning (ICL) are\nrobust in some setups but not in others. Here, we present a detailed analysis\nof which design choices cause instabilities and inconsistencies in LLM\npredictions. First, we show how spurious correlations between input\ndistributions and labels -- a known issue in TT models -- form only a minor\nproblem for prompted models. Then, we engage in a systematic, holistic\nevaluation of different factors that have been found to influence predictions\nin a prompting setup. We test all possible combinations of a range of factors\non both vanilla and instruction-tuned (IT) LLMs of different scale and\nstatistically analyse the results to show which factors are the most\ninfluential, interactive or stable. Our results show which factors can be used\nwithout precautions and which should be avoided or handled with care in most\nsettings.",
            "author": [
                "Lucas Weber",
                "Elia Bruni",
                "Dieuwke Hupkes"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13486v1",
                "http://arxiv.org/pdf/2310.13486v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13483v1",
            "title": "Application of deep learning for livestock behaviour recognition: A\n  systematic literature review",
            "updated": "2023-10-20T13:23:09Z",
            "published": "2023-10-20T13:23:09Z",
            "summary": "Livestock health and welfare monitoring has traditionally been a\nlabor-intensive task performed manually. Recent advances have led to the\nadoption of AI and computer vision techniques, particularly deep learning\nmodels, as decision-making tools within the livestock industry. These models\nhave been employed for tasks like animal identification, tracking, body part\nrecognition, and species classification. In the past decade, there has been a\ngrowing interest in using these models to explore the connection between\nlivestock behaviour and health issues. While previous review studies have been\nrather generic, there is currently no review study specifically focusing on DL\nfor livestock behaviour recognition. Hence, this systematic literature review\n(SLR) was conducted. The SLR involved an initial search across electronic\ndatabases, resulting in 1101 publications. After applying defined selection\ncriteria, 126 publications were shortlisted. These publications were further\nfiltered based on quality criteria, resulting in the selection of 44\nhigh-quality primary studies. These studies were analysed to address the\nresearch questions. The results showed that DL successfully addressed 13\nbehaviour recognition problems encompassing 44 different behaviour classes. A\nvariety of DL models and networks were employed, with CNN, Faster R-CNN,\nYOLOv5, and YOLOv4 being among the most common models, and VGG16, CSPDarknet53,\nGoogLeNet, ResNet101, and ResNet50 being popular networks. Performance\nevaluation involved ten different matrices, with precision and accuracy being\nthe most frequently used. Primary studies identified challenges, including\nocclusion, adhesion, data imbalance, and the complexities of the livestock\nenvironment. The SLR study also discussed potential solutions and research\ndirections to facilitate the development of autonomous livestock behaviour\nrecognition systems.",
            "author": [
                "Ali Rohan",
                "Muhammad Saad Rafaq",
                "Md. Junayed Hasan",
                "Furqan Asghar",
                "Ali Kashif Bashir",
                "Tania Dottorini"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13483v1",
                "http://arxiv.org/pdf/2310.13483v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13481v1",
            "title": "A review of individual tree crown detection and delineation from optical\n  remote sensing images",
            "updated": "2023-10-20T13:21:37Z",
            "published": "2023-10-20T13:21:37Z",
            "summary": "Powered by the advances of optical remote sensing sensors, the production of\nvery high spatial resolution multispectral images provides great potential for\nachieving cost-efficient and high-accuracy forest inventory and analysis in an\nautomated way. Lots of studies that aim at providing an inventory to the level\nof each individual tree have generated a variety of methods for Individual Tree\nCrown Detection and Delineation (ITCD). This review covers ITCD methods for\ndetecting and delineating individual tree crowns, and systematically reviews\nthe past and present of ITCD-related researches applied to the optical remote\nsensing images. With the goal to provide a clear knowledge map of existing ITCD\nefforts, we conduct a comprehensive review of recent ITCD papers to build a\nmeta-data analysis, including the algorithm, the study site, the tree species,\nthe sensor type, the evaluation method, etc. We categorize the reviewed methods\ninto three classes: (1) traditional image processing methods (such as local\nmaximum filtering, image segmentation, etc.); (2) traditional machine learning\nmethods (such as random forest, decision tree, etc.); and (3) deep learning\nbased methods. With the deep learning-oriented approaches contributing a\nmajority of the papers, we further discuss the deep learning-based methods as\nsemantic segmentation and object detection methods. In addition, we discuss\nfour ITCD-related issues to further comprehend the ITCD domain using optical\nremote sensing data, such as comparisons between multi-sensor based data and\noptical data in ITCD domain, comparisons among different algorithms and\ndifferent ITCD tasks, etc. Finally, this review proposes some ITCD-related\napplications and a few exciting prospects and potential hot topics in future\nITCD research.",
            "author": [
                "Juepeng Zheng",
                "Shuai Yuan",
                "Weijia Li",
                "Haohuan Fu",
                "Le Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13481v1",
                "http://arxiv.org/pdf/2310.13481v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13480v1",
            "title": "Personalized identification, prediction, and stimulation of neural\n  oscillations via data-driven models of epileptic network dynamics",
            "updated": "2023-10-20T13:21:31Z",
            "published": "2023-10-20T13:21:31Z",
            "summary": "Neural oscillations are considered to be brain-specific signatures of\ninformation processing and communication in the brain. They also reflect\npathological brain activity in neurological disorders, thus offering a basis\nfor diagnoses and forecasting. Epilepsy is one of the most common neurological\ndisorders, characterized by abnormal synchronization and desynchronization of\nthe oscillations in the brain. About one third of epilepsy cases are\npharmacoresistant, and as such emphasize the need for novel therapy approaches,\nwhere brain stimulation appears to be a promising therapeutic option. The\ndevelopment of brain stimulation paradigms, however, is often based on\ngeneralized assumptions about brain dynamics, although it is known that\nsignificant differences occur between patients and brain states. We developed a\nframework to extract individualized predictive models of epileptic network\ndynamics directly from EEG data. The models are based on the dominant coherent\noscillations and their dynamical coupling, thus combining an established\ninterpretation of dynamics through neural oscillations, with accurate\npatient-specific features. We show that it is possible to build a direct\ncorrespondence between the models of brain-network dynamics under periodic\ndriving, and the mechanism of neural entrainment via periodic stimulation. When\nour framework is applied to EEG recordings of patients in status epilepticus (a\nbrain state of perpetual seizure activity), it yields a model-driven predictive\nanalysis of the therapeutic performance of periodic brain stimulation. This\nsuggests that periodic brain stimulation can drive pathological states of\nepileptic network dynamics towards a healthy functional brain state.",
            "author": [
                "Tena Dubcek",
                "Debora Ledergerber",
                "Jana Thomann",
                "Giovanna Aiello",
                "Marc Serra-Garcia",
                "Lukas Imbach",
                "Rafael Polania"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13480v1",
                "http://arxiv.org/pdf/2310.13480v1"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC",
                "cs.LG",
                "nlin.AO",
                "physics.med-ph",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13479v2",
            "title": "Segment, Select, Correct: A Framework for Weakly-Supervised Referring\n  Segmentation",
            "updated": "2023-10-23T09:42:29Z",
            "published": "2023-10-20T13:20:17Z",
            "summary": "Referring Image Segmentation (RIS) - the problem of identifying objects in\nimages through natural language sentences - is a challenging task currently\nmostly solved through supervised learning. However, while collecting referred\nannotation masks is a time-consuming process, the few existing\nweakly-supervised and zero-shot approaches fall significantly short in\nperformance compared to fully-supervised learning ones. To bridge the\nperformance gap without mask annotations, we propose a novel weakly-supervised\nframework that tackles RIS by decomposing it into three steps: obtaining\ninstance masks for the object mentioned in the referencing instruction\n(segment), using zero-shot learning to select a potentially correct mask for\nthe given instruction (select), and bootstrapping a model which allows for\nfixing the mistakes of zero-shot selection (correct). In our experiments, using\nonly the first two steps (zero-shot segment and select) outperforms other\nzero-shot baselines by as much as 19%, while our full method improves upon this\nmuch stronger baseline and sets the new state-of-the-art for weakly-supervised\nRIS, reducing the gap between the weakly-supervised and fully-supervised\nmethods in some cases from around 33% to as little as 14%. Code is available at\nhttps://github.com/fgirbal/segment-select-correct.",
            "author": [
                "Francisco Eiras",
                "Kemal Oksuz",
                "Adel Bibi",
                "Philip H. S. Torr",
                "Puneet K. Dokania"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13479v2",
                "http://arxiv.org/pdf/2310.13479v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13474v1",
            "title": "An Analysis of $D^\u03b1$ seeding for $k$-means",
            "updated": "2023-10-20T13:15:18Z",
            "published": "2023-10-20T13:15:18Z",
            "summary": "One of the most popular clustering algorithms is the celebrated $D^\\alpha$\nseeding algorithm (also know as $k$-means++ when $\\alpha=2$) by Arthur and\nVassilvitskii (2007), who showed that it guarantees in expectation an\n$O(2^{2\\alpha}\\cdot \\log k)$-approximate solution to the ($k$,$\\alpha$)-means\ncost (where euclidean distances are raised to the power $\\alpha$) for any\n$\\alpha\\ge 1$. More recently, Balcan, Dick, and White (2018) observed\nexperimentally that using $D^\\alpha$ seeding with $\\alpha>2$ can lead to a\nbetter solution with respect to the standard $k$-means objective (i.e. the\n$(k,2)$-means cost).\n  In this paper, we provide a rigorous understanding of this phenomenon. For\nany $\\alpha>2$, we show that $D^\\alpha$ seeding guarantees in expectation an\napproximation factor of $$ O_\\alpha \\left((g_\\alpha)^{2/\\alpha}\\cdot\n\\left(\\frac{\\sigma_{\\mathrm{max}}}{\\sigma_{\\mathrm{min}}}\\right)^{2-4/\\alpha}\\cdot\n(\\min\\{\\ell,\\log k\\})^{2/\\alpha}\\right)$$ with respect to the standard\n$k$-means cost of any underlying clustering; where $g_\\alpha$ is a parameter\ncapturing the concentration of the points in each cluster,\n$\\sigma_{\\mathrm{max}}$ and $\\sigma_{\\mathrm{min}}$ are the maximum and minimum\nstandard deviation of the clusters around their means, and $\\ell$ is the number\nof distinct mixing weights in the underlying clustering (after rounding them to\nthe nearest power of $2$). We complement these results by some lower bounds\nshowing that the dependency on $g_\\alpha$ and\n$\\sigma_{\\mathrm{max}}/\\sigma_{\\mathrm{min}}$ is tight.\n  Finally, we provide an experimental confirmation of the effects of the\naforementioned parameters when using $D^\\alpha$ seeding. Further, we\ncorroborate the observation that $\\alpha>2$ can indeed improve the $k$-means\ncost compared to $D^2$ seeding, and that this advantage remains even if we run\nLloyd's algorithm after the seeding.",
            "author": [
                "Etienne Bamas",
                "Sai Ganesh Nagarajan",
                "Ola Svensson"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13474v1",
                "http://arxiv.org/pdf/2310.13474v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13471v1",
            "title": "Neural domain alignment for spoken language recognition based on optimal\n  transport",
            "updated": "2023-10-20T13:12:35Z",
            "published": "2023-10-20T13:12:35Z",
            "summary": "Domain shift poses a significant challenge in cross-domain spoken language\nrecognition (SLR) by reducing its effectiveness. Unsupervised domain adaptation\n(UDA) algorithms have been explored to address domain shifts in SLR without\nrelying on class labels in the target domain. One successful UDA approach\nfocuses on learning domain-invariant representations to align feature\ndistributions between domains. However, disregarding the class structure during\nthe learning process of domain-invariant representations can result in\nover-alignment, negatively impacting the classification task. To overcome this\nlimitation, we propose an optimal transport (OT)-based UDA algorithm for a\ncross-domain SLR, leveraging the distribution geometry structure-aware property\nof OT. An OT-based discrepancy measure on a joint distribution over feature and\nlabel information is considered during domain alignment in OT-based UDA. Our\nprevious study discovered that completely aligning the distributions between\nthe source and target domains can introduce a negative transfer, where classes\nor irrelevant classes from the source domain map to a different class in the\ntarget domain during distribution alignment. This negative transfer degrades\nthe performance of the adaptive model. To mitigate this issue, we introduce\ncoupling-weighted partial optimal transport (POT) within our UDA framework for\nSLR, where soft weighting on the OT coupling based on transport cost is\nadaptively set during domain alignment. A cross-domain SLR task was used in the\nexperiments to evaluate the proposed UDA. The results demonstrated that our\nproposed UDA algorithm significantly improved the performance over existing UDA\nalgorithms in a cross-channel SLR task.",
            "author": [
                "Xugang Lu",
                "Peng Shen",
                "Yu Tsao",
                "Hisashi Kawai"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13471v1",
                "http://arxiv.org/pdf/2310.13471v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13459v1",
            "title": "Stable Nonconvex-Nonconcave Training via Linear Interpolation",
            "updated": "2023-10-20T12:45:12Z",
            "published": "2023-10-20T12:45:12Z",
            "summary": "This paper presents a theoretical analysis of linear interpolation as a\nprincipled method for stabilizing (large-scale) neural network training. We\nargue that instabilities in the optimization process are often caused by the\nnonmonotonicity of the loss landscape and show how linear interpolation can\nhelp by leveraging the theory of nonexpansive operators. We construct a new\noptimization scheme called relaxed approximate proximal point (RAPP), which is\nthe first explicit method to achieve last iterate convergence rates for the\nfull range of cohypomonotone problems. The construction extends to constrained\nand regularized settings. By replacing the inner optimizer in RAPP we\nrediscover the family of Lookahead algorithms for which we establish\nconvergence in cohypomonotone problems even when the base optimizer is taken to\nbe gradient descent ascent. The range of cohypomonotone problems in which\nLookahead converges is further expanded by exploiting that Lookahead inherits\nthe properties of the base optimizer. We corroborate the results with\nexperiments on generative adversarial networks which demonstrates the benefits\nof the linear interpolation present in both RAPP and Lookahead.",
            "author": [
                "Thomas Pethick",
                "Wanyun Xie",
                "Volkan Cevher"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13459v1",
                "http://arxiv.org/pdf/2310.13459v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13458v3",
            "title": "Correspondence learning between morphologically different robots via\n  task demonstrations",
            "updated": "2023-11-21T19:33:52Z",
            "published": "2023-10-20T12:42:06Z",
            "summary": "We observe a large variety of robots in terms of their bodies, sensors, and\nactuators. Given the commonalities in the skill sets, teaching each skill to\neach different robot independently is inefficient and not scalable when the\nlarge variety in the robotic landscape is considered. If we can learn the\ncorrespondences between the sensorimotor spaces of different robots, we can\nexpect a skill that is learned in one robot can be more directly and easily\ntransferred to other robots. In this paper, we propose a method to learn\ncorrespondences among two or more robots that may have different morphologies.\nTo be specific, besides robots with similar morphologies with different degrees\nof freedom, we show that a fixed-based manipulator robot with joint control and\na differential drive mobile robot can be addressed within the proposed\nframework. To set up the correspondence among the robots considered, an initial\nbase task is demonstrated to the robots to achieve the same goal. Then, a\ncommon latent representation is learned along with the individual robot\npolicies for achieving the goal. After the initial learning stage, the\nobservation of a new task execution by one robot becomes sufficient to generate\na latent space representation pertaining to the other robots to achieve the\nsame task. We verified our system in a set of experiments where the\ncorrespondence between robots is learned (1) when the robots need to follow the\nsame paths to achieve the same task, (2) when the robots need to follow\ndifferent trajectories to achieve the same task, and (3) when complexities of\nthe required sensorimotor trajectories are different for the robots. We also\nprovide a proof-of-the-concept realization of correspondence learning between a\nreal manipulator robot and a simulated mobile robot.",
            "author": [
                "Hakan Aktas",
                "Yukie Nagai",
                "Minoru Asada",
                "Erhan Oztop",
                "Emre Ugur"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13458v3",
                "http://arxiv.org/pdf/2310.13458v3"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13453v1",
            "title": "Learning complexity to guide light-induced self-organized nanopatterns",
            "updated": "2023-10-20T12:37:09Z",
            "published": "2023-10-20T12:37:09Z",
            "summary": "Ultrafast laser irradiation can induce spontaneous self-organization of\nsurfaces into dissipative structures with nanoscale reliefs. These surface\npatterns emerge from symmetry-breaking dynamical processes that occur in\nRayleigh-B\\'enard-like instabilities. In this study, we demonstrate that the\ncoexistence and competition between surface patterns of different symmetries in\ntwo dimensions can be numerically unraveled using the stochastic generalized\nSwift-Hohenberg model. We originally propose a deep convolutional network to\nidentify and learn the dominant modes that stabilize for a given bifurcation\nand quadratic model coefficients. The model is scale-invariant and has been\ncalibrated on microscopy measurements using a physics-guided machine learning\nstrategy. Our approach enables the identification of experimental irradiation\nconditions for a desired self-organization pattern. It can be applied generally\nto predict structure formation in situations where the underlying physics can\nbe approximately described by a self-organization process and data is sparse\nand non-time series. Our work paves the way for supervised local manipulation\nof matter using timely-controlled optical fields in laser manufacturing.",
            "author": [
                "Eduardo Brandao",
                "Anthony Nakhoul",
                "Stefan Duffner",
                "R\u00e9mi Emonet",
                "Florence Garrelie",
                "Amaury Habrard",
                "Fran\u00e7ois Jacquenet",
                "Florent Pigeon",
                "Marc Sebban",
                "Jean-Philippe Colombier"
            ],
            "link": [
                "http://dx.doi.org/10.1103/PhysRevLett.130.226201",
                "http://arxiv.org/abs/2310.13453v1",
                "http://arxiv.org/pdf/2310.13453v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "physics.optics"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13452v2",
            "title": "Quadrotor Dead Reckoning with Multiple Inertial Sensors",
            "updated": "2023-10-26T11:18:35Z",
            "published": "2023-10-20T12:36:36Z",
            "summary": "Quadrotors are widely used for surveillance, mapping, and deliveries. In\nseveral scenarios the quadrotor operates in pure inertial navigation mode\nresulting in a navigation solution drift. To handle such situations and bind\nthe navigation drift, the quadrotor dead reckoning (QDR) approach requires\nflying the quadrotor in a periodic trajectory. Then, using model or learning\nbased approaches the quadrotor position vector can be estimated. We propose to\nuse multiple inertial measurement units (MIMU) to improve the positioning\naccuracy of the QDR approach. Several methods to utilize MIMU data in a deep\nlearning framework are derived and evaluated. Field experiments were conducted\nto validate the proposed approach and show its benefits.",
            "author": [
                "Dror Hurwitz",
                "Itzik Klein"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13452v2",
                "http://arxiv.org/pdf/2310.13452v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13451v1",
            "title": "Two-Stage Triplet Loss Training with Curriculum Augmentation for\n  Audio-Visual Retrieval",
            "updated": "2023-10-20T12:35:54Z",
            "published": "2023-10-20T12:35:54Z",
            "summary": "The cross-modal retrieval model leverages the potential of triple loss\noptimization to learn robust embedding spaces. However, existing methods often\ntrain these models in a singular pass, overlooking the distinction between\nsemi-hard and hard triples in the optimization process. The oversight of not\ndistinguishing between semi-hard and hard triples leads to suboptimal model\nperformance. In this paper, we introduce a novel approach rooted in curriculum\nlearning to address this problem. We propose a two-stage training paradigm that\nguides the model's learning process from semi-hard to hard triplets. In the\nfirst stage, the model is trained with a set of semi-hard triplets, starting\nfrom a low-loss base. Subsequently, in the second stage, we augment the\nembeddings using an interpolation technique. This process identifies potential\nhard negatives, alleviating issues arising from high-loss functions due to a\nscarcity of hard triples. Our approach then applies hard triplet mining in the\naugmented embedding space to further optimize the model. Extensive experimental\nresults conducted on two audio-visual datasets show a significant improvement\nof approximately 9.8% in terms of average Mean Average Precision (MAP) over the\ncurrent state-of-the-art method, MSNSCA, for the Audio-Visual Cross-Modal\nRetrieval (AV-CMR) task on the AVE dataset, indicating the effectiveness of our\nproposed method.",
            "author": [
                "Donghuo Zeng",
                "Kazushi Ikeda"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13451v1",
                "http://arxiv.org/pdf/2310.13451v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.CV",
                "cs.IR",
                "cs.MM",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13448v1",
            "title": "Steering Large Language Models for Machine Translation with Finetuning\n  and In-Context Learning",
            "updated": "2023-10-20T12:29:51Z",
            "published": "2023-10-20T12:29:51Z",
            "summary": "Large language models (LLMs) are a promising avenue for machine translation\n(MT). However, current LLM-based MT systems are brittle: their effectiveness\nhighly depends on the choice of few-shot examples and they often require extra\npost-processing due to overgeneration. Alternatives such as finetuning on\ntranslation instructions are computationally expensive and may weaken\nin-context learning capabilities, due to overspecialization. In this paper, we\nprovide a closer look at this problem. We start by showing that adapter-based\nfinetuning with LoRA matches the performance of traditional finetuning while\nreducing the number of training parameters by a factor of 50. This method also\noutperforms few-shot prompting and eliminates the need for post-processing or\nin-context examples. However, we show that finetuning generally degrades\nfew-shot performance, hindering adaptation capabilities. Finally, to obtain the\nbest of both worlds, we propose a simple approach that incorporates few-shot\nexamples during finetuning. Experiments on 10 language pairs show that our\nproposed approach recovers the original few-shot capabilities while keeping the\nadded benefits of finetuning.",
            "author": [
                "Duarte M. Alves",
                "Nuno M. Guerreiro",
                "Jo\u00e3o Alves",
                "Jos\u00e9 Pombal",
                "Ricardo Rei",
                "Jos\u00e9 G. C. de Souza",
                "Pierre Colombo",
                "Andr\u00e9 F. T. Martins"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13448v1",
                "http://arxiv.org/pdf/2310.13448v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13447v2",
            "title": "Multiscale Superpixel Structured Difference Graph Convolutional Network\n  for VL Representation",
            "updated": "2023-10-25T13:14:40Z",
            "published": "2023-10-20T12:26:04Z",
            "summary": "Within the multimodal field, the key to integrating vision and language lies\nin establishing a good alignment strategy. Recently, benefiting from the\nsuccess of self-supervised learning, significant progress has been made in\nmultimodal semantic representation based on pre-trained models for vision and\nlanguage. However, there is still room for improvement in visual semantic\nrepresentation. The lack of spatial semantic coherence and vulnerability to\nnoise makes it challenging for current pixel or patch-based methods to\naccurately extract complex scene boundaries. To this end, this paper develops\nsuperpixel as a comprehensive compact representation of learnable image data,\nwhich effectively reduces the number of visual primitives for subsequent\nprocessing by clustering perceptually similar pixels. To mine more precise\ntopological relations, we propose a Multiscale Difference Graph Convolutional\nNetwork (MDGCN). It parses the entire image as a fine-to-coarse hierarchical\nstructure of constituent visual patterns, and captures multiscale features by\nprogressively merging adjacent superpixels as graph nodes. Moreover, we predict\nthe differences between adjacent nodes through the graph structure,\nfacilitating key information aggregation of graph nodes to reason actual\nsemantic relations. Afterward, we design a multi-level fusion rule in a\nbottom-up manner to avoid understanding deviation by learning complementary\nspatial information at different regional scales. Our proposed method can be\nwell applied to multiple downstream task learning. Extensive experiments\ndemonstrate that our method is competitive with other state-of-the-art methods\nin visual reasoning. Our code will be released upon publication.",
            "author": [
                "Siyu Zhang",
                "Yeming Chen",
                "Sirui Cheng",
                "Yaoru Sun",
                "Jun Yang",
                "Lizhi Bai"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13447v2",
                "http://arxiv.org/pdf/2310.13447v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13434v1",
            "title": "Random Matrix Analysis to Balance between Supervised and Unsupervised\n  Learning under the Low Density Separation Assumption",
            "updated": "2023-10-20T11:46:12Z",
            "published": "2023-10-20T11:46:12Z",
            "summary": "We propose a theoretical framework to analyze semi-supervised classification\nunder the low density separation assumption in a high-dimensional regime. In\nparticular, we introduce QLDS, a linear classification model, where the low\ndensity separation assumption is implemented via quadratic margin maximization.\nThe algorithm has an explicit solution with rich theoretical properties, and we\nshow that particular cases of our algorithm are the least-square support vector\nmachine in the supervised case, the spectral clustering in the fully\nunsupervised regime, and a class of semi-supervised graph-based approaches. As\nsuch, QLDS establishes a smooth bridge between these supervised and\nunsupervised learning methods. Using recent advances in the random matrix\ntheory, we formally derive a theoretical evaluation of the classification error\nin the asymptotic regime. As an application, we derive a hyperparameter\nselection policy that finds the best balance between the supervised and the\nunsupervised terms of our learning criterion. Finally, we provide extensive\nillustrations of our framework, as well as an experimental study on several\nbenchmarks to demonstrate that QLDS, while being computationally more\nefficient, improves over cross-validation for hyperparameter selection,\nindicating a high promise of the usage of random matrix theory for\nsemi-supervised model selection.",
            "author": [
                "Vasilii Feofanov",
                "Malik Tiomoko",
                "Aladin Virmaux"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13434v1",
                "http://arxiv.org/pdf/2310.13434v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13433v1",
            "title": "Y-Diagonal Couplings: Approximating Posteriors with Conditional\n  Wasserstein Distances",
            "updated": "2023-10-20T11:46:05Z",
            "published": "2023-10-20T11:46:05Z",
            "summary": "In inverse problems, many conditional generative models approximate the\nposterior measure by minimizing a distance between the joint measure and its\nlearned approximation. While this approach also controls the distance between\nthe posterior measures in the case of the Kullback Leibler divergence, it does\nnot hold true for the Wasserstein distance. We will introduce a conditional\nWasserstein distance with a set of restricted couplings that equals the\nexpected Wasserstein distance of the posteriors. By deriving its dual, we find\na rigorous way to motivate the loss of conditional Wasserstein GANs. We outline\nconditions under which the vanilla and the conditional Wasserstein distance\ncoincide. Furthermore, we will show numerical examples where training with the\nconditional Wasserstein distance yields favorable properties for posterior\nsampling.",
            "author": [
                "Jannis Chemseddine",
                "Paul Hagemann",
                "Christian Wald"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13433v1",
                "http://arxiv.org/pdf/2310.13433v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.ST",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13430v1",
            "title": "HRTF Interpolation using a Spherical Neural Process Meta-Learner",
            "updated": "2023-10-20T11:41:54Z",
            "published": "2023-10-20T11:41:54Z",
            "summary": "Several individualization methods have recently been proposed to estimate a\nsubject's Head-Related Transfer Function (HRTF) using convenient input\nmodalities such as anthropometric measurements or pinnae photographs. There\nexists a need for adaptively correcting the estimation error committed by such\nmethods using a few data point samples from the subject's HRTF, acquired using\nacoustic measurements or perceptual feedback. To this end, we introduce a\nConvolutional Conditional Neural Process meta-learner specialized in HRTF error\ninterpolation. In particular, the model includes a Spherical Convolutional\nNeural Network component to accommodate the spherical geometry of HRTF data. It\nalso exploits potential symmetries between the HRTF's left and right channels\nabout the median axis. In this work, we evaluate the proposed model's\nperformance purely on time-aligned spectrum interpolation grounds under a\nsimplified setup where a generic population-mean HRTF forms the initial\nestimates prior to corrections instead of individualized ones. The trained\nmodel achieves up to 3 dB relative error reduction compared to state-of-the-art\ninterpolation methods despite being trained using only 85 subjects. This\nimprovement translates up to nearly a halving of the data point count required\nto achieve comparable accuracy, in particular from 50 to 28 points to reach an\naverage of -20 dB relative error per interpolated feature. Moreover, we show\nthat the trained model provides well-calibrated uncertainty estimates.\nAccordingly, such estimates can inform the sequential decision problem of\nacquiring as few correcting HRTF data points as needed to meet a desired level\nof HRTF individualization accuracy.",
            "author": [
                "Etienne Thuillier",
                "Craig Jin",
                "Vesa V\u00e4lim\u00e4ki"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13430v1",
                "http://arxiv.org/pdf/2310.13430v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.LG",
                "I.5.4; J.2"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13424v1",
            "title": "FLTracer: Accurate Poisoning Attack Provenance in Federated Learning",
            "updated": "2023-10-20T11:24:38Z",
            "published": "2023-10-20T11:24:38Z",
            "summary": "Federated Learning (FL) is a promising distributed learning approach that\nenables multiple clients to collaboratively train a shared global model.\nHowever, recent studies show that FL is vulnerable to various poisoning\nattacks, which can degrade the performance of global models or introduce\nbackdoors into them. In this paper, we first conduct a comprehensive study on\nprior FL attacks and detection methods. The results show that all existing\ndetection methods are only effective against limited and specific attacks. Most\ndetection methods suffer from high false positives, which lead to significant\nperformance degradation, especially in not independent and identically\ndistributed (non-IID) settings. To address these issues, we propose FLTracer,\nthe first FL attack provenance framework to accurately detect various attacks\nand trace the attack time, objective, type, and poisoned location of updates.\nDifferent from existing methodologies that rely solely on cross-client anomaly\ndetection, we propose a Kalman filter-based cross-round detection to identify\nadversaries by seeking the behavior changes before and after the attack. Thus,\nthis makes it resilient to data heterogeneity and is effective even in non-IID\nsettings. To further improve the accuracy of our detection method, we employ\nfour novel features and capture their anomalies with the joint decisions.\nExtensive evaluations show that FLTracer achieves an average true positive rate\nof over $96.88\\%$ at an average false positive rate of less than $2.67\\%$,\nsignificantly outperforming SOTA detection methods. \\footnote{Code is available\nat \\url{https://github.com/Eyr3/FLTracer}.}",
            "author": [
                "Xinyu Zhang",
                "Qingyu Liu",
                "Zhongjie Ba",
                "Yuan Hong",
                "Tianhang Zheng",
                "Feng Lin",
                "Li Lu",
                "Kui Ren"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13424v1",
                "http://arxiv.org/pdf/2310.13424v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI",
                "cs.DC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18331v2",
            "title": "AllTogether: Investigating the Efficacy of Spliced Prompt for Web\n  Navigation using Large Language Models",
            "updated": "2023-10-31T06:25:59Z",
            "published": "2023-10-20T11:10:14Z",
            "summary": "Large Language Models (LLMs) have emerged as promising agents for web\nnavigation tasks, interpreting objectives and interacting with web pages.\nHowever, the efficiency of spliced prompts for such tasks remains\nunderexplored. We introduces AllTogether, a standardized prompt template that\nenhances task context representation, thereby improving LLMs' performance in\nHTML-based web navigation. We evaluate the efficacy of this approach through\nprompt learning and instruction finetuning based on open-source Llama-2 and\nAPI-accessible GPT models. Our results reveal that models like GPT-4 outperform\nsmaller models in web navigation tasks. Additionally, we find that the length\nof HTML snippet and history trajectory significantly influence performance, and\nprior step-by-step instructions prove less effective than real-time\nenvironmental feedback. Overall, we believe our work provides valuable insights\nfor future research in LLM-driven web agents.",
            "author": [
                "Jiarun Liu",
                "Wentao Hu",
                "Chunhong Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18331v2",
                "http://arxiv.org/pdf/2310.18331v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13418v1",
            "title": "GenDistiller: Distilling Pre-trained Language Models based on Generative\n  Models",
            "updated": "2023-10-20T10:56:01Z",
            "published": "2023-10-20T10:56:01Z",
            "summary": "Self-supervised pre-trained models such as HuBERT and WavLM leverage\nunlabeled speech data for representation learning and offer significantly\nimprove for numerous downstream tasks. Despite the success of these methods,\ntheir large memory and strong computational requirements hinder their\napplication on resource restricted devices. Therefore, this paper introduces\nGenDistiller, a novel knowledge distillation framework to distill hidden\nrepresentations from teacher network based on generative language model. The\ngenerative structure enables the proposed model to generate the target teacher\nhidden layers autoregressively, considering the interactions between hidden\nlayers without instroducing additional inputs. A two-dimensional attention\nmechanism is implemented to ensure the causality of hidden layers, while\npreserving bidirectional attention in the time dimension. Experiments reveal\nthe advantage of the generative distiller over the baseline system that\npredicts the hidden layers of teacher network directly without a generatvie\nmodel.",
            "author": [
                "Yingying Gao",
                "Shilei Zhang",
                "Zihao Cui",
                "Yanhan Xu",
                "Chao Deng",
                "Junlan Feng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13418v1",
                "http://arxiv.org/pdf/2310.13418v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14796v1",
            "title": "A Novel Transfer Learning Method Utilizing Acoustic and Vibration\n  Signals for Rotating Machinery Fault Diagnosis",
            "updated": "2023-10-20T10:50:14Z",
            "published": "2023-10-20T10:50:14Z",
            "summary": "Fault diagnosis of rotating machinery plays a important role for the safety\nand stability of modern industrial systems. However, there is a distribution\ndiscrepancy between training data and data of real-world operation scenarios,\nwhich causing the decrease of performance of existing systems. This paper\nproposed a transfer learning based method utilizing acoustic and vibration\nsignal to address this distribution discrepancy. We designed the acoustic and\nvibration feature fusion MAVgram to offer richer and more reliable information\nof faults, coordinating with a DNN-based classifier to obtain more effective\ndiagnosis representation. The backbone was pre-trained and then fine-tuned to\nobtained excellent performance of the target task. Experimental results\ndemonstrate the effectiveness of the proposed method, and achieved improved\nperformance compared to STgram-MFN.",
            "author": [
                "Zhongliang Chen",
                "Zhuofei Huang",
                "Wenxiong Kang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14796v1",
                "http://arxiv.org/pdf/2310.14796v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.AI",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13414v1",
            "title": "Imaging detection of the inner dust belt and the four exoplanets in the\n  HR8799 system with JWST's MIRI coronagraph",
            "updated": "2023-10-20T10:48:29Z",
            "published": "2023-10-20T10:48:29Z",
            "summary": "The multi planet system HR8799 is the first target observed with MIRI's\ncoronagraphs as part of the MIRI-EC Guaranteed Time Observations exoplanets\nprogramme in Nov. 2022. We obtained deep observations in three coronagraphic\nfilters from 10 to 15mic (F1065C, F1140C, F1550C), and one standard imaging\nfilter at 20 mic (F2100W), with the goal to extract the photometry of the four\nplanets, as well as to detect and investigate the distribution of circumstellar\ndust. Using dedicated observations of a reference star, we tested several\nalgorithms to subtract the stellar diffraction pattern while preserving the\nfluxes of planets, which can be significantly affected by over-subtraction.\nMeasuring correctly the planet's flux values requires accounting for the\nattenuation by the coronagraphs as a function of their position, and to\nestimate the normalisation with respect to the central star. We tested several\nprocedures to derive averaged photometric values and error bars. These\nobservations have enabled us to obtain two main results. First of all, the four\nplanets in the system are well recovered, and their mid-IR fluxes, combined\nwith near-IR flux values from the literature, are compared to two exoplanet\natmosphere models, ATMO and Exo-REM. As a main outcome, the MIRI photometric\ndata points imply larger radii (0.86 or 1.07 RJ for planet b) and cooler\ntemperatures (950 or 1100 K for planet b), especially for planet b, in better\nagreement with evolutionary models. Second of all, these JWST/MIRI\ncoronagraphic data also deliver the first spatially resolved detection of the\ninner warm debris disk, the radius of which is constrained to about 15 au, with\nflux densities comparable, but lower than former unresolved spectroscopic\nmeasurements with Spitzer. abridged...",
            "author": [
                "Boccaletti A.",
                "M\u00e2lin M.",
                "Baudoz P.",
                "Tremplin P.",
                "Perrot C.",
                "Rouan D.",
                "Lagage P. -O.",
                "Whiteford N.",
                "Molli\u00e8re P.",
                "Waters R.",
                "Henning T.",
                "Decin L.",
                "G\u00fcdel M.",
                "Vadenbussche B.",
                "Absil O.",
                "Argyriou I.",
                "Bouwman J.",
                "Cossou C.",
                "Coulais A.",
                "Gastaud R.",
                "Glasse A.",
                "Glauser A.",
                "Kamp I.",
                "Kendrew S.",
                "Krause O.",
                "Lahuis F.",
                "Mueller M.",
                "Olofsson G.",
                "Patapis P.",
                "Pye J.",
                "Royer P.",
                "Serabyn E.",
                "Scheithauer S.",
                "Colina L.",
                "van Dischoeck E. F.",
                "Ostlin G.",
                "Ray T.",
                "Wright G"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13414v1",
                "http://arxiv.org/pdf/2310.13414v1"
            ],
            "primary_category": "astro-ph.EP",
            "category": [
                "astro-ph.EP",
                "astro-ph.IM",
                "astro-ph.SR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13412v1",
            "title": "Direct evidence of helium rain in Jupiter and Saturn",
            "updated": "2023-10-20T10:43:47Z",
            "published": "2023-10-20T10:43:47Z",
            "summary": "The immiscibility of hydrogen-helium mixture under the temperature and\npressure conditions of planetary interiors is crucial for understanding the\nstructures of gas giant planets (e.g., Jupiter and Saturn). While the\nexperimental probe at such extreme conditions is challenging, theoretical\nsimulation is heavily relied in an effort to unravel the mixing behavior of\nhydrogen and helium. Here we develop a method via a machine learning\naccelerated molecular dynamics simulation to quantify the physical separation\nof hydrogen and helium under the conditions of planetary interiors. The\nimmiscibility line achieved with the developed method yields substantially\nhigher demixing temperatures at pressure above 1.5 Mbar than earlier\ntheoretical data, but matches better to the experimental estimate. Our results\nrevise the structures of Jupiter and Saturn where H-He demixing takes place in\na large fraction of the interior radii, i.e., 27.5% in Jupiter and 48.3% in\nSaturn. This direct evidence of an H-He immiscible layer supports the formation\nof helium rain and explains the helium reduction in atmosphere of Jupiter and\nSaturn.",
            "author": [
                "Xiaoju Chang",
                "Bo Chen",
                "Qiyu Zeng",
                "Han Wang",
                "Kaiguo Chen",
                "Qunchao Tong",
                "Xiaoxiang Yu",
                "Dongdong Kang",
                "Shen Zhang",
                "Fangyu Guo",
                "Yong Hou",
                "Zengxiu Zhao",
                "Yansun Yao",
                "Yanming Ma",
                "Jiayu Dai"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13412v1",
                "http://arxiv.org/pdf/2310.13412v1"
            ],
            "primary_category": "physics.comp-ph",
            "category": [
                "physics.comp-ph",
                "astro-ph.EP",
                "physics.atm-clus"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13411v1",
            "title": "Towards Enhancing Relational Rules for Knowledge Graph Link Prediction",
            "updated": "2023-10-20T10:38:28Z",
            "published": "2023-10-20T10:38:28Z",
            "summary": "Graph neural networks (GNNs) have shown promising performance for knowledge\ngraph reasoning. A recent variant of GNN called progressive relational graph\nneural network (PRGNN), utilizes relational rules to infer missing knowledge in\nrelational digraphs and achieves notable results. However, during reasoning\nwith PRGNN, two important properties are often overlooked: (1) the\nsequentiality of relation composition, where the order of combining different\nrelations affects the semantics of the relational rules, and (2) the lagged\nentity information propagation, where the transmission speed of required\ninformation lags behind the appearance speed of new entities. Ignoring these\nproperties leads to incorrect relational rule learning and decreased reasoning\naccuracy. To address these issues, we propose a novel knowledge graph reasoning\napproach, the Relational rUle eNhanced Graph Neural Network (RUN-GNN).\nSpecifically, RUN-GNN employs a query related fusion gate unit to model the\nsequentiality of relation composition and utilizes a buffering update mechanism\nto alleviate the negative effect of lagged entity information propagation,\nresulting in higher-quality relational rule learning. Experimental results on\nmultiple datasets demonstrate the superiority of RUN-GNN is superior on both\ntransductive and inductive link prediction tasks.",
            "author": [
                "Shuhan Wu",
                "Huaiyu Wan",
                "Wei Chen",
                "Yuting Wu",
                "Junfeng Shen",
                "Youfang Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13411v1",
                "http://arxiv.org/pdf/2310.13411v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13407v1",
            "title": "Preserving your skies since 1988 -- Committee on Radio Astronomy\n  Frequencies (CRAF) -- Periodic Review 2011-2021",
            "updated": "2023-10-20T10:24:54Z",
            "published": "2023-10-20T10:24:54Z",
            "summary": "The Committee on Radio Astronomy Frequencies (CRAF) is an Expert Committee of\nthe European Science Foundation. It aims to provide a cost-effective single\nvoice on frequency protection issues for European radio astronomy observatories\nand research institutes, achieving a significantly greater impact than that\nachievable by individual national institutions. By working together, European\nobservatories and institutes can profit from synergy effects, cover many more\ntopics, and learn from each other. CRAF was founded in 1988 and has since then\nbeen engaged with the International Telecommunication Union (ITU), in\nparticular its Radiocommunication Sector (ITU-R), and the European Conference\nof Postal and Telecommunications Administrations (CEPT) and its European\nCommunications Committee (ECC). This is the self-evaluation report prepared by\nCRAF for its periodic review of the years 2011-2021.",
            "author": [
                "Committee on Radio Astronomy Frequencies",
                "Benjamin Winkel",
                "Simon Garrington",
                "Francesco Colomer",
                "Waleed Madkour",
                "Agnieszka Slowikowska",
                "Pietro Bolli",
                "Michael Lindqvist",
                "Jos\u00e9 Antonio L\u00f3pez-P\u00e9rez",
                "Leif Morten Tangen",
                "Ivan Thomas",
                "Peter Thomasson",
                "Roel Witvers",
                "Joe McCauley",
                "Marta Bautista",
                "Miguel Bergano",
                "Vladislavs Bezrukovs",
                "Fabio Giovanardi",
                "Hayo Hase",
                "Karel Jiricka",
                "Gyula I. G. J\u00f3zsa",
                "Juha Kallunki",
                "Christophe Marqu\u00e9",
                "Derek McKay",
                "Axel Murk",
                "Vincent Pietu",
                "Vincenza Tornatore",
                "Busang Sethole",
                "Marian Soida",
                "Boris Sorokin",
                "Gie Han Tan",
                "Adrian Tiplady",
                "L. Viktor T\u00f3th",
                "Federico Di Vruno",
                "Susanne Wampfler",
                "Andrew Williams",
                "Serge Yerin",
                "Justin Bray",
                "Axel Jessner",
                "Nectaria Gizani",
                "Christian Monstein",
                "Mike Peel",
                "Jo\u00e3o Salmim Ferreira",
                "Harry Smith",
                "Giorgios P. Veldes",
                "Pawel Wolak"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13407v1",
                "http://arxiv.org/pdf/2310.13407v1"
            ],
            "primary_category": "astro-ph.IM",
            "category": [
                "astro-ph.IM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13405v2",
            "title": "Cosmological Inference using Gravitational Waves and Normalising Flows",
            "updated": "2023-10-25T16:46:10Z",
            "published": "2023-10-20T10:23:41Z",
            "summary": "We present a machine learning approach using normalising flows for inferring\ncosmological parameters from gravitational wave events. Our methodology is\ngeneral to any type of compact binary coalescence event and cosmological model\nand relies on the generation of training data representing distributions of\ngravitational wave event parameters. These parameters are conditional on the\nunderlying cosmology and incorporate prior information from galaxy catalogues.\nWe provide an example analysis inferring the Hubble constant using binary black\nholes detected during the O1, O2, and O3 observational runs conducted by the\nadvanced LIGO/VIRGO gravitational wave detectors. We obtain a Bayesian\nposterior on the Hubble constant from which we derive an estimate and 1$\\sigma$\nconfidence bounds of $H_{0} = 74.51^{+14.80}_{-13.63} \\: \\text{km}\n\\:\\text{s}^{-1} \\text{Mpc}^{-1}$. We are able to compute this result in\n$\\mathcal{O}(1)$ s using our trained Normalising Flow model.",
            "author": [
                "Federico Stachurski",
                "Christopher Messenger",
                "Martin Hendry"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13405v2",
                "http://arxiv.org/pdf/2310.13405v2"
            ],
            "primary_category": "gr-qc",
            "category": [
                "gr-qc"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13403v1",
            "title": "BRFL: A Blockchain-based Byzantine-Robust Federated Learning Model",
            "updated": "2023-10-20T10:21:50Z",
            "published": "2023-10-20T10:21:50Z",
            "summary": "With the increasing importance of machine learning, the privacy and security\nof training data have become critical. Federated learning, which stores data in\ndistributed nodes and shares only model parameters, has gained significant\nattention for addressing this concern. However, a challenge arises in federated\nlearning due to the Byzantine Attack Problem, where malicious local models can\ncompromise the global model's performance during aggregation. This article\nproposes the Blockchain-based Byzantine-Robust Federated Learning (BRLF) model\nthat combines federated learning with blockchain technology. This integration\nenables traceability of malicious models and provides incentives for locally\ntrained clients. Our approach involves selecting the aggregation node based on\nPearson's correlation coefficient, and we perform spectral clustering and\ncalculate the average gradient within each cluster, validating its accuracy\nusing local dataset of the aggregation nodes. Experimental results on public\ndatasets demonstrate the superior byzantine robustness of our secure\naggregation algorithm compared to other baseline byzantine robust aggregation\nmethods, and proved our proposed model effectiveness in addressing the resource\nconsumption problem.",
            "author": [
                "Yang Li",
                "Chunhe Xia",
                "Chang Li",
                "Tianbo Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13403v1",
                "http://arxiv.org/pdf/2310.13403v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13402v1",
            "title": "Calibrating Neural Simulation-Based Inference with Differentiable\n  Coverage Probability",
            "updated": "2023-10-20T10:20:45Z",
            "published": "2023-10-20T10:20:45Z",
            "summary": "Bayesian inference allows expressing the uncertainty of posterior belief\nunder a probabilistic model given prior information and the likelihood of the\nevidence. Predominantly, the likelihood function is only implicitly established\nby a simulator posing the need for simulation-based inference (SBI). However,\nthe existing algorithms can yield overconfident posteriors (Hermans *et al.*,\n2022) defeating the whole purpose of credibility if the uncertainty\nquantification is inaccurate. We propose to include a calibration term directly\ninto the training objective of the neural model in selected amortized SBI\ntechniques. By introducing a relaxation of the classical formulation of\ncalibration error we enable end-to-end backpropagation. The proposed method is\nnot tied to any particular neural model and brings moderate computational\noverhead compared to the profits it introduces. It is directly applicable to\nexisting computational pipelines allowing reliable black-box posterior\ninference. We empirically show on six benchmark problems that the proposed\nmethod achieves competitive or better results in terms of coverage and expected\nposterior density than the previously existing approaches.",
            "author": [
                "Maciej Falkiewicz",
                "Naoya Takeishi",
                "Imahn Shekhzadeh",
                "Antoine Wehenkel",
                "Arnaud Delaunoy",
                "Gilles Louppe",
                "Alexandros Kalousis"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13402v1",
                "http://arxiv.org/pdf/2310.13402v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13397v1",
            "title": "Equivariant Deep Weight Space Alignment",
            "updated": "2023-10-20T10:12:06Z",
            "published": "2023-10-20T10:12:06Z",
            "summary": "Permutation symmetries of deep networks make simple operations like model\naveraging and similarity estimation challenging. In many cases, aligning the\nweights of the networks, i.e., finding optimal permutations between their\nweights, is necessary. More generally, weight alignment is essential for a wide\nrange of applications, from model merging, through exploring the optimization\nlandscape of deep neural networks, to defining meaningful distance functions\nbetween neural networks. Unfortunately, weight alignment is an NP-hard problem.\nPrior research has mainly focused on solving relaxed versions of the alignment\nproblem, leading to either time-consuming methods or sub-optimal solutions. To\naccelerate the alignment process and improve its quality, we propose a novel\nframework aimed at learning to solve the weight alignment problem, which we\nname Deep-Align. To that end, we first demonstrate that weight alignment\nadheres to two fundamental symmetries and then, propose a deep architecture\nthat respects these symmetries. Notably, our framework does not require any\nlabeled data. We provide a theoretical analysis of our approach and evaluate\nDeep-Align on several types of network architectures and learning setups. Our\nexperimental results indicate that a feed-forward pass with Deep-Align produces\nbetter or equivalent alignments compared to those produced by current\noptimization algorithms. Additionally, our alignments can be used as an\ninitialization for other methods to gain even better solutions with a\nsignificant speedup in convergence.",
            "author": [
                "Aviv Navon",
                "Aviv Shamsian",
                "Ethan Fetaya",
                "Gal Chechik",
                "Nadav Dym",
                "Haggai Maron"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13397v1",
                "http://arxiv.org/pdf/2310.13397v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13396v1",
            "title": "RL-X: A Deep Reinforcement Learning Library (not only) for RoboCup",
            "updated": "2023-10-20T10:06:03Z",
            "published": "2023-10-20T10:06:03Z",
            "summary": "This paper presents the new Deep Reinforcement Learning (DRL) library RL-X\nand its application to the RoboCup Soccer Simulation 3D League and classic DRL\nbenchmarks. RL-X provides a flexible and easy-to-extend codebase with\nself-contained single directory algorithms. Through the fast JAX-based\nimplementations, RL-X can reach up to 4.5x speedups compared to well-known\nframeworks like Stable-Baselines3.",
            "author": [
                "Nico Bohlinger",
                "Klaus Dorer"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13396v1",
                "http://arxiv.org/pdf/2310.13396v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13393v1",
            "title": "Optimal Best Arm Identification with Fixed Confidence in Restless\n  Bandits",
            "updated": "2023-10-20T10:04:05Z",
            "published": "2023-10-20T10:04:05Z",
            "summary": "We study best arm identification in a restless multi-armed bandit setting\nwith finitely many arms. The discrete-time data generated by each arm forms a\nhomogeneous Markov chain taking values in a common, finite state space. The\nstate transitions in each arm are captured by an ergodic transition probability\nmatrix (TPM) that is a member of a single-parameter exponential family of TPMs.\nThe real-valued parameters of the arm TPMs are unknown and belong to a given\nspace. Given a function $f$ defined on the common state space of the arms, the\ngoal is to identify the best arm -- the arm with the largest average value of\n$f$ evaluated under the arm's stationary distribution -- with the fewest number\nof samples, subject to an upper bound on the decision's error probability\n(i.e., the fixed-confidence regime). A lower bound on the growth rate of the\nexpected stopping time is established in the asymptote of a vanishing error\nprobability. Furthermore, a policy for best arm identification is proposed, and\nits expected stopping time is proved to have an asymptotic growth rate that\nmatches the lower bound. It is demonstrated that tracking the long-term\nbehavior of a certain Markov decision process and its state-action visitation\nproportions are the key ingredients in analyzing the converse and achievability\nbounds. It is shown that under every policy, the state-action visitation\nproportions satisfy a specific approximate flow conservation constraint and\nthat these proportions match the optimal proportions dictated by the lower\nbound under any asymptotically optimal policy. The prior studies on best arm\nidentification in restless bandits focus on independent observations from the\narms, rested Markov arms, and restless Markov arms with known arm TPMs. In\ncontrast, this work is the first to study best arm identification in restless\nbandits with unknown arm TPMs.",
            "author": [
                "P. N. Karthik",
                "Vincent Y. F. Tan",
                "Arpan Mukherjee",
                "Ali Tajer"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13393v1",
                "http://arxiv.org/pdf/2310.13393v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.IT",
                "cs.LG",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13391v1",
            "title": "Learning Successor Representations with Distributed Hebbian Temporal\n  Memory",
            "updated": "2023-10-20T10:03:14Z",
            "published": "2023-10-20T10:03:14Z",
            "summary": "This paper presents a novel approach to address the challenge of online\nhidden representation learning for decision-making under uncertainty in\nnon-stationary, partially observable environments. The proposed algorithm,\nDistributed Hebbian Temporal Memory (DHTM), is based on factor graph formalism\nand a multicomponent neuron model. DHTM aims to capture sequential data\nrelationships and make cumulative predictions about future observations,\nforming Successor Representation (SR). Inspired by neurophysiological models of\nthe neocortex, the algorithm utilizes distributed representations, sparse\ntransition matrices, and local Hebbian-like learning rules to overcome the\ninstability and slow learning process of traditional temporal memory algorithms\nlike RNN and HMM. Experimental results demonstrate that DHTM outperforms\nclassical LSTM and performs comparably to more advanced RNN-like algorithms,\nspeeding up Temporal Difference learning for SR in changing environments.\nAdditionally, we compare the SRs produced by DHTM to another biologically\ninspired HMM-like algorithm, CSCG. Our findings suggest that DHTM is a\npromising approach for addressing the challenges of online hidden\nrepresentation learning in dynamic environments.",
            "author": [
                "Evgenii Dzhivelikian",
                "Petr Kuderov",
                "Aleksandr I. Panov"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13391v1",
                "http://arxiv.org/pdf/2310.13391v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13388v2",
            "title": "Music Augmentation and Denoising For Peak-Based Audio Fingerprinting",
            "updated": "2023-10-29T10:48:51Z",
            "published": "2023-10-20T09:56:22Z",
            "summary": "Audio fingerprinting is a well-established solution for song identification\nfrom short recording excerpts. Popular methods rely on the extraction of sparse\nrepresentations, generally spectral peaks, and have proven to be accurate,\nfast, and scalable to large collections. However, real-world applications of\naudio identification often happen in noisy environments, which can cause these\nsystems to fail. In this work, we tackle this problem by introducing and\nreleasing a new audio augmentation pipeline that adds noise to music snippets\nin a realistic way, by stochastically mimicking real-world scenarios. We then\npropose and release a deep learning model that removes noisy components from\nspectrograms in order to improve peak-based fingerprinting systems' accuracy.\nWe show that the addition of our model improves the identification performance\nof commonly used audio fingerprinting systems, even under noisy conditions.",
            "author": [
                "Kamil Akesbi",
                "Dorian Desblancs",
                "Benjamin Martin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13388v2",
                "http://arxiv.org/pdf/2310.13388v2"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.IR",
                "cs.LG",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13387v1",
            "title": "Assumption violations in causal discovery and the robustness of score\n  matching",
            "updated": "2023-10-20T09:56:07Z",
            "published": "2023-10-20T09:56:07Z",
            "summary": "When domain knowledge is limited and experimentation is restricted by\nethical, financial, or time constraints, practitioners turn to observational\ncausal discovery methods to recover the causal structure, exploiting the\nstatistical properties of their data. Because causal discovery without further\nassumptions is an ill-posed problem, each algorithm comes with its own set of\nusually untestable assumptions, some of which are hard to meet in real\ndatasets. Motivated by these considerations, this paper extensively benchmarks\nthe empirical performance of recent causal discovery methods on observational\ni.i.d. data generated under different background conditions, allowing for\nviolations of the critical assumptions required by each selected approach. Our\nexperimental findings show that score matching-based methods demonstrate\nsurprising performance in the false positive and false negative rate of the\ninferred graph in these challenging scenarios, and we provide theoretical\ninsights into their performance. This work is also the first effort to\nbenchmark the stability of causal discovery algorithms with respect to the\nvalues of their hyperparameters. Finally, we hope this paper will set a new\nstandard for the evaluation of causal discovery methods and can serve as an\naccessible entry point for practitioners interested in the field, highlighting\nthe empirical implications of different algorithm choices.",
            "author": [
                "Francesco Montagna",
                "Atalanti A. Mastakouri",
                "Elias Eulig",
                "Nicoletta Noceti",
                "Lorenzo Rosasco",
                "Dominik Janzing",
                "Bryon Aragam",
                "Francesco Locatello"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13387v1",
                "http://arxiv.org/pdf/2310.13387v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13385v1",
            "title": "Tuna: Instruction Tuning using Feedback from Large Language Models",
            "updated": "2023-10-20T09:55:06Z",
            "published": "2023-10-20T09:55:06Z",
            "summary": "Instruction tuning of open-source large language models (LLMs) like LLaMA,\nusing direct outputs from more powerful LLMs such as Instruct-GPT and GPT-4,\nhas proven to be a cost-effective way to align model behaviors with human\npreferences. However, the instruction-tuned model has only seen one response\nper instruction, lacking the knowledge of potentially better responses. In this\npaper, we propose finetuning an instruction-tuned LLM using our novel\n\\textit{probabilistic ranking} and \\textit{contextual ranking} approaches to\nincrease the likelihood of generating better responses. Probabilistic ranking\nenables the instruction-tuned model to inherit the relative rankings of\nhigh-quality and low-quality responses from the teacher LLM. On the other hand,\nlearning with contextual ranking allows the model to refine its own response\ndistribution using the contextual understanding ability of stronger LLMs.\nFurthermore, we apply probabilistic ranking and contextual ranking sequentially\nto the instruction-tuned LLM. The resulting model, which we call \\textbf{Tuna},\nconsistently improves the performance on Super Natural Instructions (119 test\ntasks), LMentry (25 test tasks), Vicuna QA, and can even obtain better results\nthan several strong reinforcement learning baselines. Our code and data are\navailable at \\url{ https://github.com/microsoft/LMOps}.",
            "author": [
                "Haoran Li",
                "Yiran Liu",
                "Xingxing Zhang",
                "Wei Lu",
                "Furu Wei"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13385v1",
                "http://arxiv.org/pdf/2310.13385v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13384v1",
            "title": "Salted Inference: Enhancing Privacy while Maintaining Efficiency of\n  Split Inference in Mobile Computing",
            "updated": "2023-10-20T09:53:55Z",
            "published": "2023-10-20T09:53:55Z",
            "summary": "Split inference partitions a deep neural network (DNN) to run the early part\nat the edge and the later part in the cloud. This meets two key requirements\nfor on-device machine learning: input privacy and compute efficiency. Still, an\nopen question in split inference is output privacy, given that the output of a\nDNN is visible to the cloud. While encrypted computing can protect output\nprivacy, it mandates extensive computation and communication resources. In this\npaper, we introduce \"Salted DNNs\": a novel method that lets clients control the\nsemantic interpretation of DNN output at inference time while maintaining\naccuracy and efficiency very close to that of a standard DNN. Experimental\nevaluations conducted on both image and sensor data show that Salted DNNs\nachieve classification accuracy very close to standard DNNs, particularly when\nthe salted layer is positioned within the early part to meet the requirements\nof split inference. Our method is general and can be applied to various DNNs.\nWe open-source our code and results, as a benchmark for future studies.",
            "author": [
                "Mohammad Malekzadeh",
                "Fahim Kawsar"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13384v1",
                "http://arxiv.org/pdf/2310.13384v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13382v1",
            "title": "Quantum error mitigation in the regime of high noise using deep neural\n  network: Trotterized dynamics",
            "updated": "2023-10-20T09:53:05Z",
            "published": "2023-10-20T09:53:05Z",
            "summary": "We address a learning-based quantum error mitigation method, which utilizes\ndeep neural network applied at the postprocessing stage, and study its\nperformance in presence of different types of quantum noises. We concentrate on\nthe simulation of Trotterized dynamics of 2D spin lattice in the regime of high\nnoise, when expectation values of bounded traceless observables are strongly\nsuppressed. By using numerical simulations, we demonstrate a dramatic\nimprovement of data quality for both local weight-1 and weight-2 observables\nfor the depolarizing and inhomogeneous Pauli channels. The quality of error\nmitigation, especially for weight-1 observables, is limited essentially by\nstatistical uncertainties due to the probabilistic nature of measurements. At\nthe same time, the effect of coherent $ZZ$ crosstalks is not mitigated, so that\nin practise crosstalks should be at first converted into incoherent errors by\nrandomized compiling.",
            "author": [
                "A. A. Zhukov",
                "W. V. Pogosov"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13382v1",
                "http://arxiv.org/pdf/2310.13382v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13381v1",
            "title": "Accelerated sparse Kernel Spectral Clustering for large scale data\n  clustering problems",
            "updated": "2023-10-20T09:51:42Z",
            "published": "2023-10-20T09:51:42Z",
            "summary": "An improved version of the sparse multiway kernel spectral clustering (KSC)\nis presented in this brief. The original algorithm is derived from weighted\nkernel principal component (KPCA) analysis formulated within the primal-dual\nleast-squares support vector machine (LS-SVM) framework. Sparsity is achieved\nthen by the combination of the incomplete Cholesky decomposition (ICD) based\nlow rank approximation of the kernel matrix with the so called reduced set\nmethod. The original ICD based sparse KSC algorithm was reported to be\ncomputationally far too demanding, especially when applied on large scale data\nclustering problems that actually it was designed for, which has prevented to\ngain more than simply theoretical relevance so far. This is altered by the\nmodifications reported in this brief that drastically improve the computational\ncharacteristics. Solving the alternative, symmetrized version of the\ncomputationally most demanding core eigenvalue problem eliminates the necessity\nof forming and SVD of large matrices during the model construction. This\nresults in solving clustering problems now within seconds that were reported to\nrequire hours without altering the results. Furthermore, sparsity is also\nimproved significantly, leading to more compact model representation,\nincreasing further not only the computational efficiency but also the\ndescriptive power. These transform the original, only theoretically relevant\nICD based sparse KSC algorithm applicable for large scale practical clustering\nproblems. Theoretical results and improvements are demonstrated by\ncomputational experiments on carefully selected synthetic data as well as on\nreal life problems such as image segmentation.",
            "author": [
                "Mihaly Novak",
                "Rocco Langone",
                "Carlos Alzate",
                "Johan Suykens"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13381v1",
                "http://arxiv.org/pdf/2310.13381v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13380v1",
            "title": "APP: Adaptive Prototypical Pseudo-Labeling for Few-shot OOD Detection",
            "updated": "2023-10-20T09:48:52Z",
            "published": "2023-10-20T09:48:52Z",
            "summary": "Detecting out-of-domain (OOD) intents from user queries is essential for a\ntask-oriented dialogue system. Previous OOD detection studies generally work on\nthe assumption that plenty of labeled IND intents exist. In this paper, we\nfocus on a more practical few-shot OOD setting where there are only a few\nlabeled IND data and massive unlabeled mixed data that may belong to IND or\nOOD. The new scenario carries two key challenges: learning discriminative\nrepresentations using limited IND data and leveraging unlabeled mixed data.\nTherefore, we propose an adaptive prototypical pseudo-labeling (APP) method for\nfew-shot OOD detection, including a prototypical OOD detection framework\n(ProtoOOD) to facilitate low-resource OOD detection using limited IND data, and\nan adaptive pseudo-labeling method to produce high-quality pseudo OOD\\&IND\nlabels. Extensive experiments and analysis demonstrate the effectiveness of our\nmethod for few-shot OOD detection.",
            "author": [
                "Pei Wang",
                "Keqing He",
                "Yutao Mou",
                "Xiaoshuai Song",
                "Yanan Wu",
                "Jingang Wang",
                "Yunsen Xian",
                "Xunliang Cai",
                "Weiran Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13380v1",
                "http://arxiv.org/pdf/2310.13380v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13378v1",
            "title": "ScalableMap: Scalable Map Learning for Online Long-Range Vectorized HD\n  Map Construction",
            "updated": "2023-10-20T09:46:24Z",
            "published": "2023-10-20T09:46:24Z",
            "summary": "We propose a novel end-to-end pipeline for online long-range vectorized\nhigh-definition (HD) map construction using on-board camera sensors. The\nvectorized representation of HD maps, employing polylines and polygons to\nrepresent map elements, is widely used by downstream tasks. However, previous\nschemes designed with reference to dynamic object detection overlook the\nstructural constraints within linear map elements, resulting in performance\ndegradation in long-range scenarios. In this paper, we exploit the properties\nof map elements to improve the performance of map construction. We extract more\naccurate bird's eye view (BEV) features guided by their linear structure, and\nthen propose a hierarchical sparse map representation to further leverage the\nscalability of vectorized map elements and design a progressive decoding\nmechanism and a supervision strategy based on this representation. Our\napproach, ScalableMap, demonstrates superior performance on the nuScenes\ndataset, especially in long-range scenarios, surpassing previous\nstate-of-the-art model by 6.5 mAP while achieving 18.3 FPS. Code is available\nat https://github.com/jingy1yu/ScalableMap.",
            "author": [
                "Jingyi Yu",
                "Zizhao Zhang",
                "Shengfu Xia",
                "Jizhang Sang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13378v1",
                "http://arxiv.org/pdf/2310.13378v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14948v4",
            "title": "Physics-Informed Graph Convolutional Networks: Towards a generalized\n  framework for complex geometries",
            "updated": "2023-11-24T13:33:51Z",
            "published": "2023-10-20T09:46:12Z",
            "summary": "Since the seminal work of [9] and their Physics-Informed neural networks\n(PINNs), many efforts have been conducted towards solving partial differential\nequations (PDEs) with Deep Learning models. However, some challenges remain,\nfor instance the extension of such models to complex three-dimensional\ngeometries, and a study on how such approaches could be combined to classical\nnumerical solvers. In this work, we justify the use of graph neural networks\nfor these problems, based on the similarity between these architectures and the\nmeshes used in traditional numerical techniques for solving partial\ndifferential equations. After proving an issue with the Physics-Informed\nframework for complex geometries, during the computation of PDE residuals, an\nalternative procedure is proposed, by combining classical numerical solvers and\nthe Physics-Informed framework. Finally, we propose an implementation of this\napproach, that we test on a three-dimensional problem on an irregular geometry.",
            "author": [
                "Marien Chenaud",
                "Jos\u00e9 Alves",
                "Fr\u00e9d\u00e9ric Magoul\u00e8s"
            ],
            "link": [
                "http://dx.doi.org/10.4203/ccc.5.4.2",
                "http://arxiv.org/abs/2310.14948v4",
                "http://arxiv.org/pdf/2310.14948v4"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math-ph",
                "math.AP",
                "math.MP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13377v1",
            "title": "A Human-Robot Mutual Learning System with Affect-Grounded Language\n  Acquisition and Differential Outcomes Training",
            "updated": "2023-10-20T09:41:31Z",
            "published": "2023-10-20T09:41:31Z",
            "summary": "This paper presents a novel human-robot interaction setup for robot and human\nlearning of symbolic language for identifying robot homeostatic needs. The\nrobot and human learn to use and respond to the same language symbols that\nconvey homeostatic needs and the stimuli that satisfy the homeostatic needs,\nrespectively. We adopted a differential outcomes training (DOT) protocol\nwhereby the robot provides feedback specific (differential) to its internal\nneeds (e.g. `hunger') when satisfied by the correct stimulus (e.g. cookie). We\nfound evidence that DOT can enhance the human's learning efficiency, which in\nturn enables more efficient robot language acquisition. The robot used in the\nstudy has a vocabulary similar to that of a human infant in the linguistic\n``babbling'' phase. The robot software architecture is built upon a model for\naffect-grounded language acquisition where the robot associates vocabulary with\ninternal needs (hunger, thirst, curiosity) through interactions with the human.\nThe paper presents the results of an initial pilot study conducted with the\ninteractive setup, which reveal that the robot's language acquisition achieves\nhigher convergence rate in the DOT condition compared to the non-DOT control\ncondition. Additionally, participants reported positive affective experiences,\nfeeling of being in control, and an empathetic connection with the robot. This\nmutual learning (teacher-student learning) approach offers a potential\ncontribution of facilitating cognitive interventions with DOT (e.g. for people\nwith dementia) through increased therapy adherence as a result of engaging\nhumans more in training tasks by taking an active teaching-learning role. The\nhomeostatic motivational grounding of the robot's language acquisition has\npotential to contribute to more ecologically valid and social\n(collaborative/nurturing) interactions with robots.",
            "author": [
                "Alva Markelius",
                "Sofia Sj\u00f6berg",
                "Zakaria Lemhauori",
                "Laura Cohen",
                "Martin Bergstr\u00f6m",
                "Robert Lowe",
                "Lola Ca\u00f1amero"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13377v1",
                "http://arxiv.org/pdf/2310.13377v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.CL",
                "cs.HC",
                "I.2.9; I.2.6; I.2.10"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13372v1",
            "title": "The cdh-local motivic homotopy category",
            "updated": "2023-10-20T09:30:15Z",
            "published": "2023-10-20T09:30:15Z",
            "summary": "We construct a cdh-local motivic homotopy category SH_cdh(S) over an\narbitrary base scheme S, and show that there is a canonical equivalence between\nSH_cdh(S) and SH(S). We learned this result from D.-C. Cisinski.",
            "author": [
                "Adeel A. Khan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13372v1",
                "http://arxiv.org/pdf/2310.13372v1"
            ],
            "primary_category": "math.AG",
            "category": [
                "math.AG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13369v1",
            "title": "SigFormer: Signature Transformers for Deep Hedging",
            "updated": "2023-10-20T09:25:35Z",
            "published": "2023-10-20T09:25:35Z",
            "summary": "Deep hedging is a promising direction in quantitative finance, incorporating\nmodels and techniques from deep learning research. While giving excellent\nhedging strategies, models inherently requires careful treatment in designing\narchitectures for neural networks. To mitigate such difficulties, we introduce\nSigFormer, a novel deep learning model that combines the power of path\nsignatures and transformers to handle sequential data, particularly in cases\nwith irregularities. Path signatures effectively capture complex data patterns,\nwhile transformers provide superior sequential attention. Our proposed model is\nempirically compared to existing methods on synthetic data, showcasing faster\nlearning and enhanced robustness, especially in the presence of irregular\nunderlying price data. Additionally, we validate our model performance through\na real-world backtest on hedging the SP 500 index, demonstrating positive\noutcomes.",
            "author": [
                "Anh Tong",
                "Thanh Nguyen-Tang",
                "Dongeun Lee",
                "Toan Tran",
                "Jaesik Choi"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3604237.3626841",
                "http://arxiv.org/abs/2310.13369v1",
                "http://arxiv.org/pdf/2310.13369v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13367v1",
            "title": "VFedMH: Vertical Federated Learning for Training Multi-party\n  Heterogeneous Models",
            "updated": "2023-10-20T09:22:51Z",
            "published": "2023-10-20T09:22:51Z",
            "summary": "Vertical Federated Learning (VFL) has gained increasing attention as a novel\ntraining paradigm that integrates sample alignment and feature union. However,\nexisting VFL methods face challenges when dealing with heterogeneous local\nmodels among participants, which affects optimization convergence and\ngeneralization. To address this issue, this paper proposes a novel approach\ncalled Vertical Federated learning for training Multi-parties Heterogeneous\nmodels (VFedMH). VFedMH focuses on aggregating the embeddings of each\nparticipant's knowledge instead of intermediate results during forward\npropagation. The active party, who possesses labels and features of the sample,\nin VFedMH securely aggregates local embeddings to obtain global knowledge\nembeddings, and sends them to passive parties. The passive parties, who own\nonly features of the sample, then utilize the global embeddings to propagate\nforward on their local heterogeneous networks. However, the passive party does\nnot own the labels, so the local model gradient cannot be calculated locally.\nTo overcome this limitation, the active party assists the passive party in\ncomputing its local heterogeneous model gradients. Then, each participant\ntrains their local model using the heterogeneous model gradients. The objective\nis to minimize the loss value of their respective local heterogeneous models.\nAdditionally, the paper provides a theoretical analysis of VFedMH's convergence\nperformance. Extensive experiments are conducted to demonstrate that VFedMH can\nsimultaneously train multiple heterogeneous models with heterogeneous\noptimization and outperform some recent methods in model performance.",
            "author": [
                "Shuo Wang",
                "Keke Gai",
                "Jing Yu",
                "Liehuang Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13367v1",
                "http://arxiv.org/pdf/2310.13367v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13365v1",
            "title": "Towards Multi-Subsession Conversational Recommendation",
            "updated": "2023-10-20T09:12:37Z",
            "published": "2023-10-20T09:12:37Z",
            "summary": "Conversational recommendation systems (CRS) could acquire dynamic user\npreferences towards desired items through multi-round interactive dialogue.\nPrevious CRS mainly focuses on the single conversation (subsession) that user\nquits after a successful recommendation, neglecting the common scenario where\nuser has multiple conversations (multi-subsession) over a short period.\nTherefore, we propose a novel conversational recommendation scenario named\nMulti-Subsession Multi-round Conversational Recommendation (MSMCR), where user\nwould still resort to CRS after several subsessions and might preserve vague\ninterests, and system would proactively ask attributes to activate user\ninterests in the current subsession. To fill the gap in this new CRS scenario,\nwe devise a novel framework called Multi-Subsession Conversational Recommender\nwith Activation Attributes (MSCAA). Specifically, we first develop a\ncontext-aware recommendation module, comprehensively modeling user interests\nfrom historical interactions, previous subsessions, and feedback in the current\nsubsession. Furthermore, an attribute selection policy module is proposed to\nlearn a flexible strategy for asking appropriate attributes to elicit user\ninterests. Finally, we design a conversation policy module to manage the above\ntwo modules to decide actions between asking and recommending. Extensive\nexperiments on four datasets verify the effectiveness of our MSCAA framework\nfor the MSMCR setting.",
            "author": [
                "Yu Ji",
                "Qi Shen",
                "Shixuan Zhu",
                "Hang Yu",
                "Yiming Zhang",
                "Chuan Cui",
                "Zhihua Wei"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13365v1",
                "http://arxiv.org/pdf/2310.13365v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13364v1",
            "title": "Dissecting Causal Biases",
            "updated": "2023-10-20T09:12:10Z",
            "published": "2023-10-20T09:12:10Z",
            "summary": "Accurately measuring discrimination in machine learning-based automated\ndecision systems is required to address the vital issue of fairness between\nsubpopulations and/or individuals. Any bias in measuring discrimination can\nlead to either amplification or underestimation of the true value of\ndiscrimination. This paper focuses on a class of bias originating in the way\ntraining data is generated and/or collected. We call such class causal biases\nand use tools from the field of causality to formally define and analyze such\nbiases. Four sources of bias are considered, namely, confounding, selection,\nmeasurement, and interaction. The main contribution of this paper is to\nprovide, for each source of bias, a closed-form expression in terms of the\nmodel parameters. This makes it possible to analyze the behavior of each source\nof bias, in particular, in which cases they are absent and in which other cases\nthey are maximized. We hope that the provided characterizations help the\ncommunity better understand the sources of bias in machine learning\napplications.",
            "author": [
                "R\u016bta Binkyt\u0117",
                "Sami Zhioua",
                "Yassine Turki"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13364v1",
                "http://arxiv.org/pdf/2310.13364v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13362v1",
            "title": "Towards General Error Diagnosis via Behavioral Testing in Machine\n  Translation",
            "updated": "2023-10-20T09:06:41Z",
            "published": "2023-10-20T09:06:41Z",
            "summary": "Behavioral testing offers a crucial means of diagnosing linguistic errors and\nassessing capabilities of NLP models. However, applying behavioral testing to\nmachine translation (MT) systems is challenging as it generally requires human\nefforts to craft references for evaluating the translation quality of such\nsystems on newly generated test cases. Existing works in behavioral testing of\nMT systems circumvent this by evaluating translation quality without\nreferences, but this restricts diagnosis to specific types of errors, such as\nincorrect translation of single numeric or currency words. In order to diagnose\ngeneral errors, this paper proposes a new Bilingual Translation Pair Generation\nbased Behavior Testing (BTPGBT) framework for conducting behavioral testing of\nMT systems. The core idea of BTPGBT is to employ a novel bilingual translation\npair generation (BTPG) approach that automates the construction of high-quality\ntest cases and their pseudoreferences. Experimental results on various MT\nsystems demonstrate that BTPGBT could provide comprehensive and accurate\nbehavioral testing results for general error diagnosis, which further leads to\nseveral insightful findings. Our code and data are available at https:\n//github.com/wujunjie1998/BTPGBT.",
            "author": [
                "Junjie Wu",
                "Lemao Liu",
                "Dit-Yan Yeung"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13362v1",
                "http://arxiv.org/pdf/2310.13362v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13355v2",
            "title": "SILC: Improving Vision Language Pretraining with Self-Distillation",
            "updated": "2023-12-07T10:39:44Z",
            "published": "2023-10-20T08:44:47Z",
            "summary": "Image-Text pretraining on web-scale image caption datasets has become the\ndefault recipe for open vocabulary classification and retrieval models thanks\nto the success of CLIP and its variants. Several works have also used CLIP\nfeatures for dense prediction tasks and have shown the emergence of open-set\nabilities. However, the contrastive objective used by these models only focuses\non image-text alignment and does not incentivise image feature learning for\ndense prediction tasks. In this work, we introduce SILC, a novel framework for\nvision language pretraining. SILC improves image-text contrastive learning with\nthe simple addition of local-to-global correspondence learning by\nself-distillation. We show that distilling local image features from an\nexponential moving average (EMA) teacher model significantly improves model\nperformance on dense predictions tasks like detection and segmentation, while\nalso providing improvements on image-level tasks such as classification and\nretrieval. SILC models sets a new state of the art for zero-shot\nclassification, few shot classification, image and text retrieval, zero-shot\nsegmentation, and open vocabulary segmentation. We further show that SILC\nfeatures greatly benefit open vocabulary detection, captioning and visual\nquestion answering.",
            "author": [
                "Muhammad Ferjad Naeem",
                "Yongqin Xian",
                "Xiaohua Zhai",
                "Lukas Hoyer",
                "Luc Van Gool",
                "Federico Tombari"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13355v2",
                "http://arxiv.org/pdf/2310.13355v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14906v1",
            "title": "DYNAMITE: Dynamic Interplay of Mini-Batch Size and Aggregation Frequency\n  for Federated Learning with Static and Streaming Dataset",
            "updated": "2023-10-20T08:36:12Z",
            "published": "2023-10-20T08:36:12Z",
            "summary": "Federated Learning (FL) is a distributed learning paradigm that can\ncoordinate heterogeneous edge devices to perform model training without sharing\nprivate data. While prior works have focused on analyzing FL convergence with\nrespect to hyperparameters like batch size and aggregation frequency, the joint\neffects of adjusting these parameters on model performance, training time, and\nresource consumption have been overlooked, especially when facing dynamic data\nstreams and network characteristics. This paper introduces novel analytical\nmodels and optimization algorithms that leverage the interplay between batch\nsize and aggregation frequency to navigate the trade-offs among convergence,\ncost, and completion time for dynamic FL training. We establish a new\nconvergence bound for training error considering heterogeneous datasets across\ndevices and derive closed-form solutions for co-optimized batch size and\naggregation frequency that are consistent across all devices. Additionally, we\ndesign an efficient algorithm for assigning different batch configurations\nacross devices, improving model accuracy and addressing the heterogeneity of\nboth data and system characteristics. Further, we propose an adaptive control\nalgorithm that dynamically estimates network states, efficiently samples\nappropriate data batches, and effectively adjusts batch sizes and aggregation\nfrequency on the fly. Extensive experiments demonstrate the superiority of our\noffline optimal solutions and online adaptive algorithm.",
            "author": [
                "Weijie Liu",
                "Xiaoxi Zhang",
                "Jingpu Duan",
                "Carlee Joe-Wong",
                "Zhi Zhou",
                "Xu Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14906v1",
                "http://arxiv.org/pdf/2310.14906v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "I.2.6"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13350v1",
            "title": "EarlyBird: Early-Fusion for Multi-View Tracking in the Bird's Eye View",
            "updated": "2023-10-20T08:27:21Z",
            "published": "2023-10-20T08:27:21Z",
            "summary": "Multi-view aggregation promises to overcome the occlusion and missed\ndetection challenge in multi-object detection and tracking. Recent approaches\nin multi-view detection and 3D object detection made a huge performance leap by\nprojecting all views to the ground plane and performing the detection in the\nBird's Eye View (BEV). In this paper, we investigate if tracking in the BEV can\nalso bring the next performance breakthrough in Multi-Target Multi-Camera\n(MTMC) tracking. Most current approaches in multi-view tracking perform the\ndetection and tracking task in each view and use graph-based approaches to\nperform the association of the pedestrian across each view. This spatial\nassociation is already solved by detecting each pedestrian once in the BEV,\nleaving only the problem of temporal association. For the temporal association,\nwe show how to learn strong Re-Identification (re-ID) features for each\ndetection. The results show that early-fusion in the BEV achieves high accuracy\nfor both detection and tracking. EarlyBird outperforms the state-of-the-art\nmethods and improves the current state-of-the-art on Wildtrack by +4.6 MOTA and\n+5.6 IDF1.",
            "author": [
                "Torben Teepe",
                "Philipp Wolters",
                "Johannes Gilg",
                "Fabian Herzog",
                "Gerhard Rigoll"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13350v1",
                "http://arxiv.org/pdf/2310.13350v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13349v1",
            "title": "DeepFDR: A Deep Learning-based False Discovery Rate Control Method for\n  Neuroimaging Data",
            "updated": "2023-10-20T08:27:13Z",
            "published": "2023-10-20T08:27:13Z",
            "summary": "Voxel-based multiple testing is widely used in neuroimaging data analysis.\nTraditional false discovery rate (FDR) control methods often ignore the spatial\ndependence among the voxel-based tests and thus suffer from substantial loss of\ntesting power. While recent spatial FDR control methods have emerged, their\nvalidity and optimality remain questionable when handling the complex spatial\ndependencies of the brain. Concurrently, deep learning methods have\nrevolutionized image segmentation, a task closely related to voxel-based\nmultiple testing. In this paper, we propose DeepFDR, a novel spatial FDR\ncontrol method that leverages unsupervised deep learning-based image\nsegmentation to address the voxel-based multiple testing problem. Numerical\nstudies, including comprehensive simulations and Alzheimer's disease FDG-PET\nimage analysis, demonstrate DeepFDR's superiority over existing methods.\nDeepFDR not only excels in FDR control and effectively diminishes the false\nnondiscovery rate, but also boasts exceptional computational efficiency highly\nsuited for tackling large-scale neuroimaging data.",
            "author": [
                "Taehyo Kim",
                "Hai Shu",
                "Qiran Jia",
                "Mony de Leon"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13349v1",
                "http://arxiv.org/pdf/2310.13349v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13347v1",
            "title": "NurViD: A Large Expert-Level Video Database for Nursing Procedure\n  Activity Understanding",
            "updated": "2023-10-20T08:22:56Z",
            "published": "2023-10-20T08:22:56Z",
            "summary": "The application of deep learning to nursing procedure activity understanding\nhas the potential to greatly enhance the quality and safety of nurse-patient\ninteractions. By utilizing the technique, we can facilitate training and\neducation, improve quality control, and enable operational compliance\nmonitoring. However, the development of automatic recognition systems in this\nfield is currently hindered by the scarcity of appropriately labeled datasets.\nThe existing video datasets pose several limitations: 1) these datasets are\nsmall-scale in size to support comprehensive investigations of nursing\nactivity; 2) they primarily focus on single procedures, lacking expert-level\nannotations for various nursing procedures and action steps; and 3) they lack\ntemporally localized annotations, which prevents the effective localization of\ntargeted actions within longer video sequences. To mitigate these limitations,\nwe propose NurViD, a large video dataset with expert-level annotation for\nnursing procedure activity understanding. NurViD consists of over 1.5k videos\ntotaling 144 hours, making it approximately four times longer than the existing\nlargest nursing activity datasets. Notably, it encompasses 51 distinct nursing\nprocedures and 177 action steps, providing a much more comprehensive coverage\ncompared to existing datasets that primarily focus on limited procedures. To\nevaluate the efficacy of current deep learning methods on nursing activity\nunderstanding, we establish three benchmarks on NurViD: procedure recognition\non untrimmed videos, procedure and action recognition on trimmed videos, and\naction detection. Our benchmark and code will be available at\n\\url{https://github.com/minghu0830/NurViD-benchmark}.",
            "author": [
                "Ming Hu",
                "Lin Wang",
                "Siyuan Yan",
                "Don Ma",
                "Qingli Ren",
                "Peng Xia",
                "Wei Feng",
                "Peibo Duan",
                "Lie Ju",
                "Zongyuan Ge"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13347v1",
                "http://arxiv.org/pdf/2310.13347v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13344v1",
            "title": "DeepFracture: A Generative Approach for Predicting Brittle Fractures",
            "updated": "2023-10-20T08:15:13Z",
            "published": "2023-10-20T08:15:13Z",
            "summary": "In the realm of brittle fracture animation, generating realistic destruction\nanimations with physics simulation techniques can be computationally expensive.\nAlthough methods using Voronoi diagrams or pre-fractured patterns work for\nreal-time applications, they often lack realism in portraying brittle\nfractures. This paper introduces a novel learning-based approach for seamlessly\nmerging realistic brittle fracture animations with rigid-body simulations. Our\nmethod utilizes BEM brittle fracture simulations to create fractured patterns\nand collision conditions for a given shape, which serve as training data for\nthe learning process. To effectively integrate collision conditions and\nfractured shapes into a deep learning framework, we introduce the concept of\nlatent impulse representation and geometrically-segmented signed distance\nfunction (GS-SDF). The latent impulse representation serves as input, capturing\ninformation about impact forces on the shape's surface. Simultaneously, a\nGS-SDF is used as the output representation of the fractured shape. To address\nthe challenge of optimizing multiple fractured pattern targets with a single\nlatent code, we propose an eight-dimensional latent space based on a normal\ndistribution code within our latent impulse representation design. This\nadaptation effectively transforms our neural network into a generative one. Our\nexperimental results demonstrate that our approach can generate significantly\nmore detailed brittle fractures compared to existing techniques, all while\nmaintaining commendable computational efficiency during run-time.",
            "author": [
                "Yuhang Huang",
                "Takashi Kanai"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13344v1",
                "http://arxiv.org/pdf/2310.13344v1"
            ],
            "primary_category": "cs.GR",
            "category": [
                "cs.GR",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13343v1",
            "title": "Challenges and Contributing Factors in the Utilization of Large Language\n  Models (LLMs)",
            "updated": "2023-10-20T08:13:36Z",
            "published": "2023-10-20T08:13:36Z",
            "summary": "With the development of large language models (LLMs) like the GPT series,\ntheir widespread use across various application scenarios presents a myriad of\nchallenges. This review initially explores the issue of domain specificity,\nwhere LLMs may struggle to provide precise answers to specialized questions\nwithin niche fields. The problem of knowledge forgetting arises as these LLMs\nmight find it hard to balance old and new information. The knowledge repetition\nphenomenon reveals that sometimes LLMs might deliver overly mechanized\nresponses, lacking depth and originality. Furthermore, knowledge illusion\ndescribes situations where LLMs might provide answers that seem insightful but\nare actually superficial, while knowledge toxicity focuses on harmful or biased\ninformation outputs. These challenges underscore problems in the training data\nand algorithmic design of LLMs. To address these issues, it's suggested to\ndiversify training data, fine-tune models, enhance transparency and\ninterpretability, and incorporate ethics and fairness training. Future\ntechnological trends might lean towards iterative methodologies, multimodal\nlearning, model personalization and customization, and real-time learning and\nfeedback mechanisms. In conclusion, future LLMs should prioritize fairness,\ntransparency, and ethics, ensuring they uphold high moral and ethical standards\nwhen serving humanity.",
            "author": [
                "Xiaoliang Chen",
                "Liangbin Li",
                "Le Chang",
                "Yunhe Huang",
                "Yuxuan Zhao",
                "Yuxiao Zhang",
                "Dinuo Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13343v1",
                "http://arxiv.org/pdf/2310.13343v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13342v1",
            "title": "Unsupervised learning of phase transitions via modified anomaly\n  detection with autoencoders",
            "updated": "2023-10-20T08:11:53Z",
            "published": "2023-10-20T08:11:53Z",
            "summary": "In this paper, a modified method of anomaly detection using convolutional\nautoencoders is employed to predict phase transitions in several statistical\nmechanical models on a square lattice. We show that, when the autoencoder is\ntrained with input data of various phases, the mean-square-error loss function\ncan serve as a measure of disorder, and its standard deviation becomes an\nexcellent indicator of critical points. We find that various types of phase\ntransition points, including first-order, second-order, and topological ones,\ncan be faithfully detected by the peaks in the standard deviation of the loss\nfunction. Besides, the values of transition points can be accurately determined\nunder the analysis of finite-size scaling. Our results demonstrate that the\npresent approach has general application in identification/classification of\nphase transitions even without a priori knowledge of the systems in question.",
            "author": [
                "Kwai-Kong Ng",
                "Min-Fong Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13342v1",
                "http://arxiv.org/pdf/2310.13342v1"
            ],
            "primary_category": "cond-mat.dis-nn",
            "category": [
                "cond-mat.dis-nn"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13340v1",
            "title": "Large-Scale and Multi-Perspective Opinion Summarization with Diverse\n  Review Subsets",
            "updated": "2023-10-20T08:08:13Z",
            "published": "2023-10-20T08:08:13Z",
            "summary": "Opinion summarization is expected to digest larger review sets and provide\nsummaries from different perspectives. However, most existing solutions are\ndeficient in epitomizing extensive reviews and offering opinion summaries from\nvarious angles due to the lack of designs for information selection. To this\nend, we propose SUBSUMM, a supervised summarization framework for large-scale\nmulti-perspective opinion summarization. SUBSUMM consists of a review sampling\nstrategy set and a two-stage training scheme. The sampling strategies take\nsentiment orientation and contrastive information value into consideration,\nwith which the review subsets from different perspectives and quality levels\ncan be selected. Subsequently, the summarizer is encouraged to learn from the\nsub-optimal and optimal subsets successively in order to capitalize on the\nmassive input. Experimental results on AmaSum and Rotten Tomatoes datasets\ndemonstrate that SUBSUMM is adept at generating pros, cons, and verdict\nsummaries from hundreds of input reviews. Furthermore, our in-depth analysis\nverifies that the advanced selection of review subsets and the two-stage\ntraining scheme are vital to boosting the summarization performance.",
            "author": [
                "Han Jiang",
                "Rui Wang",
                "Zhihua Wei",
                "Yu Li",
                "Xinpeng Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13340v1",
                "http://arxiv.org/pdf/2310.13340v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13726v1",
            "title": "Boundary conditions, phase distribution and hidden symmetry in 1D\n  localization",
            "updated": "2023-10-20T08:06:51Z",
            "published": "2023-10-20T08:06:51Z",
            "summary": "One-dimensional disordered systems with a random potential of a small\namplitude and short-range correlations are considered near the initial band\nedge. The evolution equation is obtained for the mutual ditribution\nP(\\rho,\\psi) of the Landauer resistance \\rho and the phase variable\n\\psi=\\theta-\\varphi (\\theta and \\varphi are phases entering the transfer\nmatrix), when the system length L is increased. In the large L limit, the\nequation allows separation of variables, which provides the existence of the\nstationary distribution P(\\psi), determinative the coefficients in the\nevolution equation for P(\\rho). The limiting distribution P(\\rho) for\nL\\to\\infty is log-normal and does not depend on boundary conditions. It is\ndetermined by the 'internal' phase distribution, whose form is established in\nthe whole energy range including the forbidden band of the initial crystal. The\nrandom phase approximation is valid in the deep of the allowed band, but\nstrongly violated for other energies. The phase \\psi appears to be a 'bad'\nvariable, while the 'correct' vaiable is \\omega=-ctg (psi/2). The form of the\nstationary distribution P(\\omega) is determined by the internal properties of\nthe system and is independent of boundary conditions. Variation of the boundary\nconditions leads to the scale transformation \\omega\\to s\\omega and translations\n\\omega \\to \\omega+\\omega_0 and \\psi\\to\\psi+\\psi_0, which determinates the\n'external' phase distribution, entering the evolution equations. Independence\nof the limiting distribution P(\\rho) on the external distribution P(\\psi)\nallows to say on the hidden symmetry, whose character is revealed below.",
            "author": [
                "I. M. Suslov"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13726v1",
                "http://arxiv.org/pdf/2310.13726v1"
            ],
            "primary_category": "cond-mat.dis-nn",
            "category": [
                "cond-mat.dis-nn",
                "cond-mat.mes-hall",
                "cond-mat.stat-mech"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13332v1",
            "title": "Democratizing Reasoning Ability: Tailored Learning from Large Language\n  Model",
            "updated": "2023-10-20T07:50:10Z",
            "published": "2023-10-20T07:50:10Z",
            "summary": "Large language models (LLMs) exhibit impressive emergent abilities in natural\nlanguage processing, but their democratization is hindered due to huge\ncomputation requirements and closed-source nature. Recent research on advancing\nopen-source smaller LMs by distilling knowledge from black-box LLMs has\nobtained promising results in the instruction-following ability. However, the\nreasoning ability which is more challenging to foster, is relatively rarely\nexplored. In this paper, we propose a tailored learning approach to distill\nsuch reasoning ability to smaller LMs to facilitate the democratization of the\nexclusive reasoning ability. In contrast to merely employing LLM as a data\nannotator, we exploit the potential of LLM as a reasoning teacher by building\nan interactive multi-round learning paradigm. This paradigm enables the student\nto expose its deficiencies to the black-box teacher who then can provide\ncustomized training data in return. Further, to exploit the reasoning potential\nof the smaller LM, we propose self-reflection learning to motivate the student\nto learn from self-made mistakes. The learning from self-reflection and LLM are\nall tailored to the student's learning status, thanks to the seamless\nintegration with the multi-round learning paradigm. Comprehensive experiments\nand analysis on mathematical and commonsense reasoning tasks demonstrate the\neffectiveness of our method. The code will be available at\nhttps://github.com/Raibows/Learn-to-Reason.",
            "author": [
                "Zhaoyang Wang",
                "Shaohan Huang",
                "Yuxuan Liu",
                "Jiahai Wang",
                "Minghui Song",
                "Zihan Zhang",
                "Haizhen Huang",
                "Furu Wei",
                "Weiwei Deng",
                "Feng Sun",
                "Qi Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13332v1",
                "http://arxiv.org/pdf/2310.13332v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14890v1",
            "title": "Boosting for Bounding the Worst-class Error",
            "updated": "2023-10-20T07:49:10Z",
            "published": "2023-10-20T07:49:10Z",
            "summary": "This paper tackles the problem of the worst-class error rate, instead of the\nstandard error rate averaged over all classes. For example, a three-class\nclassification task with class-wise error rates of 10\\%, 10\\%, and 40\\% has a\nworst-class error rate of 40\\%, whereas the average is 20\\% under the\nclass-balanced condition. The worst-class error is important in many\napplications. For example, in a medical image classification task, it would not\nbe acceptable for the malignant tumor class to have a 40\\% error rate, while\nthe benign and healthy classes have 10\\% error rates.We propose a boosting\nalgorithm that guarantees an upper bound of the worst-class training error and\nderive its generalization bound. Experimental results show that the algorithm\nlowers worst-class test error rates while avoiding overfitting to the training\nset.",
            "author": [
                "Yuya Saito",
                "Shinnosuke Matsuo",
                "Seiichi Uchida",
                "Daiki Suehiro"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14890v1",
                "http://arxiv.org/pdf/2310.14890v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13326v1",
            "title": "A Critical Insight into Pretransitional Behavior and Dielectric\n  Tunability of Relaxor Ceramics",
            "updated": "2023-10-20T07:43:05Z",
            "published": "2023-10-20T07:43:05Z",
            "summary": "The model discussion focused on links between the unique properties of\nrelaxor ceramics and the basics of critical phenomena physics and glass\ntransition physics. It indicates the significance of uniaxiality for appearing\nmean-field features near paraelectric_ferroelectric transition. Pretransitional\nfluctuations, increasing up to grain size and leading to inter-grain, random,\nlocal electric fields, are indicated to be responsible for relaxor ceramics\ncharacteristics. Their impacts yield the pseudo spinodal behavior associated\nwith weakly discontinuous local phase transitions. The emerging model redefines\nthe meaning of the Burns temperature and polar nanoregions PNRs. It explains\ncoherently dielectric constant changes with the diffused maximum near\nparaelectric_ferroelectric transition, the sensitivity even to moderate\nelectric fields, tunability, and the glassy dynamics. These considerations are\nconfronted with experimental results for the complex dielectric permittivity\nstudies in relaxor ceramic, covering the 200K range, from the paraelectric to\nthe deep ferroelectric phase. The distortions-sensitive and derivative-based\nanalysis revealed the preference for the exponential scaling pattern in the\nparaelectric phase and the surroundings of the paraelectric-ferroelectric\ntransition. It may suggest the Griffith phase behavior associated with the\nmean-field criticality disturbed by random local impacts. The discussion of\nexperimental results is supplemented by relaxation times changes and the\ncoupled energy losses analysis. The studies also led to the description of\ntunability temperature changes with scaling relations.",
            "author": [
                "Sylwester J. Rzoska",
                "Aleksandra Drozd-Rzoska",
                "Weronika Bulejak",
                "Joanna Los",
                "Szymon Starzonek",
                "Mikolaj Szafran",
                "Feng Gao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13326v1",
                "http://arxiv.org/pdf/2310.13326v1"
            ],
            "primary_category": "physics.app-ph",
            "category": [
                "physics.app-ph",
                "cond-mat.mtrl-sci",
                "physics.chem-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13321v2",
            "title": "Beyond Hard Samples: Robust and Effective Grammatical Error Correction\n  with Cycle Self-Augmenting",
            "updated": "2023-10-23T07:41:09Z",
            "published": "2023-10-20T07:31:23Z",
            "summary": "Recent studies have revealed that grammatical error correction methods in the\nsequence-to-sequence paradigm are vulnerable to adversarial attack, and simply\nutilizing adversarial examples in the pre-training or post-training process can\nsignificantly enhance the robustness of GEC models to certain types of attack\nwithout suffering too much performance loss on clean data. In this paper, we\nfurther conduct a thorough robustness evaluation of cutting-edge GEC methods\nfor four different types of adversarial attacks and propose a simple yet very\neffective Cycle Self-Augmenting (CSA) method accordingly. By leveraging the\naugmenting data from the GEC models themselves in the post-training process and\nintroducing regularization data for cycle training, our proposed method can\neffectively improve the model robustness of well-trained GEC models with only a\nfew more training epochs as an extra cost. More concretely, further training on\nthe regularization data can prevent the GEC models from over-fitting on\neasy-to-learn samples and thus can improve the generalization capability and\nrobustness towards unseen data (adversarial noise/samples). Meanwhile, the\nself-augmented data can provide more high-quality pseudo pairs to improve model\nperformance on the original testing data. Experiments on four benchmark\ndatasets and seven strong models indicate that our proposed training method can\nsignificantly enhance the robustness of four types of attacks without using\npurposely built adversarial examples in training. Evaluation results on clean\ndata further confirm that our proposed CSA method significantly improves the\nperformance of four baselines and yields nearly comparable results with other\nstate-of-the-art models. Our code is available at\nhttps://github.com/ZetangForward/CSA-GEC.",
            "author": [
                "Zecheng Tang",
                "Kaifeng Qi",
                "Juntao Li",
                "Min Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13321v2",
                "http://arxiv.org/pdf/2310.13321v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13318v1",
            "title": "The neural signature of inner peace: morphometric differences between\n  high and low accepters",
            "updated": "2023-10-20T07:23:25Z",
            "published": "2023-10-20T07:23:25Z",
            "summary": "Acceptance is an adaptive emotion regulation strategy characterized by an\nopen and non-judgmental attitude toward mental and sensory experiences. While a\nfew studies have investigated the neural correlates of acceptance in task-based\nfMRI studies, a gap remains in the scientific literature in dispositional use\nof acceptance, and how this is sedimented at a structural level. Therefore, the\naim of the present study is to investigate the neural and psychological\ndifferences between infrequent acceptance users (i.e., low accepters) and\nfrequent users (i.e., high accepters). Another question is whether high and low\naccepters differ in personality traits and emotional intelligence. To this aim,\nwe applied, for the first time, a data fusion unsupervised machine learning\napproach (mCCA-jICA) to the gray matter (GM) and white matter (WM) of high\naccepters (N = 50), and low accepters (N = 78) to possibly find joint GM-WM\ndifferences in both modalities. Our results show that two covarying GM-WM\nnetworks separate high from low accepters. The first network showed decreased\nGM-WM concentration in a fronto-temporal-parietal circuit largely overlapping\nwith the Default Mode Network, while the second network showed increased GM-WM\nconcentration in portions of the orbito-frontal, temporal, and parietal areas,\nrelated to a Central Executive Network. At the psychological level, the high\naccepters display higher openness to experience compared to low accepters.\nOverall, our findings suggest that high accepters compared to low accepters\ndiffer in neural and psychological mechanisms. These findings confirm and\nextend previous studies on the relevance of acceptance as a strategy associated\nwith well-being.",
            "author": [
                "Alessandro Grecucci",
                "Parisa Ahmadi Ghomroudi",
                "Bianca Monachesi",
                "Irene Messina"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13318v1",
                "http://arxiv.org/pdf/2310.13318v1"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13316v1",
            "title": "Coarse-to-Fine Dual Encoders are Better Frame Identification Learners",
            "updated": "2023-10-20T07:11:23Z",
            "published": "2023-10-20T07:11:23Z",
            "summary": "Frame identification aims to find semantic frames associated with target\nwords in a sentence. Recent researches measure the similarity or matching score\nbetween targets and candidate frames by modeling frame definitions. However,\nthey either lack sufficient representation learning of the definitions or face\nchallenges in efficiently selecting the most suitable frame from over 1000\ncandidate frames. Moreover, commonly used lexicon filtering ($lf$) to obtain\ncandidate frames for the target may ignore out-of-vocabulary targets and cause\ninadequate frame modeling. In this paper, we propose CoFFTEA, a\n$\\underline{Co}$arse-to-$\\underline{F}$ine $\\underline{F}$rame and\n$\\underline{T}$arget $\\underline{E}$ncoders $\\underline{A}$rchitecture. With\ncontrastive learning and dual encoders, CoFFTEA efficiently and effectively\nmodels the alignment between frames and targets. By employing a coarse-to-fine\ncurriculum learning procedure, CoFFTEA gradually learns to differentiate frames\nwith varying degrees of similarity. Experimental results demonstrate that\nCoFFTEA outperforms previous models by 0.93 overall scores and 1.53 R@1 without\n$lf$. Further analysis suggests that CoFFTEA can better model the relationships\nbetween frame and frame, as well as target and target. The code for our\napproach is available at https://github.com/pkunlp-icler/COFFTEA.",
            "author": [
                "Kaikai An",
                "Ce Zheng",
                "Bofei Gao",
                "Haozhe Zhao",
                "Baobao Chang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13316v1",
                "http://arxiv.org/pdf/2310.13316v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13315v1",
            "title": "Zero-Shot Sharpness-Aware Quantization for Pre-trained Language Models",
            "updated": "2023-10-20T07:09:56Z",
            "published": "2023-10-20T07:09:56Z",
            "summary": "Quantization is a promising approach for reducing memory overhead and\naccelerating inference, especially in large pre-trained language model (PLM)\nscenarios. While having no access to original training data due to security and\nprivacy concerns has emerged the demand for zero-shot quantization. Most of the\ncutting-edge zero-shot quantization methods primarily 1) apply to computer\nvision tasks, and 2) neglect of overfitting problem in the generative\nadversarial learning process, leading to sub-optimal performance. Motivated by\nthis, we propose a novel zero-shot sharpness-aware quantization (ZSAQ)\nframework for the zero-shot quantization of various PLMs. The key algorithm in\nsolving ZSAQ is the SAM-SGA optimization, which aims to improve the\nquantization accuracy and model generalization via optimizing a minimax\nproblem. We theoretically prove the convergence rate for the minimax\noptimization problem and this result can be applied to other nonconvex-PL\nminimax optimization frameworks. Extensive experiments on 11 tasks demonstrate\nthat our method brings consistent and significant performance gains on both\ndiscriminative and generative PLMs, i.e., up to +6.98 average score.\nFurthermore, we empirically validate that our method can effectively improve\nthe model generalization.",
            "author": [
                "Miaoxi Zhu",
                "Qihuang Zhong",
                "Li Shen",
                "Liang Ding",
                "Juhua Liu",
                "Bo Du",
                "Dacheng Tao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13315v1",
                "http://arxiv.org/pdf/2310.13315v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13314v1",
            "title": "Combining Policy Gradient and Safety-Based Control for Autonomous\n  Driving",
            "updated": "2023-10-20T07:06:57Z",
            "published": "2023-10-20T07:06:57Z",
            "summary": "With the advancement of data-driven techniques, addressing continuous\ncon-trol challenges has become more efficient. However, the reliance of these\nmethods on historical data introduces the potential for unexpected decisions in\nnovel scenarios. To enhance performance in autonomous driving and collision\navoidance, we propose a symbiotic fusion of policy gradient with safety-based\ncontrol. In this study, we em-ploy the Deep Deterministic Policy Gradient\n(DDPG) algorithm to enable autono-mous driving in the absence of surrounding\nvehicles. By training the vehicle's driving policy within a stable and familiar\nenvironment, a robust and efficient learning pro-cess is achieved.\nSubsequently, an artificial potential field approach is utilized to formulate a\ncollision avoidance algorithm, accounting for the presence of surround-ing\nvehicles. Furthermore, meticulous consideration is given to path tracking\nmeth-ods. The amalgamation of these approaches demonstrates substantial\nperformance across diverse scenarios, underscoring its potential for advancing\nautonomous driving while upholding safety standards.",
            "author": [
                "Xi Xiong",
                "Lu Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13314v1",
                "http://arxiv.org/pdf/2310.13314v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13311v1",
            "title": "Non-Negative Spherical Relaxations for Universe-Free Multi-Matching and\n  Clustering",
            "updated": "2023-10-20T07:01:29Z",
            "published": "2023-10-20T07:01:29Z",
            "summary": "We propose a novel non-negative spherical relaxation for optimization\nproblems over binary matrices with injectivity constraints, which in particular\nhas applications in multi-matching and clustering. We relax respective binary\nmatrix constraints to the (high-dimensional) non-negative sphere. To optimize\nour relaxed problem, we use a conditional power iteration method to iteratively\nimprove the objective function, while at same time sweeping over a continuous\nscalar parameter that is (indirectly) related to the universe size (or number\nof clusters). Opposed to existing procedures that require to fix the integer\nuniverse size before optimization, our method automatically adjusts the\nanalogous continuous parameter. Furthermore, while our approach shares\nsimilarities with spectral multi-matching and spectral clustering, our\nformulation has the strong advantage that we do not rely on additional\npost-processing procedures to obtain binary results. Our method shows\ncompelling results in various multi-matching and clustering settings, even when\ncompared to methods that use the ground truth universe size (or number of\nclusters).",
            "author": [
                "Johan Thunberg",
                "Florian Bernard"
            ],
            "link": [
                "http://dx.doi.org/10.1007/978-3-031-31438-4_18",
                "http://arxiv.org/abs/2310.13311v1",
                "http://arxiv.org/pdf/2310.13311v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.CV",
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13310v1",
            "title": "Polarizability Models for Simulations of Finite Temperature Raman\n  Spectra from Machine Learning Molecular Dynamics",
            "updated": "2023-10-20T06:54:47Z",
            "published": "2023-10-20T06:54:47Z",
            "summary": "Raman spectroscopy is a powerful and nondestructive method that is widely\nused to study the vibrational properties of solids or molecules. Simulations of\nfinite-temperature Raman spectra rely on obtaining polarizabilities along\nmolecular dynamics trajectories, which is computationally highly demanding if\ncalculated from first principles. Machine learning force fields (MLFF) are\nbecoming widely used for accelerating molecular dynamics simulations, but\nmachine-learning models for polarizability are still rare. In this work, we\npresent and compare three polarizability models for obtaining Raman spectra in\nconjunction with MLFF molecular dynamics trajectories: (i) model based on\nprojection to primitive cell eigenmodes, (ii) bond polarizability model, and\n(iii) symmetry-adapted Gaussian process regression (SA-GPR) using smooth\noverlap of atomic positions. In particular, we investigate the accuracy of\nthese models for different systems and how much training data is required.\nModels are first applied to boron arsenide, where the first- and second-order\nRaman spectra are studied as well as the effect of boron isotopes. With MoS$_2$\nwe study the applicability of the models for highly anisotropic systems and for\nsimulating resonant Raman spectra. Finally, inorganic halide perovskites\nCsPbBr$_3$ and CsSnBr$_3$ are studied with a particular interest in simulating\nthe spectra across phase transitions and the evolution of the central peak. All\nmodels can be used to efficiently predict polarizabilities and are applicable\nto large systems and long simulation times, and while all three models were\nfound to perform similarly for BAs and MoS$_2$, only SA-GPR offers sufficient\nflexibility to accurately describe complex anharmonic materials like the\nperovskites.",
            "author": [
                "Ethan Berger",
                "Hannu-Pekka Komsa"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13310v1",
                "http://arxiv.org/pdf/2310.13310v1"
            ],
            "primary_category": "cond-mat.mes-hall",
            "category": [
                "cond-mat.mes-hall",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13307v1",
            "title": "Test-Time Self-Adaptive Small Language Models for Question Answering",
            "updated": "2023-10-20T06:49:32Z",
            "published": "2023-10-20T06:49:32Z",
            "summary": "Recent instruction-finetuned large language models (LMs) have achieved\nnotable performances in various tasks, such as question-answering (QA).\nHowever, despite their ability to memorize a vast amount of general knowledge\nacross diverse tasks, they might be suboptimal on specific tasks due to their\nlimited capacity to transfer and adapt knowledge to target tasks. Moreover,\nfurther finetuning LMs with labeled datasets is often infeasible due to their\nabsence, but it is also questionable if we can transfer smaller LMs having\nlimited knowledge only with unlabeled test data. In this work, we show and\ninvestigate the capabilities of smaller self-adaptive LMs, only with unlabeled\ntest data. In particular, we first stochastically generate multiple answers,\nand then ensemble them while filtering out low-quality samples to mitigate\nnoise from inaccurate labels. Our proposed self-adaption strategy demonstrates\nsignificant performance improvements on benchmark QA datasets with higher\nrobustness across diverse prompts, enabling LMs to stay stable. Code is\navailable at: https://github.com/starsuzi/T-SAS.",
            "author": [
                "Soyeong Jeong",
                "Jinheon Baek",
                "Sukmin Cho",
                "Sung Ju Hwang",
                "Jong C. Park"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13307v1",
                "http://arxiv.org/pdf/2310.13307v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13303v1",
            "title": "Motif-Based Prompt Learning for Universal Cross-Domain Recommendation",
            "updated": "2023-10-20T06:34:55Z",
            "published": "2023-10-20T06:34:55Z",
            "summary": "Cross-Domain Recommendation (CDR) stands as a pivotal technology addressing\nissues of data sparsity and cold start by transferring general knowledge from\nthe source to the target domain. However, existing CDR models suffer\nlimitations in adaptability across various scenarios due to their inherent\ncomplexity. To tackle this challenge, recent advancements introduce universal\nCDR models that leverage shared embeddings to capture general knowledge across\ndomains and transfer it through \"Multi-task Learning\" or \"Pre-train, Fine-tune\"\nparadigms. However, these models often overlook the broader structural topology\nthat spans domains and fail to align training objectives, potentially leading\nto negative transfer. To address these issues, we propose a motif-based prompt\nlearning framework, MOP, which introduces motif-based shared embeddings to\nencapsulate generalized domain knowledge, catering to both intra-domain and\ninter-domain CDR tasks. Specifically, we devise three typical motifs:\nbutterfly, triangle, and random walk, and encode them through a Motif-based\nEncoder to obtain motif-based shared embeddings. Moreover, we train MOP under\nthe \"Pre-training \\& Prompt Tuning\" paradigm. By unifying pre-training and\nrecommendation tasks as a common motif-based similarity learning task and\nintegrating adaptable prompt parameters to guide the model in downstream\nrecommendation tasks, MOP excels in transferring domain knowledge effectively.\nExperimental results on four distinct CDR tasks demonstrate the effectiveness\nof MOP than the state-of-the-art models.",
            "author": [
                "Bowen Hao",
                "Chaoqun Yang",
                "Lei Guo",
                "Junliang Yu",
                "Hongzhi Yin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13303v1",
                "http://arxiv.org/pdf/2310.13303v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13297v1",
            "title": "Decoding the Silent Majority: Inducing Belief Augmented Social Graph\n  with Large Language Model for Response Forecasting",
            "updated": "2023-10-20T06:17:02Z",
            "published": "2023-10-20T06:17:02Z",
            "summary": "Automatic response forecasting for news media plays a crucial role in\nenabling content producers to efficiently predict the impact of news releases\nand prevent unexpected negative outcomes such as social conflict and moral\ninjury. To effectively forecast responses, it is essential to develop measures\nthat leverage the social dynamics and contextual information surrounding\nindividuals, especially in cases where explicit profiles or historical actions\nof the users are limited (referred to as lurkers). As shown in a previous\nstudy, 97% of all tweets are produced by only the most active 25% of users.\nHowever, existing approaches have limited exploration of how to best process\nand utilize these important features. To address this gap, we propose a novel\nframework, named SocialSense, that leverages a large language model to induce a\nbelief-centered graph on top of an existent social network, along with\ngraph-based propagation to capture social dynamics. We hypothesize that the\ninduced graph that bridges the gap between distant users who share similar\nbeliefs allows the model to effectively capture the response patterns. Our\nmethod surpasses existing state-of-the-art in experimental evaluations for both\nzero-shot and supervised settings, demonstrating its effectiveness in response\nforecasting. Moreover, the analysis reveals the framework's capability to\neffectively handle unseen user and lurker scenarios, further highlighting its\nrobustness and practical applicability.",
            "author": [
                "Chenkai Sun",
                "Jinning Li",
                "Yi R. Fung",
                "Hou Pong Chan",
                "Tarek Abdelzaher",
                "ChengXiang Zhai",
                "Heng Ji"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13297v1",
                "http://arxiv.org/pdf/2310.13297v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13295v1",
            "title": "PathRL: An End-to-End Path Generation Method for Collision Avoidance via\n  Deep Reinforcement Learning",
            "updated": "2023-10-20T05:55:13Z",
            "published": "2023-10-20T05:55:13Z",
            "summary": "Robot navigation using deep reinforcement learning (DRL) has shown great\npotential in improving the performance of mobile robots. Nevertheless, most\nexisting DRL-based navigation methods primarily focus on training a policy that\ndirectly commands the robot with low-level controls, like linear and angular\nvelocities, which leads to unstable speeds and unsmooth trajectories of the\nrobot during the long-term execution. An alternative method is to train a DRL\npolicy that outputs the navigation path directly. However, two roadblocks arise\nfor training a DRL policy that outputs paths: (1) The action space for\npotential paths often involves higher dimensions comparing to low-level\ncommands, which increases the difficulties of training; (2) It takes multiple\ntime steps to track a path instead of a single time step, which requires the\npath to predicate the interactions of the robot w.r.t. the dynamic environment\nin multiple time steps. This, in turn, amplifies the challenges associated with\ntraining. In response to these challenges, we propose PathRL, a novel DRL\nmethod that trains the policy to generate the navigation path for the robot.\nSpecifically, we employ specific action space discretization techniques and\ntailored state space representation methods to address the associated\nchallenges. In our experiments, PathRL achieves better success rates and\nreduces angular rotation variability compared to other DRL navigation methods,\nfacilitating stable and smooth robot movement. We demonstrate the competitive\nedge of PathRL in both real-world scenarios and multiple challenging simulation\nenvironments.",
            "author": [
                "Wenhao Yu",
                "Jie Peng",
                "Quecheng Qiu",
                "Hanyu Wang",
                "Lu Zhang",
                "Jianmin Ji"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13295v1",
                "http://arxiv.org/pdf/2310.13295v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13294v2",
            "title": "VR PreM+ : An Immersive Pre-learning Branching Visualization System for\n  Museum Tours",
            "updated": "2023-11-01T08:23:25Z",
            "published": "2023-10-20T05:55:01Z",
            "summary": "We present VR PreM+, an innovative VR system designed to enhance web\nexploration beyond traditional computer screens. Unlike static 2D displays, VR\nPreM+ leverages 3D environments to create an immersive pre-learning experience.\nUsing keyword-based information retrieval allows users to manage and connect\nvarious content sources in a dynamic 3D space, improving communication and data\ncomparison. We conducted preliminary and user studies that demonstrated\nefficient information retrieval, increased user engagement, and a greater sense\nof presence. These findings yielded three design guidelines for future VR\ninformation systems: display, interaction, and user-centric design. VR PreM+\nbridges the gap between traditional web browsing and immersive VR, offering an\ninteractive and comprehensive approach to information acquisition. It holds\npromise for research, education, and beyond.",
            "author": [
                "Ze Gao",
                "Xiang Li",
                "Changkun Liu",
                "Xian Wang",
                "Anqi Wang",
                "Liang Yang",
                "Yuyang Wang",
                "Pan Hui",
                "Tristan Braud"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3629606.3629643",
                "http://arxiv.org/abs/2310.13294v2",
                "http://arxiv.org/pdf/2310.13294v2"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.IR",
                "14J60 (Primary) 14F05, 14J26 (Secondary)",
                "F.2.2; I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13292v1",
            "title": "CXR-CLIP: Toward Large Scale Chest X-ray Language-Image Pre-training",
            "updated": "2023-10-20T05:44:55Z",
            "published": "2023-10-20T05:44:55Z",
            "summary": "A large-scale image-text pair dataset has greatly contributed to the\ndevelopment of vision-language pre-training (VLP) models, which enable\nzero-shot or few-shot classification without costly annotation. However, in the\nmedical domain, the scarcity of data remains a significant challenge for\ndeveloping a powerful VLP model. In this paper, we tackle the lack of\nimage-text data in chest X-ray by expanding image-label pair as image-text pair\nvia general prompt and utilizing multiple images and multiple sections in a\nradiologic report. We also design two contrastive losses, named ICL and TCL,\nfor learning study-level characteristics of medical images and reports,\nrespectively. Our model outperforms the state-of-the-art models trained under\nthe same conditions. Also, enlarged dataset improve the discriminative power of\nour pre-trained model for classification, while sacrificing marginal retrieval\nperformance. Code is available at https://github.com/kakaobrain/cxr-clip.",
            "author": [
                "Kihyun You",
                "Jawook Gu",
                "Jiyeon Ham",
                "Beomhee Park",
                "Jiho Kim",
                "Eun Kyoung Hong",
                "Woonhyunk Baek",
                "Byungseok Roh"
            ],
            "link": [
                "http://dx.doi.org/10.1007/978-3-031-43895-0_10",
                "http://arxiv.org/abs/2310.13292v1",
                "http://arxiv.org/pdf/2310.13292v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13291v1",
            "title": "Assessing Privacy Risks in Language Models: A Case Study on\n  Summarization Tasks",
            "updated": "2023-10-20T05:44:39Z",
            "published": "2023-10-20T05:44:39Z",
            "summary": "Large language models have revolutionized the field of NLP by achieving\nstate-of-the-art performance on various tasks. However, there is a concern that\nthese models may disclose information in the training data. In this study, we\nfocus on the summarization task and investigate the membership inference (MI)\nattack: given a sample and black-box access to a model's API, it is possible to\ndetermine if the sample was part of the training data. We exploit text\nsimilarity and the model's resistance to document modifications as potential MI\nsignals and evaluate their effectiveness on widely used datasets. Our results\ndemonstrate that summarization models are at risk of exposing data membership,\neven in cases where the reference summary is not available. Furthermore, we\ndiscuss several safeguards for training summarization models to protect against\nMI attacks and discuss the inherent trade-off between privacy and utility.",
            "author": [
                "Ruixiang Tang",
                "Gord Lueck",
                "Rodolfo Quispe",
                "Huseyin A Inan",
                "Janardhan Kulkarni",
                "Xia Hu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13291v1",
                "http://arxiv.org/pdf/2310.13291v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13286v1",
            "title": "Unified Pretraining for Recommendation via Task Hypergraphs",
            "updated": "2023-10-20T05:33:21Z",
            "published": "2023-10-20T05:33:21Z",
            "summary": "Although pretraining has garnered significant attention and popularity in\nrecent years, its application in graph-based recommender systems is relatively\nlimited. It is challenging to exploit prior knowledge by pretraining in widely\nused ID-dependent datasets. On one hand, user-item interaction history in one\ndataset can hardly be transferred to other datasets through pretraining, where\nIDs are different. On the other hand, pretraining and finetuning on the same\ndataset leads to a high risk of overfitting. In this paper, we propose a novel\nmultitask pretraining framework named Unified Pretraining for Recommendation\nvia Task Hypergraphs. For a unified learning pattern to handle diverse\nrequirements and nuances of various pretext tasks, we design task hypergraphs\nto generalize pretext tasks to hyperedge prediction. A novel transitional\nattention layer is devised to discriminatively learn the relevance between each\npretext task and recommendation. Experimental results on three benchmark\ndatasets verify the superiority of UPRTH. Additional detailed investigations\nare conducted to demonstrate the effectiveness of the proposed framework.",
            "author": [
                "Mingdai Yang",
                "Zhiwei Liu",
                "Liangwei Yang",
                "Xiaolong Liu",
                "Chen Wang",
                "Hao Peng",
                "Philip S. Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13286v1",
                "http://arxiv.org/pdf/2310.13286v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13284v1",
            "title": "Learning Recurrent Models with Temporally Local Rules",
            "updated": "2023-10-20T05:30:30Z",
            "published": "2023-10-20T05:30:30Z",
            "summary": "Fitting generative models to sequential data typically involves two recursive\ncomputations through time, one forward and one backward. The latter could be a\ncomputation of the loss gradient (as in backpropagation through time), or an\ninference algorithm (as in the RTS/Kalman smoother). The backward pass in\nparticular is computationally expensive (since it is inherently serial and\ncannot exploit GPUs), and difficult to map onto biological processes.\nWork-arounds have been proposed; here we explore a very different one:\nrequiring the generative model to learn the joint distribution over current and\nprevious states, rather than merely the transition probabilities. We show on\ntoy datasets that different architectures employing this principle can learn\naspects of the data typically requiring the backward pass.",
            "author": [
                "Azwar Abdulsalam",
                "Joseph G. Makin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13284v1",
                "http://arxiv.org/pdf/2310.13284v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13283v1",
            "title": "FedLoRA: Model-Heterogeneous Personalized Federated Learning with LoRA\n  Tuning",
            "updated": "2023-10-20T05:24:28Z",
            "published": "2023-10-20T05:24:28Z",
            "summary": "Federated learning (FL) is an emerging machine learning paradigm in which a\ncentral server coordinates multiple participants (a.k.a. FL clients) to train a\nmodel collaboratively on decentralized data with privacy protection. This\nparadigm constrains that all clients have to train models with the same\nstructures (homogeneous). In practice, FL often faces statistical\nheterogeneity, system heterogeneity and model heterogeneity challenges. These\nchallenging issues inspire the field of Model-Heterogeneous Personalized\nFederated Learning (MHPFL) which aims to train a personalized and heterogeneous\nlocal model for each FL client. Existing MHPFL approaches cannot achieve\nsatisfactory model performance, acceptable computational overhead and efficient\ncommunication simultaneously. To bridge this gap, we propose a novel\ncomputation- and communication-efficient model-heterogeneous personalized\nFederated learning framework based on LoRA tuning (FedLoRA). It is designed to\nincorporate a homogeneous small adapter for each client's heterogeneous local\nmodel. Both models are trained following the proposed iterative training for\nglobal-local knowledge exchange. The homogeneous small local adapters are sent\nto the FL server to be aggregated into a global adapter. In this way, FL\nclients can train heterogeneous local models without incurring high computation\nand communication costs. We theoretically prove the non-convex convergence rate\nof FedLoRA. Extensive experiments on two real-world datasets demonstrate that\nFedLoRA outperforms six state-of-the-art baselines, beating the best approach\nby 1.35% in terms of test accuracy, 11.81 times computation overhead reduction\nand 7.41 times communication cost saving.",
            "author": [
                "Liping Yi",
                "Han Yu",
                "Gang Wang",
                "Xiaoguang Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13283v1",
                "http://arxiv.org/pdf/2310.13283v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14944v1",
            "title": "An Event based Prediction Suffix Tree",
            "updated": "2023-10-20T05:07:45Z",
            "published": "2023-10-20T05:07:45Z",
            "summary": "This article introduces the Event based Prediction Suffix Tree (EPST), a\nbiologically inspired, event-based prediction algorithm. The EPST learns a\nmodel online based on the statistics of an event based input and can make\npredictions over multiple overlapping patterns. The EPST uses a representation\nspecific to event based data, defined as a portion of the power set of event\nsubsequences within a short context window. It is explainable, and possesses\nmany promising properties such as fault tolerance, resistance to event noise,\nas well as the capability for one-shot learning. The computational features of\nthe EPST are examined in a synthetic data prediction task with additive event\nnoise, event jitter, and dropout. The resulting algorithm outputs predicted\nprojections for the near term future of the signal, which may be applied to\ntasks such as event based anomaly detection or pattern recognition.",
            "author": [
                "Evie Andrew",
                "Travis Monk",
                "Andr\u00e9 van Schaik"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14944v1",
                "http://arxiv.org/pdf/2310.14944v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NE",
                "I.2.6; I.5.1"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13279v1",
            "title": "Pathologist-Like Explanations Unveiled: an Explainable Deep Learning\n  System for White Blood Cell Classification",
            "updated": "2023-10-20T04:59:20Z",
            "published": "2023-10-20T04:59:20Z",
            "summary": "White blood cells (WBCs) play a crucial role in safeguarding the human body\nagainst pathogens and foreign substances. Leveraging the abundance of WBC\nimaging data and the power of deep learning algorithms, automated WBC analysis\nhas the potential for remarkable accuracy. However, the capability of deep\nlearning models to explain their WBC classification remains largely unexplored.\nIn this study, we introduce HemaX, an explainable deep neural network-based\nmodel that produces pathologist-like explanations using five attributes:\ngranularity, cytoplasm color, nucleus shape, size relative to red blood cells,\nand nucleus to cytoplasm ratio (N:C), along with cell classification,\nlocalization, and segmentation. HemaX is trained and evaluated on a novel\ndataset, LeukoX, comprising 467 blood smear images encompassing ten (10) WBC\ntypes. The proposed model achieves impressive results, with an average\nclassification accuracy of 81.08% and a Jaccard index of 89.16% for cell\nlocalization. Additionally, HemaX performs well in generating the five\nexplanations with a normalized mean square error of 0.0317 for N:C ratio and\nover 80% accuracy for the other four attributes. Comprehensive experiments\ncomparing against multiple state-of-the-art models demonstrate that HemaX's\nclassification accuracy remains unaffected by its ability to provide\nexplanations. Moreover, empirical analyses and validation by expert\nhematologists confirm the faithfulness of explanations predicted by our\nproposed model.",
            "author": [
                "Aditya Shankar Pal",
                "Debojyoti Biswas",
                "Joy Mahapatra",
                "Debasis Banerjee",
                "Prantar Chakrabarti",
                "Utpal Garain"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13279v1",
                "http://arxiv.org/pdf/2310.13279v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13276v2",
            "title": "InvGC: Robust Cross-Modal Retrieval by Inverse Graph Convolution",
            "updated": "2023-10-25T00:46:42Z",
            "published": "2023-10-20T04:45:44Z",
            "summary": "Over recent decades, significant advancements in cross-modal retrieval are\nmainly driven by breakthroughs in visual and linguistic modeling. However, a\nrecent study shows that multi-modal data representations tend to cluster within\na limited convex cone (as representation degeneration problem), which hinders\nretrieval performance due to the inseparability of these representations. In\nour study, we first empirically validate the presence of the representation\ndegeneration problem across multiple cross-modal benchmarks and methods. Next,\nto address it, we introduce a novel method, called InvGC, a post-processing\ntechnique inspired by graph convolution and average pooling. Specifically,\nInvGC defines the graph topology within the datasets and then applies graph\nconvolution in a subtractive manner. This method effectively separates\nrepresentations by increasing the distances between data points. To improve the\nefficiency and effectiveness of InvGC, we propose an advanced graph topology,\nLocalAdj, which only aims to increase the distances between each data point and\nits nearest neighbors. To understand why InvGC works, we present a detailed\ntheoretical analysis, proving that the lower bound of recall will be improved\nafter deploying InvGC. Extensive empirical results show that InvGC and InvGC\nw/LocalAdj significantly mitigate the representation degeneration problem,\nthereby enhancing retrieval performance.\n  Our code is available at\nhttps://github.com/yimuwangcs/Better_Cross_Modal_Retrieval",
            "author": [
                "Xiangru Jian",
                "Yimu Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13276v2",
                "http://arxiv.org/pdf/2310.13276v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL",
                "cs.LG",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13275v1",
            "title": "Efficient Active Deep Decoding of Linear Codes using Importance Sampling",
            "updated": "2023-10-20T04:45:37Z",
            "published": "2023-10-20T04:45:37Z",
            "summary": "The quality and quantity of data used for training greatly influence the\nperformance and effectiveness of deep learning models. In the context of error\ncorrection, it is essential to generate high-quality samples that are neither\nexcessively noisy nor entirely correct but close to the decoding region's\ndecision boundary. To accomplish this objective, this paper utilizes a\nrestricted version of a recent result on Importance Sampling (IS) distribution\nfor fast performance evaluation of linear codes. The IS distribution is used\nover the segmented observation space and integrated with active learning. This\ncombination allows for the iterative generation of samples from the shells\nwhose acquisition functions, defined as the error probabilities conditioned on\neach shell, fall within a specific range. By intelligently sampling based on\nthe proposed IS distribution, significant improvements are demonstrated in the\nperformance of BCH(63,36) and BCH(63,45) codes with cycle-reduced parity-check\nmatrices. The proposed IS-based-active Weight Belief Propagation (WBP) decoder\nshows improvements of up to 0.4dB in the waterfall region and up to 1.9dB in\nthe error-floor region of the BER curve, over the conventional WBP. This\napproach can be easily adapted to generate efficient samples to train any other\ndeep learning-based decoder.",
            "author": [
                "Hassan Noghrei",
                "Mohammad-Reza Sadeghi",
                "Wai Ho Mow"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13275v1",
                "http://arxiv.org/pdf/2310.13275v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13274v1",
            "title": "Investigation of black hole complementarity in AdS$_2$ black holes",
            "updated": "2023-10-20T04:44:42Z",
            "published": "2023-10-20T04:44:42Z",
            "summary": "Black hole complementarity plays a pivotal role in resolving the information\nloss paradox by treating Hawking radiation as carriers of information, apart\nfrom the complicated mechanisms involved in decoding information from this\nradiation. The thought experiment proposed by Susskind and Thorlacius, as well\nas the criteria set forth by Hayden and Preskill, provide deep insights into\nthe intricate relationship of black hole complementarity between fiducial and\ninfalling observers. We execute the Alice-Bob thought experiment in the context\nof two-dimensional anti-de Sitter black holes. It turns out that information\ncloning can be avoided in the case of a large black hole. According to the\nHayden-Preskill criteria, the scale parameter associated with the explicit\nbreaking of the one-dimensional group of reparametrizations must significantly\nexceed the squared mass of the black hole to effectively prevent information\ncloning.",
            "author": [
                "Wontae Kim",
                "Mungon Nam"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13274v1",
                "http://arxiv.org/pdf/2310.13274v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th",
                "gr-qc"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13270v1",
            "title": "Meta-learning of Physics-informed Neural Networks for Efficiently\n  Solving Newly Given PDEs",
            "updated": "2023-10-20T04:35:59Z",
            "published": "2023-10-20T04:35:59Z",
            "summary": "We propose a neural network-based meta-learning method to efficiently solve\npartial differential equation (PDE) problems. The proposed method is designed\nto meta-learn how to solve a wide variety of PDE problems, and uses the\nknowledge for solving newly given PDE problems. We encode a PDE problem into a\nproblem representation using neural networks, where governing equations are\nrepresented by coefficients of a polynomial function of partial derivatives,\nand boundary conditions are represented by a set of point-condition pairs. We\nuse the problem representation as an input of a neural network for predicting\nsolutions, which enables us to efficiently predict problem-specific solutions\nby the forwarding process of the neural network without updating model\nparameters. To train our model, we minimize the expected error when adapted to\na PDE problem based on the physics-informed neural network framework, by which\nwe can evaluate the error even when solutions are unknown. We demonstrate that\nour proposed method outperforms existing methods in predicting solutions of PDE\nproblems.",
            "author": [
                "Tomoharu Iwata",
                "Yusuke Tanaka",
                "Naonori Ueda"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13270v1",
                "http://arxiv.org/pdf/2310.13270v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13269v1",
            "title": "An Exploratory Study on Simulated Annealing for Feature Selection in\n  Learning-to-Rank",
            "updated": "2023-10-20T04:30:44Z",
            "published": "2023-10-20T04:30:44Z",
            "summary": "Learning-to-rank is an applied domain of supervised machine learning. As\nfeature selection has been found to be effective for improving the accuracy of\nlearning models in general, it is intriguing to investigate this process for\nlearning-to-rank domain. In this study, we investigate the use of a popular\nmeta-heuristic approach called simulated annealing for this task. Under the\ngeneral framework of simulated annealing, we explore various neighborhood\nselection strategies and temperature cooling schemes. We further introduce a\nnew hyper-parameter called the progress parameter that can effectively be used\nto traverse the search space. Our algorithms are evaluated on five publicly\nbenchmark datasets of learning-to-rank. For a better validation, we also\ncompare the simulated annealing-based feature selection algorithm with another\neffective meta-heuristic algorithm, namely local beam search. Extensive\nexperimental results shows the efficacy of our proposed models.",
            "author": [
                "Mohd. Sayemul Haque",
                "Md. Fahim",
                "Muhammad Ibrahim"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13269v1",
                "http://arxiv.org/pdf/2310.13269v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13268v3",
            "title": "DPM-Solver-v3: Improved Diffusion ODE Solver with Empirical Model\n  Statistics",
            "updated": "2023-10-28T07:03:14Z",
            "published": "2023-10-20T04:23:12Z",
            "summary": "Diffusion probabilistic models (DPMs) have exhibited excellent performance\nfor high-fidelity image generation while suffering from inefficient sampling.\nRecent works accelerate the sampling procedure by proposing fast ODE solvers\nthat leverage the specific ODE form of DPMs. However, they highly rely on\nspecific parameterization during inference (such as noise/data prediction),\nwhich might not be the optimal choice. In this work, we propose a novel\nformulation towards the optimal parameterization during sampling that minimizes\nthe first-order discretization error of the ODE solution. Based on such\nformulation, we propose DPM-Solver-v3, a new fast ODE solver for DPMs by\nintroducing several coefficients efficiently computed on the pretrained model,\nwhich we call empirical model statistics. We further incorporate multistep\nmethods and a predictor-corrector framework, and propose some techniques for\nimproving sample quality at small numbers of function evaluations (NFE) or\nlarge guidance scales. Experiments show that DPM-Solver-v3 achieves\nconsistently better or comparable performance in both unconditional and\nconditional sampling with both pixel-space and latent-space DPMs, especially in\n5$\\sim$10 NFEs. We achieve FIDs of 12.21 (5 NFE), 2.51 (10 NFE) on\nunconditional CIFAR10, and MSE of 0.55 (5 NFE, 7.5 guidance scale) on Stable\nDiffusion, bringing a speed-up of 15%$\\sim$30% compared to previous\nstate-of-the-art training-free methods. Code is available at\nhttps://github.com/thu-ml/DPM-Solver-v3.",
            "author": [
                "Kaiwen Zheng",
                "Cheng Lu",
                "Jianfei Chen",
                "Jun Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13268v3",
                "http://arxiv.org/pdf/2310.13268v3"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13267v1",
            "title": "On the Language Encoder of Contrastive Cross-modal Models",
            "updated": "2023-10-20T04:21:09Z",
            "published": "2023-10-20T04:21:09Z",
            "summary": "Contrastive cross-modal models such as CLIP and CLAP aid various\nvision-language (VL) and audio-language (AL) tasks. However, there has been\nlimited investigation of and improvement in their language encoder, which is\nthe central component of encoding natural language descriptions of image/audio\ninto vector representations. We extensively evaluate how unsupervised and\nsupervised sentence embedding training affect language encoder quality and\ncross-modal task performance. In VL pretraining, we found that sentence\nembedding training language encoder quality and aids in cross-modal tasks,\nimproving contrastive VL models such as CyCLIP. In contrast, AL pretraining\nbenefits less from sentence embedding training, which may result from the\nlimited amount of pretraining data. We analyze the representation spaces to\nunderstand the strengths of sentence embedding training, and find that it\nimproves text-space uniformity, at the cost of decreased cross-modal alignment.",
            "author": [
                "Mengjie Zhao",
                "Junya Ono",
                "Zhi Zhong",
                "Chieh-Hsin Lai",
                "Yuhta Takida",
                "Naoki Murata",
                "Wei-Hsiang Liao",
                "Takashi Shibuya",
                "Hiromi Wakaki",
                "Yuki Mitsufuji"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13267v1",
                "http://arxiv.org/pdf/2310.13267v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CV",
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13725v2",
            "title": "Enhancing drug and cell line representations via contrastive learning\n  for improved anti-cancer drug prioritization",
            "updated": "2023-10-27T16:30:51Z",
            "published": "2023-10-20T04:18:47Z",
            "summary": "Due to cancer's complex nature and variable response to therapy, precision\noncology informed by omics sequence analysis has become the current standard of\ncare. However, the amount of data produced for each patients makes it difficult\nto quickly identify the best treatment regimen. Moreover, limited data\navailability has hindered computational methods' abilities to learn patterns\nassociated with effective drug-cell line pairs. In this work, we propose the\nuse of contrastive learning to improve learned drug and cell line\nrepresentations by preserving relationship structures associated with drug\nmechanism of action and cell line cancer types. In addition to achieving\nenhanced performance relative to a state-of-the-art method, we find that\nclassifiers using our learned representations exhibit a more balances reliance\non drug- and cell line-derived features when making predictions. This\nfacilitates more personalized drug prioritizations that are informed by signals\nrelated to drug resistance.",
            "author": [
                "Patrick J. Lawrence",
                "Xia Ning"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13725v2",
                "http://arxiv.org/pdf/2310.13725v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13261v1",
            "title": "DIG-MILP: a Deep Instance Generator for Mixed-Integer Linear Programming\n  with Feasibility Guarantee",
            "updated": "2023-10-20T03:45:29Z",
            "published": "2023-10-20T03:45:29Z",
            "summary": "Mixed-integer linear programming (MILP) stands as a notable NP-hard problem\npivotal to numerous crucial industrial applications. The development of\neffective algorithms, the tuning of solvers, and the training of machine\nlearning models for MILP resolution all hinge on access to extensive, diverse,\nand representative data. Yet compared to the abundant naturally occurring data\nin image and text realms, MILP is markedly data deficient, underscoring the\nvital role of synthetic MILP generation. We present DIG-MILP, a deep generative\nframework based on variational auto-encoder (VAE), adept at extracting\ndeep-level structural features from highly limited MILP data and producing\ninstances that closely mirror the target data. Notably, by leveraging the MILP\nduality, DIG-MILP guarantees a correct and complete generation space as well as\nensures the boundedness and feasibility of the generated instances. Our\nempirical study highlights the novelty and quality of the instances generated\nby DIG-MILP through two distinct downstream tasks: (S1) Data sharing, where\nsolver solution times correlate highly positive between original and\nDIG-MILP-generated instances, allowing data sharing for solver tuning without\npublishing the original data; (S2) Data Augmentation, wherein the\nDIG-MILP-generated instances bolster the generalization performance of machine\nlearning models tasked with resolving MILP problems.",
            "author": [
                "Haoyu Wang",
                "Jialin Liu",
                "Xiaohan Chen",
                "Xinshang Wang",
                "Pan Li",
                "Wotao Yin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13261v1",
                "http://arxiv.org/pdf/2310.13261v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13260v1",
            "title": "A Data-Centric Multi-Objective Learning Framework for Responsible\n  Recommendation Systems",
            "updated": "2023-10-20T03:39:54Z",
            "published": "2023-10-20T03:39:54Z",
            "summary": "Recommendation systems effectively guide users in locating their desired\ninformation within extensive content repositories. Generally, a recommendation\nmodel is optimized to enhance accuracy metrics from a user utility standpoint,\nsuch as click-through rate or matching relevance. However, a responsible\nindustrial recommendation system must address not only user utility\n(responsibility to users) but also other objectives, including increasing\nplatform revenue (responsibility to platforms), ensuring fairness\n(responsibility to content creators), and maintaining unbiasedness\n(responsibility to long-term healthy development). Multi-objective learning is\na potent approach for achieving responsible recommendation systems.\nNevertheless, current methods encounter two challenges: difficulty in scaling\nto heterogeneous objectives within a unified framework, and inadequate\ncontrollability over objective priority during optimization, leading to\nuncontrollable solutions.\n  In this paper, we present a data-centric optimization framework, MoRec, which\nunifies the learning of diverse objectives. MoRec is a tri-level framework: the\nouter level manages the balance between different objectives, utilizing a\nproportional-integral-derivative (PID)-based controller to ensure a preset\nregularization on the primary objective. The middle level transforms\nobjective-aware optimization into data sampling weights using sign gradients.\nThe inner level employs a standard optimizer to update model parameters with\nthe sampled data. Consequently, MoRec can flexibly support various objectives\nwhile maintaining the original model intact. Comprehensive experiments on two\npublic datasets and one industrial dataset showcase the effectiveness,\ncontrollability, flexibility, and Pareto efficiency of MoRec, making it highly\nsuitable for real-world implementation.",
            "author": [
                "Xu Huang",
                "Jianxun Lian",
                "Hao Wang",
                "Defu Lian",
                "Xing Xie"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13260v1",
                "http://arxiv.org/pdf/2310.13260v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13259v1",
            "title": "Domain-specific optimization and diverse evaluation of self-supervised\n  models for histopathology",
            "updated": "2023-10-20T03:38:07Z",
            "published": "2023-10-20T03:38:07Z",
            "summary": "Task-specific deep learning models in histopathology offer promising\nopportunities for improving diagnosis, clinical research, and precision\nmedicine. However, development of such models is often limited by availability\nof high-quality data. Foundation models in histopathology that learn general\nrepresentations across a wide range of tissue types, diagnoses, and\nmagnifications offer the potential to reduce the data, compute, and technical\nexpertise necessary to develop task-specific deep learning models with the\nrequired level of model performance. In this work, we describe the development\nand evaluation of foundation models for histopathology via self-supervised\nlearning (SSL). We first establish a diverse set of benchmark tasks involving\n17 unique tissue types and 12 unique cancer types and spanning different\noptimal magnifications and task types. Next, we use this benchmark to explore\nand evaluate histopathology-specific SSL methods followed by further evaluation\non held out patch-level and weakly supervised tasks. We found that standard SSL\nmethods thoughtfully applied to histopathology images are performant across our\nbenchmark tasks and that domain-specific methodological improvements can\nfurther increase performance. Our findings reinforce the value of using\ndomain-specific SSL methods in pathology, and establish a set of high quality\nfoundation models to enable further research across diverse applications.",
            "author": [
                "Jeremy Lai",
                "Faruk Ahmed",
                "Supriya Vijay",
                "Tiam Jaroensri",
                "Jessica Loo",
                "Saurabh Vyawahare",
                "Saloni Agarwal",
                "Fayaz Jamil",
                "Yossi Matias",
                "Greg S. Corrado",
                "Dale R. Webster",
                "Jonathan Krause",
                "Yun Liu",
                "Po-Hsuan Cameron Chen",
                "Ellery Wulczyn",
                "David F. Steiner"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13259v1",
                "http://arxiv.org/pdf/2310.13259v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13258v2",
            "title": "ManiCast: Collaborative Manipulation with Cost-Aware Human Forecasting",
            "updated": "2023-11-27T17:36:19Z",
            "published": "2023-10-20T03:34:31Z",
            "summary": "Seamless human-robot manipulation in close proximity relies on accurate\nforecasts of human motion. While there has been significant progress in\nlearning forecast models at scale, when applied to manipulation tasks, these\nmodels accrue high errors at critical transition points leading to degradation\nin downstream planning performance. Our key insight is that instead of\npredicting the most likely human motion, it is sufficient to produce forecasts\nthat capture how future human motion would affect the cost of a robot's plan.\nWe present ManiCast, a novel framework that learns cost-aware human forecasts\nand feeds them to a model predictive control planner to execute collaborative\nmanipulation tasks. Our framework enables fluid, real-time interactions between\na human and a 7-DoF robot arm across a number of real-world tasks such as\nreactive stirring, object handovers, and collaborative table setting. We\nevaluate both the motion forecasts and the end-to-end forecaster-planner system\nagainst a range of learned and heuristic baselines while additionally\ncontributing new datasets. We release our code and datasets at\nhttps://portal-cornell.github.io/manicast/.",
            "author": [
                "Kushal Kedia",
                "Prithwish Dan",
                "Atiksh Bhardwaj",
                "Sanjiban Choudhury"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13258v2",
                "http://arxiv.org/pdf/2310.13258v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13257v1",
            "title": "Visual Grounding Helps Learn Word Meanings in Low-Data Regimes",
            "updated": "2023-10-20T03:33:36Z",
            "published": "2023-10-20T03:33:36Z",
            "summary": "Modern neural language models (LMs) are powerful tools for modeling human\nsentence production and comprehension, and their internal representations are\nremarkably well-aligned with representations of language in the human brain.\nBut to achieve these results, LMs must be trained in distinctly un-human-like\nways -- requiring orders of magnitude more language data than children receive\nduring development, and without any of the accompanying grounding in\nperception, action, or social behavior. Do models trained more naturalistically\n-- with grounded supervision -- exhibit more human-like language learning? We\ninvestigate this question in the context of word learning, a key sub-task in\nlanguage acquisition. We train a diverse set of LM architectures, with and\nwithout auxiliary supervision from image captioning tasks, on datasets of\nvarying scales. We then evaluate these models on a broad set of benchmarks\ncharacterizing models' learning of syntactic categories, lexical relations,\nsemantic features, semantic similarity, and alignment with human neural\nrepresentations. We find that visual supervision can indeed improve the\nefficiency of word learning. However, these improvements are limited: they are\npresent almost exclusively in the low-data regime, and sometimes canceled out\nby the inclusion of rich distributional signals from text. The information\nconveyed by text and images is not redundant -- we find that models mainly\ndriven by visual information yield qualitatively different from those mainly\ndriven by word co-occurrences. However, our results suggest that current\nmulti-modal modeling approaches fail to effectively leverage visual information\nto build more human-like word representations from human-sized datasets.",
            "author": [
                "Chengxu Zhuang",
                "Evelina Fedorenko",
                "Jacob Andreas"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13257v1",
                "http://arxiv.org/pdf/2310.13257v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13254v1",
            "title": "Socially Optimal Energy Usage via Adaptive Pricing",
            "updated": "2023-10-20T03:21:58Z",
            "published": "2023-10-20T03:21:58Z",
            "summary": "Using price signals to coordinate the electricity consumption of a group of\nusers has been studied extensively. Typically, a system operator broadcasts a\nprice, and users optimizes their own actions subject to the price and internal\ncost functions. A central challenge is the operator's lack of knowledge of the\nusers, since users may not want to share private information. In addition,\nlearning algorithms are being increasingly used to load control, and users\nmaybe unable to provide their costs in analytical form.\n  In this paper, we develop a two time-scale incentive mechanism that\nalternately updates between the users and a system operator. The system\noperator selects a price, and the users optimize their consumption. Based on\nthe consumption, a new price is then computed by the system operator. As long\nas the users can optimize their own consumption for a given price, the operator\ndoes not need to know or attempt to learn any private information of the users.\nWe show that under a wide range of assumptions, this iterative process\nconverges to the social welfare solution. In particular, the cost of the users\nneed not be strictly convex and its consumption can be the output of a learning\nalgorithm.",
            "author": [
                "Jiayi Li",
                "Matthew Motoki",
                "Baosen Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13254v1",
                "http://arxiv.org/pdf/2310.13254v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13253v1",
            "title": "Knowledge Graph Context-Enhanced Diversified Recommendation",
            "updated": "2023-10-20T03:18:57Z",
            "published": "2023-10-20T03:18:57Z",
            "summary": "The field of Recommender Systems (RecSys) has been extensively studied to\nenhance accuracy by leveraging users' historical interactions. Nonetheless,\nthis persistent pursuit of accuracy frequently engenders diminished diversity,\nculminating in the well-recognized \"echo chamber\" phenomenon. Diversified\nRecSys has emerged as a countermeasure, placing diversity on par with accuracy\nand garnering noteworthy attention from academic circles and industry\npractitioners. This research explores the realm of diversified RecSys within\nthe intricate context of knowledge graphs (KG). These KGs act as repositories\nof interconnected information concerning entities and items, offering a\npropitious avenue to amplify recommendation diversity through the incorporation\nof insightful contextual information. Our contributions include introducing an\ninnovative metric, Entity Coverage, and Relation Coverage, which effectively\nquantifies diversity within the KG domain. Additionally, we introduce the\nDiversified Embedding Learning (DEL) module, meticulously designed to formulate\nuser representations that possess an innate awareness of diversity. In tandem\nwith this, we introduce a novel technique named Conditional Alignment and\nUniformity (CAU). It adeptly encodes KG item embeddings while preserving\ncontextual integrity. Collectively, our contributions signify a substantial\nstride towards augmenting the panorama of recommendation diversity within the\nrealm of KG-informed RecSys paradigms.",
            "author": [
                "Xiaolong Liu",
                "Liangwei Yang",
                "Zhiwei Liu",
                "Mingdai Yang",
                "Chen Wang",
                "Hao Peng",
                "Philip S. Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13253v1",
                "http://arxiv.org/pdf/2310.13253v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13250v1",
            "title": "Diagnosis-oriented Medical Image Compression with Efficient Transfer\n  Learning",
            "updated": "2023-10-20T03:15:13Z",
            "published": "2023-10-20T03:15:13Z",
            "summary": "Remote medical diagnosis has emerged as a critical and indispensable\ntechnique in practical medical systems, where medical data are required to be\nefficiently compressed and transmitted for diagnosis by either professional\ndoctors or intelligent diagnosis devices. In this process, a large amount of\nredundant content irrelevant to the diagnosis is subjected to high-fidelity\ncoding, leading to unnecessary transmission costs. To mitigate this, we propose\ndiagnosis-oriented medical image compression, a special semantic compression\ntask designed for medical scenarios, targeting to reduce the compression cost\nwithout compromising the diagnosis accuracy. However, collecting sufficient\nmedical data to optimize such a compression system is significantly expensive\nand challenging due to privacy issues and the lack of professional annotation.\nIn this study, we propose DMIC, the first efficient transfer learning-based\ncodec, for diagnosis-oriented medical image compression, which can be\neffectively optimized with only few-shot annotated medical examples, by reusing\nthe knowledge in the existing reinforcement learning-based task-driven semantic\ncoding framework, i.e., HRLVSC [1]. Concretely, we focus on tuning only the\npartial parameters of the policy network for bit allocation within HRLVSC,\nwhich enables it to adapt to the medical images. In this work, we validate our\nDMIC with the typical medical task, Coronary Artery Segmentation. Extensive\nexperiments have demonstrated that our DMIC can achieve 47.594%BD-Rate savings\ncompared to the HEVC anchor, by tuning only the A2C module (2.7% parameters) of\nthe policy network with only 1 medical sample.",
            "author": [
                "Guangqi Xie",
                "Xin Li",
                "Xiaohan Pan",
                "Zhibo Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13250v1",
                "http://arxiv.org/pdf/2310.13250v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13248v1",
            "title": "FLEE-GNN: A Federated Learning System for Edge-Enhanced Graph Neural\n  Network in Analyzing Geospatial Resilience of Multicommodity Food Flows",
            "updated": "2023-10-20T03:06:41Z",
            "published": "2023-10-20T03:06:41Z",
            "summary": "Understanding and measuring the resilience of food supply networks is a\nglobal imperative to tackle increasing food insecurity. However, the complexity\nof these networks, with their multidimensional interactions and decisions,\npresents significant challenges. This paper proposes FLEE-GNN, a novel\nFederated Learning System for Edge-Enhanced Graph Neural Network, designed to\novercome these challenges and enhance the analysis of geospatial resilience of\nmulticommodity food flow network, which is one type of spatial networks.\nFLEE-GNN addresses the limitations of current methodologies, such as\nentropy-based methods, in terms of generalizability, scalability, and data\nprivacy. It combines the robustness and adaptability of graph neural networks\nwith the privacy-conscious and decentralized aspects of federated learning on\nfood supply network resilience analysis across geographical regions. This paper\nalso discusses FLEE-GNN's innovative data generation techniques, experimental\ndesigns, and future directions for improvement. The results show the\nadvancements of this approach to quantifying the resilience of multicommodity\nfood flow networks, contributing to efforts towards ensuring global food\nsecurity using AI methods. The developed FLEE-GNN has the potential to be\napplied in other spatial networks with spatially heterogeneous sub-network\ndistributions.",
            "author": [
                "Yuxiao Qu",
                "Jinmeng Rao",
                "Song Gao",
                "Qianheng Zhang",
                "Wei-Lun Chao",
                "Yu Su",
                "Michelle Miller",
                "Alfonso Morales",
                "Patrick Huber"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3615886.3627742",
                "http://arxiv.org/abs/2310.13248v1",
                "http://arxiv.org/pdf/2310.13248v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CY",
                "cs.SI",
                "I.2"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13247v1",
            "title": "Anomaly Detection of Command Shell Sessions based on DistilBERT:\n  Unsupervised and Supervised Approaches",
            "updated": "2023-10-20T03:04:32Z",
            "published": "2023-10-20T03:04:32Z",
            "summary": "Anomaly detection in command shell sessions is a critical aspect of computer\nsecurity. Recent advances in deep learning and natural language processing,\nparticularly transformer-based models, have shown great promise for addressing\ncomplex security challenges. In this paper, we implement a comprehensive\napproach to detect anomalies in Unix shell sessions using a pretrained\nDistilBERT model, leveraging both unsupervised and supervised learning\ntechniques to identify anomalous activity while minimizing data labeling. The\nunsupervised method captures the underlying structure and syntax of Unix shell\ncommands, enabling the detection of session deviations from normal behavior.\nExperiments on a large-scale enterprise dataset collected from production\nsystems demonstrate the effectiveness of our approach in detecting anomalous\nbehavior in Unix shell sessions. This work highlights the potential of\nleveraging recent advances in transformers to address important computer\nsecurity challenges.",
            "author": [
                "Zefang Liu",
                "John Buford"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13247v1",
                "http://arxiv.org/pdf/2310.13247v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13240v1",
            "title": "Transparency challenges in policy evaluation with causal machine\n  learning -- improving usability and accountability",
            "updated": "2023-10-20T02:48:29Z",
            "published": "2023-10-20T02:48:29Z",
            "summary": "Causal machine learning tools are beginning to see use in real-world policy\nevaluation tasks to flexibly estimate treatment effects. One issue with these\nmethods is that the machine learning models used are generally black boxes,\ni.e., there is no globally interpretable way to understand how a model makes\nestimates. This is a clear problem in policy evaluation applications,\nparticularly in government, because it is difficult to understand whether such\nmodels are functioning in ways that are fair, based on the correct\ninterpretation of evidence and transparent enough to allow for accountability\nif things go wrong. However, there has been little discussion of transparency\nproblems in the causal machine learning literature and how these might be\novercome. This paper explores why transparency issues are a problem for causal\nmachine learning in public policy evaluation applications and considers ways\nthese problems might be addressed through explainable AI tools and by\nsimplifying models in line with interpretable AI principles. It then applies\nthese ideas to a case-study using a causal forest model to estimate conditional\naverage treatment effects for a hypothetical change in the school leaving age\nin Australia. It shows that existing tools for understanding black-box\npredictive models are poorly suited to causal machine learning and that\nsimplifying the model to make it interpretable leads to an unacceptable\nincrease in error (in this application). It concludes that new tools are needed\nto properly understand causal machine learning models and the algorithms that\nfit them.",
            "author": [
                "Patrick Rehill",
                "Nicholas Biddle"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13240v1",
                "http://arxiv.org/pdf/2310.13240v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "econ.EM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13236v2",
            "title": "An Efficient Federated Learning Framework for Training Semantic\n  Communication System",
            "updated": "2023-11-09T10:52:14Z",
            "published": "2023-10-20T02:45:20Z",
            "summary": "Semantic communication has emerged as a pillar for the next generation of\ncommunication systems due to its capabilities in alleviating data redundancy.\nMost semantic communication systems are built upon advanced deep learning\nmodels whose training performance heavily relies on data availability. Existing\nstudies often make unrealistic assumptions of a readily accessible data source,\nwhere in practice, data is mainly created on the client side. Due to privacy\nand security concerns, the transmission of data is restricted, which is\nnecessary for conventional centralized training schemes. To address this\nchallenge, we explore semantic communication in a federated learning (FL)\nsetting that utilizes client data without leaking privacy. Additionally, we\ndesign our system to tackle the communication overhead by reducing the quantity\nof information delivered in each global round. In this way, we can save\nsignificant bandwidth for resource-limited devices and reduce overall network\ntraffic. Finally, we introduce a mechanism to aggregate the global model from\nclients, called FedLol. Extensive simulation results demonstrate the\neffectiveness of our proposed technique compared to baseline methods.",
            "author": [
                "Loc X. Nguyen",
                "Huy Q. Le",
                "Ye Lin Tun",
                "Pyae Sone Aung",
                "Yan Kyaw Tun",
                "Zhu Han",
                "Choong Seon Hong"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13236v2",
                "http://arxiv.org/pdf/2310.13236v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13235v1",
            "title": "Auxiliary Features-Guided Super Resolution for Monte Carlo Rendering",
            "updated": "2023-10-20T02:45:13Z",
            "published": "2023-10-20T02:45:13Z",
            "summary": "This paper investigates super resolution to reduce the number of pixels to\nrender and thus speed up Monte Carlo rendering algorithms. While great progress\nhas been made to super resolution technologies, it is essentially an ill-posed\nproblem and cannot recover high-frequency details in renderings. To address\nthis problem, we exploit high-resolution auxiliary features to guide super\nresolution of low-resolution renderings. These high-resolution auxiliary\nfeatures can be quickly rendered by a rendering engine and at the same time\nprovide valuable high-frequency details to assist super resolution. To this\nend, we develop a cross-modality Transformer network that consists of an\nauxiliary feature branch and a low-resolution rendering branch. These two\nbranches are designed to fuse high-resolution auxiliary features with the\ncorresponding low-resolution rendering. Furthermore, we design residual\ndensely-connected Swin Transformer groups to learn to extract representative\nfeatures to enable high-quality super-resolution. Our experiments show that our\nauxiliary features-guided super-resolution method outperforms both\nsuper-resolution methods and Monte Carlo denoising methods in producing\nhigh-quality renderings.",
            "author": [
                "Qiqi Hou",
                "Feng Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13235v1",
                "http://arxiv.org/pdf/2310.13235v1"
            ],
            "primary_category": "cs.GR",
            "category": [
                "cs.GR",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13232v1",
            "title": "Interaction Screening and Pseudolikelihood Approaches for Tensor\n  Learning in Ising Models",
            "updated": "2023-10-20T02:42:32Z",
            "published": "2023-10-20T02:42:32Z",
            "summary": "In this paper, we study two well known methods of Ising structure learning,\nnamely the pseudolikelihood approach and the interaction screening approach, in\nthe context of tensor recovery in $k$-spin Ising models. We show that both\nthese approaches, with proper regularization, retrieve the underlying\nhypernetwork structure using a sample size logarithmic in the number of network\nnodes, and exponential in the maximum interaction strength and maximum\nnode-degree. We also track down the exact dependence of the rate of tensor\nrecovery on the interaction order $k$, that is allowed to grow with the number\nof samples and nodes, for both the approaches. Finally, we provide a\ncomparative discussion of the performance of the two approaches based on\nsimulation studies, which also demonstrate the exponential dependence of the\ntensor recovery rate on the maximum coupling strength.",
            "author": [
                "Tianyu Liu",
                "Somabha Mukherjee"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13232v1",
                "http://arxiv.org/pdf/2310.13232v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "math.ST",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13231v1",
            "title": "Multi-level Contrastive Learning for Script-based Character\n  Understanding",
            "updated": "2023-10-20T02:40:52Z",
            "published": "2023-10-20T02:40:52Z",
            "summary": "In this work, we tackle the scenario of understanding characters in scripts,\nwhich aims to learn the characters' personalities and identities from their\nutterances. We begin by analyzing several challenges in this scenario, and then\npropose a multi-level contrastive learning framework to capture characters'\nglobal information in a fine-grained manner. To validate the proposed\nframework, we conduct extensive experiments on three character understanding\nsub-tasks by comparing with strong pre-trained language models, including\nSpanBERT, Longformer, BigBird and ChatGPT-3.5. Experimental results demonstrate\nthat our method improves the performances by a considerable margin. Through\nfurther in-depth analysis, we show the effectiveness of our method in\naddressing the challenges and provide more hints on the scenario of character\nunderstanding. We will open-source our work on github at\nhttps://github.com/David-Li0406/Script-based-Character-Understanding.",
            "author": [
                "Dawei Li",
                "Hengyuan Zhang",
                "Yanran Li",
                "Shiping Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13231v1",
                "http://arxiv.org/pdf/2310.13231v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13230v2",
            "title": "Absolute Policy Optimization",
            "updated": "2023-11-21T02:28:21Z",
            "published": "2023-10-20T02:40:05Z",
            "summary": "In recent years, trust region on-policy reinforcement learning has achieved\nimpressive results in addressing complex control tasks and gaming scenarios.\nHowever, contemporary state-of-the-art algorithms within this category\nprimarily emphasize improvement in expected performance, lacking the ability to\ncontrol over the worst-case performance outcomes. To address this limitation,\nwe introduce a novel objective function; by optimizing which, it will lead to\nguaranteed monotonic improvement in the lower bound of near-total performance\nsamples (absolute performance). Considering this groundbreaking theoretical\nadvancement, we then refine this theoretically grounded algorithm through a\nseries of approximations, resulting in a practical solution called Absolute\nPolicy Optimization (APO). Our experiments demonstrate the effectiveness of our\napproach across challenging continuous control benchmark tasks and extend its\napplicability to mastering Atari games. Our findings reveal that APO\nsignificantly outperforms state-of-the-art policy gradient algorithms,\nresulting in substantial improvements in both expected performance and\nworst-case performance.",
            "author": [
                "Weiye Zhao",
                "Feihan Li",
                "Yifan Sun",
                "Rui Chen",
                "Tianhao Wei",
                "Changliu Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13230v2",
                "http://arxiv.org/pdf/2310.13230v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13228v1",
            "title": "The Less the Merrier? Investigating Language Representation in\n  Multilingual Models",
            "updated": "2023-10-20T02:26:34Z",
            "published": "2023-10-20T02:26:34Z",
            "summary": "Multilingual Language Models offer a way to incorporate multiple languages in\none model and utilize cross-language transfer learning to improve performance\nfor different Natural Language Processing (NLP) tasks. Despite progress in\nmultilingual models, not all languages are supported as well, particularly in\nlow-resource settings. In this work, we investigate the linguistic\nrepresentation of different languages in multilingual models. We start by\nasking the question which languages are supported in popular multilingual\nmodels and which languages are left behind. Then, for included languages, we\nlook at models' learned representations based on language family and dialect\nand try to understand how models' learned representations for~(1) seen and~(2)\nunseen languages vary across different language groups. In addition, we test\nand analyze performance on downstream tasks such as text generation and Named\nEntity Recognition. We observe from our experiments that community-centered\nmodels -- models that focus on languages of a given family or geographical\nlocation and are built by communities who speak them -- perform better at\ndistinguishing between languages in the same family for low-resource languages.\nOur paper contributes to the literature in understanding multilingual models\nand their shortcomings and offers insights on potential ways to improve them.",
            "author": [
                "Hellina Hailu Nigatu",
                "Atnafu Lambebo Tonja",
                "Jugal Kalita"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13228v1",
                "http://arxiv.org/pdf/2310.13228v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.14783v1",
            "title": "Interpretable Deep Reinforcement Learning for Optimizing Heterogeneous\n  Energy Storage Systems",
            "updated": "2023-10-20T02:26:17Z",
            "published": "2023-10-20T02:26:17Z",
            "summary": "Energy storage systems (ESS) are pivotal component in the energy market,\nserving as both energy suppliers and consumers. ESS operators can reap benefits\nfrom energy arbitrage by optimizing operations of storage equipment. To further\nenhance ESS flexibility within the energy market and improve renewable energy\nutilization, a heterogeneous photovoltaic-ESS (PV-ESS) is proposed, which\nleverages the unique characteristics of battery energy storage (BES) and\nhydrogen energy storage (HES). For scheduling tasks of the heterogeneous\nPV-ESS, cost description plays a crucial role in guiding operator's strategies\nto maximize benefits. We develop a comprehensive cost function that takes into\naccount degradation, capital, and operation/maintenance costs to reflect\nreal-world scenarios. Moreover, while numerous methods excel in optimizing ESS\nenergy arbitrage, they often rely on black-box models with opaque\ndecision-making processes, limiting practical applicability. To overcome this\nlimitation and enable transparent scheduling strategies, a prototype-based\npolicy network with inherent interpretability is introduced. This network\nemploys human-designed prototypes to guide decision-making by comparing\nsimilarities between prototypical situations and encountered situations, which\nallows for naturally explained scheduling strategies. Comparative results\nacross four distinct cases underscore the effectiveness and practicality of our\nproposed pre-hoc interpretable optimization method when contrasted with\nblack-box models.",
            "author": [
                "Luolin Xiong",
                "Yang Tang",
                "Chensheng Liu",
                "Shuai Mao",
                "Ke Meng",
                "Zhaoyang Dong",
                "Feng Qian"
            ],
            "link": [
                "http://arxiv.org/abs/2310.14783v1",
                "http://arxiv.org/pdf/2310.14783v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13227v1",
            "title": "ToolChain*: Efficient Action Space Navigation in Large Language Models\n  with A* Search",
            "updated": "2023-10-20T02:24:35Z",
            "published": "2023-10-20T02:24:35Z",
            "summary": "Large language models (LLMs) have demonstrated powerful decision-making and\nplanning capabilities in solving complicated real-world problems. LLM-based\nautonomous agents can interact with diverse tools (e.g., functional APIs) and\ngenerate solution plans that execute a series of API function calls in a\nstep-by-step manner. The multitude of candidate API function calls\nsignificantly expands the action space, amplifying the critical need for\nefficient action space navigation. However, existing methods either struggle\nwith unidirectional exploration in expansive action spaces, trapped into a\nlocally optimal solution, or suffer from exhaustively traversing all potential\nactions, causing inefficient navigation. To address these issues, we propose\nToolChain*, an efficient tree search-based planning algorithm for LLM-based\nagents. It formulates the entire action space as a decision tree, where each\nnode represents a possible API function call involved in a solution plan. By\nincorporating the A* search algorithm with task-specific cost function design,\nit efficiently prunes high-cost branches that may involve incorrect actions,\nidentifying the most low-cost valid path as the solution. Extensive experiments\non multiple tool-use and reasoning tasks demonstrate that ToolChain*\nefficiently balances exploration and exploitation within an expansive action\nspace. It outperforms state-of-the-art baselines on planning and reasoning\ntasks by 3.1% and 3.5% on average while requiring 7.35x and 2.31x less time,\nrespectively.",
            "author": [
                "Yuchen Zhuang",
                "Xiang Chen",
                "Tong Yu",
                "Saayan Mitra",
                "Victor Bursztyn",
                "Ryan A. Rossi",
                "Somdeb Sarkhel",
                "Chao Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13227v1",
                "http://arxiv.org/pdf/2310.13227v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13225v1",
            "title": "Scalable Neural Network Kernels",
            "updated": "2023-10-20T02:12:56Z",
            "published": "2023-10-20T02:12:56Z",
            "summary": "We introduce the concept of scalable neural network kernels (SNNKs), the\nreplacements of regular feedforward layers (FFLs), capable of approximating the\nlatter, but with favorable computational properties. SNNKs effectively\ndisentangle the inputs from the parameters of the neural network in the FFL,\nonly to connect them in the final computation via the dot-product kernel. They\nare also strictly more expressive, as allowing to model complicated\nrelationships beyond the functions of the dot-products of parameter-input\nvectors. We also introduce the neural network bundling process that applies\nSNNKs to compactify deep neural network architectures, resulting in additional\ncompression gains. In its extreme version, it leads to the fully bundled\nnetwork whose optimal parameters can be expressed via explicit formulae for\nseveral loss functions (e.g. mean squared error), opening a possibility to\nbypass backpropagation. As a by-product of our analysis, we introduce the\nmechanism of the universal random features (or URFs), applied to instantiate\nseveral SNNK variants, and interesting on its own in the context of scalable\nkernel methods. We provide rigorous theoretical analysis of all these concepts\nas well as an extensive empirical evaluation, ranging from point-wise kernel\nestimation to Transformers' fine-tuning with novel adapter layers inspired by\nSNNKs. Our mechanism provides up to 5x reduction in the number of trainable\nparameters, while maintaining competitive accuracy.",
            "author": [
                "Arijit Sehanobish",
                "Krzysztof Choromanski",
                "Yunfan Zhao",
                "Avinava Dubey",
                "Valerii Likhosherstov"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13225v1",
                "http://arxiv.org/pdf/2310.13225v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13222v1",
            "title": "Equivariant Transformer is all you need",
            "updated": "2023-10-20T01:57:03Z",
            "published": "2023-10-20T01:57:03Z",
            "summary": "Machine learning, deep learning, has been accelerating computational physics,\nwhich has been used to simulate systems on a lattice. Equivariance is essential\nto simulate a physical system because it imposes a strong induction bias for\nthe probability distribution described by a machine learning model. This\nreduces the risk of erroneous extrapolation that deviates from data symmetries\nand physical laws. However, imposing symmetry on the model sometimes occur a\npoor acceptance rate in self-learning Monte-Carlo (SLMC). On the other hand,\nAttention used in Transformers like GPT realizes a large model capacity. We\nintroduce symmetry equivariant attention to SLMC. To evaluate our architecture,\nwe apply it to our proposed new architecture on a spin-fermion model on a\ntwo-dimensional lattice. We find that it overcomes poor acceptance rates for\nlinear models and observe the scaling law of the acceptance rate as in the\nlarge language models with Transformers.",
            "author": [
                "Akio Tomiya",
                "Yuki Nagai"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13222v1",
                "http://arxiv.org/pdf/2310.13222v1"
            ],
            "primary_category": "hep-lat",
            "category": [
                "hep-lat",
                "cond-mat.dis-nn",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13220v1",
            "title": "In-context Learning with Transformer Is Really Equivalent to a\n  Contrastive Learning Pattern",
            "updated": "2023-10-20T01:55:34Z",
            "published": "2023-10-20T01:55:34Z",
            "summary": "Pre-trained large language models based on Transformers have demonstrated\namazing in-context learning (ICL) abilities. Given several demonstration\nexamples, the models can implement new tasks without any parameter updates.\nHowever, it is still an open question to understand the mechanism of ICL. In\nthis paper, we interpret the inference process of ICL as a gradient descent\nprocess in a contrastive learning pattern. Firstly, leveraging kernel methods,\nwe establish the relationship between gradient descent and self-attention\nmechanism under generally used softmax attention setting instead of linear\nattention setting. Then, we analyze the corresponding gradient descent process\nof ICL from the perspective of contrastive learning without negative samples\nand discuss possible improvements of this contrastive learning pattern, based\non which the self-attention layer can be further modified. Finally, we design\nexperiments to support our opinions. To the best of our knowledge, our work is\nthe first to provide the understanding of ICL from the perspective of\ncontrastive learning and has the potential to facilitate future model design by\nreferring to related works on contrastive learning.",
            "author": [
                "Ruifeng Ren",
                "Yong Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13220v1",
                "http://arxiv.org/pdf/2310.13220v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13218v1",
            "title": "Deep Reinforcement Learning-Enabled Adaptive Forecasting-Aided State\n  Estimation in Distribution Systems with Multi-Source Multi-Rate Data",
            "updated": "2023-10-20T01:50:48Z",
            "published": "2023-10-20T01:50:48Z",
            "summary": "Distribution system state estimation (DSSE) is paramount for effective state\nmonitoring and control. However, stochastic outputs of renewables and\nasynchronous streaming of multi-rate measurements in practical systems largely\ndegrade the estimation performance. This paper proposes a deep reinforcement\nlearning (DRL)-enabled adaptive DSSE algorithm in unbalanced distribution\nsystems, which tackles hybrid measurements with different time scales\nefficiently. We construct a three-step forecasting-aided state estimation\nframework, including DRL-based parameter identification, prediction, and state\nestimation, with multi-rate measurements incorporating limited synchrophasor\ndata. Furthermore, a DRL-based adaptive parameter identification mechanism is\nembedded in the prediction step. As a novel attempt at utilizing DRL to enable\nDSSE adaptive to varying operating conditions, this method improves the\nprediction performance and further facilitates accurate state estimation. Case\nstudies in two unbalanced feeders indicate that our method captures state\nvariation with multi-source multi-rate data efficiently, outperforming the\ntraditional methods.",
            "author": [
                "Ying Zhang",
                "Junbo Zhao",
                "Di Shi",
                "Sungjoo Chung"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13218v1",
                "http://arxiv.org/pdf/2310.13218v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18330v1",
            "title": "Towards Detecting Contextual Real-Time Toxicity for In-Game Chat",
            "updated": "2023-10-20T00:29:57Z",
            "published": "2023-10-20T00:29:57Z",
            "summary": "Real-time toxicity detection in online environments poses a significant\nchallenge, due to the increasing prevalence of social media and gaming\nplatforms. We introduce ToxBuster, a simple and scalable model that reliably\ndetects toxic content in real-time for a line of chat by including chat history\nand metadata. ToxBuster consistently outperforms conventional toxicity models\nacross popular multiplayer games, including Rainbow Six Siege, For Honor, and\nDOTA 2. We conduct an ablation study to assess the importance of each model\ncomponent and explore ToxBuster's transferability across the datasets.\nFurthermore, we showcase ToxBuster's efficacy in post-game moderation,\nsuccessfully flagging 82.1% of chat-reported players at a precision level of\n90.0%. Additionally, we show how an additional 6% of unreported toxic players\ncan be proactively moderated.",
            "author": [
                "Zachary Yang",
                "Nicolas Grenan-Godbout",
                "Reihaneh Rabbany"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18330v1",
                "http://arxiv.org/pdf/2310.18330v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13201v1",
            "title": "Identification of Abnormality in Maize Plants From UAV Images Using Deep\n  Learning Approaches",
            "updated": "2023-10-20T00:06:42Z",
            "published": "2023-10-20T00:06:42Z",
            "summary": "Early identification of abnormalities in plants is an important task for\nensuring proper growth and achieving high yields from crops. Precision\nagriculture can significantly benefit from modern computer vision tools to make\nfarming strategies addressing these issues efficient and effective. As farming\nlands are typically quite large, farmers have to manually check vast areas to\ndetermine the status of the plants and apply proper treatments. In this work,\nwe consider the problem of automatically identifying abnormal regions in maize\nplants from images captured by a UAV. Using deep learning techniques, we have\ndeveloped a methodology which can detect different levels of abnormality (i.e.,\nlow, medium, high or no abnormality) in maize plants independently of their\ngrowth stage. The primary goal is to identify anomalies at the earliest\npossible stage in order to maximize the effectiveness of potential treatments.\nAt the same time, the proposed system can provide valuable information to human\nannotators for ground truth data collection by helping them to focus their\nattention on a much smaller set of images only. We have experimented with two\ndifferent but complimentary approaches, the first considering abnormality\ndetection as a classification problem and the second considering it as a\nregression problem. Both approaches can be generalized to different types of\nabnormalities and do not make any assumption about the abnormality occurring at\nan early plant growth stage which might be easier to detect due to the plants\nbeing smaller and easier to separate. As a case study, we have considered a\npublicly available data set which exhibits mostly Nitrogen deficiency in maize\nplants of various growth stages. We are reporting promising preliminary results\nwith an 88.89\\% detection accuracy of low abnormality and 100\\% detection\naccuracy of no abnormality.",
            "author": [
                "Aminul Huq",
                "Dimitris Zermas",
                "George Bebis"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13201v1",
                "http://arxiv.org/pdf/2310.13201v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13200v1",
            "title": "A Deep Learning Analysis of Climate Change, Innovation, and Uncertainty",
            "updated": "2023-10-19T23:58:28Z",
            "published": "2023-10-19T23:58:28Z",
            "summary": "We study the implications of model uncertainty in a climate-economics\nframework with three types of capital: \"dirty\" capital that produces carbon\nemissions when used for production, \"clean\" capital that generates no emissions\nbut is initially less productive than dirty capital, and knowledge capital that\nincreases with R\\&D investment and leads to technological innovation in green\nsector productivity. To solve our high-dimensional, non-linear model framework\nwe implement a neural-network-based global solution method. We show there are\nfirst-order impacts of model uncertainty on optimal decisions and social\nvaluations in our integrated climate-economic-innovation framework. Accounting\nfor interconnected uncertainty over climate dynamics, economic damages from\nclimate change, and the arrival of a green technological change leads to\nsubstantial adjustments to investment in the different capital types in\nanticipation of technological change and the revelation of climate damage\nseverity.",
            "author": [
                "Michael Barnett",
                "William Brock",
                "Lars Peter Hansen",
                "Ruimeng Hu",
                "Joseph Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13200v1",
                "http://arxiv.org/pdf/2310.13200v1"
            ],
            "primary_category": "econ.GN",
            "category": [
                "econ.GN",
                "cs.LG",
                "q-fin.EC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18329v1",
            "title": "Unveiling Energy Efficiency in Deep Learning: Measurement, Prediction,\n  and Scoring across Edge Devices",
            "updated": "2023-10-19T23:55:00Z",
            "published": "2023-10-19T23:55:00Z",
            "summary": "Today, deep learning optimization is primarily driven by research focused on\nachieving high inference accuracy and reducing latency. However, the energy\nefficiency aspect is often overlooked, possibly due to a lack of sustainability\nmindset in the field and the absence of a holistic energy dataset. In this\npaper, we conduct a threefold study, including energy measurement, prediction,\nand efficiency scoring, with an objective to foster transparency in power and\nenergy consumption within deep learning across various edge devices. Firstly,\nwe present a detailed, first-of-its-kind measurement study that uncovers the\nenergy consumption characteristics of on-device deep learning. This study\nresults in the creation of three extensive energy datasets for edge devices,\ncovering a wide range of kernels, state-of-the-art DNN models, and popular AI\napplications. Secondly, we design and implement the first kernel-level energy\npredictors for edge devices based on our kernel-level energy dataset.\nEvaluation results demonstrate the ability of our predictors to provide\nconsistent and accurate energy estimations on unseen DNN models. Lastly, we\nintroduce two scoring metrics, PCS and IECS, developed to convert complex power\nand energy consumption data of an edge device into an easily understandable\nmanner for edge device end-users. We hope our work can help shift the mindset\nof both end-users and the research community towards sustainability in edge\ncomputing, a principle that drives our research. Find data, code, and more\nup-to-date information at https://amai-gsu.github.io/DeepEn2023.",
            "author": [
                "Xiaolong Tu",
                "Anik Mallik",
                "Dawei Chen",
                "Kyungtae Han",
                "Onur Altintas",
                "Haoxin Wang",
                "Jiang Xie"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3583740.3628442",
                "http://arxiv.org/abs/2310.18329v1",
                "http://arxiv.org/pdf/2310.18329v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "cs.AI",
                "cs.LG",
                "cs.PF",
                "I.2.11"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13196v1",
            "title": "NameGuess: Column Name Expansion for Tabular Data",
            "updated": "2023-10-19T23:11:37Z",
            "published": "2023-10-19T23:11:37Z",
            "summary": "Recent advances in large language models have revolutionized many sectors,\nincluding the database industry. One common challenge when dealing with large\nvolumes of tabular data is the pervasive use of abbreviated column names, which\ncan negatively impact performance on various data search, access, and\nunderstanding tasks. To address this issue, we introduce a new task, called\nNameGuess, to expand column names (used in database schema) as a natural\nlanguage generation problem. We create a training dataset of 384K\nabbreviated-expanded column pairs using a new data fabrication method and a\nhuman-annotated evaluation benchmark that includes 9.2K examples from\nreal-world tables. To tackle the complexities associated with polysemy and\nambiguity in NameGuess, we enhance auto-regressive language models by\nconditioning on table content and column header names -- yielding a fine-tuned\nmodel (with 2.7B parameters) that matches human performance. Furthermore, we\nconduct a comprehensive analysis (on multiple LLMs) to validate the\neffectiveness of table content in NameGuess and identify promising future\nopportunities. Code has been made available at\nhttps://github.com/amazon-science/nameguess.",
            "author": [
                "Jiani Zhang",
                "Zhengyuan Shen",
                "Balasubramaniam Srinivasan",
                "Shen Wang",
                "Huzefa Rangwala",
                "George Karypis"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13196v1",
                "http://arxiv.org/pdf/2310.13196v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.DB",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13193v1",
            "title": "Heterogeneous Graph Neural Networks for Data-driven Traffic Assignment",
            "updated": "2023-10-19T23:04:09Z",
            "published": "2023-10-19T23:04:09Z",
            "summary": "The traffic assignment problem is one of the significant components of\ntraffic flow analysis for which various solution approaches have been proposed.\nHowever, deploying these approaches for large-scale networks poses significant\nchallenges. In this paper, we leverage the power of heterogeneous graph neural\nnetworks to propose a novel data-driven approach for traffic assignment and\ntraffic flow learning. The proposed model is capable of capturing spatial\ntraffic patterns across different links, yielding highly accurate results. We\npresent numerical experiments on urban transportation networks and show that\nthe proposed heterogeneous graph neural network model outperforms other\nconventional neural network models in terms of convergence rate, training loss,\nand prediction accuracy. Notably, the proposed heterogeneous graph neural\nnetwork model can also be generalized to different network topologies. This\napproach offers a promising solution for complex traffic flow analysis and\nprediction, enhancing our understanding and management of a wide range of\ntransportation systems.",
            "author": [
                "Tong Liu",
                "Hadi Meidani"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13193v1",
                "http://arxiv.org/pdf/2310.13193v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13187v1",
            "title": "Dynamic STEM-EELS for single atom and defect measurement during electron\n  beam transformations",
            "updated": "2023-10-19T22:54:40Z",
            "published": "2023-10-19T22:54:40Z",
            "summary": "On- and off-axis electron energy loss spectroscopy (EELS) is a powerful\nmethod for probing local electronic structure on single atom level. However,\nmany materials undergo electron-beam induced transformation during the scanning\ntransmission electron microscopy (STEM) and spectroscopy, the problem\nparticularly acute for off-axis EELS signals. Here, we propose and\noperationalize the rapid object detection and action system (RODAS) for dynamic\nexploration of the structure-property relationships in STEM-EELS. In this\napproach, the electron beam is used to induce dynamic transformations creating\nnew defect types at sufficiently small rates and avoiding complete material\ndestruction. The deep convolutional neural networks trained via the ensemble\nlearning iterative training (ELIT) approach are used to identify the defects as\nthey form and perform EELS measurements only at specific defect types. Overall,\nin this case the EEL spectra are collected only at predefined objects of\ninterest, avoiding measurements on the ideal regions or holes. We note that\nthis approach can be extended to identify new defect classes as they appear,\nallowing for efficient collection of structure-property relationship data via\nbalanced sampling over defect types.",
            "author": [
                "Kevin M. Roccapriore",
                "Riccardo Torsi",
                "Joshua Robinson",
                "Sergei V. Kalinin",
                "Maxim Ziatdinov"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13187v1",
                "http://arxiv.org/pdf/2310.13187v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "cond-mat.dis-nn"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13167v2",
            "title": "Visualizing Causality in Mixed Reality for Manual Task Learning: An\n  Exploratory Study",
            "updated": "2023-10-26T19:00:22Z",
            "published": "2023-10-19T21:35:11Z",
            "summary": "Mixed Reality (MR) is gaining prominence in manual task skill learning due to\nits in-situ, embodied, and immersive experience. To teach manual tasks, current\nmethodologies break the task into hierarchies (tasks into subtasks) and\nvisualize the current subtask and future in terms of causality. Existing\npsychology literature also shows that humans learn tasks by breaking them into\nhierarchies. In order to understand the design space of information visualized\nto the learner for better task understanding, we conducted a user study with 48\nusers. The study was conducted using a complex assembly task, which involves\nlearning of both actions and tool usage. We aim to explore the effect of\nvisualization of causality in the hierarchy for manual task learning in MR by\nfour options: no causality, event level causality, interaction level causality,\nand gesture level causality. The results show that the user understands and\nperforms best when all the level of causality is shown to the user. Based on\nthe results, we further provide design recommendations and in-depth discussions\nfor future manual task learning systems.",
            "author": [
                "Rahul Jain",
                "Jingyu Shi",
                "Andrew Benton",
                "Moiz Rasheed",
                "Hyungjun Doh",
                "Subramanian Chidambaram",
                "Karthik Ramani"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13167v2",
                "http://arxiv.org/pdf/2310.13167v2"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13165v1",
            "title": "CycleNet: Rethinking Cycle Consistency in Text-Guided Diffusion for\n  Image Manipulation",
            "updated": "2023-10-19T21:32:21Z",
            "published": "2023-10-19T21:32:21Z",
            "summary": "Diffusion models (DMs) have enabled breakthroughs in image synthesis tasks\nbut lack an intuitive interface for consistent image-to-image (I2I)\ntranslation. Various methods have been explored to address this issue,\nincluding mask-based methods, attention-based methods, and image-conditioning.\nHowever, it remains a critical challenge to enable unpaired I2I translation\nwith pre-trained DMs while maintaining satisfying consistency. This paper\nintroduces Cyclenet, a novel but simple method that incorporates cycle\nconsistency into DMs to regularize image manipulation. We validate Cyclenet on\nunpaired I2I tasks of different granularities. Besides the scene and object\nlevel translation, we additionally contribute a multi-domain I2I translation\ndataset to study the physical state changes of objects. Our empirical studies\nshow that Cyclenet is superior in translation consistency and quality, and can\ngenerate high-quality images for out-of-domain distributions with a simple\nchange of the textual prompt. Cyclenet is a practical framework, which is\nrobust even with very limited training data (around 2k) and requires minimal\ncomputational resources (1 GPU) to train. Project homepage:\nhttps://cyclenetweb.github.io/",
            "author": [
                "Sihan Xu",
                "Ziqiao Ma",
                "Yidong Huang",
                "Honglak Lee",
                "Joyce Chai"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13165v1",
                "http://arxiv.org/pdf/2310.13165v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13164v2",
            "title": "Almost Equivariance via Lie Algebra Convolutions",
            "updated": "2023-11-28T03:13:42Z",
            "published": "2023-10-19T21:31:11Z",
            "summary": "Recently, the equivariance of models with respect to a group action has\nbecome an important topic of research in machine learning. However, imbuing an\narchitecture with a specific group equivariance imposes a strong prior on the\ntypes of data transformations that the model expects to see. While\nstrictly-equivariant models enforce symmetries, real-world data does not always\nconform to such strict equivariances, be it due to noise in the data or\nunderlying physical laws that encode only approximate or partial symmetries. In\nsuch cases, the prior of strict equivariance can actually prove too strong and\ncause models to underperform on real-world data. Therefore, in this work we\nstudy a closely related topic, that of almost equivariance. We provide a\ndefinition of almost equivariance that differs from those extant in the current\nliterature and give a practical method for encoding almost equivariance in\nmodels by appealing to the Lie algebra of a Lie group. Specifically, we define\nLie algebra convolutions and demonstrate that they offer several benefits over\nLie group convolutions, including being well-defined for non-compact groups.\nFrom there, we pivot to the realm of theory and demonstrate connections between\nthe notions of equivariance and isometry and those of almost equivariance and\nalmost isometry, respectively. We prove two existence theorems, one showing the\nexistence of almost isometries within bounded distance of isometries of a\ngeneral manifold, and another showing the converse for Hilbert spaces. We then\nextend these theorems to prove the existence of almost equivariant manifold\nembeddings within bounded distance of fully equivariant embedding functions,\nsubject to certain constraints on the group action and the function class.\nFinally, we demonstrate the validity of our approach by benchmarking against\ndatasets in fully equivariant and almost equivariant settings.",
            "author": [
                "Daniel McNeela"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13164v2",
                "http://arxiv.org/pdf/2310.13164v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML",
                "I.2.6"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13161v1",
            "title": "A Distributed Approach to Meteorological Predictions: Addressing Data\n  Imbalance in Precipitation Prediction Models through Federated Learning and\n  GANs",
            "updated": "2023-10-19T21:28:20Z",
            "published": "2023-10-19T21:28:20Z",
            "summary": "The classification of weather data involves categorizing meteorological\nphenomena into classes, thereby facilitating nuanced analyses and precise\npredictions for various sectors such as agriculture, aviation, and disaster\nmanagement. This involves utilizing machine learning models to analyze large,\nmultidimensional weather datasets for patterns and trends. These datasets may\ninclude variables such as temperature, humidity, wind speed, and pressure,\ncontributing to meteorological conditions. Furthermore, it's imperative that\nclassification algorithms proficiently navigate challenges such as data\nimbalances, where certain weather events (e.g., storms or extreme temperatures)\nmight be underrepresented. This empirical study explores data augmentation\nmethods to address imbalanced classes in tabular weather data in centralized\nand federated settings. Employing data augmentation techniques such as the\nSynthetic Minority Over-sampling Technique or Generative Adversarial Networks\ncan improve the model's accuracy in classifying rare but critical weather\nevents. Moreover, with advancements in federated learning, machine learning\nmodels can be trained across decentralized databases, ensuring privacy and data\nintegrity while mitigating the need for centralized data storage and\nprocessing. Thus, the classification of weather data stands as a critical\nbridge, linking raw meteorological data to actionable insights, enhancing our\ncapacity to anticipate and prepare for diverse weather conditions.",
            "author": [
                "Elaheh Jafarigol",
                "Theodore Trafalis"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13161v1",
                "http://arxiv.org/pdf/2310.13161v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13160v1",
            "title": "Active Sensing for Localization with Reconfigurable Intelligent Surface",
            "updated": "2023-10-19T21:19:18Z",
            "published": "2023-10-19T21:19:18Z",
            "summary": "This paper addresses an uplink localization problem in which the base station\n(BS) aims to locate a remote user with the aid of reconfigurable intelligent\nsurface (RIS). This paper proposes a strategy in which the user transmits\npilots over multiple time frames, and the BS adaptively adjusts the RIS\nreflection coefficients based on the observations already received so far in\norder to produce an accurate estimate of the user location at the end. This is\na challenging active sensing problem for which finding an optimal solution\ninvolves a search through a complicated functional space whose dimension\nincreases with the number of measurements. In this paper, we show that the long\nshort-term memory (LSTM) network can be used to exploit the latent temporal\ncorrelation between measurements to automatically construct scalable\ninformation vectors (called hidden state) based on the measurements.\nSubsequently, the state vector can be mapped to the RIS configuration for the\nnext time frame in a codebook-free fashion via a deep neural network (DNN).\nAfter all the measurements have been received, a final DNN can be used to map\nthe LSTM cell state to the estimated user equipment (UE) position. Numerical\nresult shows that the proposed active RIS design results in lower localization\nerror as compared to existing active and nonactive methods. The proposed\nsolution produces interpretable results and is generalizable to early stopping\nin the sequence of sensing stages.",
            "author": [
                "Zhongze Zhang",
                "Tao Jiang",
                "Wei Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13160v1",
                "http://arxiv.org/pdf/2310.13160v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13157v1",
            "title": "Conditional Generative Modeling for Images, 3D Animations, and Video",
            "updated": "2023-10-19T21:10:39Z",
            "published": "2023-10-19T21:10:39Z",
            "summary": "This dissertation attempts to drive innovation in the field of generative\nmodeling for computer vision, by exploring novel formulations of conditional\ngenerative models, and innovative applications in images, 3D animations, and\nvideo. Our research focuses on architectures that offer reversible\ntransformations of noise and visual data, and the application of\nencoder-decoder architectures for generative tasks and 3D content manipulation.\nIn all instances, we incorporate conditional information to enhance the\nsynthesis of visual data, improving the efficiency of the generation process as\nwell as the generated content.\n  We introduce the use of Neural ODEs to model video dynamics using an\nencoder-decoder architecture, demonstrating their ability to predict future\nvideo frames despite being trained solely to reconstruct current frames. Next,\nwe propose a conditional variant of continuous normalizing flows that enables\nhigher-resolution image generation based on lower-resolution input, achieving\ncomparable image quality while reducing parameters and training time. Our next\ncontribution presents a pipeline that takes human images as input,\nautomatically aligns a user-specified 3D character with the pose of the human,\nand facilitates pose editing based on partial inputs. Next, we derive the\nrelevant mathematical details for denoising diffusion models that use\nnon-isotropic Gaussian processes, and show comparable generation quality.\nFinally, we devise a novel denoising diffusion framework capable of solving all\nthree video tasks of prediction, generation, and interpolation. We perform\nablation studies, and show SOTA results on multiple datasets.\n  Our contributions are published articles at peer-reviewed venues. Overall,\nour research aims to make a meaningful contribution to the pursuit of more\nefficient and flexible generative models, with the potential to shape the\nfuture of computer vision.",
            "author": [
                "Vikram Voleti"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13157v1",
                "http://arxiv.org/pdf/2310.13157v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13153v1",
            "title": "Discovering Novel Halide Perovskite Alloys using Multi-Fidelity Machine\n  Learning and Genetic Algorithm",
            "updated": "2023-10-19T20:55:08Z",
            "published": "2023-10-19T20:55:08Z",
            "summary": "Expanding the pool of stable halide perovskites with attractive\noptoelectronic properties is crucial to addressing current limitations in their\nperformance as photovoltaic (PV) absorbers. In this article, we demonstrate how\na high-throughput density functional theory (DFT) dataset of halide perovskite\nalloys can be used to train accurate surrogate models for property prediction\nand subsequently perform inverse design using genetic algorithm (GA). Our\ndataset consists of decomposition energies, band gaps, and photovoltaic\nefficiencies of nearly 800 pure and mixed composition ABX$_3$ compounds from\nboth the GGA-PBE and HSE06 functionals, and are combined with ~ 100\nexperimental data points collected from the literature. Multi-fidelity random\nforest regression models are trained on the DFT + experimental dataset for each\nproperty using descriptors that one-hot encode composition, phase, and\nfidelity, and additionally include well-known elemental or molecular properties\nof species at the A, B, and X sites. Rigorously optimized models are deployed\nfor experiment-level prediction over > 150,000 hypothetical compounds, leading\nto thousands of promising materials with low decomposition energy, band gap\nbetween 1 and 2 eV, and efficiency > 15%. Surrogate models are further combined\nwith GA using an objective function to maintain chemical feasibility, minimize\ndecomposition energy, maximize PV efficiency, and keep band gap between 1 and 2\neV; hundreds more optimal compositions and phases are thus discovered. We\npresent an analysis of the screened and inverse-designed materials, visualize\nternary phase diagrams generated for many systems of interest using ML\npredictions, and suggest strategies for further improvement and expansion in\nthe future.",
            "author": [
                "Jiaqi Yang",
                "Panayotis Manganaris",
                "Arun Mannodi-Kanakkithodi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13153v1",
                "http://arxiv.org/pdf/2310.13153v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13146v1",
            "title": "CLIFT: Analysing Natural Distribution Shift on Question Answering Models\n  in Clinical Domain",
            "updated": "2023-10-19T20:43:11Z",
            "published": "2023-10-19T20:43:11Z",
            "summary": "This paper introduces a new testbed CLIFT (Clinical Shift) for the clinical\ndomain Question-answering task. The testbed includes 7.5k high-quality question\nanswering samples to provide a diverse and reliable benchmark. We performed a\ncomprehensive experimental study and evaluated several QA deep-learning models\nunder the proposed testbed. Despite impressive results on the original test\nset, the performance degrades when applied to new test sets, which shows the\ndistribution shift. Our findings emphasize the need for and the potential for\nincreasing the robustness of clinical domain models under distributional\nshifts. The testbed offers one way to track progress in that direction. It also\nhighlights the necessity of adopting evaluation metrics that consider\nrobustness to natural distribution shifts. We plan to expand the corpus by\nadding more samples and model results. The full paper and the updated benchmark\nare available at github.com/openlifescience-ai/clift",
            "author": [
                "Ankit Pal"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13146v1",
                "http://arxiv.org/pdf/2310.13146v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.CY",
                "cs.DC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13140v1",
            "title": "Privacy Preserving Decision Tree Training and Prediction via Fully\n  Homomorphic Encryption with No Decryption",
            "updated": "2023-10-19T20:33:02Z",
            "published": "2023-10-19T20:33:02Z",
            "summary": "With data-outsourcing becoming commonplace, there grows a need for secure\noutsourcing of data and machine learning models. Namely, data and model owners\n(client) often have a need for their information to remain private and secure\nagainst the potentially untrusted computing resource (server) to whom they want\nto outsource said data and models to. Various approaches to privacy-preserving\nmachine learning (PPML) have been devised with different techniques and\nsolutions introduced in the past. These solutions often involved one of two\ncompromises: (1) client-server interactions to allow intermediary rounds of\ndecryption and re-encryption of data or (2) complex architectures for\nmulti-party computation. This paper devises a paradigm using Fully Homomorphic\nEncryption (FHE) that minimizes architectural complexity and removes\nclient-side involvement during the training and prediction lifecycle of machine\nlearning models. In addition, the paradigm proposed in this work achieves both\nmodel security as well as data security. To remove client-side involvement, the\ndevised paradigm proposes a no decryption approach that allows the server to\nhandle PPML in its entirety without rounds of decryption and re-encryption. To\nthe best of our knowledge, this paradigm is the first to achieve\nprivacy-preserving decision tree training with no decryption while maintaining\na simple client-server architecture.",
            "author": [
                "Hunjae Lee",
                "Corey Clark"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13140v1",
                "http://arxiv.org/pdf/2310.13140v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13139v2",
            "title": "Graph Neural Networks with polynomial activations have limited\n  expressivity",
            "updated": "2023-11-03T17:43:17Z",
            "published": "2023-10-19T20:32:25Z",
            "summary": "The expressivity of Graph Neural Networks (GNNs) can be entirely\ncharacterized by appropriate fragments of the first-order logic. Namely, any\nquery of the two variable fragment of graded modal logic (GC2) interpreted over\nlabeled graphs can be expressed using a GNN whose size depends only on the\ndepth of the query. As pointed out by [Barcelo & Al., 2020, Grohe, 2021], this\ndescription holds for a family of activation functions, leaving the possibility\nfor a hierarchy of logics expressible by GNNs depending on the chosen\nactivation function. In this article, we show that such hierarchy indeed exists\nby proving that GC2 queries cannot be expressed by GNNs with polynomial\nactivation functions. This implies a separation between polynomial and popular\nnon-polynomial activations (such as ReLUs, sigmoid and hyperbolic tan and\nothers) and answers an open question formulated by [Grohe, 2021].",
            "author": [
                "Sammy Khalife"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13139v2",
                "http://arxiv.org/pdf/2310.13139v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13138v2",
            "title": "LHC Hadronic Jet Generation Using Convolutional Variational Autoencoders\n  with Normalizing Flows",
            "updated": "2023-11-08T13:35:33Z",
            "published": "2023-10-19T20:30:50Z",
            "summary": "In high energy physics, one of the most important processes for collider data\nanalysis is the comparison of collected and simulated data. Nowadays the\nstate-of-the-art for data generation is in the form of Monte Carlo (MC)\ngenerators. However, because of the upcoming high-luminosity upgrade of the\nLHC, there will not be enough computational power or time to match the amount\nof needed simulated data using MC methods. An alternative approach under study\nis the usage of machine learning generative methods to fulfill that task.Since\nthe most common final-state objects of high-energy proton collisions are\nhadronic jets, which are collections of particles collimated in a given region\nof space, this work aims to develop a convolutional variational autoencoder\n(ConVAE) for the generation of particle-based LHC hadronic jets. Given the\nConVAE's limitations, a normalizing flow (NF) network is coupled to it in a\ntwo-step training process, which shows improvements on the results for the\ngenerated jets. The ConVAE+NF network is capable of generating a jet in $18.30\n\\pm 0.04 \\ \\mu$s, making it one of the fastest methods for this task up to now.",
            "author": [
                "Breno Orzari",
                "Nadezda Chernyavskaya",
                "Raphael Cobe",
                "Javier Duarte",
                "Jefferson Fialho",
                "Dimitrios Gunopulos",
                "Raghav Kansal",
                "Maurizio Pierini",
                "Thiago Tomei",
                "Mary Touranakou"
            ],
            "link": [
                "http://dx.doi.org/10.1088/2632-2153/ad04ea",
                "http://arxiv.org/abs/2310.13138v2",
                "http://arxiv.org/pdf/2310.13138v2"
            ],
            "primary_category": "physics.comp-ph",
            "category": [
                "physics.comp-ph",
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13137v1",
            "title": "Mean Estimation Under Heterogeneous Privacy Demands",
            "updated": "2023-10-19T20:29:19Z",
            "published": "2023-10-19T20:29:19Z",
            "summary": "Differential Privacy (DP) is a well-established framework to quantify privacy\nloss incurred by any algorithm. Traditional formulations impose a uniform\nprivacy requirement for all users, which is often inconsistent with real-world\nscenarios in which users dictate their privacy preferences individually. This\nwork considers the problem of mean estimation, where each user can impose their\nown distinct privacy level. The algorithm we propose is shown to be minimax\noptimal and has a near-linear run-time. Our results elicit an interesting\nsaturation phenomenon that occurs. Namely, the privacy requirements of the most\nstringent users dictate the overall error rates. As a consequence, users with\nless but differing privacy requirements are all given more privacy than they\nrequire, in equal amounts. In other words, these privacy-indifferent users are\ngiven a nontrivial degree of privacy for free, without any sacrifice in the\nperformance of the estimator.",
            "author": [
                "Syomantak Chaudhuri",
                "Konstantin Miagkov",
                "Thomas A. Courtade"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13137v1",
                "http://arxiv.org/pdf/2310.13137v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.DS",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13136v1",
            "title": "Approaches for Uncertainty Quantification of AI-predicted Material\n  Properties: A Comparison",
            "updated": "2023-10-19T20:20:39Z",
            "published": "2023-10-19T20:20:39Z",
            "summary": "The development of large databases of material properties, together with the\navailability of powerful computers, has allowed machine learning (ML) modeling\nto become a widely used tool for predicting material performances. While\nconfidence intervals are commonly reported for such ML models, prediction\nintervals, i.e., the uncertainty on each prediction, are not as frequently\navailable. Here, we investigate three easy-to-implement approaches to determine\nsuch individual uncertainty, comparing them across ten ML quantities spanning\nenergetics, mechanical, electronic, optical, and spectral properties.\nSpecifically, we focused on the Quantile approach, the direct machine learning\nof the prediction intervals and Ensemble methods.",
            "author": [
                "Francesca Tavazza",
                "Kamal Choudhary",
                "Brian DeCost"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13136v1",
                "http://arxiv.org/pdf/2310.13136v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13135v3",
            "title": "LeTFuser: Light-weight End-to-end Transformer-Based Sensor Fusion for\n  Autonomous Driving with Multi-Task Learning",
            "updated": "2023-12-01T19:59:29Z",
            "published": "2023-10-19T20:09:08Z",
            "summary": "In end-to-end autonomous driving, the utilization of existing sensor fusion\ntechniques and navigational control methods for imitation learning proves\ninadequate in challenging situations that involve numerous dynamic agents. To\naddress this issue, we introduce LeTFuser, a lightweight transformer-based\nalgorithm for fusing multiple RGB-D camera representations. To perform\nperception and control tasks simultaneously, we utilize multi-task learning.\nOur model comprises of two modules, the first being the perception module that\nis responsible for encoding the observation data obtained from the RGB-D\ncameras. Our approach employs the Convolutional vision Transformer (CvT)\n\\cite{wu2021cvt} to better extract and fuse features from multiple RGB cameras\ndue to local and global feature extraction capability of convolution and\ntransformer modules, respectively. Encoded features combined with static and\ndynamic environments are later employed by our control module to predict\nwaypoints and vehicular controls (e.g. steering, throttle, and brake). We use\ntwo methods to generate the vehicular controls levels. The first method uses a\nPID algorithm to follow the waypoints on the fly, whereas the second one\ndirectly predicts the control policy using the measurement features and\nenvironmental state. We evaluate the model and conduct a comparative analysis\nwith recent models on the CARLA simulator using various scenarios, ranging from\nnormal to adversarial conditions, to simulate real-world scenarios. Our method\ndemonstrated better or comparable results with respect to our baselines in term\nof driving abilities. The code is available at\n\\url{https://github.com/pagand/e2etransfuser/tree/cvpr-w} to facilitate future\nstudies.",
            "author": [
                "Pedram Agand",
                "Mohammad Mahdavian",
                "Manolis Savva",
                "Mo Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13135v3",
                "http://arxiv.org/pdf/2310.13135v3"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13129v2",
            "title": "Deep Reinforcement Learning-based Intelligent Traffic Signal Controls\n  with Optimized CO2 emissions",
            "updated": "2023-10-23T22:08:13Z",
            "published": "2023-10-19T19:54:47Z",
            "summary": "Nowadays, transportation networks face the challenge of sub-optimal control\npolicies that can have adverse effects on human health, the environment, and\ncontribute to traffic congestion. Increased levels of air pollution and\nextended commute times caused by traffic bottlenecks make intersection traffic\nsignal controllers a crucial component of modern transportation infrastructure.\nDespite several adaptive traffic signal controllers in literature, limited\nresearch has been conducted on their comparative performance. Furthermore,\ndespite carbon dioxide (CO2) emissions' significance as a global issue, the\nliterature has paid limited attention to this area. In this report, we propose\nEcoLight, a reward shaping scheme for reinforcement learning algorithms that\nnot only reduces CO2 emissions but also achieves competitive results in metrics\nsuch as travel time. We compare the performance of tabular Q-Learning, DQN,\nSARSA, and A2C algorithms using metrics such as travel time, CO2 emissions,\nwaiting time, and stopped time. Our evaluation considers multiple scenarios\nthat encompass a range of road users (trucks, buses, cars) with varying\npollution levels.",
            "author": [
                "Pedram Agand",
                "Alexey Iskrov",
                "Mo Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13129v2",
                "http://arxiv.org/pdf/2310.13129v2"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.AI",
                "cs.LG",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13123v2",
            "title": "Fuel Consumption Prediction for a Passenger Ferry using Machine Learning\n  and In-service Data: A Comparative Study",
            "updated": "2023-10-23T22:13:04Z",
            "published": "2023-10-19T19:35:38Z",
            "summary": "As the importance of eco-friendly transportation increases, providing an\nefficient approach for marine vessel operation is essential. Methods for status\nmonitoring with consideration to the weather condition and forecasting with the\nuse of in-service data from ships requires accurate and complete models for\npredicting the energy efficiency of a ship. The models need to effectively\nprocess all the operational data in real-time. This paper presents models that\ncan predict fuel consumption using in-service data collected from a passenger\nship. Statistical and domain-knowledge methods were used to select the proper\ninput variables for the models. These methods prevent over-fitting, missing\ndata, and multicollinearity while providing practical applicability. Prediction\nmodels that were investigated include multiple linear regression (MLR),\ndecision tree approach (DT), an artificial neural network (ANN), and ensemble\nmethods. The best predictive performance was from a model developed using the\nXGboost technique which is a boosting ensemble approach. \\rvv{Our code is\navailable on GitHub at\n\\url{https://github.com/pagand/model_optimze_vessel/tree/OE} for future\nresearch.",
            "author": [
                "Pedram Agand",
                "Allison Kennedy",
                "Trevor Harris",
                "Chanwoo Bae",
                "Mo Chen",
                "Edward J Park"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.oceaneng.2023.115271",
                "http://arxiv.org/abs/2310.13123v2",
                "http://arxiv.org/pdf/2310.13123v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13121v4",
            "title": "Understanding Addition in Transformers",
            "updated": "2023-11-25T00:52:20Z",
            "published": "2023-10-19T19:34:42Z",
            "summary": "Understanding the inner workings of machine learning models like Transformers\nis vital for their safe and ethical use. This paper presents an in-depth\nanalysis of a one-layer Transformer model trained for n-digit integer addition.\nWe reveal that the model divides the task into parallel, digit-specific streams\nand employs distinct algorithms for different digit positions. Our study also\nfinds that the model starts calculations late but executes them rapidly. A rare\nuse case with high loss is identified and explained. Overall, the model's\nalgorithm is explained in detail. These findings are validated through rigorous\ntesting and mathematical modeling, contributing to the broader works in\nMechanistic Interpretability, AI safety, and alignment. Our approach opens the\ndoor for analyzing more complex tasks and multi-layer Transformer models.",
            "author": [
                "Philip Quirke",
                "Fazl Barez"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13121v4",
                "http://arxiv.org/pdf/2310.13121v4"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13120v1",
            "title": "RSAdapter: Adapting Multimodal Models for Remote Sensing Visual Question\n  Answering",
            "updated": "2023-10-19T19:32:27Z",
            "published": "2023-10-19T19:32:27Z",
            "summary": "In recent years, with the rapid advancement of transformer models,\ntransformer-based multimodal architectures have found wide application in\nvarious downstream tasks, including but not limited to Image Captioning, Visual\nQuestion Answering (VQA), and Image-Text Generation. However, contemporary\napproaches to Remote Sensing (RS) VQA often involve resource-intensive\ntechniques, such as full fine-tuning of large models or the extraction of\nimage-text features from pre-trained multimodal models, followed by modality\nfusion using decoders. These approaches demand significant computational\nresources and time, and a considerable number of trainable parameters are\nintroduced. To address these challenges, we introduce a novel method known as\nRSAdapter, which prioritizes runtime and parameter efficiency. RSAdapter\ncomprises two key components: the Parallel Adapter and an additional linear\ntransformation layer inserted after each fully connected (FC) layer within the\nAdapter. This approach not only improves adaptation to pre-trained multimodal\nmodels but also allows the parameters of the linear transformation layer to be\nintegrated into the preceding FC layers during inference, reducing inference\ncosts. To demonstrate the effectiveness of RSAdapter, we conduct an extensive\nseries of experiments using three distinct RS-VQA datasets and achieve\nstate-of-the-art results on all three datasets. The code for RSAdapter will be\navailable online at https://github.com/Y-D-Wang/RSAdapter.",
            "author": [
                "Yuduo Wang",
                "Pedram Ghamisi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13120v1",
                "http://arxiv.org/pdf/2310.13120v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13119v1",
            "title": "DreamSpace: Dreaming Your Room Space with Text-Driven Panoramic Texture\n  Propagation",
            "updated": "2023-10-19T19:29:23Z",
            "published": "2023-10-19T19:29:23Z",
            "summary": "Diffusion-based methods have achieved prominent success in generating 2D\nmedia. However, accomplishing similar proficiencies for scene-level mesh\ntexturing in 3D spatial applications, e.g., XR/VR, remains constrained,\nprimarily due to the intricate nature of 3D geometry and the necessity for\nimmersive free-viewpoint rendering. In this paper, we propose a novel indoor\nscene texturing framework, which delivers text-driven texture generation with\nenchanting details and authentic spatial coherence. The key insight is to first\nimagine a stylized 360{\\deg} panoramic texture from the central viewpoint of\nthe scene, and then propagate it to the rest areas with inpainting and\nimitating techniques. To ensure meaningful and aligned textures to the scene,\nwe develop a novel coarse-to-fine panoramic texture generation approach with\ndual texture alignment, which both considers the geometry and texture cues of\nthe captured scenes. To survive from cluttered geometries during texture\npropagation, we design a separated strategy, which conducts texture inpainting\nin confidential regions and then learns an implicit imitating network to\nsynthesize textures in occluded and tiny structural areas. Extensive\nexperiments and the immersive VR application on real-world indoor scenes\ndemonstrate the high quality of the generated textures and the engaging\nexperience on VR headsets. Project webpage:\nhttps://ybbbbt.com/publication/dreamspace",
            "author": [
                "Bangbang Yang",
                "Wenqi Dong",
                "Lin Ma",
                "Wenbo Hu",
                "Xiao Liu",
                "Zhaopeng Cui",
                "Yuewen Ma"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13119v1",
                "http://arxiv.org/pdf/2310.13119v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13110v1",
            "title": "Semi-Supervised Learning of Dynamical Systems with Neural Ordinary\n  Differential Equations: A Teacher-Student Model Approach",
            "updated": "2023-10-19T19:17:12Z",
            "published": "2023-10-19T19:17:12Z",
            "summary": "Modeling dynamical systems is crucial for a wide range of tasks, but it\nremains challenging due to complex nonlinear dynamics, limited observations, or\nlack of prior knowledge. Recently, data-driven approaches such as Neural\nOrdinary Differential Equations (NODE) have shown promising results by\nleveraging the expressive power of neural networks to model unknown dynamics.\nHowever, these approaches often suffer from limited labeled training data,\nleading to poor generalization and suboptimal predictions. On the other hand,\nsemi-supervised algorithms can utilize abundant unlabeled data and have\ndemonstrated good performance in classification and regression tasks. We\npropose TS-NODE, the first semi-supervised approach to modeling dynamical\nsystems with NODE. TS-NODE explores cheaply generated synthetic pseudo rollouts\nto broaden exploration in the state space and to tackle the challenges brought\nby lack of ground-truth system data under a teacher-student model. TS-NODE\nemploys an unified optimization framework that corrects the teacher model based\non the student's feedback while mitigating the potential false system dynamics\npresent in pseudo rollouts. TS-NODE demonstrates significant performance\nimprovements over a baseline Neural ODE model on multiple dynamical system\nmodeling tasks.",
            "author": [
                "Yu Wang",
                "Yuxuan Yin",
                "Karthik Somayaji Nanjangud Suryanarayana",
                "Jan Drgona",
                "Malachi Schram",
                "Mahantesh Halappanavar",
                "Frank Liu",
                "Peng Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13110v1",
                "http://arxiv.org/pdf/2310.13110v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13108v1",
            "title": "Streamlining Brain Tumor Classification with Custom Transfer Learning in\n  MRI Images",
            "updated": "2023-10-19T19:13:04Z",
            "published": "2023-10-19T19:13:04Z",
            "summary": "Brain tumors are increasingly prevalent, characterized by the uncontrolled\nspread of aberrant tissues in the brain, with almost 700,000 new cases\ndiagnosed globally each year. Magnetic Resonance Imaging (MRI) is commonly used\nfor the diagnosis of brain tumors and accurate classification is a critical\nclinical procedure. In this study, we propose an efficient solution for\nclassifying brain tumors from MRI images using custom transfer learning\nnetworks. While several researchers have employed various pre-trained\narchitectures such as RESNET-50, ALEXNET, VGG-16, and VGG-19, these methods\noften suffer from high computational complexity. To address this issue, we\npresent a custom and lightweight model using a Convolutional Neural\nNetwork-based pre-trained architecture with reduced complexity. Specifically,\nwe employ the VGG-19 architecture with additional hidden layers, which reduces\nthe complexity of the base architecture but improves computational efficiency.\nThe objective is to achieve high classification accuracy using a novel\napproach. Finally, the result demonstrates a classification accuracy of 96.42%.",
            "author": [
                "Javed Hossain",
                "Md. Touhidul Islam",
                "Md. Taufiqul Haque Khan Tusar"
            ],
            "link": [
                "http://dx.doi.org/10.1109/SIST58284.2023.10223507",
                "http://arxiv.org/abs/2310.13108v1",
                "http://arxiv.org/pdf/2310.13108v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13103v1",
            "title": "AVTENet: Audio-Visual Transformer-based Ensemble Network Exploiting\n  Multiple Experts for Video Deepfake Detection",
            "updated": "2023-10-19T19:01:26Z",
            "published": "2023-10-19T19:01:26Z",
            "summary": "Forged content shared widely on social media platforms is a major social\nproblem that requires increased regulation and poses new challenges to the\nresearch community. The recent proliferation of hyper-realistic deepfake videos\nhas drawn attention to the threat of audio and visual forgeries. Most previous\nwork on detecting AI-generated fake videos only utilizes visual modality or\naudio modality. While there are some methods in the literature that exploit\naudio and visual modalities to detect forged videos, they have not been\ncomprehensively evaluated on multi-modal datasets of deepfake videos involving\nacoustic and visual manipulations. Moreover, these existing methods are mostly\nbased on CNN and suffer from low detection accuracy. Inspired by the recent\nsuccess of Transformer in various fields, to address the challenges posed by\ndeepfake technology, in this paper, we propose an Audio-Visual\nTransformer-based Ensemble Network (AVTENet) framework that considers both\nacoustic manipulation and visual manipulation to achieve effective video\nforgery detection. Specifically, the proposed model integrates several purely\ntransformer-based variants that capture video, audio, and audio-visual salient\ncues to reach a consensus in prediction. For evaluation, we use the recently\nreleased benchmark multi-modal audio-video FakeAVCeleb dataset. For a detailed\nanalysis, we evaluate AVTENet, its variants, and several existing methods on\nmultiple test sets of the FakeAVCeleb dataset. Experimental results show that\nour best model outperforms all existing methods and achieves state-of-the-art\nperformance on Testset-I and Testset-II of the FakeAVCeleb dataset.",
            "author": [
                "Ammarah Hashmi",
                "Sahibzada Adil Shahzad",
                "Chia-Wen Lin",
                "Yu Tsao",
                "Hsin-Min Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13103v1",
                "http://arxiv.org/pdf/2310.13103v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG",
                "cs.MM",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13102v2",
            "title": "Particle Guidance: non-I.I.D. Diverse Sampling with Diffusion Models",
            "updated": "2023-11-24T09:42:21Z",
            "published": "2023-10-19T19:01:00Z",
            "summary": "In light of the widespread success of generative models, a significant amount\nof research has gone into speeding up their sampling time. However, generative\nmodels are often sampled multiple times to obtain a diverse set incurring a\ncost that is orthogonal to sampling time. We tackle the question of how to\nimprove diversity and sample efficiency by moving beyond the common assumption\nof independent samples. We propose particle guidance, an extension of\ndiffusion-based generative sampling where a joint-particle time-evolving\npotential enforces diversity. We analyze theoretically the joint distribution\nthat particle guidance generates, how to learn a potential that achieves\noptimal diversity, and the connections with methods in other disciplines.\nEmpirically, we test the framework both in the setting of conditional image\ngeneration, where we are able to increase diversity without affecting quality,\nand molecular conformer generation, where we reduce the state-of-the-art median\nerror by 13% on average.",
            "author": [
                "Gabriele Corso",
                "Yilun Xu",
                "Valentin de Bortoli",
                "Regina Barzilay",
                "Tommi Jaakkola"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13102v2",
                "http://arxiv.org/pdf/2310.13102v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13099v1",
            "title": "No offence, Bert -- I insult only humans! Multiple addressees\n  sentence-level attack on toxicity detection neural network",
            "updated": "2023-10-19T18:56:50Z",
            "published": "2023-10-19T18:56:50Z",
            "summary": "We introduce a simple yet efficient sentence-level attack on black-box\ntoxicity detector models. By adding several positive words or sentences to the\nend of a hateful message, we are able to change the prediction of a neural\nnetwork and pass the toxicity detection system check. This approach is shown to\nbe working on seven languages from three different language families. We also\ndescribe the defence mechanism against the aforementioned attack and discuss\nits limitations.",
            "author": [
                "Sergey Berezin",
                "Reza Farahbakhsh",
                "Noel Crespi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13099v1",
                "http://arxiv.org/pdf/2310.13099v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13098v2",
            "title": "SRAI: Towards Standardization of Geospatial AI",
            "updated": "2023-10-23T15:03:50Z",
            "published": "2023-10-19T18:56:04Z",
            "summary": "Spatial Representations for Artificial Intelligence (srai) is a Python\nlibrary for working with geospatial data. The library can download geospatial\ndata, split a given area into micro-regions using multiple algorithms and train\nan embedding model using various architectures. It includes baseline models as\nwell as more complex methods from published works. Those capabilities make it\npossible to use srai in a complete pipeline for geospatial task solving. The\nproposed library is the first step to standardize the geospatial AI domain\ntoolset. It is fully open-source and published under Apache 2.0 licence.",
            "author": [
                "Piotr Gramacki",
                "Kacper Le\u015bniara",
                "Kamil Raczycki",
                "Szymon Wo\u017aniak",
                "Marcin Przymus",
                "Piotr Szyma\u0144ski"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3615886.3627740",
                "http://arxiv.org/abs/2310.13098v2",
                "http://arxiv.org/pdf/2310.13098v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13097v1",
            "title": "A Multi-Stage Temporal Convolutional Network for Volleyball Jumps\n  Classification Using a Waist-Mounted IMU",
            "updated": "2023-10-19T18:55:10Z",
            "published": "2023-10-19T18:55:10Z",
            "summary": "Monitoring the number of jumps for volleyball players during training or a\nmatch can be crucial to prevent injuries, yet the measurement requires\nconsiderable workload and cost using traditional methods such as video\nanalysis. Also, existing methods do not provide accurate differentiation\nbetween different types of jumps. In this study, an unobtrusive system with a\nsingle inertial measurement unit (IMU) on the waist was proposed to recognize\nthe types of volleyball jumps. A Multi-Layer Temporal Convolutional Network\n(MS-TCN) was applied for sample-wise classification. The model was evaluated on\nten volleyball players and twenty-six volleyball players, during a lab session\nwith a fixed protocol of jumping and landing tasks, and during four volleyball\ntraining sessions, respectively. The MS-TCN model achieved better performance\nthan a state-of-the-art deep learning model but with lower computational cost.\nIn the lab sessions, most jump counts showed small differences between the\npredicted jumps and video-annotated jumps, with an overall count showing a\nLimit of Agreement (LoA) of 0.1+-3.40 (r=0.884). For comparison, the proposed\nalgorithm showed slightly worse results than VERT (a commercial jumping\nassessment device) with a LoA of 0.1+-2.08 (r=0.955) but the differences were\nstill within a comparable range. In the training sessions, the recognition of\nthree types of jumps exhibited a mean difference from observation of less than\n10 jumps: block, smash, and overhead serve. These results showed the potential\nof using a single IMU to recognize the types of volleyball jumps. The\nsample-wise architecture provided high resolution of recognition and the MS-TCN\nrequired fewer parameters to train compared with state-of-the-art models.",
            "author": [
                "Meng Shang",
                "Camilla De Bleecker",
                "Jos Vanrenterghem",
                "Roel De Ridder",
                "Sabine Verschueren",
                "Carolina Varon",
                "Walter De Raedt",
                "Bart Vanrumste"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13097v1",
                "http://arxiv.org/pdf/2310.13097v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13092v1",
            "title": "Do Language Models Learn about Legal Entity Types during Pretraining?",
            "updated": "2023-10-19T18:47:21Z",
            "published": "2023-10-19T18:47:21Z",
            "summary": "Language Models (LMs) have proven their ability to acquire diverse linguistic\nknowledge during the pretraining phase, potentially serving as a valuable\nsource of incidental supervision for downstream tasks. However, there has been\nlimited research conducted on the retrieval of domain-specific knowledge, and\nspecifically legal knowledge. We propose to explore the task of Entity Typing,\nserving as a proxy for evaluating legal knowledge as an essential aspect of\ntext comprehension, and a foundational task to numerous downstream legal NLP\napplications. Through systematic evaluation and analysis and two types of\nprompting (cloze sentences and QA-based templates) and to clarify the nature of\nthese acquired cues, we compare diverse types and lengths of entities both\ngeneral and domain-specific entities, semantics or syntax signals, and\ndifferent LM pretraining corpus (generic and legal-oriented) and architectures\n(encoder BERT-based and decoder-only with Llama2). We show that (1) Llama2\nperforms well on certain entities and exhibits potential for substantial\nimprovement with optimized prompt templates, (2) law-oriented LMs show\ninconsistent performance, possibly due to variations in their training corpus,\n(3) LMs demonstrate the ability to type entities even in the case of\nmulti-token entities, (4) all models struggle with entities belonging to\nsub-domains of the law (5) Llama2 appears to frequently overlook syntactic\ncues, a shortcoming less present in BERT-based architectures.",
            "author": [
                "Claire Barale",
                "Michael Rovatsos",
                "Nehal Bhuta"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13092v1",
                "http://arxiv.org/pdf/2310.13092v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13088v1",
            "title": "Sequence Length Independent Norm-Based Generalization Bounds for\n  Transformers",
            "updated": "2023-10-19T18:31:09Z",
            "published": "2023-10-19T18:31:09Z",
            "summary": "This paper provides norm-based generalization bounds for the Transformer\narchitecture that do not depend on the input sequence length. We employ a\ncovering number based approach to prove our bounds. We use three novel covering\nnumber bounds for the function class of bounded linear transformations to upper\nbound the Rademacher complexity of the Transformer. Furthermore, we show this\ngeneralization bound applies to the common Transformer training technique of\nmasking and then predicting the masked word. We also run a simulated study on a\nsparse majority data set that empirically validates our theoretical findings.",
            "author": [
                "Jacob Trauger",
                "Ambuj Tewari"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13088v1",
                "http://arxiv.org/pdf/2310.13088v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13085v1",
            "title": "Unsupervised Representation Learning to Aid Semi-Supervised Meta\n  Learning",
            "updated": "2023-10-19T18:25:22Z",
            "published": "2023-10-19T18:25:22Z",
            "summary": "Few-shot learning or meta-learning leverages the data scarcity problem in\nmachine learning. Traditionally, training data requires a multitude of samples\nand labeling for supervised learning. To address this issue, we propose a\none-shot unsupervised meta-learning to learn the latent representation of the\ntraining samples. We use augmented samples as the query set during the training\nphase of the unsupervised meta-learning. A temperature-scaled cross-entropy\nloss is used in the inner loop of meta-learning to prevent overfitting during\nunsupervised learning. The learned parameters from this step are applied to the\ntargeted supervised meta-learning in a transfer-learning fashion for\ninitialization and fast adaptation with improved accuracy. The proposed method\nis model agnostic and can aid any meta-learning model to improve accuracy. We\nuse model agnostic meta-learning (MAML) and relation network (RN) on Omniglot\nand mini-Imagenet datasets to demonstrate the performance of the proposed\nmethod. Furthermore, a meta-learning model with the proposed initialization can\nachieve satisfactory accuracy with significantly fewer training samples.",
            "author": [
                "Atik Faysal",
                "Mohammad Rostami",
                "Huaxia Wang",
                "Avimanyu Sahoo",
                "Ryan Antle"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13085v1",
                "http://arxiv.org/pdf/2310.13085v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13083v1",
            "title": "How Can Everyday Users Efficiently Teach Robots by Demonstrations?",
            "updated": "2023-10-19T18:21:39Z",
            "published": "2023-10-19T18:21:39Z",
            "summary": "Learning from Demonstration (LfD) is a framework that allows lay users to\neasily program robots. However, the efficiency of robot learning and the\nrobot's ability to generalize to task variations hinges upon the quality and\nquantity of the provided demonstrations. Our objective is to guide human\nteachers to furnish more effective demonstrations, thus facilitating efficient\nrobot learning. To achieve this, we propose to use a measure of uncertainty,\nnamely task-related information entropy, as a criterion for suggesting\ninformative demonstration examples to human teachers to improve their teaching\nskills. In a conducted experiment (N=24), an augmented reality (AR)-based\nguidance system was employed to train novice users to produce additional\ndemonstrations from areas with the highest entropy within the workspace. These\nnovice users were trained for a few trials to teach the robot a generalizable\ntask using a limited number of demonstrations. Subsequently, the users'\nperformance after training was assessed first on the same task (retention) and\nthen on a novel task (transfer) without guidance. The results indicated a\nsubstantial improvement in robot learning efficiency from the teacher's\ndemonstrations, with an improvement of up to 198% observed on the novel task.\nFurthermore, the proposed approach was compared to a state-of-the-art heuristic\nrule and found to improve robot learning efficiency by 210% compared to the\nheuristic rule.",
            "author": [
                "Maram Sakr",
                "Zhikai Zhang",
                "Benjamin Li",
                "Haomiao Zhang",
                "H. F. Machiel Van der Loos",
                "Dana Kulic",
                "Elizabeth Croft"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13083v1",
                "http://arxiv.org/pdf/2310.13083v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13079v1",
            "title": "Critical Path Prioritization Dashboard for Alert-driven Attack Graphs",
            "updated": "2023-10-19T18:16:04Z",
            "published": "2023-10-19T18:16:04Z",
            "summary": "Although intrusion alerts can provide threat intelligence regarding attacker\nstrategies, extracting such intelligence via existing tools is expensive and\ntime-consuming. Earlier work has proposed SAGE, which generates attack graphs\nfrom intrusion alerts using unsupervised sequential machine learning. This\npaper proposes a querying and prioritization-enabled visual analytics dashboard\nfor SAGE. The dashboard has three main components: (i) a Graph Explorer that\npresents a global view of all attacker strategies, (ii) a Timeline Viewer that\ncorrelates attacker actions chronologically, and (iii) a Recommender Matrix\nthat highlights prevalent critical alerts via a MITRE ATT&CK-inspired attack\nstage matrix. We describe the utility of the proposed dashboard using intrusion\nalerts collected from a distributed multi-stage team-based attack scenario. We\nevaluate the utility of the dashboard through a user study. Based on the\nresponses of a small set of security practitioners, we find that the dashboard\nis useful in depicting attacker strategies and attack progression, but can be\nimproved in terms of usability.",
            "author": [
                "S\u00f2nia Leal D\u00edaz",
                "Sergio Pastrana",
                "Azqa Nadeem"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13079v1",
                "http://arxiv.org/pdf/2310.13079v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13077v1",
            "title": "NeuroSMPC: A Neural Network guided Sampling Based MPC for On-Road\n  Autonomous Driving",
            "updated": "2023-10-19T18:15:20Z",
            "published": "2023-10-19T18:15:20Z",
            "summary": "In this paper we show an effective means of integrating data driven\nframeworks to sampling based optimal control to vastly reduce the compute time\nfor easy adoption and adaptation to real time applications such as on-road\nautonomous driving in the presence of dynamic actors. Presented with training\nexamples, a spatio-temporal CNN learns to predict the optimal mean control over\na finite horizon that precludes further resampling, an iterative process that\nmakes sampling based optimal control formulations difficult to adopt in real\ntime settings. Generating control samples around the network-predicted optimal\nmean retains the advantage of sample diversity while enabling real time rollout\nof trajectories that avoids multiple dynamic obstacles in an on-road navigation\nsetting. Further the 3D CNN architecture implicitly learns the future\ntrajectories of the dynamic agents in the scene resulting in successful\ncollision free navigation despite no explicit future trajectory prediction. We\nshow performance gain over multiple baselines in a number of on-road scenes\nthrough closed loop simulations in CARLA. We also showcase the real world\napplicability of our system by running it on our custom Autonomous Driving\nPlatform (AutoDP).",
            "author": [
                "Kaustab Pal",
                "Aditya Sharma",
                "Mohd Omama",
                "Parth N. Shah",
                "K. Madhava Krishna"
            ],
            "link": [
                "http://dx.doi.org/10.1109/CASE56687.2023.10260513",
                "http://arxiv.org/abs/2310.13077v1",
                "http://arxiv.org/pdf/2310.13077v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13075v1",
            "title": "On the Computational Complexities of Complex-valued Neural Networks",
            "updated": "2023-10-19T18:14:04Z",
            "published": "2023-10-19T18:14:04Z",
            "summary": "Complex-valued neural networks (CVNNs) are nonlinear filters used in the\ndigital signal processing of complex-domain data. Compared with real-valued\nneural networks~(RVNNs), CVNNs can directly handle complex-valued input and\noutput signals due to their complex domain parameters and activation functions.\nWith the trend toward low-power systems, computational complexity analysis has\nbecome essential for measuring an algorithm's power consumption. Therefore,\nthis paper presents both the quantitative and asymptotic computational\ncomplexities of CVNNs. This is a crucial tool in deciding which algorithm to\nimplement. The mathematical operations are described in terms of the number of\nreal-valued multiplications, as these are the most demanding operations. To\ndetermine which CVNN can be implemented in a low-power system, quantitative\ncomputational complexities can be used to accurately estimate the number of\nfloating-point operations. We have also investigated the computational\ncomplexities of CVNNs discussed in some studies presented in the literature.",
            "author": [
                "Kayol Soares Mayer",
                "Jonathan Aguiar Soares",
                "Ariadne Arrais Cruz",
                "Dalton Soares Arantes"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13075v1",
                "http://arxiv.org/pdf/2310.13075v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE",
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13073v1",
            "title": "Using Logic Programming and Kernel-Grouping for Improving\n  Interpretability of Convolutional Neural Networks",
            "updated": "2023-10-19T18:12:49Z",
            "published": "2023-10-19T18:12:49Z",
            "summary": "Within the realm of deep learning, the interpretability of Convolutional\nNeural Networks (CNNs), particularly in the context of image classification\ntasks, remains a formidable challenge. To this end we present a neurosymbolic\nframework, NeSyFOLD-G that generates a symbolic rule-set using the last layer\nkernels of the CNN to make its underlying knowledge interpretable. What makes\nNeSyFOLD-G different from other similar frameworks is that we first find groups\nof similar kernels in the CNN (kernel-grouping) using the cosine-similarity\nbetween the feature maps generated by various kernels. Once such kernel groups\nare found, we binarize each kernel group's output in the CNN and use it to\ngenerate a binarization table which serves as input data to FOLD-SE-M which is\na Rule Based Machine Learning (RBML) algorithm. FOLD-SE-M then generates a\nrule-set that can be used to make predictions. We present a novel kernel\ngrouping algorithm and show that grouping similar kernels leads to a\nsignificant reduction in the size of the rule-set generated by FOLD-SE-M,\nconsequently, improving the interpretability. This rule-set symbolically\nencapsulates the connectionist knowledge of the trained CNN. The rule-set can\nbe viewed as a normal logic program wherein each predicate's truth value\ndepends on a kernel group in the CNN. Each predicate in the rule-set is mapped\nto a concept using a few semantic segmentation masks of the images used for\ntraining, to make it human-understandable. The last layers of the CNN can then\nbe replaced by this rule-set to obtain the NeSy-G model which can then be used\nfor the image classification task. The goal directed ASP system s(CASP) can be\nused to obtain the justification of any prediction made using the NeSy-G model.\nWe also propose a novel algorithm for labeling each predicate in the rule-set\nwith the semantic concept(s) that its corresponding kernel group represents.",
            "author": [
                "Parth Padalkar",
                "Gopal Gupta"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13073v1",
                "http://arxiv.org/pdf/2310.13073v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13072v1",
            "title": "Reinforcement Learning in Control Theory: A New Approach to Mathematical\n  Problem Solving",
            "updated": "2023-10-19T18:12:12Z",
            "published": "2023-10-19T18:12:12Z",
            "summary": "One of the central questions in control theory is achieving stability through\nfeedback control. This paper introduces a novel approach that combines\nReinforcement Learning (RL) with mathematical analysis to address this\nchallenge, with a specific focus on the Sterile Insect Technique (SIT) system.\nThe objective is to find a feedback control that stabilizes the mosquito\npopulation model. Despite the mathematical complexities and the absence of\nknown solutions for this specific problem, our RL approach identifies a\ncandidate solution for an explicit stabilizing control. This study underscores\nthe synergy between AI and mathematics, opening new avenues for tackling\nintricate mathematical problems.",
            "author": [
                "Kala Agbo Bidi",
                "Jean-Michel Coron",
                "Amaury Hayat",
                "Nathan Lichtl\u00e9"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13072v1",
                "http://arxiv.org/pdf/2310.13072v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "93B52, 49N35, 37N25,",
                "I.2.6; I.2.8"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13065v1",
            "title": "Creative Robot Tool Use with Large Language Models",
            "updated": "2023-10-19T18:02:15Z",
            "published": "2023-10-19T18:02:15Z",
            "summary": "Tool use is a hallmark of advanced intelligence, exemplified in both animal\nbehavior and robotic capabilities. This paper investigates the feasibility of\nimbuing robots with the ability to creatively use tools in tasks that involve\nimplicit physical constraints and long-term planning. Leveraging Large Language\nModels (LLMs), we develop RoboTool, a system that accepts natural language\ninstructions and outputs executable code for controlling robots in both\nsimulated and real-world environments. RoboTool incorporates four pivotal\ncomponents: (i) an \"Analyzer\" that interprets natural language to discern key\ntask-related concepts, (ii) a \"Planner\" that generates comprehensive strategies\nbased on the language input and key concepts, (iii) a \"Calculator\" that\ncomputes parameters for each skill, and (iv) a \"Coder\" that translates these\nplans into executable Python code. Our results show that RoboTool can not only\ncomprehend explicit or implicit physical constraints and environmental factors\nbut also demonstrate creative tool use. Unlike traditional Task and Motion\nPlanning (TAMP) methods that rely on explicit optimization, our LLM-based\nsystem offers a more flexible, efficient, and user-friendly solution for\ncomplex robotics tasks. Through extensive experiments, we validate that\nRoboTool is proficient in handling tasks that would otherwise be infeasible\nwithout the creative use of tools, thereby expanding the capabilities of\nrobotic systems. Demos are available on our project page:\nhttps://creative-robotool.github.io/.",
            "author": [
                "Mengdi Xu",
                "Peide Huang",
                "Wenhao Yu",
                "Shiqi Liu",
                "Xilun Zhang",
                "Yaru Niu",
                "Tingnan Zhang",
                "Fei Xia",
                "Jie Tan",
                "Ding Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13065v1",
                "http://arxiv.org/pdf/2310.13065v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13061v1",
            "title": "To grok or not to grok: Disentangling generalization and memorization on\n  corrupted algorithmic datasets",
            "updated": "2023-10-19T18:01:10Z",
            "published": "2023-10-19T18:01:10Z",
            "summary": "Robust generalization is a major challenge in deep learning, particularly\nwhen the number of trainable parameters is very large. In general, it is very\ndifficult to know if the network has memorized a particular set of examples or\nunderstood the underlying rule (or both). Motivated by this challenge, we study\nan interpretable model where generalizing representations are understood\nanalytically, and are easily distinguishable from the memorizing ones. Namely,\nwe consider two-layer neural networks trained on modular arithmetic tasks where\n($\\xi \\cdot 100\\%$) of labels are corrupted (\\emph{i.e.} some results of the\nmodular operations in the training set are incorrect). We show that (i) it is\npossible for the network to memorize the corrupted labels \\emph{and} achieve\n$100\\%$ generalization at the same time; (ii) the memorizing neurons can be\nidentified and pruned, lowering the accuracy on corrupted data and improving\nthe accuracy on uncorrupted data; (iii) regularization methods such as weight\ndecay, dropout and BatchNorm force the network to ignore the corrupted data\nduring optimization, and achieve $100\\%$ accuracy on the uncorrupted dataset;\nand (iv) the effect of these regularization methods is (``mechanistically'')\ninterpretable: weight decay and dropout force all the neurons to learn\ngeneralizing representations, while BatchNorm de-amplifies the output of\nmemorizing neurons and amplifies the output of the generalizing ones. Finally,\nwe show that in the presence of regularization, the training dynamics involves\ntwo consecutive stages: first, the network undergoes the \\emph{grokking}\ndynamics reaching high train \\emph{and} test accuracy; second, it unlearns the\nmemorizing representations, where train accuracy suddenly jumps from $100\\%$ to\n$100 (1-\\xi)\\%$.",
            "author": [
                "Darshil Doshi",
                "Aritra Das",
                "Tianyu He",
                "Andrey Gromov"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13061v1",
                "http://arxiv.org/pdf/2310.13061v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cond-mat.dis-nn",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13057v2",
            "title": "Anomaly Detection in Presence of Irrelevant Features",
            "updated": "2023-11-15T02:25:43Z",
            "published": "2023-10-19T18:00:05Z",
            "summary": "Experiments at particle colliders are the primary source of insight into\nphysics at microscopic scales. Searches at these facilities often rely on\noptimization of analyses targeting specific models of new physics.\nIncreasingly, however, data-driven model-agnostic approaches based on machine\nlearning are also being explored. A major challenge is that such methods can be\nhighly sensitive to the presence of many irrelevant features in the data. This\npaper presents Boosted Decision Tree (BDT)-based techniques to improve anomaly\ndetection in the presence of many irrelevant features. First, a BDT classifier\nis shown to be more robust than neural networks for the Classification Without\nLabels approach to finding resonant excesses assuming independence of resonant\nand non-resonant observables. Next, a tree-based probability density estimator\nusing copula transformations demonstrates significant stability and improved\nperformance over normalizing flows as irrelevant features are added. The\nresults make a compelling case for further development of tree-based algorithms\nfor more robust resonant anomaly detection in high energy physics.",
            "author": [
                "Marat Freytsis",
                "Maxim Perelstein",
                "Yik Chuen San"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13057v2",
                "http://arxiv.org/pdf/2310.13057v2"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13056v1",
            "title": "JWST uncovers helium and water abundance variations in the bulge\n  globular cluster NGC 6440",
            "updated": "2023-10-19T18:00:03Z",
            "published": "2023-10-19T18:00:03Z",
            "summary": "We used ultra-deep observations obtained with the NIRCam aboard the James\nWebb Space Telescope to explore the stellar population of NGC 6440: a typical\nmassive, obscured and contaminated globular cluster formed and orbiting within\nthe Galactic bulge. Leveraging the exceptional capabilities of this camera, we\nsampled the cluster down to ~5 magnitudes below the main-sequence turn-off in\nthe (mF115W , mF115W - mF200W ) colour-magnitude diagram. After carefully\naccounting for differential extinction and contamination by field interlopers,\nwe find that the main sequence splits into two branches both above and below\nthe characteristic knee. By comparing the morphology of the colour-magnitude\ndiagram with a suitable set of isochrones, we argue that the upper\nmain-sequence bi-modality is likely due to the presence of a He-enriched\nstellar population with a helium spread of DeltaY = 0.04. The lower\nmain-sequence bi-modality can be attributed to variations in the abundance of\nwater (i.e., oxygen) with Delta[O/Fe] ~ -0.4. This is the first evidence of\nboth helium and oxygen abundance variations in a globular cluster purely based\non JWST observations. These results open the window for future in-depth\ninvestigations of the multiple population phenomenon in clusters located in the\nGalactic bulge, which were previously unfeasible with near-UV observations, due\nto prohibitive reddening and crowding conditions.",
            "author": [
                "Mario Cadelano",
                "Cristina Pallanca",
                "Emanuele Dalessandro",
                "Maurizio Salaris",
                "Alessio Mucciarelli",
                "Silvia Leanza",
                "Francesco R. Ferraro",
                "Barbara Lanzoni",
                "Rosie H. Chen",
                "Paulo C. C. Freire",
                "Craig Heinke",
                "Scott M. Ransom"
            ],
            "link": [
                "http://dx.doi.org/10.1051/0004-6361/202347961",
                "http://arxiv.org/abs/2310.13056v1",
                "http://arxiv.org/pdf/2310.13056v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13048v1",
            "title": "Detection of Accretion Shelves Out to the Virial Radius of a Low-Mass\n  Galaxy with JWST",
            "updated": "2023-10-19T18:00:01Z",
            "published": "2023-10-19T18:00:01Z",
            "summary": "We report the serendipitous discovery of an extended stellar halo surrounding\nthe low-mass galaxy Ark 227 ($M_\\ast=5\\times10^9 M_\\odot$; d=35 Mpc) in deep\nJWST NIRCam imaging from the Blue Jay Survey. The F200W-F444W color provides\nrobust star-galaxy separation, enabling the identification of stars at very low\ndensity. By combining resolved stars at large galactocentric distances with\ndiffuse emission from NIRCam and Dragonfly imaging at smaller distances, we\ntrace the surface brightness and color profiles of this galaxy over the entire\nextent of its predicted dark matter halo, from 0.1-100 kpc. Controlled N-body\nsimulations have predicted that minor mergers create \"accretion shelves\" in the\nsurface brightness profile at large radius. We observe such a feature in Ark\n227 at 10-20 kpc, which, according to models, could be caused by a merger with\ntotal mass ratio 1:10. The metallicity declines over this radial range, further\nsupporting the minor merger scenario. There is tentative evidence of a second\nshelf at $\\mu_V\\approx 35$ mag arcsec$^{-2}$ extending from 50-100 kpc, along\nwith a corresponding drop in metallicity. The stellar mass in this outermost\nenvelope is $\\approx10^7M_\\odot$. These results suggest that Ark 227\nexperienced multiple mergers with a spectrum of lower-mass galaxies -- a\nscenario that is broadly consistent with the hierarchical growth of structure\nin a cold dark matter-dominated universe. Finally, we identify an ultra-faint\ndwarf associated with Ark 227 with $M_\\ast\\approx10^5 M_\\odot$ and\n$\\mu_{V,e}=28.1$ mag arcsec$^{-2}$, demonstrating that JWST is capable of\ndetecting very low-mass dwarfs to distances of at least ~30 Mpc.",
            "author": [
                "Charlie Conroy",
                "Benjamin D. Johnson",
                "Pieter van Dokkum",
                "Alis Deason",
                "Sandro Tacchella",
                "Sirio Belli",
                "William P. Bowman",
                "Rohan P. Naidu",
                "Minjung Park",
                "Roberto Abraham",
                "Razieh Emami"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13048v1",
                "http://arxiv.org/pdf/2310.13048v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12979v2",
            "title": "Predicting a Protein's Stability under a Million Mutations",
            "updated": "2023-10-30T19:45:12Z",
            "published": "2023-10-19T17:59:47Z",
            "summary": "Stabilizing proteins is a foundational step in protein engineering. However,\nthe evolutionary pressure of all extant proteins makes identifying the scarce\nnumber of mutations that will improve thermodynamic stability challenging. Deep\nlearning has recently emerged as a powerful tool for identifying promising\nmutations. Existing approaches, however, are computationally expensive, as the\nnumber of model inferences scales with the number of mutations queried. Our\nmain contribution is a simple, parallel decoding algorithm. Our Mutate\nEverything is capable of predicting the effect of all single and double\nmutations in one forward pass. It is even versatile enough to predict\nhigher-order mutations with minimal computational overhead. We build Mutate\nEverything on top of ESM2 and AlphaFold, neither of which were trained to\npredict thermodynamic stability. We trained on the Mega-Scale cDNA proteolysis\ndataset and achieved state-of-the-art performance on single and higher-order\nmutations on S669, ProTherm, and ProteinGym datasets. Code is available at\nhttps://github.com/jozhang97/MutateEverything",
            "author": [
                "Jeffrey Ouyang-Zhang",
                "Daniel J. Diaz",
                "Adam R. Klivans",
                "Philipp Kr\u00e4henb\u00fchl"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12979v2",
                "http://arxiv.org/pdf/2310.12979v2"
            ],
            "primary_category": "q-bio.BM",
            "category": [
                "q-bio.BM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12977v1",
            "title": "Training Dynamics of Deep Network Linear Regions",
            "updated": "2023-10-19T17:59:44Z",
            "published": "2023-10-19T17:59:44Z",
            "summary": "The study of Deep Network (DN) training dynamics has largely focused on the\nevolution of the loss function, evaluated on or around train and test set data\npoints. In fact, many DN phenomenon were first introduced in literature with\nthat respect, e.g., double descent, grokking. In this study, we look at the\ntraining dynamics of the input space partition or linear regions formed by\ncontinuous piecewise affine DNs, e.g., networks with (leaky)ReLU\nnonlinearities. First, we present a novel statistic that encompasses the local\ncomplexity (LC) of the DN based on the concentration of linear regions inside\narbitrary dimensional neighborhoods around data points. We observe that during\ntraining, the LC around data points undergoes a number of phases, starting with\na decreasing trend after initialization, followed by an ascent and ending with\na final descending trend. Using exact visualization methods, we come across the\nperplexing observation that during the final LC descent phase of training,\nlinear regions migrate away from training and test samples towards the decision\nboundary, making the DN input-output nearly linear everywhere else. We also\nobserve that the different LC phases are closely related to the memorization\nand generalization performance of the DN, especially during grokking.",
            "author": [
                "Ahmed Imtiaz Humayun",
                "Randall Balestriero",
                "Richard Baraniuk"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12977v1",
                "http://arxiv.org/pdf/2310.12977v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12976v1",
            "title": "On the Hidden Waves of Image",
            "updated": "2023-10-19T17:59:37Z",
            "published": "2023-10-19T17:59:37Z",
            "summary": "In this paper, we introduce an intriguing phenomenon-the successful\nreconstruction of images using a set of one-way wave equations with hidden and\nlearnable speeds. Each individual image corresponds to a solution with a unique\ninitial condition, which can be computed from the original image using a visual\nencoder (e.g., a convolutional neural network). Furthermore, the solution for\neach image exhibits two noteworthy mathematical properties: (a) it can be\ndecomposed into a collection of special solutions of the same one-way wave\nequations that are first-order autoregressive, with shared coefficient matrices\nfor autoregression, and (b) the product of these coefficient matrices forms a\ndiagonal matrix with the speeds of the wave equations as its diagonal elements.\nWe term this phenomenon hidden waves, as it reveals that, although the speeds\nof the set of wave equations and autoregressive coefficient matrices are\nlatent, they are both learnable and shared across images. This represents a\nmathematical invariance across images, providing a new mathematical perspective\nto understand images.",
            "author": [
                "Yinpeng Chen",
                "Dongdong Chen",
                "Xiyang Dai",
                "Mengchen Liu",
                "Lu Yuan",
                "Zicheng Liu",
                "Youzuo Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12976v1",
                "http://arxiv.org/pdf/2310.12976v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12975v1",
            "title": "Variational Inference for SDEs Driven by Fractional Noise",
            "updated": "2023-10-19T17:59:21Z",
            "published": "2023-10-19T17:59:21Z",
            "summary": "We present a novel variational framework for performing inference in (neural)\nstochastic differential equations (SDEs) driven by Markov-approximate\nfractional Brownian motion (fBM). SDEs offer a versatile tool for modeling\nreal-world continuous-time dynamic systems with inherent noise and randomness.\nCombining SDEs with the powerful inference capabilities of variational methods,\nenables the learning of representative function distributions through\nstochastic gradient descent. However, conventional SDEs typically assume the\nunderlying noise to follow a Brownian motion (BM), which hinders their ability\nto capture long-term dependencies. In contrast, fractional Brownian motion\n(fBM) extends BM to encompass non-Markovian dynamics, but existing methods for\ninferring fBM parameters are either computationally demanding or statistically\ninefficient. In this paper, building upon the Markov approximation of fBM, we\nderive the evidence lower bound essential for efficient variational inference\nof posterior path measures, drawing from the well-established field of\nstochastic analysis. Additionally, we provide a closed-form expression to\ndetermine optimal approximation coefficients. Furthermore, we propose the use\nof neural networks to learn the drift, diffusion and control terms within our\nvariational posterior, leading to the variational training of neural-SDEs. In\nthis framework, we also optimize the Hurst index, governing the nature of our\nfractional noise. Beyond validation on synthetic data, we contribute a novel\narchitecture for variational latent video prediction,-an approach that, to the\nbest of our knowledge, enables the first variational neural-SDE application to\nvideo perception.",
            "author": [
                "Rembert Daems",
                "Manfred Opper",
                "Guillaume Crevecoeur",
                "Tolga Birdal"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12975v1",
                "http://arxiv.org/pdf/2310.12975v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV",
                "stat.AP",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13040v1",
            "title": "Robust multimodal models have outlier features and encode more concepts",
            "updated": "2023-10-19T17:59:12Z",
            "published": "2023-10-19T17:59:12Z",
            "summary": "What distinguishes robust models from non-robust ones? This question has\ngained traction with the appearance of large-scale multimodal models, such as\nCLIP. These models have demonstrated unprecedented robustness with respect to\nnatural distribution shifts. While it has been shown that such differences in\nrobustness can be traced back to differences in training data, so far it is not\nknown what that translates to in terms of what the model has learned. In this\nwork, we bridge this gap by probing the representation spaces of 12 robust\nmultimodal models with various backbones (ResNets and ViTs) and pretraining\nsets (OpenAI, LAION-400M, LAION-2B, YFCC15M, CC12M and DataComp). We find two\nsignatures of robustness in the representation spaces of these models: (1)\nRobust models exhibit outlier features characterized by their activations, with\nsome being several orders of magnitude above average. These outlier features\ninduce privileged directions in the model's representation space. We\ndemonstrate that these privileged directions explain most of the predictive\npower of the model by pruning up to $80 \\%$ of the least important\nrepresentation space directions without negative impacts on model accuracy and\nrobustness; (2) Robust models encode substantially more concepts in their\nrepresentation space. While this superposition of concepts allows robust models\nto store much information, it also results in highly polysemantic features,\nwhich makes their interpretation challenging. We discuss how these insights\npave the way for future research in various fields, such as model pruning and\nmechanistic interpretability.",
            "author": [
                "Jonathan Crabb\u00e9",
                "Pau Rodr\u00edguez",
                "Vaishaal Shankar",
                "Luca Zappella",
                "Arno Blaas"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13040v1",
                "http://arxiv.org/pdf/2310.13040v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12974v1",
            "title": "FSD: Fast Self-Supervised Single RGB-D to Categorical 3D Objects",
            "updated": "2023-10-19T17:59:09Z",
            "published": "2023-10-19T17:59:09Z",
            "summary": "In this work, we address the challenging task of 3D object recognition\nwithout the reliance on real-world 3D labeled data. Our goal is to predict the\n3D shape, size, and 6D pose of objects within a single RGB-D image, operating\nat the category level and eliminating the need for CAD models during inference.\nWhile existing self-supervised methods have made strides in this field, they\noften suffer from inefficiencies arising from non-end-to-end processing,\nreliance on separate models for different object categories, and slow surface\nextraction during the training of implicit reconstruction models; thus\nhindering both the speed and real-world applicability of the 3D recognition\nprocess. Our proposed method leverages a multi-stage training pipeline,\ndesigned to efficiently transfer synthetic performance to the real-world\ndomain. This approach is achieved through a combination of 2D and 3D supervised\nlosses during the synthetic domain training, followed by the incorporation of\n2D supervised and 3D self-supervised losses on real-world data in two\nadditional learning stages. By adopting this comprehensive strategy, our method\nsuccessfully overcomes the aforementioned limitations and outperforms existing\nself-supervised 6D pose and size estimation baselines on the NOCS test-set with\na 16.4% absolute improvement in mAP for 6D pose estimation while running in\nnear real-time at 5 Hz.",
            "author": [
                "Mayank Lunayach",
                "Sergey Zakharov",
                "Dian Chen",
                "Rares Ambrus",
                "Zsolt Kira",
                "Muhammad Zubair Irshad"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12974v1",
                "http://arxiv.org/pdf/2310.12974v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12973v1",
            "title": "Frozen Transformers in Language Models Are Effective Visual Encoder\n  Layers",
            "updated": "2023-10-19T17:59:05Z",
            "published": "2023-10-19T17:59:05Z",
            "summary": "This paper reveals that large language models (LLMs), despite being trained\nsolely on textual data, are surprisingly strong encoders for purely visual\ntasks in the absence of language. Even more intriguingly, this can be achieved\nby a simple yet previously overlooked strategy -- employing a frozen\ntransformer block from pre-trained LLMs as a constituent encoder layer to\ndirectly process visual tokens. Our work pushes the boundaries of leveraging\nLLMs for computer vision tasks, significantly departing from conventional\npractices that typically necessitate a multi-modal vision-language setup with\nassociated language prompts, inputs, or outputs. We demonstrate that our\napproach consistently enhances performance across a diverse range of tasks,\nencompassing pure 2D and 3D visual recognition tasks (e.g., image and point\ncloud classification), temporal modeling tasks (e.g., action recognition),\nnon-semantic tasks (e.g., motion forecasting), and multi-modal tasks (e.g.,\n2D/3D visual question answering and image-text retrieval). Such improvements\nare a general phenomenon, applicable to various types of LLMs (e.g., LLaMA and\nOPT) and different LLM transformer blocks. We additionally propose the\ninformation filtering hypothesis to explain the effectiveness of pre-trained\nLLMs in visual encoding -- the pre-trained LLM transformer blocks discern\ninformative visual tokens and further amplify their effect. This hypothesis is\nempirically supported by the observation that the feature activation, after\ntraining with LLM transformer blocks, exhibits a stronger focus on relevant\nregions. We hope that our work inspires new perspectives on utilizing LLMs and\ndeepening our understanding of their underlying mechanisms. Code is available\nat https://github.com/ziqipang/LM4VisualEncoding.",
            "author": [
                "Ziqi Pang",
                "Ziyang Xie",
                "Yunze Man",
                "Yu-Xiong Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12973v1",
                "http://arxiv.org/pdf/2310.12973v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13039v1",
            "title": "Human Pose-based Estimation, Tracking and Action Recognition with Deep\n  Learning: A Survey",
            "updated": "2023-10-19T17:59:04Z",
            "published": "2023-10-19T17:59:04Z",
            "summary": "Human pose analysis has garnered significant attention within both the\nresearch community and practical applications, owing to its expanding array of\nuses, including gaming, video surveillance, sports performance analysis, and\nhuman-computer interactions, among others. The advent of deep learning has\nsignificantly improved the accuracy of pose capture, making pose-based\napplications increasingly practical. This paper presents a comprehensive survey\nof pose-based applications utilizing deep learning, encompassing pose\nestimation, pose tracking, and action recognition.Pose estimation involves the\ndetermination of human joint positions from images or image sequences. Pose\ntracking is an emerging research direction aimed at generating consistent human\npose trajectories over time. Action recognition, on the other hand, targets the\nidentification of action types using pose estimation or tracking data. These\nthree tasks are intricately interconnected, with the latter often reliant on\nthe former. In this survey, we comprehensively review related works, spanning\nfrom single-person pose estimation to multi-person pose estimation, from 2D\npose estimation to 3D pose estimation, from single image to video, from mining\ntemporal context gradually to pose tracking, and lastly from tracking to\npose-based action recognition. As a survey centered on the application of deep\nlearning to pose analysis, we explicitly discuss both the strengths and\nlimitations of existing techniques. Notably, we emphasize methodologies for\nintegrating these three tasks into a unified framework within video sequences.\nAdditionally, we explore the challenges involved and outline potential\ndirections for future research.",
            "author": [
                "Lijuan Zhou",
                "Xiang Meng",
                "Zhihuan Liu",
                "Mengqi Wu",
                "Zhimin Gao",
                "Pichao Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13039v1",
                "http://arxiv.org/pdf/2310.13039v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12972v1",
            "title": "CCIL: Continuity-based Data Augmentation for Corrective Imitation\n  Learning",
            "updated": "2023-10-19T17:59:03Z",
            "published": "2023-10-19T17:59:03Z",
            "summary": "We present a new technique to enhance the robustness of imitation learning\nmethods by generating corrective data to account for compounding errors and\ndisturbances. While existing methods rely on interactive expert labeling,\nadditional offline datasets, or domain-specific invariances, our approach\nrequires minimal additional assumptions beyond access to expert data. The key\ninsight is to leverage local continuity in the environment dynamics to generate\ncorrective labels. Our method first constructs a dynamics model from the expert\ndemonstration, encouraging local Lipschitz continuity in the learned model. In\nlocally continuous regions, this model allows us to generate corrective labels\nwithin the neighborhood of the demonstrations but beyond the actual set of\nstates and actions in the dataset. Training on this augmented data enhances the\nagent's ability to recover from perturbations and deal with compounding errors.\nWe demonstrate the effectiveness of our generated labels through experiments in\na variety of robotics domains in simulation that have distinct forms of\ncontinuity and discontinuity, including classic control problems, drone flying,\nnavigation with high-dimensional sensor observations, legged locomotion, and\ntabletop manipulation.",
            "author": [
                "Liyiming Ke",
                "Yunchu Zhang",
                "Abhay Deshpande",
                "Siddhartha Srinivasa",
                "Abhishek Gupta"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12972v1",
                "http://arxiv.org/pdf/2310.12972v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12969v1",
            "title": "Demystifying the Myths and Legends of Nonconvex Convergence of SGD",
            "updated": "2023-10-19T17:58:59Z",
            "published": "2023-10-19T17:58:59Z",
            "summary": "Stochastic gradient descent (SGD) and its variants are the main workhorses\nfor solving large-scale optimization problems with nonconvex objective\nfunctions. Although the convergence of SGDs in the (strongly) convex case is\nwell-understood, their convergence for nonconvex functions stands on weak\nmathematical foundations. Most existing studies on the nonconvex convergence of\nSGD show the complexity results based on either the minimum of the expected\ngradient norm or the functional sub-optimality gap (for functions with extra\nstructural property) by searching the entire range of iterates. Hence the last\niterations of SGDs do not necessarily maintain the same complexity guarantee.\nThis paper shows that an $\\epsilon$-stationary point exists in the final\niterates of SGDs, given a large enough total iteration budget, $T$, not just\nanywhere in the entire range of iterates -- a much stronger result than the\nexisting one. Additionally, our analyses allow us to measure the density of the\n$\\epsilon$-stationary points in the final iterates of SGD, and we recover the\nclassical $O(\\frac{1}{\\sqrt{T}})$ asymptotic rate under various existing\nassumptions on the objective function and the bounds on the stochastic\ngradient. As a result of our analyses, we addressed certain myths and legends\nrelated to the nonconvex convergence of SGD and posed some thought-provoking\nquestions that could set new directions for research.",
            "author": [
                "Aritra Dutta",
                "El Houcine Bergou",
                "Soumia Boucherouite",
                "Nicklas Werge",
                "Melih Kandemir",
                "Xin Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12969v1",
                "http://arxiv.org/pdf/2310.12969v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NA",
                "math.NA",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12967v1",
            "title": "Does Your Model Think Like an Engineer? Explainable AI for Bearing Fault\n  Detection with Deep Learning",
            "updated": "2023-10-19T17:58:11Z",
            "published": "2023-10-19T17:58:11Z",
            "summary": "Deep Learning has already been successfully applied to analyze industrial\nsensor data in a variety of relevant use cases. However, the opaque nature of\nmany well-performing methods poses a major obstacle for real-world deployment.\nExplainable AI (XAI) and especially feature attribution techniques promise to\nenable insights about how such models form their decision. But the plain\napplication of such methods often fails to provide truly informative and\nproblem-specific insights to domain experts. In this work, we focus on the\nspecific task of detecting faults in rolling element bearings from vibration\nsignals. We propose a novel and domain-specific feature attribution framework\nthat allows us to evaluate how well the underlying logic of a model corresponds\nwith expert reasoning. Utilizing the framework we are able to validate the\ntrustworthiness and to successfully anticipate the generalization ability of\ndifferent well-performing deep learning models. Our methodology demonstrates\nhow signal processing tools can effectively be used to enhance Explainable AI\ntechniques and acts as a template for similar problems.",
            "author": [
                "Thomas Decker",
                "Michael Lebacher",
                "Volker Tresp"
            ],
            "link": [
                "http://dx.doi.org/10.1109/ICASSP49357.2023.10096396",
                "http://arxiv.org/abs/2310.12967v1",
                "http://arxiv.org/pdf/2310.12967v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12964v1",
            "title": "PAC Prediction Sets Under Label Shift",
            "updated": "2023-10-19T17:57:57Z",
            "published": "2023-10-19T17:57:57Z",
            "summary": "Prediction sets capture uncertainty by predicting sets of labels rather than\nindividual labels, enabling downstream decisions to conservatively account for\nall plausible outcomes. Conformal inference algorithms construct prediction\nsets guaranteed to contain the true label with high probability. These\nguarantees fail to hold in the face of distribution shift, which is precisely\nwhen reliable uncertainty quantification can be most useful. We propose a novel\nalgorithm for constructing prediction sets with PAC guarantees in the label\nshift setting. This method estimates the predicted probabilities of the classes\nin a target domain, as well as the confusion matrix, then propagates\nuncertainty in these estimates through a Gaussian elimination algorithm to\ncompute confidence intervals for importance weights. Finally, it uses these\nintervals to construct prediction sets. We evaluate our approach on five\ndatasets: the CIFAR-10, ChestX-Ray and Entity-13 image datasets, the tabular\nCDC Heart dataset, and the AGNews text dataset. Our algorithm satisfies the PAC\nguarantee while producing smaller, more informative, prediction sets compared\nto several baselines.",
            "author": [
                "Wenwen Si",
                "Sangdon Park",
                "Insup Lee",
                "Edgar Dobriban",
                "Osbert Bastani"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12964v1",
                "http://arxiv.org/pdf/2310.12964v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12963v2",
            "title": "AutoMix: Automatically Mixing Language Models",
            "updated": "2023-11-15T18:23:40Z",
            "published": "2023-10-19T17:57:39Z",
            "summary": "Large language models (LLMs) are now available in various sizes and\nconfigurations from cloud API providers. While this diversity offers a broad\nspectrum of choices, effectively leveraging the options to optimize\ncomputational cost and performance remains challenging. In this work, we\npresent AutoMix, an approach that strategically routes queries to larger LMs,\nbased on the approximate correctness of outputs from a smaller LM. Central to\nAutoMix is a few-shot self-verification mechanism, which estimates the\nreliability of its own outputs without requiring training. Given that\nverifications can be noisy, we employ a meta verifier in AutoMix to refine the\naccuracy of these assessments. Our experiments using LLAMA2-13/70B, on five\ncontext-grounded reasoning datasets demonstrate that AutoMix surpasses\nestablished baselines, improving the incremental benefit per cost by up to 89%.\nOur code and data are available at https://github.com/automix-llm/automix.",
            "author": [
                "Aman Madaan",
                "Pranjal Aggarwal",
                "Ankit Anand",
                "Srividya Pranavi Potharaju",
                "Swaroop Mishra",
                "Pei Zhou",
                "Aditya Gupta",
                "Dheeraj Rajagopal",
                "Karthik Kappaganthu",
                "Yiming Yang",
                "Shyam Upadhyay",
                "Mausam",
                "Manaal Faruqui"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12963v2",
                "http://arxiv.org/pdf/2310.12963v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12962v1",
            "title": "An Emulator for Fine-Tuning Large Language Models using Small Language\n  Models",
            "updated": "2023-10-19T17:57:16Z",
            "published": "2023-10-19T17:57:16Z",
            "summary": "Widely used language models (LMs) are typically built by scaling up a\ntwo-stage training pipeline: a pre-training stage that uses a very large,\ndiverse dataset of text and a fine-tuning (sometimes, 'alignment') stage that\nuses targeted examples or other specifications of desired behaviors. While it\nhas been hypothesized that knowledge and skills come from pre-training, and\nfine-tuning mostly filters this knowledge and skillset, this intuition has not\nbeen extensively tested. To aid in doing so, we introduce a novel technique for\ndecoupling the knowledge and skills gained in these two stages, enabling a\ndirect answer to the question, \"What would happen if we combined the knowledge\nlearned by a large model during pre-training with the knowledge learned by a\nsmall model during fine-tuning (or vice versa)?\" Using an RL-based framework\nderived from recent developments in learning from human preferences, we\nintroduce emulated fine-tuning (EFT), a principled and practical method for\nsampling from a distribution that approximates (or 'emulates') the result of\npre-training and fine-tuning at different scales. Our experiments with EFT show\nthat scaling up fine-tuning tends to improve helpfulness, while scaling up\npre-training tends to improve factuality. Beyond decoupling scale, we show that\nEFT enables test-time adjustment of competing behavioral traits like\nhelpfulness and harmlessness without additional training. Finally, a special\ncase of emulated fine-tuning, which we call LM up-scaling, avoids\nresource-intensive fine-tuning of large pre-trained models by ensembling them\nwith small fine-tuned models, essentially emulating the result of fine-tuning\nthe large pre-trained model. Up-scaling consistently improves helpfulness and\nfactuality of instruction-following models in the Llama, Llama-2, and Falcon\nfamilies, without additional hyperparameters or training.",
            "author": [
                "Eric Mitchell",
                "Rafael Rafailov",
                "Archit Sharma",
                "Chelsea Finn",
                "Christopher D. Manning"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12962v1",
                "http://arxiv.org/pdf/2310.12962v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12956v1",
            "title": "Eureka-Moments in Transformers: Multi-Step Tasks Reveal Softmax Induced\n  Optimization Problems",
            "updated": "2023-10-19T17:55:06Z",
            "published": "2023-10-19T17:55:06Z",
            "summary": "In this work, we study rapid, step-wise improvements of the loss in\ntransformers when being confronted with multi-step decision tasks. We found\nthat transformers struggle to learn the intermediate tasks, whereas CNNs have\nno such issue on the tasks we studied. When transformers learn the intermediate\ntask, they do this rapidly and unexpectedly after both training and validation\nloss saturated for hundreds of epochs. We call these rapid improvements\nEureka-moments, since the transformer appears to suddenly learn a previously\nincomprehensible task. Similar leaps in performance have become known as\nGrokking. In contrast to Grokking, for Eureka-moments, both the validation and\nthe training loss saturate before rapidly improving. We trace the problem back\nto the Softmax function in the self-attention block of transformers and show\nways to alleviate the problem. These fixes improve training speed. The improved\nmodels reach 95% of the baseline model in just 20% of training steps while\nhaving a much higher likelihood to learn the intermediate task, lead to higher\nfinal accuracy and are more robust to hyper-parameters.",
            "author": [
                "David T. Hoffmann",
                "Simon Schrodi",
                "Nadine Behrmann",
                "Volker Fischer",
                "Thomas Brox"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12956v1",
                "http://arxiv.org/pdf/2310.12956v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12955v1",
            "title": "Towards Robust Offline Reinforcement Learning under Diverse Data\n  Corruption",
            "updated": "2023-10-19T17:54:39Z",
            "published": "2023-10-19T17:54:39Z",
            "summary": "Offline reinforcement learning (RL) presents a promising approach for\nlearning reinforced policies from offline datasets without the need for costly\nor unsafe interactions with the environment. However, datasets collected by\nhumans in real-world environments are often noisy and may even be maliciously\ncorrupted, which can significantly degrade the performance of offline RL. In\nthis work, we first investigate the performance of current offline RL\nalgorithms under comprehensive data corruption, including states, actions,\nrewards, and dynamics. Our extensive experiments reveal that implicit\nQ-learning (IQL) demonstrates remarkable resilience to data corruption among\nvarious offline RL algorithms. Furthermore, we conduct both empirical and\ntheoretical analyses to understand IQL's robust performance, identifying its\nsupervised policy learning scheme as the key factor. Despite its relative\nrobustness, IQL still suffers from heavy-tail targets of Q functions under\ndynamics corruption. To tackle this challenge, we draw inspiration from robust\nstatistics to employ the Huber loss to handle the heavy-tailedness and utilize\nquantile estimators to balance penalization for corrupted data and learning\nstability. By incorporating these simple yet effective modifications into IQL,\nwe propose a more robust offline RL approach named Robust IQL (RIQL). Extensive\nexperiments demonstrate that RIQL exhibits highly robust performance when\nsubjected to diverse data corruption scenarios.",
            "author": [
                "Rui Yang",
                "Han Zhong",
                "Jiawei Xu",
                "Amy Zhang",
                "Chongjie Zhang",
                "Lei Han",
                "Tong Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12955v1",
                "http://arxiv.org/pdf/2310.12955v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12952v2",
            "title": "Cousins Of The Vendi Score: A Family Of Similarity-Based Diversity\n  Metrics For Science And Machine Learning",
            "updated": "2023-10-23T19:02:02Z",
            "published": "2023-10-19T17:52:04Z",
            "summary": "Measuring diversity accurately is important for many scientific fields,\nincluding machine learning (ML), ecology, and chemistry. The Vendi Score was\nintroduced as a generic similarity-based diversity metric that extends the Hill\nnumber of order q=1 by leveraging ideas from quantum statistical mechanics.\nContrary to many diversity metrics in ecology, the Vendi Score accounts for\nsimilarity and does not require knowledge of the prevalence of the categories\nin the collection to be evaluated for diversity. However, the Vendi Score\ntreats each item in a given collection with a level of sensitivity proportional\nto the item's prevalence. This is undesirable in settings where there is a\nsignificant imbalance in item prevalence. In this paper, we extend the other\nHill numbers using similarity to provide flexibility in allocating sensitivity\nto rare or common items. This leads to a family of diversity metrics -- Vendi\nscores with different levels of sensitivity -- that can be used in a variety of\napplications. We study the properties of the scores in a synthetic controlled\nsetting where the ground truth diversity is known. We then test their utility\nin improving molecular simulations via Vendi Sampling. Finally, we use the\nVendi scores to better understand the behavior of image generative models in\nterms of memorization, duplication, diversity, and sample quality.",
            "author": [
                "Amey P. Pasarkar",
                "Adji Bousso Dieng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12952v2",
                "http://arxiv.org/pdf/2310.12952v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "physics.chem-ph",
                "q-bio.PE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12945v1",
            "title": "3D-GPT: Procedural 3D Modeling with Large Language Models",
            "updated": "2023-10-19T17:41:48Z",
            "published": "2023-10-19T17:41:48Z",
            "summary": "In the pursuit of efficient automated content creation, procedural\ngeneration, leveraging modifiable parameters and rule-based systems, emerges as\na promising approach. Nonetheless, it could be a demanding endeavor, given its\nintricate nature necessitating a deep understanding of rules, algorithms, and\nparameters. To reduce workload, we introduce 3D-GPT, a framework utilizing\nlarge language models~(LLMs) for instruction-driven 3D modeling. 3D-GPT\npositions LLMs as proficient problem solvers, dissecting the procedural 3D\nmodeling tasks into accessible segments and appointing the apt agent for each\ntask. 3D-GPT integrates three core agents: the task dispatch agent, the\nconceptualization agent, and the modeling agent. They collaboratively achieve\ntwo objectives. First, it enhances concise initial scene descriptions, evolving\nthem into detailed forms while dynamically adapting the text based on\nsubsequent instructions. Second, it integrates procedural generation,\nextracting parameter values from enriched text to effortlessly interface with\n3D software for asset creation. Our empirical investigations confirm that\n3D-GPT not only interprets and executes instructions, delivering reliable\nresults but also collaborates effectively with human designers. Furthermore, it\nseamlessly integrates with Blender, unlocking expanded manipulation\npossibilities. Our work highlights the potential of LLMs in 3D modeling,\noffering a basic framework for future advancements in scene generation and\nanimation.",
            "author": [
                "Chunyi Sun",
                "Junlin Han",
                "Weijian Deng",
                "Xinlong Wang",
                "Zishan Qin",
                "Stephen Gould"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12945v1",
                "http://arxiv.org/pdf/2310.12945v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12942v3",
            "title": "On the Representational Capacity of Recurrent Neural Language Models",
            "updated": "2023-11-22T01:39:59Z",
            "published": "2023-10-19T17:39:47Z",
            "summary": "This work investigates the computational expressivity of language models\n(LMs) based on recurrent neural networks (RNNs). Siegelmann and Sontag (1992)\nfamously showed that RNNs with rational weights and hidden states and unbounded\ncomputation time are Turing complete. However, LMs define weightings over\nstrings in addition to just (unweighted) language membership and the analysis\nof the computational power of RNN LMs (RLMs) should reflect this. We extend the\nTuring completeness result to the probabilistic case, showing how a rationally\nweighted RLM with unbounded computation time can simulate any deterministic\nprobabilistic Turing machine (PTM) with rationally weighted transitions. Since,\nin practice, RLMs work in real-time, processing a symbol at every time step, we\ntreat the above result as an upper bound on the expressivity of RLMs. We also\nprovide a lower bound by showing that under the restriction to real-time\ncomputation, such models can simulate deterministic real-time rational PTMs.",
            "author": [
                "Franz Nowak",
                "Anej Svete",
                "Li Du",
                "Ryan Cotterell"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12942v3",
                "http://arxiv.org/pdf/2310.12942v3"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12941v1",
            "title": "The Foundation Model Transparency Index",
            "updated": "2023-10-19T17:39:02Z",
            "published": "2023-10-19T17:39:02Z",
            "summary": "Foundation models have rapidly permeated society, catalyzing a wave of\ngenerative AI applications spanning enterprise and consumer-facing contexts.\nWhile the societal impact of foundation models is growing, transparency is on\nthe decline, mirroring the opacity that has plagued past digital technologies\n(e.g. social media). Reversing this trend is essential: transparency is a vital\nprecondition for public accountability, scientific innovation, and effective\ngovernance. To assess the transparency of the foundation model ecosystem and\nhelp improve transparency over time, we introduce the Foundation Model\nTransparency Index. The Foundation Model Transparency Index specifies 100\nfine-grained indicators that comprehensively codify transparency for foundation\nmodels, spanning the upstream resources used to build a foundation model (e.g\ndata, labor, compute), details about the model itself (e.g. size, capabilities,\nrisks), and the downstream use (e.g. distribution channels, usage policies,\naffected geographies). We score 10 major foundation model developers (e.g.\nOpenAI, Google, Meta) against the 100 indicators to assess their transparency.\nTo facilitate and standardize assessment, we score developers in relation to\ntheir practices for their flagship foundation model (e.g. GPT-4 for OpenAI,\nPaLM 2 for Google, Llama 2 for Meta). We present 10 top-level findings about\nthe foundation model ecosystem: for example, no developer currently discloses\nsignificant information about the downstream impact of its flagship model, such\nas the number of users, affected market sectors, or how users can seek redress\nfor harm. Overall, the Foundation Model Transparency Index establishes the\nlevel of transparency today to drive progress on foundation model governance\nvia industry standards and regulatory intervention.",
            "author": [
                "Rishi Bommasani",
                "Kevin Klyman",
                "Shayne Longpre",
                "Sayash Kapoor",
                "Nestor Maslej",
                "Betty Xiong",
                "Daniel Zhang",
                "Percy Liang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12941v1",
                "http://arxiv.org/pdf/2310.12941v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12937v1",
            "title": "End-to-End Delay Minimization based on Joint Optimization of DNN\n  Partitioning and Resource Allocation for Cooperative Edge Inference",
            "updated": "2023-10-19T17:34:18Z",
            "published": "2023-10-19T17:34:18Z",
            "summary": "Cooperative inference in Mobile Edge Computing (MEC), achieved by deploying\npartitioned Deep Neural Network (DNN) models between resource-constrained user\nequipments (UEs) and edge servers (ESs), has emerged as a promising paradigm.\nFirstly, we consider scenarios of continuous Artificial Intelligence (AI) task\narrivals, like the object detection for video streams, and utilize a serial\nqueuing model for the accurate evaluation of End-to-End (E2E) delay in\ncooperative edge inference. Secondly, to enhance the long-term performance of\ninference systems, we formulate a multi-slot stochastic E2E delay optimization\nproblem that jointly considers model partitioning and multi-dimensional\nresource allocation. Finally, to solve this problem, we introduce a\nLyapunov-guided Multi-Dimensional Optimization algorithm (LyMDO) that decouples\nthe original problem into per-slot deterministic problems, where Deep\nReinforcement Learning (DRL) and convex optimization are used for joint\noptimization of partitioning decisions and complementary resource allocation.\nSimulation results show that our approach effectively improves E2E delay while\nbalancing long-term resource constraints.",
            "author": [
                "Xinrui Ye",
                "Yanzan Sun",
                "Dingzhu Wen",
                "Guanjin Pan",
                "Shunqing Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12937v1",
                "http://arxiv.org/pdf/2310.12937v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12936v2",
            "title": "A Predictive Factor Analysis of Social Biases and Task-Performance in\n  Pretrained Masked Language Models",
            "updated": "2023-10-22T14:19:01Z",
            "published": "2023-10-19T17:33:33Z",
            "summary": "Various types of social biases have been reported with pretrained Masked\nLanguage Models (MLMs) in prior work. However, multiple underlying factors are\nassociated with an MLM such as its model size, size of the training data,\ntraining objectives, the domain from which pretraining data is sampled,\ntokenization, and languages present in the pretrained corpora, to name a few.\nIt remains unclear as to which of those factors influence social biases that\nare learned by MLMs. To study the relationship between model factors and the\nsocial biases learned by an MLM, as well as the downstream task performance of\nthe model, we conduct a comprehensive study over 39 pretrained MLMs covering\ndifferent model sizes, training objectives, tokenization methods, training data\ndomains and languages. Our results shed light on important factors often\nneglected in prior literature, such as tokenization or model objectives.",
            "author": [
                "Yi Zhou",
                "Jose Camacho-Collados",
                "Danushka Bollegala"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12936v2",
                "http://arxiv.org/pdf/2310.12936v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12934v2",
            "title": "Generative Flow Networks as Entropy-Regularized RL",
            "updated": "2023-10-23T16:12:02Z",
            "published": "2023-10-19T17:31:40Z",
            "summary": "The recently proposed generative flow networks (GFlowNets) are a method of\ntraining a policy to sample compositional discrete objects with probabilities\nproportional to a given reward via a sequence of actions. GFlowNets exploit the\nsequential nature of the problem, drawing parallels with reinforcement learning\n(RL). Our work extends the connection between RL and GFlowNets to a general\ncase. We demonstrate how the task of learning a generative flow network can be\nefficiently redefined as an entropy-regularized RL problem with a specific\nreward and regularizer structure. Furthermore, we illustrate the practical\nefficiency of this reformulation by applying standard soft RL algorithms to\nGFlowNet training across several probabilistic modeling tasks. Contrary to\npreviously reported results, we show that entropic RL approaches can be\ncompetitive against established GFlowNet training methods. This perspective\nopens a direct path for integrating reinforcement learning principles into the\nrealm of generative flow networks.",
            "author": [
                "Daniil Tiapkin",
                "Nikita Morozov",
                "Alexey Naumov",
                "Dmitry Vetrov"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12934v2",
                "http://arxiv.org/pdf/2310.12934v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12931v1",
            "title": "Eureka: Human-Level Reward Design via Coding Large Language Models",
            "updated": "2023-10-19T17:31:01Z",
            "published": "2023-10-19T17:31:01Z",
            "summary": "Large Language Models (LLMs) have excelled as high-level semantic planners\nfor sequential decision-making tasks. However, harnessing them to learn complex\nlow-level manipulation tasks, such as dexterous pen spinning, remains an open\nproblem. We bridge this fundamental gap and present Eureka, a human-level\nreward design algorithm powered by LLMs. Eureka exploits the remarkable\nzero-shot generation, code-writing, and in-context improvement capabilities of\nstate-of-the-art LLMs, such as GPT-4, to perform evolutionary optimization over\nreward code. The resulting rewards can then be used to acquire complex skills\nvia reinforcement learning. Without any task-specific prompting or pre-defined\nreward templates, Eureka generates reward functions that outperform expert\nhuman-engineered rewards. In a diverse suite of 29 open-source RL environments\nthat include 10 distinct robot morphologies, Eureka outperforms human experts\non 83% of the tasks, leading to an average normalized improvement of 52%. The\ngenerality of Eureka also enables a new gradient-free in-context learning\napproach to reinforcement learning from human feedback (RLHF), readily\nincorporating human inputs to improve the quality and the safety of the\ngenerated rewards without model updating. Finally, using Eureka rewards in a\ncurriculum learning setting, we demonstrate for the first time, a simulated\nShadow Hand capable of performing pen spinning tricks, adeptly manipulating a\npen in circles at rapid speed.",
            "author": [
                "Yecheng Jason Ma",
                "William Liang",
                "Guanzhi Wang",
                "De-An Huang",
                "Osbert Bastani",
                "Dinesh Jayaraman",
                "Yuke Zhu",
                "Linxi Fan",
                "Anima Anandkumar"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12931v1",
                "http://arxiv.org/pdf/2310.12931v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13724v1",
            "title": "Habitat 3.0: A Co-Habitat for Humans, Avatars and Robots",
            "updated": "2023-10-19T17:29:17Z",
            "published": "2023-10-19T17:29:17Z",
            "summary": "We present Habitat 3.0: a simulation platform for studying collaborative\nhuman-robot tasks in home environments. Habitat 3.0 offers contributions across\nthree dimensions: (1) Accurate humanoid simulation: addressing challenges in\nmodeling complex deformable bodies and diversity in appearance and motion, all\nwhile ensuring high simulation speed. (2) Human-in-the-loop infrastructure:\nenabling real human interaction with simulated robots via mouse/keyboard or a\nVR interface, facilitating evaluation of robot policies with human input. (3)\nCollaborative tasks: studying two collaborative tasks, Social Navigation and\nSocial Rearrangement. Social Navigation investigates a robot's ability to\nlocate and follow humanoid avatars in unseen environments, whereas Social\nRearrangement addresses collaboration between a humanoid and robot while\nrearranging a scene. These contributions allow us to study end-to-end learned\nand heuristic baselines for human-robot collaboration in-depth, as well as\nevaluate them with humans in the loop. Our experiments demonstrate that learned\nrobot policies lead to efficient task completion when collaborating with unseen\nhumanoid agents and human partners that might exhibit behaviors that the robot\nhas not seen before. Additionally, we observe emergent behaviors during\ncollaborative task execution, such as the robot yielding space when obstructing\na humanoid agent, thereby allowing the effective completion of the task by the\nhumanoid agent. Furthermore, our experiments using the human-in-the-loop tool\ndemonstrate that our automated evaluation with humanoids can provide an\nindication of the relative ordering of different policies when evaluated with\nreal human collaborators. Habitat 3.0 unlocks interesting new features in\nsimulators for Embodied AI, and we hope it paves the way for a new frontier of\nembodied human-AI interaction capabilities.",
            "author": [
                "Xavier Puig",
                "Eric Undersander",
                "Andrew Szot",
                "Mikael Dallaire Cote",
                "Tsung-Yen Yang",
                "Ruslan Partsey",
                "Ruta Desai",
                "Alexander William Clegg",
                "Michal Hlavac",
                "So Yeon Min",
                "Vladim\u00edr Vondru\u0161",
                "Theophile Gervet",
                "Vincent-Pierre Berges",
                "John M. Turner",
                "Oleksandr Maksymets",
                "Zsolt Kira",
                "Mrinal Kalakrishnan",
                "Jitendra Malik",
                "Devendra Singh Chaplot",
                "Unnat Jain",
                "Dhruv Batra",
                "Akshara Rai",
                "Roozbeh Mottaghi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13724v1",
                "http://arxiv.org/pdf/2310.13724v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.AI",
                "cs.CV",
                "cs.GR",
                "cs.MA",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12929v1",
            "title": "Probabilistic Modeling of Human Teams to Infer False Beliefs",
            "updated": "2023-10-19T17:28:37Z",
            "published": "2023-10-19T17:28:37Z",
            "summary": "We develop a probabilistic graphical model (PGM) for artificially intelligent\n(AI) agents to infer human beliefs during a simulated urban search and rescue\n(USAR) scenario executed in a Minecraft environment with a team of three\nplayers. The PGM approach makes observable states and actions explicit, as well\nas beliefs and intentions grounded by evidence about what players see and do\nover time. This approach also supports inferring the effect of interventions,\nwhich are vital if AI agents are to assist human teams. The experiment\nincorporates manipulations of players' knowledge, and the virtual\nMinecraft-based testbed provides access to several streams of information,\nincluding the objects in the players' field of view. The participants are\nequipped with a set of marker blocks that can be placed near room entrances to\nsignal the presence or absence of victims in the rooms to their teammates. In\neach team, one of the members is given a different legend for the markers than\nthe other two, which may mislead them about the state of the rooms; that is,\nthey will hold a false belief. We extend previous works in this field by\nintroducing ToMCAT, an AI agent that can reason about individual and shared\nmental states. We find that the players' behaviors are affected by what they\nsee in their in-game field of view, their beliefs about the meaning of the\nmarkers, and their beliefs about which meaning the team decided to adopt. In\naddition, we show that ToMCAT's beliefs are consistent with the players'\nactions and that it can infer false beliefs with accuracy significantly better\nthan chance and comparable to inferences made by human observers.",
            "author": [
                "Paulo Soares",
                "Adarsh Pyarelal",
                "Kobus Barnard"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12929v1",
                "http://arxiv.org/pdf/2310.12929v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.13723v1",
            "title": "Enhancing Open-World Bacterial Raman Spectra Identification by Feature\n  Regularization for Improved Resilience against Unknown Classes",
            "updated": "2023-10-19T17:19:47Z",
            "published": "2023-10-19T17:19:47Z",
            "summary": "The combination of Deep Learning techniques and Raman spectroscopy shows\ngreat potential offering precise and prompt identification of pathogenic\nbacteria in clinical settings. However, the traditional closed-set\nclassification approaches assume that all test samples belong to one of the\nknown pathogens, and their applicability is limited since the clinical\nenvironment is inherently unpredictable and dynamic, unknown or emerging\npathogens may not be included in the available catalogs. We demonstrate that\nthe current state-of-the-art Neural Networks identifying pathogens through\nRaman spectra are vulnerable to unknown inputs, resulting in an uncontrollable\nfalse positive rate. To address this issue, first, we developed a novel\nensemble of ResNet architectures combined with the attention mechanism which\noutperforms existing closed-world methods, achieving an accuracy of $87.8 \\pm\n0.1\\%$ compared to the best available model's accuracy of $86.7 \\pm 0.4\\%$.\nSecond, through the integration of feature regularization by the Objectosphere\nloss function, our model achieves both high accuracy in identifying known\npathogens from the catalog and effectively separates unknown samples\ndrastically reducing the false positive rate. Finally, the proposed feature\nregularization method during training significantly enhances the performance of\nout-of-distribution detectors during the inference phase improving the\nreliability of the detection of unknown classes. Our novel algorithm for Raman\nspectroscopy enables the detection of unknown, uncatalogued, and emerging\npathogens providing the flexibility to adapt to future pathogens that may\nemerge, and has the potential to improve the reliability of Raman-based\nsolutions in dynamic operating environments where accuracy is critical, such as\npublic safety applications.",
            "author": [
                "Yaroslav Balytskyi",
                "Nataliia Kalashnyk",
                "Inna Hubenko",
                "Alina Balytska",
                "Kelly McNear"
            ],
            "link": [
                "http://arxiv.org/abs/2310.13723v1",
                "http://arxiv.org/pdf/2310.13723v1"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12924v2",
            "title": "Digital Twin-Enabled Intelligent DDoS Detection Mechanism for Autonomous\n  Core Networks",
            "updated": "2023-10-25T23:22:27Z",
            "published": "2023-10-19T17:19:38Z",
            "summary": "Existing distributed denial of service attack (DDoS) solutions cannot handle\nhighly aggregated data rates; thus, they are unsuitable for Internet service\nprovider (ISP) core networks. This article proposes a digital twin-enabled\nintelligent DDoS detection mechanism using an online learning method for\nautonomous systems. Our contributions are three-fold: we first design a DDoS\ndetection architecture based on the digital twin for ISP core networks. We\nimplemented a Yet Another Next Generation (YANG) model and an automated feature\nselection (AutoFS) module to handle core network data. We used an online\nlearning approach to update the model instantly and efficiently, improve the\nlearning model quickly, and ensure accurate predictions. Finally, we reveal\nthat our proposed solution successfully detects DDoS attacks and updates the\nfeature selection method and learning model with a true classification rate of\nninety-seven percent. Our proposed solution can estimate the attack within\napproximately fifteen minutes after the DDoS attack starts.",
            "author": [
                "Yagmur Yigit",
                "Bahadir Bal",
                "Aytac Karameseoglu",
                "Trung Q. Duong",
                "Berk Canberk"
            ],
            "link": [
                "http://dx.doi.org/10.1109/MCOMSTD.0001.2100022",
                "http://arxiv.org/abs/2310.12924v2",
                "http://arxiv.org/pdf/2310.12924v2"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI",
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12921v1",
            "title": "Vision-Language Models are Zero-Shot Reward Models for Reinforcement\n  Learning",
            "updated": "2023-10-19T17:17:06Z",
            "published": "2023-10-19T17:17:06Z",
            "summary": "Reinforcement learning (RL) requires either manually specifying a reward\nfunction, which is often infeasible, or learning a reward model from a large\namount of human feedback, which is often very expensive. We study a more\nsample-efficient alternative: using pretrained vision-language models (VLMs) as\nzero-shot reward models (RMs) to specify tasks via natural language. We propose\na natural and general approach to using VLMs as reward models, which we call\nVLM-RMs. We use VLM-RMs based on CLIP to train a MuJoCo humanoid to learn\ncomplex tasks without a manually specified reward function, such as kneeling,\ndoing the splits, and sitting in a lotus position. For each of these tasks, we\nonly provide a single sentence text prompt describing the desired task with\nminimal prompt engineering. We provide videos of the trained agents at:\nhttps://sites.google.com/view/vlm-rm. We can improve performance by providing a\nsecond ``baseline'' prompt and projecting out parts of the CLIP embedding space\nirrelevant to distinguish between goal and baseline. Further, we find a strong\nscaling effect for VLM-RMs: larger VLMs trained with more compute and data are\nbetter reward models. The failure modes of VLM-RMs we encountered are all\nrelated to known capability limitations of current VLMs, such as limited\nspatial reasoning ability or visually unrealistic environments that are far\noff-distribution for the VLM. We find that VLM-RMs are remarkably robust as\nlong as the VLM is large enough. This suggests that future VLMs will become\nmore and more useful reward models for a wide range of RL applications.",
            "author": [
                "Juan Rocamonde",
                "Victoriano Montesinos",
                "Elvis Nava",
                "Ethan Perez",
                "David Lindner"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12921v1",
                "http://arxiv.org/pdf/2310.12921v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12920v1",
            "title": "Generative Marginalization Models",
            "updated": "2023-10-19T17:14:29Z",
            "published": "2023-10-19T17:14:29Z",
            "summary": "We introduce marginalization models (MaMs), a new family of generative models\nfor high-dimensional discrete data. They offer scalable and flexible generative\nmodeling with tractable likelihoods by explicitly modeling all induced marginal\ndistributions. Marginalization models enable fast evaluation of arbitrary\nmarginal probabilities with a single forward pass of the neural network, which\novercomes a major limitation of methods with exact marginal inference, such as\nautoregressive models (ARMs). We propose scalable methods for learning the\nmarginals, grounded in the concept of \"marginalization self-consistency\".\nUnlike previous methods, MaMs support scalable training of any-order generative\nmodels for high-dimensional problems under the setting of energy-based\ntraining, where the goal is to match the learned distribution to a given\ndesired probability (specified by an unnormalized (log) probability function\nsuch as energy function or reward function). We demonstrate the effectiveness\nof the proposed model on a variety of discrete data distributions, including\nbinary images, language, physical systems, and molecules, for maximum\nlikelihood and energy-based training settings. MaMs achieve orders of magnitude\nspeedup in evaluating the marginal probabilities on both settings. For\nenergy-based training tasks, MaMs enable any-order generative modeling of\nhigh-dimensional problems beyond the capability of previous methods. Code is at\nhttps://github.com/PrincetonLIPS/MaM.",
            "author": [
                "Sulin Liu",
                "Peter J. Ramadge",
                "Ryan P. Adams"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12920v1",
                "http://arxiv.org/pdf/2310.12920v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19816v1",
            "title": "Benchmarking GPUs on SVBRDF Extractor Model",
            "updated": "2023-10-19T17:09:06Z",
            "published": "2023-10-19T17:09:06Z",
            "summary": "With the maturity of deep learning, its use is emerging in every field. Also,\nas different types of GPUs are becoming more available in the markets, it\ncreates a difficult decision for users. How can users select GPUs to achieve\noptimal performance for a specific task? Analysis of GPU architecture is well\nstudied, but existing works that benchmark GPUs do not study tasks for networks\nwith significantly larger input. In this work, we tried to differentiate the\nperformance of different GPUs on neural network models that operate on bigger\ninput images (256x256).",
            "author": [
                "Narayan Kandel",
                "Melanie Lambert"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19816v1",
                "http://arxiv.org/pdf/2310.19816v1"
            ],
            "primary_category": "cs.PF",
            "category": [
                "cs.PF",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12914v2",
            "title": "Network-Aware AutoML Framework for Software-Defined Sensor Networks",
            "updated": "2023-10-25T23:24:57Z",
            "published": "2023-10-19T17:07:32Z",
            "summary": "As the current detection solutions of distributed denial of service attacks\n(DDoS) need additional infrastructures to handle high aggregate data rates,\nthey are not suitable for sensor networks or the Internet of Things. Besides,\nthe security architecture of software-defined sensor networks needs to pay\nattention to the vulnerabilities of both software-defined networks and sensor\nnetworks. In this paper, we propose a network-aware automated machine learning\n(AutoML) framework which detects DDoS attacks in software-defined sensor\nnetworks. Our framework selects an ideal machine learning algorithm to detect\nDDoS attacks in network-constrained environments, using metrics such as\nvariable traffic load, heterogeneous traffic rate, and detection time while\npreventing over-fitting. Our contributions are two-fold: (i) we first\ninvestigate the trade-off between the efficiency of ML algorithms and\nnetwork/traffic state in the scope of DDoS detection. (ii) we design and\nimplement a software architecture containing open-source network tools, with\nthe deployment of multiple ML algorithms. Lastly, we show that under the denial\nof service attacks, our framework ensures the traffic packets are still\ndelivered within the network with additional delays.",
            "author": [
                "Emre Horsanali",
                "Yagmur Yigit",
                "Gokhan Secinti",
                "Aytac Karameseoglu",
                "Berk Canberk"
            ],
            "link": [
                "http://dx.doi.org/10.1109/DCOSS52077.2021.00076",
                "http://arxiv.org/abs/2310.12914v2",
                "http://arxiv.org/pdf/2310.12914v2"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI",
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12912v1",
            "title": "Impact of Relational Networks in Multi-Agent Learning: A Value-Based\n  Factorization View",
            "updated": "2023-10-19T17:04:01Z",
            "published": "2023-10-19T17:04:01Z",
            "summary": "Effective coordination and cooperation among agents are crucial for\naccomplishing individual or shared objectives in multi-agent systems. In many\nreal-world multi-agent systems, agents possess varying abilities and\nconstraints, making it necessary to prioritize agents based on their specific\nproperties to ensure successful coordination and cooperation within the team.\nHowever, most existing cooperative multi-agent algorithms do not take into\naccount these individual differences, and lack an effective mechanism to guide\ncoordination strategies. We propose a novel multi-agent learning approach that\nincorporates relationship awareness into value-based factorization methods.\nGiven a relational network, our approach utilizes inter-agents relationships to\ndiscover new team behaviors by prioritizing certain agents over other,\naccounting for differences between them in cooperative tasks. We evaluated the\neffectiveness of our proposed approach by conducting fifteen experiments in two\ndifferent environments. The results demonstrate that our proposed algorithm can\ninfluence and shape team behavior, guide cooperation strategies, and expedite\nagent learning. Therefore, our approach shows promise for use in multi-agent\nsystems, especially when agents have diverse properties.",
            "author": [
                "Yasin Findik",
                "Paul Robinette",
                "Kshitij Jerath",
                "S. Reza Ahmadzadeh"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12912v1",
                "http://arxiv.org/pdf/2310.12912v1"
            ],
            "primary_category": "cs.MA",
            "category": [
                "cs.MA",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12909v1",
            "title": "Collaborative Adaptation: Learning to Recover from Unforeseen\n  Malfunctions in Multi-Robot Teams",
            "updated": "2023-10-19T17:00:09Z",
            "published": "2023-10-19T17:00:09Z",
            "summary": "Cooperative multi-agent reinforcement learning (MARL) approaches tackle the\nchallenge of finding effective multi-agent cooperation strategies for\naccomplishing individual or shared objectives in multi-agent teams. In\nreal-world scenarios, however, agents may encounter unforeseen failures due to\nconstraints like battery depletion or mechanical issues. Existing\nstate-of-the-art methods in MARL often recover slowly -- if at all -- from such\nmalfunctions once agents have already converged on a cooperation strategy. To\naddress this gap, we present the Collaborative Adaptation (CA) framework. CA\nintroduces a mechanism that guides collaboration and accelerates adaptation\nfrom unforeseen failures by leveraging inter-agent relationships. Our findings\ndemonstrate that CA enables agents to act on the knowledge of inter-agent\nrelations, recovering from unforeseen agent failures and selecting appropriate\ncooperative strategies.",
            "author": [
                "Yasin Findik",
                "Paul Robinette",
                "Kshitij Jerath",
                "S. Reza Ahmadzadeh"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12909v1",
                "http://arxiv.org/pdf/2310.12909v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12900v1",
            "title": "Personalized human mobility prediction for HuMob challenge",
            "updated": "2023-10-19T16:52:12Z",
            "published": "2023-10-19T16:52:12Z",
            "summary": "We explain the methodology used to create the data submitted to HuMob\nChallenge, a data analysis competition for human mobility prediction. We\nadopted a personalized model to predict the individual's movement trajectory\nfrom their data, instead of predicting from the overall movement, based on the\nhypothesis that human movement is unique to each person. We devised the\nfeatures such as the date and time, activity time, days of the week, time of\nday, and frequency of visits to POI (Point of Interest). As additional\nfeatures, we incorporated the movement of other individuals with similar\nbehavior patterns through the employment of clustering. The machine learning\nmodel we adopted was the Support Vector Regression (SVR). We performed accuracy\nthrough offline assessment and carried out feature selection and parameter\ntuning. Although overall dataset provided consists of 100,000 users trajectory,\nour method use only 20,000 target users data, and do not need to use other\n80,000 data. Despite the personalized model's traditional feature engineering\napproach, this model yields reasonably good accuracy with lower computational\ncost.",
            "author": [
                "Masahiro Suzuki",
                "Shomu Furuta",
                "Yusuke Fukazawa"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12900v1",
                "http://arxiv.org/pdf/2310.12900v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12899v1",
            "title": "Age-Appropriate Robot Design: In-The-Wild Child-Robot Interaction\n  Studies of Perseverance Styles and Robot's Unexpected Behavior",
            "updated": "2023-10-19T16:52:10Z",
            "published": "2023-10-19T16:52:10Z",
            "summary": "As child-robot interactions become more and more common in daily life\nenvironment, it is important to examine how robot's errors influence children's\nbehavior. We explored how a robot's unexpected behaviors affect child-robot\ninteractions during two workshops on active reading: one in a modern art museum\nand one in a school. We observed the behavior and attitudes of 42 children from\nthree age groups: 6-7 years, 8-10 years, and 10-12 years. Through our\nobservations, we identified six different types of surprising robot behaviors:\npersonality, movement malfunctions, inconsistent behavior, mispronunciation,\ndelays, and freezing. Using a qualitative analysis, we examined how children\nresponded to each type of behavior, and we observed similarities and\ndifferences between the age groups. Based on our findings, we propose\nguidelines for designing age-appropriate learning interactions with social\nrobots.",
            "author": [
                "Alicja Wr\u00f3bel",
                "Karolina \u0179r\u00f3bek",
                "Marie-Monique Schaper",
                "Paulina Zguda",
                "Bipin Indurkhya"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12899v1",
                "http://arxiv.org/pdf/2310.12899v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "I.2.9"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10733v1",
            "title": "Proceedings of the 3rd International Workshop on Mining and Learning in\n  the Legal Domain (MLLD-23)",
            "updated": "2023-10-19T16:49:11Z",
            "published": "2023-10-19T16:49:11Z",
            "summary": "This is the Proceedings of the 3rd International Workshop on Mining and\nLearning in the Legal Domain (MLLD-23) which took place in conjunction with the\n32nd ACM International Conference on Information and Knowledge Management\n(CIKM-2023) at the University of Birmingham, Birmingham, UK on Sunday 22nd\nOctober 2023.",
            "author": [
                "Masoud Makrehchi",
                "Dell Zhang",
                "Alina Petrova",
                "John Armour"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10733v1",
                "http://arxiv.org/pdf/2311.10733v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.CL",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12893v1",
            "title": "Blind quantum machine learning with quantum bipartite correlator",
            "updated": "2023-10-19T16:42:32Z",
            "published": "2023-10-19T16:42:32Z",
            "summary": "Distributed quantum computing is a promising computational paradigm for\nperforming computations that are beyond the reach of individual quantum\ndevices. Privacy in distributed quantum computing is critical for maintaining\nconfidentiality and protecting the data in the presence of untrusted computing\nnodes. In this work, we introduce novel blind quantum machine learning\nprotocols based on the quantum bipartite correlator algorithm. Our protocols\nhave reduced communication overhead while preserving the privacy of data from\nuntrusted parties. We introduce robust algorithm-specific privacy-preserving\nmechanisms with low computational overhead that do not require complex\ncryptographic techniques. We then validate the effectiveness of the proposed\nprotocols through complexity and privacy analysis. Our findings pave the way\nfor advancements in distributed quantum computing, opening up new possibilities\nfor privacy-aware machine learning applications in the era of quantum\ntechnologies.",
            "author": [
                "Changhao Li",
                "Boning Li",
                "Omar Amer",
                "Ruslan Shaydulin",
                "Shouvanik Chakrabarti",
                "Guoqing Wang",
                "Haowei Xu",
                "Hao Tang",
                "Isidor Schoch",
                "Niraj Kumar",
                "Charles Lim",
                "Ju Li",
                "Paola Cappellaro",
                "Marco Pistoia"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12893v1",
                "http://arxiv.org/pdf/2310.12893v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12887v1",
            "title": "Spatial and Temporal Attention-based emotion estimation on HRI-AVC\n  dataset",
            "updated": "2023-10-19T16:37:52Z",
            "published": "2023-10-19T16:37:52Z",
            "summary": "Many attempts have been made at estimating discrete emotions (calmness,\nanxiety, boredom, surprise, anger) and continuous emotional measures commonly\nused in psychology, namely `valence' (The pleasantness of the emotion being\ndisplayed) and `arousal' (The intensity of the emotion being displayed).\nExisting methods to estimate arousal and valence rely on learning from data\nsets, where an expert annotator labels every image frame. Access to an expert\nannotator is not always possible, and the annotation can also be tedious. Hence\nit is more practical to obtain self-reported arousal and valence values\ndirectly from the human in a real-time Human-Robot collaborative setting. Hence\nthis paper provides an emotion data set (HRI-AVC) obtained while conducting a\nhuman-robot interaction (HRI) task. The self-reported pair of labels in this\ndata set is associated with a set of image frames. This paper also proposes a\nspatial and temporal attention-based network to estimate arousal and valence\nfrom this set of image frames. The results show that an attention-based network\ncan estimate valence and arousal on the HRI-AVC data set even when Arousal and\nValence values are unavailable per frame.",
            "author": [
                "Karthik Subramanian",
                "Saurav Singh",
                "Justin Namba",
                "Jamison Heard",
                "Christopher Kanan",
                "Ferat Sahin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12887v1",
                "http://arxiv.org/pdf/2310.12887v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12882v1",
            "title": "Sequential Gibbs Posteriors with Applications to Principal Component\n  Analysis",
            "updated": "2023-10-19T16:36:18Z",
            "published": "2023-10-19T16:36:18Z",
            "summary": "Gibbs posteriors are proportional to a prior distribution multiplied by an\nexponentiated loss function, with a key tuning parameter weighting information\nin the loss relative to the prior and providing a control of posterior\nuncertainty. Gibbs posteriors provide a principled framework for\nlikelihood-free Bayesian inference, but in many situations, including a single\ntuning parameter inevitably leads to poor uncertainty quantification. In\nparticular, regardless of the value of the parameter, credible regions have far\nfrom the nominal frequentist coverage even in large samples. We propose a\nsequential extension to Gibbs posteriors to address this problem. We prove the\nproposed sequential posterior exhibits concentration and a Bernstein-von Mises\ntheorem, which holds under easy to verify conditions in Euclidean space and on\nmanifolds. As a byproduct, we obtain the first Bernstein-von Mises theorem for\ntraditional likelihood-based Bayesian posteriors on manifolds. All methods are\nillustrated with an application to principal component analysis.",
            "author": [
                "Steven Winter",
                "Omar Melikechi",
                "David B. Dunson"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12882v1",
                "http://arxiv.org/pdf/2310.12882v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12880v2",
            "title": "TwinPot: Digital Twin-assisted Honeypot for Cyber-Secure Smart Seaports",
            "updated": "2023-10-25T23:29:53Z",
            "published": "2023-10-19T16:35:28Z",
            "summary": "The idea of next-generation ports has become more apparent in the last ten\nyears in response to the challenge posed by the rising demand for efficiency\nand the ever-increasing volume of goods. In this new era of intelligent\ninfrastructure and facilities, it is evident that cyber-security has recently\nreceived the most significant attention from the seaport and maritime\nauthorities, and it is a primary concern on the agenda of most ports.\nTraditional security solutions can be applied to safeguard IoT and\nCyber-Physical Systems (CPS) from harmful entities. Nevertheless, security\nresearchers can only watch, examine, and learn about the behaviors of attackers\nif these solutions operate more transparently. Herein, honeypots are potential\nsolutions since they offer valuable information about the attackers. It can be\nvirtual or physical. Virtual honeypots must be more realistic to entice\nattackers, necessitating better high-fidelity. To this end, Digital Twin (DT)\ntechnology can be employed to increase the complexity and simulation fidelity\nof the honeypots. Seaports can be attacked from both their existing devices and\nexternal devices at the same time. Existing mechanisms are insufficient to\ndetect external attacks; therefore, the current systems cannot handle attacks\nat the desired level. DT and honeypot technologies can be used together to\ntackle them. Consequently, we suggest a DT-assisted honeypot, called TwinPot,\nfor external attacks in smart seaports. Moreover, we propose an intelligent\nattack detection mechanism to handle different attack types using DT for\ninternal attacks. Finally, we build an extensive smart seaport dataset for\ninternal and external attacks using the MANSIM tool and two existing datasets\nto test the performance of our system. We show that under simultaneous internal\nand external attacks on the system, our solution successfully detects internal\nand external attacks.",
            "author": [
                "Yagmur Yigit",
                "Omer Kemal Kinaci",
                "Trung Q. Duong",
                "Berk Canberk"
            ],
            "link": [
                "http://dx.doi.org/10.1109/ICCWorkshops57953.2023.10283756",
                "http://arxiv.org/abs/2310.12880v2",
                "http://arxiv.org/pdf/2310.12880v2"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI",
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12868v1",
            "title": "EMIT-Diff: Enhancing Medical Image Segmentation via Text-Guided\n  Diffusion Model",
            "updated": "2023-10-19T16:18:02Z",
            "published": "2023-10-19T16:18:02Z",
            "summary": "Large-scale, big-variant, and high-quality data are crucial for developing\nrobust and successful deep-learning models for medical applications since they\npotentially enable better generalization performance and avoid overfitting.\nHowever, the scarcity of high-quality labeled data always presents significant\nchallenges. This paper proposes a novel approach to address this challenge by\ndeveloping controllable diffusion models for medical image synthesis, called\nEMIT-Diff. We leverage recent diffusion probabilistic models to generate\nrealistic and diverse synthetic medical image data that preserve the essential\ncharacteristics of the original medical images by incorporating edge\ninformation of objects to guide the synthesis process. In our approach, we\nensure that the synthesized samples adhere to medically relevant constraints\nand preserve the underlying structure of imaging data. Due to the random\nsampling process by the diffusion model, we can generate an arbitrary number of\nsynthetic images with diverse appearances. To validate the effectiveness of our\nproposed method, we conduct an extensive set of medical image segmentation\nexperiments on multiple datasets, including Ultrasound breast (+13.87%), CT\nspleen (+0.38%), and MRI prostate (+7.78%), achieving significant improvements\nover the baseline segmentation methods. For the first time, to our best\nknowledge, the promising results demonstrate the effectiveness of our EMIT-Diff\nfor medical image segmentation tasks and show the feasibility of introducing a\nfirst-ever text-guided diffusion model for general medical image segmentation\ntasks. With carefully designed ablation experiments, we investigate the\ninfluence of various data augmentation ratios, hyper-parameter settings, patch\nsize for generating random merging mask settings, and combined influence with\ndifferent network architectures.",
            "author": [
                "Zheyuan Zhang",
                "Lanhong Yao",
                "Bin Wang",
                "Debesh Jha",
                "Elif Keles",
                "Alpay Medetalibeyoglu",
                "Ulas Bagci"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12868v1",
                "http://arxiv.org/pdf/2310.12868v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12866v1",
            "title": "Predicting Ovarian Cancer Treatment Response in Histopathology using\n  Hierarchical Vision Transformers and Multiple Instance Learning",
            "updated": "2023-10-19T16:16:29Z",
            "published": "2023-10-19T16:16:29Z",
            "summary": "For many patients, current ovarian cancer treatments offer limited clinical\nbenefit. For some therapies, it is not possible to predict patients' responses,\npotentially exposing them to the adverse effects of treatment without any\ntherapeutic benefit. As part of the automated prediction of treatment\neffectiveness in ovarian cancer using histopathological images (ATEC23)\nchallenge, we evaluated the effectiveness of deep learning to predict whether a\ncourse of treatment including the antiangiogenic drug bevacizumab could\ncontribute to remission or prevent disease progression for at least 6 months in\na set of 282 histopathology whole slide images (WSIs) from 78 ovarian cancer\npatients. Our approach used a pretrained Hierarchical Image Pyramid Transformer\n(HIPT) to extract region-level features and an attention-based multiple\ninstance learning (ABMIL) model to aggregate features and classify whole\nslides. The optimal HIPT-ABMIL model had an internal balanced accuracy of 60.2%\n+- 2.9% and an AUC of 0.646 +- 0.033. Histopathology-specific model pretraining\nwas found to be beneficial to classification performance, though hierarchical\ntransformers were not, with a ResNet feature extractor achieving similar\nperformance. Due to the dataset being small and highly heterogeneous,\nperformance was variable across 5-fold cross-validation folds, and there were\nsome extreme differences between validation and test set performance within\nfolds. The model did not generalise well to tissue microarrays, with accuracy\nworse than random chance. It is not yet clear whether ovarian cancer WSIs\ncontain information that can be used to accurately predict treatment response,\nwith further validation using larger, higher-quality datasets required.",
            "author": [
                "Jack Breen",
                "Katie Allen",
                "Kieran Zucker",
                "Geoff Hall",
                "Nishant Ravikumar",
                "Nicolas M. Orsi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12866v1",
                "http://arxiv.org/pdf/2310.12866v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12862v1",
            "title": "Fine-Tuning Generative Models as an Inference Method for Robotic Tasks",
            "updated": "2023-10-19T16:11:49Z",
            "published": "2023-10-19T16:11:49Z",
            "summary": "Adaptable models could greatly benefit robotic agents operating in the real\nworld, allowing them to deal with novel and varying conditions. While\napproaches such as Bayesian inference are well-studied frameworks for adapting\nmodels to evidence, we build on recent advances in deep generative models which\nhave greatly affected many areas of robotics. Harnessing modern GPU\nacceleration, we investigate how to quickly adapt the sample generation of\nneural network models to observations in robotic tasks. We propose a simple and\ngeneral method that is applicable to various deep generative models and robotic\nenvironments. The key idea is to quickly fine-tune the model by fitting it to\ngenerated samples matching the observed evidence, using the cross-entropy\nmethod. We show that our method can be applied to both autoregressive models\nand variational autoencoders, and demonstrate its usability in object shape\ninference from grasping, inverse kinematics calculation, and point cloud\ncompletion.",
            "author": [
                "Orr Krupnik",
                "Elisei Shafer",
                "Tom Jurgenson",
                "Aviv Tamar"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12862v1",
                "http://arxiv.org/pdf/2310.12862v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12858v1",
            "title": "Audio Editing with Non-Rigid Text Prompts",
            "updated": "2023-10-19T16:09:44Z",
            "published": "2023-10-19T16:09:44Z",
            "summary": "In this paper, we explore audio-editing with non-rigid text edits. We show\nthat the proposed editing pipeline is able to create audio edits that remain\nfaithful to the input audio. We explore text prompts that perform addition,\nstyle transfer, and in-painting. We quantitatively and qualitatively show that\nthe edits are able to obtain results which outperform Audio-LDM, a recently\nreleased text-prompted audio generation model. Qualitative inspection of the\nresults points out that the edits given by our approach remain more faithful to\nthe input audio in terms of keeping the original onsets and offsets of the\naudio events.",
            "author": [
                "Francesco Paissan",
                "Zhepei Wang",
                "Mirco Ravanelli",
                "Paris Smaragdis",
                "Cem Subakan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12858v1",
                "http://arxiv.org/pdf/2310.12858v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.LG",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12855v1",
            "title": "Convective scale and subadiabatic layers in simulations of rotating\n  compressible convection",
            "updated": "2023-10-19T16:06:00Z",
            "published": "2023-10-19T16:06:00Z",
            "summary": "(abridged) Context: Rotation is thought to influence the size of convective\neddies and the efficiency of convective energy transport in the deep convection\nzones of stars. Rotationally constrained convection has been invoked to explain\nthe lack of large-scale power in observations of solar flows. Aims: The main\naims are to quantify the effects of rotation on the scale of convective eddies\nand velocity, the depths of convective overshoot, and the subadiabatic\nDeardorff layers. Methods: Three-dimensional hydrodynamic simulations of\nrotating convection in Cartesian domains were run. The results were compared\nwith theoretical scaling results that assume a balance between Coriolis,\ninertial, and buoyancy (Archemedean) forces (CIA balance). Results: The scale\nof convective eddies decreases as rotation increases, and ultimately reaches a\nrotationally constrained regime consistent with the CIA balance. Using a new\nmeasure of the rotational influence on the system, it is shown that even the\ndeep parts of the solar convection zone are not in the rotationally constrained\nregime. The simulations capture the slowly and rapidly rotating scaling laws\npredicted by theory, and the Sun appears to be in between these two regimes.\nBoth, the overshooting depth and the extent of the Deardorff layer, decrease as\nrotation becomes more rapid. For sufficiently rapid rotation the Deardorff\nlayer is absent. Conclusions: Relating the simulations with the Sun suggests\nthat the convective scale even in the deep parts of the Sun is only mildly\naffected by rotation and that some other mechanism is needed to explain the\nlack of strong large-scale flows in the Sun. Taking the current results at face\nvalue, the overshoot and Deardorff layers are estimated to span roughly five\nper cent of the pressure scale height at the base of the convection zone in the\nSun.",
            "author": [
                "Petri J. K\u00e4pyl\u00e4"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12855v1",
                "http://arxiv.org/pdf/2310.12855v1"
            ],
            "primary_category": "astro-ph.SR",
            "category": [
                "astro-ph.SR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12851v1",
            "title": "EmoDiarize: Speaker Diarization and Emotion Identification from Speech\n  Signals using Convolutional Neural Networks",
            "updated": "2023-10-19T16:02:53Z",
            "published": "2023-10-19T16:02:53Z",
            "summary": "In the era of advanced artificial intelligence and human-computer\ninteraction, identifying emotions in spoken language is paramount. This\nresearch explores the integration of deep learning techniques in speech emotion\nrecognition, offering a comprehensive solution to the challenges associated\nwith speaker diarization and emotion identification. It introduces a framework\nthat combines a pre-existing speaker diarization pipeline and an emotion\nidentification model built on a Convolutional Neural Network (CNN) to achieve\nhigher precision. The proposed model was trained on data from five speech\nemotion datasets, namely, RAVDESS, CREMA-D, SAVEE, TESS, and Movie Clips, out\nof which the latter is a speech emotion dataset created specifically for this\nresearch. The features extracted from each sample include Mel Frequency\nCepstral Coefficients (MFCC), Zero Crossing Rate (ZCR), Root Mean Square (RMS),\nand various data augmentation algorithms like pitch, noise, stretch, and shift.\nThis feature extraction approach aims to enhance prediction accuracy while\nreducing computational complexity. The proposed model yields an unweighted\naccuracy of 63%, demonstrating remarkable efficiency in accurately identifying\nemotional states within speech signals.",
            "author": [
                "Hanan Hamza",
                "Fiza Gafoor",
                "Fathima Sithara",
                "Gayathri Anil",
                "V. S. Anoop"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12851v1",
                "http://arxiv.org/pdf/2310.12851v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.CL",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12848v1",
            "title": "Neural Degradation Representation Learning for All-In-One Image\n  Restoration",
            "updated": "2023-10-19T15:59:24Z",
            "published": "2023-10-19T15:59:24Z",
            "summary": "Existing methods have demonstrated effective performance on a single\ndegradation type. In practical applications, however, the degradation is often\nunknown, and the mismatch between the model and the degradation will result in\na severe performance drop. In this paper, we propose an all-in-one image\nrestoration network that tackles multiple degradations. Due to the\nheterogeneous nature of different types of degradations, it is difficult to\nprocess multiple degradations in a single network. To this end, we propose to\nlearn a neural degradation representation (NDR) that captures the underlying\ncharacteristics of various degradations. The learned NDR decomposes different\ntypes of degradations adaptively, similar to a neural dictionary that\nrepresents basic degradation components. Subsequently, we develop a degradation\nquery module and a degradation injection module to effectively recognize and\nutilize the specific degradation based on NDR, enabling the all-in-one\nrestoration ability for multiple degradations. Moreover, we propose a\nbidirectional optimization strategy to effectively drive NDR to learn the\ndegradation representation by optimizing the degradation and restoration\nprocesses alternately. Comprehensive experiments on representative types of\ndegradations (including noise, haze, rain, and downsampling) demonstrate the\neffectiveness and generalization capability of our method.",
            "author": [
                "Mingde Yao",
                "Ruikang Xu",
                "Yuanshen Guan",
                "Jie Huang",
                "Zhiwei Xiong"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12848v1",
                "http://arxiv.org/pdf/2310.12848v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12842v1",
            "title": "Model-agnostic variable importance for predictive uncertainty: an\n  entropy-based approach",
            "updated": "2023-10-19T15:51:23Z",
            "published": "2023-10-19T15:51:23Z",
            "summary": "In order to trust the predictions of a machine learning algorithm, it is\nnecessary to understand the factors that contribute to those predictions. In\nthe case of probabilistic and uncertainty-aware models, it is necessary to\nunderstand not only the reasons for the predictions themselves, but also the\nmodel's level of confidence in those predictions. In this paper, we show how\nexisting methods in explainability can be extended to uncertainty-aware models\nand how such extensions can be used to understand the sources of uncertainty in\na model's predictive distribution. In particular, by adapting permutation\nfeature importance, partial dependence plots, and individual conditional\nexpectation plots, we demonstrate that novel insights into model behaviour may\nbe obtained and that these methods can be used to measure the impact of\nfeatures on both the entropy of the predictive distribution and the\nlog-likelihood of the ground truth labels under that distribution. With\nexperiments using both synthetic and real-world data, we demonstrate the\nutility of these approaches in understanding both the sources of uncertainty\nand their impact on model performance.",
            "author": [
                "Danny Wood",
                "Theodore Papamarkou",
                "Matt Benatan",
                "Richard Allmendinger"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12842v1",
                "http://arxiv.org/pdf/2310.12842v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12837v2",
            "title": "Deep Beamforming for Speech Enhancement and Speaker Localization with an\n  Array Response-Aware Loss Function",
            "updated": "2023-10-22T11:59:06Z",
            "published": "2023-10-19T15:40:42Z",
            "summary": "Recent research advances in deep neural network (DNN)-based beamformers have\nshown great promise for speech enhancement under adverse acoustic conditions.\nDifferent network architectures and input features have been explored in\nestimating beamforming weights. In this paper, we propose a deep beamformer\nbased on an efficient convolutional recurrent network (CRN) trained with a\nnovel ARray RespOnse-aWare (ARROW) loss function. The ARROW loss exploits the\narray responses of the target and interferer by using the ground truth relative\ntransfer functions (RTFs). The DNN-based beamforming system, trained with ARROW\nloss through supervised learning, is able to perform speech enhancement and\nspeaker localization jointly. Experimental results have shown that the proposed\ndeep beamformer, trained with the linearly weighted scale-invariant\nsource-to-noise ratio (SI-SNR) and ARROW loss functions, achieves superior\nperformance in speech enhancement and speaker localization compared to two\nbaselines.",
            "author": [
                "Hsinyu Chang",
                "Yicheng Hsu",
                "Mingsian R. Bai"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12837v2",
                "http://arxiv.org/pdf/2310.12837v2"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12836v1",
            "title": "Knowledge-Augmented Language Model Verification",
            "updated": "2023-10-19T15:40:00Z",
            "published": "2023-10-19T15:40:00Z",
            "summary": "Recent Language Models (LMs) have shown impressive capabilities in generating\ntexts with the knowledge internalized in parameters. Yet, LMs often generate\nthe factually incorrect responses to the given queries, since their knowledge\nmay be inaccurate, incomplete, and outdated. To address this problem, previous\nworks propose to augment LMs with the knowledge retrieved from an external\nknowledge source. However, such approaches often show suboptimal text\ngeneration performance due to two reasons: 1) the model may fail to retrieve\nthe knowledge relevant to the given query, or 2) the model may not faithfully\nreflect the retrieved knowledge in the generated text. To overcome these, we\npropose to verify the output and the knowledge of the knowledge-augmented LMs\nwith a separate verifier, which is a small LM that is trained to detect those\ntwo types of errors through instruction-finetuning. Then, when the verifier\nrecognizes an error, we can rectify it by either retrieving new knowledge or\ngenerating new text. Further, we use an ensemble of the outputs from different\ninstructions with a single verifier to enhance the reliability of the\nverification processes. We validate the effectiveness of the proposed\nverification steps on multiple question answering benchmarks, whose results\nshow that the proposed verifier effectively identifies retrieval and generation\nerrors, allowing LMs to provide more factually correct outputs. Our code is\navailable at https://github.com/JinheonBaek/KALMV.",
            "author": [
                "Jinheon Baek",
                "Soyeong Jeong",
                "Minki Kang",
                "Jong C. Park",
                "Sung Ju Hwang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12836v1",
                "http://arxiv.org/pdf/2310.12836v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12831v1",
            "title": "Deep Metric Imitation Learning for Stable Motion Primitives",
            "updated": "2023-10-19T15:35:37Z",
            "published": "2023-10-19T15:35:37Z",
            "summary": "Imitation Learning (IL) is a powerful technique for intuitive robotic\nprogramming. However, ensuring the reliability of learned behaviors remains a\nchallenge. In the context of reaching motions, a robot should consistently\nreach its goal, regardless of its initial conditions. To meet this requirement,\nIL methods often employ specialized function approximators that guarantee this\nproperty by construction. Although effective, these approaches come with a set\nof limitations: 1) they are unable to fully exploit the capabilities of modern\nDeep Neural Network (DNN) architectures, 2) some are restricted in the family\nof motions they can model, resulting in suboptimal IL capabilities, and 3) they\nrequire explicit extensions to account for the geometry of motions that\nconsider orientations. To address these challenges, we introduce a novel\nstability loss function, drawing inspiration from the triplet loss used in the\ndeep metric learning literature. This loss does not constrain the DNN's\narchitecture and enables learning policies that yield accurate results.\nFurthermore, it is easily adaptable to the geometry of the robot's state space.\nWe provide a proof of the stability properties induced by this loss and\nempirically validate our method in various settings. These settings include\nEuclidean and non-Euclidean state spaces, as well as first-order and\nsecond-order motions, both in simulation and with real robots. More details\nabout the experimental results can be found at: https://youtu.be/ZWKLGntCI6w.",
            "author": [
                "Rodrigo P\u00e9rez-Dattari",
                "Cosimo Della Santina",
                "Jens Kober"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12831v1",
                "http://arxiv.org/pdf/2310.12831v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12823v2",
            "title": "AgentTuning: Enabling Generalized Agent Abilities for LLMs",
            "updated": "2023-10-22T16:19:16Z",
            "published": "2023-10-19T15:19:53Z",
            "summary": "Open large language models (LLMs) with great performance in various tasks\nhave significantly advanced the development of LLMs. However, they are far\ninferior to commercial models such as ChatGPT and GPT-4 when acting as agents\nto tackle complex tasks in the real world. These agent tasks employ LLMs as the\ncentral controller responsible for planning, memorization, and tool\nutilization, necessitating both fine-grained prompting methods and robust LLMs\nto achieve satisfactory performance. Though many prompting methods have been\nproposed to complete particular agent tasks, there is lack of research focusing\non improving the agent capabilities of LLMs themselves without compromising\ntheir general abilities. In this work, we present AgentTuning, a simple and\ngeneral method to enhance the agent abilities of LLMs while maintaining their\ngeneral LLM capabilities. We construct AgentInstruct, a lightweight\ninstruction-tuning dataset containing high-quality interaction trajectories. We\nemploy a hybrid instruction-tuning strategy by combining AgentInstruct with\nopen-source instructions from general domains. AgentTuning is used to\ninstruction-tune the Llama 2 series, resulting in AgentLM. Our evaluations show\nthat AgentTuning enables LLMs' agent capabilities without compromising general\nabilities. The AgentLM-70B is comparable to GPT-3.5-turbo on unseen agent\ntasks, demonstrating generalized agent capabilities. We open source the\nAgentInstruct and AgentLM-7B, 13B, and 70B models at\nhttps://github.com/THUDM/AgentTuning, serving open and powerful alternatives to\ncommercial LLMs for agent tasks.",
            "author": [
                "Aohan Zeng",
                "Mingdao Liu",
                "Rui Lu",
                "Bowen Wang",
                "Xiao Liu",
                "Yuxiao Dong",
                "Jie Tang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12823v2",
                "http://arxiv.org/pdf/2310.12823v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12822v1",
            "title": "Generating collective counterfactual explanations in score-based\n  classification via mathematical optimization",
            "updated": "2023-10-19T15:18:42Z",
            "published": "2023-10-19T15:18:42Z",
            "summary": "Due to the increasing use of Machine Learning models in high stakes decision\nmaking settings, it has become increasingly important to have tools to\nunderstand how models arrive at decisions. Assuming a trained Supervised\nClassification model, explanations can be obtained via counterfactual analysis:\na counterfactual explanation of an instance indicates how this instance should\nbe minimally modified so that the perturbed instance is classified in the\ndesired class by the Machine Learning classification model. Most of the\nCounterfactual Analysis literature focuses on the single-instance\nsingle-counterfactual setting, in which the analysis is done for one single\ninstance to provide one single explanation. Taking a stakeholder's perspective,\nin this paper we introduce the so-called collective counterfactual\nexplanations. By means of novel Mathematical Optimization models, we provide a\ncounterfactual explanation for each instance in a group of interest, so that\nthe total cost of the perturbations is minimized under some linking\nconstraints. Making the process of constructing counterfactuals collective\ninstead of individual enables us to detect the features that are critical to\nthe entire dataset to have the individuals classified in the desired class. Our\nmethodology allows for some instances to be treated individually, performing\nthe collective counterfactual analysis for a fraction of records of the group\nof interest. This way, outliers are identified and handled appropriately. Under\nsome assumptions on the classifier and the space in which counterfactuals are\nsought, finding collective counterfactuals is reduced to solving a convex\nquadratic linearly constrained mixed integer optimization problem, which, for\ndatasets of moderate size, can be solved to optimality using existing solvers.\nThe performance of our approach is illustrated on real-world datasets,\ndemonstrating its usefulness.",
            "author": [
                "Emilio Carrizosa",
                "Jasone Ram\u00edrez-Ayerbe",
                "Dolores Romero Morales"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.eswa.2023.121954",
                "http://arxiv.org/abs/2310.12822v1",
                "http://arxiv.org/pdf/2310.12822v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12819v2",
            "title": "Hybrid Search for Efficient Planning with Completeness Guarantees",
            "updated": "2023-11-28T19:23:22Z",
            "published": "2023-10-19T15:16:43Z",
            "summary": "Solving complex planning problems has been a long-standing challenge in\ncomputer science. Learning-based subgoal search methods have shown promise in\ntackling these problems, but they often suffer from a lack of completeness\nguarantees, meaning that they may fail to find a solution even if one exists.\nIn this paper, we propose an efficient approach to augment a subgoal search\nmethod to achieve completeness in discrete action spaces. Specifically, we\naugment the high-level search with low-level actions to execute a multi-level\n(hybrid) search, which we call complete subgoal search. This solution achieves\nthe best of both worlds: the practical efficiency of high-level search and the\ncompleteness of low-level search. We apply the proposed search method to a\nrecently proposed subgoal search algorithm and evaluate the algorithm trained\non offline data on complex planning problems. We demonstrate that our complete\nsubgoal search not only guarantees completeness but can even improve\nperformance in terms of search expansions for instances that the high-level\ncould solve without low-level augmentations. Our approach makes it possible to\napply subgoal-level planning for systems where completeness is a critical\nrequirement.",
            "author": [
                "Kalle Kujanp\u00e4\u00e4",
                "Joni Pajarinen",
                "Alexander Ilin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12819v2",
                "http://arxiv.org/pdf/2310.12819v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12818v1",
            "title": "Boosting Inference Efficiency: Unleashing the Power of Parameter-Shared\n  Pre-trained Language Models",
            "updated": "2023-10-19T15:13:58Z",
            "published": "2023-10-19T15:13:58Z",
            "summary": "Parameter-shared pre-trained language models (PLMs) have emerged as a\nsuccessful approach in resource-constrained environments, enabling substantial\nreductions in model storage and memory costs without significant performance\ncompromise. However, it is important to note that parameter sharing does not\nalleviate computational burdens associated with inference, thus impeding its\npracticality in situations characterized by limited stringent latency\nrequirements or computational resources. Building upon neural ordinary\ndifferential equations (ODEs), we introduce a straightforward technique to\nenhance the inference efficiency of parameter-shared PLMs. Additionally, we\npropose a simple pre-training technique that leads to fully or partially shared\nmodels capable of achieving even greater inference acceleration. The\nexperimental results demonstrate the effectiveness of our methods on both\nautoregressive and autoencoding PLMs, providing novel insights into more\nefficient utilization of parameter-shared models in resource-constrained\nsettings.",
            "author": [
                "Weize Chen",
                "Xiaoyue Xu",
                "Xu Han",
                "Yankai Lin",
                "Ruobing Xie",
                "Zhiyuan Liu",
                "Maosong Sun",
                "Jie Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12818v1",
                "http://arxiv.org/pdf/2310.12818v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12817v1",
            "title": "2D-3D Interlaced Transformer for Point Cloud Segmentation with\n  Scene-Level Supervision",
            "updated": "2023-10-19T15:12:44Z",
            "published": "2023-10-19T15:12:44Z",
            "summary": "We present a Multimodal Interlaced Transformer (MIT) that jointly considers\n2D and 3D data for weakly supervised point cloud segmentation. Research studies\nhave shown that 2D and 3D features are complementary for point cloud\nsegmentation. However, existing methods require extra 2D annotations to achieve\n2D-3D information fusion. Considering the high annotation cost of point clouds,\neffective 2D and 3D feature fusion based on weakly supervised learning is in\ngreat demand. To this end, we propose a transformer model with two encoders and\none decoder for weakly supervised point cloud segmentation using only\nscene-level class tags. Specifically, the two encoders compute the\nself-attended features for 3D point clouds and 2D multi-view images,\nrespectively. The decoder implements interlaced 2D-3D cross-attention and\ncarries out implicit 2D and 3D feature fusion. We alternately switch the roles\nof queries and key-value pairs in the decoder layers. It turns out that the 2D\nand 3D features are iteratively enriched by each other. Experiments show that\nit performs favorably against existing weakly supervised point cloud\nsegmentation methods by a large margin on the S3DIS and ScanNet benchmarks. The\nproject page will be available at https://jimmy15923.github.io/mit_web/.",
            "author": [
                "Cheng-Kun Yang",
                "Min-Hung Chen",
                "Yung-Yu Chuang",
                "Yen-Yu Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12817v1",
                "http://arxiv.org/pdf/2310.12817v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12815v1",
            "title": "Prompt Injection Attacks and Defenses in LLM-Integrated Applications",
            "updated": "2023-10-19T15:12:09Z",
            "published": "2023-10-19T15:12:09Z",
            "summary": "Large Language Models (LLMs) are increasingly deployed as the backend for a\nvariety of real-world applications called LLM-Integrated Applications. Multiple\nrecent works showed that LLM-Integrated Applications are vulnerable to prompt\ninjection attacks, in which an attacker injects malicious instruction/data into\nthe input of those applications such that they produce results as the attacker\ndesires. However, existing works are limited to case studies. As a result, the\nliterature lacks a systematic understanding of prompt injection attacks and\ntheir defenses. We aim to bridge the gap in this work. In particular, we\npropose a general framework to formalize prompt injection attacks. Existing\nattacks, which are discussed in research papers and blog posts, are special\ncases in our framework. Our framework enables us to design a new attack by\ncombining existing attacks. Moreover, we also propose a framework to\nsystematize defenses against prompt injection attacks. Using our frameworks, we\nconduct a systematic evaluation on prompt injection attacks and their defenses\nwith 10 LLMs and 7 tasks. We hope our frameworks can inspire future research in\nthis field. Our code is available at\nhttps://github.com/liu00222/Open-Prompt-Injection.",
            "author": [
                "Yupei Liu",
                "Yuqi Jia",
                "Runpeng Geng",
                "Jinyuan Jia",
                "Neil Zhenqiang Gong"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12815v1",
                "http://arxiv.org/pdf/2310.12815v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12809v1",
            "title": "Hierarchical Forecasting at Scale",
            "updated": "2023-10-19T15:06:31Z",
            "published": "2023-10-19T15:06:31Z",
            "summary": "Existing hierarchical forecasting techniques scale poorly when the number of\ntime series increases. We propose to learn a coherent forecast for millions of\ntime series with a single bottom-level forecast model by using a sparse loss\nfunction that directly optimizes the hierarchical product and/or temporal\nstructure. The benefit of our sparse hierarchical loss function is that it\nprovides practitioners a method of producing bottom-level forecasts that are\ncoherent to any chosen cross-sectional or temporal hierarchy. In addition,\nremoving the need for a post-processing step as required in traditional\nhierarchical forecasting techniques reduces the computational cost of the\nprediction phase in the forecasting pipeline. On the public M5 dataset, our\nsparse hierarchical loss function performs up to 10% (RMSE) better compared to\nthe baseline loss function. We implement our sparse hierarchical loss function\nwithin an existing forecasting model at bol, a large European e-commerce\nplatform, resulting in an improved forecasting performance of 2% at the product\nlevel. Finally, we found an increase in forecasting performance of about 5-10%\nwhen evaluating the forecasting performance across the cross-sectional\nhierarchies that we defined. These results demonstrate the usefulness of our\nsparse hierarchical loss applied to a production forecasting system at a major\ne-commerce platform.",
            "author": [
                "Olivier Sprangers",
                "Wander Wadman",
                "Sebastian Schelter",
                "Maarten de Rijke"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12809v1",
                "http://arxiv.org/pdf/2310.12809v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12808v1",
            "title": "Model Merging by Uncertainty-Based Gradient Matching",
            "updated": "2023-10-19T15:02:45Z",
            "published": "2023-10-19T15:02:45Z",
            "summary": "Models trained on different datasets can be merged by a weighted-averaging of\ntheir parameters, but why does it work and when can it fail? Here, we connect\nthe inaccuracy of weighted-averaging to mismatches in the gradients and propose\na new uncertainty-based scheme to improve the performance by reducing the\nmismatch. The connection also reveals implicit assumptions in other schemes\nsuch as averaging, task arithmetic, and Fisher-weighted averaging. Our new\nmethod gives consistent improvements for large language models and vision\ntransformers, both in terms of performance and robustness to hyperparameters.",
            "author": [
                "Nico Daheim",
                "Thomas M\u00f6llenhoff",
                "Edoardo Maria Ponti",
                "Iryna Gurevych",
                "Mohammad Emtiyaz Khan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12808v1",
                "http://arxiv.org/pdf/2310.12808v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12806v1",
            "title": "DCSI -- An improved measure of cluster separability based on separation\n  and connectedness",
            "updated": "2023-10-19T15:01:57Z",
            "published": "2023-10-19T15:01:57Z",
            "summary": "Whether class labels in a given data set correspond to meaningful clusters is\ncrucial for the evaluation of clustering algorithms using real-world data sets.\nThis property can be quantified by separability measures. A review of the\nexisting literature shows that neither classification-based complexity measures\nnor cluster validity indices (CVIs) adequately incorporate the central aspects\nof separability for density-based clustering: between-class separation and\nwithin-class connectedness. A newly developed measure (density cluster\nseparability index, DCSI) aims to quantify these two characteristics and can\nalso be used as a CVI. Extensive experiments on synthetic data indicate that\nDCSI correlates strongly with the performance of DBSCAN measured via the\nadjusted rand index (ARI) but lacks robustness when it comes to multi-class\ndata sets with overlapping classes that are ill-suited for density-based hard\nclustering. Detailed evaluation on frequently used real-world data sets shows\nthat DCSI can correctly identify touching or overlapping classes that do not\nform meaningful clusters.",
            "author": [
                "Jana Gauss",
                "Fabian Scheipl",
                "Moritz Herrmann"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12806v1",
                "http://arxiv.org/pdf/2310.12806v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12805v1",
            "title": "Detection and Evaluation of bias-inducing Features in Machine learning",
            "updated": "2023-10-19T15:01:16Z",
            "published": "2023-10-19T15:01:16Z",
            "summary": "The cause-to-effect analysis can help us decompose all the likely causes of a\nproblem, such as an undesirable business situation or unintended harm to the\nindividual(s). This implies that we can identify how the problems are\ninherited, rank the causes to help prioritize fixes, simplify a complex problem\nand visualize them. In the context of machine learning (ML), one can use\ncause-to-effect analysis to understand the reason for the biased behavior of\nthe system. For example, we can examine the root causes of biases by checking\neach feature for a potential cause of bias in the model. To approach this, one\ncan apply small changes to a given feature or a pair of features in the data,\nfollowing some guidelines and observing how it impacts the decision made by the\nmodel (i.e., model prediction). Therefore, we can use cause-to-effect analysis\nto identify the potential bias-inducing features, even when these features are\noriginally are unknown. This is important since most current methods require a\npre-identification of sensitive features for bias assessment and can actually\nmiss other relevant bias-inducing features, which is why systematic\nidentification of such features is necessary. Moreover, it often occurs that to\nachieve an equitable outcome, one has to take into account sensitive features\nin the model decision. Therefore, it should be up to the domain experts to\ndecide based on their knowledge of the context of a decision whether bias\ninduced by specific features is acceptable or not. In this study, we propose an\napproach for systematically identifying all bias-inducing features of a model\nto help support the decision-making of domain experts. We evaluated our\ntechnique using four well-known datasets to showcase how our contribution can\nhelp spearhead the standard procedure when developing, testing, maintaining,\nand deploying fair/equitable machine learning systems.",
            "author": [
                "Moses Openja",
                "Gabriel Laberge",
                "Foutse Khomh"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12805v1",
                "http://arxiv.org/pdf/2310.12805v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12804v1",
            "title": "Differentiable Vertex Fitting for Jet Flavour Tagging",
            "updated": "2023-10-19T15:01:05Z",
            "published": "2023-10-19T15:01:05Z",
            "summary": "We propose a differentiable vertex fitting algorithm that can be used for\nsecondary vertex fitting, and that can be seamlessly integrated into neural\nnetworks for jet flavour tagging. Vertex fitting is formulated as an\noptimization problem where gradients of the optimized solution vertex are\ndefined through implicit differentiation and can be passed to upstream or\ndownstream neural network components for network training. More broadly, this\nis an application of differentiable programming to integrate physics knowledge\ninto neural network models in high energy physics. We demonstrate how\ndifferentiable secondary vertex fitting can be integrated into larger\ntransformer-based models for flavour tagging and improve heavy flavour jet\nclassification.",
            "author": [
                "Rachel E. C. Smith",
                "In\u00eas Ochoa",
                "R\u00faben In\u00e1cio",
                "Jonathan Shoemaker",
                "Michael Kagan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12804v1",
                "http://arxiv.org/pdf/2310.12804v1"
            ],
            "primary_category": "hep-ex",
            "category": [
                "hep-ex",
                "cs.LG",
                "hep-ph",
                "physics.data-an"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12803v1",
            "title": "Causal-structure Driven Augmentations for Text OOD Generalization",
            "updated": "2023-10-19T14:59:25Z",
            "published": "2023-10-19T14:59:25Z",
            "summary": "The reliance of text classifiers on spurious correlations can lead to poor\ngeneralization at deployment, raising concerns about their use in\nsafety-critical domains such as healthcare. In this work, we propose to use\ncounterfactual data augmentation, guided by knowledge of the causal structure\nof the data, to simulate interventions on spurious features and to learn more\nrobust text classifiers. We show that this strategy is appropriate in\nprediction problems where the label is spuriously correlated with an attribute.\nUnder the assumptions of such problems, we discuss the favorable sample\ncomplexity of counterfactual data augmentation, compared to importance\nre-weighting. Pragmatically, we match examples using auxiliary data, based on\ndiff-in-diff methodology, and use a large language model (LLM) to represent a\nconditional probability of text. Through extensive experimentation on learning\ncaregiver-invariant predictors of clinical diagnoses from medical narratives\nand on semi-synthetic data, we demonstrate that our method for simulating\ninterventions improves out-of-distribution (OOD) accuracy compared to baseline\ninvariant learning algorithms.",
            "author": [
                "Amir Feder",
                "Yoav Wald",
                "Claudia Shi",
                "Suchi Saria",
                "David Blei"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12803v1",
                "http://arxiv.org/pdf/2310.12803v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.12802v2",
            "title": "An effective theory of collective deep learning",
            "updated": "2023-11-09T11:57:39Z",
            "published": "2023-10-19T14:58:20Z",
            "summary": "Unraveling the emergence of collective learning in systems of coupled\nartificial neural networks points to broader implications for machine learning,\nneuroscience, and society. Here we introduce a minimal model that condenses\nseveral recent decentralized algorithms by considering a competition between\ntwo terms: the local learning dynamics in the parameters of each neural network\nunit, and a diffusive coupling among units that tends to homogenize the\nparameters of the ensemble. We derive an effective theory for linear networks\nto show that the coarse-grained behavior of our system is equivalent to a\ndeformed Ginzburg-Landau model with quenched disorder. This framework predicts\ndepth-dependent disorder-order-disorder phase transitions in the parameters'\nsolutions that reveal a depth-delayed onset of a collective learning phase and\na low-rank microscopic learning path. We validate the theory in coupled\nensembles of realistic neural networks trained on the MNIST dataset under\nprivacy constraints. Interestingly, experiments confirm that individual\nnetworks -- trained on private data -- can fully generalize to unseen data\nclasses when the collective learning phase emerges. Our work establishes the\nphysics of collective learning and contributes to the mechanistic\ninterpretability of deep learning in decentralized settings.",
            "author": [
                "Llu\u00eds Arola-Fern\u00e1ndez",
                "Lucas Lacasa"
            ],
            "link": [
                "http://arxiv.org/abs/2310.12802v2",
                "http://arxiv.org/pdf/2310.12802v2"
            ],
            "primary_category": "physics.soc-ph",
            "category": [
                "physics.soc-ph",
                "cond-mat.dis-nn",
                "cs.AI",
                "cs.LG",
                "nlin.AO"
            ]
        }
    }
]