[
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08827v1",
            "title": "A Deep Reinforcement Learning Approach to Efficient Distributed\n  Optimization",
            "updated": "2023-11-15T10:02:42Z",
            "published": "2023-11-15T10:02:42Z",
            "summary": "In distributed optimization, the practical problem-solving performance is\nessentially sensitive to algorithm selection, parameter setting, problem type\nand data pattern. Thus, it is often laborious to acquire a highly efficient\nmethod for a given specific problem. In this paper, we propose a learning-based\nmethod to achieve efficient distributed optimization over networked systems.\nSpecifically, a deep reinforcement learning (DRL) framework is developed for\nadaptive configuration within a parameterized unifying algorithmic form, which\nincorporates an abundance of first-order and second-order optimization\nalgorithms that can be implemented in a decentralized fashion. We exploit the\nlocal consensus and objective information to represent the regularities of\nproblem instances and trace the solving progress, which constitute the states\nobserved by an RL agent. The framework is trained using Proximal Policy\nOptimization (PPO) on a number of practical problem instances of similar\nstructures yet different problem data. Experiments on various smooth and\nnon-smooth classes of objective functions demonstrate that our proposed\nlearning-based method outperforms several state-of-the-art distributed\noptimization algorithms in terms of convergence speed and solution accuracy.",
            "author": [
                "Daokuan Zhu",
                "Jie Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08827v1",
                "http://arxiv.org/pdf/2311.08827v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08820v1",
            "title": "Reinforcement Learning with Model Predictive Control for Highway Ramp\n  Metering",
            "updated": "2023-11-15T09:50:54Z",
            "published": "2023-11-15T09:50:54Z",
            "summary": "In the backdrop of an increasingly pressing need for effective urban and\nhighway transportation systems, this work explores the synergy between\nmodel-based and learning-based strategies to enhance traffic flow management by\nuse of an innovative approach to the problem of highway ramp metering control\nthat embeds Reinforcement Learning techniques within the Model Predictive\nControl framework. The control problem is formulated as an RL task by crafting\na suitable stage cost function that is representative of the traffic\nconditions, variability in the control action, and violations of a\nsafety-critical constraint on the maximum number of vehicles in queue. An\nMPC-based RL approach, which merges the advantages of the two paradigms in\norder to overcome the shortcomings of each framework, is proposed to learn to\nefficiently control an on-ramp and to satisfy its constraints despite\nuncertainties in the system model and variable demands. Finally, simulations\nare performed on a benchmark from the literature consisting of a small-scale\nhighway network. Results show that, starting from an MPC controller that has an\nimprecise model and is poorly tuned, the proposed methodology is able to\neffectively learn to improve the control policy such that congestion in the\nnetwork is reduced and constraints are satisfied, yielding an improved\nperformance compared to the initial controller.",
            "author": [
                "Filippo Airaldi",
                "Bart De Schutter",
                "Azita Dabiri"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08820v1",
                "http://arxiv.org/pdf/2311.08820v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.AI",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08819v1",
            "title": "Frequency Domain-based Dataset Distillation",
            "updated": "2023-11-15T09:46:30Z",
            "published": "2023-11-15T09:46:30Z",
            "summary": "This paper presents FreD, a novel parameterization method for dataset\ndistillation, which utilizes the frequency domain to distill a small-sized\nsynthetic dataset from a large-sized original dataset. Unlike conventional\napproaches that focus on the spatial domain, FreD employs frequency-based\ntransforms to optimize the frequency representations of each data instance. By\nleveraging the concentration of spatial domain information on specific\nfrequency components, FreD intelligently selects a subset of frequency\ndimensions for optimization, leading to a significant reduction in the required\nbudget for synthesizing an instance. Through the selection of frequency\ndimensions based on the explained variance, FreD demonstrates both theoretical\nand empirical evidence of its ability to operate efficiently within a limited\nbudget, while better preserving the information of the original dataset\ncompared to conventional parameterization methods. Furthermore, based on the\northogonal compatibility of FreD with existing methods, we confirm that FreD\nconsistently improves the performances of existing distillation methods over\nthe evaluation scenarios with different benchmark datasets. We release the code\nat https://github.com/sdh0818/FreD.",
            "author": [
                "Donghyeok Shin",
                "Seungjae Shin",
                "Il-Chul Moon"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08819v1",
                "http://arxiv.org/pdf/2311.08819v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08817v1",
            "title": "MAP's not dead yet: Uncovering true language model modes by conditioning\n  away degeneracy",
            "updated": "2023-11-15T09:38:53Z",
            "published": "2023-11-15T09:38:53Z",
            "summary": "It has been widely observed that exact or approximate MAP (mode-seeking)\ndecoding from natural language generation (NLG) models consistently leads to\ndegenerate outputs (Stahlberg and Byrne, 2019, Holtzman et al., 2019). This has\ngenerally been attributed to either a fundamental inadequacy of modes in models\nor weaknesses in language modeling. Contrastingly in this work, we emphasize\nthat degenerate modes can even occur in the absence of any model error, due to\ncontamination of the training data. Specifically, we show that mixing even a\ntiny amount of low-entropy noise with a population text distribution can cause\nthe data distribution's mode to become degenerate, implying that any models\ntrained on it will be as well. As the unconditional mode of NLG models will\noften be degenerate, we therefore propose to apply MAP decoding to the model's\ndistribution conditional on avoiding specific degeneracies. Using exact-search,\nwe empirically verify that the length-conditional modes of machine translation\nmodels and language models are indeed more fluent and topical than their\nunconditional modes. For the first time, we also share many examples of exact\nmodal sequences from these models, and from several variants of the LLaMA-7B\nmodel. Notably, the modes of the LLaMA models are still degenerate, showing\nthat improvements in modeling have not fixed this issue. Because of the cost of\nexact mode finding algorithms, we develop an approximate mode finding approach,\nACBS, which finds sequences that are both high-likelihood and high-quality. We\napply this approach to LLaMA-7B, a model which was not trained for instruction\nfollowing, and find that we are able to elicit reasonable outputs without any\nfinetuning.",
            "author": [
                "Davis Yoshida",
                "Kartik Goyal",
                "Kevin Gimpel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08817v1",
                "http://arxiv.org/pdf/2311.08817v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08815v1",
            "title": "Self-Supervised Disentanglement by Leveraging Structure in Data\n  Augmentations",
            "updated": "2023-11-15T09:34:08Z",
            "published": "2023-11-15T09:34:08Z",
            "summary": "Self-supervised representation learning often uses data augmentations to\ninduce some invariance to \"style\" attributes of the data. However, with\ndownstream tasks generally unknown at training time, it is difficult to deduce\na priori which attributes of the data are indeed \"style\" and can be safely\ndiscarded. To address this, we introduce a more principled approach that seeks\nto disentangle style features rather than discard them. The key idea is to add\nmultiple style embedding spaces where: (i) each is invariant to all-but-one\naugmentation; and (ii) joint entropy is maximized. We formalize our structured\ndata-augmentation procedure from a causal latent-variable-model perspective,\nand prove identifiability of both content and (multiple blocks of) style\nvariables. We empirically demonstrate the benefits of our approach on synthetic\ndatasets and then present promising but limited results on ImageNet.",
            "author": [
                "Cian Eastwood",
                "Julius von K\u00fcgelgen",
                "Linus Ericsson",
                "Diane Bouchacourt",
                "Pascal Vincent",
                "Bernhard Sch\u00f6lkopf",
                "Mark Ibrahim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08815v1",
                "http://arxiv.org/pdf/2311.08815v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08811v1",
            "title": "Correlation-aware active learning for surgery video segmentation",
            "updated": "2023-11-15T09:30:52Z",
            "published": "2023-11-15T09:30:52Z",
            "summary": "Semantic segmentation is a complex task that relies heavily on large amounts\nof annotated image data. However, annotating such data can be time-consuming\nand resource-intensive, especially in the medical domain. Active Learning (AL)\nis a popular approach that can help to reduce this burden by iteratively\nselecting images for annotation to improve the model performance. In the case\nof video data, it is important to consider the model uncertainty and the\ntemporal nature of the sequences when selecting images for annotation. This\nwork proposes a novel AL strategy for surgery video segmentation, \\COALSamp{},\nCOrrelation-aWare Active Learning. Our approach involves projecting images into\na latent space that has been fine-tuned using contrastive learning and then\nselecting a fixed number of representative images from local clusters of video\nframes. We demonstrate the effectiveness of this approach on two video datasets\nof surgical instruments and three real-world video datasets. The datasets and\ncode will be made publicly available upon receiving necessary approvals.",
            "author": [
                "Fei Wu",
                "Pablo Marquez-Neila",
                "Mingyi Zheng",
                "Hedyeh Rafii-Tari",
                "Raphael Sznitman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08811v1",
                "http://arxiv.org/pdf/2311.08811v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08808v1",
            "title": "Degradation Estimation Recurrent Neural Network with Local and Non-Local\n  Priors for Compressive Spectral Imaging",
            "updated": "2023-11-15T09:23:42Z",
            "published": "2023-11-15T09:23:42Z",
            "summary": "In coded aperture snapshot spectral imaging (CASSI) systems, a core problem\nis to recover the 3D hyperspectral image (HSI) from the 2D measurement. Current\ndeep unfolding networks (DUNs) for the HSI reconstruction mainly suffered from\nthree issues. Firstly, in previous DUNs, the DNNs across different stages were\nunable to share the feature representations learned from different stages,\nleading to parameter sparsity, which in turn limited their reconstruction\npotential. Secondly, previous DUNs fail to estimate degradation-related\nparameters within a unified framework, including the degradation matrix in the\ndata subproblem and the noise level in the prior subproblem. Consequently,\neither the accuracy of solving the data or the prior subproblem is compromised.\nThirdly, exploiting both local and non-local priors for the HSI reconstruction\nis crucial, and it remains a key issue to be addressed. In this paper, we first\ntransform the DUN into a Recurrent Neural Network (RNN) by sharing parameters\nacross stages, which allows the DNN in each stage could learn feature\nrepresentation from different stages, enhancing the representativeness of the\nDUN. Secondly, we incorporate the Degradation Estimation Network into the RNN\n(DERNN), which simultaneously estimates the degradation matrix and the noise\nlevel by residual learning with reference to the sensing matrix. Thirdly, we\npropose a Local and Non-Local Transformer (LNLT) to effectively exploit both\nlocal and non-local priors in HSIs. By integrating the LNLT into the DERNN for\nsolving the prior subproblem, we propose the DERNN-LNLT, which achieves\nstate-of-the-art performance.",
            "author": [
                "Yubo Dong",
                "Dahua Gao",
                "Yuyan Li",
                "Guangming Shi",
                "Danhua Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08808v1",
                "http://arxiv.org/pdf/2311.08808v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08798v1",
            "title": "X-GRL: An Empirical Assessment of Explainable GNN-DRL in B5G/6G Networks",
            "updated": "2023-11-15T09:11:37Z",
            "published": "2023-11-15T09:11:37Z",
            "summary": "The rapid development of artificial intelligence (AI) techniques has\ntriggered a revolution in beyond fifth-generation (B5G) and upcoming\nsixth-generation (6G) mobile networks. Despite these advances, efficient\nresource allocation in dynamic and complex networks remains a major challenge.\nThis paper presents an experimental implementation of deep reinforcement\nlearning (DRL) enhanced with graph neural networks (GNNs) on a real 5G testbed.\nThe method addresses the explainability of GNNs by evaluating the importance of\neach edge in determining the model's output. The custom sampling functions feed\nthe data into the proposed GNN-driven Monte Carlo policy gradient (REINFORCE)\nagent to optimize the gNodeB (gNB) radio resources according to the specific\ntraffic demands. The demo demonstrates real-time visualization of network\nparameters and superior performance compared to benchmarks.",
            "author": [
                "Farhad Rezazadeh",
                "Sergio Barrachina-MuNoz",
                "Engin Zeydan",
                "Houbing Song",
                "K. P. Subbalakshmi",
                "Josep Mangues-Bafalluy"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08798v1",
                "http://arxiv.org/pdf/2311.08798v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08793v1",
            "title": "German FinBERT: A German Pre-trained Language Model",
            "updated": "2023-11-15T09:07:29Z",
            "published": "2023-11-15T09:07:29Z",
            "summary": "This study presents German FinBERT, a novel pre-trained German language model\ntailored for financial textual data. The model is trained through a\ncomprehensive pre-training process, leveraging a substantial corpus comprising\nfinancial reports, ad-hoc announcements and news related to German companies.\nThe corpus size is comparable to the data sets commonly used for training\nstandard BERT models. I evaluate the performance of German FinBERT on\ndownstream tasks, specifically sentiment prediction, topic recognition and\nquestion answering against generic German language models. My results\ndemonstrate improved performance on finance-specific data, indicating the\nefficacy of German FinBERT in capturing domain-specific nuances. The presented\nfindings suggest that German FinBERT holds promise as a valuable tool for\nfinancial text analysis, potentially benefiting various applications in the\nfinancial domain.",
            "author": [
                "Moritz Scherrmann"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08793v1",
                "http://arxiv.org/pdf/2311.08793v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08792v1",
            "title": "Matroids in OSCAR",
            "updated": "2023-11-15T09:07:08Z",
            "published": "2023-11-15T09:07:08Z",
            "summary": "OSCAR is an innovative new computer algebra system which combines and extends\nthe power of its four cornerstone systems - GAP (group theory), Singular\n(algebra and algebraic geometry), Polymake (polyhedral geometry), and Antic\n(number theory). Here, we present parts of the module handeling matroids in\nOSCAR, which will appear as a chapter of the upcoming OSCAR book. A matroid is\na fundamental and actively studied object in combinatorics. Matroids generalize\nlinear dependency in vector spaces as well as many aspects of graph theory.\nMoreover, matroids form a cornerstone of tropical geometry and a deep link\nbetween algebraic geometry and combinatorics. Our focus lies in particular on\ncomputing the realization space and the Chow ring of a matroid.",
            "author": [
                "Daniel Corey",
                "Lukas K\u00fchne",
                "Benjamin Schr\u00f6ter"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08792v1",
                "http://arxiv.org/pdf/2311.08792v1"
            ],
            "primary_category": "math.CO",
            "category": [
                "math.CO",
                "math.AG",
                "05-04 (05-02, 05E14)"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14710v1",
            "title": "Neuroscience inspired scientific machine learning (Part-2): Variable\n  spiking wavelet neural operator",
            "updated": "2023-11-15T09:02:01Z",
            "published": "2023-11-15T09:02:01Z",
            "summary": "We propose, in this paper, a Variable Spiking Wavelet Neural Operator\n(VS-WNO), which aims to bridge the gap between theoretical and practical\nimplementation of Artificial Intelligence (AI) algorithms for mechanics\napplications. With recent developments like the introduction of neural\noperators, AI's potential for being used in mechanics applications has\nincreased significantly. However, AI's immense energy and resource requirements\nare a hurdle in its practical field use case. The proposed VS-WNO is based on\nthe principles of spiking neural networks, which have shown promise in reducing\nthe energy requirements of the neural networks. This makes possible the use of\nsuch algorithms in edge computing. The proposed VS-WNO utilizes variable\nspiking neurons, which promote sparse communication, thus conserving energy,\nand its use is further supported by its ability to tackle regression tasks,\noften faced in the field of mechanics. Various examples dealing with partial\ndifferential equations, like Burger's equation, Allen Cahn's equation, and\nDarcy's equation, have been shown. Comparisons have been shown against wavelet\nneural operator utilizing leaky integrate and fire neurons (direct and encoded\ninputs) and vanilla wavelet neural operator utilizing artificial neurons. The\nresults produced illustrate the ability of the proposed VS-WNO to converge to\nground truth while promoting sparse communication.",
            "author": [
                "Shailesh Garg",
                "Souvik Chakraborty"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14710v1",
                "http://arxiv.org/pdf/2311.14710v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08788v1",
            "title": "X-Eval: Generalizable Multi-aspect Text Evaluation via Augmented\n  Instruction Tuning with Auxiliary Evaluation Aspects",
            "updated": "2023-11-15T09:01:55Z",
            "published": "2023-11-15T09:01:55Z",
            "summary": "Natural Language Generation (NLG) typically involves evaluating the generated\ntext in various aspects (e.g., consistency and naturalness) to obtain a\ncomprehensive assessment. However, multi-aspect evaluation remains challenging\nas it may require the evaluator to generalize to any given evaluation aspect\neven if it's absent during training. In this paper, we introduce X-Eval, a\ntwo-stage instruction tuning framework to evaluate the text in both seen and\nunseen aspects customized by end users. X-Eval consists of two learning stages:\nthe vanilla instruction tuning stage that improves the model's ability to\nfollow evaluation instructions, and an enhanced instruction tuning stage that\nexploits the connections between fine-grained evaluation aspects to better\nassess text quality. To support the training of X-Eval, we collect\nAspectInstruct, the first instruction tuning dataset tailored for multi-aspect\nNLG evaluation spanning 27 diverse evaluation aspects with 65 tasks. To enhance\ntask diversity, we devise an augmentation strategy that converts human rating\nannotations into diverse forms of NLG evaluation tasks, including scoring,\ncomparison, ranking, and Boolean question answering. Extensive experiments\nacross three essential categories of NLG tasks: dialogue generation,\nsummarization, and data-to-text coupled with 21 aspects in meta-evaluation,\ndemonstrate that our X-Eval enables even a lightweight language model to\nachieve a comparable if not higher correlation with human judgments compared to\nthe state-of-the-art NLG evaluators, such as GPT-4.",
            "author": [
                "Minqian Liu",
                "Ying Shen",
                "Zhiyang Xu",
                "Yixin Cao",
                "Eunah Cho",
                "Vaibhav Kumar",
                "Reza Ghanadan",
                "Lifu Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08788v1",
                "http://arxiv.org/pdf/2311.08788v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.09267v1",
            "title": "Neuroscience inspired scientific machine learning (Part-1): Variable\n  spiking neuron for regression",
            "updated": "2023-11-15T08:59:06Z",
            "published": "2023-11-15T08:59:06Z",
            "summary": "Redundant information transfer in a neural network can increase the\ncomplexity of the deep learning model, thus increasing its power consumption.\nWe introduce in this paper a novel spiking neuron, termed Variable Spiking\nNeuron (VSN), which can reduce the redundant firing using lessons from\nbiological neuron inspired Leaky Integrate and Fire Spiking Neurons (LIF-SN).\nThe proposed VSN blends LIF-SN and artificial neurons. It garners the advantage\nof intermittent firing from the LIF-SN and utilizes the advantage of continuous\nactivation from the artificial neuron. This property of the proposed VSN makes\nit suitable for regression tasks, which is a weak point for the vanilla spiking\nneurons, all while keeping the energy budget low. The proposed VSN is tested\nagainst both classification and regression tasks. The results produced advocate\nfavorably towards the efficacy of the proposed spiking neuron, particularly for\nregression tasks.",
            "author": [
                "Shailesh Garg",
                "Souvik Chakraborty"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09267v1",
                "http://arxiv.org/pdf/2311.09267v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08782v1",
            "title": "Language Semantic Graph Guided Data-Efficient Learning",
            "updated": "2023-11-15T08:54:57Z",
            "published": "2023-11-15T08:54:57Z",
            "summary": "Developing generalizable models that can effectively learn from limited data\nand with minimal reliance on human supervision is a significant objective\nwithin the machine learning community, particularly in the era of deep neural\nnetworks. Therefore, to achieve data-efficient learning, researchers typically\nexplore approaches that can leverage more related or unlabeled data without\nnecessitating additional manual labeling efforts, such as Semi-Supervised\nLearning (SSL), Transfer Learning (TL), and Data Augmentation (DA). SSL\nleverages unlabeled data in the training process, while TL enables the transfer\nof expertise from related data distributions. DA broadens the dataset by\nsynthesizing new data from existing examples. However, the significance of\nadditional knowledge contained within labels has been largely overlooked in\nresearch. In this paper, we propose a novel perspective on data efficiency that\ninvolves exploiting the semantic information contained in the labels of the\navailable data. Specifically, we introduce a Language Semantic Graph (LSG)\nwhich is constructed from labels manifest as natural language descriptions.\nUpon this graph, an auxiliary graph neural network is trained to extract\nhigh-level semantic relations and then used to guide the training of the\nprimary model, enabling more adequate utilization of label knowledge. Across\nimage, video, and audio modalities, we utilize the LSG method in both TL and\nSSL scenarios and illustrate its versatility in significantly enhancing\nperformance compared to other data-efficient learning approaches. Additionally,\nour in-depth analysis shows that the LSG method also expedites the training\nprocess.",
            "author": [
                "Wenxuan Ma",
                "Shuang Li",
                "Lincan Cai",
                "Jingxuan Kang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08782v1",
                "http://arxiv.org/pdf/2311.08782v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08774v2",
            "title": "Two-stage Joint Transductive and Inductive learning for Nuclei\n  Segmentation",
            "updated": "2023-11-17T19:26:53Z",
            "published": "2023-11-15T08:37:11Z",
            "summary": "AI-assisted nuclei segmentation in histopathological images is a crucial task\nin the diagnosis and treatment of cancer diseases. It decreases the time\nrequired to manually screen microscopic tissue images and can resolve the\nconflict between pathologists during diagnosis. Deep Learning has proven useful\nin such a task. However, lack of labeled data is a significant barrier for deep\nlearning-based approaches. In this study, we propose a novel approach to nuclei\nsegmentation that leverages the available labelled and unlabelled data. The\nproposed method combines the strengths of both transductive and inductive\nlearning, which have been previously attempted separately, into a single\nframework. Inductive learning aims at approximating the general function and\ngeneralizing to unseen test data, while transductive learning has the potential\nof leveraging the unlabelled test data to improve the classification. To the\nbest of our knowledge, this is the first study to propose such a hybrid\napproach for medical image segmentation. Moreover, we propose a novel two-stage\ntransductive inference scheme. We evaluate our approach on MoNuSeg benchmark to\ndemonstrate the efficacy and potential of our method.",
            "author": [
                "Hesham Ali",
                "Idriss Tondji",
                "Mennatullah Siam"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08774v2",
                "http://arxiv.org/pdf/2311.08774v2"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.09266v1",
            "title": "Adversarially Robust Spiking Neural Networks Through Conversion",
            "updated": "2023-11-15T08:33:46Z",
            "published": "2023-11-15T08:33:46Z",
            "summary": "Spiking neural networks (SNNs) provide an energy-efficient alternative to a\nvariety of artificial neural network (ANN) based AI applications. As the\nprogress in neuromorphic computing with SNNs expands their use in applications,\nthe problem of adversarial robustness of SNNs becomes more pronounced. To the\ncontrary of the widely explored end-to-end adversarial training based\nsolutions, we address the limited progress in scalable robust SNN training\nmethods by proposing an adversarially robust ANN-to-SNN conversion algorithm.\nOur method provides an efficient approach to embrace various computationally\ndemanding robust learning objectives that have been proposed for ANNs. During a\npost-conversion robust finetuning phase, our method adversarially optimizes\nboth layer-wise firing thresholds and synaptic connectivity weights of the SNN\nto maintain transferred robustness gains from the pre-trained ANN. We perform\nexperimental evaluations in numerous adaptive adversarial settings that account\nfor the spike-based operation dynamics of SNNs, and show that our approach\nyields a scalable state-of-the-art solution for adversarially robust deep SNNs\nwith low-latency.",
            "author": [
                "Ozan \u00d6zdenizci",
                "Robert Legenstein"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09266v1",
                "http://arxiv.org/pdf/2311.09266v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14709v1",
            "title": "Towards Long-term Annotators: A Supervised Label Aggregation Baseline",
            "updated": "2023-11-15T08:25:36Z",
            "published": "2023-11-15T08:25:36Z",
            "summary": "Relying on crowdsourced workers, data crowdsourcing platforms are able to\nefficiently provide vast amounts of labeled data. Due to the variability in the\nannotation quality of crowd workers, modern techniques resort to redundant\nannotations and subsequent label aggregation to infer true labels. However,\nthese methods require model updating during the inference, posing challenges in\nreal-world implementation. Meanwhile, in recent years, many data labeling tasks\nhave begun to require skilled and experienced annotators, leading to an\nincreasing demand for long-term annotators. These annotators could leave\nsubstantial historical annotation records on the crowdsourcing platforms, which\ncan benefit label aggregation, but are ignored by previous works. Hereby, in\nthis paper, we propose a novel label aggregation technique, which does not need\nany model updating during inference and can extensively explore the historical\nannotation records. We call it SuperLA, a Supervised Label Aggregation method.\nInside this model, we design three types of input features and a\nstraightforward neural network structure to merge all the information together\nand subsequently produce aggregated labels. Based on comparison experiments\nconducted on 22 public datasets and 11 baseline methods, we find that SuperLA\nnot only outperforms all those baselines in inference performance but also\noffers significant advantages in terms of efficiency.",
            "author": [
                "Haoyu Liu",
                "Fei Wang",
                "Minmin Lin",
                "Runze Wu",
                "Renyu Zhu",
                "Shiwei Zhao",
                "Kai Wang",
                "Tangjie Lv",
                "Changjie Fan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14709v1",
                "http://arxiv.org/pdf/2311.14709v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08768v1",
            "title": "Three Conjectures on Unexpectedeness",
            "updated": "2023-11-15T08:24:41Z",
            "published": "2023-11-15T08:24:41Z",
            "summary": "Unexpectedness is a central concept in Simplicity Theory, a theory of\ncognition relating various inferential processes to the computation of\nKolmogorov complexities, rather than probabilities. Its predictive power has\nbeen confirmed by several experiments with human subjects, yet its theoretical\nbasis remains largely unexplored: why does it work? This paper lays the\ngroundwork for three theoretical conjectures. First, unexpectedness can be seen\nas a generalization of Bayes' rule. Second, the frequentist core of\nunexpectedness can be connected to the function of tracking ergodic properties\nof the world. Third, unexpectedness can be seen as constituent of various\nmeasures of divergence between the entropy of the world (environment) and the\nvariety of the observer (system). The resulting framework hints to research\ndirections that go beyond the division between probabilistic and logical\napproaches, potentially bringing new insights into the extraction of causal\nrelations, and into the role of descriptive mechanisms in learning.",
            "author": [
                "Giovanni Sileno",
                "Jean-Louis Dessalles"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08768v1",
                "http://arxiv.org/pdf/2311.08768v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.IT",
                "cs.SY",
                "eess.SY",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08765v1",
            "title": "Machine learning based dimension reduction for a stable modeling of\n  periodic flow phenomena",
            "updated": "2023-11-15T08:16:27Z",
            "published": "2023-11-15T08:16:27Z",
            "summary": "In designing efficient feedback control laws for fluid flow, the modern\ncontrol theory can serve as a powerful tool if the model can be represented by\na linear ordinary differential equation (ODE). However, it is generally\ndifficult to find such a linear model for strongly nonlinear and\nhigh-dimensional fluid flow phenomena. In this study, we propose an autoencoder\nwhich maps the periodic flow phenomena into a latent dynamics governed by a\nlinear ODE, referred to as a pseudo-symplectic Linear system Extracting\nAutoEncoder (LEAE). In addition to the normal functionality of autoencoder,\npseudo-symplectic LEAE emulates a symplectic time integration scheme so that\nthe Hamiltonian (i.e., the pseudo-energy) of the latent variables is conserved.\nWe demonstrate that the stability of the derived ODE is improved by considering\nthe integration stepping forward and backward at the same time. Here, we\nconsider the circular cylinder wake at $Re_D=100$ as a typical periodic flow\nphenomenon.",
            "author": [
                "Hiroshi Omichi",
                "Takeru Ishize",
                "Koji Fukagata"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08765v1",
                "http://arxiv.org/pdf/2311.08765v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08764v1",
            "title": "Combining Past, Present and Future: A Self-Supervised Approach for Class\n  Incremental Learning",
            "updated": "2023-11-15T08:13:52Z",
            "published": "2023-11-15T08:13:52Z",
            "summary": "Class Incremental Learning (CIL) aims to handle the scenario where data of\nnovel classes occur continuously and sequentially. The model should recognize\nthe sequential novel classes while alleviating the catastrophic forgetting. In\nthe self-supervised manner, it becomes more challenging to avoid the conflict\nbetween the feature embedding spaces of novel classes and old ones without any\nclass labels. To address the problem, we propose a self-supervised CIL\nframework CPPF, meaning Combining Past, Present and Future. In detail, CPPF\nconsists of a prototype clustering module (PC), an embedding space reserving\nmodule (ESR) and a multi-teacher distillation module (MTD). 1) The PC and the\nESR modules reserve embedding space for subsequent phases at the prototype\nlevel and the feature level respectively to prepare for knowledge learned in\nthe future. 2) The MTD module maintains the representations of the current\nphase without the interference of past knowledge. One of the teacher networks\nretains the representations of the past phases, and the other teacher network\ndistills relation information of the current phase to the student network.\nExtensive experiments on CIFAR100 and ImageNet100 datasets demonstrate that our\nproposed method boosts the performance of self-supervised class incremental\nlearning. We will release code in the near future.",
            "author": [
                "Xiaoshuang Chen",
                "Zhongyi Sun",
                "Ke Yan",
                "Shouhong Ding",
                "Hongtao Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08764v1",
                "http://arxiv.org/pdf/2311.08764v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08760v1",
            "title": "Forms of Understanding of XAI-Explanations",
            "updated": "2023-11-15T08:06:51Z",
            "published": "2023-11-15T08:06:51Z",
            "summary": "Explainability has become an important topic in computer science and\nartificial intelligence, leading to a subfield called Explainable Artificial\nIntelligence (XAI). The goal of providing or seeking explanations is to achieve\n(better) 'understanding' on the part of the explainee. However, what it means\nto 'understand' is still not clearly defined, and the concept itself is rarely\nthe subject of scientific investigation. This conceptual article aims to\npresent a model of forms of understanding in the context of XAI and beyond.\nFrom an interdisciplinary perspective bringing together computer science,\nlinguistics, sociology, and psychology, a definition of understanding and its\nforms, assessment, and dynamics during the process of giving everyday\nexplanations are explored. Two types of understanding are considered as\npossible outcomes of explanations, namely enabledness, 'knowing how' to do or\ndecide something, and comprehension, 'knowing that' -- both in different\ndegrees (from shallow to deep). Explanations regularly start with shallow\nunderstanding in a specific domain and can lead to deep comprehension and\nenabledness of the explanandum, which we see as a prerequisite for human users\nto gain agency. In this process, the increase of comprehension and enabledness\nare highly interdependent. Against the background of this systematization,\nspecial challenges of understanding in XAI are discussed.",
            "author": [
                "Hendrik Buschmeier",
                "Heike M. Buhl",
                "Friederike Kern",
                "Angela Grimminger",
                "Helen Beierling",
                "Josephine Fisher",
                "Andr\u00e9 Gro\u00df",
                "Ilona Horwath",
                "Nils Klowait",
                "Stefan Lazarov",
                "Michael Lenke",
                "Vivien Lohmer",
                "Katharina Rohlfing",
                "Ingrid Scharlau",
                "Amit Singh",
                "Lutz Terfloth",
                "Anna-Lisa Vollmer",
                "Yu Wang",
                "Annedore Wilmes",
                "Britta Wrede"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08760v1",
                "http://arxiv.org/pdf/2311.08760v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08759v1",
            "title": "4K-Resolution Photo Exposure Correction at 125 FPS with ~8K Parameters",
            "updated": "2023-11-15T08:01:12Z",
            "published": "2023-11-15T08:01:12Z",
            "summary": "The illumination of improperly exposed photographs has been widely corrected\nusing deep convolutional neural networks or Transformers. Despite with\npromising performance, these methods usually suffer from large parameter\namounts and heavy computational FLOPs on high-resolution photographs. In this\npaper, we propose extremely light-weight (with only ~8K parameters) Multi-Scale\nLinear Transformation (MSLT) networks under the multi-layer perception\narchitecture, which can process 4K-resolution sRGB images at 125\nFrame-Per-Second (FPS) by a Titan RTX GPU. Specifically, the proposed MSLT\nnetworks first decompose an input image into high and low frequency layers by\nLaplacian pyramid techniques, and then sequentially correct different layers by\npixel-adaptive linear transformation, which is implemented by efficient\nbilateral grid learning or 1x1 convolutions. Experiments on two benchmark\ndatasets demonstrate the efficiency of our MSLTs against the state-of-the-arts\non photo exposure correction. Extensive ablation studies validate the\neffectiveness of our contributions. The code is available at\nhttps://github.com/Zhou-Yijie/MSLTNet.",
            "author": [
                "Yijie Zhou",
                "Chao Li",
                "Jin Liang",
                "Tianyi Xu",
                "Xin Liu",
                "Jun Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08759v1",
                "http://arxiv.org/pdf/2311.08759v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08758v3",
            "title": "A Novel Tree Model-based DNN to Achieve a High-Resolution DOA Estimation\n  via Massive MIMO receive array",
            "updated": "2023-11-30T05:01:08Z",
            "published": "2023-11-15T07:58:54Z",
            "summary": "To satisfy the high-resolution requirements of direction-of-arrival (DOA)\nestimation, conventional deep neural network (DNN)-based methods using grid\nidea need to significantly increase the number of output classifications and\nalso produce a huge high model complexity. To address this problem, a\nmulti-level tree-based DNN model (TDNN) is proposed as an alternative, where\neach level takes small-scale multi-layer neural networks (MLNNs) as nodes to\ndivide the target angular interval into multiple sub-intervals, and each output\nclass is associated to a MLNN at the next level. Then the number of MLNNs is\ngradually increasing from the first level to the last level, and so increasing\nthe depth of tree will dramatically raise the number of output classes to\nimprove the estimation accuracy. More importantly, this network is extended to\nmake a multi-emitter DOA estimation. Simulation results show that the proposed\nTDNN performs much better than conventional DNN and root-MUSIC at extremely low\nsignal-to-noise ratio (SNR), and can achieve Cramer-Rao lower bound (CRLB).\nAdditionally, in the multi-emitter scenario, the proposed Q-TDNN has also made\na substantial performance enhancement over DNN and Root-MUSIC, and this gain\ngrows as the number of emitters increases.",
            "author": [
                "Yifan Li",
                "Feng Shu",
                "Jun Zou",
                "Wei Gao",
                "Yaoliang Song",
                "Jiangzhou Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08758v3",
                "http://arxiv.org/pdf/2311.08758v3"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.09264v1",
            "title": "Cross-domain feature disentanglement for interpretable modeling of tumor\n  microenvironment impact on drug response",
            "updated": "2023-11-15T07:50:54Z",
            "published": "2023-11-15T07:50:54Z",
            "summary": "High-throughput screening technology has facilitated the generation of\nlarge-scale drug responses across hundreds of cancer cell lines. However, there\nexists significant discrepancy between in vitro cell lines and actual tumors in\nvivo in terms of their response to drug treatments, because of tumors comprise\nof complex cellular compositions and histopathology structure, known as tumor\nmicroenvironment (TME), which greatly influences the drug cytotoxicity against\ntumor cells. To date, no study has focused on modeling the impact of the TME on\nclinical drug response. This paper proposed a domain adaptation network for\nfeature disentanglement to separate representations of cancer cells and TME of\na tumor in patients. Two denoising autoencoders were separately used to extract\nfeatures from cell lines (source domain) and tumors (target domain) for partial\ndomain alignment and feature decoupling. The specific encoder was enforced to\nextract information only about TME. Moreover, to ensure generalizability to\nnovel drugs, we applied a graph attention network to learn the latent\nrepresentation of drugs, allowing us to linearly model the drug perturbation on\ncellular state in latent space. We calibrated our model on a benchmark dataset\nand demonstrated its superior performance in predicting clinical drug response\nand dissecting the influence of the TME on drug efficacy.",
            "author": [
                "Jia Zhai",
                "Hui Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09264v1",
                "http://arxiv.org/pdf/2311.09264v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08755v1",
            "title": "Environment-independent mmWave Fall Detection with Interacting Multiple\n  Model",
            "updated": "2023-11-15T07:49:46Z",
            "published": "2023-11-15T07:49:46Z",
            "summary": "The ageing society brings attention to daily elderly care through sensing\ntechnologies. The future smart home is expected to enable in-home daily\nmonitoring, such as fall detection, for seniors in a non-invasive,\nnon-cooperative, and non-contact manner. The mmWave radar is a promising\ncandidate technology for its privacy-preserving and non-contact manner.\nHowever, existing solutions suffer from low accuracy and robustness due to\nenvironment dependent features. In this paper, we present FADE\n(\\underline{FA}ll \\underline{DE}tection), a practical fall detection radar\nsystem with enhanced accuracy and robustness in real-world scenarios. The key\nenabler underlying FADE is an interacting multiple model (IMM) state estimator\nthat can extract environment-independent features for highly accurate and\ninstantaneous fall detection. Furthermore, we proposed a robust multiple-user\ntracking system to deal with noises from the environment and other human\nbodies. We deployed our algorithm on low computing power and low power\nconsumption system-on-chip (SoC) composed of data front end, DSP, and ARM\nprocessor, and tested its performance in real-world. The experiment shows that\nthe accuracy of fall detection is up to 95\\%.",
            "author": [
                "Xuyao Yu",
                "Jiazhao Wang",
                "Wenchao Jiang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08755v1",
                "http://arxiv.org/pdf/2311.08755v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08754v1",
            "title": "Semi-supervised machine learning model for Lagrangian flow state\n  estimation",
            "updated": "2023-11-15T07:48:27Z",
            "published": "2023-11-15T07:48:27Z",
            "summary": "In recent years, many researchers have demonstrated the strength of\nsupervised machine learning for flow state estimation. Most of the studies\nassume that the sensors are fixed and the high-resolution ground truth can be\nprepared. However, the sensors are not always fixed and may be floating in\npractical situations -- for example, in oceanography and river hydraulics,\nsensors are generally floating. In addition, floating sensors make it more\ndifficult to collect the high-resolution ground truth. We here propose a\nmachine learning model for state estimation from such floating sensors without\nrequiring high-resolution ground-truth data for training. This model estimates\nvelocity fields only from floating sensor measurements and is trained with a\nloss function using only sensor locations. We call this loss function as a\n\"semi-supervised\" loss function, since the sensor measurements are utilized as\nthe ground truth but high-resolution data of the entire velocity fields are not\nrequired. To demonstrate the performance of the proposed model, we consider\nStokes' second problem and two-dimensional decaying homogeneous isotropic\nturbulence. Our results reveal that the proposed semi-supervised model can\nestimate velocity fields with reasonable accuracy when the appropriate number\nof sensors are spatially distributed to some extent in the domain. We also\ndiscuss the dependence of the estimation accuracy on the number and\ndistribution of sensors.",
            "author": [
                "Reno Miura",
                "Koji Fukagata"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08754v1",
                "http://arxiv.org/pdf/2311.08754v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.09263v1",
            "title": "Auto-ICL: In-Context Learning without Human Supervision",
            "updated": "2023-11-15T07:37:28Z",
            "published": "2023-11-15T07:37:28Z",
            "summary": "In the era of Large Language Models (LLMs), human-computer interaction has\nevolved towards natural language, offering unprecedented flexibility. Despite\nthis, LLMs are heavily reliant on well-structured prompts to function\nefficiently within the realm of In-Context Learning. Vanilla In-Context\nLearning relies on human-provided contexts, such as labeled examples, explicit\ninstructions, or other guiding mechanisms that shape the model's outputs. To\naddress this challenge, our study presents a universal framework named\nAutomatic In-Context Learning. Upon receiving a user's request, we ask the\nmodel to independently generate examples, including labels, instructions, or\nreasoning pathways. The model then leverages this self-produced context to\ntackle the given problem. Our approach is universally adaptable and can be\nimplemented in any setting where vanilla In-Context Learning is applicable. We\ndemonstrate that our method yields strong performance across a range of tasks,\nstanding up well when compared to existing methods.",
            "author": [
                "Jinghan Yang",
                "Shuming Ma",
                "Furu Wei"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09263v1",
                "http://arxiv.org/pdf/2311.09263v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08747v1",
            "title": "Improved Dense Nested Attention Network Based on Transformer for\n  Infrared Small Target Detection",
            "updated": "2023-11-15T07:29:24Z",
            "published": "2023-11-15T07:29:24Z",
            "summary": "Infrared small target detection based on deep learning offers unique\nadvantages in separating small targets from complex and dynamic backgrounds.\nHowever, the features of infrared small targets gradually weaken as the depth\nof convolutional neural network (CNN) increases. To address this issue, we\npropose a novel method for detecting infrared small targets called improved\ndense nested attention network (IDNANet), which is based on the transformer\narchitecture. We preserve the dense nested structure of dense nested attention\nnetwork (DNANet) and introduce the Swin-transformer during feature extraction\nstage to enhance the continuity of features. Furthermore, we integrate the\nACmix attention structure into the dense nested structure to enhance the\nfeatures of intermediate layers. Additionally, we design a weighted dice binary\ncross-entropy (WD-BCE) loss function to mitigate the negative impact of\nforeground-background imbalance in the samples. Moreover, we develop a dataset\nspecifically for infrared small targets, called BIT-SIRST. The dataset\ncomprises a significant amount of real-world targets and manually annotated\nlabels, as well as synthetic data and corresponding labels. We have evaluated\nthe effectiveness of our method through experiments conducted on public\ndatasets. In comparison to other state-of-the-art methods, our approach\noutperforms in terms of probability of detection (P_d), false-alarm rate (F_a),\nand mean intersection of union ($mIoU$). The $mIoU$ reaches 90.89 on the\nNUDT-SIRST dataset and 79.72 on the NUAA-SIRST dataset.",
            "author": [
                "Chun Bao",
                "Jie Cao",
                "Yaqian Ning",
                "Tianhua Zhao",
                "Zhijun Li",
                "Zechen Wang",
                "Li Zhang",
                "Qun Hao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08747v1",
                "http://arxiv.org/pdf/2311.08747v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08745v3",
            "title": "Using Stochastic Gradient Descent to Smooth Nonconvex Functions:\n  Analysis of Implicit Graduated Optimization with Optimal Noise Scheduling",
            "updated": "2023-11-29T03:12:00Z",
            "published": "2023-11-15T07:27:40Z",
            "summary": "The graduated optimization approach is a heuristic method for finding\nglobally optimal solutions for nonconvex functions and has been theoretically\nanalyzed in several studies. This paper defines a new family of nonconvex\nfunctions for graduated optimization, discusses their sufficient conditions,\nand provides a convergence analysis of the graduated optimization algorithm for\nthem. It shows that stochastic gradient descent (SGD) with mini-batch\nstochastic gradients has the effect of smoothing the function, the degree of\nwhich is determined by the learning rate and batch size. This finding provides\ntheoretical insights on why large batch sizes fall into sharp local minima, why\ndecaying learning rates and increasing batch sizes are superior to fixed\nlearning rates and batch sizes, and what the optimal learning rate scheduling\nis. To the best of our knowledge, this is the first paper to provide a\ntheoretical explanation for these aspects. Moreover, a new graduated\noptimization framework that uses a decaying learning rate and increasing batch\nsize is analyzed and experimental results of image classification that support\nour theoretical findings are reported.",
            "author": [
                "Naoki Sato",
                "Hideaki Iiduka"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08745v3",
                "http://arxiv.org/pdf/2311.08745v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08744v1",
            "title": "Towards Graph-Aware Diffusion Modeling for Collaborative Filtering",
            "updated": "2023-11-15T07:25:14Z",
            "published": "2023-11-15T07:25:14Z",
            "summary": "Recovering masked feedback with neural models is a popular paradigm in\nrecommender systems. Seeing the success of diffusion models in solving\nill-posed inverse problems, we introduce a conditional diffusion framework for\ncollaborative filtering that iteratively reconstructs a user's hidden\npreferences guided by its historical interactions. To better align with the\nintrinsic characteristics of implicit feedback data, we implement forward\ndiffusion by applying synthetic smoothing filters to interaction signals on an\nitem-item graph. The resulting reverse diffusion can be interpreted as a\npersonalized process that gradually refines preference scores. Through graph\nFourier transform, we equivalently characterize this model as an anisotropic\nGaussian diffusion in the graph spectral domain, establishing both forward and\nreverse formulations. Our model outperforms state-of-the-art methods by a large\nmargin on one dataset and yields competitive results on the others.",
            "author": [
                "Yunqin Zhu",
                "Chao Wang",
                "Hui Xiong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08744v1",
                "http://arxiv.org/pdf/2311.08744v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08743v1",
            "title": "Kernel-based independence tests for causal structure learning on\n  functional data",
            "updated": "2023-11-15T07:23:28Z",
            "published": "2023-11-15T07:23:28Z",
            "summary": "Measurements of systems taken along a continuous functional dimension, such\nas time or space, are ubiquitous in many fields, from the physical and\nbiological sciences to economics and engineering.Such measurements can be\nviewed as realisations of an underlying smooth process sampled over the\ncontinuum. However, traditional methods for independence testing and causal\nlearning are not directly applicable to such data, as they do not take into\naccount the dependence along the functional dimension. By using specifically\ndesigned kernels, we introduce statistical tests for bivariate, joint, and\nconditional independence for functional variables. Our method not only extends\nthe applicability to functional data of the HSIC and its d-variate version\n(d-HSIC), but also allows us to introduce a test for conditional independence\nby defining a novel statistic for the CPT based on the HSCIC, with optimised\nregularisation strength estimated through an evaluation rejection rate. Our\nempirical results of the size and power of these tests on synthetic functional\ndata show good performance, and we then exemplify their application to several\nconstraint- and regression-based causal structure learning problems, including\nboth synthetic examples and real socio-economic data.",
            "author": [
                "Felix Laumann",
                "Julius von K\u00fcgelgen",
                "Junhyung Park",
                "Bernhard Sch\u00f6lkopf",
                "Mauricio Barahona"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08743v1",
                "http://arxiv.org/pdf/2311.08743v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08740v1",
            "title": "AdVENTR: Autonomous Robot Navigation in Complex Outdoor Environments",
            "updated": "2023-11-15T07:10:13Z",
            "published": "2023-11-15T07:10:13Z",
            "summary": "We present a novel system, AdVENTR for autonomous robot navigation in\nunstructured outdoor environments that consist of uneven and vegetated\nterrains. Our approach is general and can enable both wheeled and legged robots\nto handle outdoor terrain complexity including unevenness, surface properties\nlike poor traction, granularity, obstacle stiffness, etc. We use data from\nsensors including RGB cameras, 3D Lidar, IMU, robot odometry, and pose\ninformation with efficient learning-based perception and planning algorithms\nthat can execute on edge computing hardware. Our system uses a scene-aware\nswitching method to perceive the environment for navigation at any time instant\nand dynamically switches between multiple perception algorithms. We test our\nsystem in a variety of sloped, rocky, muddy, and densely vegetated terrains and\ndemonstrate its performance on Husky and Spot robots.",
            "author": [
                "Kasun Weerakoon",
                "Adarsh Jagan Sathyamoorthy",
                "Mohamed Elnoor",
                "Dinesh Manocha"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08740v1",
                "http://arxiv.org/pdf/2311.08740v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08737v1",
            "title": "Probing Iron in Earth's Core With Molecular-Spin Dynamics",
            "updated": "2023-11-15T06:59:54Z",
            "published": "2023-11-15T06:59:54Z",
            "summary": "Dynamic compression of iron to Earth-core conditions is one of the few ways\nto gather important elastic and transport properties needed to uncover key\nmechanisms surrounding the geodynamo effect. Herein a new machine-learned\nab-initio derived molecular-spin dynamics (MSD) methodology with explicit\ntreatment for longitudinal spin-fluctuations is utilized to probe the dynamic\nphase-diagram of iron. This framework uniquely enables an accurate resolution\nof the phase-transition kinetics and Earth-core elastic properties, as\nhighlighted by compressional wave velocity and adiabatic bulk moduli\nmeasurements. In addition, a unique coupling of MSD with time-dependent density\nfunctional theory enables gauging electronic transport properties, critically\nimportant for resolving geodynamo dynamics.",
            "author": [
                "Svetoslav Nikolov",
                "Kushal Ramakrishna",
                "Andrew Rohskopf",
                "Mani Lokamani",
                "Julien Tranchida",
                "John Carpenter",
                "Attila Cangi",
                "Mitchell A. Wood"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08737v1",
                "http://arxiv.org/pdf/2311.08737v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08726v1",
            "title": "Uncertainty Estimation on Sequential Labeling via Uncertainty\n  Transmission",
            "updated": "2023-11-15T06:36:29Z",
            "published": "2023-11-15T06:36:29Z",
            "summary": "Sequential labeling is a task predicting labels for each token in a sequence,\nsuch as Named Entity Recognition (NER). NER tasks aim to extract entities and\npredict their labels given a text, which is important in information\nextraction. Although previous works have shown great progress in improving NER\nperformance, uncertainty estimation on NER (UE-NER) is still underexplored but\nessential. This work focuses on UE-NER, which aims to estimate uncertainty\nscores for the NER predictions. Previous uncertainty estimation models often\noverlook two unique characteristics of NER: the connection between entities\n(i.e., one entity embedding is learned based on the other ones) and wrong span\ncases in the entity extraction subtask. Therefore, we propose a Sequential\nLabeling Posterior Network (SLPN) to estimate uncertainty scores for the\nextracted entities, considering uncertainty transmitted from other tokens.\nMoreover, we have defined an evaluation strategy to address the specificity of\nwrong-span cases. Our SLPN has achieved significant improvements on two\ndatasets, such as a 5.54-point improvement in AUPR on the MIT-Restaurant\ndataset.",
            "author": [
                "Jianfeng He",
                "Linlin Yu",
                "Shuo Lei",
                "Chang-Tien Lu",
                "Feng Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08726v1",
                "http://arxiv.org/pdf/2311.08726v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.10764v1",
            "title": "Deep Group Interest Modeling of Full Lifelong User Behaviors for CTR\n  Prediction",
            "updated": "2023-11-15T06:36:11Z",
            "published": "2023-11-15T06:36:11Z",
            "summary": "Extracting users' interests from their lifelong behavior sequence is crucial\nfor predicting Click-Through Rate (CTR). Most current methods employ a\ntwo-stage process for efficiency: they first select historical behaviors\nrelated to the candidate item and then deduce the user's interest from this\nnarrowed-down behavior sub-sequence. This two-stage paradigm, though effective,\nleads to information loss. Solely using users' lifelong click behaviors doesn't\nprovide a complete picture of their interests, leading to suboptimal\nperformance. In our research, we introduce the Deep Group Interest Network\n(DGIN), an end-to-end method to model the user's entire behavior history. This\nincludes all post-registration actions, such as clicks, cart additions,\npurchases, and more, providing a nuanced user understanding. We start by\ngrouping the full range of behaviors using a relevant key (like item_id) to\nenhance efficiency. This process reduces the behavior length significantly,\nfrom O(10^4) to O(10^2). To mitigate the potential loss of information due to\ngrouping, we incorporate two categories of group attributes. Within each group,\nwe calculate statistical information on various heterogeneous behaviors (like\nbehavior counts) and employ self-attention mechanisms to highlight unique\nbehavior characteristics (like behavior type). Based on this reorganized\nbehavior data, the user's interests are derived using the Transformer\ntechnique. Additionally, we identify a subset of behaviors that share the same\nitem_id with the candidate item from the lifelong behavior sequence. The\ninsights from this subset reveal the user's decision-making process related to\nthe candidate item, improving prediction accuracy. Our comprehensive\nevaluation, both on industrial and public datasets, validates DGIN's efficacy\nand efficiency.",
            "author": [
                "Qi Liu",
                "Xuyang Hou",
                "Haoran Jin",
                "jin Chen",
                "Zhe Wang",
                "Defu Lian",
                "Tan Qu",
                "Jia Cheng",
                "Jun Lei"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10764v1",
                "http://arxiv.org/pdf/2311.10764v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08724v1",
            "title": "Method for Text Entity Linking in Power Distribution Scheduling Oriented\n  to Power Distribution Network Knowledge Graph",
            "updated": "2023-11-15T06:35:01Z",
            "published": "2023-11-15T06:35:01Z",
            "summary": "The proposed method for linking entities in power distribution dispatch texts\nto a power distribution network knowledge graph is based on a deep\nunderstanding of these networks. This method leverages the unique features of\nentities in both the power distribution network's knowledge graph and the\ndispatch texts, focusing on their semantic, phonetic, and syntactic\ncharacteristics. An enhanced model, the Lexical Semantic Feature-based Skip\nConvolutional Neural Network (LSF-SCNN), is utilized for effectively matching\ndispatch text entities with those in the knowledge graph. The efficacy of this\nmodel, compared to a control model, is evaluated through cross-validation\nmethods in real-world power distribution dispatch scenarios. The results\nindicate that the LSF-SCNN model excels in accurately linking a variety of\nentity types, demonstrating high overall accuracy in entity linking when the\nprocess is conducted in English.",
            "author": [
                "Xiang Li",
                "Che Wang",
                "Bing Li",
                "Hao Chen",
                "Sizhe Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08724v1",
                "http://arxiv.org/pdf/2311.08724v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.09261v1",
            "title": "Emerging Drug Interaction Prediction Enabled by Flow-based Graph Neural\n  Network with Biomedical Network",
            "updated": "2023-11-15T06:34:00Z",
            "published": "2023-11-15T06:34:00Z",
            "summary": "Accurately predicting drug-drug interactions (DDI) for emerging drugs, which\noffer possibilities for treating and alleviating diseases, with computational\nmethods can improve patient care and contribute to efficient drug development.\nHowever, many existing computational methods require large amounts of known DDI\ninformation, which is scarce for emerging drugs. In this paper, we propose\nEmerGNN, a graph neural network (GNN) that can effectively predict interactions\nfor emerging drugs by leveraging the rich information in biomedical networks.\nEmerGNN learns pairwise representations of drugs by extracting the paths\nbetween drug pairs, propagating information from one drug to the other, and\nincorporating the relevant biomedical concepts on the paths. The different\nedges on the biomedical network are weighted to indicate the relevance for the\ntarget DDI prediction. Overall, EmerGNN has higher accuracy than existing\napproaches in predicting interactions for emerging drugs and can identify the\nmost relevant information on the biomedical network.",
            "author": [
                "Yongqi Zhang",
                "Quanming Yao",
                "Ling Yue",
                "Xian Wu",
                "Ziheng Zhang",
                "Zhenxi Lin",
                "Yefeng Zheng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09261v1",
                "http://arxiv.org/pdf/2311.09261v1"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM",
                "cs.AI",
                "cs.CE",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08716v1",
            "title": "Scalable Federated Learning for Clients with Different Input Image Sizes\n  and Numbers of Output Categories",
            "updated": "2023-11-15T05:43:14Z",
            "published": "2023-11-15T05:43:14Z",
            "summary": "Federated learning is a privacy-preserving training method which consists of\ntraining from a plurality of clients but without sharing their confidential\ndata. However, previous work on federated learning do not explore suitable\nneural network architectures for clients with different input images sizes and\ndifferent numbers of output categories. In this paper, we propose an effective\nfederated learning method named ScalableFL, where the depths and widths of the\nlocal models for each client are adjusted according to the clients' input image\nsize and the numbers of output categories. In addition, we provide a new bound\nfor the generalization gap of federated learning. In particular, this bound\nhelps to explain the effectiveness of our scalable neural network approach. We\ndemonstrate the effectiveness of ScalableFL in several heterogeneous client\nsettings for both image classification and object detection tasks.",
            "author": [
                "Shuhei Nitta",
                "Taiji Suzuki",
                "Albert Rodr\u00edguez Mulet",
                "Atsushi Yaguchi",
                "Ryusuke Hirai"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08716v1",
                "http://arxiv.org/pdf/2311.08716v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08708v2",
            "title": "Joint User Pairing and Beamforming Design of Multi-STAR-RISs-Aided NOMA\n  in the Indoor Environment via Multi-Agent Reinforcement Learning",
            "updated": "2023-11-17T03:12:12Z",
            "published": "2023-11-15T05:18:36Z",
            "summary": "The development of 6G/B5G wireless networks, which have requirements that go\nbeyond current 5G networks, is gaining interest from academia and industry.\nHowever, to increase 6G/B5G network quality, conventional cellular networks\nthat rely on terrestrial base stations are constrained geographically and\neconomically. Meanwhile, NOMA allows multiple users to share the same\nresources, which improves the spectral efficiency of the system and has the\nadvantage of supporting a larger number of users. Additionally, by\nintelligently manipulating the phase and amplitude of both the reflected and\ntransmitted signals, STAR-RISs can achieve improved coverage, increased\nspectral efficiency, and enhanced communication reliability. However, STAR-RISs\nmust simultaneously optimize the amplitude and phase shift corresponding to\nreflection and transmission, which makes the existing terrestrial networks more\ncomplicated and is considered a major challenging issue. Motivated by the\nabove, we study the joint user pairing for NOMA and beamforming design of\nMulti-STAR-RISs in an indoor environment. Then, we formulate the optimization\nproblem with the objective of maximizing the total throughput of MUs by jointly\noptimizing the decoding order, user pairing, active beamforming, and passive\nbeamforming. However, the formulated problem is a MINLP. To address this\nchallenge, we first introduce the decoding order for NOMA networks. Next, we\ndecompose the original problem into two subproblems, namely: 1) MU pairing and\n2) Beamforming optimization under the optimal decoding order. For the first\nsubproblem, we employ correlation-based K-means clustering to solve the user\npairing problem. Then, to jointly deal with beamforming vector optimizations,\nwe propose MAPPO, which can make quick decisions in the given environment owing\nto its low complexity.",
            "author": [
                "Yu Min Park",
                "Yan Kyaw Tun",
                "Choong Seon Hong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08708v2",
                "http://arxiv.org/pdf/2311.08708v2"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "cs.AI",
                "cs.NI",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08704v1",
            "title": "Can Large Language Models Follow Concept Annotation Guidelines? A Case\n  Study on Scientific and Financial Domains",
            "updated": "2023-11-15T05:11:26Z",
            "published": "2023-11-15T05:11:26Z",
            "summary": "Although large language models (LLMs) exhibit remarkable capacity to leverage\nin-context demonstrations, it is still unclear to what extent they can learn\nnew concepts or facts from ground-truth labels. To address this question, we\nexamine the capacity of instruction-tuned LLMs to follow in-context concept\nguidelines for sentence labeling tasks. We design guidelines that present\ndifferent types of factual and counterfactual concept definitions, which are\nused as prompts for zero-shot sentence classification tasks. Our results show\nthat although concept definitions consistently help in task performance, only\nthe larger models (with 70B parameters or more) have limited ability to work\nunder counterfactual contexts. Importantly, only proprietary models such as\nGPT-3.5 and GPT-4 can recognize nonsensical guidelines, which we hypothesize is\ndue to more sophisticated alignment methods. Finally, we find that\nFalcon-180B-chat is outperformed by Llama-2-70B-chat is most cases, which\nindicates that careful fine-tuning is more effective than increasing model\nscale. Altogether, our simple evaluation method reveals significant gaps in\nconcept understanding between the most capable open-source language models and\nthe leading proprietary APIs.",
            "author": [
                "Marcio Fonseca",
                "Shay B. Cohen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08704v1",
                "http://arxiv.org/pdf/2311.08704v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08695v1",
            "title": "Attribute Diversity Determines the Systematicity Gap in VQA",
            "updated": "2023-11-15T04:50:30Z",
            "published": "2023-11-15T04:50:30Z",
            "summary": "The degree to which neural networks can generalize to new combinations of\nfamiliar concepts, and the conditions under which they are able to do so, has\nlong been an open question. In this work, we study the systematicity gap in\nvisual question answering: the performance difference between reasoning on\npreviously seen and unseen combinations of object attributes. To test, we\nintroduce a novel diagnostic dataset, CLEVR-HOPE. We find that while increased\nquantity of training data does not reduce the systematicity gap, increased\ntraining data diversity of the attributes in the unseen combination does. In\nall, our experiments suggest that the more distinct attribute type combinations\nare seen during training, the more systematic we can expect the resulting model\nto be.",
            "author": [
                "Ian Berlot-Attwell",
                "A. Michael Carrell",
                "Kumar Krishna Agrawal",
                "Yash Sharma",
                "Naomi Saphra"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08695v1",
                "http://arxiv.org/pdf/2311.08695v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08694v1",
            "title": "Near 6 GHz Sezawa Mode Surface Acoustic Wave Resonators using AlScN on\n  SiC",
            "updated": "2023-11-15T04:49:58Z",
            "published": "2023-11-15T04:49:58Z",
            "summary": "Surface Acoustic Wave (SAW) devices featuring Aluminum Scandium Nitride\n(AlScN) on a 4H-Silicon Carbide (SiC) substrate, offer a unique blend of high\nsound velocity, low thermal resistance, substantial piezoelectric response,\nsimplified fabrication, as well as suitability for high-temperature and harsh\nenvironment operation. This study presents high-frequency SAW resonators\nemploying AlScN thin films on SiC substrates, utilizing the second SAW mode\n(referred to as the Sezawa mode). The resonators achieve remarkable\nperformance, boasting a K2 value of 5.5% and a maximum Q-factor (Qmax) of 1048\nat 4.7 GHz, outperforming previous benchmarks. Additionally, a SAW resonator\nwith a 960 nm wavelength attains 5.9 GHz frequency with record K2 (4.0%) and\nQmax (887). Our study underscores the potential of the AlScN on SiC platform\nfor advanced radio-frequency applications.",
            "author": [
                "Xingyu Du",
                "Nishant Sharma",
                "Zichen Tang",
                "Chloe Leblanc",
                "Deep Jariwala",
                "Roy H. Olsson III"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08694v1",
                "http://arxiv.org/pdf/2311.08694v1"
            ],
            "primary_category": "physics.app-ph",
            "category": [
                "physics.app-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08692v1",
            "title": "Routing to the Expert: Efficient Reward-guided Ensemble of Large\n  Language Models",
            "updated": "2023-11-15T04:40:43Z",
            "published": "2023-11-15T04:40:43Z",
            "summary": "The complementary potential of Large Language Models (LLM) assumes\noff-the-shelf LLMs have heterogeneous expertise in a wide range of domains and\ntasks so that an ensemble of LLMs can achieve consistently better performance.\nExisting ensemble methods for LLMs mainly focus on reward model ranking of\noutputs, leading to significant computation overhead. To combat this issue, we\nrevisit the complementary potential of LLMs and further elaborate it by mining\nlatent expertise with off-the-shelf reward models. We propose Zooter, a\nreward-guided routing method distilling rewards on training queries to train a\nrouting function, which can precisely distribute each query to the LLM with\nexpertise about it. We also integrate a tag-based label enhancement to mitigate\nnoise from uncertainty when using rewards as silver supervision. Zooter shows\ncomputation efficiency in inference as it introduces only a minor computation\noverhead of a routing function compared with reward model ranking methods. We\nevaluate Zooter on a comprehensive benchmark collection with 26 subsets on\ndifferent domains and tasks. Zooter outperforms the best single model on\naverage and ranks first on 44% of tasks, even surpassing multiple reward model\nranking methods.",
            "author": [
                "Keming Lu",
                "Hongyi Yuan",
                "Runji Lin",
                "Junyang Lin",
                "Zheng Yuan",
                "Chang Zhou",
                "Jingren Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08692v1",
                "http://arxiv.org/pdf/2311.08692v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08690v1",
            "title": "Enabling CMF Estimation in Data-Constrained Scenarios: A\n  Semantic-Encoding Knowledge Mining Model",
            "updated": "2023-11-15T04:37:27Z",
            "published": "2023-11-15T04:37:27Z",
            "summary": "Precise estimation of Crash Modification Factors (CMFs) is central to\nevaluating the effectiveness of various road safety treatments and prioritizing\ninfrastructure investment accordingly. While customized study for each\ncountermeasure scenario is desired, the conventional CMF estimation approaches\nrely heavily on the availability of crash data at given sites. This not only\nmakes the estimation costly, but the results are also less transferable, since\nthe intrinsic similarities between different safety countermeasure scenarios\nare not fully explored. Aiming to fill this gap, this study introduces a novel\nknowledge-mining framework for CMF prediction. This framework delves into the\nconnections of existing countermeasures and reduces the reliance of CMF\nestimation on crash data availability and manual data collection. Specifically,\nit draws inspiration from human comprehension processes and introduces advanced\nNatural Language Processing (NLP) techniques to extract intricate variations\nand patterns from existing CMF knowledge. It effectively encodes unstructured\ncountermeasure scenarios into machine-readable representations and models the\ncomplex relationships between scenarios and CMF values. This new data-driven\nframework provides a cost-effective and adaptable solution that complements the\ncase-specific approaches for CMF estimation, which is particularly beneficial\nwhen availability of crash data or time imposes constraints. Experimental\nvalidation using real-world CMF Clearinghouse data demonstrates the\neffectiveness of this new approach, which shows significant accuracy\nimprovements compared to baseline methods. This approach provides insights into\nnew possibilities of harnessing accumulated transportation knowledge in various\napplications.",
            "author": [
                "Yanlin Qi",
                "Jia Li",
                "Michael Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08690v1",
                "http://arxiv.org/pdf/2311.08690v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CY",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08689v1",
            "title": "Low Complexity High Speed Deep Neural Network Augmented Wireless Channel\n  Estimation",
            "updated": "2023-11-15T04:35:25Z",
            "published": "2023-11-15T04:35:25Z",
            "summary": "The channel estimation (CE) in wireless receivers is one of the most critical\nand computationally complex signal processing operations. Recently, various\nworks have shown that the deep learning (DL) based CE outperforms conventional\nminimum mean square error (MMSE) based CE, and it is hardware-friendly.\nHowever, DL-based CE has higher complexity and latency than popularly used\nleast square (LS) based CE. In this work, we propose a novel low complexity\nhigh-speed Deep Neural Network-Augmented Least Square (LC-LSDNN) algorithm for\nIEEE 802.11p wireless physical layer and efficiently implement it on Zynq\nsystem on chip (ZSoC). The novelty of the LC-LSDNN is to use different DNNs for\nreal and imaginary values of received complex symbols. This helps reduce the\nsize of DL by 59% and optimize the critical path, allowing it to operate at 60%\nhigher clock frequency. We also explore three different architectures for\nMMSE-based CE. We show that LC-LSDNN significantly outperforms MMSE and\nstate-of-the-art DL-based CE for a wide range of signal-to-noise ratios (SNR)\nand different wireless channels. Also, it is computationally efficient, with\naround 50% lower resources than existing DL-based CE.",
            "author": [
                "Syed Asrar ul haq",
                "Varun Singh",
                "Bhanu Teja Tanaji",
                "Sumit Darak"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08689v1",
                "http://arxiv.org/pdf/2311.08689v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.AR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08687v1",
            "title": "An Eye on Clinical BERT: Investigating Language Model Generalization for\n  Diabetic Eye Disease Phenotyping",
            "updated": "2023-11-15T04:30:20Z",
            "published": "2023-11-15T04:30:20Z",
            "summary": "Diabetic eye disease is a major cause of blindness worldwide. The ability to\nmonitor relevant clinical trajectories and detect lapses in care is critical to\nmanaging the disease and preventing blindness. Alas, much of the information\nnecessary to support these goals is found only in the free text of the\nelectronic medical record. To fill this information gap, we introduce a system\nfor extracting evidence from clinical text of 19 clinical concepts related to\ndiabetic eye disease and inferring relevant attributes for each. In developing\nthis ophthalmology phenotyping system, we are also afforded a unique\nopportunity to evaluate the effectiveness of clinical language models at\nadapting to new clinical domains. Across multiple training paradigms, we find\nthat BERT language models pretrained on out-of-distribution clinical data offer\nno significant improvement over BERT language models pretrained on non-clinical\ndata for our domain. Our study tempers recent claims that language models\npretrained on clinical data are necessary for clinical NLP tasks and highlights\nthe importance of not treating clinical language data as a single homogeneous\ndomain.",
            "author": [
                "Keith Harrigian",
                "Tina Tang",
                "Anthony Gonzales",
                "Cindy X. Cai",
                "Mark Dredze"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08687v1",
                "http://arxiv.org/pdf/2311.08687v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.09260v1",
            "title": "A Proposed Artificial Neural Network based Approach for Molecules Bitter\n  Prediction",
            "updated": "2023-11-15T04:22:29Z",
            "published": "2023-11-15T04:22:29Z",
            "summary": "In recent years, the development of Artificial Intelligence (AI) has offered\nthe possibility to tackle many interdisciplinary problems, and the field of\nchemistry is not an exception. Drug analysis is crucial in drug discovery,\nplaying an important role in human life. However, this task encounters many\ndifficulties due to the wide range of computational chemistry methods. Drug\nanalysis also involves a massive amount of work, including determining taste.\nThus, applying deep learning to predict a molecule's bitterness is inevitable\nto accelerate innovation in drug analysis by reducing the time spent. This\npaper proposes an artificial neural network (ANN) based approach (EC-ANN) for\nthe molecule's bitter prediction. Our approach took the SMILE (Simplified\nmolecular-input line-entry system) string of a molecule as the input data for\nthe prediction, and the 256-bit ECFP descriptor is the input vector for our\nnetwork. It showed impressive results compared to state-of-the-art, with a\nhigher performance on two out of three test sets according to the experiences\non three popular test sets: Phyto-Dictionary, Unimi, and Bitter-new set [1].\nFor the Phyto-Dictionary test set, our model recorded 0.95 and 0.983 in\nF1-score and AUPR, respectively, depicted as the highest score in F1-score. For\nthe Unimi test set, our model achieved 0.88 in F1-score and 0.88 in AUPR, which\nis roughly 12.3% higher than the peak of previous models [1, 2, 3, 4, 5].",
            "author": [
                "Huynh Quoc Anh Bui",
                "Trong Hop Do",
                "Thanh Binh Nguyen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09260v1",
                "http://arxiv.org/pdf/2311.09260v1"
            ],
            "primary_category": "q-bio.BM",
            "category": [
                "q-bio.BM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08685v1",
            "title": "Safer-Instruct: Aligning Language Models with Automated Preference Data",
            "updated": "2023-11-15T04:22:22Z",
            "published": "2023-11-15T04:22:22Z",
            "summary": "Reinforcement Learning from Human Feedback (RLHF) is a vital strategy for\nenhancing model safety in language models. However, annotating preference data\nfor RLHF is a resource-intensive and creativity-demanding process, while\nautomatic generation methods face limitations in data diversity and quality. In\nresponse, we present Safer-Instruct, a novel pipeline for semi-automatically\nconstructing large-scale preference datasets. Our approach leverages reversed\ninstruction tuning, instruction induction, and expert model evaluation to\nefficiently generate high-quality preference data without human annotators. We\nevaluate Safer-Instruct using LLaMA for instruction induction and GPT-4 as an\nexpert model, generating approximately 10K preference samples. Finetuning an\nAlpaca model on this dataset demonstrates improved harmlessness while\nmaintaining competitive performance on conversation and downstream tasks.\nSafer-Instruct addresses the challenges in preference data acquisition,\nadvancing the development of safer and more responsible AI systems. Our code\nand data are available at https://github.com/uscnlp-lime/safer-instruct",
            "author": [
                "Taiwei Shi",
                "Kai Chen",
                "Jieyu Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08685v1",
                "http://arxiv.org/pdf/2311.08685v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08677v1",
            "title": "Federated Learning for Sparse Principal Component Analysis",
            "updated": "2023-11-15T03:55:28Z",
            "published": "2023-11-15T03:55:28Z",
            "summary": "In the rapidly evolving realm of machine learning, algorithm effectiveness\noften faces limitations due to data quality and availability. Traditional\napproaches grapple with data sharing due to legal and privacy concerns. The\nfederated learning framework addresses this challenge. Federated learning is a\ndecentralized approach where model training occurs on client sides, preserving\nprivacy by keeping data localized. Instead of sending raw data to a central\nserver, only model updates are exchanged, enhancing data security. We apply\nthis framework to Sparse Principal Component Analysis (SPCA) in this work. SPCA\naims to attain sparse component loadings while maximizing data variance for\nimproved interpretability. Beside the L1 norm regularization term in\nconventional SPCA, we add a smoothing function to facilitate gradient-based\noptimization methods. Moreover, in order to improve computational efficiency,\nwe introduce a least squares approximation to original SPCA. This enables\nanalytic solutions on the optimization processes, leading to substantial\ncomputational improvements. Within the federated framework, we formulate SPCA\nas a consensus optimization problem, which can be solved using the Alternating\nDirection Method of Multipliers (ADMM). Our extensive experiments involve both\nIID and non-IID random features across various data owners. Results on\nsynthetic and public datasets affirm the efficacy of our federated SPCA\napproach.",
            "author": [
                "Sin Cheng Ciou",
                "Pin Jui Chen",
                "Elvin Y. Tseng",
                "Yuh-Jye Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08677v1",
                "http://arxiv.org/pdf/2311.08677v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC",
                "cs.IT",
                "math.IT",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08675v1",
            "title": "Coreset Selection with Prioritized Multiple Objectives",
            "updated": "2023-11-15T03:43:04Z",
            "published": "2023-11-15T03:43:04Z",
            "summary": "Coreset selection is powerful in reducing computational costs and\naccelerating data processing for deep learning algorithms. It strives to\nidentify a small subset from large-scale data, so that training only on the\nsubset practically performs on par with full data. When coreset selection is\napplied in realistic scenes, under the premise that the identified coreset has\nachieved comparable model performance, practitioners regularly desire the\nidentified coreset can have a size as small as possible for lower costs and\ngreater acceleration. Motivated by this desideratum, for the first time, we\npose the problem of \"coreset selection with prioritized multiple objectives\",\nin which the smallest coreset size under model performance constraints is\nexplored. Moreover, to address this problem, an innovative method is proposed,\nwhich maintains optimization priority order over the model performance and\ncoreset size, and efficiently optimizes them in the coreset selection\nprocedure. Theoretically, we provide the convergence guarantee of the proposed\nmethod. Empirically, extensive experiments confirm its superiority compared\nwith previous strategies, often yielding better model performance with smaller\ncoreset sizes.",
            "author": [
                "Xiaobo Xia",
                "Jiale Liu",
                "Shaokun Zhang",
                "Qingyun Wu",
                "Tongliang Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08675v1",
                "http://arxiv.org/pdf/2311.08675v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08674v1",
            "title": "High-Precision Fruit Localization Using Active Laser-Camera Scanning:\n  Robust Laser Line Extraction for 2D-3D Transformation",
            "updated": "2023-11-15T03:39:27Z",
            "published": "2023-11-15T03:39:27Z",
            "summary": "Recent advancements in deep learning-based approaches have led to remarkable\nprogress in fruit detection, enabling robust fruit identification in complex\nenvironments. However, much less progress has been made on fruit 3D\nlocalization, which is equally crucial for robotic harvesting. Complex fruit\nshape/orientation, fruit clustering, varying lighting conditions, and\nocclusions by leaves and branches have greatly restricted existing sensors from\nachieving accurate fruit localization in the natural orchard environment. In\nthis paper, we report on the design of a novel localization technique, called\nActive Laser-Camera Scanning (ALACS), to achieve accurate and robust fruit 3D\nlocalization. The ALACS hardware setup comprises a red line laser, an RGB color\ncamera, a linear motion slide, and an external RGB-D camera. Leveraging the\nprinciples of dynamic-targeting laser-triangulation, ALACS enables precise\ntransformation of the projected 2D laser line from the surface of apples to the\n3D positions. To facilitate laser pattern acquisitions, a Laser Line Extraction\n(LLE) method is proposed for robust and high-precision feature extraction on\napples. Comprehensive evaluations of LLE demonstrated its ability to extract\nprecise patterns under variable lighting and occlusion conditions. The ALACS\nsystem achieved average apple localization accuracies of 6.9 11.2 mm at\ndistances ranging from 1.0 m to 1.6 m, compared to 21.5 mm by a commercial\nRealSense RGB-D camera, in an indoor experiment. Orchard evaluations\ndemonstrated that ALACS has achieved a 95% fruit detachment rate versus a 71%\nrate by the RealSense camera. By overcoming the challenges of apple 3D\nlocalization, this research contributes to the advancement of robotic fruit\nharvesting technology.",
            "author": [
                "Pengyu Chu",
                "Zhaojian Li",
                "Kaixiang Zhang",
                "Kyle Lammers",
                "Renfu Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08674v1",
                "http://arxiv.org/pdf/2311.08674v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08673v1",
            "title": "CP-EB: Talking Face Generation with Controllable Pose and Eye Blinking\n  Embedding",
            "updated": "2023-11-15T03:37:41Z",
            "published": "2023-11-15T03:37:41Z",
            "summary": "This paper proposes a talking face generation method named \"CP-EB\" that takes\nan audio signal as input and a person image as reference, to synthesize a\nphoto-realistic people talking video with head poses controlled by a short\nvideo clip and proper eye blinking embedding. It's noted that not only the head\npose but also eye blinking are both important aspects for deep fake detection.\nThe implicit control of poses by video has already achieved by the state-of-art\nwork. According to recent research, eye blinking has weak correlation with\ninput audio which means eye blinks extraction from audio and generation are\npossible. Hence, we propose a GAN-based architecture to extract eye blink\nfeature from input audio and reference video respectively and employ\ncontrastive training between them, then embed it into the concatenated features\nof identity and poses to generate talking face images. Experimental results\nshow that the proposed method can generate photo-realistic talking face with\nsynchronous lips motions, natural head poses and blinking eyes.",
            "author": [
                "Jianzong Wang",
                "Yimin Deng",
                "Ziqi Liang",
                "Xulong Zhang",
                "Ning Cheng",
                "Jing Xiao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08673v1",
                "http://arxiv.org/pdf/2311.08673v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08670v1",
            "title": "CLN-VC: Text-Free Voice Conversion Based on Fine-Grained Style Control\n  and Contrastive Learning with Negative Samples Augmentation",
            "updated": "2023-11-15T03:29:31Z",
            "published": "2023-11-15T03:29:31Z",
            "summary": "Better disentanglement of speech representation is essential to improve the\nquality of voice conversion. Recently contrastive learning is applied to voice\nconversion successfully based on speaker labels. However, the performance of\nmodel will reduce in conversion between similar speakers. Hence, we propose an\naugmented negative sample selection to address the issue. Specifically, we\ncreate hard negative samples based on the proposed speaker fusion module to\nimprove learning ability of speaker encoder. Furthermore, considering the\nfine-grain modeling of speaker style, we employ a reference encoder to extract\nfine-grained style and conduct the augmented contrastive learning on global\nstyle. The experimental results show that the proposed method outperforms\nprevious work in voice conversion tasks.",
            "author": [
                "Yimin Deng",
                "Xulong Zhang",
                "Jianzong Wang",
                "Ning Cheng",
                "Jing Xiao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08670v1",
                "http://arxiv.org/pdf/2311.08670v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08669v1",
            "title": "Understanding Calibration for Multilingual Question Answering Models",
            "updated": "2023-11-15T03:29:02Z",
            "published": "2023-11-15T03:29:02Z",
            "summary": "Multilingual pre-trained language models are incredibly effective at Question\nAnswering (QA), a core task in Natural Language Understanding, achieving high\naccuracies on several multilingual benchmarks. However, little is known about\nhow well they are calibrated. In this paper, we study the calibration\nproperties of several pre-trained multilingual large language models (LLMs) on\na variety of question-answering tasks. We perform extensive experiments,\nspanning both extractive and generative QA model designs and diverse languages,\nspanning both high-resource and low-resource ones. We study different\ndimensions of calibration in in-distribution, out-of-distribution, and\ncross-lingual transfer settings, and investigate strategies to improve it,\nincluding post-hoc methods and regularized fine-tuning. We demonstrate\nautomatically translated data augmentation as a highly effective technique to\nimprove model calibration. We also conduct a number of ablation experiments to\nstudy the effect of model size on calibration and how multilingual models\ncompare with their monolingual counterparts for diverse tasks and languages.",
            "author": [
                "Yahan Yang",
                "Soham Dan",
                "Dan Roth",
                "Insup Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08669v1",
                "http://arxiv.org/pdf/2311.08669v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08667v2",
            "title": "EDMSound: Spectrogram Based Diffusion Models for Efficient and\n  High-Quality Audio Synthesis",
            "updated": "2023-11-18T15:16:16Z",
            "published": "2023-11-15T03:27:35Z",
            "summary": "Audio diffusion models can synthesize a wide variety of sounds. Existing\nmodels often operate on the latent domain with cascaded phase recovery modules\nto reconstruct waveform. This poses challenges when generating high-fidelity\naudio. In this paper, we propose EDMSound, a diffusion-based generative model\nin spectrogram domain under the framework of elucidated diffusion models (EDM).\nCombining with efficient deterministic sampler, we achieved similar Fr\\'echet\naudio distance (FAD) score as top-ranked baseline with only 10 steps and\nreached state-of-the-art performance with 50 steps on the DCASE2023 foley sound\ngeneration benchmark. We also revealed a potential concern regarding diffusion\nbased audio generation models that they tend to generate samples with high\nperceptual similarity to the data from training data. Project page:\nhttps://agentcooper2002.github.io/EDMSound/",
            "author": [
                "Ge Zhu",
                "Yutong Wen",
                "Marc-Andr\u00e9 Carbonneau",
                "Zhiyao Duan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08667v2",
                "http://arxiv.org/pdf/2311.08667v2"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08666v1",
            "title": "It Takes Two to Negotiate: Modeling Social Exchange in Online\n  Multiplayer Games",
            "updated": "2023-11-15T03:21:04Z",
            "published": "2023-11-15T03:21:04Z",
            "summary": "Online games are dynamic environments where players interact with each other,\nwhich offers a rich setting for understanding how players negotiate their way\nthrough the game to an ultimate victory. This work studies online player\ninteractions during the turn-based strategy game, Diplomacy. We annotated a\ndataset of over 10,000 chat messages for different negotiation strategies and\nempirically examined their importance in predicting long- and short-term game\noutcomes. Although negotiation strategies can be predicted reasonably\naccurately through the linguistic modeling of the chat messages, more is needed\nfor predicting short-term outcomes such as trustworthiness. On the other hand,\nthey are essential in graph-aware reinforcement learning approaches to predict\nlong-term outcomes, such as a player's success, based on their prior\nnegotiation history. We close with a discussion of the implications and impact\nof our work. The dataset is available at\nhttps://github.com/kj2013/claff-diplomacy.",
            "author": [
                "Kokil Jaidka",
                "Hansin Ahuja",
                "Lynnette Ng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08666v1",
                "http://arxiv.org/pdf/2311.08666v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.GT",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08661v1",
            "title": "Deep Neural Network Identification of Limnonectes Species and New Class\n  Detection Using Image Data",
            "updated": "2023-11-15T02:57:59Z",
            "published": "2023-11-15T02:57:59Z",
            "summary": "As is true of many complex tasks, the work of discovering, describing, and\nunderstanding the diversity of life on Earth (viz., biological systematics and\ntaxonomy) requires many tools. Some of this work can be accomplished as it has\nbeen done in the past, but some aspects present us with challenges which\ntraditional knowledge and tools cannot adequately resolve. One such challenge\nis presented by species complexes in which the morphological similarities among\nthe group members make it difficult to reliably identify known species and\ndetect new ones. We address this challenge by developing new tools using the\nprinciples of machine learning to resolve two specific questions related to\nspecies complexes. The first question is formulated as a classification problem\nin statistics and machine learning and the second question is an\nout-of-distribution (OOD) detection problem. We apply these tools to a species\ncomplex comprising Southeast Asian stream frogs (Limnonectes kuhlii complex)\nand employ a morphological character (hind limb skin texture) traditionally\ntreated qualitatively in a quantitative and objective manner. We demonstrate\nthat deep neural networks can successfully automate the classification of an\nimage into a known species group for which it has been trained. We further\ndemonstrate that the algorithm can successfully classify an image into a new\nclass if the image does not belong to the existing classes. Additionally, we\nuse the larger MNIST dataset to test the performance of our OOD detection\nalgorithm. We finish our paper with some concluding remarks regarding the\napplication of these methods to species complexes and our efforts to document\ntrue biodiversity. This paper has online supplementary materials.",
            "author": [
                "Li Xu",
                "Yili Hong",
                "Eric P. Smith",
                "David S. McLeod",
                "Xinwei Deng",
                "Laura J. Freeman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08661v1",
                "http://arxiv.org/pdf/2311.08661v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.CV",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08658v1",
            "title": "Structured Estimation of Heterogeneous Time Series",
            "updated": "2023-11-15T02:39:13Z",
            "published": "2023-11-15T02:39:13Z",
            "summary": "How best to model structurally heterogeneous processes is a foundational\nquestion in the social, health and behavioral sciences. Recently, Fisher et\nal., (2022) introduced the multi-VAR approach for simultaneously estimating\nmultiple-subject multivariate time series characterized by common and\nindividualizing features using penalized estimation. This approach differs from\nmany popular modeling approaches for multiple-subject time series in that\nqualitative and quantitative differences in a large number of individual\ndynamics are well-accommodated. The current work extends the multi-VAR\nframework to include new adaptive weighting schemes that greatly improve\nestimation performance. In a small set of simulation studies we compare\nadaptive multi-VAR with these new penalty weights to common alternative\nestimators in terms of path recovery and bias. Furthermore, we provide toy\nexamples and code demonstrating the utility of multi-VAR under different\nheterogeneity regimes using the multivar package for R (Fisher, 2022).",
            "author": [
                "Zachary F. Fisher",
                "Younghoon Kim",
                "Vladas Pipiras",
                "Christopher Crawford",
                "Daniel J. Petrie",
                "Michael D. Hunter",
                "Charles F. Geier"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08658v1",
                "http://arxiv.org/pdf/2311.08658v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08657v1",
            "title": "ConeQuest: A Benchmark for Cone Segmentation on Mars",
            "updated": "2023-11-15T02:33:08Z",
            "published": "2023-11-15T02:33:08Z",
            "summary": "Over the years, space scientists have collected terabytes of Mars data from\nsatellites and rovers. One important set of features identified in Mars orbital\nimages is pitted cones, which are interpreted to be mud volcanoes believed to\nform in regions that were once saturated in water (i.e., a lake or ocean).\nIdentifying pitted cones globally on Mars would be of great importance, but\nexpert geologists are unable to sort through the massive orbital image archives\nto identify all examples. However, this task is well suited for computer\nvision. Although several computer vision datasets exist for various\nMars-related tasks, there is currently no open-source dataset available for\ncone detection/segmentation. Furthermore, previous studies trained models using\ndata from a single region, which limits their applicability for global\ndetection and mapping. Motivated by this, we introduce ConeQuest, the first\nexpert-annotated public dataset to identify cones on Mars. ConeQuest consists\nof >13k samples from 3 different regions of Mars. We propose two benchmark\ntasks using ConeQuest: (i) Spatial Generalization and (ii) Cone-size\nGeneralization. We finetune and evaluate widely-used segmentation models on\nboth benchmark tasks. Results indicate that cone segmentation is a challenging\nopen problem not solved by existing segmentation models, which achieve an\naverage IoU of 52.52% and 42.55% on in-distribution data for tasks (i) and\n(ii), respectively. We believe this new benchmark dataset will facilitate the\ndevelopment of more accurate and robust models for cone segmentation. Data and\ncode are available at https://github.com/kerner-lab/ConeQuest.",
            "author": [
                "Mirali Purohit",
                "Jacob Adler",
                "Hannah Kerner"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08657v1",
                "http://arxiv.org/pdf/2311.08657v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08655v1",
            "title": "Review of AlexNet for Medical Image Classification",
            "updated": "2023-11-15T02:28:52Z",
            "published": "2023-11-15T02:28:52Z",
            "summary": "In recent years, the rapid development of deep learning has led to a wide\nrange of applications in the field of medical image classification. The\nvariants of neural network models with ever-increasing performance share some\ncommonalities: to try to mitigate overfitting, improve generalization, avoid\ngradient vanishing and exploding, etc. AlexNet first utilizes the dropout\ntechnique to mitigate overfitting and the ReLU activation function to avoid\ngradient vanishing. Therefore, we focus our discussion on AlexNet, which has\ncontributed greatly to the development of CNNs in 2012. After reviewing over 40\npapers, including journal papers and conference papers, we give a narrative on\nthe technical details, advantages, and application areas of AlexNet.",
            "author": [
                "Wenhao Tang",
                "Junding Sun",
                "Shuihua Wang",
                "Yudong Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08655v1",
                "http://arxiv.org/pdf/2311.08655v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08652v1",
            "title": "Refining Perception Contracts: Case Studies in Vision-based Safe\n  Auto-landing",
            "updated": "2023-11-15T02:26:41Z",
            "published": "2023-11-15T02:26:41Z",
            "summary": "Perception contracts provide a method for evaluating safety of control\nsystems that use machine learning for perception. A perception contract is a\nspecification for testing the ML components, and it gives a method for proving\nend-to-end system-level safety requirements. The feasibility of contract-based\ntesting and assurance was established earlier in the context of straight lane\nkeeping: a 3-dimensional system with relatively simple dynamics. This paper\npresents the analysis of two 6 and 12-dimensional flight control systems that\nuse multi-stage, heterogeneous, ML-enabled perception. The paper advances\nmethodology by introducing an algorithm for constructing data and requirement\nguided refinement of perception contracts (DaRePC). The resulting analysis\nprovides testable contracts which establish the state and environment\nconditions under which an aircraft can safety touchdown on the runway and a\ndrone can safely pass through a sequence of gates. It can also discover\nconditions (e.g., low-horizon sun) that can possibly violate the safety of the\nvision-based control system.",
            "author": [
                "Yangge Li",
                "Benjamin C Yang",
                "Yixuan Jia",
                "Daniel Zhuang",
                "Sayan Mitra"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08652v1",
                "http://arxiv.org/pdf/2311.08652v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08648v1",
            "title": "Explore Spurious Correlations at the Concept Level in Language Models\n  for Text Classification",
            "updated": "2023-11-15T01:58:54Z",
            "published": "2023-11-15T01:58:54Z",
            "summary": "Language models (LMs) have gained great achievement in various NLP tasks for\nboth fine-tuning and in-context learning (ICL) methods. Despite its outstanding\nperformance, evidence shows that spurious correlations caused by imbalanced\nlabel distributions in training data (or exemplars in ICL) lead to robustness\nissues. However, previous studies mostly focus on word- and phrase-level\nfeatures and fail to tackle it from the concept level, partly due to the lack\nof concept labels and subtle and diverse expressions of concepts in text. In\nthis paper, we first use the LLM to label the concept for each text and then\nmeasure the concept bias of models for fine-tuning or ICL on the test data.\nSecond, we propose a data rebalancing method to mitigate the spurious\ncorrelations by adding the LLM-generated counterfactual data to make a balanced\nlabel distribution for each concept. We verify the effectiveness of our\nmitigation method and show its superiority over the token removal method.\nOverall, our results show that there exist label distribution biases in\nconcepts across multiple text classification datasets, and LMs will utilize\nthese shortcuts to make predictions in both fine-tuning and ICL methods.",
            "author": [
                "Yuhang Zhou",
                "Paiheng Xu",
                "Xiaoyu Liu",
                "Bang An",
                "Wei Ai",
                "Furong Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08648v1",
                "http://arxiv.org/pdf/2311.08648v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08646v1",
            "title": "Painterly Image Harmonization via Adversarial Residual Learning",
            "updated": "2023-11-15T01:53:46Z",
            "published": "2023-11-15T01:53:46Z",
            "summary": "Image compositing plays a vital role in photo editing. After inserting a\nforeground object into another background image, the composite image may look\nunnatural and inharmonious. When the foreground is photorealistic and the\nbackground is an artistic painting, painterly image harmonization aims to\ntransfer the style of background painting to the foreground object, which is a\nchallenging task due to the large domain gap between foreground and background.\nIn this work, we employ adversarial learning to bridge the domain gap between\nforeground feature map and background feature map. Specifically, we design a\ndual-encoder generator, in which the residual encoder produces the residual\nfeatures added to the foreground feature map from main encoder. Then, a\npixel-wise discriminator plays against the generator, encouraging the refined\nforeground feature map to be indistinguishable from background feature map.\nExtensive experiments demonstrate that our method could achieve more harmonious\nand visually appealing results than previous methods.",
            "author": [
                "Xudong Wang",
                "Li Niu",
                "Junyan Cao",
                "Yan Hong",
                "Liqing Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08646v1",
                "http://arxiv.org/pdf/2311.08646v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08644v1",
            "title": "Interpretable by Design: Wrapper Boxes Combine Neural Performance with\n  Faithful Explanations",
            "updated": "2023-11-15T01:50:53Z",
            "published": "2023-11-15T01:50:53Z",
            "summary": "Can we preserve the accuracy of neural models while also providing faithful\nexplanations? We present wrapper boxes, a general approach to generate\nfaithful, example-based explanations for model predictions while maintaining\npredictive performance. After training a neural model as usual, its learned\nfeature representation is input to a classic, interpretable model to perform\nthe actual prediction. This simple strategy is surprisingly effective, with\nresults largely comparable to those of the original neural model, as shown\nacross three large pre-trained language models, two datasets of varying scale,\nfour classic models, and four evaluation metrics. Moreover, because these\nclassic models are interpretable by design, the subset of training examples\nthat determine classic model predictions can be shown directly to users.",
            "author": [
                "Yiheng Su",
                "Juni Jessy Li",
                "Matthew Lease"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08644v1",
                "http://arxiv.org/pdf/2311.08644v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08640v1",
            "title": "Multistage Collaborative Knowledge Distillation from Large Language\n  Models",
            "updated": "2023-11-15T01:28:28Z",
            "published": "2023-11-15T01:28:28Z",
            "summary": "We study semi-supervised sequence prediction tasks where labeled data are too\nscarce to effectively finetune a model and at the same time few-shot prompting\nof a large language model (LLM) has suboptimal performance. This happens when a\ntask, such as parsing, is expensive to annotate and also unfamiliar to a\npretrained LLM. In this paper, we present a discovery that student models\ndistilled from a prompted LLM can often generalize better than their teacher on\nsuch tasks. Leveraging this finding, we propose a new distillation method,\nmultistage collaborative knowledge distillation from an LLM (MCKD), for such\ntasks. MCKD first prompts an LLM using few-shot in-context learning to produce\npseudolabels for unlabeled data. Then, at each stage of distillation, a pair of\nstudents are trained on disjoint partitions of the pseudolabeled data. Each\nstudent subsequently produces new and improved pseudolabels for the unseen\npartition to supervise the next round of student(s) with. We show the benefit\nof multistage cross-partition labeling on two constituency parsing tasks. On\nCRAFT biomedical parsing, 3-stage MCKD with 50 labeled examples matches the\nperformance of supervised finetuning with 500 examples and outperforms the\nprompted LLM and vanilla KD by 7.5% and 3.7% parsing F1, respectively.",
            "author": [
                "Jiachen Zhao",
                "Wenlong Zhao",
                "Andrew Drozdov",
                "Benjamin Rozonoyer",
                "Md Arafat Sultan",
                "Jay-Yoon Lee",
                "Mohit Iyyer",
                "Andrew McCallum"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08640v1",
                "http://arxiv.org/pdf/2311.08640v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08636v1",
            "title": "Supervised low-rank semi-nonnegative matrix factorization with frequency\n  regularization for forecasting spatio-temporal data",
            "updated": "2023-11-15T01:23:13Z",
            "published": "2023-11-15T01:23:13Z",
            "summary": "We propose a novel methodology for forecasting spatio-temporal data using\nsupervised semi-nonnegative matrix factorization (SSNMF) with frequency\nregularization. Matrix factorization is employed to decompose spatio-temporal\ndata into spatial and temporal components. To improve clarity in the temporal\npatterns, we introduce a nonnegativity constraint on the time domain along with\nregularization in the frequency domain. Specifically, regularization in the\nfrequency domain involves selecting features in the frequency space, making an\ninterpretation in the frequency domain more convenient. We propose two methods\nin the frequency domain: soft and hard regularizations, and provide convergence\nguarantees to first-order stationary points of the corresponding constrained\noptimization problem. While our primary motivation stems from geophysical data\nanalysis based on GRACE (Gravity Recovery and Climate Experiment) data, our\nmethodology has the potential for wider application. Consequently, when\napplying our methodology to GRACE data, we find that the results with the\nproposed methodology are comparable to previous research in the field of\ngeophysical sciences but offer clearer interpretability.",
            "author": [
                "Keunsu Kim",
                "Hanbaek Lyu",
                "Jinsu Kim",
                "Jae-Hun Jung"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08636v1",
                "http://arxiv.org/pdf/2311.08636v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "65F22, 65F55 and 86A04"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08635v1",
            "title": "Spatio-Temporal Graph Neural Point Process for Traffic Congestion Event\n  Prediction",
            "updated": "2023-11-15T01:22:47Z",
            "published": "2023-11-15T01:22:47Z",
            "summary": "Traffic congestion event prediction is an important yet challenging task in\nintelligent transportation systems. Many existing works about traffic\nprediction integrate various temporal encoders and graph convolution networks\n(GCNs), called spatio-temporal graph-based neural networks, which focus on\npredicting dense variables such as flow, speed and demand in time snapshots,\nbut they can hardly forecast the traffic congestion events that are sparsely\ndistributed on the continuous time axis. In recent years, neural point process\n(NPP) has emerged as an appropriate framework for event prediction in\ncontinuous time scenarios. However, most conventional works about NPP cannot\nmodel the complex spatio-temporal dependencies and congestion evolution\npatterns. To address these limitations, we propose a spatio-temporal graph\nneural point process framework, named STGNPP for traffic congestion event\nprediction. Specifically, we first design the spatio-temporal graph learning\nmodule to fully capture the long-range spatio-temporal dependencies from the\nhistorical traffic state data along with the road network. The extracted\nspatio-temporal hidden representation and congestion event information are then\nfed into a continuous gated recurrent unit to model the congestion evolution\npatterns. In particular, to fully exploit the periodic information, we also\nimprove the intensity function calculation of the point process with a periodic\ngated mechanism. Finally, our model simultaneously predicts the occurrence time\nand duration of the next congestion. Extensive experiments on two real-world\ndatasets demonstrate that our method achieves superior performance in\ncomparison to existing state-of-the-art approaches.",
            "author": [
                "Guangyin Jin",
                "Lingbo Liu",
                "Fuxian Li",
                "Jincai Huang"
            ],
            "link": [
                "http://dx.doi.org/10.1609/aaai.v37i12.26669",
                "http://arxiv.org/abs/2311.08635v1",
                "http://arxiv.org/pdf/2311.08635v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08631v2",
            "title": "Influence of Video Dynamics on EEG-based Single-Trial Video Target\n  Surveillance Syste",
            "updated": "2023-11-19T03:00:35Z",
            "published": "2023-11-15T01:10:24Z",
            "summary": "Target detection models are one of the widely used deep learning-based\napplications for reducing human efforts on video surveillance and patrol.\nHowever, the application of conventional computer vision-based target detection\nmodels in military usage can result in limited performance, due to the lack of\nsample data of hostile targets. In this paper, we present the possibility of\nthe electroencephalography-based video target detection model, which could be\napplied as a supportive module of the military video surveillance system. The\nproposed framework and detection model showed prospective performance achieving\na mean macro F-beta of 0.6522 with asynchronous real-time data from five\nsubjects, in a certain video stimulus, but not on some video stimuli. By\nanalyzing the results of experiments using each video stimulus, we present the\nfactors that would affect the performance of electroencephalography-based video\ntarget detection models.",
            "author": [
                "Heon-Gyu Kwak",
                "Sung-Jin Kim",
                "Hyeon-Taek Han",
                "Ji-Hoon Jeong",
                "Seong-Whan Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08631v2",
                "http://arxiv.org/pdf/2311.08631v2"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08624v1",
            "title": "Flow control by a hybrid use of machine learning and control theory",
            "updated": "2023-11-15T01:01:57Z",
            "published": "2023-11-15T01:01:57Z",
            "summary": "Flow control has a great potential to contribute to the sustainable society\nthrough mitigation of environmental burden. However, high dimensional and\nnonlinear nature of fluid flows poses challenges in designing efficient control\nlaws. This paper aims to propose a hybrid method (i.e., machine learning and\ncontrol theory) for feedback control of fluid flows. We propose a partially\nnonlinear linear-system extraction autoencoder (pn-LEAE), which consists of\nconvolutional neural networks-based autoencoder (CNN-AE) and a custom layer to\nextract a low-dimensional latent dynamics. This pn-LEAE basically extracts a\nlinear dynamical system so that the modern control theory can easily be\napplied, but at the same time, it is designed to capture a nonlinear\ndevelopment of the latent dynamics. We demonstrate the effectiveness of the\nlinear system extracted by the pn-LEAE, as well as the designed control law's\neffectiveness for a flow around a circular cylinder at the Reynolds number of\n${\\rm Re}_{D}=100$. This is the first attempt utilizing CNN-AE for\nlinearization of fluid flows involving transient development to design a\nfeedback control law.",
            "author": [
                "Takeru Ishize",
                "Hiroshi Omichi",
                "Koji Fukagata"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08624v1",
                "http://arxiv.org/pdf/2311.08624v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08623v1",
            "title": "DEED: Dynamic Early Exit on Decoder for Accelerating Encoder-Decoder\n  Transformer Models",
            "updated": "2023-11-15T01:01:02Z",
            "published": "2023-11-15T01:01:02Z",
            "summary": "Encoder-decoder transformer models have achieved great success on various\nvision-language (VL) tasks, but they suffer from high inference latency.\nTypically, the decoder takes up most of the latency because of the\nauto-regressive decoding. To accelerate the inference, we propose an approach\nof performing Dynamic Early Exit on Decoder (DEED). We build a multi-exit\nencoder-decoder transformer model which is trained with deep supervision so\nthat each of its decoder layers is capable of generating plausible predictions.\nIn addition, we leverage simple yet practical techniques, including shared\ngeneration head and adaptation modules, to keep accuracy when exiting at\nshallow decoder layers. Based on the multi-exit model, we perform step-level\ndynamic early exit during inference, where the model may decide to use fewer\ndecoder layers based on its confidence of the current layer at each individual\ndecoding step. Considering different number of decoder layers may be used at\ndifferent decoding steps, we compute deeper-layer decoder features of previous\ndecoding steps just-in-time, which ensures the features from different decoding\nsteps are semantically aligned. We evaluate our approach with two\nstate-of-the-art encoder-decoder transformer models on various VL tasks. We\nshow our approach can reduce overall inference latency by 30%-60% with\ncomparable or even higher accuracy compared to baselines.",
            "author": [
                "Peng Tang",
                "Pengkai Zhu",
                "Tian Li",
                "Srikar Appalaraju",
                "Vijay Mahadevan",
                "R. Manmatha"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08623v1",
                "http://arxiv.org/pdf/2311.08623v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08622v1",
            "title": "Multiple-Question Multiple-Answer Text-VQA",
            "updated": "2023-11-15T01:00:02Z",
            "published": "2023-11-15T01:00:02Z",
            "summary": "We present Multiple-Question Multiple-Answer (MQMA), a novel approach to do\ntext-VQA in encoder-decoder transformer models. The text-VQA task requires a\nmodel to answer a question by understanding multi-modal content: text\n(typically from OCR) and an associated image. To the best of our knowledge,\nalmost all previous approaches for text-VQA process a single question and its\nassociated content to predict a single answer. In order to answer multiple\nquestions from the same image, each question and content are fed into the model\nmultiple times. In contrast, our proposed MQMA approach takes multiple\nquestions and content as input at the encoder and predicts multiple answers at\nthe decoder in an auto-regressive manner at the same time. We make several\nnovel architectural modifications to standard encoder-decoder transformers to\nsupport MQMA. We also propose a novel MQMA denoising pre-training task which is\ndesigned to teach the model to align and delineate multiple questions and\ncontent with associated answers. MQMA pre-trained model achieves\nstate-of-the-art results on multiple text-VQA datasets, each with strong\nbaselines. Specifically, on OCR-VQA (+2.5%), TextVQA (+1.4%), ST-VQA (+0.6%),\nDocVQA (+1.1%) absolute improvements over the previous state-of-the-art\napproaches.",
            "author": [
                "Peng Tang",
                "Srikar Appalaraju",
                "R. Manmatha",
                "Yusheng Xie",
                "Vijay Mahadevan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08622v1",
                "http://arxiv.org/pdf/2311.08622v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08621v1",
            "title": "Cross Device Federated Intrusion Detector for Early Stage Botnet\n  Propagation in IoT",
            "updated": "2023-11-15T00:58:35Z",
            "published": "2023-11-15T00:58:35Z",
            "summary": "A botnet is an army of zombified computers infected with malware and\ncontrolled by malicious actors to carry out tasks such as Distributed Denial of\nService (DDoS) attacks. Billions of Internet of Things (IoT) devices are\nprimarily targeted to be infected as bots since they are configured with weak\ncredentials or contain common vulnerabilities. Detecting botnet propagation by\nmonitoring the network traffic is difficult as they easily blend in with\nregular network traffic. The traditional machine learning (ML) based Intrusion\nDetection System (IDS) requires the raw data to be captured and sent to the ML\nprocessor to detect intrusion. In this research, we examine the viability of a\ncross-device federated intrusion detection mechanism where each device runs the\nML model on its data and updates the model weights to the central coordinator.\nThis mechanism ensures the client's data is not shared with any third party,\nterminating privacy leakage. The model examines each data packet separately and\npredicts anomalies. We evaluate our proposed mechanism on a real botnet\npropagation dataset called MedBIoT. Overall, the proposed method produces an\naverage accuracy of 71%, precision 78%, recall 71%, and f1-score 68%. In\naddition, we also examined whether any device taking part in federated learning\ncan employ a poisoning attack on the overall system.",
            "author": [
                "Angela Grace Famera",
                "Raj Mani Shukla",
                "Suman Bhunia"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08621v1",
                "http://arxiv.org/pdf/2311.08621v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08620v1",
            "title": "Toucan: Token-Aware Character Level Language Modeling",
            "updated": "2023-11-15T00:57:51Z",
            "published": "2023-11-15T00:57:51Z",
            "summary": "Character-level language models obviate the need for separately trained\ntokenizers, but efficiency suffers from longer sequence lengths. Learning to\ncombine character representations into tokens has made training these models\nmore efficient, but they still require decoding characters individually. We\npropose Toucan, an augmentation to character-level models to make them\n\"token-aware\". Comparing our method to prior work, we demonstrate significant\nspeed-ups in character generation without a loss in language modeling\nperformance. We then explore differences between our learned dynamic\ntokenization of character sequences with popular fixed vocabulary solutions\nsuch as Byte-Pair Encoding and WordPiece, finding our approach leads to a\ngreater amount of longer sequences tokenized as single items. Our project and\ncode are available at https://nlp.jhu.edu/nuggets/.",
            "author": [
                "William Fleshman",
                "Benjamin Van Durme"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08620v1",
                "http://arxiv.org/pdf/2311.08620v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08615v1",
            "title": "Non-Uniform Smoothness for Gradient Descent",
            "updated": "2023-11-15T00:44:08Z",
            "published": "2023-11-15T00:44:08Z",
            "summary": "The analysis of gradient descent-type methods typically relies on the\nLipschitz continuity of the objective gradient. This generally requires an\nexpensive hyperparameter tuning process to appropriately calibrate a stepsize\nfor a given problem. In this work we introduce a local first-order smoothness\noracle (LFSO) which generalizes the Lipschitz continuous gradients smoothness\ncondition and is applicable to any twice-differentiable function. We show that\nthis oracle can encode all relevant problem information for tuning stepsizes\nfor a suitably modified gradient descent method and give global and local\nconvergence results. We also show that LFSOs in this modified first-order\nmethod can yield global linear convergence rates for non-strongly convex\nproblems with extremely flat minima, and thus improve over the lower bound on\nrates achievable by general (accelerated) first-order methods.",
            "author": [
                "Albert S. Berahas",
                "Lindon Roberts",
                "Fred Roosta"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08615v1",
                "http://arxiv.org/pdf/2311.08615v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG",
                "65K05, 90C30"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.10763v1",
            "title": "Comparing Generalization in Learning with Limited Numbers of Exemplars:\n  Transformer vs. RNN in Attractor Dynamics",
            "updated": "2023-11-15T00:37:49Z",
            "published": "2023-11-15T00:37:49Z",
            "summary": "ChatGPT, a widely-recognized large language model (LLM), has recently gained\nsubstantial attention for its performance scaling, attributed to the billions\nof web-sourced natural language sentences used for training. Its underlying\narchitecture, Transformer, has found applications across diverse fields,\nincluding video, audio signals, and robotic movement. %The crucial question\nthis raises concerns the Transformer's generalization-in-learning (GIL)\ncapacity. However, this raises a crucial question about Transformer's\ngeneralization in learning (GIL) capacity. Is ChatGPT's success chiefly due to\nthe vast dataset used for training, or is there more to the story? To\ninvestigate this, we compared Transformer's GIL capabilities with those of a\ntraditional Recurrent Neural Network (RNN) in tasks involving attractor\ndynamics learning. For performance evaluation, the Dynamic Time Warping (DTW)\nmethod has been employed. Our simulation results suggest that under conditions\nof limited data availability, Transformer's GIL abilities are markedly inferior\nto those of RNN.",
            "author": [
                "Rui Fukushima",
                "Jun Tani"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10763v1",
                "http://arxiv.org/pdf/2311.10763v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08614v1",
            "title": "XplainLLM: A QA Explanation Dataset for Understanding LLM\n  Decision-Making",
            "updated": "2023-11-15T00:34:28Z",
            "published": "2023-11-15T00:34:28Z",
            "summary": "Large Language Models (LLMs) have recently made impressive strides in natural\nlanguage understanding tasks. Despite their remarkable performance,\nunderstanding their decision-making process remains a big challenge. In this\npaper, we look into bringing some transparency to this process by introducing a\nnew explanation dataset for question answering (QA) tasks that integrates\nknowledge graphs (KGs) in a novel way. Our dataset includes 12,102\nquestion-answer-explanation (QAE) triples. Each explanation in the dataset\nlinks the LLM's reasoning to entities and relations in the KGs. The explanation\ncomponent includes a why-choose explanation, a why-not-choose explanation, and\na set of reason-elements that underlie the LLM's decision. We leverage KGs and\ngraph attention networks (GAT) to find the reason-elements and transform them\ninto why-choose and why-not-choose explanations that are comprehensible to\nhumans. Through quantitative and qualitative evaluations, we demonstrate the\npotential of our dataset to improve the in-context learning of LLMs, and\nenhance their interpretability and explainability. Our work contributes to the\nfield of explainable AI by enabling a deeper understanding of the LLMs\ndecision-making process to make them more transparent and thereby, potentially\nmore reliable, to researchers and practitioners alike. Our dataset is available\nat: https://github.com/chen-zichen/XplainLLM_dataset.git",
            "author": [
                "Zichen Chen",
                "Jianda Chen",
                "Mitali Gaidhani",
                "Ambuj Singh",
                "Misha Sra"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08614v1",
                "http://arxiv.org/pdf/2311.08614v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08610v1",
            "title": "Converting Transformers to Polynomial Form for Secure Inference Over\n  Homomorphic Encryption",
            "updated": "2023-11-15T00:23:58Z",
            "published": "2023-11-15T00:23:58Z",
            "summary": "Designing privacy-preserving deep learning models is a major challenge within\nthe deep learning community. Homomorphic Encryption (HE) has emerged as one of\nthe most promising approaches in this realm, enabling the decoupling of\nknowledge between the model owner and the data owner. Despite extensive\nresearch and application of this technology, primarily in convolutional neural\nnetworks, incorporating HE into transformer models has been challenging because\nof the difficulties in converting these models into a polynomial form. We break\nnew ground by introducing the first polynomial transformer, providing the first\ndemonstration of secure inference over HE with transformers. This includes a\ntransformer architecture tailored for HE, alongside a novel method for\nconverting operators to their polynomial equivalent. This innovation enables us\nto perform secure inference on LMs with WikiText-103. It also allows us to\nperform image classification with CIFAR-100 and Tiny-ImageNet. Our models yield\nresults comparable to traditional methods, bridging the performance gap with\ntransformers of similar scale and underscoring the viability of HE for\nstate-of-the-art applications. Finally, we assess the stability of our models\nand conduct a series of ablations to quantify the contribution of each model\ncomponent.",
            "author": [
                "Itamar Zimerman",
                "Moran Baruch",
                "Nir Drucker",
                "Gilad Ezov",
                "Omri Soceanu",
                "Lior Wolf"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08610v1",
                "http://arxiv.org/pdf/2311.08610v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR",
                "F.2.2; I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08607v1",
            "title": "Towards Generalizable SER: Soft Labeling and Data Augmentation for\n  Modeling Temporal Emotion Shifts in Large-Scale Multilingual Speech",
            "updated": "2023-11-15T00:09:21Z",
            "published": "2023-11-15T00:09:21Z",
            "summary": "Recognizing emotions in spoken communication is crucial for advanced\nhuman-machine interaction. Current emotion detection methodologies often\ndisplay biases when applied cross-corpus. To address this, our study\namalgamates 16 diverse datasets, resulting in 375 hours of data across\nlanguages like English, Chinese, and Japanese. We propose a soft labeling\nsystem to capture gradational emotional intensities. Using the Whisper encoder\nand data augmentation methods inspired by contrastive learning, our method\nemphasizes the temporal dynamics of emotions. Our validation on four\nmultilingual datasets demonstrates notable zero-shot generalization. We publish\nour open source model weights and initial promising results after fine-tuning\non Hume-Prosody.",
            "author": [
                "Mohamed Osman",
                "Tamer Nadeem",
                "Ghada Khoriba"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08607v1",
                "http://arxiv.org/pdf/2311.08607v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08599v1",
            "title": "High-speed surface-property recognition by 140-GHz frequency",
            "updated": "2023-11-14T23:45:00Z",
            "published": "2023-11-14T23:45:00Z",
            "summary": "In the field of integrated sensing and communication, there's a growing need\nfor advanced environmental perception. The terahertz (THz) frequency band,\nsignificant for ultra-high-speed data connections, shows promise in\nenvironmental sensing, particularly in detecting surface textures crucial for\nautonomous system's decision-making. However, traditional numerical methods for\nparameter estimation in these environments struggle with accuracy, speed, and\nstability, especially in high-speed scenarios like vehicle-to-everything\ncommunications. This study introduces a deep learning approach for identifying\nsurface roughness using a 140-GHz setup tailored for high-speed conditions. A\nhigh-speed data acquisition system was developed to mimic real-world scenarios,\nand a diverse set of rough surface samples was collected for realistic\nhigh-speed datasets to train the models. The model was trained and validated in\nthree challenging scenarios: random occlusions, sparse data, and narrow-angle\nobservations. The results demonstrate the method's effectiveness in high-speed\nconditions, suggesting terahertz frequencies' potential in future sensing and\ncommunication applications.",
            "author": [
                "Jiacheng Liu",
                "Da Li",
                "Guohao Liu",
                "Yige Qiao",
                "Menghan Wei",
                "Chengyu Zhang",
                "Houjun Sun",
                "Jianjun Ma"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08599v1",
                "http://arxiv.org/pdf/2311.08599v1"
            ],
            "primary_category": "physics.app-ph",
            "category": [
                "physics.app-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08594v1",
            "title": "Variational Temporal IRT: Fast, Accurate, and Explainable Inference of\n  Dynamic Learner Proficiency",
            "updated": "2023-11-14T23:36:39Z",
            "published": "2023-11-14T23:36:39Z",
            "summary": "Dynamic Item Response Models extend the standard Item Response Theory (IRT)\nto capture temporal dynamics in learner ability. While these models have the\npotential to allow instructional systems to actively monitor the evolution of\nlearner proficiency in real time, existing dynamic item response models rely on\nexpensive inference algorithms that scale poorly to massive datasets. In this\nwork, we propose Variational Temporal IRT (VTIRT) for fast and accurate\ninference of dynamic learner proficiency. VTIRT offers orders of magnitude\nspeedup in inference runtime while still providing accurate inference.\nMoreover, the proposed algorithm is intrinsically interpretable by virtue of\nits modular design. When applied to 9 real student datasets, VTIRT consistently\nyields improvements in predicting future learner performance over other learner\nproficiency models.",
            "author": [
                "Yunsung Kim",
                "Sreechan Sankaranarayanan",
                "Chris Piech",
                "Candace Thille"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08594v1",
                "http://arxiv.org/pdf/2311.08594v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08585v1",
            "title": "Unsupervised segmentation of irradiation$\\unicode{x2010}$induced\n  order$\\unicode{x2010}$disorder phase transitions in electron microscopy",
            "updated": "2023-11-14T23:13:59Z",
            "published": "2023-11-14T23:13:59Z",
            "summary": "We present a method for the unsupervised segmentation of electron microscopy\nimages, which are powerful descriptors of materials and chemical systems.\nImages are oversegmented into overlapping chips, and similarity graphs are\ngenerated from embeddings extracted from a domain$\\unicode{x2010}$pretrained\nconvolutional neural network (CNN). The Louvain method for community detection\nis then applied to perform segmentation. The graph representation provides an\nintuitive way of presenting the relationship between chips and communities. We\ndemonstrate our method to track irradiation$\\unicode{x2010}$induced amorphous\nfronts in thin films used for catalysis and electronics. This method has\npotential for \"on$\\unicode{x2010}$the$\\unicode{x2010}$fly\" segmentation to\nguide emerging automated electron microscopes.",
            "author": [
                "Arman H Ter-Petrosyan",
                "Jenna A Bilbrey",
                "Christina M Doty",
                "Bethany E Matthews",
                "Le Wang",
                "Yingge Du",
                "Eric Lang",
                "Khalid Hattar",
                "Steven R Spurgeon"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08585v1",
                "http://arxiv.org/pdf/2311.08585v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "cs.CV",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08579v1",
            "title": "Graph-Induced Syntactic-Semantic Spaces in Transformer-Based Variational\n  AutoEncoders",
            "updated": "2023-11-14T22:47:23Z",
            "published": "2023-11-14T22:47:23Z",
            "summary": "The injection of syntactic information in Variational AutoEncoders (VAEs) has\nbeen shown to result in an overall improvement of performances and\ngeneralisation. An effective strategy to achieve such a goal is to separate the\nencoding of distributional semantic features and syntactic structures into\nheterogeneous latent spaces via multi-task learning or dual encoder\narchitectures. However, existing works employing such techniques are limited to\nLSTM-based VAEs. In this paper, we investigate latent space separation methods\nfor structural syntactic injection in Transformer-based VAE architectures\n(i.e., Optimus). Specifically, we explore how syntactic structures can be\nleveraged in the encoding stage through the integration of graph-based and\nsequential models, and how multiple, specialised latent representations can be\ninjected into the decoder's attention mechanism via low-rank operators. Our\nempirical evaluation, carried out on natural language sentences and\nmathematical expressions, reveals that the proposed end-to-end VAE architecture\ncan result in a better overall organisation of the latent space, alleviating\nthe information loss occurring in standard VAE setups, resulting in enhanced\nperformances on language modelling and downstream generation tasks.",
            "author": [
                "Yingji Zhang",
                "Marco Valentino",
                "Danilo S. Carvalho",
                "Ian Pratt-Hartmann",
                "Andr\u00e9 Freitas"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08579v1",
                "http://arxiv.org/pdf/2311.08579v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08576v1",
            "title": "Towards Evaluating AI Systems for Moral Status Using Self-Reports",
            "updated": "2023-11-14T22:45:44Z",
            "published": "2023-11-14T22:45:44Z",
            "summary": "As AI systems become more advanced and widely deployed, there will likely be\nincreasing debate over whether AI systems could have conscious experiences,\ndesires, or other states of potential moral significance. It is important to\ninform these discussions with empirical evidence to the extent possible. We\nargue that under the right circumstances, self-reports, or an AI system's\nstatements about its own internal states, could provide an avenue for\ninvestigating whether AI systems have states of moral significance.\nSelf-reports are the main way such states are assessed in humans (\"Are you in\npain?\"), but self-reports from current systems like large language models are\nspurious for many reasons (e.g. often just reflecting what humans would say).\nTo make self-reports more appropriate for this purpose, we propose to train\nmodels to answer many kinds of questions about themselves with known answers,\nwhile avoiding or limiting training incentives that bias self-reports. The hope\nof this approach is that models will develop introspection-like capabilities,\nand that these capabilities will generalize to questions about states of moral\nsignificance. We then propose methods for assessing the extent to which these\ntechniques have succeeded: evaluating self-report consistency across contexts\nand between similar models, measuring the confidence and resilience of models'\nself-reports, and using interpretability to corroborate self-reports. We also\ndiscuss challenges for our approach, from philosophical difficulties in\ninterpreting self-reports to technical reasons why our proposal might fail. We\nhope our discussion inspires philosophers and AI researchers to criticize and\nimprove our proposed methodology, as well as to run experiments to test whether\nself-reports can be made reliable enough to provide information about states of\nmoral significance.",
            "author": [
                "Ethan Perez",
                "Robert Long"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08576v1",
                "http://arxiv.org/pdf/2311.08576v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08575v1",
            "title": "Gaussian Approximation of Convex Sets by Intersections of Halfspaces",
            "updated": "2023-11-14T22:42:47Z",
            "published": "2023-11-14T22:42:47Z",
            "summary": "We study the approximability of general convex sets in $\\mathbb{R}^n$ by\nintersections of halfspaces, where the approximation quality is measured with\nrespect to the standard Gaussian distribution $N(0,I_n)$ and the complexity of\nan approximation is the number of halfspaces used. While a large body of\nresearch has considered the approximation of convex sets by intersections of\nhalfspaces under distance metrics such as the Lebesgue measure and Hausdorff\ndistance, prior to our work there has not been a systematic study of convex\napproximation under the Gaussian distribution.\n  We establish a range of upper and lower bounds, both for general convex sets\nand for specific natural convex sets that are of particular interest. Our\nresults demonstrate that the landscape of approximation is intriguingly\ndifferent under the Gaussian distribution versus previously studied distance\nmeasures. For example, we show that $2^{\\Theta(\\sqrt{n})}$ halfspaces are both\nnecessary and sufficient to approximate the origin-centered $\\ell_2$ ball of\nGaussian volume 1/2 to any constant accuracy, and that for $1 \\leq p < 2$, the\norigin-centered $\\ell_p$ ball of Gaussian volume 1/2 can be approximated to any\nconstant accuracy as an intersection of $2^{\\widetilde{O}(n^{3/4})}$ many\nhalfspaces. These bounds are quite different from known approximation results\nunder more commonly studied distance measures.\n  Our results are proved using techniques from many different areas. These\ninclude classical results on convex polyhedral approximation, Cram\\'er-type\nbounds on large deviations from probability theory, and -- perhaps surprisingly\n-- a range of topics from computational complexity, including computational\nlearning theory, unconditional pseudorandomness, and the study of influences\nand noise sensitivity in the analysis of Boolean functions.",
            "author": [
                "Anindya De",
                "Shivam Nadimpalli",
                "Rocco A. Servedio"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08575v1",
                "http://arxiv.org/pdf/2311.08575v1"
            ],
            "primary_category": "cs.CC",
            "category": [
                "cs.CC",
                "cs.DS",
                "math.MG",
                "math.PR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08572v1",
            "title": "Parameter-Efficient Multilingual Summarisation: An Empirical Study",
            "updated": "2023-11-14T22:32:39Z",
            "published": "2023-11-14T22:32:39Z",
            "summary": "With the increasing prevalence of Large Language Models, traditional full\nfine-tuning approaches face growing challenges, especially in memory-intensive\ntasks. This paper investigates the potential of Parameter-Efficient\nFine-Tuning, focusing on Low-Rank Adaptation (LoRA), for complex and\nunder-explored multilingual summarisation tasks. We conduct an extensive study\nacross different data availability scenarios, including full-data, low-data,\nand cross-lingual transfer, leveraging models of different sizes. Our findings\nreveal that LoRA lags behind full fine-tuning when trained with full data,\nhowever, it excels in low-data scenarios and cross-lingual transfer.\nInterestingly, as models scale up, the performance gap between LoRA and full\nfine-tuning diminishes. Additionally, we investigate effective strategies for\nfew-shot cross-lingual transfer, finding that continued LoRA tuning achieves\nthe best performance compared to both full fine-tuning and dynamic composition\nof language-specific LoRA modules.",
            "author": [
                "Chenxi Whitehouse",
                "Fantine Huot",
                "Jasmijn Bastings",
                "Mostafa Dehghani",
                "Chu-Cheng Lin",
                "Mirella Lapata"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08572v1",
                "http://arxiv.org/pdf/2311.08572v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08569v2",
            "title": "Uncertainty Quantification in Neural-Network Based Pain Intensity\n  Estimation",
            "updated": "2023-11-29T13:20:53Z",
            "published": "2023-11-14T22:14:07Z",
            "summary": "Improper pain management can lead to severe physical or mental consequences,\nincluding suffering, and an increased risk of opioid dependency. Assessing the\npresence and severity of pain is imperative to prevent such outcomes and\ndetermine the appropriate intervention. However, the evaluation of pain\nintensity is challenging because different individuals experience pain\ndifferently. To overcome this, researchers have employed machine learning\nmodels to evaluate pain intensity objectively. However, these efforts have\nprimarily focused on point estimation of pain, disregarding the inherent\nuncertainty and variability present in the data and model. Consequently, the\npoint estimates provide only partial information for clinical decision-making.\nThis study presents a neural network-based method for objective pain interval\nestimation, incorporating uncertainty quantification. This work explores three\nalgorithms: the bootstrap method, lower and upper bound estimation (LossL)\noptimized by genetic algorithm, and modified lower and upper bound estimation\n(LossS) optimized by gradient descent algorithm. Our empirical results reveal\nthat LossS outperforms the other two by providing a narrower prediction\ninterval. As LossS outperforms, we assessed its performance in three different\nscenarios for pain assessment: (1) a generalized approach (single model for the\nentire population), (2) a personalized approach (separate model for each\nindividual), and (3) a hybrid approach (separate model for each cluster of\nindividuals). Our findings demonstrate the hybrid approach's superior\nperformance, with notable practicality in clinical contexts. It has the\npotential to be a valuable tool for clinicians, enabling objective pain\nintensity assessment while taking uncertainty into account. This capability is\ncrucial in facilitating effective pain management and reducing the risks\nassociated with improper treatment.",
            "author": [
                "Burcu Ozek",
                "Zhenyuan Lu",
                "Srinivasan Radhakrishnan",
                "Sagar Kamarthi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08569v2",
                "http://arxiv.org/pdf/2311.08569v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08568v1",
            "title": "Adversarial Imitation Learning On Aggregated Data",
            "updated": "2023-11-14T22:13:38Z",
            "published": "2023-11-14T22:13:38Z",
            "summary": "Inverse Reinforcement Learning (IRL) learns an optimal policy, given some\nexpert demonstrations, thus avoiding the need for the tedious process of\nspecifying a suitable reward function. However, current methods are constrained\nby at least one of the following requirements. The first one is the need to\nfully solve a forward Reinforcement Learning (RL) problem in the inner loop of\nthe algorithm, which might be prohibitively expensive in many complex\nenvironments. The second one is the need for full trajectories from the\nexperts, which might not be easily available. The third one is the assumption\nthat the expert data is homogeneous rather than a collection from various\nexperts or possibly alternative solutions to the same task. Such constraints\nmake IRL approaches either not scalable or not usable on certain existing\nsystems. In this work we propose an approach which removes these requirements\nthrough a dynamic, adaptive method called Adversarial Imitation Learning on\nAggregated Data (AILAD). It learns conjointly both a non linear reward function\nand the associated optimal policy using an adversarial framework. The reward\nlearner only uses aggregated data. Moreover, it generates diverse behaviors\nproducing a distribution over the aggregated data matching that of the experts.",
            "author": [
                "Pierre Le Pelletier de Woillemont",
                "R\u00e9mi Labory",
                "Vincent Corruble"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08568v1",
                "http://arxiv.org/pdf/2311.08568v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08561v1",
            "title": "Measuring association with recursive rank binning",
            "updated": "2023-11-14T21:43:56Z",
            "published": "2023-11-14T21:43:56Z",
            "summary": "Pairwise measures of dependence are a common tool to map data in the early\nstages of analysis with several modern examples based on maximized partitions\nof the pairwise sample space. Following a short survey of modern measures of\ndependence, we introduce a new measure which recursively splits the ranks of a\npair of variables to partition the sample space and computes the $\\chi^2$\nstatistic on the resulting bins. Splitting logic is detailed for splits\nmaximizing a score function and randomly selected splits. Simulations indicate\nthat random splitting produces a statistic conservatively approximated by the\n$\\chi^2$ distribution without a loss of power to detect numerous different data\npatterns compared to maximized binning. Though it seems to add no power to\ndetect dependence, maximized recursive binning is shown to produce a natural\nvisualization of the data and the measure. Applying maximized recursive rank\nbinning to S&P 500 constituent data suggests the automatic detection of tail\ndependence.",
            "author": [
                "Chris Salahub",
                "Wayne Oldford"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08561v1",
                "http://arxiv.org/pdf/2311.08561v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.CO",
                "stat.ML",
                "62G10",
                "G.3; J.2"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08557v1",
            "title": "Low-light Pedestrian Detection in Visible and Infrared Image Feeds:\n  Issues and Challenges",
            "updated": "2023-11-14T21:39:15Z",
            "published": "2023-11-14T21:39:15Z",
            "summary": "Pedestrian detection has become a cornerstone for several high-level tasks,\nincluding autonomous driving, intelligent transportation, and traffic\nsurveillance. There are several works focussed on pedestrian detection using\nvisible images, mainly in the daytime. However, this task is very intriguing\nwhen the environmental conditions change to poor lighting or nighttime.\nRecently, new ideas have been spurred to use alternative sources, such as Far\nInfraRed (FIR) temperature sensor feeds for detecting pedestrians in low-light\nconditions. This study comprehensively reviews recent developments in low-light\npedestrian detection approaches. It systematically categorizes and analyses\nvarious algorithms from region-based to non-region-based and graph-based\nlearning methodologies by highlighting their methodologies, implementation\nissues, and challenges. It also outlines the key benchmark datasets that can be\nused for research and development of advanced pedestrian detection algorithms,\nparticularly in low-light situations",
            "author": [
                "Hrishikesh Vachhani",
                "Thangarajah Akilan",
                "Yash Devmurari",
                "Nisharaff Shaik",
                "Dhruvisha Patel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08557v1",
                "http://arxiv.org/pdf/2311.08557v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08549v1",
            "title": "Manifold learning in Wasserstein space",
            "updated": "2023-11-14T21:21:35Z",
            "published": "2023-11-14T21:21:35Z",
            "summary": "This paper aims at building the theoretical foundations for manifold learning\nalgorithms in the space of absolutely continuous probability measures on a\ncompact and convex subset of $\\mathbb{R}^d$, metrized with the Wasserstein-2\ndistance $W$. We begin by introducing a natural construction of submanifolds\n$\\Lambda$ of probability measures equipped with metric $W_\\Lambda$, the\ngeodesic restriction of $W$ to $\\Lambda$. In contrast to other constructions,\nthese submanifolds are not necessarily flat, but still allow for local\nlinearizations in a similar fashion to Riemannian submanifolds of\n$\\mathbb{R}^d$. We then show how the latent manifold structure of\n$(\\Lambda,W_{\\Lambda})$ can be learned from samples $\\{\\lambda_i\\}_{i=1}^N$ of\n$\\Lambda$ and pairwise extrinsic Wasserstein distances $W$ only. In particular,\nwe show that the metric space $(\\Lambda,W_{\\Lambda})$ can be asymptotically\nrecovered in the sense of Gromov--Wasserstein from a graph with nodes\n$\\{\\lambda_i\\}_{i=1}^N$ and edge weights $W(\\lambda_i,\\lambda_j)$. In addition,\nwe demonstrate how the tangent space at a sample $\\lambda$ can be\nasymptotically recovered via spectral analysis of a suitable \"covariance\noperator\" using optimal transport maps from $\\lambda$ to sufficiently close and\ndiverse samples $\\{\\lambda_i\\}_{i=1}^N$. The paper closes with some explicit\nconstructions of submanifolds $\\Lambda$ and numerical examples on the recovery\nof tangent spaces through spectral analysis.",
            "author": [
                "Keaton Hamm",
                "Caroline Moosm\u00fcller",
                "Bernhard Schmitzer",
                "Matthew Thorpe"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08549v1",
                "http://arxiv.org/pdf/2311.08549v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "math.DG",
                "49Q22, 41A65, 58B20, 53Z50"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08547v1",
            "title": "DeepThought: An Architecture for Autonomous Self-motivated Systems",
            "updated": "2023-11-14T21:20:23Z",
            "published": "2023-11-14T21:20:23Z",
            "summary": "The ability of large language models (LLMs) to engage in credible dialogues\nwith humans, taking into account the training data and the context of the\nconversation, has raised discussions about their ability to exhibit intrinsic\nmotivations, agency, or even some degree of consciousness. We argue that the\ninternal architecture of LLMs and their finite and volatile state cannot\nsupport any of these properties. By combining insights from complementary\nlearning systems, global neuronal workspace, and attention schema theories, we\npropose to integrate LLMs and other deep learning systems into an architecture\nfor cognitive language agents able to exhibit properties akin to agency,\nself-motivation, even some features of meta-cognition.",
            "author": [
                "Arlindo L. Oliveira",
                "Tiago Domingos",
                "M\u00e1rio Figueiredo",
                "Pedro U. Lima"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08547v1",
                "http://arxiv.org/pdf/2311.08547v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "I.2"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08543v1",
            "title": "2D-RC: Two-Dimensional Neural Network Approach for OTFS Symbol Detection",
            "updated": "2023-11-14T21:16:40Z",
            "published": "2023-11-14T21:16:40Z",
            "summary": "Orthogonal time frequency space (OTFS) is a promising modulation scheme for\nwireless communication in high-mobility scenarios. Recently, a reservoir\ncomputing (RC) based approach has been introduced for online subframe-based\nsymbol detection in the OTFS system, where only a limited number of\nover-the-air (OTA) pilot symbols are utilized for training. However, this\napproach does not leverage the domain knowledge specific to the OTFS system.\nThis paper introduces a novel two-dimensional RC (2D-RC) method that\nincorporates the structural knowledge of the OTFS system into the design for\nonline symbol detection on a subframe basis. Specifically, as the channel\nresponse acts as a two-dimensional (2D) operation over the transmitted\ninformation symbols in the delay-Doppler (DD) domain, the 2D-RC is designed to\nhave a 2D structure to equalize the channel. With the introduced architecture,\nthe 2D-RC can benefit from the predictable channel representation in the DD\ndomain. Moreover, unlike the previous work that requires multiple RCs to learn\nthe channel feature, the 2D-RC only requires a single neural network for\ndetection. Experimental results demonstrate the effectiveness of the 2D-RC\napproach across different OTFS system variants and modulation orders.",
            "author": [
                "Jiarui Xu",
                "Karim Said",
                "Lizhong Zheng",
                "Lingjia Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08543v1",
                "http://arxiv.org/pdf/2311.08543v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08539v1",
            "title": "Physical Adversarial Examples for Multi-Camera Systems",
            "updated": "2023-11-14T21:04:49Z",
            "published": "2023-11-14T21:04:49Z",
            "summary": "Neural networks build the foundation of several intelligent systems, which,\nhowever, are known to be easily fooled by adversarial examples. Recent advances\nmade these attacks possible even in air-gapped scenarios, where the autonomous\nsystem observes its surroundings by, e.g., a camera. We extend these ideas in\nour research and evaluate the robustness of multi-camera setups against such\nphysical adversarial examples. This scenario becomes ever more important with\nthe rise in popularity of autonomous vehicles, which fuse the information of\nseveral cameras for their driving decision. While we find that multi-camera\nsetups provide some robustness towards past attack methods, we see that this\nadvantage reduces when optimizing on multiple perspectives at once. We propose\na novel attack method that we call Transcender-MC, where we incorporate online\n3D renderings and perspective projections in the training process. Moreover, we\nmotivate that certain data augmentation techniques can facilitate the\ngeneration of successful adversarial examples even further. Transcender-MC is\n11% more effective in successfully attacking multi-camera setups than\nstate-of-the-art methods. Our findings offer valuable insights regarding the\nresilience of object detection in a setup with multiple cameras and motivate\nthe need of developing adequate defense mechanisms against them.",
            "author": [
                "Ana R\u0103du\u0163oiu",
                "Jan-Philipp Schulze",
                "Philip Sperl",
                "Konstantin B\u00f6ttinger"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08539v1",
                "http://arxiv.org/pdf/2311.08539v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08538v1",
            "title": "Extending Multilingual Machine Translation through Imitation Learning",
            "updated": "2023-11-14T21:04:03Z",
            "published": "2023-11-14T21:04:03Z",
            "summary": "Despite the growing variety of languages supported by existing multilingual\nneural machine translation (MNMT) models, most of the world's languages are\nstill being left behind. We aim to extend large-scale MNMT models to a new\nlanguage, allowing for translation between the newly added and all of the\nalready supported languages in a challenging scenario: using only a parallel\ncorpus between the new language and English. Previous approaches, such as\ncontinued training on parallel data including the new language, suffer from\ncatastrophic forgetting (i.e., performance on other languages is reduced). Our\nnovel approach Imit-MNMT treats the task as an imitation learning process,\nwhich mimicks the behavior of an expert, a technique widely used in the\ncomputer vision area, but not well explored in NLP. More specifically, we\nconstruct a pseudo multi-parallel corpus of the new and the original languages\nby pivoting through English, and imitate the output distribution of the\noriginal MNMT model. Extensive experiments show that our approach significantly\nimproves the translation performance between the new and the original\nlanguages, without severe catastrophic forgetting. We also demonstrate that our\napproach is capable of solving copy and off-target problems, which are two\ncommon issues existence in current large-scale MNMT models.",
            "author": [
                "Wen Lai",
                "Viktor Hangya",
                "Alexander Fraser"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08538v1",
                "http://arxiv.org/pdf/2311.08538v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08536v1",
            "title": "Low-Frequency Load Identification using CNN-BiLSTM Attention Mechanism",
            "updated": "2023-11-14T21:02:27Z",
            "published": "2023-11-14T21:02:27Z",
            "summary": "Non-intrusive Load Monitoring (NILM) is an established technique for\neffective and cost-efficient electricity consumption management. The method is\nused to estimate appliance-level power consumption from aggregated power\nmeasurements. This paper presents a hybrid learning approach, consisting of a\nconvolutional neural network (CNN) and a bidirectional long short-term memory\n(BILSTM), featuring an integrated attention mechanism, all within the context\nof disaggregating low-frequency power data. While prior research has been\nmainly focused on high-frequency data disaggregation, our study takes a\ndistinct direction by concentrating on low-frequency data. The proposed hybrid\nCNN-BILSTM model is adept at extracting both temporal (time-related) and\nspatial (location-related) features, allowing it to precisely identify energy\nconsumption patterns at the appliance level. This accuracy is further enhanced\nby the attention mechanism, which aids the model in pinpointing crucial parts\nof the data for more precise event detection and load disaggregation. We\nconduct simulations using the existing low-frequency REDD dataset to assess our\nmodel performance. The results demonstrate that our proposed approach\noutperforms existing methods in terms of accuracy and computation time.",
            "author": [
                "Amanie Azzam",
                "Saba Sanami",
                "Amir G. Aghdam"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08536v1",
                "http://arxiv.org/pdf/2311.08536v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.LG",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08533v1",
            "title": "Natural Language Processing for Financial Regulation",
            "updated": "2023-11-14T20:58:21Z",
            "published": "2023-11-14T20:58:21Z",
            "summary": "This article provides an understanding of Natural Language Processing\ntechniques in the framework of financial regulation, more specifically in order\nto perform semantic matching search between rules and policy when no dataset is\navailable for supervised learning. We outline how to outperform simple\npre-trained sentences-transformer models using freely available resources and\nexplain the mathematical concepts behind the key building blocks of Natural\nLanguage Processing.",
            "author": [
                "Ixandra Achitouv",
                "Dragos Gorduza",
                "Antoine Jacquier"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08533v1",
                "http://arxiv.org/pdf/2311.08533v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG",
                "q-fin.CP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08531v1",
            "title": "Reciprocal Asymptotically Decoupled Hamiltonian for Cavity Quantum\n  Electrodynamics",
            "updated": "2023-11-14T20:56:24Z",
            "published": "2023-11-14T20:56:24Z",
            "summary": "We develop a new theoretical framework for describing light-matter\ninteractions in cavity quantum electrodynamics (QED), optimized for efficient\nconvergence at arbitrarily strong coupling strengths and is naturally\napplicable to low-dimensional materials. This new Hamiltonian is obtained by\napplying a unitary gauge transformation on the p$\\cdot$A Hamiltonian, with a\nshift on both the matter coordinate and the photonic coordinate, then\nperforming a phase rotation and transforming in the reciprocal space of the\nmatter. By formulating the light-matter interaction in terms of an\nupper-bounded effective coupling parameter, this method allows one to easily\nconverge eigenspectra calculations for any coupling strength, even far into the\nultra-strong and deep-strong coupling regimes. We refer to this new approach as\nthe Reciprocal Asymptotically Decoupled (RAD) Hamiltonian. The RAD Hamiltonian\nallows for a fast convergence of the polariton eigenspectrum with a much\nsmaller matter and photon basis, compared to the commonly used p$\\cdot$A or\ndipole gauge Hamiltonians. The RAD Hamiltonian also allows one to go beyond the\ncommonly used long-wavelength approximation and accurately describes the\nspatial variations of the field inside the cavity, which ensures the\nconservation of momentum between light and matter.",
            "author": [
                "Michael A. D. Taylor",
                "Braden M. Weight",
                "Pengfei Huo3"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08531v1",
                "http://arxiv.org/pdf/2311.08531v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cond-mat.other",
                "physics.optics"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08530v1",
            "title": "SceneScore: Learning a Cost Function for Object Arrangement",
            "updated": "2023-11-14T20:55:40Z",
            "published": "2023-11-14T20:55:40Z",
            "summary": "Arranging objects correctly is a key capability for robots which unlocks a\nwide range of useful tasks. A prerequisite for creating successful arrangements\nis the ability to evaluate the desirability of a given arrangement. Our method\n\"SceneScore\" learns a cost function for arrangements, such that desirable,\nhuman-like arrangements have a low cost. We learn the distribution of training\narrangements offline using an energy-based model, solely from example images\nwithout requiring environment interaction or human supervision. Our model is\nrepresented by a graph neural network which learns object-object relations,\nusing graphs constructed from images. Experiments demonstrate that the learned\ncost function can be used to predict poses for missing objects, generalise to\nnovel objects using semantic features, and can be composed with other cost\nfunctions to satisfy constraints at inference time.",
            "author": [
                "Ivan Kapelyukh",
                "Edward Johns"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08530v1",
                "http://arxiv.org/pdf/2311.08530v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08527v1",
            "title": "Inferring the Long-Term Causal Effects of Long-Term Treatments from\n  Short-Term Experiments",
            "updated": "2023-11-14T20:42:52Z",
            "published": "2023-11-14T20:42:52Z",
            "summary": "We study inference on the long-term causal effect of a continual exposure to\na novel intervention, which we term a long-term treatment, based on an\nexperiment involving only short-term observations. Key examples include the\nlong-term health effects of regularly-taken medicine or of environmental\nhazards and the long-term effects on users of changes to an online platform.\nThis stands in contrast to short-term treatments or \"shocks,\" whose long-term\neffect can reasonably be mediated by short-term observations, enabling the use\nof surrogate methods. Long-term treatments by definition have direct effects on\nlong-term outcomes via continual exposure so surrogacy cannot reasonably hold.\n  Our approach instead learns long-term temporal dynamics directly from\nshort-term experimental data, assuming that the initial dynamics observed\npersist but avoiding the need for both surrogacy assumptions and auxiliary data\nwith long-term observations. We connect the problem with offline reinforcement\nlearning, leveraging doubly-robust estimators to estimate long-term causal\neffects for long-term treatments and construct confidence intervals. Finally,\nwe demonstrate the method in simulated experiments.",
            "author": [
                "Allen Tran",
                "Aur\u00e9lien Bibaut",
                "Nathan Kallus"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08527v1",
                "http://arxiv.org/pdf/2311.08527v1"
            ],
            "primary_category": "stat.AP",
            "category": [
                "stat.AP",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08526v1",
            "title": "GLiNER: Generalist Model for Named Entity Recognition using\n  Bidirectional Transformer",
            "updated": "2023-11-14T20:39:12Z",
            "published": "2023-11-14T20:39:12Z",
            "summary": "Named Entity Recognition (NER) is essential in various Natural Language\nProcessing (NLP) applications. Traditional NER models are effective but limited\nto a set of predefined entity types. In contrast, Large Language Models (LLMs)\ncan extract arbitrary entities through natural language instructions, offering\ngreater flexibility. However, their size and cost, particularly for those\naccessed via APIs like ChatGPT, make them impractical in resource-limited\nscenarios. In this paper, we introduce a compact NER model trained to identify\nany type of entity. Leveraging a bidirectional transformer encoder, our model,\nGLiNER, facilitates parallel entity extraction, an advantage over the slow\nsequential token generation of LLMs. Through comprehensive testing, GLiNER\ndemonstrate strong performance, outperforming both ChatGPT and fine-tuned LLMs\nin zero-shot evaluations on various NER benchmarks.",
            "author": [
                "Urchade Zaratiana",
                "Nadi Tomeh",
                "Pierre Holat",
                "Thierry Charnois"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08526v1",
                "http://arxiv.org/pdf/2311.08526v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08525v1",
            "title": "Efficient Rotation Invariance in Deep Neural Networks through Artificial\n  Mental Rotation",
            "updated": "2023-11-14T20:37:54Z",
            "published": "2023-11-14T20:37:54Z",
            "summary": "Humans and animals recognize objects irrespective of the beholder's point of\nview, which may drastically change their appearances. Artificial pattern\nrecognizers also strive to achieve this, e.g., through translational invariance\nin convolutional neural networks (CNNs). However, both CNNs and vision\ntransformers (ViTs) perform very poorly on rotated inputs. Here we present\nartificial mental rotation (AMR), a novel deep learning paradigm for dealing\nwith in-plane rotations inspired by the neuro-psychological concept of mental\nrotation. Our simple AMR implementation works with all common CNN and ViT\narchitectures. We test it on ImageNet, Stanford Cars, and Oxford Pet. With a\ntop-1 error (averaged across datasets and architectures) of $0.743$, AMR\noutperforms the current state of the art (rotational data augmentation, average\ntop-1 error of $0.626$) by $19\\%$. We also easily transfer a trained AMR module\nto a downstream task to improve the performance of a pre-trained semantic\nsegmentation model on rotated CoCo from $32.7$ to $55.2$ IoU.",
            "author": [
                "Lukas Tuggener",
                "Thilo Stadelmann",
                "J\u00fcrgen Schmidhuber"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08525v1",
                "http://arxiv.org/pdf/2311.08525v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08524v1",
            "title": "Cross-dataset domain adaptation for the classification COVID-19 using\n  chest computed tomography images",
            "updated": "2023-11-14T20:36:34Z",
            "published": "2023-11-14T20:36:34Z",
            "summary": "Detecting COVID-19 patients using Computed Tomography (CT) images of the\nlungs is an active area of research. Datasets of CT images from COVID-19\npatients are becoming available. Deep learning (DL) solutions and in particular\nConvolutional Neural Networks (CNN) have achieved impressive results for the\nclassification of COVID-19 CT images, but only when the training and testing\ntake place within the same dataset. Work on the cross-dataset problem is still\nlimited and the achieved results are low. Our work tackles the cross-dataset\nproblem through a Domain Adaptation (DA) technique with deep learning. Our\nproposed solution, COVID19-DANet, is based on pre-trained CNN backbone for\nfeature extraction. For this task, we select the pre-trained Efficientnet-B3\nCNN because it has achieved impressive classification accuracy in previous\nwork. The backbone CNN is followed by a prototypical layer which is a concept\nborrowed from prototypical networks in few-shot learning (FSL). It computes a\ncosine distance between given samples and the class prototypes and then\nconverts them to class probabilities using the Softmax function. To train the\nCOVID19-DANet model, we propose a combined loss function that is composed of\nthe standard cross-entropy loss for class discrimination and another entropy\nloss computed over the unlabelled target set only. This so-called unlabelled\ntarget entropy loss is minimized and maximized in an alternative fashion, to\nreach the two objectives of class discrimination and domain invariance.\nCOVID19-DANet is tested under four cross-dataset scenarios using the\nSARS-CoV-2-CT and COVID19-CT datasets and has achieved encouraging results\ncompared to recent work in the literature.",
            "author": [
                "Ridha Ouni",
                "Haikel Alhichri"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08524v1",
                "http://arxiv.org/pdf/2311.08524v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08516v1",
            "title": "LLMs cannot find reasoning errors, but can correct them!",
            "updated": "2023-11-14T20:12:38Z",
            "published": "2023-11-14T20:12:38Z",
            "summary": "While self-correction has shown promise in improving LLM outputs in terms of\nstyle and quality (e.g. Chen et al., 2023; Madaan et al., 2023), recent\nattempts to self-correct logical or reasoning errors often cause correct\nanswers to become incorrect, resulting in worse performances overall (Huang et\nal., 2023). In this paper, we break down the self-correction process into two\ncore components: mistake finding and output correction. For mistake finding, we\nrelease BIG-Bench Mistake, a dataset of logical mistakes in Chain-of-Thought\nreasoning traces. We provide benchmark numbers for several state-of-the-art\nLLMs, and demonstrate that LLMs generally struggle with finding logical\nmistakes. For output correction, we propose a backtracking method which\nprovides large improvements when given information on mistake location. We\nconstrue backtracking as a lightweight alternative to reinforcement learning\nmethods, and show that it remains effective with a reward model at 60-70%\naccuracy.",
            "author": [
                "Gladys Tyen",
                "Hassan Mansoor",
                "Peter Chen",
                "Tony Mak",
                "Victor C\u0103rbune"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08516v1",
                "http://arxiv.org/pdf/2311.08516v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.00026v1",
            "title": "A Quality-of-Service Compliance System using Federated Learning and\n  Optimistic Rollups",
            "updated": "2023-11-14T20:02:37Z",
            "published": "2023-11-14T20:02:37Z",
            "summary": "Edge computing brings a new paradigm in which the sharing of computing,\nstorage, and bandwidth resources as close as possible to the mobile devices or\nsensors generating a large amount of data. A parallel trend is the rise of\nphones and tablets as primary computing devices for many people. The powerful\nsensors present on these devices combined with the fact that they are mobile,\nmean they have access to data of an unprecedentedly diverse and private nature.\nModels learned on such data hold the promise of greatly improving usability by\npowering more intelligent applications, but the sensitive nature of the data\nmeans there are risks and responsibilities to storing it in a centralized\nlocation. To address the data privacy required for some data in these devices\nwe propose the use of Federated Learning (FL) so that specific data about\nservices performed by clients do not leave the source machines. Instead of\nsharing data, users collaboratively train a model by only sending weight\nupdates to a server. However, the naive use of FL in those scenarios exposes it\nto a risk of corruption, whether intentional or not, during the training phase.\nTo improve the security of the FL structure, we propose a decentralized\nBlockchain-based FL in an edge computing scenario. We also apply blockchain to\ncreate a reward mechanism in FL to enable incentive strategy for trainers.",
            "author": [
                "Joao Paulo de Brito Goncalves",
                "Guilherme Emerick Sathler",
                "Rodolfo da Silva Villaca"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00026v1",
                "http://arxiv.org/pdf/2312.00026v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08504v1",
            "title": "On semi-supervised estimation using exponential tilt mixture models",
            "updated": "2023-11-14T19:53:26Z",
            "published": "2023-11-14T19:53:26Z",
            "summary": "Consider a semi-supervised setting with a labeled dataset of binary responses\nand predictors and an unlabeled dataset with only the predictors. Logistic\nregression is equivalent to an exponential tilt model in the labeled\npopulation. For semi-supervised estimation, we develop further analysis and\nunderstanding of a statistical approach using exponential tilt mixture (ETM)\nmodels and maximum nonparametric likelihood estimation, while allowing that the\nclass proportions may differ between the unlabeled and labeled data. We derive\nasymptotic properties of ETM-based estimation and demonstrate improved\nefficiency over supervised logistic regression in a random sampling setup and\nan outcome-stratified sampling setup previously used. Moreover, we reconcile\nsuch efficiency improvement with the existing semiparametric efficiency theory\nwhen the class proportions in the unlabeled and labeled data are restricted to\nbe the same. We also provide a simulation study to numerically illustrate our\ntheoretical findings.",
            "author": [
                "Ye Tian",
                "Xinwei Zhang",
                "Zhiqiang Tan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08504v1",
                "http://arxiv.org/pdf/2311.08504v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08503v1",
            "title": "MADG: Margin-based Adversarial Learning for Domain Generalization",
            "updated": "2023-11-14T19:53:09Z",
            "published": "2023-11-14T19:53:09Z",
            "summary": "Domain Generalization (DG) techniques have emerged as a popular approach to\naddress the challenges of domain shift in Deep Learning (DL), with the goal of\ngeneralizing well to the target domain unseen during the training. In recent\nyears, numerous methods have been proposed to address the DG setting, among\nwhich one popular approach is the adversarial learning-based methodology. The\nmain idea behind adversarial DG methods is to learn domain-invariant features\nby minimizing a discrepancy metric. However, most adversarial DG methods use\n0-1 loss based $\\mathcal{H}\\Delta\\mathcal{H}$ divergence metric. In contrast,\nthe margin loss-based discrepancy metric has the following advantages: more\ninformative, tighter, practical, and efficiently optimizable. To mitigate this\ngap, this work proposes a novel adversarial learning DG algorithm, MADG,\nmotivated by a margin loss-based discrepancy metric. The proposed MADG model\nlearns domain-invariant features across all source domains and uses adversarial\ntraining to generalize well to the unseen target domain. We also provide a\ntheoretical analysis of the proposed MADG model based on the unseen target\nerror bound. Specifically, we construct the link between the source and unseen\ndomains in the real-valued hypothesis space and derive the generalization bound\nusing margin loss and Rademacher complexity. We extensively experiment with the\nMADG model on popular real-world DG datasets, VLCS, PACS, OfficeHome,\nDomainNet, and TerraIncognita. We evaluate the proposed algorithm on\nDomainBed's benchmark and observe consistent performance across all the\ndatasets.",
            "author": [
                "Aveen Dayal",
                "Vimal K. B.",
                "Linga Reddy Cenkeramaddi",
                "C. Krishna Mohan",
                "Abhinav Kumar",
                "Vineeth N Balasubramanian"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08503v1",
                "http://arxiv.org/pdf/2311.08503v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08502v2",
            "title": "Variational Quantum Eigensolver with Constraints (VQEC): Solving\n  Constrained Optimization Problems via VQE",
            "updated": "2023-11-17T16:08:52Z",
            "published": "2023-11-14T19:49:09Z",
            "summary": "Variational quantum approaches have shown great promise in finding\nnear-optimal solutions to computationally challenging tasks. Nonetheless,\nenforcing constraints in a disciplined fashion has been largely unexplored. To\naddress this gap, this work proposes a hybrid quantum-classical algorithmic\nparadigm termed VQEC that extends the celebrated VQE to handle optimization\nwith constraints. As with the standard VQE, the vector of optimization\nvariables is captured by the state of a variational quantum circuit (VQC). To\ndeal with constraints, VQEC optimizes a Lagrangian function classically over\nboth the VQC parameters as well as the dual variables associated with\nconstraints. To comply with the quantum setup, variables are updated via a\nperturbed primal-dual method leveraging the parameter shift rule. Among a wide\ngamut of potential applications, we showcase how VQEC can approximately solve\nquadratically-constrained binary optimization (QCBO) problems, find stochastic\nbinary policies satisfying quadratic constraints on the average and in\nprobability, and solve large-scale linear programs (LP) over the probability\nsimplex. Under an assumption on the error for the VQC to approximate an\narbitrary probability mass function (PMF), we provide bounds on the optimality\ngap attained by a VQC. Numerical tests on a quantum simulator investigate the\neffect of various parameters and corroborate that VQEC can generate\nhigh-quality solutions.",
            "author": [
                "Thinh Viet Le",
                "Vassilis Kekatos"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08502v2",
                "http://arxiv.org/pdf/2311.08502v2"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16167v1",
            "title": "MMPDE-Net and Moving Sampling Physics-informed Neural Networks Based On\n  Moving Mesh Method",
            "updated": "2023-11-14T19:43:56Z",
            "published": "2023-11-14T19:43:56Z",
            "summary": "In this work, we propose an end-to-end adaptive sampling neural network\n(MMPDE-Net) based on the moving mesh PDE method, which can adaptively generate\nnew coordinates of sampling points by solving the moving mesh PDE. This model\nfocuses on improving the efficiency of individual sampling points. Moreover, we\nhave developed an iterative algorithm based on MMPDE-Net, which makes the\nsampling points more precise and controllable. Since MMPDE-Net is a framework\nindependent of the deep learning solver, we combine it with PINN to propose\nMS-PINN and demonstrate its effectiveness by performing error analysis under\nthe assumptions given in this paper. Meanwhile, we demonstrate the performance\nimprovement of MS-PINN compared to PINN through numerical experiments on four\ntypical examples to verify the effectiveness of our method.",
            "author": [
                "Yu Yang",
                "Qihong Yang",
                "Yangtao Deng",
                "Qiaolin He"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16167v1",
                "http://arxiv.org/pdf/2311.16167v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.AI",
                "cs.LG",
                "cs.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08496v1",
            "title": "Robust Differentiable Predictive Control with Safety Guarantees: A\n  Predictive Safety Filter Approach",
            "updated": "2023-11-14T19:42:00Z",
            "published": "2023-11-14T19:42:00Z",
            "summary": "In this paper, we propose a novel predictive safety filter that is robust to\nbounded perturbations and is combined with a learning-based control called\ndifferentiable predictive control (DPC). The proposed method provides rigorous\nguarantees of safety in the presence of bounded perturbations and implements\nDPC so long as the DPC control satisfies the system constraints. The approach\nalso incorporates two forms of event-triggering to reduce online computation.\nThe approach is comprised of a robust predictive safety filter that extends\nupon existing work to reject disturbances for discrete-time, time-varying\nnonlinear systems with time-varying constraints. The safety filter is based on\nnovel concepts of robust, discrete-time barrier functions and can be used to\nfilter any control law. Here we use the safety filter in conjunction with DPC\nas a promising policy optimization method. The approach is demonstrated on a\nsingle-integrator, two-tank system, and building example.",
            "author": [
                "Wenceslao Shaw Cortez",
                "Jan Drgona",
                "Draguna Vrabie",
                "Mahantesh Halappanavar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08496v1",
                "http://arxiv.org/pdf/2311.08496v1"
            ],
            "primary_category": "cs.SY",
            "category": [
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08493v1",
            "title": "Performance of Machine Learning Classification in Mammography Images\n  using BI-RADS",
            "updated": "2023-11-14T19:41:19Z",
            "published": "2023-11-14T19:41:19Z",
            "summary": "This research aims to investigate the classification accuracy of various\nstate-of-the-art image classification models across different categories of\nbreast ultrasound images, as defined by the Breast Imaging Reporting and Data\nSystem (BI-RADS). To achieve this, we have utilized a comprehensively assembled\ndataset of 2,945 mammographic images sourced from 1,540 patients. In order to\nconduct a thorough analysis, we employed six advanced classification\narchitectures, including VGG19 \\cite{simonyan2014very}, ResNet50\n\\cite{he2016deep}, GoogleNet \\cite{szegedy2015going}, ConvNext\n\\cite{liu2022convnet}, EfficientNet \\cite{tan2019efficientnet}, and Vision\nTransformers (ViT) \\cite{dosovitskiy2020image}, instead of traditional machine\nlearning models. We evaluate models in three different settings: full\nfine-tuning, linear evaluation and training from scratch. Our findings\ndemonstrate the effectiveness and capability of our Computer-Aided Diagnosis\n(CAD) system, with a remarkable accuracy of 76.39\\% and an F1 score of 67.94\\%\nin the full fine-tuning setting. Our findings indicate the potential for\nenhanced diagnostic accuracy in the field of breast imaging, providing a solid\nfoundation for future endeavors aiming to improve the precision and reliability\nof CAD systems in medical imaging.",
            "author": [
                "Malitha Gunawardhana",
                "Norbert Zolek"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08493v1",
                "http://arxiv.org/pdf/2311.08493v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08485v1",
            "title": "Automated Identification of Sexual Orientation and Gender Identity\n  Discriminatory Texts from Issue Comments",
            "updated": "2023-11-14T19:24:31Z",
            "published": "2023-11-14T19:24:31Z",
            "summary": "In an industry dominated by straight men, many developers representing other\ngender identities and sexual orientations often encounter hateful or\ndiscriminatory messages. Such communications pose barriers to participation for\nwomen and LGBTQ+ persons. Due to sheer volume, manual inspection of all\ncommunications for discriminatory communication is infeasible for a large-scale\nFree Open-Source Software (FLOSS) community. To address this challenge, this\nstudy aims to develop an automated mechanism to identify Sexual orientation and\nGender identity Discriminatory (SGID) texts from software developers'\ncommunications. On this goal, we trained and evaluated SGID4SE ( Sexual\norientation and Gender Identity Discriminatory text identification for (4)\nSoftware Engineering texts) as a supervised learning-based SGID detection tool.\nSGID4SE incorporates six preprocessing steps and ten state-of-the-art\nalgorithms. SGID4SE implements six different strategies to improve the\nperformance of the minority class. We empirically evaluated each strategy and\nidentified an optimum configuration for each algorithm. In our ten-fold\ncross-validation-based evaluations, a BERT-based model boosts the best\nperformance with 85.9% precision, 80.0% recall, and 82.9% F1-Score for the SGID\nclass. This model achieves 95.7% accuracy and 80.4% Matthews Correlation\nCoefficient. Our dataset and tool establish a foundation for further research\nin this direction.",
            "author": [
                "Sayma Sultana",
                "Jaydeb Sarker",
                "Farzana Israt",
                "Rajshakhar Paul",
                "Amiangshu Bosu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08485v1",
                "http://arxiv.org/pdf/2311.08485v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08481v1",
            "title": "Functionality learning through specification instructions",
            "updated": "2023-11-14T19:15:55Z",
            "published": "2023-11-14T19:15:55Z",
            "summary": "Test suites assess natural language processing models' performance on\nspecific functionalities: cases of interest involving model robustness,\nfairness, or particular linguistic capabilities. They enable fine-grained\nevaluations of model aspects that would otherwise go unnoticed in standard\nevaluation datasets, but they do not address the problem of how to fix the\nfailure cases. Previous work has explored functionality learning by fine-tuning\nmodels on suite data. While this improves performance on seen functionalities,\nit often does not generalize to unseen ones and can harm general performance.\n  This paper analyses a fine-tuning-free approach to functionality learning.\nFor each functionality in a suite, we generate a specification instruction that\nencodes it. We combine the obtained specification instructions to create\nspecification-augmented prompts, which we feed to language models pre-trained\non natural instruction data to generate suite predictions. A core aspect of our\nanalysis is to measure the effect that including a set of specifications has on\na held-out set of unseen, qualitatively different specifications. Our\nexperiments across four tasks and models ranging from 80M to 175B parameters\nshow that smaller models struggle to follow specification instructions.\nHowever, larger models (> 3B params.) can benefit from specifications and even\ngeneralize desirable behaviors across functionalities.",
            "author": [
                "Pedro Henrique Luz de Araujo",
                "Benjamin Roth"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08481v1",
                "http://arxiv.org/pdf/2311.08481v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08479v1",
            "title": "Leveraging Foundation Models to Improve Lightweight Clients in Federated\n  Learning",
            "updated": "2023-11-14T19:10:56Z",
            "published": "2023-11-14T19:10:56Z",
            "summary": "Federated Learning (FL) is a distributed training paradigm that enables\nclients scattered across the world to cooperatively learn a global model\nwithout divulging confidential data. However, FL faces a significant challenge\nin the form of heterogeneous data distributions among clients, which leads to a\nreduction in performance and robustness. A recent approach to mitigating the\nimpact of heterogeneous data distributions is through the use of foundation\nmodels, which offer better performance at the cost of larger computational\noverheads and slower inference speeds. We introduce foundation model\ndistillation to assist in the federated training of lightweight client models\nand increase their performance under heterogeneous data settings while keeping\ninference costs low. Our results show improvement in the global model\nperformance on a balanced testing set, which contains rarely observed samples,\neven under extreme non-IID client data distributions. We conduct a thorough\nevaluation of our framework with different foundation model backbones on\nCIFAR10, with varying degrees of heterogeneous data distributions ranging from\nclass-specific data partitions across clients to dirichlet data sampling,\nparameterized by values between 0.01 and 1.0.",
            "author": [
                "Xidong Wu",
                "Wan-Yi Lin",
                "Devin Willmott",
                "Filipe Condessa",
                "Yufei Huang",
                "Zhenzhen Li",
                "Madan Ravi Ganesh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08479v1",
                "http://arxiv.org/pdf/2311.08479v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08473v1",
            "title": "Real-time topology optimization via learnable mappings",
            "updated": "2023-11-14T19:04:16Z",
            "published": "2023-11-14T19:04:16Z",
            "summary": "In traditional topology optimization, the computing time required to\niteratively update the material distribution within a design domain strongly\ndepends on the complexity or size of the problem, limiting its application in\nreal engineering contexts. This work proposes a multi-stage machine learning\nstrategy that aims to predict an optimal topology and the related stress fields\nof interest, either in 2D or 3D, without resorting to any iterative analysis\nand design process. The overall topology optimization is treated as regression\ntask in a low-dimensional latent space, that encodes the variability of the\ntarget designs. First, a fully-connected model is employed to surrogate the\nfunctional link between the parametric input space characterizing the design\nproblem and the latent space representation of the corresponding optimal\ntopology. The decoder branch of an autoencoder is then exploited to reconstruct\nthe desired optimal topology from its latent representation. The deep learning\nmodels are trained on a dataset generated through a standard method of topology\noptimization implementing the solid isotropic material with penalization, for\nvarying boundary and loading conditions. The underlying hypothesis behind the\nproposed strategy is that optimal topologies share enough common patterns to be\ncompressed into small latent space representations without significant\ninformation loss. Results relevant to a 2D Messerschmitt-B\\\"olkow-Blohm beam\nand a 3D bridge case demonstrate the capabilities of the proposed framework to\nprovide accurate optimal topology predictions in a fraction of a second.",
            "author": [
                "Gabriel Garayalde",
                "Matteo Torzoni",
                "Matteo Bruggi",
                "Alberto Corigliano"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08473v1",
                "http://arxiv.org/pdf/2311.08473v1"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08472v1",
            "title": "Selecting Shots for Demographic Fairness in Few-Shot Learning with Large\n  Language Models",
            "updated": "2023-11-14T19:02:03Z",
            "published": "2023-11-14T19:02:03Z",
            "summary": "Recently, work in NLP has shifted to few-shot (in-context) learning, with\nlarge language models (LLMs) performing well across a range of tasks. However,\nwhile fairness evaluations have become a standard for supervised methods,\nlittle is known about the fairness of LLMs as prediction systems. Further,\ncommon standard methods for fairness involve access to models weights or are\napplied during finetuning, which are not applicable in few-shot learning. Do\nLLMs exhibit prediction biases when used for standard NLP tasks? In this work,\nwe explore the effect of shots, which directly affect the performance of\nmodels, on the fairness of LLMs as NLP classification systems. We consider how\ndifferent shot selection strategies, both existing and new demographically\nsensitive methods, affect model fairness across three standard fairness\ndatasets. We discuss how future work can include LLM fairness evaluations.",
            "author": [
                "Carlos Aguirre",
                "Kuleen Sasse",
                "Isabel Cachola",
                "Mark Dredze"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08472v1",
                "http://arxiv.org/pdf/2311.08472v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08469v1",
            "title": "UNcommonsense Reasoning: Abductive Reasoning about Uncommon Situations",
            "updated": "2023-11-14T19:00:55Z",
            "published": "2023-11-14T19:00:55Z",
            "summary": "Language technologies that accurately model the dynamics of events must\nperform commonsense reasoning. Existing work evaluating commonsense reasoning\nfocuses on making inferences about common, everyday situations. To instead\ninvestigate the ability to model unusual, unexpected, and unlikely situations,\nwe explore the task of uncommonsense abductive reasoning. Given a piece of\ncontext with an unexpected outcome, this task requires reasoning abductively to\ngenerate a natural language explanation that makes the unexpected outcome more\nlikely in the context. To this end, we curate and release a new English\nlanguage corpus called UNcommonsense. We characterize the differences between\nthe performance of human explainers and the best performing large language\nmodels, finding that model-enhanced human-written explanations achieve the\nhighest quality by trading off between specificity and diversity. Finally, we\nexperiment with several online imitation learning algorithms to train open and\naccessible language models on this task. When compared with the vanilla\nsupervised fine-tuning approach, these methods consistently reduce lose rates\non both common and uncommonsense abductive reasoning judged by human\nevaluators.",
            "author": [
                "Wenting Zhao",
                "Justin T Chiu",
                "Jena D. Hwang",
                "Faeze Brahman",
                "Jack Hessel",
                "Sanjiban Choudhury",
                "Yejin Choi",
                "Xiang Lorraine Li",
                "Alane Suhr"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08469v1",
                "http://arxiv.org/pdf/2311.08469v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08466v1",
            "title": "AGN in overdense environments at high-$z$ with AXIS",
            "updated": "2023-11-14T19:00:25Z",
            "published": "2023-11-14T19:00:25Z",
            "summary": "Overdense regions at high redshift ($z \\gtrsim 2$) are perfect laboratories\nto study the relations between environment and SMBH growth, and the AGN\nfeedback processes on the surrounding galaxies and diffuse gas. In this white\npaper, we discuss how AXIS will 1) constrain the AGN incidence in\nprotoclusters, as a function of parameters such as redshift, overdensity, mass\nof the structure; 2) search for low-luminosity and obscured AGN in the\nsatellite galaxies of luminous QSOs at $z>6$, exploiting the large galaxy\ndensity around such biased objects; 3) probe the AGN feedback on the proto-ICM\nvia the measurement of the AGN contribution to the gas ionization and\nexcitation, and the detection of extended X-ray emission from the ionized gas\nand from radio jets; 4) discover new large-scale structures in the wide and\ndeep AXIS surveys as spikes in the redshift distribution of X-ray sources.\nThese goals can be achieved only with an X-ray mission with the capabilities of\nAXIS, ensuring a strong synergy with current and future state-of-the-art\nfacilities in other wavelengths. This White Paper is part of a series\ncommissioned for the AXIS Probe Concept Mission; additional AXIS White Papers\ncan be found at http://axis.astro.umd.edu/ with a mission overview at\nhttps://arxiv.org/abs/2311.00780.",
            "author": [
                "Fabio Vito",
                "Paolo Tozzi",
                "Roberto Gilli",
                "Stefano Marchesi",
                "Nico Cappelluti",
                "Adi Foord"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08466v1",
                "http://arxiv.org/pdf/2311.08466v1"
            ],
            "primary_category": "astro-ph.IM",
            "category": [
                "astro-ph.IM",
                "astro-ph.CO",
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08458v1",
            "title": "Prospects for AGN Studies with AXIS: AGN Fueling -- Resolving Hot Gas\n  inside Bondi Radius of SMBHs",
            "updated": "2023-11-14T19:00:03Z",
            "published": "2023-11-14T19:00:03Z",
            "summary": "Hot gas around a supermassive black hole (SMBH) should be captured within the\ngravitational \"sphere of influence\", characterized by the Bondi radius. Deep\nChandra observations have spatially resolved the Bondi radii of at least five\nnearby SMBHs. Contrary to earlier hot accretion models that predicted a steep\ntemperature increase within the Bondi radius, none of the resolved temperature\nprofiles exhibit such an increase. The temperature inside the Bondi radius\nappears to be complex, indicative of a multi-temperature phase of hot gas with\na cooler component at about 0.2-0.3 keV. The density profiles within the Bondi\nregions are shallow, suggesting the presence of strong outflows. These findings\nmight be explained by recent realistic numerical simulations that suggest that\nlarge-scale accretion inside the Bondi radius can be chaotic, with cooler gas\nraining down in some directions and hotter gas outflowing in others. With an\nangular resolution similar to Chandra and a significantly larger collecting\narea, AXIS will collect enough photons to map the emerging accretion flow\nwithin and around the \"sphere of influence\" of a sample of active galactic\nnuclei (AGNs). AXIS will reveal transitions in the inflow that ultimately fuels\nthe AGN, as well as outflows that provide feedback to the environment.",
            "author": [
                "Ka-Wah Wong",
                "Helen Russell",
                "Jimmy Irwin",
                "Nico Cappelluti",
                "Adi Foord"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08458v1",
                "http://arxiv.org/pdf/2311.08458v1"
            ],
            "primary_category": "astro-ph.HE",
            "category": [
                "astro-ph.HE",
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08460v1",
            "title": "Surrogate Modeling for Computationally Expensive Simulations of\n  Supernovae in High-Resolution Galaxy Simulations",
            "updated": "2023-11-14T19:00:03Z",
            "published": "2023-11-14T19:00:03Z",
            "summary": "Some stars are known to explode at the end of their lives, called supernovae\n(SNe). The substantial amount of matter and energy that SNe release provides\nsignificant feedback to star formation and gas dynamics in a galaxy. SNe\nrelease a substantial amount of matter and energy to the interstellar medium,\nresulting in significant feedback to star formation and gas dynamics in a\ngalaxy. While such feedback has a crucial role in galaxy formation and\nevolution, in simulations of galaxy formation, it has only been implemented\nusing simple {\\it sub-grid models} instead of numerically solving the evolution\nof gas elements around SNe in detail due to a lack of resolution. We develop a\nmethod combining machine learning and Gibbs sampling to predict how a supernova\n(SN) affects the surrounding gas. The fidelity of our model in the thermal\nenergy and momentum distribution outperforms the low-resolution SN simulations.\nOur method can replace the SN sub-grid models and help properly simulate\nun-resolved SN feedback in galaxy formation simulations. We find that employing\nour new approach reduces the necessary computational cost to $\\sim$ 1 percent\ncompared to directly resolving SN feedback.",
            "author": [
                "Keiya Hirashima",
                "Kana Moriwaki",
                "Michiko S. Fujii",
                "Yutaka Hirai",
                "Takayuki R. Saitoh",
                "Junichiro Makino",
                "Shirley Ho"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08460v1",
                "http://arxiv.org/pdf/2311.08460v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08452v1",
            "title": "Aligned Grains and Scattered Light Found in Gaps of Planet-Forming Disk",
            "updated": "2023-11-14T19:00:01Z",
            "published": "2023-11-14T19:00:01Z",
            "summary": "Polarized (sub)millimeter emission from dust grains in circumstellar disks\nwas initially thought to be due to grains aligned with the magnetic field.\nHowever, higher resolution multi-wavelength observations along with improved\nmodels found that this polarization is dominated by self-scattering at shorter\nwavelengths (e.g., 870 $\\mu$m) and by grains aligned with something other than\nmagnetic fields at longer wavelengths (e.g., 3 mm). Nevertheless, the\npolarization signal is expected to depend on the underlying substructure, and\nobservations hitherto have been unable to resolve polarization in multiple\nrings and gaps. HL Tau, a protoplanetary disk located 147.3 $\\pm$ 0.5 pc away,\nis the brightest Class I or Class II disk at millimeter/submillimeter\nwavelengths. Here we show deep, high-resolution 870 $\\mu$m polarization\nobservations of HL Tau, resolving polarization in both the rings and gaps. We\nfind that the gaps have polarization angles with a significant azimuthal\ncomponent and a higher polarization fraction than the rings. Our models show\nthat the disk polarization is due to both scattering and emission from aligned\neffectively prolate grains. The intrinsic polarization of aligned dust grains\nis likely over 10%, which is much higher than what was expected in low\nresolution observations (~1%). Asymmetries and dust features are revealed in\nthe polarization observations that are not seen in non-polarimetric\nobservations.",
            "author": [
                "Ian W. Stephens",
                "Zhe-Yu Daniel Lin",
                "Manuel Fernandez-Lopez",
                "Zhi-Yun Li",
                "Leslie W. Looney",
                "Haifeng Yang",
                "Rachel Harrison",
                "Akimasa Kataoka",
                "Carlos Carrasco-Gonzalez",
                "Satoshi Okuzumi",
                "Ryo Tazaki"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08452v1",
                "http://arxiv.org/pdf/2311.08452v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA",
                "astro-ph.SR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08447v1",
            "title": "An analysis of parton distributions in a pion with B\u00e9zier\n  parametrizations",
            "updated": "2023-11-14T19:00:00Z",
            "published": "2023-11-14T19:00:00Z",
            "summary": "We explore the role of parametrizations for nonperturbative QCD functions in\nglobal analyses, with a specific application to extending a phenomenological\nanalysis of the parton distribution functions (PDFs) in the charged pion\nrealized in the xFitter fitting framework. The parametrization dependence of\nPDFs in our pion fits substantially enlarges the uncertainties from the\nexperimental sources estimated in the previous analyses. We systematically\nexplore the parametrization dependence by employing a novel technique to\nautomate generation of polynomial parametrizations for PDFs that makes use of\nB\\'ezier curves. This technique is implemented in a C++ module Fant\\^omas that\nis included in the xFitter program. Our analysis reveals that the sea and gluon\ndistributions in the pion are not well disentangled, even when considering\nmeasurements in leading-neutron deep inelastic scattering. For example, the\npion PDF solutions with a vanishing gluon and large quark sea are still\nexperimentally allowed, which elevates the importance of ongoing lattice and\nnonperturbative QCD calculations, together with the planned pion scattering\nexperiments, for conclusive studies of the pion structure.",
            "author": [
                "Lucas Kotz",
                "Aurore Courtoy",
                "Pavel Nadolsky",
                "Fredrick Olness",
                "Maximiliano Ponce-Chavez"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08447v1",
                "http://arxiv.org/pdf/2311.08447v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08448v1",
            "title": "Detecting Wandering Intermediate-Mass Black Holes with AXIS in the Milky\n  Way and Local Massive Galaxies",
            "updated": "2023-11-14T19:00:00Z",
            "published": "2023-11-14T19:00:00Z",
            "summary": "This white paper explores the detectability of intermediate-mass black holes\n(IMBHs) wandering in the Milky Way (MW) and massive local galaxies, with a\nparticular emphasis on the role of AXIS. IMBHs, ranging within $10^{3-6} \\,\nM_\\odot$, are commonly found at the centers of dwarf galaxies and may exist,\nyet undiscovered, in the MW. By using model spectra for advection-dominated\naccretion flows (ADAFs), we calculated the expected fluxes emitted by a\npopulation of wandering IMBHs with a mass of $10^5 \\, M_\\odot$ in various MW\nenvironments and extrapolated our results to massive local galaxies. Around\n$40\\%$ of the potential population of wandering IMBHs in the MW can be detected\nin an AXIS deep field. We proposed criteria to aid in selecting IMBH candidates\nusing already available optical surveys. We also showed that IMBHs wandering in\n$>200$ galaxies within $10$ Mpc can be easily detected with AXIS when passing\nwithin dense galactic environments (e.g., molecular clouds and cold neutral\nmedium). In summary, we highlighted the potential X-ray detectability of\nwandering IMBHs in local galaxies and provided insights for guiding future\nsurveys. Detecting wandering IMBHs is crucial for understanding their\ndemographics, evolution, and the merging history of galaxies.",
            "author": [
                "Fabio Pacucci",
                "Bryan Seepaul",
                "Yueying Ni",
                "Nico Cappelluti",
                "Adi Foord"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08448v1",
                "http://arxiv.org/pdf/2311.08448v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA",
                "astro-ph.CO",
                "astro-ph.HE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08449v1",
            "title": "X-ray Redshift for obscured AGN with AXIS deep and intermediate surveys",
            "updated": "2023-11-14T19:00:00Z",
            "published": "2023-11-14T19:00:00Z",
            "summary": "This study presents the capabilities of the AXIS telescope in estimating\nredshifts from X-ray spectra alone (X-ray redshifts, XZs). Through extensive\nsimulations, we establish that AXIS observations enable reliable XZ estimates\nfor more than 5500 obscured Active Galactic Nuclei (AGN) up to redshift $z\\sim\n6$ in the proposed deep (7 Ms) and intermediate (375 ks) surveys. Notably, at\nleast 1600 of them are expected to be in the Compton-Thick regime ($\\log\nN_H/\\mathrm{cm^{-2}}\\geq 24$), underscoring the pivotal role of AXIS in sample\nthese elusive objects that continue to be poorly understood. XZs provide an\nefficient alternative for optical/infrared faint sources, overcoming the need\nfor time-consuming spectroscopy, potential limitations of photometric\nredshifts, and potential issues related to multi-band counterpart association.\nThis approach will significantly enhance the accuracy of constraints on the\nX-ray luminosity function and obscured AGN fractions up to high redshift. This\nWhite Paper is part of a series commissioned for the AXIS Probe Concept\nMission; additional AXIS White Papers can be found at the AXIS website\n(http://axis.astro.umd.edu) with a mission overview here: arXiv:2311.00780.",
            "author": [
                "Alessandro Peca",
                "Nico Cappelluti",
                "Stefano Marchesi",
                "Edmund Hodges-Kluck",
                "Adi Foord"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08449v1",
                "http://arxiv.org/pdf/2311.08449v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA",
                "astro-ph.HE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08403v1",
            "title": "Instant3D: Instant Text-to-3D Generation",
            "updated": "2023-11-14T18:59:59Z",
            "published": "2023-11-14T18:59:59Z",
            "summary": "Text-to-3D generation, which aims to synthesize vivid 3D objects from text\nprompts, has attracted much attention from the computer vision community. While\nseveral existing works have achieved impressive results for this task, they\nmainly rely on a time-consuming optimization paradigm. Specifically, these\nmethods optimize a neural field from scratch for each text prompt, taking\napproximately one hour or more to generate one object. This heavy and\nrepetitive training cost impedes their practical deployment. In this paper, we\npropose a novel framework for fast text-to-3D generation, dubbed Instant3D.\nOnce trained, Instant3D is able to create a 3D object for an unseen text prompt\nin less than one second with a single run of a feedforward network. We achieve\nthis remarkable speed by devising a new network that directly constructs a 3D\ntriplane from a text prompt. The core innovation of our Instant3D lies in our\nexploration of strategies to effectively inject text conditions into the\nnetwork. Furthermore, we propose a simple yet effective activation function,\nthe scaled-sigmoid, to replace the original sigmoid function, which speeds up\nthe training convergence by more than ten times. Finally, to address the Janus\n(multi-head) problem in 3D generation, we propose an adaptive Perp-Neg\nalgorithm that can dynamically adjust its concept negation scales according to\nthe severity of the Janus problem during training, effectively reducing the\nmulti-head effect. Extensive experiments on a wide variety of benchmark\ndatasets demonstrate that the proposed algorithm performs favorably against the\nstate-of-the-art methods both qualitatively and quantitatively, while achieving\nsignificantly better efficiency. The project page is at\nhttps://ming1993li.github.io/Instant3DProj.",
            "author": [
                "Ming Li",
                "Pan Zhou",
                "Jia-Wei Liu",
                "Jussi Keppo",
                "Min Lin",
                "Shuicheng Yan",
                "Xiangyu Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08403v1",
                "http://arxiv.org/pdf/2311.08403v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.GR",
                "cs.LG",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08401v1",
            "title": "Fine-tuning Language Models for Factuality",
            "updated": "2023-11-14T18:59:15Z",
            "published": "2023-11-14T18:59:15Z",
            "summary": "The fluency and creativity of large pre-trained language models (LLMs) have\nled to their widespread use, sometimes even as a replacement for traditional\nsearch engines. Yet language models are prone to making convincing but\nfactually inaccurate claims, often referred to as 'hallucinations.' These\nerrors can inadvertently spread misinformation or harmfully perpetuate\nmisconceptions. Further, manual fact-checking of model responses is a\ntime-consuming process, making human factuality labels expensive to acquire. In\nthis work, we fine-tune language models to be more factual, without human\nlabeling and targeting more open-ended generation settings than past work. We\nleverage two key recent innovations in NLP to do so. First, several recent\nworks have proposed methods for judging the factuality of open-ended text by\nmeasuring consistency with an external knowledge base or simply a large model's\nconfidence scores. Second, the direct preference optimization algorithm enables\nstraightforward fine-tuning of language models on objectives other than\nsupervised imitation, using a preference ranking over possible model responses.\nWe show that learning from automatically generated factuality preference\nrankings, generated either through existing retrieval systems or our novel\nretrieval-free approach, significantly improves the factuality (percent of\ngenerated claims that are correct) of Llama-2 on held-out topics compared with\nRLHF or decoding strategies targeted at factuality. At 7B scale, compared to\nLlama-2-chat, we observe 58% and 40% reduction in factual error rate when\ngenerating biographies and answering medical questions, respectively.",
            "author": [
                "Katherine Tian",
                "Eric Mitchell",
                "Huaxiu Yao",
                "Christopher D. Manning",
                "Chelsea Finn"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08401v1",
                "http://arxiv.org/pdf/2311.08401v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08398v2",
            "title": "Are Large Language Models Temporally Grounded?",
            "updated": "2023-11-16T09:41:28Z",
            "published": "2023-11-14T18:57:15Z",
            "summary": "Are Large language models (LLMs) temporally grounded? Since LLMs cannot\nperceive and interact with the environment, it is impossible to answer this\nquestion directly. Instead, we provide LLMs with textual narratives and probe\nthem with respect to their common-sense knowledge of the structure and duration\nof events, their ability to order events along a timeline, and self-consistency\nwithin their temporal model (e.g., temporal relations such as after and before\nare mutually exclusive for any pair of events). We evaluate state-of-the-art\nLLMs (such as LLaMA 2 and GPT-4) on three tasks reflecting these abilities.\nGenerally, we find that LLMs lag significantly behind both human performance as\nwell as small-scale, specialised LMs. In-context learning, instruction tuning,\nand chain-of-thought prompting reduce this gap only to a limited degree.\nCrucially, LLMs struggle the most with self-consistency, displaying incoherent\nbehaviour in at least 27.23% of their predictions. Contrary to expectations, we\nalso find that scaling the model size does not guarantee positive gains in\nperformance. To explain these results, we study the sources from which LLMs may\ngather temporal information: we find that sentence ordering in unlabelled\ntexts, available during pre-training, is only weakly correlated with event\nordering. Moreover, public instruction tuning mixtures contain few temporal\ntasks. Hence, we conclude that current LLMs lack a consistent temporal model of\ntextual narratives. Code, datasets, and LLM outputs are available at\nhttps://github.com/yfqiu-nlp/temporal-llms.",
            "author": [
                "Yifu Qiu",
                "Zheng Zhao",
                "Yftah Ziser",
                "Anna Korhonen",
                "Edoardo M. Ponti",
                "Shay B. Cohen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08398v2",
                "http://arxiv.org/pdf/2311.08398v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08396v1",
            "title": "Zero-shot audio captioning with audio-language model guidance and audio\n  context keywords",
            "updated": "2023-11-14T18:55:48Z",
            "published": "2023-11-14T18:55:48Z",
            "summary": "Zero-shot audio captioning aims at automatically generating descriptive\ntextual captions for audio content without prior training for this task.\nDifferent from speech recognition which translates audio content that contains\nspoken language into text, audio captioning is commonly concerned with ambient\nsounds, or sounds produced by a human performing an action. Inspired by\nzero-shot image captioning methods, we propose ZerAuCap, a novel framework for\nsummarising such general audio signals in a text caption without requiring\ntask-specific training. In particular, our framework exploits a pre-trained\nlarge language model (LLM) for generating the text which is guided by a\npre-trained audio-language model to produce captions that describe the audio\ncontent. Additionally, we use audio context keywords that prompt the language\nmodel to generate text that is broadly relevant to sounds. Our proposed\nframework achieves state-of-the-art results in zero-shot audio captioning on\nthe AudioCaps and Clotho datasets. Our code is available at\nhttps://github.com/ExplainableML/ZerAuCap.",
            "author": [
                "Leonard Salewski",
                "Stefan Fauth",
                "A. Sophia Koepke",
                "Zeynep Akata"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08396v1",
                "http://arxiv.org/pdf/2311.08396v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.AI",
                "cs.CL",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08393v2",
            "title": "MVSA-Net: Multi-View State-Action Recognition for Robust and Deployable\n  Trajectory Generation",
            "updated": "2023-11-18T21:51:33Z",
            "published": "2023-11-14T18:53:28Z",
            "summary": "The learn-from-observation (LfO) paradigm is a human-inspired mode for a\nrobot to learn to perform a task simply by watching it being performed. LfO can\nfacilitate robot integration on factory floors by minimizing disruption and\nreducing tedious programming. A key component of the LfO pipeline is a\ntransformation of the depth camera frames to the corresponding task state and\naction pairs, which are then relayed to learning techniques such as imitation\nor inverse reinforcement learning for understanding the task parameters. While\nseveral existing computer vision models analyze videos for activity\nrecognition, SA-Net specifically targets robotic LfO from RGB-D data. However,\nSA-Net and many other models analyze frame data captured from a single\nviewpoint. Their analysis is therefore highly sensitive to occlusions of the\nobserved task, which are frequent in deployments. An obvious way of reducing\nocclusions is to simultaneously observe the task from multiple viewpoints and\nsynchronously fuse the multiple streams in the model. Toward this, we present\nmulti-view SA-Net, which generalizes the SA-Net model to allow the perception\nof multiple viewpoints of the task activity, integrate them, and better\nrecognize the state and action in each frame. Performance evaluations on two\ndistinct domains establish that MVSA-Net recognizes the state-action pairs\nunder occlusion more accurately compared to single-view MVSA-Net and other\nbaselines. Our ablation studies further evaluate its performance under\ndifferent ambient conditions and establish the contribution of the architecture\ncomponents. As such, MVSA-Net offers a significantly more robust and deployable\nstate-action trajectory generation compared to previous methods.",
            "author": [
                "Ehsan Asali",
                "Prashant Doshi",
                "Jin Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08393v2",
                "http://arxiv.org/pdf/2311.08393v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08384v1",
            "title": "Offline Data Enhanced On-Policy Policy Gradient with Provable Guarantees",
            "updated": "2023-11-14T18:45:56Z",
            "published": "2023-11-14T18:45:56Z",
            "summary": "Hybrid RL is the setting where an RL agent has access to both offline data\nand online data by interacting with the real-world environment. In this work,\nwe propose a new hybrid RL algorithm that combines an on-policy actor-critic\nmethod with offline data. On-policy methods such as policy gradient and natural\npolicy gradient (NPG) have shown to be more robust to model misspecification,\nthough sometimes it may not be as sample efficient as methods that rely on\noff-policy learning. On the other hand, offline methods that depend on\noff-policy training often require strong assumptions in theory and are less\nstable to train in practice. Our new approach integrates a procedure of\noff-policy training on the offline data into an on-policy NPG framework. We\nshow that our approach, in theory, can obtain a best-of-both-worlds type of\nresult -- it achieves the state-of-art theoretical guarantees of offline RL\nwhen offline RL-specific assumptions hold, while at the same time maintaining\nthe theoretical guarantees of on-policy NPG regardless of the offline RL\nassumptions' validity. Experimentally, in challenging rich-observation\nenvironments, we show that our approach outperforms a state-of-the-art hybrid\nRL baseline which only relies on off-policy policy optimization, demonstrating\nthe empirical benefit of combining on-policy and off-policy learning. Our code\nis publicly available at https://github.com/YifeiZhou02/HNPG.",
            "author": [
                "Yifei Zhou",
                "Ayush Sekhari",
                "Yuda Song",
                "Wen Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08384v1",
                "http://arxiv.org/pdf/2311.08384v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08380v1",
            "title": "Direct Preference Optimization for Neural Machine Translation with\n  Minimum Bayes Risk Decoding",
            "updated": "2023-11-14T18:43:51Z",
            "published": "2023-11-14T18:43:51Z",
            "summary": "Minimum Bayes Risk (MBR) decoding can significantly improve translation\nperformance of Multilingual Large Language Models (MLLMs). However, MBR\ndecoding is computationally expensive and in this paper, we show how recently\ndeveloped Reinforcement Learning (RL) technique, Direct Preference Optimization\n(DPO) can be used to fine-tune MLLMs so that we get the gains from MBR without\nthe additional computation in inference. Our fine-tuned models have\nsignificantly improved performance on multiple NMT test sets compared to base\nMLLMs without preference optimization. Our method boosts the translation\nperformance of MLLMs using relatively small monolingual fine-tuning sets.",
            "author": [
                "Guangyu Yang",
                "Jinghong Chen",
                "Weizhe Lin",
                "Bill Byrne"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08380v1",
                "http://arxiv.org/pdf/2311.08380v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08445v1",
            "title": "Lecture notes on quantum computing",
            "updated": "2023-11-14T18:42:55Z",
            "published": "2023-11-14T18:42:55Z",
            "summary": "These are the lecture notes of the master's course \"Quantum Computing\",\ntaught at Chalmers University of Technology every fall since 2020, with\nparticipation of students from RWTH Aachen and Delft University of Technology.\nThe aim of this course is to provide a theoretical overview of quantum\ncomputing, excluding specific hardware implementations. Topics covered in these\nnotes include quantum algorithms (such as Grover's algorithm, the quantum\nFourier transform, phase estimation, and Shor's algorithm), variational quantum\nalgorithms that utilise an interplay between classical and quantum computers\n[such as the variational quantum eigensolver (VQE) and the quantum approximate\noptimisation algorithm (QAOA), among others], quantum error correction, various\nversions of quantum computing (such as measurement-based quantum computation,\nadiabatic quantum computation, and the continuous-variable approach to quantum\ninformation), the intersection of quantum computing and machine learning, and\nquantum complexity theory. Lectures on these topics are compiled into 12\nchapters, most of which contain a few suggested exercises at the end, and\ninterspersed with four tutorials, which provide practical exercises as well as\nfurther details. At Chalmers, the course is taught in seven weeks, with three\ntwo-hour lectures or tutorials per week. It is recommended that the students\ntaking the course have some previous experience with quantum physics, but not\nstrictly necessary.",
            "author": [
                "Anton Frisk Kockum",
                "Ariadna Soro",
                "Laura Garc\u00eda-\u00c1lvarez",
                "Pontus Vikst\u00e5l",
                "Tom Douce",
                "G\u00f6ran Johansson",
                "Giulia Ferrini"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08445v1",
                "http://arxiv.org/pdf/2311.08445v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08379v3",
            "title": "Scheming AIs: Will AIs fake alignment during training in order to get\n  power?",
            "updated": "2023-11-27T19:30:35Z",
            "published": "2023-11-14T18:42:40Z",
            "summary": "This report examines whether advanced AIs that perform well in training will\nbe doing so in order to gain power later -- a behavior I call \"scheming\" (also\nsometimes called \"deceptive alignment\"). I conclude that scheming is a\ndisturbingly plausible outcome of using baseline machine learning methods to\ntrain goal-directed AIs sophisticated enough to scheme (my subjective\nprobability on such an outcome, given these conditions, is roughly 25%). In\nparticular: if performing well in training is a good strategy for gaining power\n(as I think it might well be), then a very wide variety of goals would motivate\nscheming -- and hence, good training performance. This makes it plausible that\ntraining might either land on such a goal naturally and then reinforce it, or\nactively push a model's motivations towards such a goal as an easy way of\nimproving performance. What's more, because schemers pretend to be aligned on\ntests designed to reveal their motivations, it may be quite difficult to tell\nwhether this has occurred. However, I also think there are reasons for comfort.\nIn particular: scheming may not actually be such a good strategy for gaining\npower; various selection pressures in training might work against schemer-like\ngoals (for example, relative to non-schemers, schemers need to engage in extra\ninstrumental reasoning, which might harm their training performance); and we\nmay be able to increase such pressures intentionally. The report discusses\nthese and a wide variety of other considerations in detail, and it suggests an\narray of empirical research directions for probing the topic further.",
            "author": [
                "Joe Carlsmith"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08379v3",
                "http://arxiv.org/pdf/2311.08379v3"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08377v1",
            "title": "Learning to Filter Context for Retrieval-Augmented Generation",
            "updated": "2023-11-14T18:41:54Z",
            "published": "2023-11-14T18:41:54Z",
            "summary": "On-the-fly retrieval of relevant knowledge has proven an essential element of\nreliable systems for tasks such as open-domain question answering and fact\nverification. However, because retrieval systems are not perfect, generation\nmodels are required to generate outputs given partially or entirely irrelevant\npassages. This can cause over- or under-reliance on context, and result in\nproblems in the generated output such as hallucinations. To alleviate these\nproblems, we propose FILCO, a method that improves the quality of the context\nprovided to the generator by (1) identifying useful context based on lexical\nand information-theoretic approaches, and (2) training context filtering models\nthat can filter retrieved contexts at test time. We experiment on six\nknowledge-intensive tasks with FLAN-T5 and LLaMa2, and demonstrate that our\nmethod outperforms existing approaches on extractive question answering (QA),\ncomplex multi-hop and long-form QA, fact verification, and dialog generation\ntasks. FILCO effectively improves the quality of context, whether or not it\nsupports the canonical output.",
            "author": [
                "Zhiruo Wang",
                "Jun Araki",
                "Zhengbao Jiang",
                "Md Rizwan Parvez",
                "Graham Neubig"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08377v1",
                "http://arxiv.org/pdf/2311.08377v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08376v1",
            "title": "Ensemble sampling for linear bandits: small ensembles suffice",
            "updated": "2023-11-14T18:41:28Z",
            "published": "2023-11-14T18:41:28Z",
            "summary": "We provide the first useful, rigorous analysis of ensemble sampling for the\nstochastic linear bandit setting. In particular, we show that, under standard\nassumptions, for a $d$-dimensional stochastic linear bandit with an interaction\nhorizon $T$, ensemble sampling with an ensemble of size $m$ on the order of $d\n\\log T$ incurs regret bounded by order $(d \\log T)^{5/2} \\sqrt{T}$. Ours is the\nfirst result in any structured setting not to require the size of the ensemble\nto scale linearly with $T$ -- which defeats the purpose of ensemble sampling --\nwhile obtaining near $\\sqrt{T}$ order regret. Ours is also the first result\nthat allows infinite action sets.",
            "author": [
                "David Janz",
                "Alexander E. Litvak",
                "Csaba Szepesv\u00e1ri"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08376v1",
                "http://arxiv.org/pdf/2311.08376v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08371v1",
            "title": "USLR: an open-source tool for unbiased and smooth longitudinal\n  registration of brain MR",
            "updated": "2023-11-14T18:34:18Z",
            "published": "2023-11-14T18:34:18Z",
            "summary": "We present USLR, a computational framework for longitudinal registration of\nbrain MRI scans to estimate nonlinear image trajectories that are smooth across\ntime, unbiased to any timepoint, and robust to imaging artefacts. It operates\non the Lie algebra parameterisation of spatial transforms (which is compatible\nwith rigid transforms and stationary velocity fields for nonlinear deformation)\nand takes advantage of log-domain properties to solve the problem using\nBayesian inference. USRL estimates rigid and nonlinear registrations that: (i)\nbring all timepoints to an unbiased subject-specific space; and (i) compute a\nsmooth trajectory across the imaging time-series. We capitalise on\nlearning-based registration algorithms and closed-form expressions for fast\ninference. A use-case Alzheimer's disease study is used to showcase the\nbenefits of the pipeline in multiple fronts, such as time-consistent image\nsegmentation to reduce intra-subject variability, subject-specific prediction\nor population analysis using tensor-based morphometry. We demonstrate that such\napproach improves upon cross-sectional methods in identifying group\ndifferences, which can be helpful in detecting more subtle atrophy levels or in\nreducing sample sizes in clinical trials. The code is publicly available in\nhttps://github.com/acasamitjana/uslr",
            "author": [
                "Adri\u00e0 Casamitjana",
                "Roser Sala-Llonch",
                "Karim Lekadir",
                "Juan Eugenio Iglesias"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08371v1",
                "http://arxiv.org/pdf/2311.08371v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.09253v1",
            "title": "The Perception-Robustness Tradeoff in Deterministic Image Restoration",
            "updated": "2023-11-14T18:30:34Z",
            "published": "2023-11-14T18:30:34Z",
            "summary": "We study the behavior of deterministic methods for solving inverse problems\nin imaging. These methods are commonly designed to achieve two goals: (1)\nattaining high perceptual quality, and (2) generating reconstructions that are\nconsistent with the measurements. We provide a rigorous proof that the better a\npredictor satisfies these two requirements, the larger its Lipschitz constant\nmust be, regardless of the nature of the degradation involved. In particular,\nto approach perfect perceptual quality and perfect consistency, the Lipschitz\nconstant of the model must grow to infinity. This implies that such methods are\nnecessarily more susceptible to adversarial attacks. We demonstrate our theory\non single image super-resolution algorithms, addressing both noisy and\nnoiseless settings. We also show how this undesired behavior can be leveraged\nto explore the posterior distribution, thereby allowing the deterministic model\nto imitate stochastic methods.",
            "author": [
                "Guy Ohayon",
                "Tomer Michaeli",
                "Michael Elad"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09253v1",
                "http://arxiv.org/pdf/2311.09253v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08364v1",
            "title": "Plum: Prompt Learning using Metaheuristic",
            "updated": "2023-11-14T18:14:56Z",
            "published": "2023-11-14T18:14:56Z",
            "summary": "Since the emergence of large language models, prompt learning has become a\npopular method for optimizing and customizing these models. Special prompts,\nsuch as Chain-of-Thought, have even revealed previously unknown reasoning\ncapabilities within these models. However, the progress of discovering\neffective prompts has been slow, driving a desire for general prompt\noptimization methods. Unfortunately, few existing prompt learning methods\nsatisfy the criteria of being truly \"general\", i.e., automatic, discrete,\nblack-box, gradient-free, and interpretable all at once. In this paper, we\nintroduce metaheuristics, a branch of discrete non-convex optimization methods\nwith over 100 options, as a promising approach to prompt learning. Within our\nparadigm, we test six typical methods: hill climbing, simulated annealing,\ngenetic algorithms with/without crossover, tabu search, and harmony search,\ndemonstrating their effectiveness in black-box prompt learning and\nChain-of-Thought prompt tuning. Furthermore, we show that these methods can be\nused to discover more human-understandable prompts that were previously\nunknown, opening the door to a cornucopia of possibilities in prompt\noptimization. We release all the codes in\n\\url{https://github.com/research4pan/Plum}.",
            "author": [
                "Rui Pan",
                "Shuo Xing",
                "Shizhe Diao",
                "Xiang Liu",
                "Kashun Shum",
                "Jipeng Zhang",
                "Tong Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08364v1",
                "http://arxiv.org/pdf/2311.08364v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.DM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08362v1",
            "title": "Transformers can optimally learn regression mixture models",
            "updated": "2023-11-14T18:09:15Z",
            "published": "2023-11-14T18:09:15Z",
            "summary": "Mixture models arise in many regression problems, but most methods have seen\nlimited adoption partly due to these algorithms' highly-tailored and\nmodel-specific nature. On the other hand, transformers are flexible, neural\nsequence models that present the intriguing possibility of providing\ngeneral-purpose prediction methods, even in this mixture setting. In this work,\nwe investigate the hypothesis that transformers can learn an optimal predictor\nfor mixtures of regressions. We construct a generative process for a mixture of\nlinear regressions for which the decision-theoretic optimal procedure is given\nby data-driven exponential weights on a finite set of parameters. We observe\nthat transformers achieve low mean-squared error on data generated via this\nprocess. By probing the transformer's output at inference time, we also show\nthat transformers typically make predictions that are close to the optimal\npredictor. Our experiments also demonstrate that transformers can learn\nmixtures of regressions in a sample-efficient fashion and are somewhat robust\nto distribution shifts. We complement our experimental observations by proving\nconstructively that the decision-theoretic optimal procedure is indeed\nimplementable by a transformer.",
            "author": [
                "Reese Pathak",
                "Rajat Sen",
                "Weihao Kong",
                "Abhimanyu Das"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08362v1",
                "http://arxiv.org/pdf/2311.08362v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08360v2",
            "title": "The Transient Nature of Emergent In-Context Learning in Transformers",
            "updated": "2023-11-15T04:02:44Z",
            "published": "2023-11-14T18:03:20Z",
            "summary": "Transformer neural networks can exhibit a surprising capacity for in-context\nlearning (ICL) despite not being explicitly trained for it. Prior work has\nprovided a deeper understanding of how ICL emerges in transformers, e.g.\nthrough the lens of mechanistic interpretability, Bayesian inference, or by\nexamining the distributional properties of training data. However, in each of\nthese cases, ICL is treated largely as a persistent phenomenon; namely, once\nICL emerges, it is assumed to persist asymptotically. Here, we show that the\nemergence of ICL during transformer training is, in fact, often transient. We\ntrain transformers on synthetic data designed so that both ICL and in-weights\nlearning (IWL) strategies can lead to correct predictions. We find that ICL\nfirst emerges, then disappears and gives way to IWL, all while the training\nloss decreases, indicating an asymptotic preference for IWL. The transient\nnature of ICL is observed in transformers across a range of model sizes and\ndatasets, raising the question of how much to \"overtrain\" transformers when\nseeking compact, cheaper-to-run models. We find that L2 regularization may\noffer a path to more persistent ICL that removes the need for early stopping\nbased on ICL-style validation tasks. Finally, we present initial evidence that\nICL transience may be caused by competition between ICL and IWL circuits.",
            "author": [
                "Aaditya K. Singh",
                "Stephanie C. Y. Chan",
                "Ted Moskovitz",
                "Erin Grant",
                "Andrew M. Saxe",
                "Felix Hill"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08360v2",
                "http://arxiv.org/pdf/2311.08360v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08359v1",
            "title": "Rotation-Agnostic Image Representation Learning for Digital Pathology",
            "updated": "2023-11-14T18:01:15Z",
            "published": "2023-11-14T18:01:15Z",
            "summary": "This paper addresses complex challenges in histopathological image analysis\nthrough three key contributions. Firstly, it introduces a fast patch selection\nmethod, FPS, for whole-slide image (WSI) analysis, significantly reducing\ncomputational cost while maintaining accuracy. Secondly, it presents PathDino,\na lightweight histopathology feature extractor with a minimal configuration of\nfive Transformer blocks and only 9 million parameters, markedly fewer than\nalternatives. Thirdly, it introduces a rotation-agnostic representation\nlearning paradigm using self-supervised learning, effectively mitigating\noverfitting. We also show that our compact model outperforms existing\nstate-of-the-art histopathology-specific vision transformers on 12 diverse\ndatasets, including both internal datasets spanning four sites (breast, liver,\nskin, and colorectal) and seven public datasets (PANDA, CAMELYON16, BRACS,\nDigestPath, Kather, PanNuke, and WSSS4LUAD). Notably, even with a training\ndataset of 6 million histopathology patches from The Cancer Genome Atlas\n(TCGA), our approach demonstrates an average 8.5% improvement in patch-level\nmajority vote performance. These contributions provide a robust framework for\nenhancing image analysis in digital pathology, rigorously validated through\nextensive evaluation. Project Page: https://rhazeslab.github.io/PathDino-Page/",
            "author": [
                "Saghir Alfasly",
                "Abubakr Shafique",
                "Peyman Nejat",
                "Jibran Khan",
                "Areej Alsaafin",
                "Ghazal Alabtah",
                "H. R. Tizhoosh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08359v1",
                "http://arxiv.org/pdf/2311.08359v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08357v1",
            "title": "Sparsity-Preserving Differentially Private Training of Large Embedding\n  Models",
            "updated": "2023-11-14T17:59:51Z",
            "published": "2023-11-14T17:59:51Z",
            "summary": "As the use of large embedding models in recommendation systems and language\napplications increases, concerns over user data privacy have also risen.\nDP-SGD, a training algorithm that combines differential privacy with stochastic\ngradient descent, has been the workhorse in protecting user privacy without\ncompromising model accuracy by much. However, applying DP-SGD naively to\nembedding models can destroy gradient sparsity, leading to reduced training\nefficiency. To address this issue, we present two new algorithms, DP-FEST and\nDP-AdaFEST, that preserve gradient sparsity during private training of large\nembedding models. Our algorithms achieve substantial reductions ($10^6 \\times$)\nin gradient size, while maintaining comparable levels of accuracy, on benchmark\nreal-world datasets.",
            "author": [
                "Badih Ghazi",
                "Yangsibo Huang",
                "Pritish Kamath",
                "Ravi Kumar",
                "Pasin Manurangsi",
                "Amer Sinha",
                "Chiyuan Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08357v1",
                "http://arxiv.org/pdf/2311.08357v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08345v1",
            "title": "Speeding Up Optimization-based Motion Planning through Deep Learning",
            "updated": "2023-11-14T17:42:01Z",
            "published": "2023-11-14T17:42:01Z",
            "summary": "Planning collision-free motions for robots with many degrees of freedom is\nchallenging in environments with complex obstacle geometries. Recent work\nintroduced the idea of speeding up the planning by encoding prior experience of\nsuccessful motion plans in a neural network. However, this \"neural motion\nplanning\" did not scale to complex robots in unseen 3D environments as needed\nfor real-world applications. Here, we introduce \"basis point set\", well-known\nin computer vision, to neural motion planning as a modern compact environment\nencoding enabling efficient supervised training networks that generalize well\nover diverse 3D worlds. Combined with a new elaborate training scheme, we reach\na planning success rate of 100%. We use the network to predict an educated\ninitial guess for an optimization-based planner (OMP), which quickly converges\nto a feasible solution, massively outperforming random multi-starts when tested\non previously unseen environments. For the DLR humanoid Agile Justin with 19DoF\nand in challenging obstacle environments, optimal paths can be generated in\n200ms using only a single CPU core. We also show a first successful real-world\nexperiment based on a high-resolution world model from an integrated 3D sensor.",
            "author": [
                "Johannes Tenhumberg",
                "Darius Burschka",
                "Berthold B\u00e4uml"
            ],
            "link": [
                "http://dx.doi.org/10.1109/IROS47612.2022.9981717",
                "http://arxiv.org/abs/2311.08345v1",
                "http://arxiv.org/pdf/2311.08345v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08442v1",
            "title": "Mean-field variational inference with the TAP free energy: Geometric and\n  statistical properties in linear models",
            "updated": "2023-11-14T17:35:01Z",
            "published": "2023-11-14T17:35:01Z",
            "summary": "We study mean-field variational inference in a Bayesian linear model when the\nsample size n is comparable to the dimension p. In high dimensions, the common\napproach of minimizing a Kullback-Leibler divergence from the posterior\ndistribution, or maximizing an evidence lower bound, may deviate from the true\nposterior mean and underestimate posterior uncertainty. We study instead\nminimization of the TAP free energy, showing in a high-dimensional asymptotic\nframework that it has a local minimizer which provides a consistent estimate of\nthe posterior marginals and may be used for correctly calibrated posterior\ninference. Geometrically, we show that the landscape of the TAP free energy is\nstrongly convex in an extensive neighborhood of this local minimizer, which\nunder certain general conditions can be found by an Approximate Message Passing\n(AMP) algorithm. We then exhibit an efficient algorithm that linearly converges\nto the minimizer within this local neighborhood. In settings where it is\nconjectured that no efficient algorithm can find this local neighborhood, we\nprove analogous geometric properties for a local minimizer of the TAP free\nenergy reachable by AMP, and show that posterior inference based on this\nminimizer remains correctly calibrated.",
            "author": [
                "Michael Celentano",
                "Zhou Fan",
                "Licong Lin",
                "Song Mei"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08442v1",
                "http://arxiv.org/pdf/2311.08442v1"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "cs.LG",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08340v1",
            "title": "Causal Message Passing: A Method for Experiments with Unknown and\n  General Network Interference",
            "updated": "2023-11-14T17:31:50Z",
            "published": "2023-11-14T17:31:50Z",
            "summary": "Randomized experiments are a powerful methodology for data-driven evaluation\nof decisions or interventions. Yet, their validity may be undermined by network\ninterference. This occurs when the treatment of one unit impacts not only its\noutcome but also that of connected units, biasing traditional treatment effect\nestimations. Our study introduces a new framework to accommodate complex and\nunknown network interference, moving beyond specialized models in the existing\nliterature. Our framework, which we term causal message-passing, is grounded in\na high-dimensional approximate message passing methodology and is specifically\ntailored to experimental design settings with prevalent network interference.\nUtilizing causal message-passing, we present a practical algorithm for\nestimating the total treatment effect and demonstrate its efficacy in four\nnumerical scenarios, each with its unique interference structure.",
            "author": [
                "Sadegh Shirani",
                "Mohsen Bayati"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08340v1",
                "http://arxiv.org/pdf/2311.08340v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08331v1",
            "title": "Radio Galaxy Zoo: Leveraging latent space representations from\n  variational autoencoder",
            "updated": "2023-11-14T17:21:16Z",
            "published": "2023-11-14T17:21:16Z",
            "summary": "We propose to learn latent space representations of radio galaxies, and train\na very deep variational autoencoder (\\protect\\Verb+VDVAE+) on RGZ DR1, an\nunlabeled dataset, to this end. We show that the encoded features can be\nleveraged for downstream tasks such as classifying galaxies in labeled\ndatasets, and similarity search. Results show that the model is able to\nreconstruct its given inputs, capturing the salient features of the latter. We\nuse the latent codes of galaxy images, from MiraBest Confident and FR-DEEP NVSS\ndatasets, to train various non-neural network classifiers. It is found that the\nlatter can differentiate FRI from FRII galaxies achieving \\textit{accuracy}\n$\\ge 76\\%$, \\textit{roc-auc} $\\ge 0.86$, \\textit{specificity} $\\ge 0.73$ and\n\\textit{recall} $\\ge 0.78$ on MiraBest Confident dataset, comparable to results\nobtained in previous studies. The performance of simple classifiers trained on\nFR-DEEP NVSS data representations is on par with that of a deep learning\nclassifier (CNN based) trained on images in previous work, highlighting how\npowerful the compressed information is. We successfully exploit the learned\nrepresentations to search for galaxies in a dataset that are semantically\nsimilar to a query image belonging to a different dataset. Although generating\nnew galaxy images (e.g. for data augmentation) is not our primary objective, we\nfind that the \\protect\\Verb+VDVAE+ model is a relatively good emulator.\nFinally, as a step toward detecting anomaly/novelty, a density estimator --\nMasked Autoregressive Flow (\\protect\\Verb+MAF+) -- is trained on the latent\ncodes, such that the log-likelihood of data can be estimated. The downstream\ntasks conducted in this work demonstrate the meaningfulness of the latent\ncodes.",
            "author": [
                "Sambatra Andrianomena",
                "Hongming Tang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08331v1",
                "http://arxiv.org/pdf/2311.08331v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA",
                "astro-ph.IM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08330v2",
            "title": "Generative De-Quantization for Neural Speech Codec via Latent Diffusion",
            "updated": "2023-11-15T15:23:03Z",
            "published": "2023-11-14T17:19:40Z",
            "summary": "In low-bitrate speech coding, end-to-end speech coding networks aim to learn\ncompact yet expressive features and a powerful decoder in a single network. A\nchallenging problem as such results in unwelcome complexity increase and\ninferior speech quality. In this paper, we propose to separate the\nrepresentation learning and information reconstruction tasks. We leverage an\nend-to-end codec for learning low-dimensional discrete tokens and employ a\nlatent diffusion model to de-quantize coded features into a high-dimensional\ncontinuous space, relieving the decoder's burden of de-quantizing and\nupsampling. To mitigate the issue of over-smooth generation, we introduce\nmidway-infilling with less noise reduction and stronger conditioning. In\nablation studies, we investigate the hyperparameters for midway-infilling and\nlatent diffusion space with different dimensions. Subjective listening tests\nshow that our model outperforms the state-of-the-art at two low bitrates, 1.5\nand 3 kbps. Codes and samples of this work are available on our webpage.",
            "author": [
                "Haici Yang",
                "Inseon Jang",
                "Minje Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08330v2",
                "http://arxiv.org/pdf/2311.08330v2"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08324v1",
            "title": "Anti-LM Decoding for Zero-shot In-context Machine Translation",
            "updated": "2023-11-14T17:09:43Z",
            "published": "2023-11-14T17:09:43Z",
            "summary": "Zero-shot In-context learning is the phenomenon where models can perform the\ntask simply given the instructions. However, pre-trained large language models\nare known to be poorly calibrated for this task. One of the most effective\napproaches to handling this bias is to adopt a contrastive decoding objective,\nwhich accounts for the prior probability of generating the next token by\nconditioning on some context. This work introduces an Anti-Language Model\nobjective with a decay factor designed to address the weaknesses of In-context\nMachine Translation. We conduct our experiments across 3 model types and sizes,\n3 language directions, and for both greedy decoding and beam search ($B=5$).\nThe proposed method outperforms other state-of-art decoding objectives, with up\nto $20$ BLEU point improvement from the default objective observed in some\nsettings.",
            "author": [
                "Suzanna Sia",
                "Alexandra DeLucia",
                "Kevin Duh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08324v1",
                "http://arxiv.org/pdf/2311.08324v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08315v1",
            "title": "Total Empiricism: Learning from Data",
            "updated": "2023-11-14T16:59:37Z",
            "published": "2023-11-14T16:59:37Z",
            "summary": "Statistical analysis is an important tool to distinguish systematic from\nchance findings. Current statistical analyses rely on distributional\nassumptions reflecting the structure of some underlying model, which if not met\nlead to problems in the analysis and interpretation of the results. Instead of\ntrying to fix the model or \"correct\" the data, we here describe a totally\nempirical statistical approach that does not rely on ad hoc distributional\nassumptions in order to overcome many problems in contemporary statistics.\nStarting from elementary combinatorics, we motivate an information-guided\nformalism to quantify knowledge extracted from the given data. Subsequently, we\nderive model-agnostic methods to identify patterns that are solely evidenced by\nthe data based on our prior knowledge. The data-centric character of empiricism\nallows for its universal applicability, particularly as sample size grows\nlarger. In this comprehensive framework, we re-interpret and extend model\ndistributions, scores and statistical tests used in different schools of\nstatistics.",
            "author": [
                "Orestis Loukas",
                "Ho Ryun Chung"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08315v1",
                "http://arxiv.org/pdf/2311.08315v1"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "physics.data-an",
                "stat.ME",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08314v1",
            "title": "Convolutional Neural Networks Exploiting Attributes of Biological\n  Neurons",
            "updated": "2023-11-14T16:58:18Z",
            "published": "2023-11-14T16:58:18Z",
            "summary": "In this era of artificial intelligence, deep neural networks like\nConvolutional Neural Networks (CNNs) have emerged as front-runners, often\nsurpassing human capabilities. These deep networks are often perceived as the\npanacea for all challenges. Unfortunately, a common downside of these networks\nis their ''black-box'' character, which does not necessarily mirror the\noperation of biological neural systems. Some even have millions/billions of\nlearnable (tunable) parameters, and their training demands extensive data and\ntime.\n  Here, we integrate the principles of biological neurons in certain layer(s)\nof CNNs. Specifically, we explore the use of neuro-science-inspired\ncomputational models of the Lateral Geniculate Nucleus (LGN) and simple cells\nof the primary visual cortex. By leveraging such models, we aim to extract\nimage features to use as input to CNNs, hoping to enhance training efficiency\nand achieve better accuracy. We aspire to enable shallow networks with a\nPush-Pull Combination of Receptive Fields (PP-CORF) model of simple cells as\nthe foundation layer of CNNs to enhance their learning process and performance.\nTo achieve this, we propose a two-tower CNN, one shallow tower and the other as\nResNet 18. Rather than extracting the features blindly, it seeks to mimic how\nthe brain perceives and extracts features. The proposed system exhibits a\nnoticeable improvement in the performance (on an average of $5\\%-10\\%$) on\nCIFAR-10, CIFAR-100, and ImageNet-100 datasets compared to ResNet-18. We also\ncheck the efficiency of only the Push-Pull tower of the network.",
            "author": [
                "Neeraj Kumar Singh",
                "Nikhil R. Pal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08314v1",
                "http://arxiv.org/pdf/2311.08314v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08309v1",
            "title": "Introducing an Improved Information-Theoretic Measure of Predictive\n  Uncertainty",
            "updated": "2023-11-14T16:55:12Z",
            "published": "2023-11-14T16:55:12Z",
            "summary": "Applying a machine learning model for decision-making in the real world\nrequires to distinguish what the model knows from what it does not. A critical\nfactor in assessing the knowledge of a model is to quantify its predictive\nuncertainty. Predictive uncertainty is commonly measured by the entropy of the\nBayesian model average (BMA) predictive distribution. Yet, the properness of\nthis current measure of predictive uncertainty was recently questioned. We\nprovide new insights regarding those limitations. Our analyses show that the\ncurrent measure erroneously assumes that the BMA predictive distribution is\nequivalent to the predictive distribution of the true model that generated the\ndataset. Consequently, we introduce a theoretically grounded measure to\novercome these limitations. We experimentally verify the benefits of our\nintroduced measure of predictive uncertainty. We find that our introduced\nmeasure behaves more reasonably in controlled synthetic tasks. Moreover, our\nevaluations on ImageNet demonstrate that our introduced measure is advantageous\nin real-world applications utilizing predictive uncertainty.",
            "author": [
                "Kajetan Schweighofer",
                "Lukas Aichberger",
                "Mykyta Ielanskyi",
                "Sepp Hochreiter"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08309v1",
                "http://arxiv.org/pdf/2311.08309v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08306v1",
            "title": "On-the-Fly Fusion of Large Language Models and Machine Translation",
            "updated": "2023-11-14T16:49:33Z",
            "published": "2023-11-14T16:49:33Z",
            "summary": "We propose the on-the-fly ensembling of a machine translation model with an\nLLM, prompted on the same task and input. We perform experiments on 4 language\npairs (both directions) with varying data amounts. We find that a slightly\nweaker-at-translation LLM can improve translations of a NMT model, and\nensembling with an LLM can produce better translations than ensembling two\nstronger MT models. We combine our method with various techniques from LLM\nprompting, such as in context learning and translation context.",
            "author": [
                "Hieu Hoang",
                "Huda Khayrallah",
                "Marcin Junczys-Dowmunt"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08306v1",
                "http://arxiv.org/pdf/2311.08306v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08302v2",
            "title": "Inverse Learning with Extremely Sparse Feedback for Recommendation",
            "updated": "2023-11-20T23:52:58Z",
            "published": "2023-11-14T16:46:10Z",
            "summary": "Modern personalized recommendation services often rely on user feedback,\neither explicit or implicit, to improve the quality of services. Explicit\nfeedback refers to behaviors like ratings, while implicit feedback refers to\nbehaviors like user clicks. However, in the scenario of full-screen video\nviewing experiences like Tiktok and Reels, the click action is absent,\nresulting in unclear feedback from users, hence introducing noises in modeling\ntraining. Existing approaches on de-noising recommendation mainly focus on\npositive instances while ignoring the noise in a large amount of sampled\nnegative feedback. In this paper, we propose a meta-learning method to annotate\nthe unlabeled data from loss and gradient perspectives, which considers the\nnoises in both positive and negative instances. Specifically, we first propose\nan Inverse Dual Loss (IDL) to boost the true label learning and prevent the\nfalse label learning. Then we further propose an Inverse Gradient (IG) method\nto explore the correct updating gradient and adjust the updating based on\nmeta-learning. Finally, we conduct extensive experiments on both benchmark and\nindustrial datasets where our proposed method can significantly improve AUC by\n9.25% against state-of-the-art methods. Further analysis verifies the proposed\ninverse learning framework is model-agnostic and can improve a variety of\nrecommendation backbones. The source code, along with the best hyper-parameter\nsettings, is available at this link:\nhttps://github.com/Guanyu-Lin/InverseLearning.",
            "author": [
                "Guanyu Lin",
                "Chen Gao",
                "Yu Zheng",
                "Yinfeng Li",
                "Jianxin Chang",
                "Yanan Niu",
                "Yang Song",
                "Kun Gai",
                "Zhiheng Li",
                "Depeng Jin",
                "Yong Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08302v2",
                "http://arxiv.org/pdf/2311.08302v2"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08300v1",
            "title": "Workflow-Guided Response Generation for Task-Oriented Dialogue",
            "updated": "2023-11-14T16:44:33Z",
            "published": "2023-11-14T16:44:33Z",
            "summary": "Task-oriented dialogue (TOD) systems aim to achieve specific goals through\ninteractive dialogue. Such tasks usually involve following specific workflows,\ni.e. executing a sequence of actions in a particular order. While prior work\nhas focused on supervised learning methods to condition on past actions, they\ndo not explicitly optimize for compliance to a desired workflow. In this paper,\nwe propose a novel framework based on reinforcement learning (RL) to generate\ndialogue responses that are aligned with a given workflow. Our framework\nconsists of ComplianceScorer, a metric designed to evaluate how well a\ngenerated response executes the specified action, combined with an RL\nopimization process that utilizes an interactive sampling technique. We\nevaluate our approach on two TOD datasets, Action-Based Conversations Dataset\n(ABCD) (Chen et al., 2021a) and MultiWOZ 2.2 (Zang et al., 2020) on a range of\nautomated and human evaluation metrics. Our findings indicate that our RL-based\nframework outperforms baselines and is effective at enerating responses that\nboth comply with the intended workflows while being expressed in a natural and\nfluent manner.",
            "author": [
                "Do June Min",
                "Paloma Sodhi",
                "Ramya Ramakrishnan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08300v1",
                "http://arxiv.org/pdf/2311.08300v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08299v1",
            "title": "VERVE: Template-based ReflectiVE Rewriting for MotiVational IntErviewing",
            "updated": "2023-11-14T16:44:16Z",
            "published": "2023-11-14T16:44:16Z",
            "summary": "Reflective listening is a fundamental skill that counselors must acquire to\nachieve proficiency in motivational interviewing (MI). It involves responding\nin a manner that acknowledges and explores the meaning of what the client has\nexpressed in the conversation. In this work, we introduce the task of\ncounseling response rewriting, which transforms non-reflective statements into\nreflective responses. We introduce VERVE, a template-based rewriting system\nwith paraphrase-augmented training and adaptive template updating. VERVE first\ncreates a template by identifying and filtering out tokens that are not\nrelevant to reflections and constructs a reflective response using the\ntemplate. Paraphrase-augmented training allows the model to learn less-strict\nfillings of masked spans, and adaptive template updating helps discover\neffective templates for rewriting without significantly removing the original\ncontent. Using both automatic and human evaluations, we compare our method\nagainst text rewriting baselines and show that our framework is effective in\nturning non-reflective statements into more reflective responses while\nachieving a good content preservation-reflection style trade-off.",
            "author": [
                "Do June Min",
                "Ver\u00f3nica P\u00e9rez-Rosas",
                "Kenneth Resnicow",
                "Rada Mihalcea"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08299v1",
                "http://arxiv.org/pdf/2311.08299v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08290v1",
            "title": "On-Policy Policy Gradient Reinforcement Learning Without On-Policy\n  Sampling",
            "updated": "2023-11-14T16:37:28Z",
            "published": "2023-11-14T16:37:28Z",
            "summary": "On-policy reinforcement learning (RL) algorithms perform policy updates using\ni.i.d. trajectories collected by the current policy. However, after observing\nonly a finite number of trajectories, on-policy sampling may produce data that\nfails to match the expected on-policy data distribution. This sampling error\nleads to noisy updates and data inefficient on-policy learning. Recent work in\nthe policy evaluation setting has shown that non-i.i.d., off-policy sampling\ncan produce data with lower sampling error than on-policy sampling can produce.\nMotivated by this observation, we introduce an adaptive, off-policy sampling\nmethod to improve the data efficiency of on-policy policy gradient algorithms.\nOur method, Proximal Robust On-Policy Sampling (PROPS), reduces sampling error\nby collecting data with a behavior policy that increases the probability of\nsampling actions that are under-sampled with respect to the current policy.\nRather than discarding data from old policies -- as is commonly done in\non-policy algorithms -- PROPS uses data collection to adjust the distribution\nof previously collected data to be approximately on-policy. We empirically\nevaluate PROPS on both continuous-action MuJoCo benchmark tasks as well as\ndiscrete-action tasks and demonstrate that (1) PROPS decreases sampling error\nthroughout training and (2) improves the data efficiency of on-policy policy\ngradient algorithms. Our work improves the RL community's understanding of a\nnuance in the on-policy vs off-policy dichotomy: on-policy learning requires\non-policy data, not on-policy sampling.",
            "author": [
                "Nicholas E. Corrado",
                "Josiah P. Hanna"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08290v1",
                "http://arxiv.org/pdf/2311.08290v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08287v1",
            "title": "How Well Do Large Language Models Understand Syntax? An Evaluation by\n  Asking Natural Language Questions",
            "updated": "2023-11-14T16:30:36Z",
            "published": "2023-11-14T16:30:36Z",
            "summary": "While recent advancements in large language models (LLMs) bring us closer to\nachieving artificial general intelligence, the question persists: Do LLMs truly\nunderstand language, or do they merely mimic comprehension through pattern\nrecognition? This study seeks to explore this question through the lens of\nsyntax, a crucial component of sentence comprehension. Adopting a natural\nlanguage question-answering (Q&A) scheme, we craft questions targeting nine\nsyntactic knowledge points that are most closely related to sentence\ncomprehension. Experiments conducted on 24 LLMs suggest that most have a\nlimited grasp of syntactic knowledge, exhibiting notable discrepancies across\ndifferent syntactic knowledge points. In particular, questions involving\nprepositional phrase attachment pose the greatest challenge, whereas those\nconcerning adjectival modifier and indirect object are relatively easier for\nLLMs to handle. Furthermore, a case study on the training dynamics of the LLMs\nreveals that the majority of syntactic knowledge is learned during the initial\nstages of training, hinting that simply increasing the number of training\ntokens may not be the `silver bullet' for improving the comprehension ability\nof LLMs.",
            "author": [
                "Houquan Zhou",
                "Yang Hou",
                "Zhenghua Li",
                "Xuebin Wang",
                "Zhefeng Wang",
                "Xinyu Duan",
                "Min Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08287v1",
                "http://arxiv.org/pdf/2311.08287v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08284v1",
            "title": "Level Set KSVD",
            "updated": "2023-11-14T16:27:33Z",
            "published": "2023-11-14T16:27:33Z",
            "summary": "We present a new algorithm for image segmentation - Level-set KSVD. Level-set\nKSVD merges the methods of sparse dictionary learning for feature extraction\nand variational level-set method for image segmentation. Specifically, we use a\ngeneralization of the Chan-Vese functional with features learned by KSVD. The\nmotivation for this model is agriculture based. Aerial images are taken in\norder to detect the spread of fungi in various crops. Our model is tested on\nsuch images of cotton fields. The results are compared to other methods.",
            "author": [
                "Omer Sapir",
                "Iftach Klapp",
                "Nir Sochen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08284v1",
                "http://arxiv.org/pdf/2311.08284v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08275v1",
            "title": "Non-Volatile Control of Valley Polarized Emission in 2D WSe2-AlScN\n  Heterostructures",
            "updated": "2023-11-14T16:11:58Z",
            "published": "2023-11-14T16:11:58Z",
            "summary": "Achieving robust and electrically controlled valley polarization in monolayer\ntransition metal dichalcogenides (ML-TMDs) is a frontier challenge for\nrealistic valleytronic applications. Theoretical investigations show that\nintegration of 2D materials with ferroelectrics is a promising strategy;\nhowever, its experimental demonstration has remained elusive. Here, we\nfabricate ferroelectric field-effect transistors using a ML-WSe2 channel and a\nAlScN ferroelectric dielectric, and experimentally demonstrate efficient tuning\nas well as non-volatile control of valley polarization. We measured a large\narray of transistors and obtained a maximum valley polarization of ~27% at 80 K\nwith stable retention up to 5400 secs. The enhancement in the valley\npolarization was ascribed to the efficient exciton-to-trion (X-T) conversion\nand its coupling with an out-of-plane electric field, viz. the quantum-confined\nStark effect. This changes the valley depolarization pathway from strong\nexchange interactions to slow spin-flip intervalley scattering. Our research\ndemonstrates a promising approach for achieving non-volatile control over\nvalley polarization and suggests new design principles for practical\nvalleytronic devices.",
            "author": [
                "Simrjit Singh",
                "Kwan-Ho Kim",
                "Kiyoung Jo",
                "Pariasadat Musavigharavi",
                "Bumho Kim",
                "Jeffrey Zheng",
                "Nicholas Trainor",
                "Chen Chen",
                "Joan M. Redwing",
                "Eric A Stach",
                "Roy H Olsson III",
                "Deep Jariwala"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08275v1",
                "http://arxiv.org/pdf/2311.08275v1"
            ],
            "primary_category": "cond-mat.mes-hall",
            "category": [
                "cond-mat.mes-hall",
                "physics.app-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08272v1",
            "title": "Mixed Attention Network for Cross-domain Sequential Recommendation",
            "updated": "2023-11-14T16:07:16Z",
            "published": "2023-11-14T16:07:16Z",
            "summary": "In modern recommender systems, sequential recommendation leverages\nchronological user behaviors to make effective next-item suggestions, which\nsuffers from data sparsity issues, especially for new users. One promising line\nof work is the cross-domain recommendation, which trains models with data\nacross multiple domains to improve the performance in data-scarce domains.\nRecent proposed cross-domain sequential recommendation models such as PiNet and\nDASL have a common drawback relying heavily on overlapped users in different\ndomains, which limits their usage in practical recommender systems. In this\npaper, we propose a Mixed Attention Network (MAN) with local and global\nattention modules to extract the domain-specific and cross-domain information.\nFirstly, we propose a local/global encoding layer to capture the\ndomain-specific/cross-domain sequential pattern. Then we propose a mixed\nattention layer with item similarity attention, sequence-fusion attention, and\ngroup-prototype attention to capture the local/global item similarity, fuse the\nlocal/global item sequence, and extract the user groups across different\ndomains, respectively. Finally, we propose a local/global prediction layer to\nfurther evolve and combine the domain-specific and cross-domain interests.\nExperimental results on two real-world datasets (each with two domains)\ndemonstrate the superiority of our proposed model. Further study also\nillustrates that our proposed method and components are model-agnostic and\neffective, respectively. The code and data are available at\nhttps://github.com/Guanyu-Lin/MAN.",
            "author": [
                "Guanyu Lin",
                "Chen Gao",
                "Yu Zheng",
                "Jianxin Chang",
                "Yanan Niu",
                "Yang Song",
                "Kun Gai",
                "Zhiheng Li",
                "Depeng Jin",
                "Yong Li",
                "Meng Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08272v1",
                "http://arxiv.org/pdf/2311.08272v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08271v1",
            "title": "Mobility-Induced Graph Learning for WiFi Positioning",
            "updated": "2023-11-14T16:06:11Z",
            "published": "2023-11-14T16:06:11Z",
            "summary": "A smartphone-based user mobility tracking could be effective in finding\nhis/her location, while the unpredictable error therein due to low\nspecification of built-in inertial measurement units (IMUs) rejects its\nstandalone usage but demands the integration to another positioning technique\nlike WiFi positioning. This paper aims to propose a novel integration technique\nusing a graph neural network called Mobility-INduced Graph LEarning (MINGLE),\nwhich is designed based on two types of graphs made by capturing different user\nmobility features. Specifically, considering sequential measurement points\n(MPs) as nodes, a user's regular mobility pattern allows us to connect neighbor\nMPs as edges, called time-driven mobility graph (TMG). Second, a user's\nrelatively straight transition at a constant pace when moving from one position\nto another can be captured by connecting the nodes on each path, called a\ndirection-driven mobility graph (DMG). Then, we can design graph convolution\nnetwork (GCN)-based cross-graph learning, where two different GCN models for\nTMG and DMG are jointly trained by feeding different input features created by\nWiFi RTTs yet sharing their weights. Besides, the loss function includes a\nmobility regularization term such that the differences between adjacent\nlocation estimates should be less variant due to the user's stable moving pace.\nNoting that the regularization term does not require ground-truth location,\nMINGLE can be designed under semi- and self-supervised learning frameworks. The\nproposed MINGLE's effectiveness is extensively verified through field\nexperiments, showing a better positioning accuracy than benchmarks, say root\nmean square errors (RMSEs) being 1.398 (m) and 1.073 (m) for self- and\nsemi-supervised learning cases, respectively.",
            "author": [
                "Kyuwon Han",
                "Seung Min Yu",
                "Seong-Lyun Kim",
                "Seung-Woo Ko"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08271v1",
                "http://arxiv.org/pdf/2311.08271v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.IT",
                "cs.NI",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08269v2",
            "title": "Defining the boundaries: challenges and advances in identifying cells in\n  microscopy images",
            "updated": "2023-11-28T17:18:44Z",
            "published": "2023-11-14T16:02:18Z",
            "summary": "Segmentation, or the outlining of objects within images, is a critical step\nin the measurement and analysis of cells within microscopy images. While\nimprovements continue to be made in tools that rely on classical methods for\nsegmentation, deep learning-based tools increasingly dominate advances in the\ntechnology. Specialist models such as Cellpose continue to improve in accuracy\nand user-friendliness, and segmentation challenges such as the Multi-Modality\nCell Segmentation Challenge continue to push innovation in accuracy across\nwidely-varying test data as well as efficiency and usability. Increased\nattention on documentation, sharing, and evaluation standards are leading to\nincreased user-friendliness and acceleration towards the goal of a truly\nuniversal method.",
            "author": [
                "Nodar Gogoberidze",
                "Beth A. Cimini"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08269v2",
                "http://arxiv.org/pdf/2311.08269v2"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08265v1",
            "title": "On The Relationship Between Universal Adversarial Attacks And Sparse\n  Representations",
            "updated": "2023-11-14T16:00:29Z",
            "published": "2023-11-14T16:00:29Z",
            "summary": "The prominent success of neural networks, mainly in computer vision tasks, is\nincreasingly shadowed by their sensitivity to small, barely perceivable\nadversarial perturbations in image input.\n  In this work, we aim at explaining this vulnerability through the framework\nof sparsity.\n  We show the connection between adversarial attacks and sparse\nrepresentations, with a focus on explaining the universality and\ntransferability of adversarial examples in neural networks.\n  To this end, we show that sparse coding algorithms, and the neural\nnetwork-based learned iterative shrinkage thresholding algorithm (LISTA) among\nthem, suffer from this sensitivity, and that common attacks on neural networks\ncan be expressed as attacks on the sparse representation of the input image.\nThe phenomenon that we observe holds true also when the network is agnostic to\nthe sparse representation and dictionary, and thus can provide a possible\nexplanation for the universality and transferability of adversarial attacks.\n  The code is available at\nhttps://github.com/danawr/adversarial_attacks_and_sparse_representations.",
            "author": [
                "Dana Weitzner",
                "Raja Giryes"
            ],
            "link": [
                "http://dx.doi.org/10.1109/OJSP.2023.3244486",
                "http://arxiv.org/abs/2311.08265v1",
                "http://arxiv.org/pdf/2311.08265v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08258v2",
            "title": "Unprecedented reach and rich online journeys drive hate and extremism\n  globally",
            "updated": "2023-11-16T13:11:26Z",
            "published": "2023-11-14T15:54:19Z",
            "summary": "Hate and extremism cannot be controlled globally without understanding how\nthey operate at scale. Both have escalated dramatically during the Israel-Hamas\nand Ukraine-Russia wars. Here we show how the online hate-extremism system is\nnow operating at unprecedented scale across 26 social media platforms of all\nsizes, audience demographics, and geographic locations; and we analyze\nindividuals' journeys through it. This new picture contradicts notions of\nrabbit-hole activity at the fringe of the Internet. Instead, it shows that\nhate-extremism support now enjoys a direct link to more than a billion of the\ngeneral global population, and that newcomers now enjoy a rich variety of\nonline journey experiences during which they get to mingle with experienced\nviolent actors, discuss topics from diverse news sources, and learn to\ncollectively adapt in order to bypass platform shutdowns. Our results mean that\nlaw enforcement must expect future mass shooters to have increasingly\nhard-to-understand online journeys; that new E.U. laws will fall short because\nthe combined impact of many smaller, lesser-known platforms outstrips larger\nones like Twitter; and that the current global hate-extremism infrastructure\nwill become increasingly robust in 2024 and beyond. Fortunately, it also\nreveals a new opportunity for system-wide control akin to adaptive vs.\nextinction treatments for cancer.",
            "author": [
                "Richard Sear",
                "Neil F. Johnson"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08258v2",
                "http://arxiv.org/pdf/2311.08258v2"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "cs.HC",
                "nlin.AO",
                "physics.soc-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08256v1",
            "title": "Consensus and Disagreement: Information Aggregation under (not so) Naive\n  Learning",
            "updated": "2023-11-14T15:52:23Z",
            "published": "2023-11-14T15:52:23Z",
            "summary": "We explore a model of non-Bayesian information aggregation in networks.\nAgents non-cooperatively choose among Friedkin-Johnsen type aggregation rules\nto maximize payoffs. The DeGroot rule is chosen in equilibrium if and only if\nthere is noiseless information transmission, leading to consensus. With noisy\ntransmission, while some disagreement is inevitable, the optimal choice of rule\namplifies the disagreement: even with little noise, individuals place\nsubstantial weight on their own initial opinion in every period, exacerbating\nthe disagreement. We use this framework to think about equilibrium versus\nsocially efficient choice of rules and its connection to polarization of\nopinions across groups.",
            "author": [
                "Abhijit Banerjee",
                "Olivier Compte"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08256v1",
                "http://arxiv.org/pdf/2311.08256v1"
            ],
            "primary_category": "econ.GN",
            "category": [
                "econ.GN",
                "q-fin.EC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08254v1",
            "title": "Identifiable and interpretable nonparametric factor analysis",
            "updated": "2023-11-14T15:49:29Z",
            "published": "2023-11-14T15:49:29Z",
            "summary": "Factor models have been widely used to summarize the variability of\nhigh-dimensional data through a set of factors with much lower dimensionality.\nGaussian linear factor models have been particularly popular due to their\ninterpretability and ease of computation. However, in practice, data often\nviolate the multivariate Gaussian assumption. To characterize higher-order\ndependence and nonlinearity, models that include factors as predictors in\nflexible multivariate regression are popular, with GP-LVMs using Gaussian\nprocess (GP) priors for the regression function and VAEs using deep neural\nnetworks. Unfortunately, such approaches lack identifiability and\ninterpretability and tend to produce brittle and non-reproducible results. To\naddress these problems by simplifying the nonparametric factor model while\nmaintaining flexibility, we propose the NIFTY framework, which parsimoniously\ntransforms uniform latent variables using one-dimensional nonlinear mappings\nand then applies a linear generative model. The induced multivariate\ndistribution falls into a flexible class while maintaining simple computation\nand interpretation. We prove that this model is identifiable and empirically\nstudy NIFTY using simulated data, observing good performance in density\nestimation and data visualization. We then apply NIFTY to bird song data in an\nenvironmental monitoring application.",
            "author": [
                "Maoran Xu",
                "Amy H. Herring",
                "David B. Dunson"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08254v1",
                "http://arxiv.org/pdf/2311.08254v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14708v1",
            "title": "Large Language Model-Driven Classroom Flipping: Empowering\n  Student-Centric Peer Questioning with Flipped Interaction",
            "updated": "2023-11-14T15:48:19Z",
            "published": "2023-11-14T15:48:19Z",
            "summary": "Reciprocal questioning is essential for effective teaching and learning,\nfostering active engagement and deeper understanding through collaborative\ninteractions, especially in large classrooms. Can large language model (LLM),\nsuch as OpenAI's GPT (Generative Pre-trained Transformer) series, assist in\nthis? This paper investigates a pedagogical approach of classroom flipping\nbased on flipped interaction in LLMs. Flipped interaction involves using\nlanguage models to prioritize generating questions instead of answers to\nprompts. We demonstrate how traditional classroom flipping techniques,\nincluding Peer Instruction and Just-in-Time Teaching (JiTT), can be enhanced\nthrough flipped interaction techniques, creating student-centric questions for\nhybrid teaching. In particular, we propose a workflow to integrate prompt\nengineering with clicker and JiTT quizzes by a poll-prompt-quiz routine and a\nquiz-prompt-discuss routine to empower students to self-regulate their learning\ncapacity and enable teachers to swiftly personalize training pathways. We\ndevelop an LLM-driven chatbot software that digitizes various elements of\nclassroom flipping and facilitates the assessment of students using these\nroutines to deliver peer-generated questions. We have applied our LLM-driven\nchatbot software for teaching both undergraduate and graduate students from\n2020 to 2022, effectively useful for bridging the gap between teachers and\nstudents in remote teaching during the COVID-19 pandemic years. In particular,\nLLM-driven classroom flipping can be particularly beneficial in large class\nsettings to optimize teaching pace and enable engaging classroom experiences.",
            "author": [
                "Chee Wei Tan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14708v1",
                "http://arxiv.org/pdf/2311.14708v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.AI",
                "cs.CL",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08252v1",
            "title": "REST: Retrieval-Based Speculative Decoding",
            "updated": "2023-11-14T15:43:47Z",
            "published": "2023-11-14T15:43:47Z",
            "summary": "We introduce Retrieval-Based Speculative Decoding (REST), a novel algorithm\ndesigned to speed up language model generation. The key insight driving the\ndevelopment of REST is the observation that the process of text generation\noften includes certain common phases and patterns. Unlike previous methods that\nrely on a draft language model for speculative decoding, REST harnesses the\npower of retrieval to generate draft tokens. This method draws from the\nreservoir of existing knowledge, retrieving and employing relevant tokens based\non the current context. Its plug-and-play nature allows for seamless\nintegration and acceleration of any language models, all without necessitating\nadditional training. When benchmarked on 7B and 13B language models in a\nsingle-batch setting, REST achieves a significant speedup of 1.62X to 2.36X on\ncode or text generation. The code of REST is available at\nhttps://github.com/FasterDecoding/REST.",
            "author": [
                "Zhenyu He",
                "Zexuan Zhong",
                "Tianle Cai",
                "Jason D Lee",
                "Di He"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08252v1",
                "http://arxiv.org/pdf/2311.08252v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.09251v1",
            "title": "A Simple and Powerful Framework for Stable Dynamic Network Embedding",
            "updated": "2023-11-14T15:38:17Z",
            "published": "2023-11-14T15:38:17Z",
            "summary": "In this paper, we address the problem of dynamic network embedding, that is,\nrepresenting the nodes of a dynamic network as evolving vectors within a\nlow-dimensional space. While the field of static network embedding is wide and\nestablished, the field of dynamic network embedding is comparatively in its\ninfancy. We propose that a wide class of established static network embedding\nmethods can be used to produce interpretable and powerful dynamic network\nembeddings when they are applied to the dilated unfolded adjacency matrix. We\nprovide a theoretical guarantee that, regardless of embedding dimension, these\nunfolded methods will produce stable embeddings, meaning that nodes with\nidentical latent behaviour will be exchangeable, regardless of their position\nin time or space. We additionally define a hypothesis testing framework which\ncan be used to evaluate the quality of a dynamic network embedding by testing\nfor planted structure in simulated networks. Using this, we demonstrate that,\neven in trivial cases, unstable methods are often either conservative or encode\nincorrect structure. In contrast, we demonstrate that our suite of stable\nunfolded methods are not only more interpretable but also more powerful in\ncomparison to their unstable counterparts.",
            "author": [
                "Ed Davis",
                "Ian Gallagher",
                "Daniel John Lawson",
                "Patrick Rubin-Delanchy"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09251v1",
                "http://arxiv.org/pdf/2311.09251v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "cs.LG",
                "stat.ML",
                "62H15 (Primary) 62H30, 62M10, 62G99 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08249v1",
            "title": "On Using Distribution-Based Compositionality Assessment to Evaluate\n  Compositional Generalisation in Machine Translation",
            "updated": "2023-11-14T15:37:19Z",
            "published": "2023-11-14T15:37:19Z",
            "summary": "Compositional generalisation (CG), in NLP and in machine learning more\ngenerally, has been assessed mostly using artificial datasets. It is important\nto develop benchmarks to assess CG also in real-world natural language tasks in\norder to understand the abilities and limitations of systems deployed in the\nwild. To this end, our GenBench Collaborative Benchmarking Task submission\nutilises the distribution-based compositionality assessment (DBCA) framework to\nsplit the Europarl translation corpus into a training and a test set in such a\nway that the test set requires compositional generalisation capacity.\nSpecifically, the training and test sets have divergent distributions of\ndependency relations, testing NMT systems' capability of translating\ndependencies that they have not been trained on. This is a fully-automated\nprocedure to create natural language compositionality benchmarks, making it\nsimple and inexpensive to apply it further to other datasets and languages. The\ncode and data for the experiments is available at\nhttps://github.com/aalto-speech/dbca.",
            "author": [
                "Anssi Moisio",
                "Mathias Creutz",
                "Mikko Kurimo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08249v1",
                "http://arxiv.org/pdf/2311.08249v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08245v1",
            "title": "TENT: Connect Language Models with IoT Sensors for Zero-Shot Activity\n  Recognition",
            "updated": "2023-11-14T15:30:17Z",
            "published": "2023-11-14T15:30:17Z",
            "summary": "Recent achievements in language models have showcased their extraordinary\ncapabilities in bridging visual information with semantic language\nunderstanding. This leads us to a novel question: can language models connect\ntextual semantics with IoT sensory signals to perform recognition tasks, e.g.,\nHuman Activity Recognition (HAR)? If so, an intelligent HAR system with\nhuman-like cognition can be built, capable of adapting to new environments and\nunseen categories. This paper explores its feasibility with an innovative\napproach, IoT-sEnsors-language alignmEnt pre-Training (TENT), which jointly\naligns textual embeddings with IoT sensor signals, including camera video,\nLiDAR, and mmWave. Through the IoT-language contrastive learning, we derive a\nunified semantic feature space that aligns multi-modal features with language\nembeddings, so that the IoT data corresponds to specific words that describe\nthe IoT data. To enhance the connection between textual categories and their\nIoT data, we propose supplementary descriptions and learnable prompts that\nbring more semantic information into the joint feature space. TENT can not only\nrecognize actions that have been seen but also ``guess'' the unseen action by\nthe closest textual words from the feature space. We demonstrate TENT achieves\nstate-of-the-art performance on zero-shot HAR tasks using different modalities,\nimproving the best vision-language models by over 12%.",
            "author": [
                "Yunjiao Zhou",
                "Jianfei Yang",
                "Han Zou",
                "Lihua Xie"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08245v1",
                "http://arxiv.org/pdf/2311.08245v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08244v1",
            "title": "Language and Sketching: An LLM-driven Interactive Multimodal Multitask\n  Robot Navigation Framework",
            "updated": "2023-11-14T15:29:52Z",
            "published": "2023-11-14T15:29:52Z",
            "summary": "The socially-aware navigation system has evolved to adeptly avoid various\nobstacles while performing multiple tasks, such as point-to-point navigation,\nhuman-following, and -guiding. However, a prominent gap persists: in\nHuman-Robot Interaction (HRI), the procedure of communicating commands to\nrobots demands intricate mathematical formulations. Furthermore, the transition\nbetween tasks does not quite possess the intuitive control and user-centric\ninteractivity that one would desire. In this work, we propose an LLM-driven\ninteractive multimodal multitask robot navigation framework, termed LIM2N, to\nsolve the above new challenge in the navigation field. We achieve this by first\nintroducing a multimodal interaction framework where language and hand-drawn\ninputs can serve as navigation constraints and control objectives. Next, a\nreinforcement learning agent is built to handle multiple tasks with the\nreceived information. Crucially, LIM2N creates smooth cooperation among the\nreasoning of multimodal input, multitask planning, and adaptation and\nprocessing of the intelligent sensing modules in the complicated system.\nExtensive experiments are conducted in both simulation and the real world\ndemonstrating that LIM2N has superior user needs understanding, alongside an\nenhanced interactive experience.",
            "author": [
                "Weiqin Zu",
                "Wenbin Song",
                "Ruiqing Chen",
                "Ze Guo",
                "Fanglei Sun",
                "Zheng Tian",
                "Wei Pan",
                "Jun Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08244v1",
                "http://arxiv.org/pdf/2311.08244v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08440v2",
            "title": "Secondary beams at high-intensity electron accelerator facilities",
            "updated": "2023-12-04T10:52:58Z",
            "published": "2023-11-14T15:28:32Z",
            "summary": "The interaction of a high-current $O$(100~\\textmu A), medium energy\n$O$(10\\,GeV) electron beam with a thick target $O$(1m) produces an overwhelming\nshower of standard matter particles in addition to hypothetical Light Dark\nMatter particles. While most of the radiation (gamma, electron/positron, and\nneutron) is contained in the thick target, deep penetrating particles (muons,\nneutrinos, and light dark matter particles) propagate over a long distance,\nproducing high-intense secondary beams. Using sophisticated Monte Carlo\nsimulations based on FLUKA and GEANT4, we explored the characteristics of\nsecondary muons and neutrinos and (hypothetical) dark scalar particles produced\nby the interaction of Jefferson Lab 11 GeV intense electron beam with the\nexperimental Hall-A beam dump. Considering the possible beam energy upgrade,\nthis study was repeated for a 20 GeV CEBAF beam.",
            "author": [
                "Marco Battaglieri",
                "Andrea Bianconi",
                "Mariangela Bond\u00ed",
                "Raffaella De Vita",
                "Antonino Fulci",
                "Giulia Gosta",
                "Stefano Grazzi",
                "Hyon-Suk Jo",
                "Changhui Lee",
                "Giuseppe Mandaglio",
                "Valerio Mascagna",
                "Tetiana Nagorna",
                "Alessandro Pilloni",
                "Marco Spreafico",
                "Luca J Tagliapietra",
                "Luca Venturelli",
                "Tommaso Vittorini"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08440v2",
                "http://arxiv.org/pdf/2311.08440v2"
            ],
            "primary_category": "physics.acc-ph",
            "category": [
                "physics.acc-ph",
                "hep-ex",
                "nucl-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08243v1",
            "title": "MCMC to address model misspecification in Deep Learning classification\n  of Radio Galaxies",
            "updated": "2023-11-14T15:25:44Z",
            "published": "2023-11-14T15:25:44Z",
            "summary": "The radio astronomy community is adopting deep learning techniques to deal\nwith the huge data volumes expected from the next-generation of radio\nobservatories. Bayesian neural networks (BNNs) provide a principled way to\nmodel uncertainty in the predictions made by deep learning models and will play\nan important role in extracting well-calibrated uncertainty estimates from the\noutputs of these models. However, most commonly used approximate Bayesian\ninference techniques such as variational inference and MCMC-based algorithms\nexperience a \"cold posterior effect (CPE)\", according to which the posterior\nmust be down-weighted in order to get good predictive performance. The CPE has\nbeen linked to several factors such as data augmentation or dataset curation\nleading to a misspecified likelihood and prior misspecification. In this work\nwe use MCMC sampling to show that a Gaussian parametric family is a poor\nvariational approximation to the true posterior and gives rise to the CPE\npreviously observed in morphological classification of radio galaxies using\nvariational inference based BNNs.",
            "author": [
                "Devina Mohan",
                "Anna Scaife"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08243v1",
                "http://arxiv.org/pdf/2311.08243v1"
            ],
            "primary_category": "astro-ph.IM",
            "category": [
                "astro-ph.IM",
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08239v2",
            "title": "Learning Physics-Inspired Regularization for Medical Image Registration\n  with Hypernetworks",
            "updated": "2023-12-04T08:25:58Z",
            "published": "2023-11-14T15:20:42Z",
            "summary": "Medical image registration aims at identifying the spatial deformation\nbetween images of the same anatomical region and is fundamental to image-based\ndiagnostics and therapy. To date, the majority of the deep learning-based\nregistration methods employ regularizers that enforce global spatial\nsmoothness, e.g., the diffusion regularizer. However, such regularizers are not\ntailored to the data and might not be capable of reflecting the complex\nunderlying deformation. In contrast, physics-inspired regularizers promote\nphysically plausible deformations. One such regularizer is the linear elastic\nregularizer which models the deformation of elastic material. These\nregularizers are driven by parameters that define the material's physical\nproperties. For biological tissue, a wide range of estimations of such\nparameters can be found in the literature and it remains an open challenge to\nidentify suitable parameter values for successful registration. To overcome\nthis problem and to incorporate physical properties into learning-based\nregistration, we propose to use a hypernetwork that learns the effect of the\nphysical parameters of a physics-inspired regularizer on the resulting spatial\ndeformation field. In particular, we adapt the HyperMorph framework to learn\nthe effect of the two elasticity parameters of the linear elastic regularizer.\nOur approach enables the efficient discovery of suitable, data-specific\nphysical parameters at test time.",
            "author": [
                "Anna Reithmeir",
                "Julia A. Schnabel",
                "Veronika A. Zimmer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08239v2",
                "http://arxiv.org/pdf/2311.08239v2"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08439v1",
            "title": "A Unified Approach for Comprehensive Analysis of Various Spectral and\n  Tissue Doppler Echocardiography",
            "updated": "2023-11-14T15:10:05Z",
            "published": "2023-11-14T15:10:05Z",
            "summary": "Doppler echocardiography offers critical insights into cardiac function and\nphases by quantifying blood flow velocities and evaluating myocardial motion.\nHowever, previous methods for automating Doppler analysis, ranging from initial\nsignal processing techniques to advanced deep learning approaches, have been\nconstrained by their reliance on electrocardiogram (ECG) data and their\ninability to process Doppler views collectively. We introduce a novel unified\nframework using a convolutional neural network for comprehensive analysis of\nspectral and tissue Doppler echocardiography images that combines automatic\nmeasurements and end-diastole (ED) detection into a singular method. The\nnetwork automatically recognizes key features across various Doppler views,\nwith novel Doppler shape embedding and anti-aliasing modules enhancing\ninterpretation and ensuring consistent analysis. Empirical results indicate a\nconsistent outperformance in performance metrics, including dice similarity\ncoefficients (DSC) and intersection over union (IoU). The proposed framework\ndemonstrates strong agreement with clinicians in Doppler automatic measurements\nand competitive performance in ED detection.",
            "author": [
                "Jaeik Jeon",
                "Jiyeon Kim",
                "Yeonggul Jang",
                "Yeonyee E. Yoon",
                "Dawun Jeong",
                "Youngtaek Hong",
                "Seung-Ah Lee",
                "Hyuk-Jae Chang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08439v1",
                "http://arxiv.org/pdf/2311.08439v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08228v3",
            "title": "Counterfactual Explanation for Regression via Disentanglement in Latent\n  Space",
            "updated": "2023-11-23T10:11:06Z",
            "published": "2023-11-14T15:08:14Z",
            "summary": "Counterfactual Explanations (CEs) help address the question: How can the\nfactors that influence the prediction of a predictive model be changed to\nachieve a more favorable outcome from a user's perspective? Thus, they bear the\npotential to guide the user's interaction with AI systems since they represent\neasy-to-understand explanations. To be applicable, CEs need to be realistic and\nactionable. In the literature, various methods have been proposed to generate\nCEs. However, the majority of research on CEs focuses on classification\nproblems where questions like \"What should I do to get my rejected loan\napproved?\" are raised. In practice, answering questions like \"What should I do\nto increase my salary?\" are of a more regressive nature. In this paper, we\nintroduce a novel method to generate CEs for a pre-trained regressor by first\ndisentangling the label-relevant from the label-irrelevant dimensions in the\nlatent space. CEs are then generated by combining the label-irrelevant\ndimensions and the predefined output. The intuition behind this approach is\nthat the ideal counterfactual search should focus on the label-irrelevant\ncharacteristics of the input and suggest changes toward target-relevant\ncharacteristics. Searching in the latent space could help achieve this goal. We\nshow that our method maintains the characteristics of the query sample during\nthe counterfactual search. In various experiments, we demonstrate that the\nproposed method is competitive based on different quality measures on image and\ntabular datasets in regression problem settings. It efficiently returns results\ncloser to the original data manifold compared to three state-of-the-art\nmethods, which is essential for realistic high-dimensional machine learning\napplications. Our code will be made available as an open-source package upon\nthe publication of this work.",
            "author": [
                "Xuan Zhao",
                "Klaus Broelemann",
                "Gjergji Kasneci"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08228v3",
                "http://arxiv.org/pdf/2311.08228v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08223v2",
            "title": "Improving Image Captioning via Predicting Structured Concepts",
            "updated": "2023-11-28T04:05:03Z",
            "published": "2023-11-14T15:01:58Z",
            "summary": "Having the difficulty of solving the semantic gap between images and texts\nfor the image captioning task, conventional studies in this area paid some\nattention to treating semantic concepts as a bridge between the two modalities\nand improved captioning performance accordingly. Although promising results on\nconcept prediction were obtained, the aforementioned studies normally ignore\nthe relationship among concepts, which relies on not only objects in the image,\nbut also word dependencies in the text, so that offers a considerable potential\nfor improving the process of generating good descriptions. In this paper, we\npropose a structured concept predictor (SCP) to predict concepts and their\nstructures, then we integrate them into captioning, so as to enhance the\ncontribution of visual signals in this task via concepts and further use their\nrelations to distinguish cross-modal semantics for better description\ngeneration. Particularly, we design weighted graph convolutional networks\n(W-GCN) to depict concept relations driven by word dependencies, and then\nlearns differentiated contributions from these concepts for following decoding\nprocess. Therefore, our approach captures potential relations among concepts\nand discriminatively learns different concepts, so that effectively facilitates\nimage captioning with inherited information across modalities. Extensive\nexperiments and their results demonstrate the effectiveness of our approach as\nwell as each proposed module in this work.",
            "author": [
                "Ting Wang",
                "Weidong Chen",
                "Yuanhe Tian",
                "Yan Song",
                "Zhendong Mao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08223v2",
                "http://arxiv.org/pdf/2311.08223v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08217v1",
            "title": "Peer is Your Pillar: A Data-unbalanced Conditional GANs for Few-shot\n  Image Generation",
            "updated": "2023-11-14T14:55:42Z",
            "published": "2023-11-14T14:55:42Z",
            "summary": "Few-shot image generation aims to train generative models using a small\nnumber of training images. When there are few images available for training\n(e.g. 10 images), Learning From Scratch (LFS) methods often generate images\nthat closely resemble the training data while Transfer Learning (TL) methods\ntry to improve performance by leveraging prior knowledge from GANs pre-trained\non large-scale datasets. However, current TL methods may not allow for\nsufficient control over the degree of knowledge preservation from the source\nmodel, making them unsuitable for setups where the source and target domains\nare not closely related. To address this, we propose a novel pipeline called\nPeer is your Pillar (PIP), which combines a target few-shot dataset with a peer\ndataset to create a data-unbalanced conditional generation. Our approach\nincludes a class embedding method that separates the class space from the\nlatent space, and we use a direction loss based on pre-trained CLIP to improve\nimage diversity. Experiments on various few-shot datasets demonstrate the\nadvancement of the proposed PIP, especially reduces the training requirements\nof few-shot image generation.",
            "author": [
                "Ziqiang Li",
                "Chaoyue Wang",
                "Xue Rui",
                "Chao Xue",
                "Jiaxu Leng",
                "Bin Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08217v1",
                "http://arxiv.org/pdf/2311.08217v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08214v1",
            "title": "Frequentist Guarantees of Distributed (Non)-Bayesian Inference",
            "updated": "2023-11-14T14:50:46Z",
            "published": "2023-11-14T14:50:46Z",
            "summary": "Motivated by the need to analyze large, decentralized datasets, distributed\nBayesian inference has become a critical research area across multiple fields,\nincluding statistics, electrical engineering, and economics. This paper\nestablishes Frequentist properties, such as posterior consistency, asymptotic\nnormality, and posterior contraction rates, for the distributed (non-)Bayes\nInference problem among agents connected via a communication network. Our\nresults show that, under appropriate assumptions on the communication graph,\ndistributed Bayesian inference retains parametric efficiency while enhancing\nrobustness in uncertainty quantification. We also explore the trade-off between\nstatistical efficiency and communication efficiency by examining how the design\nand size of the communication graph impact the posterior contraction rate.\nFurthermore, We extend our analysis to time-varying graphs and apply our\nresults to exponential family models, distributed logistic regression, and\ndecentralized detection models.",
            "author": [
                "Bohan Wu",
                "C\u00e9sar A. Uribe"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08214v1",
                "http://arxiv.org/pdf/2311.08214v1"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08213v1",
            "title": "Unlock the Power: Competitive Distillation for Multi-Modal Large\n  Language Models",
            "updated": "2023-11-14T14:49:46Z",
            "published": "2023-11-14T14:49:46Z",
            "summary": "Recently, multi-modal content generation has attracted lots of attention from\nresearchers by investigating the utilization of visual instruction tuning based\non large language models (LLMs). To enhance the performance and generalization\nability of such LLMs, the practice of distilling knowledge from pretrained\nmulti-modal models (a.k.a. teachers) to more compact multi-modal LLMs\n(students) has gained considerable interest. However, the prevailing paradigm\nof instructiontuning in multi-modal LLMs knowledge distillation is\nresource-intensive and unidirectional, neglecting the potential for mutual\nfeedback between the student and teacher models. Thus, we propose an innovative\nCompetitive Multi-modal Distillation framework (CoMD), which captures\nbidirectional feedback between teacher and student models and continually\nupdates the multi-modal capabilities that the student model has learned. It\ncomprises two stages: multi-modal pre-training and multi-modal competitive\ndistillation. The first stage pre-trains the student model on a large number of\nfiltered multi-modal datasets. The second stage facilitates a bidirectional\nknowledge transfer between the student and teacher models. Our experimental\nanalysis of diverse datasets shows that our knowledge transfer method\nconsistently improves the capabilities of the student model. Finally, the\n7B-sized student model after four distillations surpassed the current\nstate-of-the-art model LLaVA-13B on the ScienceQA and LLaVA Test dataset, also\noutperforms other strong baselines in the zero-shot setting.",
            "author": [
                "Xinwei Li",
                "Li Lin",
                "Shuai Wang",
                "Chen Qian"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08213v1",
                "http://arxiv.org/pdf/2311.08213v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08202v1",
            "title": "Federated Skewed Label Learning with Logits Fusion",
            "updated": "2023-11-14T14:37:33Z",
            "published": "2023-11-14T14:37:33Z",
            "summary": "Federated learning (FL) aims to collaboratively train a shared model across\nmultiple clients without transmitting their local data. Data heterogeneity is a\ncritical challenge in realistic FL settings, as it causes significant\nperformance deterioration due to discrepancies in optimization among local\nmodels. In this work, we focus on label distribution skew, a common scenario in\ndata heterogeneity, where the data label categories are imbalanced on each\nclient. To address this issue, we propose FedBalance, which corrects the\noptimization bias among local models by calibrating their logits. Specifically,\nwe introduce an extra private weak learner on the client side, which forms an\nensemble model with the local model. By fusing the logits of the two models,\nthe private weak learner can capture the variance of different data, regardless\nof their category. Therefore, the optimization direction of local models can be\nimproved by increasing the penalty for misclassifying minority classes and\nreducing the attention to majority classes, resulting in a better global model.\nExtensive experiments show that our method can gain 13\\% higher average\naccuracy compared with state-of-the-art methods.",
            "author": [
                "Yuwei Wang",
                "Runhan Li",
                "Hao Tan",
                "Xuefeng Jiang",
                "Sheng Sun",
                "Min Liu",
                "Bo Gao",
                "Zhiyuan Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08202v1",
                "http://arxiv.org/pdf/2311.08202v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.00025v1",
            "title": "Secure Transformer Inference",
            "updated": "2023-11-14T14:37:23Z",
            "published": "2023-11-14T14:37:23Z",
            "summary": "We present a three-party protocol that can protect both Transformer\nparameters and user data during the inference phase. For each feedforward\ninference process, our protocol only introduces permutation computation of\ninput and output data on the user side. Our protocol, Secure Transformer\nInference Protocol (STIP), can be applied to real-world services like ChatGPT.",
            "author": [
                "Mu Yuan",
                "Lan Zhang",
                "Xiang-Yang Li"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00025v1",
                "http://arxiv.org/pdf/2312.00025v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08199v1",
            "title": "Diffusion-based generation of Histopathological Whole Slide Images at a\n  Gigapixel scale",
            "updated": "2023-11-14T14:33:39Z",
            "published": "2023-11-14T14:33:39Z",
            "summary": "We present a novel diffusion-based approach to generate synthetic\nhistopathological Whole Slide Images (WSIs) at an unprecedented gigapixel\nscale. Synthetic WSIs have many potential applications: They can augment\ntraining datasets to enhance the performance of many computational pathology\napplications. They allow the creation of synthesized copies of datasets that\ncan be shared without violating privacy regulations. Or they can facilitate\nlearning representations of WSIs without requiring data annotations. Despite\nthis variety of applications, no existing deep-learning-based method generates\nWSIs at their typically high resolutions. Mainly due to the high computational\ncomplexity. Therefore, we propose a novel coarse-to-fine sampling scheme to\ntackle image generation of high-resolution WSIs. In this scheme, we increase\nthe resolution of an initial low-resolution image to a high-resolution WSI.\nParticularly, a diffusion model sequentially adds fine details to images and\nincreases their resolution. In our experiments, we train our method with WSIs\nfrom the TCGA-BRCA dataset. Additionally to quantitative evaluations, we also\nperformed a user study with pathologists. The study results suggest that our\ngenerated WSIs resemble the structure of real WSIs.",
            "author": [
                "Robert Harb",
                "Thomas Pock",
                "Heimo M\u00fcller"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08199v1",
                "http://arxiv.org/pdf/2311.08199v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG",
                "I.4.9; I.5.4; I.2.10"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08438v1",
            "title": "LocaliseBot: Multi-view 3D object localisation with differentiable\n  rendering for robot grasping",
            "updated": "2023-11-14T14:27:53Z",
            "published": "2023-11-14T14:27:53Z",
            "summary": "Robot grasp typically follows five stages: object detection, object\nlocalisation, object pose estimation, grasp pose estimation, and grasp\nplanning. We focus on object pose estimation. Our approach relies on three\npieces of information: multiple views of the object, the camera's extrinsic\nparameters at those viewpoints, and 3D CAD models of objects. The first step\ninvolves a standard deep learning backbone (FCN ResNet) to estimate the object\nlabel, semantic segmentation, and a coarse estimate of the object pose with\nrespect to the camera. Our novelty is using a refinement module that starts\nfrom the coarse pose estimate and refines it by optimisation through\ndifferentiable rendering. This is a purely vision-based approach that avoids\nthe need for other information such as point cloud or depth images. We evaluate\nour object pose estimation approach on the ShapeNet dataset and show\nimprovements over the state of the art. We also show that the estimated object\npose results in 99.65% grasp accuracy with the ground truth grasp candidates on\nthe Object Clutter Indoor Dataset (OCID) Grasp dataset, as computed using\nstandard practice.",
            "author": [
                "Sujal Vijayaraghavan",
                "Redwan Alqasemi",
                "Rajiv Dubey",
                "Sudeep Sarkar"
            ],
            "link": [
                "http://dx.doi.org/10.1007/978-3-031-25075-0_47",
                "http://arxiv.org/abs/2311.08438v1",
                "http://arxiv.org/pdf/2311.08438v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08190v1",
            "title": "SAMIHS: Adaptation of Segment Anything Model for Intracranial Hemorrhage\n  Segmentation",
            "updated": "2023-11-14T14:23:09Z",
            "published": "2023-11-14T14:23:09Z",
            "summary": "Segment Anything Model (SAM), a vision foundation model trained on\nlarge-scale annotations, has recently continued raising awareness within\nmedical image segmentation. Despite the impressive capabilities of SAM on\nnatural scenes, it struggles with performance decline when confronted with\nmedical images, especially those involving blurry boundaries and highly\nirregular regions of low contrast. In this paper, a SAM-based\nparameter-efficient fine-tuning method, called SAMIHS, is proposed for\nintracranial hemorrhage segmentation, which is a crucial and challenging step\nin stroke diagnosis and surgical planning. Distinguished from previous SAM and\nSAM-based methods, SAMIHS incorporates parameter-refactoring adapters into\nSAM's image encoder and considers the efficient and flexible utilization of\nadapters' parameters. Additionally, we employ a combo loss that combines binary\ncross-entropy loss and boundary-sensitive loss to enhance SAMIHS's ability to\nrecognize the boundary regions. Our experimental results on two public datasets\ndemonstrate the effectiveness of our proposed method. Code is available at\nhttps://github.com/mileswyn/SAMIHS .",
            "author": [
                "Yinuo Wang",
                "Kai Chen",
                "Weimin Yuan",
                "Cai Meng",
                "XiangZhi Bai"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08190v1",
                "http://arxiv.org/pdf/2311.08190v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08185v1",
            "title": "Predicting Dynamic Memory Requirements for Scientific Workflow Tasks",
            "updated": "2023-11-14T14:14:51Z",
            "published": "2023-11-14T14:14:51Z",
            "summary": "With the increasing amount of data available to scientists in disciplines as\ndiverse as bioinformatics, physics, and remote sensing, scientific workflow\nsystems are becoming increasingly important for composing and executing\nscalable data analysis pipelines. When writing such workflows, users need to\nspecify the resources to be reserved for tasks so that sufficient resources are\nallocated on the target cluster infrastructure. Crucially, underestimating a\ntask's memory requirements can result in task failures. Therefore, users often\nresort to overprovisioning, resulting in significant resource wastage and\ndecreased throughput.\n  In this paper, we propose a novel online method that uses monitoring time\nseries data to predict task memory usage in order to reduce the memory wastage\nof scientific workflow tasks. Our method predicts a task's runtime, divides it\ninto k equally-sized segments, and learns the peak memory value for each\nsegment depending on the total file input size. We evaluate the prototype\nimplementation of our method using workflows from the publicly available\nnf-core repository, showing an average memory wastage reduction of 29.48%\ncompared to the best state-of-the-art approach",
            "author": [
                "Jonathan Bader",
                "Nils Diedrich",
                "Lauritz Thamsen",
                "Odej Kao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08185v1",
                "http://arxiv.org/pdf/2311.08185v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08182v1",
            "title": "Self-Evolved Diverse Data Sampling for Efficient Instruction Tuning",
            "updated": "2023-11-14T14:10:40Z",
            "published": "2023-11-14T14:10:40Z",
            "summary": "Enhancing the instruction-following ability of Large Language Models (LLMs)\nprimarily demands substantial instruction-tuning datasets. However, the sheer\nvolume of these imposes a considerable computational burden and annotation\ncost. To investigate a label-efficient instruction tuning method that allows\nthe model itself to actively sample subsets that are equally or even more\neffective, we introduce a self-evolving mechanism DiverseEvol. In this process,\na model iteratively augments its training subset to refine its own performance,\nwithout requiring any intervention from humans or more advanced LLMs. The key\nto our data sampling technique lies in the enhancement of diversity in the\nchosen subsets, as the model selects new data points most distinct from any\nexisting ones according to its current embedding space. Extensive experiments\nacross three datasets and benchmarks demonstrate the effectiveness of\nDiverseEvol. Our models, trained on less than 8% of the original dataset,\nmaintain or improve performance compared with finetuning on full data. We also\nprovide empirical evidence to analyze the importance of diversity in\ninstruction data and the iterative scheme as opposed to one-time sampling. Our\ncode is publicly available at https://github.com/OFA-Sys/DiverseEvol.git.",
            "author": [
                "Shengguang Wu",
                "Keming Lu",
                "Benfeng Xu",
                "Junyang Lin",
                "Qi Su",
                "Chang Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08182v1",
                "http://arxiv.org/pdf/2311.08182v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08179v1",
            "title": "Semi-Supervised Learning via Swapped Prediction for Communication Signal\n  Recognition",
            "updated": "2023-11-14T14:08:55Z",
            "published": "2023-11-14T14:08:55Z",
            "summary": "Deep neural networks have been widely used in communication signal\nrecognition and achieved remarkable performance, but this superiority typically\ndepends on using massive examples for supervised learning, whereas training a\ndeep neural network on small datasets with few labels generally falls into\noverfitting, resulting in degenerated performance. To this end, we develop a\nsemi-supervised learning (SSL) method that effectively utilizes a large\ncollection of more readily available unlabeled signal data to improve\ngeneralization. The proposed method relies largely on a novel implementation of\nconsistency-based regularization, termed Swapped Prediction, which leverages\nstrong data augmentation to perturb an unlabeled sample and then encourage its\ncorresponding model prediction to be close to its original, optimized with a\nscaled cross-entropy loss with swapped symmetry. Extensive experiments indicate\nthat our proposed method can achieve a promising result for deep SSL of\ncommunication signal recognition.",
            "author": [
                "Weidong Wang",
                "Hongshu Liao",
                "Lu Gan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08179v1",
                "http://arxiv.org/pdf/2311.08179v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08177v2",
            "title": "Overcoming the Size Limit of First Principles Molecular Dynamics\n  Simulations with an In-Distribution Substructure Embedding Active Learner",
            "updated": "2023-11-15T03:45:38Z",
            "published": "2023-11-14T14:06:56Z",
            "summary": "Large-scale first principles molecular dynamics are crucial for simulating\ncomplex processes in chemical, biomedical, and materials sciences. However, the\nunfavorable time complexity with respect to system sizes leads to prohibitive\ncomputational costs when the simulation contains over a few hundred atoms in\npractice. We present an In-Distribution substructure Embedding Active Learner\n(IDEAL) to enable efficient simulation of large complex systems with quantum\naccuracy by maintaining a machine learning force field (MLFF) as an accurate\nsurrogate to the first principles methods. By extracting high-uncertainty\nsubstructures into low-uncertainty atom environments, the active learner is\nallowed to concentrate on and learn from small substructures of interest rather\nthan carrying out intractable quantum chemical computations on large\nstructures. IDEAL is benchmarked on various systems and shows sub-linear\ncomplexity, accelerating the simulation thousands of times compared with\nconventional active learning and millions of times compared with pure first\nprinciples simulations. To demonstrate the capability of IDEAL in practical\napplications, we simulated a polycrystalline lithium system composed of one\nmillion atoms and the full ammonia formation process in a Haber-Bosch reaction\non a 3-nm Iridium nanoparticle catalyst on a computing node comprising one\nsingle A100 GPU and 24 CPU cores.",
            "author": [
                "Lingyu Kong",
                "Jielan Li",
                "Lixin Sun",
                "Han Yang",
                "Hongxia Hao",
                "Chi Chen",
                "Nongnuch Artrith",
                "Jose Antonio Garrido Torres",
                "Ziheng Lu",
                "Yichi Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08177v2",
                "http://arxiv.org/pdf/2311.08177v2"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08176v1",
            "title": "A deformation-based morphometry framework for disentangling Alzheimer's\n  disease from normal aging using learned normal aging templates",
            "updated": "2023-11-14T14:04:35Z",
            "published": "2023-11-14T14:04:35Z",
            "summary": "Alzheimer's Disease and normal aging are both characterized by brain atrophy.\nThe question of whether AD-related brain atrophy represents accelerated aging\nor a neurodegeneration process distinct from that in normal aging remains\nunresolved. Moreover, precisely disentangling AD-related brain atrophy from\nnormal aging in a clinical context is complex. In this study, we propose a\ndeformation-based morphometry framework to estimate normal aging and\nAD-specific atrophy patterns of subjects from morphological MRI scans. We first\nleverage deep-learning-based methods to create age-dependent templates of\ncognitively normal (CN) subjects. These templates model the normal aging\natrophy patterns in a CN population. Then, we use the learned diffeomorphic\nregistration to estimate the one-year normal aging pattern at the voxel level.\nWe register the testing image to the 60-year-old CN template in the second\nstep. Finally, normal aging and AD-specific scores are estimated by measuring\nthe alignment of this registration with the one-year normal aging pattern. The\nmethodology was developed and evaluated on the OASIS3 dataset with 1,014\nT1-weighted MRI scans. Of these, 326 scans were from CN subjects, and 688 scans\nwere from individuals clinically diagnosed with AD at different stages of\nclinical severity defined by clinical dementia rating (CDR) scores. The results\nshow that ventricles predominantly follow an accelerated normal aging pattern\nin subjects with AD. In turn, hippocampi and amygdala regions were affected by\nboth normal aging and AD-specific factors. Interestingly, hippocampi and\namygdala regions showed more of an accelerated normal aging pattern for\nsubjects during the early clinical stages of the disease, while the AD-specific\nscore increases in later clinical stages. Our code is freely available at\nhttps://github.com/Fjr9516/DBM_with_DL.",
            "author": [
                "Jingru Fu",
                "Daniel Ferreira",
                "\u00d6rjan Smedby",
                "Rodrigo Moreno"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08176v1",
                "http://arxiv.org/pdf/2311.08176v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08170v1",
            "title": "Neural Lattice Reduction: A Self-Supervised Geometric Deep Learning\n  Approach",
            "updated": "2023-11-14T13:54:35Z",
            "published": "2023-11-14T13:54:35Z",
            "summary": "Lattice reduction is a combinatorial optimization problem aimed at finding\nthe most orthogonal basis in a given lattice. In this work, we address lattice\nreduction via deep learning methods. We design a deep neural model outputting\nfactorized unimodular matrices and train it in a self-supervised manner by\npenalizing non-orthogonal lattice bases. We incorporate the symmetries of\nlattice reduction into the model by making it invariant and equivariant with\nrespect to appropriate continuous and discrete groups.",
            "author": [
                "Giovanni Luca Marchetti",
                "Gabriele Cesa",
                "Kumar Pratik",
                "Arash Behboodi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08170v1",
                "http://arxiv.org/pdf/2311.08170v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.DM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08169v1",
            "title": "Modeling ionic flow between small targets: insights from diffusion and\n  electro-diffusion theory",
            "updated": "2023-11-14T13:49:47Z",
            "published": "2023-11-14T13:49:47Z",
            "summary": "The flow of ions through permeable channels causes voltage drop in\nphysiological nanodomains such as synapses, dendrites and dendritic spines, and\nother protrusions. How the voltage changes around channels in these nanodomains\nhas remained poorly studied. We focus this book chapter on summarizing recent\nefforts in computing the steady-state current, voltage and ionic concentration\ndistributions based on the Poisson-Nernst-Planck equations as a model of\nelectro-diffusion. We first consider the spatial distribution of an uncharged\nparticle density and derive asymptotic formulas for the concentration\ndifference by solving the Laplace's equation with mixed boundary conditions. We\nstudy a constant particles injection rate modeled by a Neumann flux condition\nat a channel represented by a small boundary target, while the injected\nparticles can exit at one or several narrow patches. We then discuss the case\nof two species (positive and negative charges) and take into account motions\ndue to both concentration and electrochemical gradients. The voltage resulting\nfrom charge interactions is calculated by solving the Poisson's equation. We\nshow how deep an influx diffusion propagates inside a nanodomain, for\npopulations of both uncharged and charged particles. We estimate the\nconcentration and voltage changes in relations with geometrical parameters and\nquantify the impact of membrane curvature.",
            "author": [
                "Fr\u00e9d\u00e9ric Paquin-Lefebvre",
                "David Holcman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08169v1",
                "http://arxiv.org/pdf/2311.08169v1"
            ],
            "primary_category": "cond-mat.soft",
            "category": [
                "cond-mat.soft",
                "math.AP",
                "q-bio.SC",
                "35J05, 35J08, 35J25"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08168v1",
            "title": "Time-Uniform Confidence Spheres for Means of Random Vectors",
            "updated": "2023-11-14T13:49:46Z",
            "published": "2023-11-14T13:49:46Z",
            "summary": "We derive and study time-uniform confidence spheres - termed confidence\nsphere sequences (CSSs) - which contain the mean of random vectors with high\nprobability simultaneously across all sample sizes. Inspired by the original\nwork of Catoni and Giulini, we unify and extend their analysis to cover both\nthe sequential setting and to handle a variety of distributional assumptions.\nMore concretely, our results include an empirical-Bernstein CSS for bounded\nrandom vectors (resulting in a novel empirical-Bernstein confidence interval),\na CSS for sub-$\\psi$ random vectors, and a CSS for heavy-tailed random vectors\nbased on a sequentially valid Catoni-Giulini estimator. Finally, we provide a\nversion of our empirical-Bernstein CSS that is robust to contamination by Huber\nnoise.",
            "author": [
                "Ben Chugg",
                "Hongjian Wang",
                "Aaditya Ramdas"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08168v1",
                "http://arxiv.org/pdf/2311.08168v1"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "cs.IT",
                "math.IT",
                "stat.ME",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08166v1",
            "title": "MechAgents: Large language model multi-agent collaborations can solve\n  mechanics problems, generate new data, and integrate knowledge",
            "updated": "2023-11-14T13:49:03Z",
            "published": "2023-11-14T13:49:03Z",
            "summary": "Solving mechanics problems using numerical methods requires comprehensive\nintelligent capability of retrieving relevant knowledge and theory,\nconstructing and executing codes, analyzing the results, a task that has thus\nfar mainly been reserved for humans. While emerging AI methods can provide\neffective approaches to solve end-to-end problems, for instance via the use of\ndeep surrogate models or various data analytics strategies, they often lack\nphysical intuition since knowledge is baked into the parametric complement\nthrough training, offering less flexibility when it comes to incorporating\nmathematical or physical insights. By leveraging diverse capabilities of\nmultiple dynamically interacting large language models (LLMs), we can overcome\nthe limitations of conventional approaches and develop a new class of\nphysics-inspired generative machine learning platform, here referred to as\nMechAgents. A set of AI agents can solve mechanics tasks, here demonstrated for\nelasticity problems, via autonomous collaborations. A two-agent team can\neffectively write, execute and self-correct code, in order to apply finite\nelement methods to solve classical elasticity problems in various flavors\n(different boundary conditions, domain geometries, meshes, small/finite\ndeformation and linear/hyper-elastic constitutive laws, and others). For more\ncomplex tasks, we construct a larger group of agents with enhanced division of\nlabor among planning, formulating, coding, executing and criticizing the\nprocess and results. The agents mutually correct each other to improve the\noverall team-work performance in understanding, formulating and validating the\nsolution. Our framework shows the potential of synergizing the intelligence of\nlanguage models, the reliability of physics-based modeling, and the dynamic\ncollaborations among diverse agents, opening novel avenues for automation of\nsolving engineering problems.",
            "author": [
                "Bo Ni",
                "Markus J. Buehler"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08166v1",
                "http://arxiv.org/pdf/2311.08166v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cond-mat.dis-nn",
                "cond-mat.mtrl-sci",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08159v1",
            "title": "DynamicSurf: Dynamic Neural RGB-D Surface Reconstruction with an\n  Optimizable Feature Grid",
            "updated": "2023-11-14T13:39:01Z",
            "published": "2023-11-14T13:39:01Z",
            "summary": "We propose DynamicSurf, a model-free neural implicit surface reconstruction\nmethod for high-fidelity 3D modelling of non-rigid surfaces from monocular\nRGB-D video. To cope with the lack of multi-view cues in monocular sequences of\ndeforming surfaces, one of the most challenging settings for 3D reconstruction,\nDynamicSurf exploits depth, surface normals, and RGB losses to improve\nreconstruction fidelity and optimisation time. DynamicSurf learns a neural\ndeformation field that maps a canonical representation of the surface geometry\nto the current frame. We depart from current neural non-rigid surface\nreconstruction models by designing the canonical representation as a learned\nfeature grid which leads to faster and more accurate surface reconstruction\nthan competing approaches that use a single MLP. We demonstrate DynamicSurf on\npublic datasets and show that it can optimize sequences of varying frames with\n$6\\times$ speedup over pure MLP-based approaches while achieving comparable\nresults to the state-of-the-art methods. Project is available at\nhttps://mirgahney.github.io//DynamicSurf.io/.",
            "author": [
                "Mirgahney Mohamed",
                "Lourdes Agapito"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08159v1",
                "http://arxiv.org/pdf/2311.08159v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08158v1",
            "title": "Channel Estimation with Dynamic Metasurface Antennas via Model-Based\n  Learning",
            "updated": "2023-11-14T13:38:55Z",
            "published": "2023-11-14T13:38:55Z",
            "summary": "Dynamic Metasurface Antenna (DMA) is a cutting-edge antenna technology\noffering scalable and sustainable solutions for large antenna arrays. The\neffectiveness of DMAs stems from their inherent configurable analog signal\nprocessing capabilities, which facilitate cost-limited implementations.\nHowever, when DMAs are used in multiple input multiple output (MIMO)\ncommunication systems, they pose challenges in channel estimation due to their\nanalog compression. In this paper, we propose two model-based learning methods\nto overcome this challenge. Our approach starts by casting channel estimation\nas a compressed sensing problem. Here, the sensing matrix is formed using a\nrandom DMA weighting matrix combined with a spatial gridding dictionary. We\nthen employ the learned iterative shrinkage and thresholding algorithm (LISTA)\nto recover the sparse channel parameters. LISTA unfolds the iterative shrinkage\nand thresholding algorithm into a neural network and trains the neural network\ninto a highly efficient channel estimator fitting with the previous channel. As\nthe sensing matrix is crucial to the accuracy of LISTA recovery, we introduce\nanother data-aided method, LISTA-sensing matrix optimization (LISTA-SMO), to\njointly optimize the sensing matrix. LISTA-SMO takes LISTA as a backbone and\nembeds the sensing matrix optimization layers in LISTA's neural network,\nallowing for the optimization of the sensing matrix along with the training of\nLISTA. Furthermore, we propose a self-supervised learning technique to tackle\nthe difficulty of acquiring noise-free data. Our numerical results demonstrate\nthat LISTA outperforms traditional sparse recovery methods regarding channel\nestimation accuracy and efficiency. Besides, LISTA-SMO achieves better channel\naccuracy than LISTA, demonstrating the effectiveness in optimizing the sensing\nmatrix.",
            "author": [
                "Xiangyu Zhang",
                "Haiyang Zhang",
                "Luxi Yang",
                "Yonina C. Eldar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08158v1",
                "http://arxiv.org/pdf/2311.08158v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "cs.NI",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08153v1",
            "title": "When Mining Electric Locomotives Meet Reinforcement Learning",
            "updated": "2023-11-14T13:29:01Z",
            "published": "2023-11-14T13:29:01Z",
            "summary": "As the most important auxiliary transportation equipment in coal mines,\nmining electric locomotives are mostly operated manually at present. However,\ndue to the complex and ever-changing coal mine environment, electric locomotive\nsafety accidents occur frequently these years. A mining electric locomotive\ncontrol method that can adapt to different complex mining environments is\nneeded. Reinforcement Learning (RL) is concerned with how artificial agents\nought to take actions in an environment so as to maximize reward, which can\nhelp achieve automatic control of mining electric locomotive. In this paper, we\npresent how to apply RL to the autonomous control of mining electric\nlocomotives. To achieve more precise control, we further propose an improved\nepsilon-greedy (IEG) algorithm which can better balance the exploration and\nexploitation. To verify the effectiveness of this method, a co-simulation\nplatform for autonomous control of mining electric locomotives is built which\ncan complete closed-loop simulation of the vehicles. The simulation results\nshow that this method ensures the locomotives following the front vehicle\nsafely and responding promptly in the event of sudden obstacles on the road\nwhen the vehicle in complex and uncertain coal mine environments.",
            "author": [
                "Ying Li",
                "Zhencai Zhu",
                "Xiaoqiang Li",
                "Chunyu Yang",
                "Hao Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08153v1",
                "http://arxiv.org/pdf/2311.08153v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.AI",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08150v1",
            "title": "The Hyperdimensional Transform for Distributional Modelling, Regression\n  and Classification",
            "updated": "2023-11-14T13:26:49Z",
            "published": "2023-11-14T13:26:49Z",
            "summary": "Hyperdimensional computing (HDC) is an increasingly popular computing\nparadigm with immense potential for future intelligent applications. Although\nthe main ideas already took form in the 1990s, HDC recently gained significant\nattention, especially in the field of machine learning and data science. Next\nto efficiency, interoperability and explainability, HDC offers attractive\nproperties for generalization as it can be seen as an attempt to combine\nconnectionist ideas from neural networks with symbolic aspects. In recent work,\nwe introduced the hyperdimensional transform, revealing deep theoretical\nfoundations for representing functions and distributions as high-dimensional\nholographic vectors. Here, we present the power of the hyperdimensional\ntransform to a broad data science audience. We use the hyperdimensional\ntransform as a theoretical basis and provide insight into state-of-the-art HDC\napproaches for machine learning. We show how existing algorithms can be\nmodified and how this transform can lead to a novel, well-founded toolbox. Next\nto the standard regression and classification tasks of machine learning, our\ndiscussion includes various aspects of statistical modelling, such as\nrepresentation, learning and deconvolving distributions, sampling, Bayesian\ninference, and uncertainty estimation.",
            "author": [
                "Pieter Dewulf",
                "Bernard De Baets",
                "Michiel Stock"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08150v1",
                "http://arxiv.org/pdf/2311.08150v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.AR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08148v1",
            "title": "Cattle Identification Using Muzzle Images and Deep Learning Techniques",
            "updated": "2023-11-14T13:25:41Z",
            "published": "2023-11-14T13:25:41Z",
            "summary": "Traditional animal identification methods such as ear-tagging, ear notching,\nand branding have been effective but pose risks to the animal and have\nscalability issues. Electrical methods offer better tracking and monitoring but\nrequire specialized equipment and are susceptible to attacks. Biometric\nidentification using time-immutable dermatoglyphic features such as muzzle\nprints and iris patterns is a promising solution. This project explores cattle\nidentification using 4923 muzzle images collected from 268 beef cattle. Two\ndeep learning classification models are implemented - wide ResNet50 and\nVGG16\\_BN and image compression is done to lower the image quality and adapt\nthe models to work for the African context. From the experiments run, a maximum\naccuracy of 99.5\\% is achieved while using the wide ResNet50 model with a\ncompression retaining 25\\% of the original image. From the study, it is noted\nthat the time required by the models to train and converge as well as\nrecognition time are dependent on the machine used to run the model.",
            "author": [
                "G. N. Kimani",
                "P. Oluwadara",
                "P. Fashingabo",
                "M. Busogi",
                "E. Luhanga",
                "K. Sowon",
                "L. Chacha"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08148v1",
                "http://arxiv.org/pdf/2311.08148v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08149v2",
            "title": "Modeling Complex Disease Trajectories using Deep Generative Models with\n  Semi-Supervised Latent Processes",
            "updated": "2023-11-17T11:51:18Z",
            "published": "2023-11-14T13:25:41Z",
            "summary": "In this paper, we propose a deep generative time series approach using latent\ntemporal processes for modeling and holistically analyzing complex disease\ntrajectories. We aim to find meaningful temporal latent representations of an\nunderlying generative process that explain the observed disease trajectories in\nan interpretable and comprehensive way. To enhance the interpretability of\nthese latent temporal processes, we develop a semi-supervised approach for\ndisentangling the latent space using established medical concepts. By combining\nthe generative approach with medical knowledge, we leverage the ability to\ndiscover novel aspects of the disease while integrating medical concepts into\nthe model. We show that the learned temporal latent processes can be utilized\nfor further data analysis and clinical hypothesis testing, including finding\nsimilar patients and clustering the disease into new sub-types. Moreover, our\nmethod enables personalized online monitoring and prediction of multivariate\ntime series including uncertainty quantification. We demonstrate the\neffectiveness of our approach in modeling systemic sclerosis, showcasing the\npotential of our machine learning model to capture complex disease trajectories\nand acquire new medical knowledge.",
            "author": [
                "C\u00e9cile Trottet",
                "Manuel Sch\u00fcrch",
                "Ahmed Allam",
                "Imon Barua",
                "Liubov Petelytska",
                "Oliver Distler",
                "Anna-Maria Hoffmann-Vold",
                "Michael Krauthammer",
                "the EUSTAR collaborators"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08149v2",
                "http://arxiv.org/pdf/2311.08149v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.17924v1",
            "title": "Unrolling Virtual Worlds for Immersive Experiences",
            "updated": "2023-11-14T13:16:34Z",
            "published": "2023-11-14T13:16:34Z",
            "summary": "This research pioneers a method for generating immersive worlds, drawing\ninspiration from elements of vintage adventure games like Myst and employing\nmodern text-to-image models. We explore the intricate conversion of 2D\npanoramas into 3D scenes using equirectangular projections, addressing the\ndistortions in perception that occur as observers navigate within the\nencompassing sphere. Our approach employs a technique similar to \"inpainting\"\nto rectify distorted projections, enabling the smooth construction of locally\ncoherent worlds. This provides extensive insight into the interrelation of\ntechnology, perception, and experiential reality within human-computer\ninteraction.",
            "author": [
                "Alexey Tikhonov",
                "Anton Repushko"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17924v1",
                "http://arxiv.org/pdf/2311.17924v1"
            ],
            "primary_category": "cs.GR",
            "category": [
                "cs.GR",
                "cs.HC",
                "cs.LG",
                "cs.MM",
                "68U05, 00A66, 68T45, 91C99, 68U35, 94A08",
                "I.2.6; I.3.7; H.5.1; I.3.3; J.5"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08141v1",
            "title": "GMTR: Graph Matching Transformers",
            "updated": "2023-11-14T13:12:47Z",
            "published": "2023-11-14T13:12:47Z",
            "summary": "Vision transformers (ViTs) have recently been used for visual matching beyond\nobject detection and segmentation. However, the original grid dividing strategy\nof ViTs neglects the spatial information of the keypoints, limiting the\nsensitivity to local information. Therefore, we propose \\textbf{QueryTrans}\n(Query Transformer), which adopts a cross-attention module and keypoints-based\ncenter crop strategy for better spatial information extraction. We further\nintegrate the graph attention module and devise a transformer-based graph\nmatching approach \\textbf{GMTR} (Graph Matching TRansformers) whereby the\ncombinatorial nature of GM is addressed by a graph transformer neural GM\nsolver. On standard GM benchmarks, GMTR shows competitive performance against\nthe SOTA frameworks. Specifically, on Pascal VOC, GMTR achieves\n$\\mathbf{83.6\\%}$ accuracy, $\\mathbf{0.9\\%}$ higher than the SOTA framework. On\nSpair-71k, GMTR shows great potential and outperforms most of the previous\nworks. Meanwhile, on Pascal VOC, QueryTrans improves the accuracy of NGMv2 from\n$80.1\\%$ to $\\mathbf{83.3\\%}$, and BBGM from $79.0\\%$ to $\\mathbf{84.5\\%}$. On\nSpair-71k, QueryTrans improves NGMv2 from $80.6\\%$ to $\\mathbf{82.5\\%}$, and\nBBGM from $82.1\\%$ to $\\mathbf{83.9\\%}$. Source code will be made publicly\navailable.",
            "author": [
                "Jinpei Guo",
                "Shaofeng Zhang",
                "Runzhong Wang",
                "Chang Liu",
                "Junchi Yan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08141v1",
                "http://arxiv.org/pdf/2311.08141v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08139v1",
            "title": "Feedforward neural networks as statistical models: Improving\n  interpretability through uncertainty quantification",
            "updated": "2023-11-14T13:08:58Z",
            "published": "2023-11-14T13:08:58Z",
            "summary": "Feedforward neural networks (FNNs) are typically viewed as pure prediction\nalgorithms, and their strong predictive performance has led to their use in\nmany machine-learning applications. However, their flexibility comes with an\ninterpretability trade-off; thus, FNNs have been historically less popular\namong statisticians. Nevertheless, classical statistical theory, such as\nsignificance testing and uncertainty quantification, is still relevant.\nSupplementing FNNs with methods of statistical inference, and covariate-effect\nvisualisations, can shift the focus away from black-box prediction and make\nFNNs more akin to traditional statistical models. This can allow for more\ninferential analysis, and, hence, make FNNs more accessible within the\nstatistical-modelling context.",
            "author": [
                "Andrew McInerney",
                "Kevin Burke"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08139v1",
                "http://arxiv.org/pdf/2311.08139v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.ML",
                "62J02, 68T07, 62F03"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08134v1",
            "title": "Applying hybrid clustering in pulsar candidate sifting with\n  multi-modality for FAST survey",
            "updated": "2023-11-14T13:00:40Z",
            "published": "2023-11-14T13:00:40Z",
            "summary": "Pulsar search is always the basis of pulsar navigation, gravitational wave\ndetection and other research topics. Currently, the volume of pulsar candidates\ncollected by Five-hundred-meter Aperture Spherical radio Telescope (FAST) shows\nan explosive growth rate that has brought challenges for its pulsar candidate\nfiltering System. Particularly, the multi-view heterogeneous data and class\nimbalance between true pulsars and non-pulsar candidates have negative effects\non traditional single-modal supervised classification methods. In this study, a\nmulti-modal and semi-supervised learning based pulsar candidate sifting\nalgorithm is presented, which adopts a hybrid ensemble clustering scheme of\ndensity-based and partition-based methods combined with a feature-level fusion\nstrategy for input data and a data partition strategy for parallelization.\nExperiments on both HTRU (The High Time Resolution Universe Survey) 2 and FAST\nactual observation data demonstrate that the proposed algorithm could\nexcellently identify the pulsars: On HTRU2, the precision and recall rates of\nits parallel mode reach 0.981 and 0.988. On FAST data, those of its parallel\nmode reach 0.891 and 0.961, meanwhile, the running time also significantly\ndecrease with the increment of parallel nodes within limits. So, we can get the\nconclusion that our algorithm could be a feasible idea for large scale pulsar\ncandidate sifting of FAST drift scan observation.",
            "author": [
                "Zi-Yi You",
                "Yun-Rong Pan",
                "Zhi Ma",
                "Li Zhang",
                "Shuo Xiao",
                "Dan-Dan Zhang",
                "Shi-Jun Dang",
                "Ru-Shuang Zhao",
                "Pei Wang",
                "Ai-Jun Dong",
                "Jia-Tao Jiang",
                "Ji-Bing Leng",
                "Wei-An Li",
                "Si-Yao Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08134v1",
                "http://arxiv.org/pdf/2311.08134v1"
            ],
            "primary_category": "astro-ph.IM",
            "category": [
                "astro-ph.IM",
                "astro-ph.HE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08129v1",
            "title": "Learning based Deep Disentangling Light Field Reconstruction and\n  Disparity Estimation Application",
            "updated": "2023-11-14T12:48:17Z",
            "published": "2023-11-14T12:48:17Z",
            "summary": "Light field cameras have a wide range of uses due to their ability to\nsimultaneously record light intensity and direction. The angular resolution of\nlight fields is important for downstream tasks such as depth estimation, yet is\noften difficult to improve due to hardware limitations. Conventional methods\ntend to perform poorly against the challenge of large disparity in sparse light\nfields, while general CNNs have difficulty extracting spatial and angular\nfeatures coupled together in 4D light fields. The light field disentangling\nmechanism transforms the 4D light field into 2D image format, which is more\nfavorable for CNN for feature extraction. In this paper, we propose a Deep\nDisentangling Mechanism, which inherits the principle of the light field\ndisentangling mechanism and further develops the design of the feature\nextractor and adds advanced network structure. We design a light-field\nreconstruction network (i.e., DDASR) on the basis of the Deep Disentangling\nMechanism, and achieve SOTA performance in the experiments. In addition, we\ndesign a Block Traversal Angular Super-Resolution Strategy for the practical\napplication of depth estimation enhancement where the input views is often\nhigher than 2x2 in the experiments resulting in a high memory usage, which can\nreduce the memory usage while having a better reconstruction performance.",
            "author": [
                "Langqing Shi",
                "Ping Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08129v1",
                "http://arxiv.org/pdf/2311.08129v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08125v1",
            "title": "Lite it fly: An All-Deformable-Butterfly Network",
            "updated": "2023-11-14T12:41:22Z",
            "published": "2023-11-14T12:41:22Z",
            "summary": "Most deep neural networks (DNNs) consist fundamentally of convolutional\nand/or fully connected layers, wherein the linear transform can be cast as the\nproduct between a filter matrix and a data matrix obtained by arranging feature\ntensors into columns. The lately proposed deformable butterfly (DeBut)\ndecomposes the filter matrix into generalized, butterflylike factors, thus\nachieving network compression orthogonal to the traditional ways of pruning or\nlow-rank decomposition. This work reveals an intimate link between DeBut and a\nsystematic hierarchy of depthwise and pointwise convolutions, which explains\nthe empirically good performance of DeBut layers. By developing an automated\nDeBut chain generator, we show for the first time the viability of homogenizing\na DNN into all DeBut layers, thus achieving an extreme sparsity and\ncompression. Various examples and hardware benchmarks verify the advantages of\nAll-DeBut networks. In particular, we show it is possible to compress a\nPointNet to < 5% parameters with < 5% accuracy drop, a record not achievable by\nother compression schemes.",
            "author": [
                "Rui Lin",
                "Jason Chun Lok Li",
                "Jiajun Zhou",
                "Binxiao Huang",
                "Jie Ran",
                "Ngai Wong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08125v1",
                "http://arxiv.org/pdf/2311.08125v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08123v1",
            "title": "Memory-efficient Stochastic methods for Memory-based Transformers",
            "updated": "2023-11-14T12:37:25Z",
            "published": "2023-11-14T12:37:25Z",
            "summary": "Training Memory-based transformers can require a large amount of memory and\ncan be quite inefficient. We propose a novel two-phase training mechanism and a\nnovel regularization technique to improve the training efficiency of\nmemory-based transformers, which are often used for long-range context\nproblems. For our experiments, we consider transformer-XL as our baseline model\nwhich is one of memorybased transformer models. We show that our resultant\nmodel, Skip Cross-head TransformerXL, outperforms the baseline on character\nlevel language modeling task with similar parameters and outperforms the\nbaseline on word level language modelling task with almost 20% fewer\nparameters. Our proposed methods do not require any additional memory. We also\ndemonstrate the effectiveness of our regularization mechanism on BERT which\nshows similar performance with reduction in standard deviation of scores of\naround 30% on multiple GLUE tasks.",
            "author": [
                "Vishwajit Kumar Vishnu",
                "C. Chandra Sekhar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08123v1",
                "http://arxiv.org/pdf/2311.08123v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08120v1",
            "title": "Caring Trouble and Musical AI: Considerations towards a Feminist Musical\n  AI",
            "updated": "2023-11-14T12:35:17Z",
            "published": "2023-11-14T12:35:17Z",
            "summary": "The ethics of AI as both material and medium for interaction remains in murky\nwaters within the context of musical and artistic practice. The\ninterdisciplinarity of the field is revealing matters of concern and care,\nwhich necessitate interdisciplinary methodologies for evaluation to trouble and\ncritique the inheritance of \"residue-laden\" AI-tools in musical applications.\nSeeking to unsettle these murky waters, this paper critically examines the\nexample of Holly+, a deep neural network that generates raw audio in the\nlikeness of its creator Holly Herndon. Drawing from theoretical concerns and\nconsiderations from speculative feminism and care ethics, we care-fully trouble\nthe structures, frameworks and assumptions that oscillate within and around\nHolly+. We contribute with several considerations and contemplate future\ndirections for integrating speculative feminism and care into musical-AI agent\nand system design, derived from our critical feminist examination.",
            "author": [
                "Kelsey Cotton",
                "K\u0131van\u00e7 Tatar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08120v1",
                "http://arxiv.org/pdf/2311.08120v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08118v1",
            "title": "Evaluating Neighbor Explainability for Graph Neural Networks",
            "updated": "2023-11-14T12:33:19Z",
            "published": "2023-11-14T12:33:19Z",
            "summary": "Explainability in Graph Neural Networks (GNNs) is a new field growing in the\nlast few years. In this publication we address the problem of determining how\nimportant is each neighbor for the GNN when classifying a node and how to\nmeasure the performance for this specific task. To do this, various known\nexplainability methods are reformulated to get the neighbor importance and four\nnew metrics are presented. Our results show that there is almost no difference\nbetween the explanations provided by gradient-based techniques in the GNN\ndomain. In addition, many explainability techniques failed to identify\nimportant neighbors when GNNs without self-loops are used.",
            "author": [
                "Oscar Llorente",
                "P\u00e9ter Vaderna",
                "S\u00e1ndor Laki",
                "Roland Kotrocz\u00f3",
                "Rita Csoma",
                "J\u00e1nos M\u00e1rk Szalai-Gindl"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08118v1",
                "http://arxiv.org/pdf/2311.08118v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08116v1",
            "title": "Smart Skin separation control using distributed-input\n  distributed-output, multi-modal actuators, and machine learning",
            "updated": "2023-11-14T12:28:48Z",
            "published": "2023-11-14T12:28:48Z",
            "summary": "Efficient flow separation control represents significant economic benefit.\nThis study applies a machine learning algorithm to minimize flow separation in\nSmart Skin, a flow control device that features distributed-input and\ndistributed-output (DIDO). Smart Skin comprises 30 hybrid actuator units, each\nintegrating a height-adjustable vortex generator and a mini-jet actuator. These\nunits are deployed on a backward-facing ramp to reduce flow separation in a\ndistributed manner. To monitor the flow state, distributed pressure taps are\ndeployed around the multi-modal actuators. Parametric studies indicate that the\nmapping between control parameters and separation control performance is\ncomplex. To optimize separation control, a cutting-edge variant of the particle\nswarm optimization (PSO-TPME) is used for the control parameters in the Smart\nSkin. This algorithm is capable of achieving fast optimization in\nhigh-dimensional parameter spaces. The results demonstrate the efficiency of\nPSO-TPME, and the optimized solution significantly outperforms the best result\nfrom the parametric study. These findings represent a promising future of\nmachine learning-based flow control using distributed actuators and sensors.",
            "author": [
                "Songqi Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08116v1",
                "http://arxiv.org/pdf/2311.08116v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY",
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08115v1",
            "title": "Stochastic Optimization of Large-Scale Parametrized Dynamical Systems",
            "updated": "2023-11-14T12:25:57Z",
            "published": "2023-11-14T12:25:57Z",
            "summary": "Many relevant problems in the area of systems and control, such as controller\nsynthesis, observer design and model reduction, can be viewed as optimization\nproblems involving dynamical systems: for instance, maximizing performance in\nthe synthesis setting or minimizing error in the reduction setting. When the\ninvolved dynamics are large-scale (e.g., high-dimensional semi-discretizations\nof partial differential equations), the optimization becomes computationally\ninfeasible. Existing methods in literature lack computational scalability or\nsolve an approximation of the problem (thereby losing guarantees with respect\nto the original problem). In this paper, we propose a novel method that\ncircumvents these issues. The method is an extension of Stochastic Gradient\nDescent (SGD) which is widely used in the context of large-scale machine\nlearning problems. The proposed SGD scheme minimizes the $\\mathcal{H}_2$ norm\nof a (differentiable) parametrized dynamical system, and we prove that the\nscheme is guaranteed to preserve stability with high probability under\nboundedness conditions on the step size. Conditioned on the stability\npreservation, we also obtain probabilistic convergence guarantees to local\nminimizers. The method is also applicable to problems involving non-realizable\ndynamics as it only requires frequency-domain input-output samples. We\ndemonstrate the potential of the approach on two numerical examples:\nfixed-order observer design for a large-scale thermal model and controller\ntuning for an infinite-dimensional system.",
            "author": [
                "Pascal Den Boef",
                "Jos Maubach",
                "Wil Schilders",
                "Nathan van de Wouw"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08115v1",
                "http://arxiv.org/pdf/2311.08115v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08113v1",
            "title": "Understanding learning from EEG data: Combining machine learning and\n  feature engineering based on hidden Markov models and mixed models",
            "updated": "2023-11-14T12:24:12Z",
            "published": "2023-11-14T12:24:12Z",
            "summary": "Theta oscillations, ranging from 4-8 Hz, play a significant role in spatial\nlearning and memory functions during navigation tasks. Frontal theta\noscillations are thought to play an important role in spatial navigation and\nmemory. Electroencephalography (EEG) datasets are very complex, making any\nchanges in the neural signal related to behaviour difficult to interpret.\nHowever, multiple analytical methods are available to examine complex data\nstructure, especially machine learning based techniques. These methods have\nshown high classification performance and the combination with feature\nengineering enhances the capability of these methods. This paper proposes using\nhidden Markov and linear mixed effects models to extract features from EEG\ndata. Based on the engineered features obtained from frontal theta EEG data\nduring a spatial navigation task in two key trials (first, last) and between\ntwo conditions (learner and non-learner), we analysed the performance of six\nmachine learning methods (Polynomial Support Vector Machines, Non-linear\nSupport Vector Machines, Random Forests, K-Nearest Neighbours, Ridge, and Deep\nNeural Networks) on classifying learner and non-learner participants. We also\nanalysed how different standardisation methods used to pre-process the EEG data\ncontribute to classification performance. We compared the classification\nperformance of each trial with data gathered from the same subjects, including\nsolely coordinate-based features, such as idle time and average speed. We found\nthat more machine learning methods perform better classification using\ncoordinate-based data. However, only deep neural networks achieved an area\nunder the ROC curve higher than 80% using the theta EEG data alone. Our\nfindings suggest that standardising the theta EEG data and using deep neural\nnetworks enhances the classification of learner and non-learner subjects in a\nspatial learning task.",
            "author": [
                "Gabriel Rodrigues Palma",
                "Conor Thornberry",
                "Se\u00e1n Commins",
                "Rafael de Andrade Moral"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08113v1",
                "http://arxiv.org/pdf/2311.08113v1"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM",
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08112v1",
            "title": "Reconfigurable Intelligent Surface for Physical Layer Security in\n  6G-IoT: Designs, Issues, and Advances",
            "updated": "2023-11-14T12:24:07Z",
            "published": "2023-11-14T12:24:07Z",
            "summary": "Sixth-generation (6G) networks pose substantial security risks because\nconfidential information is transmitted over wireless channels with a broadcast\nnature, and various attack vectors emerge. Physical layer security (PLS)\nexploits the dynamic characteristics of wireless environments to provide secure\ncommunications, while reconfigurable intelligent surfaces (RISs) can facilitate\nPLS by controlling wireless transmissions. With RIS-aided PLS, a lightweight\nsecurity solution can be designed for low-end Internet of Things (IoT) devices,\ndepending on the design scenario and communication objective. This article\ndiscusses RIS-aided PLS designs for 6G-IoT networks against eavesdropping and\njamming attacks. The theoretical background and literature review of RIS-aided\nPLS are discussed, and design solutions related to resource allocation,\nbeamforming, artificial noise, and cooperative communication are presented. We\nprovide simulation results to show the effectiveness of RIS in terms of PLS. In\naddition, we examine the research issues and possible solutions for RIS\nmodeling, channel modeling and estimation, optimization, and machine learning.\nFinally, we discuss recent advances, including STAR-RIS and malicious RIS.",
            "author": [
                "Waqas Khalid",
                "M. Atif Ur Rehman",
                "Trinh Van Chien",
                "Zeeshan Kaleem",
                "Howon Lee",
                "Heejung Yu"
            ],
            "link": [
                "http://dx.doi.org/10.1109/JIOT.2023.3297241",
                "http://arxiv.org/abs/2311.08112v1",
                "http://arxiv.org/pdf/2311.08112v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "10.1109/JIOT.2023.3297241"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08110v1",
            "title": "Improving hateful memes detection via learning hatefulness-aware\n  embedding space through retrieval-guided contrastive learning",
            "updated": "2023-11-14T12:14:54Z",
            "published": "2023-11-14T12:14:54Z",
            "summary": "Hateful memes have emerged as a significant concern on the Internet. These\nmemes, which are a combination of image and text, often convey messages vastly\ndifferent from their individual meanings. Thus, detecting hateful memes\nrequires the system to jointly understand the visual and textual modalities.\nHowever, our investigation reveals that the embedding space of existing\nCLIP-based systems lacks sensitivity to subtle differences in memes that are\nvital for correct hatefulness classification. To address this issue, we propose\nconstructing a hatefulness-aware embedding space through retrieval-guided\ncontrastive training. Specifically, we add an auxiliary loss that utilizes hard\nnegative and pseudo-gold samples to train the embedding space. Our approach\nachieves state-of-the-art performance on the HatefulMemes dataset with an AUROC\nof 86.7. Notably, our approach outperforms much larger fine-tuned Large\nMultimodal Models like Flamingo and LLaVA. Finally, we demonstrate a\nretrieval-based hateful memes detection system, which is capable of making\nhatefulness classification based on data unseen in training from a database.\nThis allows developers to update the hateful memes detection system by simply\nadding new data without retraining, a desirable feature for real services in\nthe constantly-evolving landscape of hateful memes on the Internet.",
            "author": [
                "Jingbiao Mei",
                "Jinghong Chen",
                "Weizhe Lin",
                "Bill Byrne",
                "Marcus Tomalin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08110v1",
                "http://arxiv.org/pdf/2311.08110v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08107v1",
            "title": "SAIE Framework: Support Alone Isn't Enough -- Advancing LLM Training\n  with Adversarial Remarks",
            "updated": "2023-11-14T12:12:25Z",
            "published": "2023-11-14T12:12:25Z",
            "summary": "Large Language Models (LLMs) can justify or criticize their predictions\nthrough discussion with other models or humans, thereby enhancing their\nintrinsic understanding of instances. While proactive discussions enhance\nperformance, this approach is currently limited to the inference phase. In this\ncontext, we posit a hypothesis: learning interactive discussions during\ntraining can improve understanding for the instances in the training step and\nproficiency in logical/critical thinking ability and verbalized expression of\nthe model in the inference step. Our proposed SAIE training method involves\nboth supportive and adversarial discussions between the learner and partner\nmodels. The learner model receives a remark from the partner through the\ndiscussion, and the parameters of the learner model are then updated based on\nthis remark. That is, the teacher signal dynamically adjusts in response to the\nevolving model output throughout the training step. By bolstering the capacity\nfor discussion and comprehension of instances, our experiments across datasets,\nincluding GSM8K, CommonsenseQA, and MMLU, reveal that models fine-tuned with\nour method consistently surpass those trained with standard fine-tuning\ntechniques. Moreover, our approach demonstrates superior performance in\nmulti-agent inference scenarios, boosting the models' reasoning abilities at\nthe inference step.",
            "author": [
                "Mengsay Loem",
                "Masahiro Kaneko",
                "Naoaki Okazaki"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08107v1",
                "http://arxiv.org/pdf/2311.08107v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08106v1",
            "title": "Carpe Diem: On the Evaluation of World Knowledge in Lifelong Language\n  Models",
            "updated": "2023-11-14T12:12:02Z",
            "published": "2023-11-14T12:12:02Z",
            "summary": "In an ever-evolving world, the dynamic nature of knowledge presents\nchallenges for language models that are trained on static data, leading to\noutdated encoded information. However, real-world scenarios require models not\nonly to acquire new knowledge but also to overwrite outdated information into\nupdated ones. To address this under-explored issue, we introduce the temporally\nevolving question answering benchmark, EvolvingQA - a novel benchmark designed\nfor training and evaluating LMs on an evolving Wikipedia database, where the\nconstruction of our benchmark is automated with our pipeline using large\nlanguage models. Our benchmark incorporates question-answering as a downstream\ntask to emulate real-world applications. Through EvolvingQA, we uncover that\nexisting continual learning baselines have difficulty in updating and\nforgetting outdated knowledge. Our findings suggest that the models fail to\nlearn updated knowledge due to the small weight gradient. Furthermore, we\nelucidate that the models struggle mostly on providing numerical or temporal\nanswers to questions asking for updated knowledge. Our work aims to model the\ndynamic nature of real-world information, offering a robust measure for the\nevolution-adaptability of language models.",
            "author": [
                "Yujin Kim",
                "Jaehong Yoon",
                "Seonghyeon Ye",
                "Sung Ju Hwang",
                "Se-young Yun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08106v1",
                "http://arxiv.org/pdf/2311.08106v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08105v2",
            "title": "DiLoCo: Distributed Low-Communication Training of Language Models",
            "updated": "2023-12-02T14:10:14Z",
            "published": "2023-11-14T12:05:45Z",
            "summary": "Large language models (LLM) have become a critical component in many\napplications of machine learning. However, standard approaches to training LLM\nrequire a large number of tightly interconnected accelerators, with devices\nexchanging gradients and other intermediate states at each optimization step.\nWhile it is difficult to build and maintain a single computing cluster hosting\nmany accelerators, it might be easier to find several computing clusters each\nhosting a smaller number of devices. In this work, we propose a distributed\noptimization algorithm, Distributed Low-Communication (DiLoCo), that enables\ntraining of language models on islands of devices that are poorly connected.\nThe approach is a variant of federated averaging, where the number of inner\nsteps is large, the inner optimizer is AdamW, and the outer optimizer is\nNesterov momentum. On the widely used C4 dataset, we show that DiLoCo on 8\nworkers performs as well as fully synchronous optimization while communicating\n500 times less. DiLoCo exhibits great robustness to the data distribution of\neach worker. It is also robust to resources becoming unavailable over time, and\nvice versa, it can seamlessly leverage resources that become available during\ntraining.",
            "author": [
                "Arthur Douillard",
                "Qixuan Feng",
                "Andrei A. Rusu",
                "Rachita Chhaparia",
                "Yani Donchev",
                "Adhiguna Kuncoro",
                "Marc'Aurelio Ranzato",
                "Arthur Szlam",
                "Jiajun Shen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08105v2",
                "http://arxiv.org/pdf/2311.08105v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08104v1",
            "title": "Reimagining Speech: A Scoping Review of Deep Learning-Powered Voice\n  Conversion",
            "updated": "2023-11-14T12:03:46Z",
            "published": "2023-11-14T12:03:46Z",
            "summary": "Research on deep learning-powered voice conversion (VC) in speech-to-speech\nscenarios is getting increasingly popular. Although many of the works in the\nfield of voice conversion share a common global pipeline, there is a\nconsiderable diversity in the underlying structures, methods, and neural\nsub-blocks used across research efforts. Thus, obtaining a comprehensive\nunderstanding of the reasons behind the choice of the different methods in the\nvoice conversion pipeline can be challenging, and the actual hurdles in the\nproposed solutions are often unclear. To shed light on these aspects, this\npaper presents a scoping review that explores the use of deep learning in\nspeech analysis, synthesis, and disentangled speech representation learning\nwithin modern voice conversion systems. We screened 621 publications from more\nthan 38 different venues between the years 2017 and 2023, followed by an\nin-depth review of a final database consisting of 123 eligible studies. Based\non the review, we summarise the most frequently used approaches to voice\nconversion based on deep learning and highlight common pitfalls within the\ncommunity. Lastly, we condense the knowledge gathered, identify main challenges\nand provide recommendations for future research directions.",
            "author": [
                "Anders R. Bargum",
                "Stefania Serafin",
                "Cumhur Erkut"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08104v1",
                "http://arxiv.org/pdf/2311.08104v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.AI",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08100v2",
            "title": "DeepEMplanner: An End-to-End EM Motion Planner with Iterative\n  Interactions",
            "updated": "2023-11-29T07:53:47Z",
            "published": "2023-11-14T11:53:24Z",
            "summary": "Motion planning is a computational problem that finds a sequence of valid\ntrajectories, often based on surrounding agents' forecasting, environmental\nunderstanding, and historical and future contexts. It can also be viewed as a\ngame in which agents continuously plan their next move according to other\nagents' intentions and the encountering environment, further achieving their\nultimate goals through incremental actions. To model the dynamic planning and\ninteraction process, we propose a novel framework, DeepEMplanner, which takes\nthe stepwise interaction into account for fine-grained behavior learning. The\nego vehicle maximizes each step motion to reach its eventual driving outcome\nbased on the stepwise expectation from agents and its upcoming road conditions.\nOn the other hand, the agents also follow the same philosophy to maximize their\nstepwise behavior under the encountering environment and the expectations from\nego and other agents. Our DeepEMplanner models the interactions among ego,\nagents, and the dynamic environment in an autoregressive manner by interleaving\nthe Expectation and Maximization processes. Further, we design ego-to-agents,\nego-to-map, and ego-to-BEV interaction mechanisms with hierarchical dynamic key\nobjects attention to better model the interactions. Experiments on the nuScenes\nbenchmark show that our approach achieves state-of-the-art results.",
            "author": [
                "Zhili Chen",
                "Maosheng Ye",
                "Shuangjie Xu",
                "Tongyi Cao",
                "Qifeng Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08100v2",
                "http://arxiv.org/pdf/2311.08100v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08094v1",
            "title": "Act-VIT: A Representationally Robust Attention Architecture for Skeleton\n  Based Action Recognition Using Vision Transformer",
            "updated": "2023-11-14T11:38:38Z",
            "published": "2023-11-14T11:38:38Z",
            "summary": "Skeleton-based action recognition receives the attention of many researchers\nas it is robust to viewpoint and illumination changes, and its processing is\nmuch more efficient than video frames. With the emergence of deep learning\nmodels, it has become very popular to represent the skeleton data in\npseudo-image form and apply Convolutional Neural Networks for action\nrecognition. Thereafter, studies concentrated on finding effective methods for\nforming pseudo-images. Recently, attention networks, more specifically\ntransformers have provided promising results in various vision problems. In\nthis study, the effectiveness of vision transformers for skeleton-based action\nrecognition is examined and its robustness on the pseudo-image representation\nscheme is investigated. To this end, a three-level architecture, Act-VIT is\nproposed, which forms a set of pseudo images apply a classifier on each of the\nrepresentation and combine their results to find the final action class. The\nclassifiers of Act-VIT are first realized by CNNs and then by VITs and their\nperformances are compared. Experimental studies reveal that the vision\ntransformer is less sensitive to the initial pseudo-image representation\ncompared to CNN. Nevertheless, even with the vision transformer, the\nrecognition performance can be further improved by consensus of classifiers.",
            "author": [
                "Ozge Oztimur Karadag"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08094v1",
                "http://arxiv.org/pdf/2311.08094v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08089v1",
            "title": "Align after Pre-train: Improving Multilingual Generative Models with\n  Cross-lingual Alignment",
            "updated": "2023-11-14T11:24:08Z",
            "published": "2023-11-14T11:24:08Z",
            "summary": "Multilingual generative models obtain remarkable cross-lingual capabilities\nthrough pre-training on large-scale corpora. However, they still exhibit a\nperformance bias toward high-resource languages, and learn isolated\ndistributions of sentence representations across languages. To bridge this gap,\nwe propose a simple yet effective alignment framework exploiting pairs of\ntranslation sentences. It aligns the internal sentence representations across\ndifferent languages via multilingual contrastive learning and aligns model\noutputs by answering prompts in different languages. Experimental results\ndemonstrate that even with less than 0.1 {\\textperthousand} of pre-training\ntokens, our alignment framework significantly boosts the cross-lingual\nabilities of generative models and mitigates the performance gap. Further\nanalysis reveals that it results in a better internal multilingual\nrepresentation distribution of multilingual models.",
            "author": [
                "Chong Li",
                "Shaonan Wang",
                "Jiajun Zhang",
                "Chengqing Zong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08089v1",
                "http://arxiv.org/pdf/2311.08089v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08085v1",
            "title": "Optimizing Electric Vehicle Efficiency with Real-Time Telemetry using\n  Machine Learning",
            "updated": "2023-11-14T11:12:48Z",
            "published": "2023-11-14T11:12:48Z",
            "summary": "In the contemporary world with degrading natural resources, the urgency of\nenergy efficiency has become imperative due to the conservation and\nenvironmental safeguarding. Therefore, it's crucial to look for advanced\ntechnology to minimize energy consumption. This research focuses on the\noptimization of battery-electric city style vehicles through the use of a\nreal-time in-car telemetry system that communicates between components through\nthe robust Controller Area Network (CAN) protocol. By harnessing real-time data\nfrom various sensors embedded within vehicles, our driving assistance system\nprovides the driver with visual and haptic actionable feedback that guides the\ndriver on using the optimum driving style to minimize power consumed by the\nvehicle. To develop the pace feedback mechanism for the driver, real-time data\nis collected through a Shell Eco Marathon Urban Concept vehicle platform and\nafter pre-processing, it is analyzed using the novel machine learning algorithm\nTEMSL, that outperforms the existing baseline approaches across various\nperformance metrics. This innovative method after numerous experimentation has\nproven effective in enhancing energy efficiency, guiding the driver along the\ntrack, and reducing human errors. The driving-assistance system offers a range\nof utilities, from cost savings and extended vehicle lifespan to significant\ncontributions to environmental conservation and sustainable driving practices.",
            "author": [
                "Aryaman Rao",
                "Harshit Gupta",
                "Parth Singh",
                "Shivam Mittal",
                "Utkrash Singh",
                "Dinesh Kumar Vishwakarma"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08085v1",
                "http://arxiv.org/pdf/2311.08085v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08083v1",
            "title": "Solving ARC visual analogies with neural embeddings and vector\n  arithmetic: A generalized method",
            "updated": "2023-11-14T11:10:46Z",
            "published": "2023-11-14T11:10:46Z",
            "summary": "Analogical reasoning derives information from known relations and generalizes\nthis information to similar yet unfamiliar situations. One of the first\ngeneralized ways in which deep learning models were able to solve verbal\nanalogies was through vector arithmetic of word embeddings, essentially\nrelating words that were mapped to a vector space (e.g., king - man + woman =\n__?). In comparison, most attempts to solve visual analogies are still\npredominantly task-specific and less generalizable. This project focuses on\nvisual analogical reasoning and applies the initial generalized mechanism used\nto solve verbal analogies to the visual realm. Taking the Abstraction and\nReasoning Corpus (ARC) as an example to investigate visual analogy solving, we\nuse a variational autoencoder (VAE) to transform ARC items into low-dimensional\nlatent vectors, analogous to the word embeddings used in the verbal approaches.\nThrough simple vector arithmetic, underlying rules of ARC items are discovered\nand used to solve them. Results indicate that the approach works well on simple\nitems with fewer dimensions (i.e., few colors used, uniform shapes), similar\ninput-to-output examples, and high reconstruction accuracy on the VAE.\nPredictions on more complex items showed stronger deviations from expected\noutputs, although, predictions still often approximated parts of the item's\nrule set. Error patterns indicated that the model works as intended. On the\nofficial ARC paradigm, the model achieved a score of 2% (cf. current world\nrecord is 21%) and on ConceptARC it scored 8.8%. Although the methodology\nproposed involves basic dimensionality reduction techniques and standard vector\narithmetic, this approach demonstrates promising outcomes on ARC and can easily\nbe generalized to other abstract visual reasoning tasks.",
            "author": [
                "Luca H. Thoms",
                "Karel A. Veldkamp",
                "Hannes Rosenbusch",
                "Claire E. Stevenson"
            ],
            "link": [
                "http://dx.doi.org/10.17605/OSF.IO/AKP86",
                "http://arxiv.org/abs/2311.08083v1",
                "http://arxiv.org/pdf/2311.08083v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08081v1",
            "title": "Evolutionary-enhanced quantum supervised learning model",
            "updated": "2023-11-14T11:08:47Z",
            "published": "2023-11-14T11:08:47Z",
            "summary": "Quantum supervised learning, utilizing variational circuits, stands out as a\npromising technology for NISQ devices due to its efficiency in hardware\nresource utilization during the creation of quantum feature maps and the\nimplementation of hardware-efficient ansatz with trainable parameters. Despite\nthese advantages, the training of quantum models encounters challenges, notably\nthe barren plateau phenomenon, leading to stagnation in learning during\noptimization iterations. This study proposes an innovative approach: an\nevolutionary-enhanced ansatz-free supervised learning model. In contrast to\nparametrized circuits, our model employs circuits with variable topology that\nevolves through an elitist method, mitigating the barren plateau issue.\nAdditionally, we introduce a novel concept, the superposition of multi-hot\nencodings, facilitating the treatment of multi-classification problems. Our\nframework successfully avoids barren plateaus, resulting in enhanced model\naccuracy. Comparative analysis with variational quantum classifiers from the\ntechnology's state-of-the-art reveal a substantial improvement in training\nefficiency and precision. Furthermore, we conduct tests on a challenging\ndataset class, traditionally problematic for conventional kernel machines,\ndemonstrating a potential alternative path for achieving quantum advantage in\nsupervised learning for NISQ era.",
            "author": [
                "Anton Simen Albino",
                "Rodrigo Bloot",
                "Otto M. Pires",
                "Erick G. S. Nascimento"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08081v1",
                "http://arxiv.org/pdf/2311.08081v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.LG",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08080v1",
            "title": "Identifying Light-curve Signals with a Deep Learning Based Object\n  Detection Algorithm. II. A General Light Curve Classification Framework",
            "updated": "2023-11-14T11:08:34Z",
            "published": "2023-11-14T11:08:34Z",
            "summary": "Vast amounts of astronomical photometric data are generated from various\nprojects, requiring significant efforts to identify variable stars and other\nobject classes. In light of this, a general, widely applicable classification\nframework would simplify the task of designing custom classifiers. We present a\nnovel deep learning framework for classifying light curves using a weakly\nsupervised object detection model. Our framework identifies the optimal windows\nfor both light curves and power spectra automatically, and zooms in on their\ncorresponding data. This allows for automatic feature extraction from both time\nand frequency domains, enabling our model to handle data across different\nscales and sampling intervals. We train our model on datasets obtained from\nboth space-based and ground-based multi-band observations of variable stars and\ntransients. We achieve an accuracy of 87% for combined variables and transient\nevents, which is comparable to the performance of previous feature-based\nmodels. Our trained model can be utilized directly to other missions, such as\nASAS-SN, without requiring any retraining or fine-tuning. To address known\nissues with miscalibrated predictive probabilities, we apply conformal\nprediction to generate robust predictive sets that guarantee true label\ncoverage with a given probability. Additionally, we incorporate various anomaly\ndetection algorithms to empower our model with the ability to identify\nout-of-distribution objects. Our framework is implemented in the Deep-LC\ntoolkit, which is an open-source Python package hosted on Github and PyPI.",
            "author": [
                "Kaiming Cui",
                "D. J. Armstrong",
                "Fabo Feng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08080v1",
                "http://arxiv.org/pdf/2311.08080v1"
            ],
            "primary_category": "astro-ph.IM",
            "category": [
                "astro-ph.IM",
                "astro-ph.HE",
                "astro-ph.SR",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08077v1",
            "title": "Zero-Shot Segmentation of Eye Features Using the Segment Anything Model\n  (SAM)",
            "updated": "2023-11-14T11:05:08Z",
            "published": "2023-11-14T11:05:08Z",
            "summary": "The advent of foundation models signals a new era in artificial intelligence.\nThe Segment Anything Model (SAM) is the first foundation model for image\nsegmentation. In this study, we evaluate SAM's ability to segment features from\neye images recorded in virtual reality setups. The increasing requirement for\nannotated eye-image datasets presents a significant opportunity for SAM to\nredefine the landscape of data annotation in gaze estimation. Our investigation\ncenters on SAM's zero-shot learning abilities and the effectiveness of prompts\nlike bounding boxes or point clicks. Our results are consistent with studies in\nother domains, demonstrating that SAM's segmentation effectiveness can be\non-par with specialized models depending on the feature, with prompts improving\nits performance, evidenced by an IoU of 93.34% for pupil segmentation in one\ndataset. Foundation models like SAM could revolutionize gaze estimation by\nenabling quick and easy image segmentation, reducing reliance on specialized\nmodels and extensive manual annotation.",
            "author": [
                "Virmarie Maquiling",
                "Sean Anthony Byrne",
                "Diederick C. Niehorster",
                "Marcus Nystr\u00f6m",
                "Enkelejda Kasneci"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08077v1",
                "http://arxiv.org/pdf/2311.08077v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08075v1",
            "title": "GlanceSeg: Real-time microaneurysm lesion segmentation with\n  gaze-map-guided foundation model for early detection of diabetic retinopathy",
            "updated": "2023-11-14T10:59:45Z",
            "published": "2023-11-14T10:59:45Z",
            "summary": "Early-stage diabetic retinopathy (DR) presents challenges in clinical\ndiagnosis due to inconspicuous and minute microangioma lesions, resulting in\nlimited research in this area. Additionally, the potential of emerging\nfoundation models, such as the segment anything model (SAM), in medical\nscenarios remains rarely explored. In this work, we propose a\nhuman-in-the-loop, label-free early DR diagnosis framework called GlanceSeg,\nbased on SAM. GlanceSeg enables real-time segmentation of microangioma lesions\nas ophthalmologists review fundus images. Our human-in-the-loop framework\nintegrates the ophthalmologist's gaze map, allowing for rough localization of\nminute lesions in fundus images. Subsequently, a saliency map is generated\nbased on the located region of interest, which provides prompt points to assist\nthe foundation model in efficiently segmenting microangioma lesions. Finally, a\ndomain knowledge filter refines the segmentation of minute lesions. We\nconducted experiments on two newly-built public datasets, i.e., IDRiD and\nRetinal-Lesions, and validated the feasibility and superiority of GlanceSeg\nthrough visualized illustrations and quantitative measures. Additionally, we\ndemonstrated that GlanceSeg improves annotation efficiency for clinicians and\nenhances segmentation performance through fine-tuning using annotations. This\nstudy highlights the potential of GlanceSeg-based annotations for self-model\noptimization, leading to enduring performance advancements through continual\nlearning.",
            "author": [
                "Hongyang Jiang",
                "Mengdi Gao",
                "Zirong Liu",
                "Chen Tang",
                "Xiaoqing Zhang",
                "Shuai Jiang",
                "Wu Yuan",
                "Jiang Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08075v1",
                "http://arxiv.org/pdf/2311.08075v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08053v1",
            "title": "Communication-Constrained Bayesian Active Knowledge Distillation",
            "updated": "2023-11-14T10:23:00Z",
            "published": "2023-11-14T10:23:00Z",
            "summary": "Consider an active learning setting in which a learner has a training set\nwith few labeled examples and a pool set with many unlabeled inputs, while a\nremote teacher has a pre-trained model that is known to perform well for the\nlearner's task. The learner actively transmits batches of unlabeled inputs to\nthe teacher through a constrained communication channel for labeling. This\npaper addresses the following key questions: (i) Active batch selection: Which\nbatch of inputs should be sent to the teacher to acquire the most useful\ninformation and thus reduce the number of required communication rounds? (ii)\nBatch encoding: How do we encode the batch of inputs for transmission to the\nteacher to reduce the communication resources required at each round? We\nintroduce Communication-Constrained Bayesian Active Knowledge Distillation\n(CC-BAKD), a novel protocol that integrates Bayesian active learning with\ncompression via a linear mix-up mechanism. Bayesian active learning selects the\nbatch of inputs based on their epistemic uncertainty, addressing the\n\"confirmation bias\" that is known to increase the number of required\ncommunication rounds. Furthermore, the proposed mix-up compression strategy is\nintegrated with the epistemic uncertainty-based active batch selection process\nto reduce the communication overhead per communication round.",
            "author": [
                "Victor Croisfelt",
                "Shashi Raj Pandey",
                "Osvaldo Simeone",
                "Petar Popovski"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08053v1",
                "http://arxiv.org/pdf/2311.08053v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08045v1",
            "title": "Adversarial Preference Optimization",
            "updated": "2023-11-14T10:10:31Z",
            "published": "2023-11-14T10:10:31Z",
            "summary": "Human preference alignment is a crucial training step to improve the\ninteraction quality of large language models (LLMs). Existing aligning methods\ndepend on manually annotated preference data to guide the LLM optimization\ndirections. However, in practice, continuously updating LLMs raises a\ndistribution gap between model-generated samples and human-preferred responses,\nwhich hinders model fine-tuning efficiency. To mitigate this issue, previous\nmethods require additional preference annotation on generated samples to adapt\nthe shifted distribution, which consumes a large amount of annotation\nresources. Targeting more efficient human preference optimization, we propose\nan adversarial preference optimization (APO) framework, where the LLM agent and\nthe preference model update alternatively via a min-max game. Without\nadditional annotation, our APO method can make a self-adaption to the\ngeneration distribution gap through the adversarial learning process. In\nexperiments, we empirically verify the effectiveness of APO in improving LLM's\nhelpfulness and harmlessness compared with rejection sampling baselines.",
            "author": [
                "Pengyu Cheng",
                "Yifan Yang",
                "Jian Li",
                "Yong Dai",
                "Nan Du"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08045v1",
                "http://arxiv.org/pdf/2311.08045v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08043v1",
            "title": "Contrastive Learning for Multi-Object Tracking with Transformers",
            "updated": "2023-11-14T10:07:52Z",
            "published": "2023-11-14T10:07:52Z",
            "summary": "The DEtection TRansformer (DETR) opened new possibilities for object\ndetection by modeling it as a translation task: converting image features into\nobject-level representations. Previous works typically add expensive modules to\nDETR to perform Multi-Object Tracking (MOT), resulting in more complicated\narchitectures. We instead show how DETR can be turned into a MOT model by\nemploying an instance-level contrastive loss, a revised sampling strategy and a\nlightweight assignment method. Our training scheme learns object appearances\nwhile preserving detection capabilities and with little overhead. Its\nperformance surpasses the previous state-of-the-art by +2.6 mMOTA on the\nchallenging BDD100K dataset and is comparable to existing transformer-based\nmethods on the MOT17 dataset.",
            "author": [
                "Pierre-Fran\u00e7ois De Plaen",
                "Nicola Marinello",
                "Marc Proesmans",
                "Tinne Tuytelaars",
                "Luc Van Gool"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08043v1",
                "http://arxiv.org/pdf/2311.08043v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08035v1",
            "title": "Data-driven building energy efficiency prediction based on envelope heat\n  losses using physics-informed neural networks",
            "updated": "2023-11-14T09:55:03Z",
            "published": "2023-11-14T09:55:03Z",
            "summary": "The analytical prediction of building energy performance in residential\nbuildings based on the heat losses of its individual envelope components is a\nchallenging task. It is worth noting that this field is still in its infancy,\nwith relatively limited research conducted in this specific area to date,\nespecially when it comes for data-driven approaches. In this paper we introduce\na novel physics-informed neural network model for addressing this problem.\nThrough the employment of unexposed datasets that encompass general building\ninformation, audited characteristics, and heating energy consumption, we feed\nthe deep learning model with general building information, while the model's\noutput consists of the structural components and several thermal properties\nthat are in fact the basic elements of an energy performance certificate (EPC).\nOn top of this neural network, a function, based on physics equations,\ncalculates the energy consumption of the building based on heat losses and\nenhances the loss function of the deep learning model. This methodology is\ntested on a real case study for 256 buildings located in Riga, Latvia. Our\ninvestigation comes up with promising results in terms of prediction accuracy,\npaving the way for automated, and data-driven energy efficiency performance\nprediction based on basic properties of the building, contrary to exhaustive\nenergy efficiency audits led by humans, which are the current status quo.",
            "author": [
                "Vasilis Michalakopoulos",
                "Sotiris Pelekis",
                "Giorgos Kormpakis",
                "Vagelis Karakolis",
                "Spiros Mouzakitis",
                "Dimitris Askounis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08035v1",
                "http://arxiv.org/pdf/2311.08035v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08034v1",
            "title": "Keplerian disks and outflows in binary post-AGB stars",
            "updated": "2023-11-14T09:54:10Z",
            "published": "2023-11-14T09:54:10Z",
            "summary": "There is a class of binary post-AGB stars that are surrounded by Keplerian\ndisks and that often present outflows resulting from gas escaping from the\ndisk. We present maps and complex models of 12CO and 13CO J=2-1 emission lines\nfor four objects: AC Herculis, 89 Herculis, IRAS 19125+0343, and R Scuti. Our\nmaps and models allow us to study their morphology, kinematics, and mass\ndistribution. Our maps and modeling of AC Her reveal that 95% of the total\nnebular mass is located in the disk. So this source is a disk-dominated source\n(like the Red Rectangle, IW Carinae, IRAS 08544-4431). On the contrary, our\nmaps and modeling of 89 Herculis, IRAS 19125+0343, and R Scuti suggest that the\noutflow is the dominant component of the nebula, resulting in a new subclass\nnebulae around binary post-AGB stars: the outflow-dominated ones. Besides CO,\nthe molecular content of this kind of sources was barely known. We also present\nthe first and very deep single-dish radio molecular survey in the 1.3, 2, 3, 7,\nand 13 mm bands. Our results allow us to classify our sources as O- or C-rich.\nWe also conclude that these sources present in general a low molecular\nrichness, especially those that are disk-dominated, compared to circumstellar\nenvelopes around AGB stars and other post-AGB stars.\n  This thesis presents a comprehensive study at millimetre wavelengths. On the\none hand, we perform a detailed kinetic study of these objects through NOEMA\ninterferometric observations and complex models. On the other hand, we study\nthe chemistry of these sources, thanks to our sensitive single-dish\nobservations.\n  The union of these different methods yields a comprehensive study of the\nmolecular gas present in these sources. Hopefully, this Ph.D. thesis will\nbecome a reference for future studies of molecular gas in nebulae around binary\npost-AGB stars.",
            "author": [
                "Iv\u00e1n Gallardo Cava"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08034v1",
                "http://arxiv.org/pdf/2311.08034v1"
            ],
            "primary_category": "astro-ph.SR",
            "category": [
                "astro-ph.SR",
                "astro-ph.GA",
                "astro-ph.IM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08024v1",
            "title": "MD-IQA: Learning Multi-scale Distributed Image Quality Assessment with\n  Semi Supervised Learning for Low Dose CT",
            "updated": "2023-11-14T09:33:33Z",
            "published": "2023-11-14T09:33:33Z",
            "summary": "Image quality assessment (IQA) plays a critical role in optimizing radiation\ndose and developing novel medical imaging techniques in computed tomography\n(CT). Traditional IQA methods relying on hand-crafted features have limitations\nin summarizing the subjective perceptual experience of image quality. Recent\ndeep learning-based approaches have demonstrated strong modeling capabilities\nand potential for medical IQA, but challenges remain regarding model\ngeneralization and perceptual accuracy. In this work, we propose a multi-scale\ndistributions regression approach to predict quality scores by constraining the\noutput distribution, thereby improving model generalization. Furthermore, we\ndesign a dual-branch alignment network to enhance feature extraction\ncapabilities. Additionally, semi-supervised learning is introduced by utilizing\npseudo-labels for unlabeled data to guide model training. Extensive qualitative\nexperiments demonstrate the effectiveness of our proposed method for advancing\nthe state-of-the-art in deep learning-based medical IQA. Code is available at:\nhttps://github.com/zunzhumu/MD-IQA.",
            "author": [
                "Tao Song",
                "Ruizhi Hou",
                "Lisong Dai",
                "Lei Xiang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08024v1",
                "http://arxiv.org/pdf/2311.08024v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08022v1",
            "title": "Two-Stage Predict+Optimize for Mixed Integer Linear Programs with\n  Unknown Parameters in Constraints",
            "updated": "2023-11-14T09:32:02Z",
            "published": "2023-11-14T09:32:02Z",
            "summary": "Consider the setting of constrained optimization, with some parameters\nunknown at solving time and requiring prediction from relevant features.\nPredict+Optimize is a recent framework for end-to-end training supervised\nlearning models for such predictions, incorporating information about the\noptimization problem in the training process in order to yield better\npredictions in terms of the quality of the predicted solution under the true\nparameters. Almost all prior works have focused on the special case where the\nunknowns appear only in the optimization objective and not the constraints. Hu\net al.~proposed the first adaptation of Predict+Optimize to handle unknowns\nappearing in constraints, but the framework has somewhat ad-hoc elements, and\nthey provided a training algorithm only for covering and packing linear\nprograms. In this work, we give a new \\emph{simpler} and \\emph{more powerful}\nframework called \\emph{Two-Stage Predict+Optimize}, which we believe should be\nthe canonical framework for the Predict+Optimize setting. We also give a\ntraining algorithm usable for all mixed integer linear programs, vastly\ngeneralizing the applicability of the framework. Experimental results\ndemonstrate the superior prediction performance of our training framework over\nall classical and state-of-the-art methods.",
            "author": [
                "Xinyi Hu",
                "Jasper C. H. Lee",
                "Jimmy H. M. Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08022v1",
                "http://arxiv.org/pdf/2311.08022v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08016v1",
            "title": "Velocity-Based Channel Charting with Spatial Distribution Map Matching",
            "updated": "2023-11-14T09:21:09Z",
            "published": "2023-11-14T09:21:09Z",
            "summary": "Fingerprint-based localization improves the positioning performance in\nchallenging, non-line-of-sight (NLoS) dominated indoor environments. However,\nfingerprinting models require an expensive life-cycle management including\nrecording and labeling of radio signals for the initial training and regularly\nat environmental changes. Alternatively, channel-charting avoids this labeling\neffort as it implicitly associates relative coordinates to the recorded radio\nsignals. Then, with reference real-world coordinates (positions) we can use\nsuch charts for positioning tasks. However, current channel-charting approaches\nlag behind fingerprinting in their positioning accuracy and still require\nreference samples for localization, regular data recording and labeling to keep\nthe models up to date. Hence, we propose a novel framework that does not\nrequire reference positions. We only require information from velocity\ninformation, e.g., from pedestrian dead reckoning or odometry to model the\nchannel charts, and topological map information, e.g., a building floor plan,\nto transform the channel charts into real coordinates. We evaluate our approach\non two different real-world datasets using 5G and distributed\nsingle-input/multiple-output system (SIMO) radio systems. Our experiments show\nthat even with noisy velocity estimates and coarse map information, we achieve\nsimilar position accuracies",
            "author": [
                "Maximilian Stahlke",
                "George Yammine",
                "Tobias Feigl",
                "Bjoern M. Eskofier",
                "Christopher Mutschler"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08016v1",
                "http://arxiv.org/pdf/2311.08016v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08013v1",
            "title": "CP-SLAM: Collaborative Neural Point-based SLAM System",
            "updated": "2023-11-14T09:17:15Z",
            "published": "2023-11-14T09:17:15Z",
            "summary": "This paper presents a collaborative implicit neural simultaneous localization\nand mapping (SLAM) system with RGB-D image sequences, which consists of\ncomplete front-end and back-end modules including odometry, loop detection,\nsub-map fusion, and global refinement. In order to enable all these modules in\na unified framework, we propose a novel neural point based 3D scene\nrepresentation in which each point maintains a learnable neural feature for\nscene encoding and is associated with a certain keyframe. Moreover, a\ndistributed-to-centralized learning strategy is proposed for the collaborative\nimplicit SLAM to improve consistency and cooperation. A novel global\noptimization framework is also proposed to improve the system accuracy like\ntraditional bundle adjustment. Experiments on various datasets demonstrate the\nsuperiority of the proposed method in both camera tracking and mapping.",
            "author": [
                "Jiarui Hu",
                "Mao Mao",
                "Hujun Bao",
                "Guofeng Zhang",
                "Zhaopeng Cui"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08013v1",
                "http://arxiv.org/pdf/2311.08013v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08011v1",
            "title": "Forgetting before Learning: Utilizing Parametric Arithmetic for\n  Knowledge Updating in Large Language Models",
            "updated": "2023-11-14T09:12:40Z",
            "published": "2023-11-14T09:12:40Z",
            "summary": "Recently Large Language Models (LLMs) have demonstrated their amazing text\nunderstanding and generation capabilities. However, even stronger LLMs may\nstill learn incorrect knowledge from the training corpus, as well as some\nknowledge that is outdated over time. Direct secondary fine-tuning with data\ncontaining new knowledge may be ineffective in updating knowledge due to the\nconflict between old and new knowledge. In this paper, we propose a new\nparadigm for fine-tuning called F-Learning (Forgetting before Learning), which\nis based on parametric arithmetic to achieve forgetting of old knowledge and\nlearning of new knowledge. Experimental results on two publicly available\ndatasets demonstrate that our proposed F-Learning can obviously improve the\nknowledge updating performance of both full fine-tuning and LoRA fine-tuning.\nMoreover, we have also discovered that forgetting old knowledge by subtracting\nthe parameters of LoRA can achieve a similar effect to subtracting the\nparameters of full fine-tuning, and sometimes even surpass it significantly.",
            "author": [
                "Shiwen Ni",
                "Dingwei Chen",
                "Chengming Li",
                "Xiping Hu",
                "Ruifeng Xu",
                "Min Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08011v1",
                "http://arxiv.org/pdf/2311.08011v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08010v1",
            "title": "Distantly-Supervised Named Entity Recognition with Uncertainty-aware\n  Teacher Learning and Student-student Collaborative Learning",
            "updated": "2023-11-14T09:09:58Z",
            "published": "2023-11-14T09:09:58Z",
            "summary": "Distantly-Supervised Named Entity Recognition (DS-NER) effectively alleviates\nthe burden of annotation, but meanwhile suffers from the label noise. Recent\nworks attempt to adopt the teacher-student framework to gradually refine the\ntraining labels and improve the overall robustness. However, we argue that\nthese teacher-student methods achieve limited performance because poor network\ncalibration produces incorrectly pseudo-labeled samples, leading to error\npropagation. Therefore, we attempt to mitigate this issue by proposing: (1)\nUncertainty-aware Teacher Learning that leverages the prediction uncertainty to\nguide the selection of pseudo-labels, avoiding the number of incorrect\npseudo-labels in the self-training stage. (2) Student-student Collaborative\nLearning that allows the transfer of reliable labels between two student\nnetworks instead of completely relying on all pseudo-labels from its teacher.\nMeanwhile, this approach allows a full exploration of mislabeled samples rather\nthan simply filtering unreliable pseudo-labeled samples. Extensive experimental\nresults on five DS-NER datasets demonstrate that our method is superior to\nstate-of-the-art teacher-student methods.",
            "author": [
                "Helan Hu",
                "Shuzheng Si",
                "Haozhe Zhao",
                "Shuang Zeng",
                "Kaikai An",
                "Zefan Cai",
                "Baobao Chang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08010v1",
                "http://arxiv.org/pdf/2311.08010v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08007v1",
            "title": "Clearer Frames, Anytime: Resolving Velocity Ambiguity in Video Frame\n  Interpolation",
            "updated": "2023-11-14T09:08:30Z",
            "published": "2023-11-14T09:08:30Z",
            "summary": "Existing video frame interpolation (VFI) methods blindly predict where each\nobject is at a specific timestep t (\"time indexing\"), which struggles to\npredict precise object movements. Given two images of a baseball, there are\ninfinitely many possible trajectories: accelerating or decelerating, straight\nor curved. This often results in blurry frames as the method averages out these\npossibilities. Instead of forcing the network to learn this complicated\ntime-to-location mapping implicitly together with predicting the frames, we\nprovide the network with an explicit hint on how far the object has traveled\nbetween start and end frames, a novel approach termed \"distance indexing\". This\nmethod offers a clearer learning goal for models, reducing the uncertainty tied\nto object speeds. We further observed that, even with this extra guidance,\nobjects can still be blurry especially when they are equally far from both\ninput frames (i.e., halfway in-between), due to the directional ambiguity in\nlong-range motion. To solve this, we propose an iterative reference-based\nestimation strategy that breaks down a long-range prediction into several\nshort-range steps. When integrating our plug-and-play strategies into\nstate-of-the-art learning-based models, they exhibit markedly sharper outputs\nand superior perceptual quality in arbitrary time interpolations, using a\nuniform distance indexing map in the same format as time indexing.\nAdditionally, distance indexing can be specified pixel-wise, which enables\ntemporal manipulation of each object independently, offering a novel tool for\nvideo editing tasks like re-timing.",
            "author": [
                "Zhihang Zhong",
                "Gurunandan Krishnan",
                "Xiao Sun",
                "Yu Qiao",
                "Sizhuo Ma",
                "Jian Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08007v1",
                "http://arxiv.org/pdf/2311.08007v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08005v1",
            "title": "Iterative missing value imputation based on feature importance",
            "updated": "2023-11-14T09:03:33Z",
            "published": "2023-11-14T09:03:33Z",
            "summary": "Many datasets suffer from missing values due to various reasons,which not\nonly increases the processing difficulty of related tasks but also reduces the\naccuracy of classification. To address this problem, the mainstream approach is\nto use missing value imputation to complete the dataset. Existing imputation\nmethods estimate the missing parts based on the observed values in the original\nfeature space, and they treat all features as equally important during data\ncompletion, while in fact different features have different importance.\nTherefore, we have designed an imputation method that considers feature\nimportance. This algorithm iteratively performs matrix completion and feature\nimportance learning, and specifically, matrix completion is based on a filling\nloss that incorporates feature importance. Our experimental analysis involves\nthree types of datasets: synthetic datasets with different noisy features and\nmissing values, real-world datasets with artificially generated missing values,\nand real-world datasets originally containing missing values. The results on\nthese datasets consistently show that the proposed method outperforms the\nexisting five imputation algorithms.To the best of our knowledge, this is the\nfirst work that considers feature importance in the imputation model.",
            "author": [
                "Cong Guo",
                "Chun Liu",
                "Wei Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08005v1",
                "http://arxiv.org/pdf/2311.08005v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08000v1",
            "title": "LiPar: A Lightweight Parallel Learning Model for Practical In-Vehicle\n  Network Intrusion Detection",
            "updated": "2023-11-14T08:54:00Z",
            "published": "2023-11-14T08:54:00Z",
            "summary": "With the development of intelligent transportation systems, vehicles are\nexposed to a complex network environment. As the main network of in-vehicle\nnetworks, the controller area network (CAN) has many potential security\nhazards, resulting in higher requirements for intrusion detection systems to\nensure safety. Among intrusion detection technologies, methods based on deep\nlearning work best without prior expert knowledge. However, they all have a\nlarge model size and rely on cloud computing, and are therefore not suitable to\nbe installed on the in-vehicle network. Therefore, we propose a lightweight\nparallel neural network structure, LiPar, to allocate task loads to multiple\nelectronic control units (ECU). The LiPar model consists of multi-dimensional\nbranch convolution networks, spatial and temporal feature fusion learning, and\na resource adaptation algorithm. Through experiments, we prove that LiPar has\ngreat detection performance, running efficiency, and lightweight model size,\nwhich can be well adapted to the in-vehicle environment practically and protect\nthe in-vehicle CAN bus security.",
            "author": [
                "Aiheng Zhang",
                "Kai Wang",
                "Bailing Wang",
                "Yulei Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08000v1",
                "http://arxiv.org/pdf/2311.08000v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07997v1",
            "title": "Deep-water limit of the intermediate long wave equation in $L^2$",
            "updated": "2023-11-14T08:52:14Z",
            "published": "2023-11-14T08:52:14Z",
            "summary": "We study the well-posedness issue of the intermediate long wave equation\n(ILW) on both the real line and the circle. By applying the gauge transform for\nthe Benjamin-Ono equation (BO) and adapting the $L^2$ well-posedness argument\nfor BO by Molinet and the fourth author (2012), we prove global well-posedness\nof ILW in $L^2$ on both the real line and the circle. In the periodic setting,\nthis provides the first low regularity well-posedness of ILW. We then establish\nconvergence of the ILW dynamics to the BO dynamics in the deep-water limit at\nthe $L^2$-level.",
            "author": [
                "Andreia Chapouto",
                "Guopeng Li",
                "Tadahiro Oh",
                "Didier Pilod"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07997v1",
                "http://arxiv.org/pdf/2311.07997v1"
            ],
            "primary_category": "math.AP",
            "category": [
                "math.AP",
                "35Q35"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07993v1",
            "title": "Explicit Change Relation Learning for Change Detection in VHR Remote\n  Sensing Images",
            "updated": "2023-11-14T08:47:38Z",
            "published": "2023-11-14T08:47:38Z",
            "summary": "Change detection has always been a concerned task in the interpretation of\nremote sensing images. It is essentially a unique binary classification task\nwith two inputs, and there is a change relationship between these two inputs.\nAt present, the mining of change relationship features is usually implicit in\nthe network architectures that contain single-branch or two-branch encoders.\nHowever, due to the lack of artificial prior design for change relationship\nfeatures, these networks cannot learn enough change semantic information and\nlose more accurate change detection performance. So we propose a network\narchitecture NAME for the explicit mining of change relation features. In our\nopinion, the change features of change detection should be divided into\npre-changed image features, post-changed image features and change relation\nfeatures. In order to fully mine these three kinds of change features, we\npropose the triple branch network combining the transformer and convolutional\nneural network (CNN) to extract and fuse these change features from two\nperspectives of global information and local information, respectively. In\naddition, we design the continuous change relation (CCR) branch to further\nobtain the continuous and detail change relation features to improve the change\ndiscrimination capability of the model. The experimental results show that our\nnetwork performs better, in terms of F1, IoU, and OA, than those of the\nexisting advanced networks for change detection on four public very\nhigh-resolution (VHR) remote sensing datasets. Our source code is available at\nhttps://github.com/DalongZ/NAME.",
            "author": [
                "Dalong Zheng",
                "Zebin Wu",
                "Jia Liu",
                "Chih-Cheng Hung",
                "Zhihui Wei"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07993v1",
                "http://arxiv.org/pdf/2311.07993v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07992v1",
            "title": "Probable Object Location (POLo) Score Estimation for Efficient Object\n  Goal Navigation",
            "updated": "2023-11-14T08:45:32Z",
            "published": "2023-11-14T08:45:32Z",
            "summary": "To advance the field of autonomous robotics, particularly in object search\ntasks within unexplored environments, we introduce a novel framework centered\naround the Probable Object Location (POLo) score. Utilizing a 3D object\nprobability map, the POLo score allows the agent to make data-driven decisions\nfor efficient object search. We further enhance the framework's practicality by\nintroducing POLoNet, a neural network trained to approximate the\ncomputationally intensive POLo score. Our approach addresses critical\nlimitations of both end-to-end reinforcement learning methods, which suffer\nfrom memory decay over long-horizon tasks, and traditional map-based methods\nthat neglect visibility constraints. Our experiments, involving the first phase\nof the OVMM 2023 challenge, demonstrate that an agent equipped with POLoNet\nsignificantly outperforms a range of baseline methods, including end-to-end RL\ntechniques and prior map-based strategies. To provide a comprehensive\nevaluation, we introduce new performance metrics that offer insights into the\nefficiency and effectiveness of various agents in object goal navigation.",
            "author": [
                "Jiaming Wang",
                "Harold Soh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07992v1",
                "http://arxiv.org/pdf/2311.07992v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07985v1",
            "title": "Configurable convolutional neural networks for real-time\n  pedestrian-level wind prediction in urban environments",
            "updated": "2023-11-14T08:27:00Z",
            "published": "2023-11-14T08:27:00Z",
            "summary": "Urbanization has underscored the importance of understanding the pedestrian\nwind environment in urban and architectural design contexts. Pedestrian Wind\nComfort (PWC) focuses on the effects of wind on the safety and comfort of\npedestrians and cyclists, given the influence of urban structures on the local\nmicroclimate. Traditional Computational Fluid Dynamics (CFD) methods used for\nPWC analysis have limitations in computation, cost, and time. Deep-learning\nmodels have the potential to significantly speed up this process. The\nprevailing state-of-the-art methodologies largely rely on GAN-based models,\nsuch as pix2pix, which have exhibited training instability issues. In contrast,\nour work introduces a convolutional neural network (CNN) approach based on the\nU-Net architecture, offering a more stable and streamlined solution. The\nprocess of generating a wind flow prediction at pedestrian level is\nreformulated from a 3D CFD simulation into a 2D image-to-image translation\ntask, using the projected building heights as input. Testing on standard\nconsumer hardware shows that our model can efficiently predict wind velocities\nin urban settings in real time. Further tests on different configurations of\nthe model, combined with a Pareto front analysis, helped identify the trade-off\nbetween accuracy and computational efficiency. This CNN-based approach provides\na fast and efficient method for PWC analysis, potentially aiding in more\nefficient urban design processes.",
            "author": [
                "Alfredo Vicente Clemente",
                "Knut Erik Teigen Giljarhus",
                "Luca Oggiano",
                "Massimiliano Ruocco"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07985v1",
                "http://arxiv.org/pdf/2311.07985v1"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE",
                "I.2.10; I.6.0; J.2"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07981v1",
            "title": "Benchmarking Individual Tree Mapping with Sub-meter Imagery",
            "updated": "2023-11-14T08:21:36Z",
            "published": "2023-11-14T08:21:36Z",
            "summary": "There is a rising interest in mapping trees using satellite or aerial\nimagery, but there is no standardized evaluation protocol for comparing and\nenhancing methods. In dense canopy areas, the high variability of tree sizes\nand their spatial proximity makes it arduous to define the quality of the\npredictions. Concurrently, object-centric approaches such as bounding box\ndetection usuallyperform poorly on small and dense objects. It thus remains\nunclear what is the ideal framework for individual tree mapping, in regards to\ndetection and segmentation approaches, convolutional neural networks and\ntransformers. In this paper, we introduce an evaluation framework suited for\nindividual tree mapping in any physical environment, with annotation costs and\napplicative goals in mind. We review and compare different approaches and deep\narchitectures, and introduce a new method that we experimentally prove to be a\ngood compromise between segmentation and detection.",
            "author": [
                "Dimitri Gominski",
                "Ankit Kariryaa",
                "Martin Brandt",
                "Christian Igel",
                "Sizhuo Li",
                "Maurice Mugabowindekwe",
                "Rasmus Fensholt"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07981v1",
                "http://arxiv.org/pdf/2311.07981v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07980v1",
            "title": "QuantumEyes: Towards Better Interpretability of Quantum Circuits",
            "updated": "2023-11-14T08:20:11Z",
            "published": "2023-11-14T08:20:11Z",
            "summary": "Quantum computing offers significant speedup compared to classical computing,\nwhich has led to a growing interest among users in learning and applying\nquantum computing across various applications. However, quantum circuits, which\nare fundamental for implementing quantum algorithms, can be challenging for\nusers to understand due to their underlying logic, such as the temporal\nevolution of quantum states and the effect of quantum amplitudes on the\nprobability of basis quantum states. To fill this research gap, we propose\nQuantumEyes, an interactive visual analytics system to enhance the\ninterpretability of quantum circuits through both global and local levels. For\nthe global-level analysis, we present three coupled visualizations to delineate\nthe changes of quantum states and the underlying reasons: a Probability Summary\nView to overview the probability evolution of quantum states; a State Evolution\nView to enable an in-depth analysis of the influence of quantum gates on the\nquantum states; a Gate Explanation View to show the individual qubit states and\nfacilitate a better understanding of the effect of quantum gates. For the\nlocal-level analysis, we design a novel geometrical visualization Dandelion\nChart to explicitly reveal how the quantum amplitudes affect the probability of\nthe quantum state. We thoroughly evaluated QuantumEyes as well as the novel\nQuantumEyes integrated into it through two case studies on different types of\nquantum algorithms and in-depth expert interviews with 12 domain experts. The\nresults demonstrate the effectiveness and usability of our approach in\nenhancing the interpretability of quantum circuits.",
            "author": [
                "Shaolun Ruan",
                "Qiang Guan",
                "Paul Griffin",
                "Ying Mao",
                "Yong Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07980v1",
                "http://arxiv.org/pdf/2311.07980v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07978v1",
            "title": "How good are Large Language Models on African Languages?",
            "updated": "2023-11-14T08:10:14Z",
            "published": "2023-11-14T08:10:14Z",
            "summary": "Recent advancements in natural language processing have led to the\nproliferation of large language models (LLMs). These models have been shown to\nyield good performance, using in-context learning, even on unseen tasks and\nlanguages. Additionally, they have been widely adopted as\nlanguage-model-as-a-service commercial APIs like GPT-4 API. However, their\nperformance on African languages is largely unknown. We present an analysis of\nthree popular large language models (mT0, LLaMa 2, and GPT-4) on five tasks\n(news topic classification, sentiment classification, machine translation,\nquestion answering, and named entity recognition) across 30 African languages,\nspanning different language families and geographical regions. Our results\nsuggest that all LLMs produce below-par performance on African languages, and\nthere is a large gap in performance compared to high-resource languages like\nEnglish most tasks. We find that GPT-4 has an average or impressive performance\non classification tasks but very poor results on generative tasks like machine\ntranslation. Surprisingly, we find that mT0 had the best overall on\ncross-lingual QA, better than the state-of-the-art supervised model (i.e.\nfine-tuned mT5) and GPT-4 on African languages. Overall, LLaMa 2 records the\nworst performance due to its limited multilingual capabilities and\nEnglish-centric pre-training corpus. In general, our findings present a\ncall-to-action to ensure African languages are well represented in large\nlanguage models, given their growing popularity.",
            "author": [
                "Jessica Ojo",
                "Kelechi Ogueji",
                "Pontus Stenetorp",
                "David I. Adelani"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07978v1",
                "http://arxiv.org/pdf/2311.07978v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07976v1",
            "title": "Detailing secondary frontal bore of internal tides breaking above\n  deep-ocean topography",
            "updated": "2023-11-14T08:07:11Z",
            "published": "2023-11-14T08:07:11Z",
            "summary": "Above steep deep-sea topography internal tidal waves may break vigorously.\nThe associated turbulent mixing is important for resuspending matter, bringing\nit tens of meters away from the seafloor for redistribution. While intense\nturbulence-generation occurs around a primary (frontal) bore during each\ntransition from warming downslope to cooling upslope phase of the internal\n(tidal) carrier wave, a secondary bore can appear about half a wave-period\nlater before the turn to the warming phase. As will be demonstrated from a\n100-day mooring array consisting of 200 high-resolution temperature sensors\nbetween h = 6-404 m above a steep slope of a large North-Atlantic seamount and\na low-resolution acoustic Doppler current profiler sampling between 50 and 450\nm, secondary bores show about the same turbulence intensity as around primary\nbores but they generally show larger overturns that always reach the seafloor.\nThe secondary bores associate with a sudden drop in along-isobath flow speed, a\n(renewed) increase in upslope flow of up to |0.2| m s-1, and with\nfirst-harmonic quarter-diurnal periodicity which provides a spectral peak for\nturbulence dissipation rate. While each bore is different in appearance,\nvarying from curved like a primary bore to almost straight upward with a ragged\nbore, secondary bores are in a first approximation forward breaking in contrast\nwith backward breaking primary bores.",
            "author": [
                "Hans van Haren"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07976v1",
                "http://arxiv.org/pdf/2311.07976v1"
            ],
            "primary_category": "physics.ao-ph",
            "category": [
                "physics.ao-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07975v1",
            "title": "Out-of-Distribution Knowledge Distillation via Confidence Amendment",
            "updated": "2023-11-14T08:05:02Z",
            "published": "2023-11-14T08:05:02Z",
            "summary": "Out-of-distribution (OOD) detection is essential in identifying test samples\nthat deviate from the in-distribution (ID) data upon which a standard network\nis trained, ensuring network robustness and reliability. This paper introduces\nOOD knowledge distillation, a pioneering learning framework applicable whether\nor not training ID data is available, given a standard network. This framework\nharnesses OOD-sensitive knowledge from the standard network to craft a binary\nclassifier adept at distinguishing between ID and OOD samples. To accomplish\nthis, we introduce Confidence Amendment (CA), an innovative methodology that\ntransforms an OOD sample into an ID one while progressively amending prediction\nconfidence derived from the standard network. This approach enables the\nsimultaneous synthesis of both ID and OOD samples, each accompanied by an\nadjusted prediction confidence, thereby facilitating the training of a binary\nclassifier sensitive to OOD. Theoretical analysis provides bounds on the\ngeneralization error of the binary classifier, demonstrating the pivotal role\nof confidence amendment in enhancing OOD sensitivity. Extensive experiments\nspanning various datasets and network architectures confirm the efficacy of the\nproposed method in detecting OOD samples.",
            "author": [
                "Zhilin Zhao",
                "Longbing Cao",
                "Yixuan Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07975v1",
                "http://arxiv.org/pdf/2311.07975v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07972v1",
            "title": "Residual Importance Weighted Transfer Learning For High-dimensional\n  Linear Regression",
            "updated": "2023-11-14T07:53:42Z",
            "published": "2023-11-14T07:53:42Z",
            "summary": "Transfer learning is an emerging paradigm for leveraging multiple sources to\nimprove the statistical inference on a single target. In this paper, we propose\na novel approach named residual importance weighted transfer learning (RIW-TL)\nfor high-dimensional linear models built on penalized likelihood. Compared to\nexisting methods such as Trans-Lasso that selects sources in an all-in-all-out\nmanner, RIW-TL includes samples via importance weighting and thus may permit\nmore effective sample use. To determine the weights, remarkably RIW-TL only\nrequires the knowledge of one-dimensional densities dependent on residuals,\nthus overcoming the curse of dimensionality of having to estimate\nhigh-dimensional densities in naive importance weighting. We show that the\noracle RIW-TL provides a faster rate than its competitors and develop a\ncross-fitting procedure to estimate this oracle. We discuss variants of RIW-TL\nby adopting different choices for residual weighting. The theoretical\nproperties of RIW-TL and its variants are established and compared with those\nof LASSO and Trans-Lasso. Extensive simulation and a real data analysis confirm\nits advantages.",
            "author": [
                "Junlong Zhao",
                "Shengbin Zheng",
                "Chenlei Leng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07972v1",
                "http://arxiv.org/pdf/2311.07972v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07967v1",
            "title": "Comparison of two data fusion approaches for land use classification",
            "updated": "2023-11-14T07:46:03Z",
            "published": "2023-11-14T07:46:03Z",
            "summary": "Accurate land use maps, describing the territory from an anthropic\nutilisation point of view, are useful tools for land management and planning.\nTo produce them, the use of optical images alone remains limited. It is\ntherefore necessary to make use of several heterogeneous sources, each carrying\ncomplementary or contradictory information due to their imperfections or their\ndifferent specifications. This study compares two different approaches i.e. a\npre-classification and a post-classification fusion approach for combining\nseveral sources of spatial data in the context of land use classification. The\napproaches are applied on authoritative land use data located in the Gers\ndepartment in the southwest of France. Pre-classification fusion, while not\nexplicitly modeling imperfections, has the best final results, reaching an\noverall accuracy of 97% and a macro-mean F1 score of 88%.",
            "author": [
                "Martin Cubaud",
                "Arnaud Le Bris",
                "Laurence Jolivet",
                "Ana-Maria Olteanu-Raimond"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07967v1",
                "http://arxiv.org/pdf/2311.07967v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07966v1",
            "title": "Higher-Order Expander Graph Propagation",
            "updated": "2023-11-14T07:44:46Z",
            "published": "2023-11-14T07:44:46Z",
            "summary": "Graph neural networks operate on graph-structured data via exchanging\nmessages along edges. One limitation of this message passing paradigm is the\nover-squashing problem. Over-squashing occurs when messages from a node's\nexpanded receptive field are compressed into fixed-size vectors, potentially\ncausing information loss. To address this issue, recent works have explored\nusing expander graphs, which are highly-connected sparse graphs with low\ndiameters, to perform message passing. However, current methods on expander\ngraph propagation only consider pair-wise interactions, ignoring higher-order\nstructures in complex data. To explore the benefits of capturing these\nhigher-order correlations while still leveraging expander graphs, we introduce\nhigher-order expander graph propagation. We propose two methods for\nconstructing bipartite expanders and evaluate their performance on both\nsynthetic and real-world datasets.",
            "author": [
                "Thomas Christie",
                "Yu He"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07966v1",
                "http://arxiv.org/pdf/2311.07966v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07965v2",
            "title": "DQR-TTS: Semi-supervised Text-to-speech Synthesis with Dynamic Quantized\n  Representation",
            "updated": "2023-11-29T01:34:51Z",
            "published": "2023-11-14T07:40:08Z",
            "summary": "Most existing neural-based text-to-speech methods rely on extensive datasets\nand face challenges under low-resource condition. In this paper, we introduce a\nnovel semi-supervised text-to-speech synthesis model that learns from both\npaired and unpaired data to address this challenge. The key component of the\nproposed model is a dynamic quantized representation module, which is\nintegrated into a sequential autoencoder. When given paired data, the module\nincorporates a trainable codebook that learns quantized representations under\nthe supervision of the paired data. However, due to the limited paired data in\nlow-resource scenario, these paired data are difficult to cover all phonemes.\nThen unpaired data is fed to expand the dynamic codebook by adding quantized\nrepresentation vectors that are sufficiently distant from the existing ones\nduring training. Experiments show that with less than 120 minutes of paired\ndata, the proposed method outperforms existing methods in both subjective and\nobjective metrics.",
            "author": [
                "Jiangzong Wang",
                "Pengcheng Li",
                "Xulong Zhang",
                "Ning Cheng",
                "Jing Xiao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07965v2",
                "http://arxiv.org/pdf/2311.07965v2"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08434v1",
            "title": "Uplift Modeling based on Graph Neural Network Combined with Causal\n  Knowledge",
            "updated": "2023-11-14T07:21:00Z",
            "published": "2023-11-14T07:21:00Z",
            "summary": "Uplift modeling is a fundamental component of marketing effect modeling,\nwhich is commonly employed to evaluate the effects of treatments on outcomes.\nThrough uplift modeling, we can identify the treatment with the greatest\nbenefit. On the other side, we can identify clients who are likely to make\nfavorable decisions in response to a certain treatment. In the past, uplift\nmodeling approaches relied heavily on the difference-in-difference (DID)\narchitecture, paired with a machine learning model as the estimation learner,\nwhile neglecting the link and confidential information between features. We\nproposed a framework based on graph neural networks that combine causal\nknowledge with an estimate of uplift value. Firstly, we presented a causal\nrepresentation technique based on CATE (conditional average treatment effect)\nestimation and adjacency matrix structure learning. Secondly, we suggested a\nmore scalable uplift modeling framework based on graph convolution networks for\ncombining causal knowledge. Our findings demonstrate that this method works\neffectively for predicting uplift values, with small errors in typical\nsimulated data, and its effectiveness has been verified in actual industry\nmarketing data.",
            "author": [
                "Haowen Wang",
                "Xinyan Ye",
                "Yangze Zhou",
                "Zhiyi Zhang",
                "Longhan Zhang",
                "Jing Jiang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08434v1",
                "http://arxiv.org/pdf/2311.08434v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07957v1",
            "title": "Language Models are Better Bug Detector Through Code-Pair Classification",
            "updated": "2023-11-14T07:20:57Z",
            "published": "2023-11-14T07:20:57Z",
            "summary": "Large language models (LLMs) such as GPT-3.5 and CodeLlama are powerful\nmodels for code generation and understanding. Fine-tuning these models comes\nwith a high computational cost and requires a large labeled dataset.\nAlternatively, in-context learning techniques allow models to learn downstream\ntasks with only a few examples. Recently, researchers have shown how in-context\nlearning performs well in bug detection and repair. In this paper, we propose\ncode-pair classification task in which both the buggy and non-buggy versions\nare given to the model, and the model identifies the buggy ones. We evaluate\nour task in real-world dataset of bug detection and two most powerful LLMs. Our\nexperiments indicate that an LLM can often pick the buggy from the non-buggy\nversion of the code, and the code-pair classification task is much easier\ncompared to be given a snippet and deciding if and where a bug exists.",
            "author": [
                "Kamel Alrashedy"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07957v1",
                "http://arxiv.org/pdf/2311.07957v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07956v2",
            "title": "Robust Learning Based Condition Diagnosis Method for Distribution\n  Network Switchgear",
            "updated": "2023-12-07T00:17:41Z",
            "published": "2023-11-14T07:20:46Z",
            "summary": "This paper introduces a robust, learning-based method for diagnosing the\nstate of distribution network switchgear, which is crucial for maintaining the\npower quality for end users. Traditional diagnostic models often rely heavily\non expert knowledge and lack robustness. To address this, our method\nincorporates an expanded feature vector that includes environmental data,\ntemperature readings, switch position, motor operation, insulation conditions,\nand local discharge information. We tackle the issue of high dimensionality\nthrough feature mapping. The method introduces a decision radius to categorize\nunlabeled samples and updates the model parameters using a combination of\nsupervised and unsupervised loss, along with a consistency regularization\nfunction. This approach ensures robust learning even with a limited number of\nlabeled samples. Comparative analysis demonstrates that this method\nsignificantly outperforms existing models in both accuracy and robustness.",
            "author": [
                "Wenxi Zhang",
                "Zhe Li",
                "Weixi Li",
                "Weisi Ma",
                "Xinyi Chen",
                "Sizhe Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07956v2",
                "http://arxiv.org/pdf/2311.07956v2"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07955v2",
            "title": "Deep Learning-Based Object Detection in Maritime Unmanned Aerial Vehicle\n  Imagery: Review and Experimental Comparisons",
            "updated": "2023-11-15T02:38:37Z",
            "published": "2023-11-14T07:20:38Z",
            "summary": "With the advancement of maritime unmanned aerial vehicles (UAVs) and deep\nlearning technologies, the application of UAV-based object detection has become\nincreasingly significant in the fields of maritime industry and ocean\nengineering. Endowed with intelligent sensing capabilities, the maritime UAVs\nenable effective and efficient maritime surveillance. To further promote the\ndevelopment of maritime UAV-based object detection, this paper provides a\ncomprehensive review of challenges, relative methods, and UAV aerial datasets.\nSpecifically, in this work, we first briefly summarize four challenges for\nobject detection on maritime UAVs, i.e., object feature diversity, device\nlimitation, maritime environment variability, and dataset scarcity. We then\nfocus on computational methods to improve maritime UAV-based object detection\nperformance in terms of scale-aware, small object detection, view-aware,\nrotated object detection, lightweight methods, and others. Next, we review the\nUAV aerial image/video datasets and propose a maritime UAV aerial dataset named\nMS2ship for ship detection. Furthermore, we conduct a series of experiments to\npresent the performance evaluation and robustness analysis of object detection\nmethods on maritime datasets. Eventually, we give the discussion and outlook on\nfuture works for maritime UAV-based object detection. The MS2ship dataset is\navailable at\n\\href{https://github.com/zcj234/MS2ship}{https://github.com/zcj234/MS2ship}.",
            "author": [
                "Chenjie Zhao",
                "Ryan Wen Liu",
                "Jingxiang Qu",
                "Ruobin Gao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07955v2",
                "http://arxiv.org/pdf/2311.07955v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07951v1",
            "title": "A Fast and Simple Algorithm for computing the MLE of Amplitude Density\n  Function Parameters",
            "updated": "2023-11-14T07:04:47Z",
            "published": "2023-11-14T07:04:47Z",
            "summary": "Over the last decades, the family of $\\alpha$-stale distributions has proven\nto be useful for modelling in telecommunication systems. Particularly, in the\ncase of radar applications, finding a fast and accurate estimation for the\namplitude density function parameters appears to be very important. In this\nwork, the maximum likelihood estimator (MLE) is proposed for parameters of the\namplitude distribution. To do this, the amplitude data are \\emph{projected} on\nthe horizontal and vertical axes using two simple transformations. It is proved\nthat the \\emph{projected} data follow a zero-location symmetric $\\alpha$-stale\ndistribution for which the MLE can be computed quite fast. The average of\ncomputed MLEs based on two \\emph{projections} is considered as estimator for\nparameters of the amplitude distribution. Performance of the proposed\n\\emph{projection} method is demonstrated through simulation study and analysis\nof two sets of real radar data.",
            "author": [
                "Mahdi Teimouri"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07951v1",
                "http://arxiv.org/pdf/2311.07951v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07948v1",
            "title": "Finding Inductive Loop Invariants using Large Language Models",
            "updated": "2023-11-14T06:58:09Z",
            "published": "2023-11-14T06:58:09Z",
            "summary": "Loop invariants are fundamental to reasoning about programs with loops. They\nestablish properties about a given loop's behavior. When they additionally are\ninductive, they become useful for the task of formal verification that seeks to\nestablish strong mathematical guarantees about program's runtime behavior. The\ninductiveness ensures that the invariants can be checked locally without\nconsulting the entire program, thus are indispensable artifacts in a formal\nproof of correctness. Finding inductive loop invariants is an undecidable\nproblem, and despite a long history of research towards practical solutions, it\nremains far from a solved problem. This paper investigates the capabilities of\nthe Large Language Models (LLMs) in offering a new solution towards this old,\nyet important problem. To that end, we first curate a dataset of verification\nproblems on programs with loops. Next, we design a prompt for exploiting LLMs,\nobtaining inductive loop invariants, that are checked for correctness using\nsound symbolic tools. Finally, we explore the effectiveness of using an\nefficient combination of a symbolic tool and an LLM on our dataset and compare\nit against a purely symbolic baseline. Our results demonstrate that LLMs can\nhelp improve the state-of-the-art in automated program verification.",
            "author": [
                "Adharsh Kamath",
                "Aditya Senthilnathan",
                "Saikat Chakraborty",
                "Pantazis Deligiannis",
                "Shuvendu K. Lahiri",
                "Akash Lal",
                "Aseem Rastogi",
                "Subhajit Roy",
                "Rahul Sharma"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07948v1",
                "http://arxiv.org/pdf/2311.07948v1"
            ],
            "primary_category": "cs.PL",
            "category": [
                "cs.PL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07946v1",
            "title": "The Impact of Adversarial Node Placement in Decentralized Federated\n  Learning Networks",
            "updated": "2023-11-14T06:48:50Z",
            "published": "2023-11-14T06:48:50Z",
            "summary": "As Federated Learning (FL) grows in popularity, new decentralized frameworks\nare becoming widespread. These frameworks leverage the benefits of\ndecentralized environments to enable fast and energy-efficient inter-device\ncommunication. However, this growing popularity also intensifies the need for\nrobust security measures. While existing research has explored various aspects\nof FL security, the role of adversarial node placement in decentralized\nnetworks remains largely unexplored. This paper addresses this gap by analyzing\nthe performance of decentralized FL for various adversarial placement\nstrategies when adversaries can jointly coordinate their placement within a\nnetwork. We establish two baseline strategies for placing adversarial node:\nrandom placement and network centrality-based placement. Building on this\nfoundation, we propose a novel attack algorithm that prioritizes adversarial\nspread over adversarial centrality by maximizing the average network distance\nbetween adversaries. We show that the new attack algorithm significantly\nimpacts key performance metrics such as testing accuracy, outperforming the\nbaseline frameworks by between 9% and 66.5% for the considered setups. Our\nfindings provide valuable insights into the vulnerabilities of decentralized FL\nsystems, setting the stage for future research aimed at developing more secure\nand robust decentralized FL frameworks.",
            "author": [
                "Adam Piaseczny",
                "Eric Ruzomberka",
                "Rohit Parasnis",
                "Christopher G. Brinton"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07946v1",
                "http://arxiv.org/pdf/2311.07946v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08433v2",
            "title": "Clinical Characteristics and Laboratory Biomarkers in ICU-admitted\n  Septic Patients with and without Bacteremia",
            "updated": "2023-11-16T12:21:56Z",
            "published": "2023-11-14T06:44:26Z",
            "summary": "Few studies have investigated the diagnostic utilities of biomarkers for\npredicting bacteremia among septic patients admitted to intensive care units\n(ICU). Therefore, this study evaluated the prediction power of laboratory\nbiomarkers to utilize those markers with high performance to optimize the\npredictive model for bacteremia. This retrospective cross-sectional study was\nconducted at the ICU department of Gyeongsang National University Changwon\nHospital in 2019. Adult patients qualifying SEPSIS-3 (increase in sequential\norgan failure score greater than or equal to 2) criteria with at least two sets\nof blood culture were selected. Collected data was initially analyzed\nindependently to identify the significant predictors, which was then used to\nbuild the multivariable logistic regression (MLR) model. A total of 218\npatients with 48 cases of true bacteremia were analyzed in this research. Both\nCRP and PCT showed a substantial area under the curve (AUC) value for\ndiscriminating bacteremia among septic patients (0.757 and 0.845,\nrespectively). To further enhance the predictive accuracy, we combined PCT,\nbilirubin, neutrophil lymphocyte ratio (NLR), platelets, lactic acid,\nerythrocyte sedimentation rate (ESR), and Glasgow Coma Scale (GCS) score to\nbuild the predictive model with an AUC of 0.907 (95% CI, 0.843 to 0.956). In\naddition, a high association between bacteremia and mortality rate was\ndiscovered through the survival analysis (0.004). While PCT is certainly a\nuseful index for distinguishing patients with and without bacteremia by itself,\nour MLR model indicates that the accuracy of bacteremia prediction\nsubstantially improves by the combined use of PCT, bilirubin, NLR, platelets,\nlactic acid, ESR, and GCS score.",
            "author": [
                "Sangwon Baek",
                "Seung Jun Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08433v2",
                "http://arxiv.org/pdf/2311.08433v2"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM",
                "cs.LG",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07939v1",
            "title": "Discretized Distributed Optimization over Dynamic Digraphs",
            "updated": "2023-11-14T06:33:41Z",
            "published": "2023-11-14T06:33:41Z",
            "summary": "We consider a discrete-time model of continuous-time distributed optimization\nover dynamic directed-graphs (digraphs) with applications to distributed\nlearning. Our optimization algorithm works over general strongly connected\ndynamic networks under switching topologies, e.g., in mobile multi-agent\nsystems and volatile networks due to link failures. Compared to many existing\nlines of work, there is no need for bi-stochastic weight designs on the links.\nThe existing literature mostly needs the link weights to be stochastic using\nspecific weight-design algorithms needed both at the initialization and at all\ntimes when the topology of the network changes. This paper eliminates the need\nfor such algorithms and paves the way for distributed optimization over\ntime-varying digraphs. We derive the bound on the gradient-tracking step-size\nand discrete time-step for convergence and prove dynamic stability using\narguments from consensus algorithms, matrix perturbation theory, and Lyapunov\ntheory. This work, particularly, is an improvement over existing\nstochastic-weight undirected networks in case of link removal or packet drops.\nThis is because the existing literature may need to rerun time-consuming and\ncomputationally complex algorithms for stochastic design, while the proposed\nstrategy works as long as the underlying network is weight-symmetric and\nbalanced. The proposed optimization framework finds applications to distributed\nclassification and learning.",
            "author": [
                "Mohammadreza Doostmohammadian",
                "Wei Jiang",
                "Muwahida Liaquat",
                "Alireza Aghasi",
                "Houman Zarrabi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07939v1",
                "http://arxiv.org/pdf/2311.07939v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG",
                "cs.SY",
                "eess.SP",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07932v1",
            "title": "Cross-subject dual-domain fusion network with task-related and\n  task-discriminant component analysis enhancing one-shot SSVEP classification",
            "updated": "2023-11-14T06:20:50Z",
            "published": "2023-11-14T06:20:50Z",
            "summary": "This study addresses the significant challenge of developing efficient\ndecoding algorithms for classifying steady-state visual evoked potentials\n(SSVEPs) in scenarios characterized by extreme scarcity of calibration data,\nwhere only one calibration is available for each stimulus target. To tackle\nthis problem, we introduce a novel cross-subject dual-domain fusion network\n(CSDuDoFN) incorporating task-related and task-discriminant component analysis\n(TRCA and TDCA) for one-shot SSVEP classification. The CSDuDoFN framework is\ndesigned to comprehensively transfer information from source subjects, while\nTRCA and TDCA are employed to exploit the single available calibration of the\ntarget subject. Specifically, we develop multi-reference least-squares\ntransformation (MLST) to map data from both source subjects and the target\nsubject into the domain of sine-cosine templates, thereby mitigating\ninter-individual variability and benefiting transfer learning. Subsequently,\nthe transformed data in the sine-cosine templates domain and the original\ndomain data are separately utilized to train a convolutional neural network\n(CNN) model, with the adequate fusion of their feature maps occurring at\ndistinct network layers. To further capitalize on the calibration of the target\nsubject, source aliasing matrix estimation (SAME) data augmentation is\nincorporated into the training process of the ensemble TRCA (eTRCA) and TDCA\nmodels. Ultimately, the outputs of the CSDuDoFN, eTRCA, and TDCA are combined\nfor SSVEP classification. The effectiveness of our proposed approach is\ncomprehensively evaluated on three publicly available SSVEP datasets, achieving\nthe best performance on two datasets and competitive performance on one. This\nunderscores the potential for integrating brain-computer interface (BCI) into\ndaily life.",
            "author": [
                "Yang Deng",
                "Zhiwei Ji",
                "Yijun Wang",
                "S. Kevin Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07932v1",
                "http://arxiv.org/pdf/2311.07932v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07929v1",
            "title": "Self-supervised Heterogeneous Graph Variational Autoencoders",
            "updated": "2023-11-14T06:15:16Z",
            "published": "2023-11-14T06:15:16Z",
            "summary": "Heterogeneous Information Networks (HINs), which consist of various types of\nnodes and edges, have recently demonstrated excellent performance in graph\nmining. However, most existing heterogeneous graph neural networks (HGNNs)\nignore the problems of missing attributes, inaccurate attributes and scarce\nlabels for nodes, which limits their expressiveness. In this paper, we propose\na generative self-supervised model SHAVA to address these issues\nsimultaneously. Specifically, SHAVA first initializes all the nodes in the\ngraph with a low-dimensional representation matrix. After that, based on the\nvariational graph autoencoder framework, SHAVA learns both node-level and\nattribute-level embeddings in the encoder, which can provide fine-grained\nsemantic information to construct node attributes. In the decoder, SHAVA\nreconstructs both links and attributes. Instead of directly reconstructing raw\nfeatures for attributed nodes, SHAVA generates the initial low-dimensional\nrepresentation matrix for all the nodes, based on which raw features of\nattributed nodes are further reconstructed to leverage accurate attributes. In\nthis way, SHAVA can not only complete informative features for non-attributed\nnodes, but rectify inaccurate ones for attributed nodes. Finally, we conduct\nextensive experiments to show the superiority of SHAVA in tackling HINs with\nmissing and inaccurate attributes.",
            "author": [
                "Yige Zhao",
                "Jianxiang Yu",
                "Yao Cheng",
                "Chengcheng Yu",
                "Yiding Liu",
                "Xiang Li",
                "Shuaiqiang Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07929v1",
                "http://arxiv.org/pdf/2311.07929v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07928v1",
            "title": "Towards Improving Robustness Against Common Corruptions in Object\n  Detectors Using Adversarial Contrastive Learning",
            "updated": "2023-11-14T06:13:52Z",
            "published": "2023-11-14T06:13:52Z",
            "summary": "Neural networks have revolutionized various domains, exhibiting remarkable\naccuracy in tasks like natural language processing and computer vision.\nHowever, their vulnerability to slight alterations in input samples poses\nchallenges, particularly in safety-critical applications like autonomous\ndriving. Current approaches, such as introducing distortions during training,\nfall short in addressing unforeseen corruptions. This paper proposes an\ninnovative adversarial contrastive learning framework to enhance neural network\nrobustness simultaneously against adversarial attacks and common corruptions.\nBy generating instance-wise adversarial examples and optimizing contrastive\nloss, our method fosters representations that resist adversarial perturbations\nand remain robust in real-world scenarios. Subsequent contrastive learning then\nstrengthens the similarity between clean samples and their adversarial\ncounterparts, fostering representations resistant to both adversarial attacks\nand common distortions. By focusing on improving performance under adversarial\nand real-world conditions, our approach aims to bolster the robustness of\nneural networks in safety-critical applications, such as autonomous vehicles\nnavigating unpredictable weather conditions. We anticipate that this framework\nwill contribute to advancing the reliability of neural networks in challenging\nenvironments, facilitating their widespread adoption in mission-critical\nscenarios.",
            "author": [
                "Shashank Kotyan",
                "Danilo Vasconcellos Vargas"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07928v1",
                "http://arxiv.org/pdf/2311.07928v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07925v1",
            "title": "Brain-Driven Representation Learning Based on Diffusion Model",
            "updated": "2023-11-14T05:59:58Z",
            "published": "2023-11-14T05:59:58Z",
            "summary": "Interpreting EEG signals linked to spoken language presents a complex\nchallenge, given the data's intricate temporal and spatial attributes, as well\nas the various noise factors. Denoising diffusion probabilistic models (DDPMs),\nwhich have recently gained prominence in diverse areas for their capabilities\nin representation learning, are explored in our research as a means to address\nthis issue. Using DDPMs in conjunction with a conditional autoencoder, our new\napproach considerably outperforms traditional machine learning algorithms and\nestablished baseline models in accuracy. Our results highlight the potential of\nDDPMs as a sophisticated computational method for the analysis of\nspeech-related EEG signals. This could lead to significant advances in\nbrain-computer interfaces tailored for spoken communication.",
            "author": [
                "Soowon Kim",
                "Seo-Hyun Lee",
                "Young-Eun Lee",
                "Ji-Won Lee",
                "Ji-Ha Park",
                "Seong-Whan Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07925v1",
                "http://arxiv.org/pdf/2311.07925v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.09248v1",
            "title": "Smart Home Goal Feature Model -- A guide to support Smart Homes for\n  Ageing in Place",
            "updated": "2023-11-14T05:42:13Z",
            "published": "2023-11-14T05:42:13Z",
            "summary": "Smart technologies are significant in supporting ageing in place for elderly.\nLeveraging Artificial Intelligence (AI) and Machine Learning (ML), it provides\npeace of mind, enabling the elderly to continue living independently. Elderly\nuse smart technologies for entertainment and social interactions, this can be\nextended to provide safety and monitor health and environmental conditions,\ndetect emergencies and notify informal and formal caregivers when care is\nneeded. This paper provides an overview of the smart home technologies\ncommercially available to support ageing in place, the advantages and\nchallenges of smart home technologies, and their usability from elderlys\nperspective. Synthesizing prior knowledge, we created a structured Smart Home\nGoal Feature Model (SHGFM) to resolve heuristic approaches used by the Subject\nMatter Experts (SMEs) at aged care facilities and healthcare researchers in\nadapting smart homes. The SHGFM provides SMEs the ability to (i) establish\ngoals and (ii) identify features to set up strategies to design, develop and\ndeploy smart homes for the elderly based on personalised needs. Our model\nprovides guidance to healthcare researchers and aged care industries to set up\nsmart homes based on the needs of elderly, by defining a set of goals at\ndifferent levels mapped to a different set of features.",
            "author": [
                "Irini Logothetis",
                "Priya Rani",
                "Shangeetha Sivasothy",
                "Rajesh Vasa",
                "Kon Mouzakis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09248v1",
                "http://arxiv.org/pdf/2311.09248v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07919v1",
            "title": "Qwen-Audio: Advancing Universal Audio Understanding via Unified\n  Large-Scale Audio-Language Models",
            "updated": "2023-11-14T05:34:50Z",
            "published": "2023-11-14T05:34:50Z",
            "summary": "Recently, instruction-following audio-language models have received broad\nattention for audio interaction with humans. However, the absence of\npre-trained audio models capable of handling diverse audio types and tasks has\nhindered progress in this field. Consequently, most existing works have only\nbeen able to support a limited range of interaction capabilities. In this\npaper, we develop the Qwen-Audio model and address this limitation by scaling\nup audio-language pre-training to cover over 30 tasks and various audio types,\nsuch as human speech, natural sounds, music, and songs, to facilitate universal\naudio understanding abilities. However, directly co-training all tasks and\ndatasets can lead to interference issues, as the textual labels associated with\ndifferent datasets exhibit considerable variations due to differences in task\nfocus, language, granularity of annotation, and text structure. To overcome the\none-to-many interference, we carefully design a multi-task training framework\nby conditioning on a sequence of hierarchical tags to the decoder for\nencouraging knowledge sharing and avoiding interference through shared and\nspecified tags respectively. Remarkably, Qwen-Audio achieves impressive\nperformance across diverse benchmark tasks without requiring any task-specific\nfine-tuning, surpassing its counterparts. Building upon the capabilities of\nQwen-Audio, we further develop Qwen-Audio-Chat, which allows for input from\nvarious audios and text inputs, enabling multi-turn dialogues and supporting\nvarious audio-central scenarios.",
            "author": [
                "Yunfei Chu",
                "Jin Xu",
                "Xiaohuan Zhou",
                "Qian Yang",
                "Shiliang Zhang",
                "Zhijie Yan",
                "Chang Zhou",
                "Jingren Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07919v1",
                "http://arxiv.org/pdf/2311.07919v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07914v1",
            "title": "Can Knowledge Graphs Reduce Hallucinations in LLMs? : A Survey",
            "updated": "2023-11-14T05:21:57Z",
            "published": "2023-11-14T05:21:57Z",
            "summary": "The contemporary LLMs are prone to producing hallucinations, stemming mainly\nfrom the knowledge gaps within the models. To address this critical limitation,\nresearchers employ diverse strategies to augment the LLMs by incorporating\nexternal knowledge, aiming to reduce hallucinations and enhance reasoning\naccuracy. Among these strategies, leveraging knowledge graphs as a source of\nexternal information has demonstrated promising results. In this survey, we\nconduct a comprehensive review of these knowledge-graph-based knowledge\naugmentation techniques in LLMs, focusing on their efficacy in mitigating\nhallucinations. We systematically categorize these methods into three\noverarching groups, offering both methodological comparisons and empirical\nevaluations of their performance. Lastly, the paper explores the challenges\nassociated with these techniques and outlines potential avenues for future\nresearch in this emerging field.",
            "author": [
                "Garima Agrawal",
                "Tharindu Kumarage",
                "Zeyad Alghami",
                "Huan Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07914v1",
                "http://arxiv.org/pdf/2311.07914v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07911v1",
            "title": "Instruction-Following Evaluation for Large Language Models",
            "updated": "2023-11-14T05:13:55Z",
            "published": "2023-11-14T05:13:55Z",
            "summary": "One core capability of Large Language Models (LLMs) is to follow natural\nlanguage instructions. However, the evaluation of such abilities is not\nstandardized: Human evaluations are expensive, slow, and not objectively\nreproducible, while LLM-based auto-evaluation is potentially biased or limited\nby the ability of the evaluator LLM. To overcome these issues, we introduce\nInstruction-Following Eval (IFEval) for large language models. IFEval is a\nstraightforward and easy-to-reproduce evaluation benchmark. It focuses on a set\nof \"verifiable instructions\" such as \"write in more than 400 words\" and\n\"mention the keyword of AI at least 3 times\". We identified 25 types of those\nverifiable instructions and constructed around 500 prompts, with each prompt\ncontaining one or more verifiable instructions. We show evaluation results of\ntwo widely available LLMs on the market. Our code and data can be found at\nhttps://github.com/google-research/google-research/tree/master/instruction_following_eval",
            "author": [
                "Jeffrey Zhou",
                "Tianjian Lu",
                "Swaroop Mishra",
                "Siddhartha Brahma",
                "Sujoy Basu",
                "Yi Luan",
                "Denny Zhou",
                "Le Hou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07911v1",
                "http://arxiv.org/pdf/2311.07911v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG",
                "68T50 (Primary) 68T99 (Secondary)",
                "I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07910v1",
            "title": "Force Training Neural Network Potential Energy Surface Models",
            "updated": "2023-11-14T05:10:12Z",
            "published": "2023-11-14T05:10:12Z",
            "summary": "Machine learned chemical potentials have shown great promise as alternatives\nto conventional computational chemistry methods to represent the potential\nenergy of a given atomic or molecular system as a function of its geometry.\nHowever, such potentials are only as good as the data they are trained on, and\nbuilding a comprehensive training set can be a costly process. Therefore, it is\nimportant to extract as much information from training data as possible without\nfurther increasing the computational cost. One way to accomplish this is by\ntraining on molecular forces in addition to energies. This allows for three\nadditional labels per atom within the molecule. Here we develop a neural\nnetwork potential energy surface for studying a hydrogen transfer reaction\nbetween two conformers of C5H5. We show that, for a much smaller training set,\nforce training can greatly improve the accuracy of the model compared to only\ntraining to energies. We also demonstrate the importance of choosing the proper\nforce to energy weight ratio for the loss function to minimize the model test\nerror.",
            "author": [
                "Christian Devereux",
                "Yoona Yang",
                "Carles Mart\u00ed",
                "Judit Z\u00e1dor",
                "Michael S. Eldred",
                "Habib N. Najm"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07910v1",
                "http://arxiv.org/pdf/2311.07910v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07908v1",
            "title": "Learning Bayes-Optimal Channel Estimation for Holographic MIMO in\n  Unknown EM Environments",
            "updated": "2023-11-14T05:02:46Z",
            "published": "2023-11-14T05:02:46Z",
            "summary": "Holographic MIMO (HMIMO) has recently been recognized as a promising enabler\nfor future 6G systems through the use of an ultra-massive number of antennas in\na compact space to exploit the propagation characteristics of the\nelectromagnetic (EM) channel. Nevertheless, the promised gain of HMIMO could\nnot be fully unleashed without an efficient means to estimate the\nhigh-dimensional channel. Bayes-optimal estimators typically necessitate either\na large volume of supervised training samples or a priori knowledge of the true\nchannel distribution, which could hardly be available in practice due to the\nenormous system scale and the complicated EM environments. It is thus important\nto design a Bayes-optimal estimator for the HMIMO channels in arbitrary and\nunknown EM environments, free of any supervision or priors. This work proposes\na self-supervised minimum mean-square-error (MMSE) channel estimation algorithm\nbased on powerful machine learning tools, i.e., score matching and principal\ncomponent analysis. The training stage requires only the pilot signals, without\nknowing the spatial correlation, the ground-truth channels, or the received\nsignal-to-noise-ratio. Simulation results will show that, even being totally\nself-supervised, the proposed algorithm can still approach the performance of\nthe oracle MMSE method with an extremely low complexity, making it a\ncompetitive candidate in practice.",
            "author": [
                "Wentao Yu",
                "Hengtao He",
                "Xianghao Yu",
                "Shenghui Song",
                "Jun Zhang",
                "Ross D. Murch",
                "Khaled B. Letaief"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07908v1",
                "http://arxiv.org/pdf/2311.07908v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.09247v2",
            "title": "Comparing Humans, GPT-4, and GPT-4V On Abstraction and Reasoning Tasks",
            "updated": "2023-11-26T20:42:08Z",
            "published": "2023-11-14T04:33:49Z",
            "summary": "We explore the abstract reasoning abilities of text-only and multimodal\nversions of GPT-4, using the ConceptARC benchmark [10], which is designed to\nevaluate robust understanding and reasoning with core-knowledge concepts. We\nextend the work of Moskvichev et al. [10] by evaluating GPT-4 on more detailed,\none-shot prompting (rather than simple, zero-shot prompts) with text versions\nof ConceptARC tasks, and by evaluating GPT-4V, the multimodal version of GPT-4,\non zero- and one-shot prompts using image versions of the simplest tasks. Our\nexperimental results support the conclusion that neither version of GPT-4 has\ndeveloped robust abstraction abilities at humanlike levels.",
            "author": [
                "Melanie Mitchell",
                "Alessandro B. Palmarini",
                "Arseny Moskvichev"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09247v2",
                "http://arxiv.org/pdf/2311.09247v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07896v1",
            "title": "Bayesian Conditional Diffusion Models for Versatile Spatiotemporal\n  Turbulence Generation",
            "updated": "2023-11-14T04:08:14Z",
            "published": "2023-11-14T04:08:14Z",
            "summary": "Turbulent flows have historically presented formidable challenges to\npredictive computational modeling. Traditional numerical simulations often\nrequire vast computational resources, making them infeasible for numerous\nengineering applications. As an alternative, deep learning-based surrogate\nmodels have emerged, offering data-drive solutions. However, these are\ntypically constructed within deterministic settings, leading to shortfall in\ncapturing the innate chaotic and stochastic behaviors of turbulent dynamics. We\nintroduce a novel generative framework grounded in probabilistic diffusion\nmodels for versatile generation of spatiotemporal turbulence. Our method\nunifies both unconditional and conditional sampling strategies within a\nBayesian framework, which can accommodate diverse conditioning scenarios,\nincluding those with a direct differentiable link between specified conditions\nand generated unsteady flow outcomes, and scenarios lacking such explicit\ncorrelations. A notable feature of our approach is the method proposed for\nlong-span flow sequence generation, which is based on autoregressive\ngradient-based conditional sampling, eliminating the need for cumbersome\nretraining processes. We showcase the versatile turbulence generation\ncapability of our framework through a suite of numerical experiments,\nincluding: 1) the synthesis of LES simulated instantaneous flow sequences from\nURANS inputs; 2) holistic generation of inhomogeneous, anisotropic wall-bounded\nturbulence, whether from given initial conditions, prescribed turbulence\nstatistics, or entirely from scratch; 3) super-resolved generation of\nhigh-speed turbulent boundary layer flows from low-resolution data across a\nrange of input resolutions. Collectively, our numerical experiments highlight\nthe merit and transformative potential of the proposed methods, making a\nsignificant advance in the field of turbulence generation.",
            "author": [
                "Han Gao",
                "Xu Han",
                "Xiantao Fan",
                "Luning Sun",
                "Li-Ping Liu",
                "Lian Duan",
                "Jian-Xun Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07896v1",
                "http://arxiv.org/pdf/2311.07896v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07888v1",
            "title": "RoboSense At Edge: Detecting Slip, Crumple and Shape of the Object in\n  Robotic Hand for Teleoprations",
            "updated": "2023-11-14T03:49:20Z",
            "published": "2023-11-14T03:49:20Z",
            "summary": "Slip and crumple detection is essential for performing robust manipulation\ntasks with a robotic hand (RH) like remote surgery. It has been one of the\nchallenging problems in the robotics manipulation community. In this work, we\npropose a technique based on machine learning (ML) based techniques to detect\nthe slip, and crumple as well as the shape of an object that is currently held\nin the robotic hand. We proposed ML model will detect the slip, crumple, and\nshape using the force/torque exerted and the angular positions of the actuators\npresent in the RH. The proposed model would be integrated into the loop of a\nrobotic hand(RH) and haptic glove(HG). This would help us to reduce the latency\nin case of teleoperation",
            "author": [
                "Sudev Kumar Padhi",
                "Mohit Kumar",
                "Debanka Giri",
                "Subidh Ali"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07888v1",
                "http://arxiv.org/pdf/2311.07888v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07877v1",
            "title": "Test-Time Training for Semantic Segmentation with Output Contrastive\n  Loss",
            "updated": "2023-11-14T03:13:47Z",
            "published": "2023-11-14T03:13:47Z",
            "summary": "Although deep learning-based segmentation models have achieved impressive\nperformance on public benchmarks, generalizing well to unseen environments\nremains a major challenge. To improve the model's generalization ability to the\nnew domain during evaluation, the test-time training (TTT) is a challenging\nparadigm that adapts the source-pretrained model in an online fashion. Early\nefforts on TTT mainly focus on the image classification task. Directly\nextending these methods to semantic segmentation easily experiences unstable\nadaption due to segmentation's inherent characteristics, such as extreme class\nimbalance and complex decision spaces. To stabilize the adaptation process, we\nintroduce contrastive loss (CL), known for its capability to learn robust and\ngeneralized representations. Nevertheless, the traditional CL operates in the\nrepresentation space and cannot directly enhance predictions. In this paper, we\nresolve this limitation by adapting the CL to the output space, employing a\nhigh temperature, and simplifying the formulation, resulting in a\nstraightforward yet effective loss function called Output Contrastive Loss\n(OCL). Our comprehensive experiments validate the efficacy of our approach\nacross diverse evaluation scenarios. Notably, our method excels even when\napplied to models initially pre-trained using domain adaptation methods on test\ndomain data, showcasing its resilience and adaptability.\\footnote{Code and more\ninformation could be found at~ \\url{https://github.com/dazhangyu123/OCL}}",
            "author": [
                "Yunlong Zhang",
                "Yuxuan Sun",
                "Sunyi Zheng",
                "Zhongyi Shui",
                "Chenglu Zhu",
                "Lin Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07877v1",
                "http://arxiv.org/pdf/2311.07877v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07876v1",
            "title": "Learning Adversarial Low-rank Markov Decision Processes with Unknown\n  Transition and Full-information Feedback",
            "updated": "2023-11-14T03:12:43Z",
            "published": "2023-11-14T03:12:43Z",
            "summary": "In this work, we study the low-rank MDPs with adversarially changed losses in\nthe full-information feedback setting. In particular, the unknown transition\nprobability kernel admits a low-rank matrix decomposition \\citep{REPUCB22}, and\nthe loss functions may change adversarially but are revealed to the learner at\nthe end of each episode. We propose a policy optimization-based algorithm POLO,\nand we prove that it attains the\n$\\widetilde{O}(K^{\\frac{5}{6}}A^{\\frac{1}{2}}d\\ln(1+M)/(1-\\gamma)^2)$ regret\nguarantee, where $d$ is rank of the transition kernel (and hence the dimension\nof the unknown representations), $A$ is the cardinality of the action space,\n$M$ is the cardinality of the model class, and $\\gamma$ is the discounted\nfactor. Notably, our algorithm is oracle-efficient and has a regret guarantee\nwith no dependence on the size of potentially arbitrarily large state space.\nFurthermore, we also prove an $\\Omega(\\frac{\\gamma^2}{1-\\gamma} \\sqrt{d A K})$\nregret lower bound for this problem, showing that low-rank MDPs are\nstatistically more difficult to learn than linear MDPs in the regret\nminimization setting. To the best of our knowledge, we present the first\nalgorithm that interleaves representation learning, exploration, and\nexploitation to achieve the sublinear regret guarantee for RL with nonlinear\nfunction approximation and adversarial losses.",
            "author": [
                "Canzhe Zhao",
                "Ruofeng Yang",
                "Baoxiang Wang",
                "Xuezhou Zhang",
                "Shuai Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07876v1",
                "http://arxiv.org/pdf/2311.07876v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07871v1",
            "title": "Dual-channel Prototype Network for few-shot Classification of\n  Pathological Images",
            "updated": "2023-11-14T03:03:21Z",
            "published": "2023-11-14T03:03:21Z",
            "summary": "In pathology, the rarity of certain diseases and the complexity in annotating\npathological images significantly hinder the creation of extensive,\nhigh-quality datasets. This limitation impedes the progress of deep\nlearning-assisted diagnostic systems in pathology. Consequently, it becomes\nimperative to devise a technology that can discern new disease categories from\na minimal number of annotated examples. Such a technology would substantially\nadvance deep learning models for rare diseases. Addressing this need, we\nintroduce the Dual-channel Prototype Network (DCPN), rooted in the few-shot\nlearning paradigm, to tackle the challenge of classifying pathological images\nwith limited samples. DCPN augments the Pyramid Vision Transformer (PVT)\nframework for few-shot classification via self-supervised learning and\nintegrates it with convolutional neural networks. This combination forms a\ndual-channel architecture that extracts multi-scale, highly precise\npathological features. The approach enhances the versatility of prototype\nrepresentations and elevates the efficacy of prototype networks in few-shot\npathological image classification tasks. We evaluated DCPN using three publicly\navailable pathological datasets, configuring small-sample classification tasks\nthat mirror varying degrees of clinical scenario domain shifts. Our\nexperimental findings robustly affirm DCPN's superiority in few-shot\npathological image classification, particularly in tasks within the same\ndomain, where it achieves the benchmarks of supervised learning.",
            "author": [
                "Hao Quan",
                "Xinjia Li",
                "Dayu Hu",
                "Tianhang Nan",
                "Xiaoyu Cui"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07871v1",
                "http://arxiv.org/pdf/2311.07871v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08430v1",
            "title": "Rankitect: Ranking Architecture Search Battling World-class Engineers at\n  Meta Scale",
            "updated": "2023-11-14T03:02:02Z",
            "published": "2023-11-14T03:02:02Z",
            "summary": "Neural Architecture Search (NAS) has demonstrated its efficacy in computer\nvision and potential for ranking systems. However, prior work focused on\nacademic problems, which are evaluated at small scale under well-controlled\nfixed baselines. In industry system, such as ranking system in Meta, it is\nunclear whether NAS algorithms from the literature can outperform production\nbaselines because of: (1) scale - Meta ranking systems serve billions of users,\n(2) strong baselines - the baselines are production models optimized by\nhundreds to thousands of world-class engineers for years since the rise of deep\nlearning, (3) dynamic baselines - engineers may have established new and\nstronger baselines during NAS search, and (4) efficiency - the search pipeline\nmust yield results quickly in alignment with the productionization life cycle.\nIn this paper, we present Rankitect, a NAS software framework for ranking\nsystems at Meta. Rankitect seeks to build brand new architectures by composing\nlow level building blocks from scratch. Rankitect implements and improves\nstate-of-the-art (SOTA) NAS methods for comprehensive and fair comparison under\nthe same search space, including sampling-based NAS, one-shot NAS, and\nDifferentiable NAS (DNAS). We evaluate Rankitect by comparing to multiple\nproduction ranking models at Meta. We find that Rankitect can discover new\nmodels from scratch achieving competitive tradeoff between Normalized Entropy\nloss and FLOPs. When utilizing search space designed by engineers, Rankitect\ncan generate better models than engineers, achieving positive offline\nevaluation and online A/B test at Meta scale.",
            "author": [
                "Wei Wen",
                "Kuang-Hung Liu",
                "Igor Fedorov",
                "Xin Zhang",
                "Hang Yin",
                "Weiwei Chu",
                "Kaveh Hassani",
                "Mengying Sun",
                "Jiang Liu",
                "Xu Wang",
                "Lin Jiang",
                "Yuxin Chen",
                "Buyun Zhang",
                "Xi Liu",
                "Dehua Cheng",
                "Zhengxing Chen",
                "Guang Zhao",
                "Fangqiu Han",
                "Jiyan Yang",
                "Yuchen Hao",
                "Liang Xiong",
                "Wen-Yen Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08430v1",
                "http://arxiv.org/pdf/2311.08430v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07870v2",
            "title": "AutoML for Large Capacity Modeling of Meta's Ranking Systems",
            "updated": "2023-11-16T17:21:15Z",
            "published": "2023-11-14T03:00:50Z",
            "summary": "Web-scale ranking systems at Meta serving billions of users is complex.\nImproving ranking models is essential but engineering heavy. Automated Machine\nLearning (AutoML) can release engineers from labor intensive work of tuning\nranking models; however, it is unknown if AutoML is efficient enough to meet\ntight production timeline in real-world and, at the same time, bring additional\nimprovements to the strong baselines. Moreover, to achieve higher ranking\nperformance, there is an ever-increasing demand to scale up ranking models to\neven larger capacity, which imposes more challenges on the efficiency. The\nlarge scale of models and tight production schedule requires AutoML to\noutperform human baselines by only using a small number of model evaluation\ntrials (around 100). We presents a sampling-based AutoML method, focusing on\nneural architecture search and hyperparameter optimization, addressing these\nchallenges in Meta-scale production when building large capacity models. Our\napproach efficiently handles large-scale data demands. It leverages a\nlightweight predictor-based searcher and reinforcement learning to explore vast\nsearch spaces, significantly reducing the number of model evaluations. Through\nexperiments in large capacity modeling for CTR and CVR applications, we show\nthat our method achieves outstanding Return on Investment (ROI) versus human\ntuned baselines, with up to 0.09% Normalized Entropy (NE) loss reduction or\n$25\\%$ Query per Second (QPS) increase by only sampling one hundred models on\naverage from a curated search space. The proposed AutoML method has already\nmade real-world impact where a discovered Instagram CTR model with up to -0.36%\nNE gain (over existing production baseline) was selected for large-scale online\nA/B test and show statistically significant gain. These production results\nproved AutoML efficacy and accelerated its adoption in ranking systems at Meta.",
            "author": [
                "Hang Yin",
                "Kuang-Hung Liu",
                "Mengying Sun",
                "Yuxin Chen",
                "Buyun Zhang",
                "Jiang Liu",
                "Vivek Sehgal",
                "Rudresh Rajnikant Panchal",
                "Eugen Hotaj",
                "Xi Liu",
                "Daifeng Guo",
                "Jamey Zhang",
                "Zhou Wang",
                "Shali Jiang",
                "Huayu Li",
                "Zhengxing Chen",
                "Wen-Yen Chen",
                "Jiyan Yang",
                "Wei Wen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07870v2",
                "http://arxiv.org/pdf/2311.07870v2"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07868v1",
            "title": "Multi-Signal Reconstruction Using Masked Autoencoder From EEG During\n  Polysomnography",
            "updated": "2023-11-14T02:57:37Z",
            "published": "2023-11-14T02:57:37Z",
            "summary": "Polysomnography (PSG) is an indispensable diagnostic tool in sleep medicine,\nessential for identifying various sleep disorders. By capturing physiological\nsignals, including EEG, EOG, EMG, and cardiorespiratory metrics, PSG presents a\npatient's sleep architecture. However, its dependency on complex equipment and\nexpertise confines its use to specialized clinical settings. Addressing these\nlimitations, our study aims to perform PSG by developing a system that requires\nonly a single EEG measurement. We propose a novel system capable of\nreconstructing multi-signal PSG from a single-channel EEG based on a masked\nautoencoder. The masked autoencoder was trained and evaluated using the\nSleep-EDF-20 dataset, with mean squared error as the metric for assessing the\nsimilarity between original and reconstructed signals. The model demonstrated\nproficiency in reconstructing multi-signal data. Our results present promise\nfor the development of more accessible and long-term sleep monitoring systems.\nThis suggests the expansion of PSG's applicability, enabling its use beyond the\nconfines of clinics.",
            "author": [
                "Young-Seok Kweon",
                "Gi-Hwan Shin",
                "Heon-Gyu Kwak",
                "Ha-Na Jo",
                "Seong-Whan Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07868v1",
                "http://arxiv.org/pdf/2311.07868v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07867v1",
            "title": "Mixture of Coupled HMMs for Robust Modeling of Multivariate Healthcare\n  Time Series",
            "updated": "2023-11-14T02:55:37Z",
            "published": "2023-11-14T02:55:37Z",
            "summary": "Analysis of multivariate healthcare time series data is inherently\nchallenging: irregular sampling, noisy and missing values, and heterogeneous\npatient groups with different dynamics violating exchangeability. In addition,\ninterpretability and quantification of uncertainty are critically important.\nHere, we propose a novel class of models, a mixture of coupled hidden Markov\nmodels (M-CHMM), and demonstrate how it elegantly overcomes these challenges.\nTo make the model learning feasible, we derive two algorithms to sample the\nsequences of the latent variables in the CHMM: samplers based on (i) particle\nfiltering and (ii) factorized approximation. Compared to existing inference\nmethods, our algorithms are computationally tractable, improve mixing, and\nallow for likelihood estimation, which is necessary to learn the mixture model.\nExperiments on challenging real-world epidemiological and semi-synthetic data\ndemonstrate the advantages of the M-CHMM: improved data fit, capacity to\nefficiently handle missing and noisy measurements, improved prediction\naccuracy, and ability to identify interpretable subsets in the data.",
            "author": [
                "Onur Poyraz",
                "Pekka Marttinen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07867v1",
                "http://arxiv.org/pdf/2311.07867v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.AP",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07864v1",
            "title": "Probing clustering in neural network representations",
            "updated": "2023-11-14T02:33:54Z",
            "published": "2023-11-14T02:33:54Z",
            "summary": "Neural network representations contain structure beyond what was present in\nthe training labels. For instance, representations of images that are visually\nor semantically similar tend to lie closer to each other than to dissimilar\nimages, regardless of their labels. Clustering these representations can thus\nprovide insights into dataset properties as well as the network internals. In\nthis work, we study how the many design choices involved in neural network\ntraining affect the clusters formed in the hidden representations. To do so, we\nestablish an evaluation setup based on the BREEDS hierarchy, for the task of\nsubclass clustering after training models with only superclass information. We\nisolate the training dataset and architecture as important factors affecting\nclusterability. Datasets with labeled classes consisting of unrelated\nsubclasses yield much better clusterability than those following a natural\nhierarchy. When using pretrained models to cluster representations on\ndownstream datasets, models pretrained on subclass labels provide better\nclusterability than models pretrained on superclass labels, but only when there\nis a high degree of domain overlap between the pretraining and downstream data.\nArchitecturally, we find that normalization strategies affect which layers\nyield the best clustering performance, and, surprisingly, Vision Transformers\nattain lower subclass clusterability than ResNets.",
            "author": [
                "Thao Nguyen",
                "Simon Kornblith"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07864v1",
                "http://arxiv.org/pdf/2311.07864v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07853v1",
            "title": "Learning Mutually Informed Representations for Characters and Subwords",
            "updated": "2023-11-14T02:09:10Z",
            "published": "2023-11-14T02:09:10Z",
            "summary": "Most pretrained language models rely on subword tokenization, which processes\ntext as a sequence of subword tokens. However, different granularities of text,\nsuch as characters, subwords, and words, can contain different kinds of\ninformation. Previous studies have shown that incorporating multiple input\ngranularities improves model generalization, yet very few of them outputs\nuseful representations for each granularity. In this paper, we introduce the\nentanglement model, aiming to combine character and subword language models.\nInspired by vision-language models, our model treats characters and subwords as\nseparate modalities, and it generates mutually informed representations for\nboth granularities as output. We evaluate our model on text classification,\nnamed entity recognition, and POS-tagging tasks. Notably, the entanglement\nmodel outperforms its backbone language models, particularly in the presence of\nnoisy texts and low-resource languages. Furthermore, the entanglement model\neven outperforms larger pre-trained models on all English sequence labeling\ntasks and classification tasks. Our anonymized code is available at\nhttps://anonymous.4open.science/r/noisy-IE-A673",
            "author": [
                "Yilin Wang",
                "Xinyi Hu",
                "Matthew R. Gormley"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07853v1",
                "http://arxiv.org/pdf/2311.07853v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07850v1",
            "title": "Bring Your Own KG: Self-Supervised Program Synthesis for Zero-Shot KGQA",
            "updated": "2023-11-14T02:05:29Z",
            "published": "2023-11-14T02:05:29Z",
            "summary": "We present BYOKG, a universal question-answering (QA) system that can operate\non any knowledge graph (KG), requires no human-annotated training data, and can\nbe ready to use within a day -- attributes that are out-of-scope for current\nKGQA systems. BYOKG draws inspiration from the remarkable ability of humans to\ncomprehend information present in an unseen KG through exploration -- starting\nat random nodes, inspecting the labels of adjacent nodes and edges, and\ncombining them with their prior world knowledge. In BYOKG, exploration\nleverages an LLM-backed symbolic agent that generates a diverse set of\nquery-program exemplars, which are then used to ground a retrieval-augmented\nreasoning procedure to predict programs for arbitrary questions. BYOKG is\neffective over both small- and large-scale graphs, showing dramatic gains in QA\naccuracy over a zero-shot baseline of 27.89 and 58.02 F1 on GrailQA and MetaQA,\nrespectively. On GrailQA, we further show that our unsupervised BYOKG\noutperforms a supervised in-context learning method, demonstrating the\neffectiveness of exploration. Lastly, we find that performance of BYOKG\nreliably improves with continued exploration as well as improvements in the\nbase LLM, notably outperforming a state-of-the-art fine-tuned model by 7.08 F1\non a sub-sampled zero-shot split of GrailQA.",
            "author": [
                "Dhruv Agarwal",
                "Rajarshi Das",
                "Sopan Khosla",
                "Rashmi Gangadharaiah"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07850v1",
                "http://arxiv.org/pdf/2311.07850v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.DB",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07849v1",
            "title": "Neural integration for constitutive equations using small data",
            "updated": "2023-11-14T02:02:30Z",
            "published": "2023-11-14T02:02:30Z",
            "summary": "Data-driven models based on deep learning algorithms intend to overcome the\nlimitations of traditional constitutive modelling by directly learning from\ndata. However, the need for extensive data that collate the full state of the\nmaterial is hindered by traditional experimental observations, which typically\nprovide only small data - sparse and partial material state observations. To\naddress this issue, we develop a novel deep learning algorithm referred to as\nNeural Integration for Constitutive Equations to discover constitutive models\nat the material point level from scarce and incomplete observations. It builds\nupon the solution of the initial value problem describing the time evolution of\nthe material state, unlike the majority of data-driven approaches for\nconstitutive modelling that require large data of increments of state\nvariables. Numerical benchmarks demonstrate that the method can learn accurate,\nconsistent, and robust constitutive models from incomplete, sparse, and noisy\ndata collecting simple conventional experimental protocols.",
            "author": [
                "Filippo Masi",
                "Itai Einav"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07849v1",
                "http://arxiv.org/pdf/2311.07849v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07841v2",
            "title": "PEMS: Pre-trained Epidemic Time-series Models",
            "updated": "2023-11-19T19:47:36Z",
            "published": "2023-11-14T01:40:21Z",
            "summary": "Providing accurate and reliable predictions about the future of an epidemic\nis an important problem for enabling informed public health decisions. Recent\nworks have shown that leveraging data-driven solutions that utilize advances in\ndeep learning methods to learn from past data of an epidemic often outperform\ntraditional mechanistic models. However, in many cases, the past data is sparse\nand may not sufficiently capture the underlying dynamics. While there exists a\nlarge amount of data from past epidemics, leveraging prior knowledge from\ntime-series data of other diseases is a non-trivial challenge. Motivated by the\nsuccess of pre-trained models in language and vision tasks, we tackle the\nproblem of pre-training epidemic time-series models to learn from multiple\ndatasets from different diseases and epidemics. We introduce Pre-trained\nEpidemic Time-Series Models (PEMS) that learn from diverse time-series datasets\nof a variety of diseases by formulating pre-training as a set of\nself-supervised learning (SSL) tasks. We tackle various important challenges\nspecific to pre-training for epidemic time-series such as dealing with\nheterogeneous dynamics and efficiently capturing useful patterns from multiple\nepidemic datasets by carefully designing the SSL tasks to learn important\npriors about the epidemic dynamics that can be leveraged for fine-tuning to\nmultiple downstream tasks. The resultant PEM outperforms previous\nstate-of-the-art methods in various downstream time-series tasks across\ndatasets of varying seasonal patterns, geography, and mechanism of contagion\nincluding the novel Covid-19 pandemic unseen in pre-trained data with better\nefficiency using smaller fraction of datasets.",
            "author": [
                "Harshavardhan Kamarthi",
                "B. Aditya Prakash"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07841v2",
                "http://arxiv.org/pdf/2311.07841v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07840v1",
            "title": "Enabling Decision-Support Systems through Automated Cell Tower Detection",
            "updated": "2023-11-14T01:40:08Z",
            "published": "2023-11-14T01:40:08Z",
            "summary": "Cell phone coverage and high-speed service gaps persist in rural areas in\nsub-Saharan Africa, impacting public access to mobile-based financial,\neducational, and humanitarian services. Improving maps of telecommunications\ninfrastructure can help inform strategies to eliminate gaps in mobile coverage.\nDeep neural networks, paired with remote sensing images, can be used for object\ndetection of cell towers and eliminate the need for inefficient and burdensome\nmanual mapping to find objects over large geographic regions. In this study, we\ndemonstrate a partially automated workflow to train an object detection model\nto locate cell towers using OpenStreetMap (OSM) features and high-resolution\nMaxar imagery. For model fine-tuning and evaluation, we curated a diverse\ndataset of over 6,000 unique images of cell towers in 26 countries in eastern,\nsouthern, and central Africa using automatically generated annotations from OSM\npoints. Our model achieves an average precision at 50% Intersection over Union\n(IoU) (AP@50) of 81.2 with good performance across different geographies and\nout-of-sample testing. Accurate localization of cell towers can yield more\naccurate cell coverage maps, in turn enabling improved delivery of digital\nservices for decision-support applications.",
            "author": [
                "Natasha Krell",
                "Will Gleave",
                "Daniel Nakada",
                "Justin Downes",
                "Amanda Willet",
                "Matthew Baran"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07840v1",
                "http://arxiv.org/pdf/2311.07840v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07833v1",
            "title": "Toward Efficient and Incremental Spectral Clustering via Parametric\n  Spectral Clustering",
            "updated": "2023-11-14T01:26:20Z",
            "published": "2023-11-14T01:26:20Z",
            "summary": "Spectral clustering is a popular method for effectively clustering\nnonlinearly separable data. However, computational limitations, memory\nrequirements, and the inability to perform incremental learning challenge its\nwidespread application. To overcome these limitations, this paper introduces a\nnovel approach called parametric spectral clustering (PSC). By extending the\ncapabilities of spectral clustering, PSC addresses the challenges associated\nwith big data and real-time scenarios and enables efficient incremental\nclustering with new data points. Experimental evaluations conducted on various\nopen datasets demonstrate the superiority of PSC in terms of computational\nefficiency while achieving clustering quality mostly comparable to standard\nspectral clustering. The proposed approach has significant potential for\nincremental and real-time data analysis applications, facilitating timely and\naccurate clustering in dynamic and evolving datasets. The findings of this\nresearch contribute to the advancement of clustering techniques and open new\navenues for efficient and effective data analysis. We publish the experimental\ncode at https://github.com/109502518/PSC_BigData.",
            "author": [
                "Jo-Chun Chen",
                "Hung-Hsuan Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07833v1",
                "http://arxiv.org/pdf/2311.07833v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07828v1",
            "title": "Machine learning analysis of dimensional reduction conjecture for\n  nonequilibrium Berezinskii-Kosterlitz-Thouless transition in three dimensions",
            "updated": "2023-11-14T01:07:53Z",
            "published": "2023-11-14T01:07:53Z",
            "summary": "We investigate the recently proposed dimensional reduction conjecture in\ndriven disordered systems using a machine learning technique. The conjecture\nstates that a static snapshot of a disordered system driven at a constant\nvelocity is equal to a space-time trajectory of its lower-dimensional pure\ncounterpart. This suggests that the three-dimensional random field XY model\nexhibits the Berezinskii-Kosterlitz-Thouless transition when driven out of\nequilibrium. To verify the conjecture directly by observing configurations of\nthe system, we utilize the capacity of neural networks to detect subtle\nfeatures of images. Specifically, we train a convolutional neural network to\ndifferentiate snapshots of the three-dimensional driven random field XY model\nfrom space-time trajectories of the two-dimensional pure XY model. Our results\ndemonstrate that the network cannot distinguish between the two, confirming the\ndimensional reduction conjecture.",
            "author": [
                "Taiki Haga"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07828v1",
                "http://arxiv.org/pdf/2311.07828v1"
            ],
            "primary_category": "cond-mat.dis-nn",
            "category": [
                "cond-mat.dis-nn",
                "cond-mat.stat-mech"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08429v1",
            "title": "Purpose in the Machine: Do Traffic Simulators Produce Distributionally\n  Equivalent Outcomes for Reinforcement Learning Applications?",
            "updated": "2023-11-14T01:05:14Z",
            "published": "2023-11-14T01:05:14Z",
            "summary": "Traffic simulators are used to generate data for learning in intelligent\ntransportation systems (ITSs). A key question is to what extent their modelling\nassumptions affect the capabilities of ITSs to adapt to various scenarios when\ndeployed in the real world. This work focuses on two simulators commonly used\nto train reinforcement learning (RL) agents for traffic applications, CityFlow\nand SUMO. A controlled virtual experiment varying driver behavior and\nsimulation scale finds evidence against distributional equivalence in\nRL-relevant measures from these simulators, with the root mean squared error\nand KL divergence being significantly greater than 0 for all assessed measures.\nWhile granular real-world validation generally remains infeasible, these\nfindings suggest that traffic simulators are not a deus ex machina for RL\ntraining: understanding the impacts of inter-simulator differences is necessary\nto train and deploy RL-based ITSs.",
            "author": [
                "Rex Chen",
                "Kathleen M. Carley",
                "Fei Fang",
                "Norman Sadeh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08429v1",
                "http://arxiv.org/pdf/2311.08429v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07823v1",
            "title": "Plug-and-Play Latent Feature Editing for Orientation-Adaptive\n  Quantitative Susceptibility Mapping Neural Networks",
            "updated": "2023-11-14T00:49:56Z",
            "published": "2023-11-14T00:49:56Z",
            "summary": "Quantitative susceptibility mapping (QSM) is a post-processing technique for\nderiving tissue magnetic susceptibility distribution from MRI phase\nmeasurements. Deep learning (DL) algorithms hold great potential for solving\nthe ill-posed QSM reconstruction problem. However, a significant challenge\nfacing current DL-QSM approaches is their limited adaptability to magnetic\ndipole field orientation variations during training and testing. In this work,\nwe propose a novel Orientation-Adaptive Latent Feature Editing (OA-LFE) module\nto learn the encoding of acquisition orientation vectors and seamlessly\nintegrate them into the latent features of deep networks. Importantly, it can\nbe directly Plug-and-Play (PnP) into various existing DL-QSM architectures,\nenabling reconstructions of QSM from arbitrary magnetic dipole orientations.\nIts effectiveness is demonstrated by combining the OA-LFE module into our\npreviously proposed phase-to-susceptibility single-step instant QSM (iQSM)\nnetwork, which was initially tailored for pure-axial acquisitions. The proposed\nOA-LFE-empowered iQSM, which we refer to as iQSM+, is trained in a\nself-supervised manner on a specially-designed simulation brain dataset.\nComprehensive experiments are conducted on simulated and in vivo human brain\ndatasets, encompassing subjects ranging from healthy individuals to those with\npathological conditions. These experiments involve various MRI platforms (3T\nand 7T) and aim to compare our proposed iQSM+ against several established QSM\nreconstruction frameworks, including the original iQSM. The iQSM+ yields QSM\nimages with significantly improved accuracies and mitigates artifacts,\nsurpassing other state-of-the-art DL-QSM algorithms.",
            "author": [
                "Yang Gao",
                "Zhuang Xiong",
                "Shanshan Shan",
                "Yin Liu",
                "Pengfei Rong",
                "Min Li",
                "Alan H Wilman",
                "G. Bruce Pike",
                "Feng Liu",
                "Hongfu Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07823v1",
                "http://arxiv.org/pdf/2311.07823v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07822v2",
            "title": "A Central Motor System Inspired Pre-training Reinforcement Learning for\n  Robotic Control",
            "updated": "2023-12-05T00:47:30Z",
            "published": "2023-11-14T00:49:12Z",
            "summary": "Designing controllers to achieve natural motor capabilities for multi-joint\nrobots is a significant challenge. However, animals in nature are naturally\nwith basic motor abilities and can master various complex motor skills through\nacquired learning. On the basis of analyzing the mechanism of the central motor\nsystem in mammals, we propose a novel pre-training reinforcement learning\nalgorithm that enables robots to learn rich motor skills and apply them to\ncomplex task environments without relying on external data. We first design a\nskill based network similar to the cerebellum by utilizing the selection\nmechanism of voluntary movements in the basal ganglia and the basic motor\nregulation ability of the cerebellum. Subsequently, by imitating the structure\nof advanced centers in the central motor system, we propose a high-level policy\nto generate different skill combinations, thereby enabling the robot to acquire\nnatural motor abilities. We conduct experiments on 4 types of robots and 22\ntask environments, and the results show that the proposed method can enable\ndifferent types of robots to achieve flexible motor skills. Overall, our\nresearch provides a promising framework for the design of neural network motor\ncontrollers.",
            "author": [
                "Pei Zhang",
                "Zhaobo Hua",
                "Jinliang Ding"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07822v2",
                "http://arxiv.org/pdf/2311.07822v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07821v1",
            "title": "Statistical Parameterized Physics-Based Machine Learning Digital Twin\n  Models for Laser Powder Bed Fusion Process",
            "updated": "2023-11-14T00:45:53Z",
            "published": "2023-11-14T00:45:53Z",
            "summary": "A digital twin (DT) is a virtual representation of physical process, products\nand/or systems that requires a high-fidelity computational model for continuous\nupdate through the integration of sensor data and user input. In the context of\nlaser powder bed fusion (LPBF) additive manufacturing, a digital twin of the\nmanufacturing process can offer predictions for the produced parts, diagnostics\nfor manufacturing defects, as well as control capabilities. This paper\nintroduces a parameterized physics-based digital twin (PPB-DT) for the\nstatistical predictions of LPBF metal additive manufacturing process. We\naccomplish this by creating a high-fidelity computational model that accurately\nrepresents the melt pool phenomena and subsequently calibrating and validating\nit through controlled experiments. In PPB-DT, a mechanistic reduced-order\nmethod-driven stochastic calibration process is introduced, which enables the\nstatistical predictions of the melt pool geometries and the identification of\ndefects such as lack-of-fusion porosity and surface roughness, specifically for\ndiagnostic applications. Leveraging data derived from this physics-based model\nand experiments, we have trained a machine learning-based digital twin\n(PPB-ML-DT) model for predicting, monitoring, and controlling melt pool\ngeometries. These proposed digital twin models can be employed for predictions,\ncontrol, optimization, and quality assurance within the LPBF process,\nultimately expediting product development and certification in LPBF-based metal\nadditive manufacturing.",
            "author": [
                "Yangfan Li",
                "Satyajit Mojumder",
                "Ye Lu",
                "Abdullah Al Amin",
                "Jiachen Guo",
                "Xiaoyu Xie",
                "Wei Chen",
                "Gregory J. Wagner",
                "Jian Cao",
                "Wing Kam Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07821v1",
                "http://arxiv.org/pdf/2311.07821v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CE",
                "cs.NA",
                "math.NA",
                "physics.data-an"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07811v1",
            "title": "In-context Learning Generalizes, But Not Always Robustly: The Case of\n  Syntax",
            "updated": "2023-11-13T23:52:43Z",
            "published": "2023-11-13T23:52:43Z",
            "summary": "In-context learning (ICL) is now a common method for supervising large\nlanguage models (LLMs): given labeled examples in the input context, the LLM\nlearns to perform the task without weight updates. Despite ICL's prevalence and\nutility, we understand little about whether models supervised in this manner\nrepresent the underlying structure of their tasks, rather than superficial\nheuristics that only generalize to identically distributed examples. In this\nstudy, we investigate the robustness of LLMs supervised via ICL using the test\ncase of sensitivity to syntax, which is a prerequisite for robust language\nunderstanding. Our experiments are based on two simple and well-controlled\nsyntactic transformations tasks, where correct out-of-distribution\ngeneralization requires an accurate syntactic analysis of the input. We further\ninvestigate whether out-of-distribution generalization can be improved via\nchain-of-thought prompting, where the model is provided with a sequence of\nintermediate computation steps that illustrate how the task ought to be\nperformed. In experiments with models from the GPT, PaLM, and Llama 2 families,\nwe find large variance across LMs on this fundamental linguistic phenomenon,\nand that the variance is explained more by the composition of the pre-training\ncorpus and supervision methods than by model size. In particular, we find\nevidence that models pre-trained on code generalize better, and benefit to a\ngreater extent from chain-of-thought prompting.",
            "author": [
                "Aaron Mueller",
                "Albert Webson",
                "Jackson Petty",
                "Tal Linzen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07811v1",
                "http://arxiv.org/pdf/2311.07811v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07808v1",
            "title": "A Primal-Dual Analysis of Monotone Submodular Maximization",
            "updated": "2023-11-13T23:47:55Z",
            "published": "2023-11-13T23:47:55Z",
            "summary": "In this paper we design a new primal-dual algorithm for the classic discrete\noptimization problem of maximizing a monotone submodular function subject to a\ncardinality constraint achieving the optimal approximation of $(1-1/e)$. This\nproblem and its special case, the maximum $k$-coverage problem, have a wide\nrange of applications in various fields including operations research, machine\nlearning, and economics. While greedy algorithms have been known to achieve\nthis approximation factor, our algorithms also provide a dual certificate which\nupper bounds the optimum value of any instance. This certificate may be used in\npractice to certify much stronger guarantees than the worst-case $(1-1/e)$\napproximation factor.",
            "author": [
                "Deeparnab Chakrabarty",
                "Luc Cote"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07808v1",
                "http://arxiv.org/pdf/2311.07808v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.00792v1",
            "title": "Visualization and Characterization of Agricultural Sprays Using Machine\n  Learning based Digital Inline Holography",
            "updated": "2023-11-13T23:37:22Z",
            "published": "2023-11-13T23:37:22Z",
            "summary": "Accurate characterization of agricultural sprays is crucial to predict in\nfield performance of liquid applied crop protection products. Here we introduce\na robust and efficient machine learning (ML) based Digital In-line Holography\n(DIH) to accurately characterize the droplet field for a wide range of\nagricultural spray nozzles. Compared to non-ML methods, our method enhances\naccuracy, generalizability, and processing speed. Our approach employs two\nneural networks: a modified U-Net to obtain the 3D droplet field from the\nnumerically reconstructed optical field, followed by a VGG16 classifier to\nreduce false positives from the U-Net prediction. The modified U-Net is trained\nusing holograms generated using a single spray nozzle at three spray locations;\ncenter, half-span, and the spray edge to create training data with various\nnumber densities and droplet size ranges. VGG16 is trained via the minimum\nintensity projection of the droplet 3D point spread function. Data augmentation\nis used to increase the efficiency of classification and make the algorithm\ngeneralizable for different measurement settings. The model is validated via\nNIST traceable glass beads and six agricultural spray nozzles representing\nvarious spray characteristics. The results demonstrate a high accuracy rate,\nwith over 90% droplet extraction and less than 5% false positives. Compared to\ntraditional spray measurement techniques, our method offers a significant leap\nforward in spatial resolution and generalizability. In particular, our method\ncan extract the real cumulative volume distribution of the NIST beads, where\nthe laser diffraction is biased towards droplets moving at slower speeds.\nAdditionally, the ML-based DIH enables the estimation of mass and momentum flux\nat different locations and the calculation of relative velocities of droplet\npairs, which are difficult to obtain via conventional techniques.",
            "author": [
                "Shyam Kumar M",
                "Christopher J. Hogan",
                "Steven A. Fredericks",
                "Jiarong Hong"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00792v1",
                "http://arxiv.org/pdf/2312.00792v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07798v1",
            "title": "Probabilistic Physics-integrated Neural Differentiable Modeling for\n  Isothermal Chemical Vapor Infiltration Process",
            "updated": "2023-11-13T23:25:18Z",
            "published": "2023-11-13T23:25:18Z",
            "summary": "Chemical vapor infiltration (CVI) is a widely adopted manufacturing technique\nused in producing carbon-carbon and carbon-silicon carbide composites. These\nmaterials are especially valued in the aerospace and automotive industries for\ntheir robust strength and lightweight characteristics. The densification\nprocess during CVI critically influences the final performance, quality, and\nconsistency of these composite materials. Experimentally optimizing the CVI\nprocesses is challenging due to long experimental time and large optimization\nspace. To address these challenges, this work takes a modeling-centric\napproach. Due to the complexities and limited experimental data of the\nisothermal CVI densification process, we have developed a data-driven\npredictive model using the physics-integrated neural differentiable (PiNDiff)\nmodeling framework. An uncertainty quantification feature has been embedded\nwithin the PiNDiff method, bolstering the model's reliability and robustness.\nThrough comprehensive numerical experiments involving both synthetic and\nreal-world manufacturing data, the proposed method showcases its capability in\nmodeling densification during the CVI process. This research highlights the\npotential of the PiNDiff framework as an instrumental tool for advancing our\nunderstanding, simulation, and optimization of the CVI manufacturing process,\nparticularly when faced with sparse data and an incomplete description of the\nunderlying physics.",
            "author": [
                "Deepak Akhare",
                "Zeping Chen",
                "Richard Gulotty",
                "Tengfei Luo",
                "Jian-Xun Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07798v1",
                "http://arxiv.org/pdf/2311.07798v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07797v1",
            "title": "Explainable History Distillation by Marked Temporal Point Process",
            "updated": "2023-11-13T23:15:29Z",
            "published": "2023-11-13T23:15:29Z",
            "summary": "Explainability of machine learning models is mandatory when researchers\nintroduce these commonly believed black boxes to real-world tasks, especially\nhigh-stakes ones. In this paper, we build a machine learning system to\nautomatically generate explanations of happened events from history by \\gls{ca}\nbased on the \\acrfull{tpp}. Specifically, we propose a new task called\n\\acrfull{ehd}. This task requires a model to distill as few events as possible\nfrom observed history. The target is that the event distribution conditioned on\nleft events predicts the observed future noticeably worse. We then regard\ndistilled events as the explanation for the future. To efficiently solve\n\\acrshort{ehd}, we rewrite the task into a \\gls{01ip} and directly estimate the\nsolution to the program by a model called \\acrfull{model}. This work fills the\ngap between our task and existing works, which only spot the difference between\nfactual and counterfactual worlds after applying a predefined modification to\nthe environment. Experiment results on Retweet and StackOverflow datasets prove\nthat \\acrshort{model} significantly outperforms other \\acrshort{ehd} baselines\nand can reveal the rationale underpinning real-world processes.",
            "author": [
                "Sishun Liu",
                "Ke Deng",
                "Yan Wang",
                "Xiuzhen Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07797v1",
                "http://arxiv.org/pdf/2311.07797v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07790v1",
            "title": "Leveraging Hamilton-Jacobi PDEs with time-dependent Hamiltonians for\n  continual scientific machine learning",
            "updated": "2023-11-13T22:55:56Z",
            "published": "2023-11-13T22:55:56Z",
            "summary": "We address two major challenges in scientific machine learning (SciML):\ninterpretability and computational efficiency. We increase the interpretability\nof certain learning processes by establishing a new theoretical connection\nbetween optimization problems arising from SciML and a generalized Hopf\nformula, which represents the viscosity solution to a Hamilton-Jacobi partial\ndifferential equation (HJ PDE) with time-dependent Hamiltonian. Namely, we show\nthat when we solve certain regularized learning problems with integral-type\nlosses, we actually solve an optimal control problem and its associated HJ PDE\nwith time-dependent Hamiltonian. This connection allows us to reinterpret\nincremental updates to learned models as the evolution of an associated HJ PDE\nand optimal control problem in time, where all of the previous information is\nintrinsically encoded in the solution to the HJ PDE. As a result, existing HJ\nPDE solvers and optimal control algorithms can be reused to design new\nefficient training approaches for SciML that naturally coincide with the\ncontinual learning framework, while avoiding catastrophic forgetting. As a\nfirst exploration of this connection, we consider the special case of linear\nregression and leverage our connection to develop a new Riccati-based\nmethodology for solving these learning problems that is amenable to continual\nlearning applications. We also provide some corresponding numerical examples\nthat demonstrate the potential computational and memory advantages our\nRiccati-based approach can provide.",
            "author": [
                "Paula Chen",
                "Tingwei Meng",
                "Zongren Zou",
                "J\u00e9r\u00f4me Darbon",
                "George Em Karniadakis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07790v1",
                "http://arxiv.org/pdf/2311.07790v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07789v1",
            "title": "Level-k Thinking in the Extensive Form",
            "updated": "2023-11-13T22:50:09Z",
            "published": "2023-11-13T22:50:09Z",
            "summary": "Level-$k$ thinking and Cognitive Hierarchy have been widely applied as a\nnormal-form solution concept in behavioral and experimental game theory. We\nconsider level-k thinking in games in extensive form. Player's may learn about\nlevels of opponents' thinking during the play of the game because some\ninformation sets may be inconsistent with certain levels. In particular, for\nany information set reached, a level-$k$ player attaches the maximum\nlevel-$\\ell$ thinking for $\\ell < k$ to her opponents consistent with the\ninformation set. We compare our notion of strong level-$k$ thinking with other\nsolution concepts such as level-$k$ thinking in the associated normal form,\nstrong rationalizability, $\\Delta$-rationalizability, iterated admissibility,\nbackward rationalizability, backward level-$k$ thinking, and backward\ninduction. We use strong level-$k$ thinking to reanalyze data from some prior\nexperiments in the literature.",
            "author": [
                "Burkhard C. Schipper",
                "Hang Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07789v1",
                "http://arxiv.org/pdf/2311.07789v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07788v1",
            "title": "CSLP-AE: A Contrastive Split-Latent Permutation Autoencoder Framework\n  for Zero-Shot Electroencephalography Signal Conversion",
            "updated": "2023-11-13T22:46:43Z",
            "published": "2023-11-13T22:46:43Z",
            "summary": "Electroencephalography (EEG) is a prominent non-invasive neuroimaging\ntechnique providing insights into brain function. Unfortunately, EEG data\nexhibit a high degree of noise and variability across subjects hampering\ngeneralizable signal extraction. Therefore, a key aim in EEG analysis is to\nextract the underlying neural activation (content) as well as to account for\nthe individual subject variability (style). We hypothesize that the ability to\nconvert EEG signals between tasks and subjects requires the extraction of\nlatent representations accounting for content and style. Inspired by recent\nadvancements in voice conversion technologies, we propose a novel contrastive\nsplit-latent permutation autoencoder (CSLP-AE) framework that directly\noptimizes for EEG conversion. Importantly, the latent representations are\nguided using contrastive learning to promote the latent splits to explicitly\nrepresent subject (style) and task (content). We contrast CSLP-AE to\nconventional supervised, unsupervised (AE), and self-supervised (contrastive\nlearning) training and find that the proposed approach provides favorable\ngeneralizable characterizations of subject and task. Importantly, the procedure\nalso enables zero-shot conversion between unseen subjects. While the present\nwork only considers conversion of EEG, the proposed CSLP-AE provides a general\nframework for signal conversion and extraction of content (task activation) and\nstyle (subject variability) components of general interest for the modeling and\nanalysis of biological signals.",
            "author": [
                "Anders Vestergaard N\u00f8rskov",
                "Alexander Neergaard Zahid",
                "Morten M\u00f8rup"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07788v1",
                "http://arxiv.org/pdf/2311.07788v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "eess.SP",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07787v1",
            "title": "Hybrid Synaptic Structure for Spiking Neural Network Realization",
            "updated": "2023-11-13T22:42:07Z",
            "published": "2023-11-13T22:42:07Z",
            "summary": "Neural networks and neuromorphic computing play pivotal roles in deep\nlearning and machine vision. Due to their dissipative nature and inherent\nlimitations, traditional semiconductor-based circuits face challenges in\nrealizing ultra-fast and low-power neural networks. However, the spiking\nbehavior characteristic of single flux quantum (SFQ) circuits positions them as\npromising candidates for spiking neural networks (SNNs). Our previous work\nshowcased a JJ-Soma design capable of operating at tens of gigahertz while\nconsuming only a fraction of the power compared to traditional circuits, as\ndocumented in [1]. This paper introduces a compact SFQ-based synapse design\nthat applies positive and negative weighted inputs to the JJ-Soma. Using an\nRSFQ synapse empowers us to replicate the functionality of a biological neuron,\na crucial step in realizing a complete SNN. The JJ-Synapse can operate at\nultra-high frequencies, exhibits orders of magnitude lower power consumption\nthan CMOS counterparts, and can be conveniently fabricated using commercial Nb\nprocesses. Furthermore, the network's flexibility enables modifications by\nincorporating cryo-CMOS circuits for weight value adjustments. In our endeavor,\nwe have successfully designed, fabricated, and partially tested the JJ-Synapse\nwithin our cryocooler system. Integration with the JJ-Soma further facilitates\nthe realization of a high-speed inference SNN.",
            "author": [
                "Sasan Razmkhah",
                "Mustafa Altay Karamuftuoglu",
                "Ali Bozbey"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07787v1",
                "http://arxiv.org/pdf/2311.07787v1"
            ],
            "primary_category": "cond-mat.supr-con",
            "category": [
                "cond-mat.supr-con",
                "cs.AR",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07786v1",
            "title": "Predicting the First Response Latency of Maintainers and Contributors in\n  Pull Requests",
            "updated": "2023-11-13T22:32:02Z",
            "published": "2023-11-13T22:32:02Z",
            "summary": "The success of a Pull Request (PR) depends on the responsiveness of the\nmaintainers and the contributor during the review process. Being aware of the\nexpected waiting times can lead to better interactions and managed expectations\nfor both the maintainers and the contributor. In this paper, we propose a\nmachine-learning approach to predict the first response latency of the\nmaintainers following the submission of a PR, and the first response latency of\nthe contributor after receiving the first response from the maintainers. We\ncurate a dataset of 20 large and popular open-source projects on GitHub and\nextract 21 features to characterize projects, contributors, PRs, and review\nprocesses. Using these features, we then evaluate seven types of classifiers to\nidentify the best-performing models. We also perform permutation feature\nimportance and SHAP analyses to understand the importance and impact of\ndifferent features on the predicted response latencies. Our best-performing\nmodels achieve an average improvement of 33% in AUC-ROC and 58% in AUC-PR for\nmaintainers, as well as 42% in AUC-ROC and 95% in AUC-PR for contributors\ncompared to a no-skilled classifier across the projects. Our findings indicate\nthat PRs submitted earlier in the week, containing an average or slightly\nabove-average number of commits, and with concise descriptions are more likely\nto receive faster first responses from the maintainers. Similarly, PRs with a\nlower first response latency from maintainers, that received the first response\nof maintainers earlier in the week, and containing an average or slightly\nabove-average number of commits tend to receive faster first responses from the\ncontributors. Additionally, contributors with a higher acceptance rate and a\nhistory of timely responses in the project are likely to both obtain and\nprovide faster first responses.",
            "author": [
                "SayedHassan Khatoonabadi",
                "Ahmad Abdellatif",
                "Diego Elias Costa",
                "Emad Shihab"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07786v1",
                "http://arxiv.org/pdf/2311.07786v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07784v2",
            "title": "A Data-Free Approach to Mitigate Catastrophic Forgetting in Federated\n  Class Incremental Learning for Vision Tasks",
            "updated": "2023-11-21T08:23:31Z",
            "published": "2023-11-13T22:21:27Z",
            "summary": "Deep learning models often suffer from forgetting previously learned\ninformation when trained on new data. This problem is exacerbated in federated\nlearning (FL), where the data is distributed and can change independently for\neach user. Many solutions are proposed to resolve this catastrophic forgetting\nin a centralized setting. However, they do not apply directly to FL because of\nits unique complexities, such as privacy concerns and resource limitations. To\novercome these challenges, this paper presents a framework for\n$\\textbf{federated class incremental learning}$ that utilizes a generative\nmodel to synthesize samples from past distributions. This data can be later\nexploited alongside the training data to mitigate catastrophic forgetting. To\npreserve privacy, the generative model is trained on the server using data-free\nmethods at the end of each task without requesting data from clients. Moreover,\nour solution does not demand the users to store old data or models, which gives\nthem the freedom to join/leave the training at any time. Additionally, we\nintroduce SuperImageNet, a new regrouping of the ImageNet dataset specifically\ntailored for federated continual learning. We demonstrate significant\nimprovements compared to existing baselines through extensive experiments on\nmultiple datasets.",
            "author": [
                "Sara Babakniya",
                "Zalan Fabian",
                "Chaoyang He",
                "Mahdi Soltanolkotabi",
                "Salman Avestimehr"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07784v2",
                "http://arxiv.org/pdf/2311.07784v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07772v3",
            "title": "In-context Learning and Gradient Descent Revisited",
            "updated": "2023-11-18T19:58:27Z",
            "published": "2023-11-13T21:42:38Z",
            "summary": "In-context learning (ICL) has shown impressive results in few-shot learning\ntasks, yet its underlying mechanism is still not fully understood. Recent works\nsuggest that ICL can be thought of as a gradient descent (GD) based\noptimization process. While promising, these results mainly focus on simplified\nsettings of ICL and provide only a preliminary evaluation of the similarities\nbetween the two methods. In this work, we revisit the comparison between ICL\nand GD-based finetuning and study what properties of ICL an equivalent process\nmust follow. We highlight a major difference in the flow of information between\nICL and standard finetuning. Namely, ICL can only rely on information from\nlower layers at every point, while finetuning depends on loss gradients from\ndeeper layers. We refer to this discrepancy as Layer Causality and show that a\nlayer causal variant of the finetuning process aligns with ICL on par with\nvanilla finetuning and is even better in most cases across relevant metrics. To\nthe best of our knowledge, this is the first work to discuss this discrepancy\nexplicitly and suggest a solution that tackles this problem with minimal\nchanges.",
            "author": [
                "Gilad Deutch",
                "Nadav Magar",
                "Tomer Bar Natan",
                "Guy Dar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07772v3",
                "http://arxiv.org/pdf/2311.07772v3"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07767v1",
            "title": "GreekT5: A Series of Greek Sequence-to-Sequence Models for News\n  Summarization",
            "updated": "2023-11-13T21:33:12Z",
            "published": "2023-11-13T21:33:12Z",
            "summary": "Text summarization (TS) is a natural language processing (NLP) subtask\npertaining to the automatic formulation of a concise and coherent summary that\ncovers the major concepts and topics from one or multiple documents. Recent\nadvancements in deep learning have led to the development of abstractive\nsummarization transformer-based models, which outperform classical approaches.\nIn any case, research in this field focuses on high resource languages such as\nEnglish, while the corresponding work for low resource languages is still\nunderdeveloped. Taking the above into account, this paper proposes a series of\nnovel TS models for Greek news articles. The proposed models were thoroughly\nevaluated on the same dataset against GreekBART, which is the state-of-the-art\nmodel in Greek abstractive news summarization. Our evaluation results reveal\nthat most of the proposed models significantly outperform GreekBART on various\nevaluation metrics. We make our evaluation code public, aiming to increase the\nreproducibility of this work and facilitate future research in the field.",
            "author": [
                "Nikolaos Giarelis",
                "Charalampos Mastrokostas",
                "Nikos Karacapilidis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07767v1",
                "http://arxiv.org/pdf/2311.07767v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "68T07, 68T50",
                "I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07766v1",
            "title": "Vision-Language Integration in Multimodal Video Transformers (Partially)\n  Aligns with the Brain",
            "updated": "2023-11-13T21:32:37Z",
            "published": "2023-11-13T21:32:37Z",
            "summary": "Integrating information from multiple modalities is arguably one of the\nessential prerequisites for grounding artificial intelligence systems with an\nunderstanding of the real world. Recent advances in video transformers that\njointly learn from vision, text, and sound over time have made some progress\ntoward this goal, but the degree to which these models integrate information\nfrom modalities still remains unclear. In this work, we present a promising\napproach for probing a pre-trained multimodal video transformer model by\nleveraging neuroscientific evidence of multimodal information processing in the\nbrain. Using brain recordings of participants watching a popular TV show, we\nanalyze the effects of multi-modal connections and interactions in a\npre-trained multi-modal video transformer on the alignment with uni- and\nmulti-modal brain regions. We find evidence that vision enhances masked\nprediction performance during language processing, providing support that\ncross-modal representations in models can benefit individual modalities.\nHowever, we don't find evidence of brain-relevant information captured by the\njoint multi-modal transformer representations beyond that captured by all of\nthe individual modalities. We finally show that the brain alignment of the\npre-trained joint representation can be improved by fine-tuning using a task\nthat requires vision-language inferences. Overall, our results paint an\noptimistic picture of the ability of multi-modal transformers to integrate\nvision and language in partially brain-relevant ways but also show that\nimproving the brain alignment of these models may require new approaches.",
            "author": [
                "Dota Tianai Dong",
                "Mariya Toneva"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07766v1",
                "http://arxiv.org/pdf/2311.07766v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07765v1",
            "title": "FedOpenHAR: Federated Multi-Task Transfer Learning for Sensor-Based\n  Human Activity Recognition",
            "updated": "2023-11-13T21:31:07Z",
            "published": "2023-11-13T21:31:07Z",
            "summary": "Motion sensors integrated into wearable and mobile devices provide valuable\ninformation about the device users. Machine learning and, recently, deep\nlearning techniques have been used to characterize sensor data. Mostly, a\nsingle task, such as recognition of activities, is targeted, and the data is\nprocessed centrally at a server or in a cloud environment. However, the same\nsensor data can be utilized for multiple tasks and distributed machine-learning\ntechniques can be used without the requirement of the transmission of data to a\ncentre. This paper explores Federated Transfer Learning in a Multi-Task manner\nfor both sensor-based human activity recognition and device position\nidentification tasks. The OpenHAR framework is used to train the models, which\ncontains ten smaller datasets. The aim is to obtain model(s) applicable for\nboth tasks in different datasets, which may include only some label types.\nMultiple experiments are carried in the Flower federated learning environment\nusing the DeepConvLSTM architecture. Results are presented for federated and\ncentralized versions under different parameters and restrictions. By utilizing\ntransfer learning and training a task-specific and personalized federated\nmodel, we obtained a similar accuracy with training each client individually\nand higher accuracy than a fully centralized approach.",
            "author": [
                "Egemen \u0130\u015fg\u00fcder",
                "\u00d6zlem Durmaz \u0130ncel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07765v1",
                "http://arxiv.org/pdf/2311.07765v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07763v1",
            "title": "The Disagreement Problem in Faithfulness Metrics",
            "updated": "2023-11-13T21:26:24Z",
            "published": "2023-11-13T21:26:24Z",
            "summary": "The field of explainable artificial intelligence (XAI) aims to explain how\nblack-box machine learning models work. Much of the work centers around the\nholy grail of providing post-hoc feature attributions to any model\narchitecture. While the pace of innovation around novel methods has slowed\ndown, the question remains of how to choose a method, and how to make it fit\nfor purpose. Recently, efforts around benchmarking XAI methods have suggested\nmetrics for that purpose -- but there are many choices. That bounty of choice\nstill leaves an end user unclear on how to proceed. This paper focuses on\ncomparing metrics with the aim of measuring faithfulness of local explanations\non tabular classification problems -- and shows that the current metrics don't\nagree; leaving users unsure how to choose the most faithful explanations.",
            "author": [
                "Brian Barr",
                "Noah Fatsi",
                "Leif Hancox-Li",
                "Peter Richter",
                "Daniel Proano",
                "Caleb Mok"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07763v1",
                "http://arxiv.org/pdf/2311.07763v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07762v1",
            "title": "Finite Mixtures of Multivariate Poisson-Log Normal Factor Analyzers for\n  Clustering Count Data",
            "updated": "2023-11-13T21:23:15Z",
            "published": "2023-11-13T21:23:15Z",
            "summary": "A mixture of multivariate Poisson-log normal factor analyzers is introduced\nby imposing constraints on the covariance matrix, which resulted in flexible\nmodels for clustering purposes. In particular, a class of eight parsimonious\nmixture models based on the mixtures of factor analyzers model are introduced.\nVariational Gaussian approximation is used for parameter estimation, and\ninformation criteria are used for model selection. The proposed models are\nexplored in the context of clustering discrete data arising from RNA sequencing\nstudies. Using real and simulated data, the models are shown to give favourable\nclustering performance. The GitHub R package for this work is available at\nhttps://github.com/anjalisilva/mixMPLNFA and is released under the open-source\nMIT license.",
            "author": [
                "Andrea Payne",
                "Anjali Silva",
                "Steven J. Rothstein",
                "Paul D. McNicholas",
                "Sanjeena Subedi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07762v1",
                "http://arxiv.org/pdf/2311.07762v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.CO",
                "stat.ML",
                "62H30"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07760v1",
            "title": "Ransomware Detection Using Federated Learning with Imbalanced Datasets",
            "updated": "2023-11-13T21:21:39Z",
            "published": "2023-11-13T21:21:39Z",
            "summary": "Ransomware is a type of malware which encrypts user data and extorts payments\nin return for the decryption keys. This cyberthreat is one of the most serious\nchallenges facing organizations today and has already caused immense financial\ndamage. As a result, many researchers have been developing techniques to\ncounter ransomware. Recently, the federated learning (FL) approach has also\nbeen applied for ransomware analysis, allowing corporations to achieve\nscalable, effective detection and attribution without having to share their\nprivate data. However, in reality there is much variation in the quantity and\ncomposition of ransomware data collected across multiple FL client\nsites/regions. This imbalance will inevitably degrade the effectiveness of any\ndefense mechanisms. To address this concern, a modified FL scheme is proposed\nusing a weighted cross-entropy loss function approach to mitigate dataset\nimbalance. A detailed performance evaluation study is then presented for the\ncase of static analysis using the latest Windows-based ransomware families. The\nfindings confirm improved ML classifier performance for a highly imbalanced\ndataset.",
            "author": [
                "Aldin Vehabovic",
                "Hadi Zanddizari",
                "Nasir Ghani",
                "G. Javidi",
                "S. Uluagac",
                "M. Rahouti",
                "E. Bou-Harb",
                "M. Safaei Pour"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07760v1",
                "http://arxiv.org/pdf/2311.07760v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07752v1",
            "title": "Doubly Robust Estimation under Possibly Misspecified Marginal Structural\n  Cox Model",
            "updated": "2023-11-13T21:09:37Z",
            "published": "2023-11-13T21:09:37Z",
            "summary": "In this paper we address the challenges posed by non-proportional hazards and\ninformative censoring, offering a path toward more meaningful causal inference\nconclusions. We start from the marginal structural Cox model, which has been\nwidely used for analyzing observational studies with survival outcomes, and\ntypically relies on the inverse probability weighting method. The latter hinges\nupon a propensity score model for the treatment assignment, and a censoring\nmodel which incorporates both the treatment and the covariates. In such\nsettings, model misspecification can occur quite effortlessly, and the Cox\nregression model's non-collapsibility has historically posed challenges when\nstriving to guard against model misspecification through augmentation. We\nintroduce an augmented inverse probability weighted estimator which, enriched\nwith doubly robust properties, paves the way for integrating machine learning\nand a plethora of nonparametric methods, effectively overcoming the challenges\nof non-collapsibility. The estimator extends naturally to estimating a\ntime-average treatment effect when the proportional hazards assumption fails.\nWe closely examine its theoretical and practical performance, showing that it\nsatisfies both the assumption-lean and the well-specification criteria\ndiscussed in the recent literature. Finally, its application to a dataset\nreveals insights into the impact of mid-life alcohol consumption on mortality\nin later life.",
            "author": [
                "Jiyu Luo",
                "Denise Rava",
                "Jelena Bradic",
                "Ronghui Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07752v1",
                "http://arxiv.org/pdf/2311.07752v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07750v2",
            "title": "SynthEnsemble: A Fusion of CNN, Vision Transformer, and Hybrid Models\n  for Multi-Label Chest X-Ray Classification",
            "updated": "2023-11-20T15:01:19Z",
            "published": "2023-11-13T21:07:07Z",
            "summary": "Chest X-rays are widely used to diagnose thoracic diseases, but the lack of\ndetailed information about these abnormalities makes it challenging to develop\naccurate automated diagnosis systems, which is crucial for early detection and\neffective treatment. To address this challenge, we employed deep learning\ntechniques to identify patterns in chest X-rays that correspond to different\ndiseases. We conducted experiments on the \"ChestX-ray14\" dataset using various\npre-trained CNNs, transformers, hybrid(CNN+Transformer) models and classical\nmodels. The best individual model was the CoAtNet, which achieved an area under\nthe receiver operating characteristic curve (AUROC) of 84.2%. By combining the\npredictions of all trained models using a weighted average ensemble where the\nweight of each model was determined using differential evolution, we further\nimproved the AUROC to 85.4%, outperforming other state-of-the-art methods in\nthis field. Our findings demonstrate the potential of deep learning techniques,\nparticularly ensemble deep learning, for improving the accuracy of automatic\ndiagnosis of thoracic diseases from chest X-rays.",
            "author": [
                "S. M. Nabil Ashraf",
                "Md. Adyelullahil Mamun",
                "Hasnat Md. Abdullah",
                "Md. Golam Rabiul Alam"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07750v2",
                "http://arxiv.org/pdf/2311.07750v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG",
                "I.4; I.5"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07745v1",
            "title": "Simplifying Complex Observation Models in Continuous POMDP Planning with\n  Probabilistic Guarantees and Practice",
            "updated": "2023-11-13T20:55:02Z",
            "published": "2023-11-13T20:55:02Z",
            "summary": "Solving partially observable Markov decision processes (POMDPs) with high\ndimensional and continuous observations, such as camera images, is required for\nmany real life robotics and planning problems. Recent researches suggested\nmachine learned probabilistic models as observation models, but their use is\ncurrently too computationally expensive for online deployment. We deal with the\nquestion of what would be the implication of using simplified observation\nmodels for planning, while retaining formal guarantees on the quality of the\nsolution. Our main contribution is a novel probabilistic bound based on a\nstatistical total variation distance of the simplified model. We show that it\nbounds the theoretical POMDP value w.r.t. original model, from the empirical\nplanned value with the simplified model, by generalizing recent results of\nparticle-belief MDP concentration bounds. Our calculations can be separated\ninto offline and online parts, and we arrive at formal guarantees without\nhaving to access the costly model at all during planning, which is also a novel\nresult. Finally, we demonstrate in simulation how to integrate the bound into\nthe routine of an existing continuous online POMDP solver.",
            "author": [
                "Idan Lev-Yehudi",
                "Moran Barenboim",
                "Vadim Indelman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07745v1",
                "http://arxiv.org/pdf/2311.07745v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07744v1",
            "title": "Dynamic Local Attention with Hierarchical Patching for Irregular\n  Clinical Time Series",
            "updated": "2023-11-13T20:54:52Z",
            "published": "2023-11-13T20:54:52Z",
            "summary": "Irregular multivariate time series data is prevalent in the clinical and\nhealthcare domains. It is characterized by time-wise and feature-wise\nirregularities, making it challenging for machine learning methods to work\nwith. To solve this, we introduce a new model architecture composed of two\nmodules: (1) DLA, a Dynamic Local Attention mechanism that uses learnable\nqueries and feature-specific local windows when computing the self-attention\noperation. This results in aggregating irregular time steps raw input within\neach window to a harmonized regular latent space representation while taking\ninto account the different features' sampling rates. (2) A hierarchical MLP\nmixer that processes the output of DLA through multi-scale patching to leverage\ninformation at various scales for the downstream tasks. Our approach\noutperforms state-of-the-art methods on three real-world datasets, including\nthe latest clinical MIMIC IV dataset.",
            "author": [
                "Xingyu Chen",
                "Xiaochen Zheng",
                "Amina Mollaysa",
                "Manuel Sch\u00fcrch",
                "Ahmed Allam",
                "Michael Krauthammer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07744v1",
                "http://arxiv.org/pdf/2311.07744v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07742v1",
            "title": "Modeling Sequences as Star Graphs to Address Over-smoothing in\n  Self-attentive Sequential Recommendation",
            "updated": "2023-11-13T20:49:01Z",
            "published": "2023-11-13T20:49:01Z",
            "summary": "Self-attention (SA) mechanisms have been widely used in developing sequential\nrecommendation (SR) methods, and demonstrated state-of-the-art performance.\nHowever, in this paper, we show that self-attentive SR methods substantially\nsuffer from the over-smoothing issue that item embeddings within a sequence\nbecome increasingly similar across attention blocks. As widely demonstrated in\nthe literature, this issue could lead to a loss of information in individual\nitems, and significantly degrade models' scalability and performance. To\naddress the over-smoothing issue, in this paper, we view items within a\nsequence constituting a star graph and develop a method, denoted as MSSG, for\nSR. Different from existing self-attentive methods, MSSG introduces an\nadditional internal node to specifically capture the global information within\nthe sequence, and does not require information propagation among items. This\ndesign fundamentally addresses the over-smoothing issue and enables MSSG a\nlinear time complexity with respect to the sequence length. We compare MSSG\nwith ten state-of-the-art baseline methods on six public benchmark datasets.\nOur experimental results demonstrate that MSSG significantly outperforms the\nbaseline methods, with an improvement of as much as 10.10%. Our analysis shows\nthe superior scalability of MSSG over the state-of-the-art self-attentive\nmethods. Our complexity analysis and run-time performance comparison together\nshow that MSSG is both theoretically and practically more efficient than\nself-attentive methods. Our analysis of the attention weights learned in\nSA-based methods indicates that on sparse recommendation data, modeling\ndependencies in all item pairs using the SA mechanism yields limited\ninformation gain, and thus, might not benefit the recommendation performance",
            "author": [
                "Bo Peng",
                "Ziqi Chen",
                "Srinivasan Parthasarathy",
                "Xia Ning"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07742v1",
                "http://arxiv.org/pdf/2311.07742v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07734v1",
            "title": "Quality-Aware Prototype Memory for Face Representation Learning",
            "updated": "2023-11-13T20:36:54Z",
            "published": "2023-11-13T20:36:54Z",
            "summary": "Prototype Memory is a powerful model for face representation learning. It\nenables the training of face recognition models using datasets of any size,\nwith on-the-fly generation of prototypes (classifier weights) and efficient\nways of their utilization. Prototype Memory demonstrated strong results in many\nface recognition benchmarks. However, the algorithm of prototype generation,\nused in it, is prone to the problems of imperfectly calculated prototypes in\ncase of low-quality or poorly recognizable faces in the images, selected for\nthe prototype creation. All images of the same person, presented in the\nmini-batch, used with equal weights, and the resulting averaged prototype could\nbe contaminated with imperfect embeddings of such face images. It can lead to\nmisdirected training signals and impair the performance of the trained face\nrecognition models. In this paper, we propose a simple and effective way to\nimprove Prototype Memory with quality-aware prototype generation. Quality-Aware\nPrototype Memory uses different weights for images of different quality in the\nprocess of prototype generation. With this improvement, prototypes get more\nvaluable information from high-quality images and less hurt by low-quality\nones. We propose and compare several methods of quality estimation and usage,\nperform extensive experiments on the different face recognition benchmarks and\ndemonstrate the advantages of the proposed model compared to the basic version\nof Prototype Memory.",
            "author": [
                "Evgeny Smirnov",
                "Vasiliy Galyuk",
                "Evgeny Lukyanets"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07734v1",
                "http://arxiv.org/pdf/2311.07734v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07726v1",
            "title": "A Simple Quantum Blockmodeling with Qubits and Permutations",
            "updated": "2023-11-13T20:10:53Z",
            "published": "2023-11-13T20:10:53Z",
            "summary": "Blockmodeling of a given problem represented by an $N\\times N$ adjacency\nmatrix can be found by swapping rows and columns of the matrix (i.e.\nmultiplying matrix from left and right by a permutation matrix). In general,\nthrough performing this task, row and column permutations affect the fitness\nvalue in optimization: For an $N\\times N$ matrix, it requires $O(N)$\ncomputations to find (or update) the fitness value of a candidate solution.\n  On quantum computers, permutations can be applied in parallel and\nefficiently, and their implementations can be as simple as a single qubit\noperation (a NOT gate on a qubit) which takes an $O(1)$ time algorithmic step.\nIn this paper, using permutation matrices, we describe a quantum blockmodeling\nfor data analysis tasks. In the model, the measurement outcome of a small group\nof qubits are mapped to indicate the fitness value. Therefore, we show that it\nis possible to find or update the fitness value in $O(log(N))$ time. This lead\nus to show that when the number of iterations are less than $log(N)$ time, it\nmay be possible to reach the same solution exponentially faster on quantum\ncomputers in comparison to classical computers. In addition, since on quantum\ncircuits the different sequence of permutations can be applied in parallel\n(superpositon), the machine learning task in this model can be implemented more\nefficiently on quantum computers.",
            "author": [
                "Ammar Daskin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07726v1",
                "http://arxiv.org/pdf/2311.07726v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.LG",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07723v2",
            "title": "Generalization Analogies: A Testbed for Generalizing AI Oversight to\n  Hard-To-Measure Domains",
            "updated": "2023-11-19T01:33:53Z",
            "published": "2023-11-13T20:07:36Z",
            "summary": "As AI systems become more intelligent and their behavior becomes more\nchallenging to assess, they may learn to game the flaws of human feedback\ninstead of genuinely striving to follow instructions; however, this risk can be\nmitigated by controlling how LLMs generalize human feedback to situations where\nit is unreliable. To better understand how reward models generalize, we craft\n69 distribution shifts spanning 8 categories. We find that reward models do not\nlearn to evaluate `instruction-following' by default and instead favor personas\nthat resemble internet text. Techniques for interpreting reward models'\ninternal representations achieve better generalization than standard\nfine-tuning, but still frequently fail to distinguish instruction-following\nfrom conflated behaviors. We consolidate the 15 most challenging distribution\nshifts into the GENeralization analogIES (GENIES) benchmark, which we hope will\nenable progress toward controlling reward model generalization.",
            "author": [
                "Joshua Clymer",
                "Garrett Baker",
                "Rohan Subramani",
                "Sam Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07723v2",
                "http://arxiv.org/pdf/2311.07723v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07715v1",
            "title": "PolyIE: A Dataset of Information Extraction from Polymer Material\n  Scientific Literature",
            "updated": "2023-11-13T19:56:18Z",
            "published": "2023-11-13T19:56:18Z",
            "summary": "Scientific information extraction (SciIE), which aims to automatically\nextract information from scientific literature, is becoming more important than\never. However, there are no existing SciIE datasets for polymer materials,\nwhich is an important class of materials used ubiquitously in our daily lives.\nTo bridge this gap, we introduce POLYIE, a new SciIE dataset for polymer\nmaterials. POLYIE is curated from 146 full-length polymer scholarly articles,\nwhich are annotated with different named entities (i.e., materials, properties,\nvalues, conditions) as well as their N-ary relations by domain experts. POLYIE\npresents several unique challenges due to diverse lexical formats of entities,\nambiguity between entities, and variable-length relations. We evaluate\nstate-of-the-art named entity extraction and relation extraction models on\nPOLYIE, analyze their strengths and weaknesses, and highlight some difficult\ncases for these models. To the best of our knowledge, POLYIE is the first SciIE\nbenchmark for polymer materials, and we hope it will lead to more research\nefforts from the community on this challenging task. Our code and data are\navailable on: https://github.com/jerry3027/PolyIE.",
            "author": [
                "Jerry Junyang Cheung",
                "Yuchen Zhuang",
                "Yinghao Li",
                "Pranav Shetty",
                "Wantian Zhao",
                "Sanjeev Grampurohit",
                "Rampi Ramprasad",
                "Chao Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07715v1",
                "http://arxiv.org/pdf/2311.07715v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07711v1",
            "title": "Histopathologic Cancer Detection",
            "updated": "2023-11-13T19:51:46Z",
            "published": "2023-11-13T19:51:46Z",
            "summary": "Early diagnosis of the cancer cells is necessary for making an effective\ntreatment plan and for the health and safety of a patient. Nowadays, doctors\nusually use a histological grade that pathologists determine by performing a\nsemi-quantitative analysis of the histopathological and cytological features of\nhematoxylin-eosin (HE) stained histopathological images. This research\ncontributes a potential classification model for cancer prognosis to\nefficiently utilize the valuable information underlying the HE-stained\nhistopathological images. This work uses the PatchCamelyon benchmark datasets\nand trains them in a multi-layer perceptron and convolution model to observe\nthe model's performance in terms of precision, Recall, F1 Score, Accuracy, and\nAUC Score. The evaluation result shows that the baseline convolution model\noutperforms the baseline MLP model. Also, this paper introduced ResNet50 and\nInceptionNet models with data augmentation, where ResNet50 is able to beat the\nstate-of-the-art model. Furthermore, the majority vote and concatenation\nensemble were evaluated and provided the future direction of using transfer\nlearning and segmentation to understand the specific features.",
            "author": [
                "Varan Singh Rohila",
                "Neeraj Lalwani",
                "Lochan Basyal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07711v1",
                "http://arxiv.org/pdf/2311.07711v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07708v1",
            "title": "Reinforcement Learning for Solving Stochastic Vehicle Routing Problem",
            "updated": "2023-11-13T19:46:22Z",
            "published": "2023-11-13T19:46:22Z",
            "summary": "This study addresses a gap in the utilization of Reinforcement Learning (RL)\nand Machine Learning (ML) techniques in solving the Stochastic Vehicle Routing\nProblem (SVRP) that involves the challenging task of optimizing vehicle routes\nunder uncertain conditions. We propose a novel end-to-end framework that\ncomprehensively addresses the key sources of stochasticity in SVRP and utilizes\nan RL agent with a simple yet effective architecture and a tailored training\nmethod. Through comparative analysis, our proposed model demonstrates superior\nperformance compared to a widely adopted state-of-the-art metaheuristic,\nachieving a significant 3.43% reduction in travel costs. Furthermore, the model\nexhibits robustness across diverse SVRP settings, highlighting its adaptability\nand ability to learn optimal routing strategies in varying environments. The\npublicly available implementation of our framework serves as a valuable\nresource for future research endeavors aimed at advancing RL-based solutions\nfor SVRP.",
            "author": [
                "Zangir Iklassov",
                "Ikboljon Sobirov",
                "Ruben Solozabal",
                "Martin Takac"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07708v1",
                "http://arxiv.org/pdf/2311.07708v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CE",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07705v1",
            "title": "Robust and Scalable Hyperdimensional Computing With Brain-Like Neural\n  Adaptations",
            "updated": "2023-11-13T19:42:33Z",
            "published": "2023-11-13T19:42:33Z",
            "summary": "The Internet of Things (IoT) has facilitated many applications utilizing\nedge-based machine learning (ML) methods to analyze locally collected data.\nUnfortunately, popular ML algorithms often require intensive computations\nbeyond the capabilities of today's IoT devices. Brain-inspired hyperdimensional\ncomputing (HDC) has been introduced to address this issue. However, existing\nHDCs use static encoders, requiring extremely high dimensionality and hundreds\nof training iterations to achieve reasonable accuracy. This results in a huge\nefficiency loss, severely impeding the application of HDCs in IoT systems. We\nobserved that a main cause is that the encoding module of existing HDCs lacks\nthe capability to utilize and adapt to information learned during training. In\ncontrast, neurons in human brains dynamically regenerate all the time and\nprovide more useful functionalities when learning new information. While the\ngoal of HDC is to exploit the high-dimensionality of randomly generated base\nhypervectors to represent the information as a pattern of neural activity, it\nremains challenging for existing HDCs to support a similar behavior as brain\nneural regeneration. In this work, we present dynamic HDC learning frameworks\nthat identify and regenerate undesired dimensions to provide adequate accuracy\nwith significantly lowered dimensionalities, thereby accelerating both the\ntraining and inference.",
            "author": [
                "Junyao Wang",
                "Mohammad Abdullah Al Faruque"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07705v1",
                "http://arxiv.org/pdf/2311.07705v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07700v1",
            "title": "AuthentiGPT: Detecting Machine-Generated Text via Black-Box Language\n  Models Denoising",
            "updated": "2023-11-13T19:36:54Z",
            "published": "2023-11-13T19:36:54Z",
            "summary": "Large language models (LLMs) have opened up enormous opportunities while\nsimultaneously posing ethical dilemmas. One of the major concerns is their\nability to create text that closely mimics human writing, which can lead to\npotential misuse, such as academic misconduct, disinformation, and fraud. To\naddress this problem, we present AuthentiGPT, an efficient classifier that\ndistinguishes between machine-generated and human-written texts. Under the\nassumption that human-written text resides outside the distribution of\nmachine-generated text, AuthentiGPT leverages a black-box LLM to denoise input\ntext with artificially added noise, and then semantically compares the denoised\ntext with the original to determine if the content is machine-generated. With\nonly one trainable parameter, AuthentiGPT eliminates the need for a large\ntraining dataset, watermarking the LLM's output, or computing the\nlog-likelihood. Importantly, the detection capability of AuthentiGPT can be\neasily adapted to any generative language model. With a 0.918 AUROC score on a\ndomain-specific dataset, AuthentiGPT demonstrates its effectiveness over other\ncommercial algorithms, highlighting its potential for detecting\nmachine-generated text in academic settings.",
            "author": [
                "Zhen Guo",
                "Shangdi Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07700v1",
                "http://arxiv.org/pdf/2311.07700v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08428v1",
            "title": "Deep Phenotyping of Non-Alcoholic Fatty Liver Disease Patients with\n  Genetic Factors for Insights into the Complex Disease",
            "updated": "2023-11-13T19:31:12Z",
            "published": "2023-11-13T19:31:12Z",
            "summary": "Non-alcoholic fatty liver disease (NAFLD) is a prevalent chronic liver\ndisorder characterized by the excessive accumulation of fat in the liver in\nindividuals who do not consume significant amounts of alcohol, including risk\nfactors like obesity, insulin resistance, type 2 diabetes, etc. We aim to\nidentify subgroups of NAFLD patients based on demographic, clinical, and\ngenetic characteristics for precision medicine. The genomic and phenotypic data\n(3,408 cases and 4,739 controls) for this study were gathered from participants\nin Mayo Clinic Tapestry Study (IRB#19-000001) and their electric health\nrecords, including their demographic, clinical, and comorbidity data, and the\ngenotype information through whole exome sequencing performed at Helix using\nthe Exome+$^\\circledR$ Assay according to standard procedure\n(www$.$helix$.$com). Factors highly relevant to NAFLD were determined by the\nchi-square test and stepwise backward-forward regression model. Latent class\nanalysis (LCA) was performed on NAFLD cases using significant indicator\nvariables to identify subgroups. The optimal clustering revealed 5 latent\nsubgroups from 2,013 NAFLD patients (mean age 60.6 years and 62.1% women),\nwhile a polygenic risk score based on 6 single-nucleotide polymorphism (SNP)\nvariants and disease outcomes were used to analyze the subgroups. The groups\nare characterized by metabolic syndrome, obesity, different comorbidities,\npsychoneurological factors, and genetic factors. Odds ratios were utilized to\ncompare the risk of complex diseases, such as fibrosis, cirrhosis, and\nhepatocellular carcinoma (HCC), as well as liver failure between the clusters.\nCluster 2 has a significantly higher complex disease outcome compared to other\nclusters. Keywords: Fatty liver disease; Polygenic risk score; Precision\nmedicine; Deep phenotyping; NAFLD comorbidities; Latent class analysis.",
            "author": [
                "Tahmina Sultana Priya",
                "Fan Leng",
                "Anthony C. Luehrs",
                "Eric W. Klee",
                "Alina M. Allen",
                "Konstantinos N. Lazaridis",
                "Danfeng",
                "Yao",
                "Shulan Tian"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08428v1",
                "http://arxiv.org/pdf/2311.08428v1"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07693v1",
            "title": "Matching aggregate posteriors in the variational autoencoder",
            "updated": "2023-11-13T19:22:37Z",
            "published": "2023-11-13T19:22:37Z",
            "summary": "The variational autoencoder (VAE) is a well-studied, deep, latent-variable\nmodel (DLVM) that efficiently optimizes the variational lower bound of the log\nmarginal data likelihood and has a strong theoretical foundation. However, the\nVAE's known failure to match the aggregate posterior often results in\n\\emph{pockets/holes} in the latent distribution (i.e., a failure to match the\nprior) and/or \\emph{posterior collapse}, which is associated with a loss of\ninformation in the latent space. This paper addresses these shortcomings in\nVAEs by reformulating the objective function associated with VAEs in order to\nmatch the aggregate/marginal posterior distribution to the prior. We use kernel\ndensity estimate (KDE) to model the aggregate posterior in high dimensions. The\nproposed method is named the \\emph{aggregate variational autoencoder} (AVAE)\nand is built on the theoretical framework of the VAE. Empirical evaluation of\nthe proposed method on multiple benchmark data sets demonstrates the\neffectiveness of the AVAE relative to state-of-the-art (SOTA) methods.",
            "author": [
                "Surojit Saha",
                "Sarang Joshi",
                "Ross Whitaker"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07693v1",
                "http://arxiv.org/pdf/2311.07693v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07692v1",
            "title": "On The Truthfulness of 'Surprisingly Likely' Responses of Large Language\n  Models",
            "updated": "2023-11-13T19:21:25Z",
            "published": "2023-11-13T19:21:25Z",
            "summary": "The surprisingly likely criterion in the seminal work of Prelec (the Bayesian\nTruth Serum) guarantees truthfulness in a game-theoretic multi-agent setting,\nby rewarding rational agents to maximise the expected information gain with\ntheir answers w.r.t. their probabilistic beliefs. We investigate the relevance\nof a similar criterion for responses of LLMs. We hypothesize that if the\nsurprisingly likely criterion works in LLMs, under certain conditions, the\nresponses that maximize the reward under this criterion should be more accurate\nthan the responses that only maximize the posterior probability. Using\nbenchmarks including the TruthfulQA benchmark and using openly available LLMs:\nGPT-2 and LLaMA-2, we show that the method indeed improves the accuracy\nsignificantly (for example, upto 24 percentage points aggregate improvement on\nTruthfulQA and upto 70 percentage points improvement on individual categories\nof questions).",
            "author": [
                "Naman Goel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07692v1",
                "http://arxiv.org/pdf/2311.07692v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL",
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07687v1",
            "title": "Language Model-In-The-Loop: Data Optimal Approach to Learn-To-Recommend\n  Actions in Text Games",
            "updated": "2023-11-13T19:12:49Z",
            "published": "2023-11-13T19:12:49Z",
            "summary": "Large Language Models (LLMs) have demonstrated superior performance in\nlanguage understanding benchmarks. CALM, a popular approach, leverages\nlinguistic priors of LLMs -- GPT-2 -- for action candidate recommendations to\nimprove the performance in text games in Jericho without environment-provided\nactions. However, CALM adapts GPT-2 with annotated human gameplays and keeps\nthe LLM fixed during the learning of the text based games. In this work, we\nexplore and evaluate updating LLM used for candidate recommendation during the\nlearning of the text based game as well to mitigate the reliance on the human\nannotated gameplays, which are costly to acquire. We observe that by updating\nthe LLM during learning using carefully selected in-game transitions, we can\nreduce the dependency on using human annotated game plays for fine-tuning the\nLLMs. We conducted further analysis to study the transferability of the updated\nLLMs and observed that transferring in-game trained models to other games did\nnot result in a consistent transfer.",
            "author": [
                "Arjun Vaithilingam Sudhakar",
                "Prasanna Parthasarathi",
                "Janarthanan Rajendran",
                "Sarath Chandar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07687v1",
                "http://arxiv.org/pdf/2311.07687v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07682v1",
            "title": "Fuse to Forget: Bias Reduction and Selective Memorization through Model\n  Fusion",
            "updated": "2023-11-13T19:02:56Z",
            "published": "2023-11-13T19:02:56Z",
            "summary": "Model fusion research aims to aggregate the knowledge of multiple models to\nenhance performance by combining their weights. In this work, we study the\ninverse, investigating whether and how can model fusion interfere and reduce\nunwanted knowledge. We delve into the effects of model fusion on the evolution\nof learned shortcuts, social biases, and memorization capabilities in\nfine-tuned language models. Through several experiments covering text\nclassification and generation tasks, our analysis highlights that shared\nknowledge among models is usually enhanced during model fusion, while unshared\nknowledge is usually lost or forgotten. Based on this observation, we\ndemonstrate the potential of model fusion as a debiasing tool and showcase its\nefficacy in addressing privacy concerns associated with language models.",
            "author": [
                "Kerem Zaman",
                "Leshem Choshen",
                "Shashank Srivastava"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07682v1",
                "http://arxiv.org/pdf/2311.07682v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07669v1",
            "title": "Surveying the onset and evolution of supermassive black holes at high-z\n  with AXIS",
            "updated": "2023-11-13T19:00:47Z",
            "published": "2023-11-13T19:00:47Z",
            "summary": "The nature and origin of supermassive black holes (SMBHs) remain an open\nmatter of debate within the scientific community. While various theoretical\nscenarios have been proposed, each with specific observational signatures, the\nlack of sufficiently sensitive X-ray observations hinders the progress of\nobservational tests. In this white paper, we present how AXIS will contribute\nto solving this issue. With an angular resolution of 1.5$^{\\prime\\prime}$\non-axis and minimal off-axis degradation, we have designed a deep survey\ncapable of reaching flux limits in the [0.5-2] keV range of approximately\n2$\\times$10$^{-18}$ \\fcgs~ over an area of 0.13 deg$^2$ in approximately 7\nmillion seconds (7 Ms). Furthermore, we have planned an intermediate depth\nsurvey covering approximately 2 deg$^2$ and reaching flux limits of about\n2$\\times$10$^{-17}$ \\fcgs ~ in order to detect a significant number of SMBHs\nwith X-ray luminosities (L$_X$) of approximately 10$^{42}$ \\lx up to z$\\sim$10.\nThese observations will enable AXIS to detect SMBHs with masses smaller than\n10$^5$ \\ms, assuming Eddington-limited accretion and a typical bolometric\ncorrection for Type II AGN. AXIS will provide valuable information on the\nseeding and population synthesis models of SMBH, allowing for more accurate\nconstraints on their initial mass function (IMF) and accretion history from\nz$\\sim$0-10. To accomplish this, AXIS will leverage the unique synergy of\nsurvey telescopes such as JWST, Roman, Euclid, LSST, and the new generation of\n30m class telescopes. These instruments will provide optical identification and\nredshift measurements, while AXIS will discover the smoking gun of nuclear\nactivity, particularly in the case of highly obscured AGN or peculiar UV\nspectra as predicted and recently observed in the early Universe.",
            "author": [
                "Nico Cappelluti",
                "Adi Foord",
                "Stefano Marchesi",
                "Fabio Pacucci",
                "Angelo Ricarte",
                "Melanie Habouzit",
                "Fabio Vito",
                "Meredith Powell",
                "Michael Koss",
                "Richard Mushotzky",
                "the AXIS AGN-SWG"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07669v1",
                "http://arxiv.org/pdf/2311.07669v1"
            ],
            "primary_category": "astro-ph.HE",
            "category": [
                "astro-ph.HE",
                "astro-ph.CO",
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07666v2",
            "title": "Efficient MPS representations and quantum circuits from the Fourier\n  modes of classical image data",
            "updated": "2023-12-01T14:42:23Z",
            "published": "2023-11-13T19:00:33Z",
            "summary": "Machine learning tasks are an exciting application for quantum computers, as\nit has been proven that they can learn certain problems more efficiently than\nclassical ones. Applying quantum machine learning algorithms to classical data\ncan have many important applications, as qubits allow for dealing with\nexponentially more data than classical bits. However, preparing the\ncorresponding quantum states usually requires an exponential number of gates\nand therefore may ruin any potential quantum speedups. Here, we show that\nclassical data with a sufficiently quickly decaying Fourier spectrum after\nbeing mapped to a quantum state can be well-approximated by states with a small\nSchmidt rank (i.e., matrix product states) and we derive explicit error bounds.\nThese approximated states can, in turn, be prepared on a quantum computer with\na linear number of nearest-neighbor two-qubit gates. We confirm our results\nnumerically on a set of $1024\\times1024$-pixel images taken from the\n'Imagenette' dataset. Additionally, we consider different variational circuit\nans\\\"atze and demonstrate numerically that one-dimensional sequential circuits\nachieve the same compression quality as more powerful ans\\\"atze.",
            "author": [
                "Bernhard Jobst",
                "Kevin Shen",
                "Carlos A. Riofr\u00edo",
                "Elvira Shishenina",
                "Frank Pollmann"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07666v2",
                "http://arxiv.org/pdf/2311.07666v2"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07652v1",
            "title": "Safe but Incalculable: Energy-weighting is not all you need",
            "updated": "2023-11-13T19:00:02Z",
            "published": "2023-11-13T19:00:02Z",
            "summary": "Infrared and collinear (IRC) safety has long been used a proxy for robustness\nwhen developing new jet substructure observables. This guiding philosophy has\nbeen carried into the deep learning era, where IRC-safe neural networks have\nbeen used for many jet studies. For graph-based neural networks, the most\nstraightforward way to achieve IRC safety is to weight particle inputs by their\nenergies. However, energy-weighting by itself does not guarantee that\nperturbative calculations of machine-learned observables will enjoy small\nnon-perturbative corrections. In this paper, we demonstrate the sensitivity of\nIRC-safe networks to non-perturbative effects, by training an energy flow\nnetwork (EFN) to maximize its sensitivity to hadronization. We then show how to\nconstruct Lipschitz Energy Flow Networks (L-EFNs), which are both IRC safe and\nrelatively insensitive to non-perturbative corrections. We demonstrate the\nperformance of L-EFNs on generated samples of quark and gluon jets, and\nshowcase fascinating differences between the learned latent representations of\nEFNs and L-EFNs.",
            "author": [
                "Samuel Bright-Thonney",
                "Benjamin Nachman",
                "Jesse Thaler"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07652v1",
                "http://arxiv.org/pdf/2311.07652v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07575v1",
            "title": "SPHINX: The Joint Mixing of Weights, Tasks, and Visual Embeddings for\n  Multi-modal Large Language Models",
            "updated": "2023-11-13T18:59:47Z",
            "published": "2023-11-13T18:59:47Z",
            "summary": "We present SPHINX, a versatile multi-modal large language model (MLLM) with a\njoint mixing of model weights, tuning tasks, and visual embeddings. First, for\nstronger vision-language alignment, we unfreeze the large language model (LLM)\nduring pre-training, and introduce a weight mix strategy between LLMs trained\nby real-world and synthetic data. By directly integrating the weights from two\ndomains, the mixed LLM can efficiently incorporate diverse semantics with\nfavorable robustness. Then, to enable multi-purpose capabilities, we mix a\nvariety of tasks for joint visual instruction tuning, and design task-specific\ninstructions to avoid inter-task conflict. In addition to the basic visual\nquestion answering, we include more challenging tasks such as region-level\nunderstanding, caption grounding, document layout detection, and human pose\nestimation, contributing to mutual enhancement over different scenarios.\nAdditionally, we propose to extract comprehensive visual embeddings from\nvarious network architectures, pre-training paradigms, and information\ngranularity, providing language models with more robust image representations.\nBased on our proposed joint mixing, SPHINX exhibits superior multi-modal\nunderstanding capabilities on a wide range of applications. On top of this, we\nfurther propose an efficient strategy aiming to better capture fine-grained\nappearances of high-resolution images. With a mixing of different scales and\nhigh-resolution sub-images, SPHINX attains exceptional visual parsing and\nreasoning performance on existing evaluation benchmarks. We hope our work may\ncast a light on the exploration of joint mixing in future MLLM research. Code\nis released at https://github.com/Alpha-VLLM/LLaMA2-Accessory.",
            "author": [
                "Ziyi Lin",
                "Chris Liu",
                "Renrui Zhang",
                "Peng Gao",
                "Longtian Qiu",
                "Han Xiao",
                "Han Qiu",
                "Chen Lin",
                "Wenqi Shao",
                "Keqin Chen",
                "Jiaming Han",
                "Siyuan Huang",
                "Yichi Zhang",
                "Xuming He",
                "Hongsheng Li",
                "Yu Qiao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07575v1",
                "http://arxiv.org/pdf/2311.07575v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07568v1",
            "title": "Feature emergence via margin maximization: case studies in algebraic\n  tasks",
            "updated": "2023-11-13T18:56:33Z",
            "published": "2023-11-13T18:56:33Z",
            "summary": "Understanding the internal representations learned by neural networks is a\ncornerstone challenge in the science of machine learning. While there have been\nsignificant recent strides in some cases towards understanding how neural\nnetworks implement specific target functions, this paper explores a\ncomplementary question -- why do networks arrive at particular computational\nstrategies? Our inquiry focuses on the algebraic learning tasks of modular\naddition, sparse parities, and finite group operations. Our primary theoretical\nfindings analytically characterize the features learned by stylized neural\nnetworks for these algebraic tasks. Notably, our main technique demonstrates\nhow the principle of margin maximization alone can be used to fully specify the\nfeatures learned by the network. Specifically, we prove that the trained\nnetworks utilize Fourier features to perform modular addition and employ\nfeatures corresponding to irreducible group-theoretic representations to\nperform compositions in general groups, aligning closely with the empirical\nobservations of Nanda et al. and Chughtai et al. More generally, we hope our\ntechniques can help to foster a deeper understanding of why neural networks\nadopt specific computational strategies.",
            "author": [
                "Depen Morwani",
                "Benjamin L. Edelman",
                "Costin-Andrei Oncescu",
                "Rosie Zhao",
                "Sham Kakade"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07568v1",
                "http://arxiv.org/pdf/2311.07568v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "I.5.1; I.2.6"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07565v1",
            "title": "Exploration via linearly perturbed loss minimisation",
            "updated": "2023-11-13T18:54:43Z",
            "published": "2023-11-13T18:54:43Z",
            "summary": "We introduce exploration via linear loss perturbations (EVILL), a randomised\nexploration method for structured stochastic bandit problems that works by\nsolving for the minimiser of a linearly perturbed regularised negative\nlog-likelihood function. We show that, for the case of generalised linear\nbandits, EVILL reduces to perturbed history exploration (PHE), a method where\nexploration is done by training on randomly perturbed rewards. In doing so, we\nprovide a simple and clean explanation of when and why random reward\nperturbations give rise to good bandit algorithms. With the data-dependent\nperturbations we propose, not present in previous PHE-type methods, EVILL is\nshown to match the performance of Thompson-sampling-style\nparameter-perturbation methods, both in theory and in practice. Moreover, we\nshow an example outside of generalised linear bandits where PHE leads to\ninconsistent estimates, and thus linear regret, while EVILL remains performant.\nLike PHE, EVILL can be implemented in just a few lines of code.",
            "author": [
                "David Janz",
                "Shuai Liu",
                "Alex Ayoub",
                "Csaba Szepesv\u00e1ri"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07565v1",
                "http://arxiv.org/pdf/2311.07565v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07564v1",
            "title": "Can Authorship Attribution Models Distinguish Speakers in Speech\n  Transcripts?",
            "updated": "2023-11-13T18:54:17Z",
            "published": "2023-11-13T18:54:17Z",
            "summary": "Authorship verification is the problem of determining if two distinct writing\nsamples share the same author and is typically concerned with the attribution\nof written text. In this paper, we explore the attribution of transcribed\nspeech, which poses novel challenges. The main challenge is that many stylistic\nfeatures, such as punctuation and capitalization, are not available or\nreliable. Therefore, we expect a priori that transcribed speech is a more\nchallenging domain for attribution. On the other hand, other stylistic\nfeatures, such as speech disfluencies, may enable more successful attribution\nbut, being specific to speech, require special purpose models. To better\nunderstand the challenges of this setting, we contribute the first systematic\nstudy of speaker attribution based solely on transcribed speech. Specifically,\nwe propose a new benchmark for speaker attribution focused on conversational\nspeech transcripts. To control for spurious associations of speakers with\ntopic, we employ both conversation prompts and speakers' participating in the\nsame conversation to construct challenging verification trials of varying\ndifficulties. We establish the state of the art on this new benchmark by\ncomparing a suite of neural and non-neural baselines, finding that although\nwritten text attribution models achieve surprisingly good performance in\ncertain settings, they struggle in the hardest settings we consider.",
            "author": [
                "Cristina Aggazzotti",
                "Nicholas Andrews",
                "Elizabeth Allyn Smith"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07564v1",
                "http://arxiv.org/pdf/2311.07564v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07563v1",
            "title": "Learning Control Policies of Hodgkin-Huxley Neuronal Dynamics",
            "updated": "2023-11-13T18:53:50Z",
            "published": "2023-11-13T18:53:50Z",
            "summary": "We present a neural network approach for closed-loop deep brain stimulation\n(DBS). We cast the problem of finding an optimal neurostimulation strategy as a\ncontrol problem. In this setting, control policies aim to optimize therapeutic\noutcomes by tailoring the parameters of a DBS system, typically via electrical\nstimulation, in real time based on the patient's ongoing neuronal activity. We\napproximate the value function offline using a neural network to enable\ngenerating controls (stimuli) in real time via the feedback form. The neuronal\nactivity is characterized by a nonlinear, stiff system of differential\nequations as dictated by the Hodgkin-Huxley model. Our training process\nleverages the relationship between Pontryagin's maximum principle and\nHamilton-Jacobi-Bellman equations to update the value function estimates\nsimultaneously. Our numerical experiments illustrate the accuracy of our\napproach for out-of-distribution samples and the robustness to moderate shocks\nand disturbances in the system.",
            "author": [
                "Malvern Madondo",
                "Deepanshu Verma",
                "Lars Ruthotto",
                "Nicholas Au Yong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07563v1",
                "http://arxiv.org/pdf/2311.07563v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07558v1",
            "title": "Data-Efficient Task Generalization via Probabilistic Model-based Meta\n  Reinforcement Learning",
            "updated": "2023-11-13T18:51:57Z",
            "published": "2023-11-13T18:51:57Z",
            "summary": "We introduce PACOH-RL, a novel model-based Meta-Reinforcement Learning\n(Meta-RL) algorithm designed to efficiently adapt control policies to changing\ndynamics. PACOH-RL meta-learns priors for the dynamics model, allowing swift\nadaptation to new dynamics with minimal interaction data. Existing Meta-RL\nmethods require abundant meta-learning data, limiting their applicability in\nsettings such as robotics, where data is costly to obtain. To address this,\nPACOH-RL incorporates regularization and epistemic uncertainty quantification\nin both the meta-learning and task adaptation stages. When facing new dynamics,\nwe use these uncertainty estimates to effectively guide exploration and data\ncollection. Overall, this enables positive transfer, even when access to data\nfrom prior tasks or dynamic settings is severely limited. Our experiment\nresults demonstrate that PACOH-RL outperforms model-based RL and model-based\nMeta-RL baselines in adapting to new dynamic conditions. Finally, on a real\nrobotic car, we showcase the potential for efficient RL policy adaptation in\ndiverse, data-scarce conditions.",
            "author": [
                "Arjun Bhardwaj",
                "Jonas Rothfuss",
                "Bhavya Sukhija",
                "Yarden As",
                "Marco Hutter",
                "Stelian Coros",
                "Andreas Krause"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07558v1",
                "http://arxiv.org/pdf/2311.07558v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07556v1",
            "title": "Using Natural Language Explanations to Improve Robustness of In-context\n  Learning for Natural Language Inference",
            "updated": "2023-11-13T18:49:13Z",
            "published": "2023-11-13T18:49:13Z",
            "summary": "Recent studies have demonstrated that large language models (LLMs) excel in\ndiverse tasks through in-context learning (ICL) facilitated by task-specific\nprompts and examples. However, the existing literature shows that ICL\nencounters performance deterioration when exposed to adversarial inputs.\nEnhanced performance has been observed when ICL is augmented with natural\nlanguage explanations (NLEs) (we refer to it as X-ICL). Thus, this work\ninvestigates whether X-ICL can improve the robustness of LLMs on a suite of\nseven adversarial and challenging natural language inference datasets.\nMoreover, we introduce a new approach to X-ICL by prompting an LLM (ChatGPT in\nour case) with few human-generated NLEs to produce further NLEs (we call it\nChatGPT few-shot), which we show superior to both ChatGPT zero-shot and\nhuman-generated NLEs alone. We evaluate five popular LLMs (GPT3.5-turbo,\nLLaMa2, Vicuna, Zephyr, Mistral) and show that X-ICL with ChatGPT few-shot\nyields over 6% improvement over ICL. Furthermore, while prompt selection\nstrategies were previously shown to significantly improve ICL on\nin-distribution test sets, we show that these strategies do not match the\nefficacy of the X-ICL paradigm in robustness-oriented evaluations.",
            "author": [
                "Xuanli He",
                "Yuxiang Wu",
                "Oana-Maria Camburu",
                "Pasquale Minervini",
                "Pontus Stenetorp"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07556v1",
                "http://arxiv.org/pdf/2311.07556v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07555v1",
            "title": "On Bounding and Approximating Functions of Multiple Expectations using\n  Quasi-Monte Carlo",
            "updated": "2023-11-13T18:49:03Z",
            "published": "2023-11-13T18:49:03Z",
            "summary": "Monte Carlo and Quasi-Monte Carlo methods present a convenient approach for\napproximating the expected value of a random variable. Algorithms exist to\nadaptively sample the random variable until a user defined absolute error\ntolerance is satisfied with high probability. This work describes an extension\nof such methods which supports adaptive sampling to satisfy general error\ncriteria for functions of a common array of expectations. Although several\nfunctions involving multiple expectations are being evaluated, only one random\nsequence is required, albeit sometimes of larger dimension than the underlying\nrandomness. These enhanced Monte Carlo and Quasi-Monte Carlo algorithms are\nimplemented in the QMCPy Python package with support for economic and parallel\nfunction evaluation. We exemplify these capabilities on problems from machine\nlearning and global sensitivity analysis.",
            "author": [
                "Aleksei G. Sorokin",
                "Jagadeeswaran Rathinavel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07555v1",
                "http://arxiv.org/pdf/2311.07555v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07550v1",
            "title": "Tabdoor: Backdoor Vulnerabilities in Transformer-based Neural Networks\n  for Tabular Data",
            "updated": "2023-11-13T18:39:44Z",
            "published": "2023-11-13T18:39:44Z",
            "summary": "Deep neural networks (DNNs) have shown great promise in various domains.\nAlongside these developments, vulnerabilities associated with DNN training,\nsuch as backdoor attacks, are a significant concern. These attacks involve the\nsubtle insertion of triggers during model training, allowing for manipulated\npredictions. More recently, DNNs for tabular data have gained increasing\nattention due to the rise of transformer models.\n  Our research presents a comprehensive analysis of backdoor attacks on tabular\ndata using DNNs, particularly focusing on transformer-based networks. Given the\ninherent complexities of tabular data, we explore the challenges of embedding\nbackdoors. Through systematic experimentation across benchmark datasets, we\nuncover that transformer-based DNNs for tabular data are highly susceptible to\nbackdoor attacks, even with minimal feature value alterations. Our results\nindicate nearly perfect attack success rates (approx100%) by introducing novel\nbackdoor attack strategies to tabular data. Furthermore, we evaluate several\ndefenses against these attacks, identifying Spectral Signatures as the most\neffective one. Our findings highlight the urgency to address such\nvulnerabilities and provide insights into potential countermeasures for\nsecuring DNN models against backdoors on tabular data.",
            "author": [
                "Bart Pleiter",
                "Behrad Tajalli",
                "Stefanos Koffas",
                "Gorka Abad",
                "Jing Xu",
                "Martha Larson",
                "Stjepan Picek"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07550v1",
                "http://arxiv.org/pdf/2311.07550v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07548v1",
            "title": "Interpretable Fine-Tuning for Graph Neural Network Surrogate Models",
            "updated": "2023-11-13T18:37:07Z",
            "published": "2023-11-13T18:37:07Z",
            "summary": "Data-based surrogate modeling has surged in capability in recent years with\nthe emergence of graph neural networks (GNNs), which can operate directly on\nmesh-based representations of data. The goal of this work is to introduce an\ninterpretable fine-tuning strategy for GNNs, with application to unstructured\nmesh-based fluid dynamics modeling. The end result is a fine-tuned GNN that\nadds interpretability to a pre-trained baseline GNN through an adaptive\nsub-graph sampling strategy that isolates regions in physical space\nintrinsically linked to the forecasting task, while retaining the predictive\ncapability of the baseline. The structures identified by the fine-tuned GNNs,\nwhich are adaptively produced in the forward pass as explicit functions of the\ninput, serve as an accessible link between the baseline model architecture, the\noptimization goal, and known problem-specific physics. Additionally, through a\nregularization procedure, the fine-tuned GNNs can also be used to identify,\nduring inference, graph nodes that correspond to a majority of the anticipated\nforecasting error, adding a novel interpretable error-tagging capability to\nbaseline models. Demonstrations are performed using unstructured flow data\nsourced from flow over a backward-facing step at high Reynolds numbers.",
            "author": [
                "Shivam Barwey",
                "Romit Maulik"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07548v1",
                "http://arxiv.org/pdf/2311.07548v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "physics.comp-ph",
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07547v1",
            "title": "GPT-4V(ision) as A Social Media Analysis Engine",
            "updated": "2023-11-13T18:36:50Z",
            "published": "2023-11-13T18:36:50Z",
            "summary": "Recent research has offered insights into the extraordinary capabilities of\nLarge Multimodal Models (LMMs) in various general vision and language tasks.\nThere is growing interest in how LMMs perform in more specialized domains.\nSocial media content, inherently multimodal, blends text, images, videos, and\nsometimes audio. Understanding social multimedia content remains a challenging\nproblem for contemporary machine learning frameworks. In this paper, we explore\nGPT-4V(ision)'s capabilities for social multimedia analysis. We select five\nrepresentative tasks, including sentiment analysis, hate speech detection, fake\nnews identification, demographic inference, and political ideology detection,\nto evaluate GPT-4V. Our investigation begins with a preliminary quantitative\nanalysis for each task using existing benchmark datasets, followed by a careful\nreview of the results and a selection of qualitative samples that illustrate\nGPT-4V's potential in understanding multimodal social media content. GPT-4V\ndemonstrates remarkable efficacy in these tasks, showcasing strengths such as\njoint understanding of image-text pairs, contextual and cultural awareness, and\nextensive commonsense knowledge. Despite the overall impressive capacity of\nGPT-4V in the social media domain, there remain notable challenges. GPT-4V\nstruggles with tasks involving multilingual social multimedia comprehension and\nhas difficulties in generalizing to the latest trends in social media.\nAdditionally, it exhibits a tendency to generate erroneous information in the\ncontext of evolving celebrity and politician knowledge, reflecting the known\nhallucination problem. The insights gleaned from our findings underscore a\npromising future for LMMs in enhancing our comprehension of social media\ncontent and its users through the analysis of multimodal information.",
            "author": [
                "Hanjia Lyu",
                "Jinfa Huang",
                "Daoan Zhang",
                "Yongsheng Yu",
                "Xinyi Mou",
                "Jinsheng Pan",
                "Zhengyuan Yang",
                "Zhongyu Wei",
                "Jiebo Luo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07547v1",
                "http://arxiv.org/pdf/2311.07547v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07541v1",
            "title": "mlscorecheck: Testing the consistency of reported performance scores and\n  experiments in machine learning",
            "updated": "2023-11-13T18:31:48Z",
            "published": "2023-11-13T18:31:48Z",
            "summary": "Addressing the reproducibility crisis in artificial intelligence through the\nvalidation of reported experimental results is a challenging task. It\nnecessitates either the reimplementation of techniques or a meticulous\nassessment of papers for deviations from the scientific method and best\nstatistical practices. To facilitate the validation of reported results, we\nhave developed numerical techniques capable of identifying inconsistencies\nbetween reported performance scores and various experimental setups in machine\nlearning problems, including binary/multiclass classification and regression.\nThese consistency tests are integrated into the open-source package\nmlscorecheck, which also provides specific test bundles designed to detect\nsystematically recurring flaws in various fields, such as retina image\nprocessing and synthetic minority oversampling.",
            "author": [
                "Gy\u00f6rgy Kov\u00e1cs",
                "Attila Fazekas"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07541v1",
                "http://arxiv.org/pdf/2311.07541v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "68T01",
                "I.2.0"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07538v1",
            "title": "Leveraging Multiple Teachers for Test-Time Adaptation of Language-Guided\n  Classifiers",
            "updated": "2023-11-13T18:28:25Z",
            "published": "2023-11-13T18:28:25Z",
            "summary": "Recent approaches have explored language-guided classifiers capable of\nclassifying examples from novel tasks when provided with task-specific natural\nlanguage explanations, instructions or prompts (Sanh et al., 2022; R. Menon et\nal., 2022). While these classifiers can generalize in zero-shot settings, their\ntask performance often varies substantially between different language\nexplanations in unpredictable ways (Lu et al., 2022; Gonen et al., 2022). Also,\ncurrent approaches fail to leverage unlabeled examples that may be available in\nmany scenarios. Here, we introduce TALC, a framework that uses data programming\nto adapt a language-guided classifier for a new task during inference when\nprovided with explanations from multiple teachers and unlabeled test examples.\nOur results show that TALC consistently outperforms a competitive baseline from\nprior work by an impressive 9.3% (relative improvement). Further, we\ndemonstrate the robustness of TALC to variations in the quality and quantity of\nprovided explanations, highlighting its potential in scenarios where learning\nfrom multiple teachers or a crowd is involved. Our code is available at:\nhttps://github.com/WeiKangda/TALC.git.",
            "author": [
                "Kangda Wei",
                "Sayan Ghosh",
                "Rakesh R. Menon",
                "Shashank Srivastava"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07538v1",
                "http://arxiv.org/pdf/2311.07538v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07537v1",
            "title": "Estimating optical vegetation indices with Sentinel-1 SAR data and\n  AutoML",
            "updated": "2023-11-13T18:23:46Z",
            "published": "2023-11-13T18:23:46Z",
            "summary": "Current optical vegetation indices (VIs) for monitoring forest ecosystems are\nwidely used in various applications. However, continuous monitoring based on\noptical satellite data can be hampered by atmospheric effects such as clouds.\nOn the contrary, synthetic aperture radar (SAR) data can offer insightful and\nsystematic forest monitoring with complete time series due to signal\npenetration through clouds and day and night acquisitions. The goal of this\nwork is to overcome the issues affecting optical data with SAR data and serve\nas a substitute for estimating optical VIs for forests using machine learning.\nTime series of four VIs (LAI, FAPAR, EVI and NDVI) were estimated using\nmultitemporal Sentinel-1 SAR and ancillary data. This was enabled by creating a\npaired multi-temporal and multi-modal dataset in Google Earth Engine (GEE),\nincluding temporally and spatially aligned Sentinel-1, Sentinel-2, digital\nelevation model (DEM), weather and land cover datasets (MMT-GEE). The use of\nancillary features generated from DEM and weather data improved the results.\nThe open-source Automatic Machine Learning (AutoML) approach, auto-sklearn,\noutperformed Random Forest Regression for three out of four VIs, while a 1-hour\noptimization length was enough to achieve sufficient results with an R2 of\n69-84% low errors (0.05-0.32 of MAE depending on VI). Great agreement was also\nfound for selected case studies in the time series analysis and in the spatial\ncomparison between the original and estimated SAR-based VIs. In general,\ncompared to VIs from currently freely available optical satellite data and\navailable global VI products, a better temporal resolution (up to 240\nmeasurements/year) and a better spatial resolution (20 m) were achieved using\nestimated SAR-based VIs. A great advantage of the SAR-based VI is the ability\nto detect abrupt forest changes with a sub-weekly temporal accuracy.",
            "author": [
                "Daniel Paluba",
                "Bertrand Le Saux",
                "Francesco Sarti",
                "P\u0159emysl Stych"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07537v1",
                "http://arxiv.org/pdf/2311.07537v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "stat.AP",
                "I.4.8; I.4.9"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07536v1",
            "title": "A Comprehensive Evaluation of GPT-4V on Knowledge-Intensive Visual\n  Question Answering",
            "updated": "2023-11-13T18:22:32Z",
            "published": "2023-11-13T18:22:32Z",
            "summary": "The emergence of multimodal large models (MLMs) has significantly advanced\nthe field of visual understanding, offering remarkable capabilities in the\nrealm of visual question answering (VQA). Yet, the true challenge lies in the\ndomain of knowledge-intensive VQA tasks, which necessitate not just recognition\nof visual elements, but also a deep comprehension of the visual information in\nconjunction with a vast repository of learned knowledge. To uncover such\ncapabilities of MLMs, particularly the newly introduced GPT-4V, we provide an\nin-depth evaluation from three perspectives: 1) Commonsense Knowledge, which\nassesses how well models can understand visual cues and connect to general\nknowledge; 2) Fine-grained World Knowledge, which tests the model's skill in\nreasoning out specific knowledge from images, showcasing their proficiency\nacross various specialized fields; 3) Comprehensive Knowledge with\nDecision-making Rationales, which examines model's capability to provide\nlogical explanations for its inference, facilitating a deeper analysis from the\ninterpretability perspective. Extensive experiments indicate that GPT-4V\nachieves SOTA performance on above three tasks. Interestingly, we find that: a)\nGPT-4V demonstrates enhanced reasoning and explanation when using composite\nimages as few-shot; b) GPT-4V produces severe hallucinations when dealing with\nworld knowledge, highlighting the future need for advancements in this research\ndirection.",
            "author": [
                "Yunxin Li",
                "Longyue Wang",
                "Baotian Hu",
                "Xinyu Chen",
                "Wanqi Zhong",
                "Chenyang Lyu",
                "Min Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07536v1",
                "http://arxiv.org/pdf/2311.07536v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07534v2",
            "title": "Unsupervised Musical Object Discovery from Audio",
            "updated": "2023-11-14T08:15:25Z",
            "published": "2023-11-13T18:21:33Z",
            "summary": "Current object-centric learning models such as the popular SlotAttention\narchitecture allow for unsupervised visual scene decomposition. Our novel\nMusicSlots method adapts SlotAttention to the audio domain, to achieve\nunsupervised music decomposition. Since concepts of opacity and occlusion in\nvision have no auditory analogues, the softmax normalization of alpha masks in\nthe decoders of visual object-centric models is not well-suited for decomposing\naudio objects. MusicSlots overcomes this problem. We introduce a\nspectrogram-based multi-object music dataset tailored to evaluate\nobject-centric learning on western tonal music. MusicSlots achieves good\nperformance on unsupervised note discovery and outperforms several established\nbaselines on supervised note property prediction tasks.",
            "author": [
                "Joonsu Gha",
                "Vincent Herrmann",
                "Benjamin Grewe",
                "J\u00fcrgen Schmidhuber",
                "Anand Gopalakrishnan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07534v2",
                "http://arxiv.org/pdf/2311.07534v2"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.LG",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07533v2",
            "title": "Lattice relaxation, electronic structure and continuum model for twisted\n  bilayer MoTe$_2$",
            "updated": "2023-11-16T17:24:58Z",
            "published": "2023-11-13T18:19:19Z",
            "summary": "We investigate the lattice relaxation effect on moir\\'e band structures in\ntwisted bilayer MoTe$_2$ with two approaches: (a) large-scale plane-wave basis\nfirst principle calculation down to $2.88^{\\circ}$, (b) transfer learning\nstructure relaxation + local-basis first principles calculation down to\n$1.1^{\\circ}$. Two types of van der Waals corrections have been examined: the\nD2 method of Grimme and the density-dependent energy correction. We note the\ndensity-dependent energy correction yields a continuous evolution of bandwidth\nwith twist angles. Including second harmonic of intralayer potential/interlayer\ntunneling and the strain induced gauge field, we develop a more complete\ncontinuum model with a single set of parameters for a wide range of twist\nangles, providing a useful starting point for many body simulation.",
            "author": [
                "Ning Mao",
                "Cheng Xu",
                "Jiangxu Li",
                "Ting Bao",
                "Peitao Liu",
                "Yong Xu",
                "Claudia Felser",
                "Liang Fu",
                "Yang Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07533v2",
                "http://arxiv.org/pdf/2311.07533v2"
            ],
            "primary_category": "cond-mat.str-el",
            "category": [
                "cond-mat.str-el"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07527v1",
            "title": "Automatic Identification of Driving Maneuver Patterns using a Robust\n  Hidden Semi-Markov Models",
            "updated": "2023-11-13T18:13:55Z",
            "published": "2023-11-13T18:13:55Z",
            "summary": "There is an increase in interest to model driving maneuver patterns via the\nautomatic unsupervised clustering of naturalistic sequential kinematic driving\ndata. The patterns learned are often used in transportation research areas such\nas eco-driving, road safety, and intelligent vehicles. One such model capable\nof modeling these patterns is the Hierarchical Dirichlet Process Hidden\nSemi-Markov Model (HDP-HSMM), as it is often used to estimate data\nsegmentation, state duration, and transition probabilities. While this model is\na powerful tool for automatically clustering observed sequential data, the\nexisting HDP-HSMM estimation suffers from an inherent tendency to overestimate\nthe number of states. This can result in poor estimation, which can potentially\nimpact impact transportation research through incorrect inference of driving\npatterns. In this paper, a new robust HDP-HSMM (rHDP-HSMM) method is proposed\nto reduce the number of redundant states and improve the consistency of the\nmodel's estimation. Both a simulation study and a case study using naturalistic\ndriving data are presented to demonstrate the effectiveness of the proposed\nrHDP-HSMM in identifying and inference of driving maneuver patterns.",
            "author": [
                "Matthew Aguirre",
                "Wenbo Sun",
                "Jionghua",
                "Jin",
                "Yang Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07527v1",
                "http://arxiv.org/pdf/2311.07527v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07519v1",
            "title": "Machine Learning For Beamline Steering",
            "updated": "2023-11-13T18:00:06Z",
            "published": "2023-11-13T18:00:06Z",
            "summary": "Beam steering is the process involving the calibration of the angle and\nposition at which a particle accelerator's electron beam is incident upon the\nx-ray target with respect to the rotation axis of the collimator. Beam Steering\nis an essential task for light sources. In the case under study, the LINAC To\nUndulator (LTU) section of the beamline is difficult to aim. Each use of the\naccelerator requires re-calibration of the magnets in this section. This\ninvolves a substantial amount of time and effort from human operators, while\nreducing scientific throughput of the light source. We investigate the use of\ndeep neural networks to assist in this task. The deep learning models are\ntrained on archival data and then validated on simulation data. The performance\nof the deep learning model is contrasted against that of trained human\noperators.",
            "author": [
                "Isaac Kante"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07519v1",
                "http://arxiv.org/pdf/2311.07519v1"
            ],
            "primary_category": "physics.acc-ph",
            "category": [
                "physics.acc-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07518v1",
            "title": "FEMDA: a unified framework for discriminant analysis",
            "updated": "2023-11-13T17:59:37Z",
            "published": "2023-11-13T17:59:37Z",
            "summary": "Although linear and quadratic discriminant analysis are widely recognized\nclassical methods, they can encounter significant challenges when dealing with\nnon-Gaussian distributions or contaminated datasets. This is primarily due to\ntheir reliance on the Gaussian assumption, which lacks robustness. We first\nexplain and review the classical methods to address this limitation and then\npresent a novel approach that overcomes these issues. In this new approach, the\nmodel considered is an arbitrary Elliptically Symmetrical (ES) distribution per\ncluster with its own arbitrary scale parameter. This flexible model allows for\npotentially diverse and independent samples that may not follow identical\ndistributions. By deriving a new decision rule, we demonstrate that\nmaximum-likelihood parameter estimation and classification are simple,\nefficient, and robust compared to state-of-the-art methods.",
            "author": [
                "Pierre Houdouin",
                "Matthieu Jonckheere",
                "Frederic Pascal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07518v1",
                "http://arxiv.org/pdf/2311.07518v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07514v1",
            "title": "VGSG: Vision-Guided Semantic-Group Network for Text-based Person Search",
            "updated": "2023-11-13T17:56:54Z",
            "published": "2023-11-13T17:56:54Z",
            "summary": "Text-based Person Search (TBPS) aims to retrieve images of target pedestrian\nindicated by textual descriptions. It is essential for TBPS to extract\nfine-grained local features and align them crossing modality. Existing methods\nutilize external tools or heavy cross-modal interaction to achieve explicit\nalignment of cross-modal fine-grained features, which is inefficient and\ntime-consuming. In this work, we propose a Vision-Guided Semantic-Group Network\n(VGSG) for text-based person search to extract well-aligned fine-grained visual\nand textual features. In the proposed VGSG, we develop a Semantic-Group Textual\nLearning (SGTL) module and a Vision-guided Knowledge Transfer (VGKT) module to\nextract textual local features under the guidance of visual local clues. In\nSGTL, in order to obtain the local textual representation, we group textual\nfeatures from the channel dimension based on the semantic cues of language\nexpression, which encourages similar semantic patterns to be grouped implicitly\nwithout external tools. In VGKT, a vision-guided attention is employed to\nextract visual-related textual features, which are inherently aligned with\nvisual cues and termed vision-guided textual features. Furthermore, we design a\nrelational knowledge transfer, including a vision-language similarity transfer\nand a class probability transfer, to adaptively propagate information of the\nvision-guided textual features to semantic-group textual features. With the\nhelp of relational knowledge transfer, VGKT is capable of aligning\nsemantic-group textual features with corresponding visual features without\nexternal tools and complex pairwise interaction. Experimental results on two\nchallenging benchmarks demonstrate its superiority over state-of-the-art\nmethods.",
            "author": [
                "Shuting He",
                "Hao Luo",
                "Wei Jiang",
                "Xudong Jiang",
                "Henghui Ding"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07514v1",
                "http://arxiv.org/pdf/2311.07514v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07513v1",
            "title": "A Hypothesis on Good Practices for AI-based Systems for Financial Time\n  Series Forecasting: Towards Domain-Driven XAI Methods",
            "updated": "2023-11-13T17:56:45Z",
            "published": "2023-11-13T17:56:45Z",
            "summary": "Machine learning and deep learning have become increasingly prevalent in\nfinancial prediction and forecasting tasks, offering advantages such as\nenhanced customer experience, democratising financial services, improving\nconsumer protection, and enhancing risk management. However, these complex\nmodels often lack transparency and interpretability, making them challenging to\nuse in sensitive domains like finance. This has led to the rise of eXplainable\nArtificial Intelligence (XAI) methods aimed at creating models that are easily\nunderstood by humans. Classical XAI methods, such as LIME and SHAP, have been\ndeveloped to provide explanations for complex models. While these methods have\nmade significant contributions, they also have limitations, including\ncomputational complexity, inherent model bias, sensitivity to data sampling,\nand challenges in dealing with feature dependence. In this context, this paper\nexplores good practices for deploying explainability in AI-based systems for\nfinance, emphasising the importance of data quality, audience-specific methods,\nconsideration of data properties, and the stability of explanations. These\npractices aim to address the unique challenges and requirements of the\nfinancial industry and guide the development of effective XAI tools.",
            "author": [
                "Branka Hadji Misheva",
                "Joerg Osterrieder"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07513v1",
                "http://arxiv.org/pdf/2311.07513v1"
            ],
            "primary_category": "q-fin.GN",
            "category": [
                "q-fin.GN",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07511v1",
            "title": "Machine learning for uncertainty estimation in fusing precipitation\n  observations from satellites and ground-based gauges",
            "updated": "2023-11-13T17:55:28Z",
            "published": "2023-11-13T17:55:28Z",
            "summary": "To form precipitation datasets that are accurate and, at the same time, have\nhigh spatial densities, data from satellites and gauges are often merged in the\nliterature. However, uncertainty estimates for the data acquired in this manner\nare scarcely provided, although the importance of uncertainty quantification in\npredictive modelling is widely recognized. Furthermore, the benefits that\nmachine learning can bring to the task of providing such estimates have not\nbeen broadly realized and properly explored through benchmark experiments. The\npresent study aims at filling in this specific gap by conducting the first\nbenchmark tests on the topic. On a large dataset that comprises 15-year-long\nmonthly data spanning across the contiguous United States, we extensively\ncompared six learners that are, by their construction, appropriate for\npredictive uncertainty quantification. These are the quantile regression (QR),\nquantile regression forests (QRF), generalized random forests (GRF), gradient\nboosting machines (GBM), light gradient boosting machines (LightGBM) and\nquantile regression neural networks (QRNN). The comparison referred to the\ncompetence of the learners in issuing predictive quantiles at nine levels that\nfacilitate a good approximation of the entire predictive probability\ndistribution, and was primarily based on the quantile and continuous ranked\nprobability skill scores. Three types of predictor variables (i.e., satellite\nprecipitation variables, distances between a point of interest and satellite\ngrid points, and elevation at a point of interest) were used in the comparison\nand were additionally compared with each other. This additional comparison was\nbased on the explainable machine learning concept of feature importance. The\nresults suggest that the order from the best to the worst of the learners for\nthe task investigated is the following: LightGBM, QRF, GRF, GBM, QRNN and QR...",
            "author": [
                "Georgia Papacharalampous",
                "Hristos Tyralis",
                "Nikolaos Doulamis",
                "Anastasios Doulamis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07511v1",
                "http://arxiv.org/pdf/2311.07511v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "physics.ao-ph",
                "stat.AP",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07510v1",
            "title": "Explicit Foundation Model Optimization with Self-Attentive Feed-Forward\n  Neural Units",
            "updated": "2023-11-13T17:55:07Z",
            "published": "2023-11-13T17:55:07Z",
            "summary": "Iterative approximation methods using backpropagation enable the optimization\nof neural networks, but they remain computationally expensive, especially when\nused at scale. This paper presents an efficient alternative for optimizing\nneural networks that reduces the costs of scaling neural networks and provides\nhigh-efficiency optimizations for low-resource applications. We will discuss a\ngeneral result about feed-forward neural networks and then extend this solution\nto compositional (mult-layer) networks, which are applied to a simplified\ntransformer block containing feed-forward and self-attention layers. These\nmodels are used to train highly-specified and complex multi-layer neural\narchitectures that we refer to as self-attentive feed-forward unit (SAFFU)\nlayers, which we use to develop a transformer that appears to generalize well\nover small, cognitively-feasible, volumes of data. Testing demonstrates\nexplicit solutions outperform models optimized by backpropagation alone.\nMoreover, further application of backpropagation after explicit solutions leads\nto better optima from smaller scales of data, training effective models from\nmuch less data is enabled by explicit solution warm starts. We then carry out\nablation experiments training a roadmap of about 250 transformer models over\n1-million tokens to determine ideal settings. We find that multiple different\narchitectural variants produce highly-performant models, and discover from this\nablation that some of the best are not the most parameterized. This appears to\nindicate well-generalized models could be reached using less data by using\nexplicit solutions, and that architectural exploration using explicit solutions\npays dividends in guiding the search for efficient variants with fewer\nparameters, and which could be incorporated into low-resource hardware where AI\nmight be embodied.",
            "author": [
                "Jake Ryland Williams",
                "Haoran Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07510v1",
                "http://arxiv.org/pdf/2311.07510v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.PR",
                "physics.data-an",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.02984v1",
            "title": "Diff-GO: Diffusion Goal-Oriented Communications to Achieve Ultra-High\n  Spectrum Efficiency",
            "updated": "2023-11-13T17:52:44Z",
            "published": "2023-11-13T17:52:44Z",
            "summary": "The latest advances in artificial intelligence (AI) present many\nunprecedented opportunities to achieve much improved bandwidth saving in\ncommunications. Unlike conventional communication systems focusing on packet\ntransport, rich datasets and AI makes it possible to efficiently transfer only\nthe information most critical to the goals of message recipients. One of the\nmost exciting advances in generative AI known as diffusion model presents a\nunique opportunity for designing ultra-fast communication systems well beyond\nlanguage-based messages. This work presents an ultra-efficient communication\ndesign by utilizing generative AI-based on diffusion models as a specific\nexample of the general goal-oriented communication framework. To better control\nthe regenerated message at the receiver output, our diffusion system design\nincludes a local regeneration module with finite dimensional noise latent. The\ncritical significance of noise latent control and sharing residing on our\nDiff-GO is the ability to introduce the concept of \"local generative feedback\"\n(Local-GF), which enables the transmitter to monitor the quality and gauge the\nquality or accuracy of the message recovery at the semantic system receiver. To\nthis end, we propose a new low-dimensional noise space for the training of\ndiffusion models, which significantly reduces the communication overhead and\nachieves satisfactory message recovery performance. Our experimental results\ndemonstrate that the proposed noise space and the diffusion-based generative\nmodel achieve ultra-high spectrum efficiency and accurate recovery of\ntransmitted image signals. By trading off computation for bandwidth efficiency\n(C4BE), this new framework provides an important avenue to achieve exceptional\ncomputation-bandwidth tradeoff.",
            "author": [
                "Achintha Wijesinghe",
                "Songyang Zhang",
                "Suchinthaka Wanninayaka",
                "Weiwei Wang",
                "Zhi Ding"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02984v1",
                "http://arxiv.org/pdf/2312.02984v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV",
                "cs.MM",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07506v1",
            "title": "Provably Efficient Learning of Phases of Matter via Dissipative\n  Evolutions",
            "updated": "2023-11-13T17:50:18Z",
            "published": "2023-11-13T17:50:18Z",
            "summary": "The combination of quantum many-body and machine learning techniques has\nrecently proved to be a fertile ground for new developments in quantum\ncomputing. Several works have shown that it is possible to classically\nefficiently predict the expectation values of local observables on all states\nwithin a phase of matter using a machine learning algorithm after learning from\ndata obtained from other states in the same phase. However, existing results\nare restricted to phases of matter such as ground states of gapped Hamiltonians\nand Gibbs states that exhibit exponential decay of correlations. In this work,\nwe drop this requirement and show how it is possible to learn local expectation\nvalues for all states in a phase, where we adopt the Lindbladian phase\ndefinition by Coser \\& P\\'erez-Garc\\'ia [Coser \\& P\\'erez-Garc\\'ia, Quantum 3,\n174 (2019)], which defines states to be in the same phase if we can drive one\nto other rapidly with a local Lindbladian. This definition encompasses the\nbetter-known Hamiltonian definition of phase of matter for gapped ground state\nphases, and further applies to any family of states connected by short unitary\ncircuits, as well as non-equilibrium phases of matter, and those stable under\nexternal dissipative interactions. Under this definition, we show that $N =\nO(\\log(n/\\delta)2^{polylog(1/\\epsilon)})$ samples suffice to learn local\nexpectation values within a phase for a system with $n$ qubits, to error\n$\\epsilon$ with failure probability $\\delta$. This sample complexity is\ncomparable to previous results on learning gapped and thermal phases, and it\nencompasses previous results of this nature in a unified way. Furthermore, we\nalso show that we can learn families of states which go beyond the Lindbladian\ndefinition of phase, and we derive bounds on the sample complexity which are\ndependent on the mixing time between states under a Lindbladian evolution.",
            "author": [
                "Emilio Onorati",
                "Cambyse Rouz\u00e9",
                "Daniel Stilck Fran\u00e7a",
                "James D. Watson"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07506v1",
                "http://arxiv.org/pdf/2311.07506v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cond-mat.other",
                "cond-mat.str-el"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07505v1",
            "title": "What can we learn from diffusion about Anderson localization of a\n  degenerate Fermi gas?",
            "updated": "2023-11-13T17:46:08Z",
            "published": "2023-11-13T17:46:08Z",
            "summary": "Disorder can fundamentally modify the transport properties of a system. A\nstriking example is Anderson localization, suppressing transport due to\ndestructive interference of propagation paths. In inhomogeneous many-body\nsystems, not all particles are localized for finite-strength disorder, and the\nsystem can become partially diffusive. Unravelling the intricate signatures of\nlocalization from such observed diffusion is a long-standing problem. Here, we\nexperimentally study a degenerate, spin-polarized Fermi gas in a disorder\npotential formed by an optical speckle pattern. We record the diffusion in the\ndisordered potential upon release from an external confining potential. We\ncompare different methods to analyze the resulting density distributions,\nincluding a new method to capture particle dynamics by evaluating\nabsorption-image statistics. Using standard observables, such as diffusion\nexponent and coefficient, localized fraction, or localization length, we find\nthat some show signatures for a transition to localization above a critical\ndisorder strength, while others show a smooth crossover to a modified diffusion\nregime. In laterally displaced disorder, we spatially resolve different\ntransport regimes simultaneously which allows us to extract the subdiffusion\nexponent expected for weak localization. Our work emphasizes that the\ntransition toward localization can be investigated by closely analyzing the\nsystem's diffusion, offering ways of revealing localization effects beyond the\nsignature of exponentially decaying density distribution.",
            "author": [
                "Sian Barbosa",
                "Maximilian Kiefer-Emmanouilidis",
                "Felix Lang",
                "Jennifer Koch",
                "Artur Widera"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07505v1",
                "http://arxiv.org/pdf/2311.07505v1"
            ],
            "primary_category": "cond-mat.quant-gas",
            "category": [
                "cond-mat.quant-gas",
                "physics.atom-ph",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07504v1",
            "title": "STEM Rebalance: A Novel Approach for Tackling Imbalanced Datasets using\n  SMOTE, Edited Nearest Neighbour, and Mixup",
            "updated": "2023-11-13T17:45:28Z",
            "published": "2023-11-13T17:45:28Z",
            "summary": "Imbalanced datasets in medical imaging are characterized by skewed class\nproportions and scarcity of abnormal cases. When trained using such data,\nmodels tend to assign higher probabilities to normal cases, leading to biased\nperformance. Common oversampling techniques such as SMOTE rely on local\ninformation and can introduce marginalization issues. This paper investigates\nthe potential of using Mixup augmentation that combines two training examples\nalong with their corresponding labels to generate new data points as a generic\nvicinal distribution. To this end, we propose STEM, which combines SMOTE-ENN\nand Mixup at the instance level. This integration enables us to effectively\nleverage the entire distribution of minority classes, thereby mitigating both\nbetween-class and within-class imbalances. We focus on the breast cancer\nproblem, where imbalanced datasets are prevalent. The results demonstrate the\neffectiveness of STEM, which achieves AUC values of 0.96 and 0.99 in the\nDigital Database for Screening Mammography and Wisconsin Breast Cancer\n(Diagnostics) datasets, respectively. Moreover, this method shows promising\npotential when applied with an ensemble of machine learning (ML) classifiers.",
            "author": [
                "Yumnah Hasan",
                "Fatemeh Amerehi",
                "Patrick Healy",
                "Conor Ryan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07504v1",
                "http://arxiv.org/pdf/2311.07504v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07499v1",
            "title": "Bridging the Sim-to-Real Gap with Dynamic Compliance Tuning for\n  Industrial Insertion",
            "updated": "2023-11-13T17:40:34Z",
            "published": "2023-11-13T17:40:34Z",
            "summary": "Contact-rich manipulation tasks often exhibit a large sim-to-real gap. For\ninstance, industrial assembly tasks frequently involve tight insertions where\nthe clearance is less than \\(0.1\\) mm and can even be negative when dealing\nwith a deformable receptacle. This narrow clearance leads to complex contact\ndynamics that are difficult to model accurately in simulation, making it\nchallenging to transfer simulation-learned policies to real-world robots. In\nthis paper, we propose a novel framework for robustly learning manipulation\nskills for real-world tasks using only the simulated data. Our framework\nconsists of two main components: the ``Force Planner'' and the ``Gain Tuner''.\nThe Force Planner is responsible for planning both the robot motion and desired\ncontact forces, while the Gain Tuner dynamically adjusts the compliance control\ngains to accurately track the desired contact forces during task execution. The\nkey insight of this work is that by adaptively adjusting the robot's compliance\ncontrol gains during task execution, we can modulate contact forces in the new\nenvironment, thereby generating trajectories similar to those trained in\nsimulation and narrows the sim-to-real gap. Experimental results show that our\nmethod, trained in simulation on a generic square peg-and-hole task, can\ngeneralize to a variety of real-world insertion tasks involving narrow or even\nnegative clearances, all without requiring any fine-tuning.",
            "author": [
                "Xiang Zhang",
                "Masayoshi Tomizuka",
                "Hui Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07499v1",
                "http://arxiv.org/pdf/2311.07499v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07498v1",
            "title": "Reducing the Need for Backpropagation and Discovering Better Optima With\n  Explicit Optimizations of Neural Networks",
            "updated": "2023-11-13T17:38:07Z",
            "published": "2023-11-13T17:38:07Z",
            "summary": "Iterative differential approximation methods that rely upon backpropagation\nhave enabled the optimization of neural networks; however, at present, they\nremain computationally expensive, especially when training models at scale. In\nthis paper, we propose a computationally efficient alternative for optimizing\nneural networks that can both reduce the costs of scaling neural networks and\nprovide high-efficiency optimizations for low-resource applications. We derive\nan explicit solution to a simple feed-forward language model (LM) by\nmathematically analyzing its gradients. This solution generalizes from\nsingle-layer LMs to the class of all single-layer feed-forward\nsoftmax-activated neural models trained on positive-valued features, as is\ndemonstrated by our extension of this solution application to MNIST digit\nclassification. For both LM and digit classifiers, we find computationally that\nexplicit solutions perform near-optimality in experiments showing that 1)\niterative optimization only marginally improves the explicit solution\nparameters and 2) randomly initialized parameters iteratively optimize towards\nthe explicit solution. We also preliminarily apply the explicit solution\nlocally by layer in multi-layer networks and discuss how the solution's\ncomputational savings increase with model complexity -- for both single- and\nmult-layer applications of the explicit solution, we emphasize that the optima\nachieved cannot be reached by backpropagation alone, i.e., better optima appear\ndiscoverable only after explicit solutions are applied. Finally, we discuss the\nsolution's computational savings alongside its impact on model interpretability\nand suggest future directions for the derivation of explicit solutions to\ncomplex- and multi-layer architectures.",
            "author": [
                "Jake Ryland Williams",
                "Haoran Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07498v1",
                "http://arxiv.org/pdf/2311.07498v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.PR",
                "physics.data-an",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07497v1",
            "title": "Multilingual Nonce Dependency Treebanks: Understanding how LLMs\n  represent and process syntactic structure",
            "updated": "2023-11-13T17:36:58Z",
            "published": "2023-11-13T17:36:58Z",
            "summary": "We introduce SPUD (Semantically Perturbed Universal Dependencies), a\nframework for creating nonce treebanks for the multilingual Universal\nDependencies (UD) corpora. SPUD data satisfies syntactic argument structure,\nprovides syntactic annotations, and ensures grammaticality via\nlanguage-specific rules. We create nonce data in Arabic, English, French,\nGerman, and Russian, and demonstrate two use cases of SPUD treebanks. First, we\ninvestigate the effect of nonce data on word co-occurrence statistics, as\nmeasured by perplexity scores of autoregressive (ALM) and masked language\nmodels (MLM). We find that ALM scores are significantly more affected by nonce\ndata than MLM scores. Second, we show how nonce data affects the performance of\nsyntactic dependency probes. We replicate the findings of M\\\"uller-Eberstein et\nal. (2022) on nonce test data and show that the performance declines on both\nMLMs and ALMs wrt. original test data. However, a majority of the performance\nis kept, suggesting that the probe indeed learns syntax independently from\nsemantics.",
            "author": [
                "David Arps",
                "Laura Kallmeyer",
                "Younes Samih",
                "Hassan Sajjad"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07497v1",
                "http://arxiv.org/pdf/2311.07497v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07495v1",
            "title": "The Last Decade in Review: Tracing the Evolution of Safety Assurance\n  Cases through a Comprehensive Bibliometric Analysis",
            "updated": "2023-11-13T17:34:23Z",
            "published": "2023-11-13T17:34:23Z",
            "summary": "Safety assurance is of paramount importance across various domains, including\nautomotive, aerospace, and nuclear energy, where the reliability and\nacceptability of mission-critical systems are imperative. This assurance is\neffectively realized through the utilization of Safety Assurance Cases. The use\nof safety assurance cases allows for verifying the correctness of the created\nsystems capabilities, preventing system failure. The latter may result in loss\nof life, severe injuries, large-scale environmental damage, property\ndestruction, and major economic loss. Still, the emergence of complex\ntechnologies such as cyber-physical systems (CPSs), characterized by their\nheterogeneity, autonomy, machine learning capabilities, and the uncertainty of\ntheir operational environments poses significant challenges for safety\nassurance activities. Several papers have tried to propose solutions to tackle\nthese challenges, but to the best of our knowledge, no secondary study\ninvestigates the trends, patterns, and relationships characterizing the safety\ncase scientific literature. This makes it difficult to have a holistic view of\nthe safety case landscape and to identify the most promising future research\ndirections. In this paper, we, therefore, rely on state-of-the-art bibliometric\ntools(e.g., VosViewer) to conduct a bibliometric analysis that allows us to\ngenerate valuable insights, identify key authors and venues, and gain a birds\neye view of the current state of research in the safety assurance area. By\nrevealing knowledge gaps and highlighting potential avenues for future\nresearch, our analysis provides an essential foundation for researchers,\ncorporate safety analysts, and regulators seeking to embrace or enhance safety\npractices that align with their specific needs and objectives.",
            "author": [
                "Mithila Sivakumar",
                "Alvine Boaye Belle",
                "Jinjun Shan",
                "Opeyemi Adesina",
                "Song Wang",
                "Marsha Chechik",
                "Marios Fokaefs",
                "Kimya Khakzad Shahandashti",
                "Oluwafemi Odu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07495v1",
                "http://arxiv.org/pdf/2311.07495v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07485v1",
            "title": "EvoFed: Leveraging Evolutionary Strategies for Communication-Efficient\n  Federated Learning",
            "updated": "2023-11-13T17:25:06Z",
            "published": "2023-11-13T17:25:06Z",
            "summary": "Federated Learning (FL) is a decentralized machine learning paradigm that\nenables collaborative model training across dispersed nodes without having to\nforce individual nodes to share data. However, its broad adoption is hindered\nby the high communication costs of transmitting a large number of model\nparameters. This paper presents EvoFed, a novel approach that integrates\nEvolutionary Strategies (ES) with FL to address these challenges. EvoFed\nemploys a concept of 'fitness-based information sharing', deviating\nsignificantly from the conventional model-based FL. Rather than exchanging the\nactual updated model parameters, each node transmits a distance-based\nsimilarity measure between the locally updated model and each member of the\nnoise-perturbed model population. Each node, as well as the server, generates\nan identical population set of perturbed models in a completely synchronized\nfashion using the same random seeds. With properly chosen noise variance and\npopulation size, perturbed models can be combined to closely reflect the actual\nmodel updated using the local dataset, allowing the transmitted similarity\nmeasures (or fitness values) to carry nearly the complete information about the\nmodel parameters. As the population size is typically much smaller than the\nnumber of model parameters, the savings in communication load is large. The\nserver aggregates these fitness values and is able to update the global model.\nThis global fitness vector is then disseminated back to the nodes, each of\nwhich applies the same update to be synchronized to the global model. Our\nanalysis shows that EvoFed converges, and our experimental results validate\nthat at the cost of increased local processing loads, EvoFed achieves\nperformance comparable to FedAvg while reducing overall communication\nrequirements drastically in various practical settings.",
            "author": [
                "Mohammad Mahdi Rahimi",
                "Hasnain Irshad Bhatti",
                "Younghyun Park",
                "Humaira Kousar",
                "Jaekyun Moon"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07485v1",
                "http://arxiv.org/pdf/2311.07485v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07483v1",
            "title": "The galaxies missed by Hubble and ALMA: the contribution of extremely\n  red galaxies to the cosmic census at 3<z<8",
            "updated": "2023-11-13T17:17:45Z",
            "published": "2023-11-13T17:17:45Z",
            "summary": "Using deep JWST imaging from JADES, JEMS and SMILES, we characterize\noptically-faint and extremely red galaxies at $z>3$ that were previously\nmissing from galaxy census estimates. The data indicate the existence of\nabundant, dusty and post-starburst-like galaxies down to $10^8$M$_\\odot$, below\nthe sensitivity limit of Spitzer and ALMA. Modeling the NIRCam and HST\nphotometry of these red sources can result in extreme, high values for both\nstellar mass and star formation rate (SFR); however, including 7 MIRI filters\nout to 21$\\mu$m results in decreased mass (median 0.6 dex for\nlog$_{10}$M$^*$/M$_{\\odot}>$10), and SFR (median 10$\\times$ for SFR$>$100\nM$_{\\odot}$/yr). At $z>6$, our sample includes a high fraction of little red\ndots (LRDs; NIRCam-selected dust-reddened AGN candidates). We significantly\nmeasure older stellar populations in the LRDs out to rest-frame 3$\\mu$m (the\nstellar bump) and rule out a dominant contribution from hot dust emission, a\nsignature of AGN contamination to stellar population measurements. This allows\nus to measure their contribution to the cosmic census at $z>3$, below the\ntypical detection limits of ALMA ($L_{\\rm IR}<10^{12}L_\\odot$). We find that\nthese sources, which are overwhelmingly missed by HST and ALMA, could\neffectively double the obscured fraction of the star formation rate density at\n$4<z<6$ compared to some estimates, showing that prior to JWST, the obscured\ncontribution from fainter sources could be underestimated. Finally, we identify\nfive sources with evidence for Balmer breaks and high stellar masses at\n$5.5<z<7.7$. While spectroscopy is required to determine their nature, we\ndiscuss possible measurement systematics to explore with future data.",
            "author": [
                "Christina C. Williams",
                "Stacey Alberts",
                "Zhiyuan Ji",
                "Kevin N. Hainline",
                "Jianwei Lyu",
                "George Rieke",
                "Ryan Endsley",
                "Katherine A. Suess",
                "Benjamin D. Johnson",
                "Michael Florian",
                "Irene Shivaei",
                "Wiphu Rujopakarn",
                "William M. Baker",
                "Rachana Bhatawdekar",
                "Kristan Boyett",
                "Andrew J. Bunker",
                "Stefano Carniani",
                "Stephane Charlot",
                "Emma Curtis-Lake",
                "Christa DeCoursey",
                "Anna de Graaff",
                "Eiichi Egami",
                "Daniel J. Eisenstein",
                "Justus L. Gibson",
                "Ryan Hausen",
                "Jakob M. Helton",
                "Roberto Maiolino",
                "Michael V. Maseda",
                "Erica J. Nelson",
                "Pablo G. Perez-Gonzalez",
                "Marcia J. Rieke",
                "Brant E. Robertson",
                "Fengwu Sun",
                "Sandro Tacchella",
                "Christopher N. A. Willmer",
                "Chris J. Willott"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07483v1",
                "http://arxiv.org/pdf/2311.07483v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07479v1",
            "title": "Towards Robotic Tree Manipulation: Leveraging Graph Representations",
            "updated": "2023-11-13T17:13:13Z",
            "published": "2023-11-13T17:13:13Z",
            "summary": "There is growing interest in automating agricultural tasks that require\nintricate and precise interaction with specialty crops, such as trees and\nvines. However, developing robotic solutions for crop manipulation remains a\ndifficult challenge due to complexities involved in modeling their deformable\nbehavior. In this study, we present a framework for learning the deformation\nbehavior of tree-like crops under contact interaction. Our proposed method\ninvolves encoding the state of a spring-damper modeled tree crop as a graph.\nThis representation allows us to employ graph networks to learn both a forward\nmodel for predicting resulting deformations, and a contact policy for inferring\nactions to manipulate tree crops. We conduct a comprehensive set of experiments\nin a simulated environment and demonstrate generalizability of our method on\npreviously unseen trees. Videos can be found on the project website:\nhttps://kantor-lab.github.io/tree_gnn",
            "author": [
                "Chung Hee Kim",
                "Moonyoung Lee",
                "Oliver Kroemer",
                "George Kantor"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07479v1",
                "http://arxiv.org/pdf/2311.07479v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07477v1",
            "title": "Temporal Performance Prediction for Deep Convolutional Long Short-Term\n  Memory Networks",
            "updated": "2023-11-13T17:11:35Z",
            "published": "2023-11-13T17:11:35Z",
            "summary": "Quantifying predictive uncertainty of deep semantic segmentation networks is\nessential in safety-critical tasks. In applications like autonomous driving,\nwhere video data is available, convolutional long short-term memory networks\nare capable of not only providing semantic segmentations but also predicting\nthe segmentations of the next timesteps. These models use cell states to\nbroadcast information from previous data by taking a time series of inputs to\npredict one or even further steps into the future. We present a temporal\npostprocessing method which estimates the prediction performance of\nconvolutional long short-term memory networks by either predicting the\nintersection over union of predicted and ground truth segments or classifying\nbetween intersection over union being equal to zero or greater than zero. To\nthis end, we create temporal cell state-based input metrics per segment and\ninvestigate different models for the estimation of the predictive quality based\non these metrics. We further study the influence of the number of considered\ncell states for the proposed metrics.",
            "author": [
                "Laura Fieback",
                "Bidya Dash",
                "Jakob Spiegelberg",
                "Hanno Gottschalk"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07477v1",
                "http://arxiv.org/pdf/2311.07477v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "I.4"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07474v1",
            "title": "A Federated Data Fusion-Based Prognostic Model for Applications with\n  Multi-Stream Incomplete Signals",
            "updated": "2023-11-13T17:08:34Z",
            "published": "2023-11-13T17:08:34Z",
            "summary": "Most prognostic methods require a decent amount of data for model training.\nIn reality, however, the amount of historical data owned by a single\norganization might be small or not large enough to train a reliable prognostic\nmodel. To address this challenge, this article proposes a federated prognostic\nmodel that allows multiple users to jointly construct a failure time prediction\nmodel using their multi-stream, high-dimensional, and incomplete data while\nkeeping each user's data local and confidential. The prognostic model first\nemploys multivariate functional principal component analysis to fuse the\nmulti-stream degradation signals. Then, the fused features coupled with the\ntimes-to-failure are utilized to build a (log)-location-scale regression model\nfor failure prediction. To estimate parameters using distributed datasets and\nkeep the data privacy of all participants, we propose a new federated algorithm\nfor feature extraction. Numerical studies indicate that the performance of the\nproposed model is the same as that of classic non-federated prognostic models\nand is better than that of the models constructed by each user itself.",
            "author": [
                "Madi Arabi",
                "Xiaolei Fang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07474v1",
                "http://arxiv.org/pdf/2311.07474v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "eess.SP",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07468v2",
            "title": "Are We Falling in a Middle-Intelligence Trap? An Analysis and Mitigation\n  of the Reversal Curse",
            "updated": "2023-11-16T08:35:05Z",
            "published": "2023-11-13T17:01:12Z",
            "summary": "Recent studies have highlighted a phenomenon in large language models (LLMs)\nknown as \"the reversal curse,\" in which the order of knowledge entities in the\ntraining data biases the models' comprehension. For example, if a model is\ntrained on sentences where entity A consistently appears before entity B, it\ncan respond to queries about A by providing B as the answer. However, it may\nencounter confusion when presented with questions concerning B. We contend that\nthe reversal curse is partially a result of specific model training objectives,\nparticularly evident in the prevalent use of the next-token prediction within\nmost causal language models. For the next-token prediction, models solely focus\non a token's preceding context, resulting in a restricted comprehension of the\ninput. In contrast, we illustrate that the GLM, trained using the\nautoregressive blank infilling objective where tokens to be predicted have\naccess to the entire context, exhibits better resilience against the reversal\ncurse. We propose a novel training method, BIdirectional Casual language\nmodeling Optimization (BICO), designed to mitigate the reversal curse when\nfine-tuning pretrained causal language models on new data. BICO modifies the\ncausal attention mechanism to function bidirectionally and employs a mask\ndenoising optimization. In the task designed to assess the reversal curse, our\napproach improves Llama's accuracy from the original 0% to around 70%. We hope\nthat more attention can be focused on exploring and addressing these inherent\nweaknesses of the current LLMs, in order to achieve a higher level of\nintelligence.",
            "author": [
                "Ang Lv",
                "Kaiyi Zhang",
                "Shufang Xie",
                "Quan Tu",
                "Yuhan Chen",
                "Ji-Rong Wen",
                "Rui Yan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07468v2",
                "http://arxiv.org/pdf/2311.07468v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07466v1",
            "title": "On Measuring Faithfulness of Natural Language Explanations",
            "updated": "2023-11-13T16:53:51Z",
            "published": "2023-11-13T16:53:51Z",
            "summary": "Large language models (LLMs) can explain their own predictions, through\npost-hoc or Chain-of-Thought (CoT) explanations. However the LLM could make up\nreasonably sounding explanations that are unfaithful to its underlying\nreasoning. Recent work has designed tests that aim to judge the faithfulness of\neither post-hoc or CoT explanations. In this paper we argue that existing\nfaithfulness tests are not actually measuring faithfulness in terms of the\nmodels' inner workings, but only evaluate their self-consistency on the output\nlevel. The aims of our work are two-fold. i) We aim to clarify the status of\nexisting faithfulness tests in terms of model explainability, characterising\nthem as self-consistency tests instead. This assessment we underline by\nconstructing a Comparative Consistency Bank for self-consistency tests that for\nthe first time compares existing tests on a common suite of 11 open-source LLMs\nand 5 datasets -- including ii) our own proposed self-consistency measure\nCC-SHAP. CC-SHAP is a new fine-grained measure (not test) of LLM\nself-consistency that compares a model's input contributions to answer\nprediction and generated explanation. With CC-SHAP, we aim to take a step\nfurther towards measuring faithfulness with a more interpretable and\nfine-grained method. Code available at\n\\url{https://github.com/Heidelberg-NLP/CC-SHAP}",
            "author": [
                "Letitia Parcalabescu",
                "Anette Frank"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07466v1",
                "http://arxiv.org/pdf/2311.07466v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG",
                "68Txx",
                "I.2.7; I.2.10"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07465v1",
            "title": "Computerized Tomography and Reproducing Kernels",
            "updated": "2023-11-13T16:53:38Z",
            "published": "2023-11-13T16:53:38Z",
            "summary": "The X-ray transform is one of the most fundamental integral operators in\nimage processing and reconstruction. In this article, we revisit its\nmathematical formalism, and propose an innovative approach making use of\nReproducing Kernel Hilbert Spaces (RKHS). Within this framework, the X-ray\ntransform can be considered as a natural analogue of Euclidean projections. The\nRKHS framework considerably simplifies projection image interpolation, and\nleads to an analogue of the celebrated representer theorem for the problem of\ntomographic reconstruction. It leads to methodology that is dimension-free and\nstands apart from conventional filtered back-projection techniques, as it does\nnot hinge on the Fourier transform. It also allows us to establish sharp\nstability results at a genuinely functional level, but in the realistic setting\nwhere the data are discrete and noisy. The RKHS framework is amenable to any\nreproducing kernel on a unit ball, affording a high level of generality. When\nthe kernel is chosen to be rotation-invariant, one can obtain explicit spectral\nrepresentations which elucidate the regularity structure of the associated\nHilbert spaces, and one can also solve the reconstruction problem at the same\ncomputational cost as filtered back-projection.",
            "author": [
                "Ho Yun",
                "Victor M. Panaretos"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07465v1",
                "http://arxiv.org/pdf/2311.07465v1"
            ],
            "primary_category": "math.FA",
            "category": [
                "math.FA",
                "math.ST",
                "stat.ML",
                "stat.TH",
                "44A12 (Primary), 46E22 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07462v1",
            "title": "Investigating Robustness in Cyber-Physical Systems:\n  Specification-Centric Analysis in the face of System Deviations",
            "updated": "2023-11-13T16:44:43Z",
            "published": "2023-11-13T16:44:43Z",
            "summary": "The adoption of cyber-physical systems (CPS) is on the rise in complex\nphysical environments, encompassing domains such as autonomous vehicles, the\nInternet of Things (IoT), and smart cities. A critical attribute of CPS is\nrobustness, denoting its capacity to operate safely despite potential\ndisruptions and uncertainties in the operating environment. This paper proposes\na novel specification-based robustness, which characterizes the effectiveness\nof a controller in meeting a specified system requirement, articulated through\nSignal Temporal Logic (STL) while accounting for possible deviations in the\nsystem. This paper also proposes the robustness falsification problem based on\nthe definition, which involves identifying minor deviations capable of\nviolating the specified requirement. We present an innovative two-layer\nsimulation-based analysis framework designed to identify subtle robustness\nviolations. To assess our methodology, we devise a series of benchmark problems\nwherein system parameters can be adjusted to emulate various forms of\nuncertainties and disturbances. Initial evaluations indicate that our\nfalsification approach proficiently identifies robustness violations, providing\nvaluable insights for comparing robustness between conventional and\nreinforcement learning (RL)-based controllers",
            "author": [
                "Changjian Zhang",
                "Parv Kapoor",
                "Romulo Meira-Goes",
                "David Garlan",
                "Eunsuk Kang",
                "Akila Ganlath",
                "Shatadal Mishra",
                "Nejib Ammar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07462v1",
                "http://arxiv.org/pdf/2311.07462v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.LO",
                "cs.SE",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07461v1",
            "title": "On Self-Supervised Dynamic Incremental Regularised Adaptation",
            "updated": "2023-11-13T16:44:29Z",
            "published": "2023-11-13T16:44:29Z",
            "summary": "In this paper, we overview a recent method for dynamic domain adaptation\nnamed DIRA, which relies on a few samples in addition to a regularisation\napproach named elastic weight consolidation to achieve state-of-the-art (SOTA)\ndomain adaptation results. DIRA has been previously shown to perform\ncompetitively with SOTA unsupervised adaption techniques. However, a limitation\nof DIRA is that it relies on labels to be provided for the few samples used in\nadaption. This makes it a supervised technique. In this paper, we discuss a\nproposed alteration to the DIRA method to make it self-supervised i.e. remove\nthe need for providing labels. Experiments on our proposed alteration will be\nprovided in future work.",
            "author": [
                "Abanoub Ghobrial",
                "Kerstin Eder"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07461v1",
                "http://arxiv.org/pdf/2311.07461v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07460v1",
            "title": "KnowSafe: Combined Knowledge and Data Driven Hazard Mitigation in\n  Artificial Pancreas Systems",
            "updated": "2023-11-13T16:43:34Z",
            "published": "2023-11-13T16:43:34Z",
            "summary": "Significant progress has been made in anomaly detection and run-time\nmonitoring to improve the safety and security of cyber-physical systems (CPS).\nHowever, less attention has been paid to hazard mitigation. This paper proposes\na combined knowledge and data driven approach, KnowSafe, for the design of\nsafety engines that can predict and mitigate safety hazards resulting from\nsafety-critical malicious attacks or accidental faults targeting a CPS\ncontroller. We integrate domain-specific knowledge of safety constraints and\ncontext-specific mitigation actions with machine learning (ML) techniques to\nestimate system trajectories in the far and near future, infer potential\nhazards, and generate optimal corrective actions to keep the system safe.\nExperimental evaluation on two realistic closed-loop testbeds for artificial\npancreas systems (APS) and a real-world clinical trial dataset for diabetes\ntreatment demonstrates that KnowSafe outperforms the state-of-the-art by\nachieving higher accuracy in predicting system state trajectories and potential\nhazards, a low false positive rate, and no false negatives. It also maintains\nthe safe operation of the simulated APS despite faults or attacks without\nintroducing any new hazards, with a hazard mitigation success rate of 92.8%,\nwhich is at least 76% higher than solely rule-based (50.9%) and data-driven\n(52.7%) methods.",
            "author": [
                "Xugui Zhou",
                "Maxfield Kouzel",
                "Chloe Smith",
                "Homa Alemzadeh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07460v1",
                "http://arxiv.org/pdf/2311.07460v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07454v1",
            "title": "Causal Discovery under Latent Class Confounding",
            "updated": "2023-11-13T16:35:34Z",
            "published": "2023-11-13T16:35:34Z",
            "summary": "Directed acyclic graphs are used to model the causal structure of a system.\n``Causal discovery'' describes the problem of learning this structure from\ndata. When data is an aggregate from multiple sources (populations or\nenvironments), global confounding obscures conditional independence properties\nthat drive many causal discovery algorithms. For this reason, existing causal\ndiscovery algorithms are not suitable for the multiple-source setting. We\ndemonstrate that, if the confounding is of bounded cardinality (i.e. the data\ncomes from a limited number of sources), causal discovery can still be\nachieved. The feasibility of this problem is governed by a trade-off between\nthe cardinality of the global confounder, the cardinalities of the observed\nvariables, and the sparsity of the causal structure.",
            "author": [
                "Bijan Mazaheri",
                "Spencer Gordon",
                "Yuval Rabani",
                "Leonard Schulman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07454v1",
                "http://arxiv.org/pdf/2311.07454v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CC",
                "math.ST",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07452v1",
            "title": "Explainable Boosting Machines with Sparsity -- Maintaining\n  Explainability in High-Dimensional Settings",
            "updated": "2023-11-13T16:34:59Z",
            "published": "2023-11-13T16:34:59Z",
            "summary": "Compared to \"black-box\" models, like random forests and deep neural networks,\nexplainable boosting machines (EBMs) are considered \"glass-box\" models that can\nbe competitively accurate while also maintaining a higher degree of\ntransparency and explainability. However, EBMs become readily less transparent\nand harder to interpret in high-dimensional settings with many predictor\nvariables; they also become more difficult to use in production due to\nincreases in scoring time. We propose a simple solution based on the least\nabsolute shrinkage and selection operator (LASSO) that can help introduce\nsparsity by reweighting the individual model terms and removing the less\nrelevant ones, thereby allowing these models to maintain their transparency and\nrelatively fast scoring times in higher-dimensional settings. In short,\npost-processing a fitted EBM with many (i.e., possibly hundreds or thousands)\nof terms using the LASSO can help reduce the model's complexity and drastically\nimprove scoring time. We illustrate the basic idea using two real-world\nexamples with code.",
            "author": [
                "Brandon M. Greenwell",
                "Annika Dahlmann",
                "Saurabh Dhoble"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07452v1",
                "http://arxiv.org/pdf/2311.07452v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07449v1",
            "title": "Language Grounded QFormer for Efficient Vision Language Understanding",
            "updated": "2023-11-13T16:30:49Z",
            "published": "2023-11-13T16:30:49Z",
            "summary": "Large-scale pretraining and instruction tuning have been successful for\ntraining general-purpose language models with broad competencies. However,\nextending to general-purpose vision-language models is challenging due to the\ndistributional diversity in visual inputs. A recent line of work explores\nvision-language instruction tuning, taking inspiration from the Query\nTransformer (QFormer) approach proposed in BLIP-2 models for bridging frozen\nmodalities. However, these approaches rely heavily on large-scale multi-modal\npretraining for representation learning before eventual finetuning, incurring a\nhuge computational overhead, poor scaling, and limited accessibility. To that\nend, we propose a more efficient method for QFormer-based vision-language\nalignment and demonstrate the effectiveness of our strategy compared to\nexisting baselines in improving the efficiency of vision-language pretraining.",
            "author": [
                "Moulik Choraria",
                "Nitesh Sekhar",
                "Yue Wu",
                "Xu Zhang",
                "Prateek Singhal",
                "Lav R. Varshney"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07449v1",
                "http://arxiv.org/pdf/2311.07449v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14707v1",
            "title": "Knowledge Tracing Challenge: Optimal Activity Sequencing for Students",
            "updated": "2023-11-13T16:28:34Z",
            "published": "2023-11-13T16:28:34Z",
            "summary": "Knowledge tracing is a method used in education to assess and track the\nacquisition of knowledge by individual learners. It involves using a variety of\ntechniques, such as quizzes, tests, and other forms of assessment, to determine\nwhat a learner knows and does not know about a particular subject. The goal of\nknowledge tracing is to identify gaps in understanding and provide targeted\ninstruction to help learners improve their understanding and retention of\nmaterial. This can be particularly useful in situations where learners are\nworking at their own pace, such as in online learning environments. By\nproviding regular feedback and adjusting instruction based on individual needs,\nknowledge tracing can help learners make more efficient progress and achieve\nbetter outcomes. Effectively solving the KT problem would unlock the potential\nof computer-aided education applications such as intelligent tutoring systems,\ncurriculum learning, and learning materials recommendations. In this paper, we\nwill present the results of the implementation of two Knowledge Tracing\nalgorithms on a newly released dataset as part of the AAAI2023 Global Knowledge\nTracing Challenge.",
            "author": [
                "Yann Hicke"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14707v1",
                "http://arxiv.org/pdf/2311.14707v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07445v1",
            "title": "Think Before You Speak: Cultivating Communication Skills of Large\n  Language Models via Inner Monologue",
            "updated": "2023-11-13T16:19:42Z",
            "published": "2023-11-13T16:19:42Z",
            "summary": "The emergence of large language models (LLMs) further improves the\ncapabilities of open-domain dialogue systems and can generate fluent, coherent,\nand diverse responses. However, LLMs still lack an important ability:\ncommunication skills, which makes them more like information seeking tools than\nanthropomorphic chatbots. To make LLMs more anthropomorphic and proactive\nduring the conversation, we add five communication skills to the response\ngeneration process: topic transition, proactively asking questions, concept\nguidance, empathy, and summarising often. The addition of communication skills\nincreases the interest of users in the conversation and attracts them to chat\nfor longer. To enable LLMs better understand and use communication skills, we\ndesign and add the inner monologue to LLMs. The complete process is achieved\nthrough prompt engineering and in-context learning. To evaluate communication\nskills, we construct a benchmark named Cskills for evaluating various\ncommunication skills, which can also more comprehensively evaluate the dialogue\ngeneration ability of the model. Experimental results show that the proposed\nCSIM strategy improves the backbone models and outperforms the baselines in\nboth automatic and human evaluations.",
            "author": [
                "Junkai Zhou",
                "Liang Pang",
                "Huawei Shen",
                "Xueqi Cheng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07445v1",
                "http://arxiv.org/pdf/2311.07445v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07444v1",
            "title": "On the Robustness of Neural Collapse and the Neural Collapse of\n  Robustness",
            "updated": "2023-11-13T16:18:58Z",
            "published": "2023-11-13T16:18:58Z",
            "summary": "Neural Collapse refers to the curious phenomenon in the end of training of a\nneural network, where feature vectors and classification weights converge to a\nvery simple geometrical arrangement (a simplex). While it has been observed\nempirically in various cases and has been theoretically motivated, its\nconnection with crucial properties of neural networks, like their\ngeneralization and robustness, remains unclear. In this work, we study the\nstability properties of these simplices. We find that the simplex structure\ndisappears under small adversarial attacks, and that perturbed examples \"leap\"\nbetween simplex vertices. We further analyze the geometry of networks that are\noptimized to be robust against adversarial perturbations of the input, and find\nthat Neural Collapse is a pervasive phenomenon in these cases as well, with\nclean and perturbed representations forming aligned simplices, and giving rise\nto a robust simple nearest-neighbor classifier. By studying the propagation of\nthe amount of collapse inside the network, we identify novel properties of both\nrobust and non-robust machine learning models, and show that earlier, unlike\nlater layers maintain reliable simplices on perturbed data.",
            "author": [
                "Jingtong Su",
                "Ya Shi Zhang",
                "Nikolaos Tsilivis",
                "Julia Kempe"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07444v1",
                "http://arxiv.org/pdf/2311.07444v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07439v2",
            "title": "Investigating Multi-Pivot Ensembling with Massively Multilingual Machine\n  Translation Models",
            "updated": "2023-11-14T14:01:46Z",
            "published": "2023-11-13T16:15:20Z",
            "summary": "Massively multilingual machine translation models allow for the translation\nof a large number of languages with a single model, but have limited\nperformance on low- and very-low-resource translation directions. Pivoting via\nhigh-resource languages remains a strong strategy for low-resource directions,\nand in this paper we revisit ways of pivoting through multiple languages.\nPrevious work has used a simple averaging of probability distributions from\nmultiple paths, but we find that this performs worse than using a single pivot,\nand exacerbates the hallucination problem because the same hallucinations can\nbe probable across different paths. As an alternative, we propose MaxEns, a\ncombination strategy that is biased towards the most confident predictions,\nhypothesising that confident predictions are less prone to be hallucinations.\nWe evaluate different strategies on the FLORES benchmark for 20 low-resource\nlanguage directions, demonstrating that MaxEns improves translation quality for\nlow-resource languages while reducing hallucination in translations, compared\nto both direct translation and an averaging approach. On average, multi-pivot\nstrategies still lag behind using English as a single pivot language, raising\nthe question of how to identify the best pivoting strategy for a given\ntranslation direction.",
            "author": [
                "Alireza Mohammadshahi",
                "Jannis Vamvas",
                "Rico Sennrich"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07439v2",
                "http://arxiv.org/pdf/2311.07439v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07432v1",
            "title": "Supersampling of Data from Structured-light Scanner with Deep Learning",
            "updated": "2023-11-13T16:04:41Z",
            "published": "2023-11-13T16:04:41Z",
            "summary": "This paper focuses on increasing the resolution of depth maps obtained from\n3D cameras using structured light technology. Two deep learning models FDSR and\nDKN are modified to work with high-resolution data, and data pre-processing\ntechniques are implemented for stable training. The models are trained on our\ncustom dataset of 1200 3D scans. The resulting high-resolution depth maps are\nevaluated using qualitative and quantitative metrics. The approach for depth\nmap upsampling offers benefits such as reducing the processing time of a\npipeline by first downsampling a high-resolution depth map, performing various\nprocessing steps at the lower resolution and upsampling the resulting depth map\nor increasing the resolution of a point cloud captured in lower resolution by a\ncheaper device. The experiments demonstrate that the FDSR model excels in terms\nof faster processing time, making it a suitable choice for applications where\nspeed is crucial. On the other hand, the DKN model provides results with higher\nprecision, making it more suitable for applications that prioritize accuracy.",
            "author": [
                "Martin Melicher\u010d\u00edk",
                "Luk\u00e1\u0161 Gajdo\u0161ech",
                "Viktor Kocur",
                "Martin Madaras"
            ],
            "link": [
                "http://dx.doi.org/10.1109/DISA59116.2023.10308923",
                "http://arxiv.org/abs/2311.07432v1",
                "http://arxiv.org/pdf/2311.07432v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07427v1",
            "title": "Boolean Variation and Boolean Logic BackPropagation",
            "updated": "2023-11-13T16:01:43Z",
            "published": "2023-11-13T16:01:43Z",
            "summary": "The notion of variation is introduced for the Boolean set and based on which\nBoolean logic backpropagation principle is developed. Using this concept, deep\nmodels can be built with weights and activations being Boolean numbers and\noperated with Boolean logic instead of real arithmetic. In particular, Boolean\ndeep models can be trained directly in the Boolean domain without latent\nweights. No gradient but logic is synthesized and backpropagated through\nlayers.",
            "author": [
                "Van Minh Nguyen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07427v1",
                "http://arxiv.org/pdf/2311.07427v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DM",
                "cs.LO",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07426v1",
            "title": "Optimising Human-AI Collaboration by Learning Convincing Explanations",
            "updated": "2023-11-13T16:00:16Z",
            "published": "2023-11-13T16:00:16Z",
            "summary": "Machine learning models are being increasingly deployed to take, or assist in\ntaking, complicated and high-impact decisions, from quasi-autonomous vehicles\nto clinical decision support systems. This poses challenges, particularly when\nmodels have hard-to-detect failure modes and are able to take actions without\noversight. In order to handle this challenge, we propose a method for a\ncollaborative system that remains safe by having a human ultimately making\ndecisions, while giving the model the best opportunity to convince and debate\nthem with interpretable explanations. However, the most helpful explanation\nvaries among individuals and may be inconsistent across stated preferences. To\nthis end we develop an algorithm, Ardent, to efficiently learn a ranking\nthrough interaction and best assist humans complete a task. By utilising a\ncollaborative approach, we can ensure safety and improve performance while\naddressing transparency and accountability concerns. Ardent enables efficient\nand effective decision-making by adapting to individual preferences for\nexplanations, which we validate through extensive simulations alongside a user\nstudy involving a challenging image classification task, demonstrating\nconsistent improvement over competing systems.",
            "author": [
                "Alex J. Chan",
                "Alihan Huyuk",
                "Mihaela van der Schaar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07426v1",
                "http://arxiv.org/pdf/2311.07426v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07421v1",
            "title": "Robust semi-supervised segmentation with timestep ensembling diffusion\n  models",
            "updated": "2023-11-13T15:57:17Z",
            "published": "2023-11-13T15:57:17Z",
            "summary": "Medical image segmentation is a challenging task, made more difficult by many\ndatasets' limited size and annotations. Denoising diffusion probabilistic\nmodels (DDPM) have recently shown promise in modelling the distribution of\nnatural images and were successfully applied to various medical imaging tasks.\nThis work focuses on semi-supervised image segmentation using diffusion models,\nparticularly addressing domain generalisation. Firstly, we demonstrate that\nsmaller diffusion steps generate latent representations that are more robust\nfor downstream tasks than larger steps. Secondly, we use this insight to\npropose an improved esembling scheme that leverages information-dense small\nsteps and the regularising effect of larger steps to generate predictions. Our\nmodel shows significantly better performance in domain-shifted settings while\nretaining competitive performance in-domain. Overall, this work highlights the\npotential of DDPMs for semi-supervised medical image segmentation and provides\ninsights into optimising their performance under domain shift.",
            "author": [
                "Margherita Rosnati",
                "Melanie Roschewitz",
                "Ben Glocker"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07421v1",
                "http://arxiv.org/pdf/2311.07421v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07418v1",
            "title": "Speech-based Slot Filling using Large Language Models",
            "updated": "2023-11-13T15:54:30Z",
            "published": "2023-11-13T15:54:30Z",
            "summary": "Recently, advancements in large language models (LLMs) have shown an\nunprecedented ability across various language tasks. This paper investigates\nthe potential application of LLMs to slot filling with noisy ASR\ntranscriptions, via both in-context learning and task-specific fine-tuning.\nDedicated prompt designs and fine-tuning approaches are proposed to improve the\nrobustness of LLMs for slot filling with noisy ASR transcriptions. Moreover, a\nlinearised knowledge injection (LKI) scheme is also proposed to integrate\ndynamic external knowledge into LLMs. Experiments were performed on SLURP to\nquantify the performance of LLMs, including GPT-3.5-turbo, GPT-4, LLaMA-13B and\nVicuna-13B (v1.1 and v1.5) with different ASR error rates. The use of the\nproposed fine-tuning together with the LKI scheme for LLaMA-13B achieved an\n8.3% absolute SLU-F1 improvement compared to the strong Flan-T5-base baseline\nsystem on a limited data setup.",
            "author": [
                "Guangzhi Sun",
                "Shutong Feng",
                "Dongcheng Jiang",
                "Chao Zhang",
                "Milica Ga\u0161i\u0107",
                "Philip C. Woodland"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07418v1",
                "http://arxiv.org/pdf/2311.07418v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07417v1",
            "title": "Mitigating Backdoors within Deep Neural Networks in Data-limited\n  Configuration",
            "updated": "2023-11-13T15:54:27Z",
            "published": "2023-11-13T15:54:27Z",
            "summary": "As the capacity of deep neural networks (DNNs) increases, their need for huge\namounts of data significantly grows. A common practice is to outsource the\ntraining process or collect more data over the Internet, which introduces the\nrisks of a backdoored DNN. A backdoored DNN shows normal behavior on clean data\nwhile behaving maliciously once a trigger is injected into a sample at the test\ntime. In such cases, the defender faces multiple difficulties. First, the\navailable clean dataset may not be sufficient for fine-tuning and recovering\nthe backdoored DNN. Second, it is impossible to recover the trigger in many\nreal-world applications without information about it. In this paper, we\nformulate some characteristics of poisoned neurons. This backdoor\nsuspiciousness score can rank network neurons according to their activation\nvalues, weights, and their relationship with other neurons in the same layer.\nOur experiments indicate the proposed method decreases the chance of attacks\nbeing successful by more than 50% with a tiny clean dataset, i.e., ten clean\nsamples for the CIFAR-10 dataset, without significantly deteriorating the\nmodel's performance. Moreover, the proposed method runs three times as fast as\nbaselines.",
            "author": [
                "Soroush Hashemifar",
                "Saeed Parsa",
                "Morteza Zakeri-Nasrabadi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07417v1",
                "http://arxiv.org/pdf/2311.07417v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR",
                "cs.CV",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07416v1",
            "title": "Three-dimensional granular flow simulation using graph neural\n  network-based learned simulator",
            "updated": "2023-11-13T15:54:09Z",
            "published": "2023-11-13T15:54:09Z",
            "summary": "Reliable evaluations of geotechnical hazards like landslides and debris flow\nrequire accurate simulation of granular flow dynamics. Traditional numerical\nmethods can simulate the complex behaviors of such flows that involve\nsolid-like to fluid-like transitions, but they are computationally intractable\nwhen simulating large-scale systems. Surrogate models based on statistical or\nmachine learning methods are a viable alternative, but they are typically\nempirical and rely on a confined set of parameters in evaluating associated\nrisks. Due to their permutation-dependent learning, conventional machine\nlearning models require an unreasonably large amount of training data for\nbuilding generalizable surrogate models. We employ a graph neural network\n(GNN), a novel deep learning technique, to develop a GNN-based simulator (GNS)\nfor granular flows to address these issues. Graphs represent the state of\ngranular flows and interactions, like the exchange of energy and momentum\nbetween grains, and GNN learns the local interaction law. GNS takes the current\nstate of the granular flow and estimates the next state using Euler explicit\nintegration. We train GNS on a limited set of granular flow trajectories and\nevaluate its performance in a three-dimensional granular column collapse\ndomain. GNS successfully reproduces the overall behaviors of column collapses\nwith various aspect ratios that were not encountered during training. The\ncomputation speed of GNS outperforms high-fidelity numerical simulators by 300\ntimes.",
            "author": [
                "Yongjin Choi",
                "Krishna Kumar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07416v1",
                "http://arxiv.org/pdf/2311.07416v1"
            ],
            "primary_category": "physics.geo-ph",
            "category": [
                "physics.geo-ph",
                "cs.LG",
                "I.6.8"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07411v1",
            "title": "A Large Deviations Perspective on Policy Gradient Algorithms",
            "updated": "2023-11-13T15:44:27Z",
            "published": "2023-11-13T15:44:27Z",
            "summary": "We derive the first large deviation rate function for the stochastic iterates\ngenerated by policy gradient methods with a softmax parametrization and an\nentropy regularized objective. Leveraging the contraction principle from large\ndeviations theory, we also develop a general recipe for deriving exponential\nconvergence rates for a wide spectrum of other policy parametrizations. This\napproach unifies several results from the literature and simplifies existing\nproof techniques.",
            "author": [
                "Wouter Jongeneel",
                "Mengmeng Li",
                "Daniel Kuhn"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07411v1",
                "http://arxiv.org/pdf/2311.07411v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "stat.ML",
                "60F10, 90C26"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07407v1",
            "title": "Towards Automatic Honey Bee Flower-Patch Assays with Paint Marking\n  Re-Identification",
            "updated": "2023-11-13T15:41:25Z",
            "published": "2023-11-13T15:41:25Z",
            "summary": "In this paper, we show that paint markings are a feasible approach to\nautomatize the analysis of behavioral assays involving honey bees in the field\nwhere marking has to be as lightweight as possible. We contribute a novel\ndataset for bees re-identification with paint-markings with 4392 images and 27\nidentities. Contrastive learning with a ResNet backbone and triplet loss led to\nidentity representation features with almost perfect recognition in closed\nsetting where identities are known in advance. Diverse experiments evaluate the\ncapability to generalize to separate IDs, and show the impact of using\ndifferent body parts for identification, such as using the unmarked abdomen\nonly. In addition, we show the potential to fully automate the visit detection\nand provide preliminary results of compute time for future real-time deployment\nin the field on an edge device.",
            "author": [
                "Luke Meyers",
                "Josu\u00e9 Rodr\u00edguez Cordero",
                "Carlos Corrada Bravo",
                "Fanfan Noel",
                "Jos\u00e9 Agosto-Rivera",
                "Tugrul Giray",
                "R\u00e9mi M\u00e9gret"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07407v1",
                "http://arxiv.org/pdf/2311.07407v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "I.4.8; I.4.9; J.3"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07399v1",
            "title": "Context-Aware Adaptive Prefetching for DASH Streaming over 5G Networks",
            "updated": "2023-11-13T15:27:23Z",
            "published": "2023-11-13T15:27:23Z",
            "summary": "The increasing consumption of video streams and the demand for higher-quality\ncontent drive the evolution of telecommunication networks and the development\nof new network accelerators to boost media delivery while optimizing network\nusage. Multi-access Edge Computing (MEC) enables the possibility to enforce\nmedia delivery by deploying caching instances at the network edge, close to the\nRadio Access Network (RAN). Thus, the content can be prefetched and served from\nthe MEC host, reducing network traffic and increasing the Quality of Service\n(QoS) and the Quality of Experience (QoE). This paper proposes a novel\nmechanism to prefetch Dynamic Adaptive Streaming over HTTP (DASH) streams at\nthe MEC, employing a Machine Learning (ML) classification model to select the\nmedia segments to prefetch. The model is trained with media session metrics to\nimprove the forecasts with application layer information. The proposal is\ntested with Mobile Network Operators (MNOs)' 5G MEC and RAN and compared with\nother strategies by assessing cache and player's performance metrics.",
            "author": [
                "Juncal Uriol",
                "Inhar Yeregui",
                "Alvaro Gabilondo",
                "Roberto Viola",
                "Pablo Angueira",
                "Jon Montalban"
            ],
            "link": [
                "http://dx.doi.org/10.1109/BMSB58369.2023.10211275",
                "http://arxiv.org/abs/2311.07399v1",
                "http://arxiv.org/pdf/2311.07399v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07398v1",
            "title": "Processing and Segmentation of Human Teeth from 2D Images using Weakly\n  Supervised Learning",
            "updated": "2023-11-13T15:25:55Z",
            "published": "2023-11-13T15:25:55Z",
            "summary": "Teeth segmentation is an essential task in dental image analysis for accurate\ndiagnosis and treatment planning. While supervised deep learning methods can be\nutilized for teeth segmentation, they often require extensive manual annotation\nof segmentation masks, which is time-consuming and costly. In this research, we\npropose a weakly supervised approach for teeth segmentation that reduces the\nneed for manual annotation. Our method utilizes the output heatmaps and\nintermediate feature maps from a keypoint detection network to guide the\nsegmentation process. We introduce the TriDental dataset, consisting of 3000\noral cavity images annotated with teeth keypoints, to train a teeth keypoint\ndetection network. We combine feature maps from different layers of the\nkeypoint detection network, enabling accurate teeth segmentation without\nexplicit segmentation annotations. The detected keypoints are also used for\nfurther refinement of the segmentation masks. Experimental results on the\nTriDental dataset demonstrate the superiority of our approach in terms of\naccuracy and robustness compared to state-of-the-art segmentation methods. Our\nmethod offers a cost-effective and efficient solution for teeth segmentation in\nreal-world dental applications, eliminating the need for extensive manual\nannotation efforts.",
            "author": [
                "Tom\u00e1\u0161 Kunzo",
                "Viktor Kocur",
                "Luk\u00e1\u0161 Gajdo\u0161ech",
                "Martin Madaras"
            ],
            "link": [
                "http://dx.doi.org/10.1109/DISA59116.2023.10308924",
                "http://arxiv.org/abs/2311.07398v1",
                "http://arxiv.org/pdf/2311.07398v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07395v1",
            "title": "Predicting Continuous Locomotion Modes via Multidimensional Feature\n  Learning from sEMG",
            "updated": "2023-11-13T15:23:26Z",
            "published": "2023-11-13T15:23:26Z",
            "summary": "Walking-assistive devices require adaptive control methods to ensure smooth\ntransitions between various modes of locomotion. For this purpose, detecting\nhuman locomotion modes (e.g., level walking or stair ascent) in advance is\ncrucial for improving the intelligence and transparency of such robotic\nsystems. This study proposes Deep-STF, a unified end-to-end deep learning model\ndesigned for integrated feature extraction in spatial, temporal, and frequency\ndimensions from surface electromyography (sEMG) signals. Our model enables\naccurate and robust continuous prediction of nine locomotion modes and 15\ntransitions at varying prediction time intervals, ranging from 100 to 500 ms.\nIn addition, we introduced the concept of 'stable prediction time' as a\ndistinct metric to quantify prediction efficiency. This term refers to the\nduration during which consistent and accurate predictions of mode transitions\nare made, measured from the time of the fifth correct prediction to the\noccurrence of the critical event leading to the task transition. This\ndistinction between stable prediction time and prediction time is vital as it\nunderscores our focus on the precision and reliability of mode transition\npredictions. Experimental results showcased Deep-STP's cutting-edge prediction\nperformance across diverse locomotion modes and transitions, relying solely on\nsEMG data. When forecasting 100 ms ahead, Deep-STF surpassed CNN and other\nmachine learning techniques, achieving an outstanding average prediction\naccuracy of 96.48%. Even with an extended 500 ms prediction horizon, accuracy\nonly marginally decreased to 93.00%. The averaged stable prediction times for\ndetecting next upcoming transitions spanned from 28.15 to 372.21 ms across the\n100-500 ms time advances.",
            "author": [
                "Peiwen Fu",
                "Wenjuan Zhong",
                "Yuyang Zhang",
                "Wenxuan Xiong",
                "Yuzhou Lin",
                "Yanlong Tai",
                "Lin Meng",
                "Mingming Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07395v1",
                "http://arxiv.org/pdf/2311.07395v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07636v2",
            "title": "Attention-based Multi-task Learning for Base Editor Outcome Prediction",
            "updated": "2023-11-15T16:06:36Z",
            "published": "2023-11-13T15:16:24Z",
            "summary": "Human genetic diseases often arise from point mutations, emphasizing the\ncritical need for precise genome editing techniques. Among these, base editing\nstands out as it allows targeted alterations at the single nucleotide level.\nHowever, its clinical application is hindered by low editing efficiency and\nunintended mutations, necessitating extensive trial-and-error experimentation\nin the laboratory. To speed up this process, we present an attention-based\ntwo-stage machine learning model that learns to predict the likelihood of all\npossible editing outcomes for a given genomic target sequence. We further\npropose a multi-task learning schema to jointly learn multiple base editors\n(i.e. variants) at once. Our model's predictions consistently demonstrated a\nstrong correlation with the actual experimental results on multiple datasets\nand base editor variants. These results provide further validation for the\nmodels' capacity to enhance and accelerate the process of refining base editing\ndesigns.",
            "author": [
                "Amina Mollaysa",
                "Ahmed Allam",
                "Michael Krauthammer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07636v2",
                "http://arxiv.org/pdf/2311.07636v2"
            ],
            "primary_category": "q-bio.GN",
            "category": [
                "q-bio.GN",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07389v1",
            "title": "Transpose Attack: Stealing Datasets with Bidirectional Training",
            "updated": "2023-11-13T15:14:50Z",
            "published": "2023-11-13T15:14:50Z",
            "summary": "Deep neural networks are normally executed in the forward direction. However,\nin this work, we identify a vulnerability that enables models to be trained in\nboth directions and on different tasks. Adversaries can exploit this capability\nto hide rogue models within seemingly legitimate models. In addition, in this\nwork we show that neural networks can be taught to systematically memorize and\nretrieve specific samples from datasets. Together, these findings expose a\nnovel method in which adversaries can exfiltrate datasets from protected\nlearning environments under the guise of legitimate models. We focus on the\ndata exfiltration attack and show that modern architectures can be used to\nsecretly exfiltrate tens of thousands of samples with high fidelity, high\nenough to compromise data privacy and even train new models. Moreover, to\nmitigate this threat we propose a novel approach for detecting infected models.",
            "author": [
                "Guy Amit",
                "Mosh Levy",
                "Yisroel Mirsky"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07389v1",
                "http://arxiv.org/pdf/2311.07389v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07383v1",
            "title": "LM-Polygraph: Uncertainty Estimation for Language Models",
            "updated": "2023-11-13T15:08:59Z",
            "published": "2023-11-13T15:08:59Z",
            "summary": "Recent advancements in the capabilities of large language models (LLMs) have\npaved the way for a myriad of groundbreaking applications in various fields.\nHowever, a significant challenge arises as these models often \"hallucinate\",\ni.e., fabricate facts without providing users an apparent means to discern the\nveracity of their statements. Uncertainty estimation (UE) methods are one path\nto safer, more responsible, and more effective use of LLMs. However, to date,\nresearch on UE methods for LLMs has been focused primarily on theoretical\nrather than engineering contributions. In this work, we tackle this issue by\nintroducing LM-Polygraph, a framework with implementations of a battery of\nstate-of-the-art UE methods for LLMs in text generation tasks, with unified\nprogram interfaces in Python. Additionally, it introduces an extendable\nbenchmark for consistent evaluation of UE techniques by researchers, and a demo\nweb application that enriches the standard chat dialog with confidence scores,\nempowering end-users to discern unreliable responses. LM-Polygraph is\ncompatible with the most recent LLMs, including BLOOMz, LLaMA-2, ChatGPT, and\nGPT-4, and is designed to support future releases of similarly-styled LMs.",
            "author": [
                "Ekaterina Fadeeva",
                "Roman Vashurin",
                "Akim Tsvigun",
                "Artem Vazhentsev",
                "Sergey Petrakov",
                "Kirill Fedyanin",
                "Daniil Vasilev",
                "Elizaveta Goncharova",
                "Alexander Panchenko",
                "Maxim Panov",
                "Timothy Baldwin",
                "Artem Shelmanov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07383v1",
                "http://arxiv.org/pdf/2311.07383v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07377v1",
            "title": "Testing learning-enabled cyber-physical systems with Large-Language\n  Models: A Formal Approach",
            "updated": "2023-11-13T14:56:14Z",
            "published": "2023-11-13T14:56:14Z",
            "summary": "The integration of machine learning (ML) into cyber-physical systems (CPS)\noffers significant benefits, including enhanced efficiency, predictive\ncapabilities, real-time responsiveness, and the enabling of autonomous\noperations. This convergence has accelerated the development and deployment of\na range of real-world applications, such as autonomous vehicles, delivery\ndrones, service robots, and telemedicine procedures. However, the software\ndevelopment life cycle (SDLC) for AI-infused CPS diverges significantly from\ntraditional approaches, featuring data and learning as two critical components.\nExisting verification and validation techniques are often inadequate for these\nnew paradigms. In this study, we pinpoint the main challenges in ensuring\nformal safety for learningenabled CPS.We begin by examining testing as the most\npragmatic method for verification and validation, summarizing the current\nstate-of-the-art methodologies. Recognizing the limitations in current testing\napproaches to provide formal safety guarantees, we propose a roadmap to\ntransition from foundational probabilistic testing to a more rigorous approach\ncapable of delivering formal assurance.",
            "author": [
                "Xi Zheng",
                "Aloysius K. Mok",
                "Ruzica Piskac",
                "Yong Jae Lee",
                "Bhaskar Krishnamachari",
                "Dakai Zhu",
                "Oleg Sokolsky",
                "Insup Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07377v1",
                "http://arxiv.org/pdf/2311.07377v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.AI",
                "cs.DC",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07635v1",
            "title": "Past as a Guide: Leveraging Retrospective Learning for Python Code\n  Completion",
            "updated": "2023-11-13T14:40:33Z",
            "published": "2023-11-13T14:40:33Z",
            "summary": "This work presents Past as a Guide (PaG), a simple approach for Large\nLanguage Models (LLMs) to improve the coding capabilities by integrating the\npast history with interactive and iterative code refinements. To be specific,\ninspired by human cognitive processes, the proposed method enables LLMs to\nutilize previous programming and debugging experiences to enhance the Python\ncode completion tasks. The framework facilitates LLMs to iteratively refine the\nPython code based on previous execution and debugging results and optimize\nlearning and reasoning capabilities. The proposed methodology achieved a 92\\%\npass@1 on HumanEval, demonstrating the potential to advance the field by\nleveraging retrospection from past experiences and interactive and iterative\nrefinement processes without external correctness indicators.",
            "author": [
                "Seunggyoon Shin",
                "Seunggyu Chang",
                "Sungjoon Choi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07635v1",
                "http://arxiv.org/pdf/2311.07635v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07370v2",
            "title": "Classification of developmental and brain disorders via graph\n  convolutional aggregation",
            "updated": "2023-11-16T14:55:15Z",
            "published": "2023-11-13T14:36:29Z",
            "summary": "While graph convolution based methods have become the de-facto standard for\ngraph representation learning, their applications to disease prediction tasks\nremain quite limited, particularly in the classification of neurodevelopmental\nand neurodegenerative brain disorders. In this paper, we introduce an\naggregator normalization graph convolutional network by leveraging aggregation\nin graph sampling, as well as skip connections and identity mapping. The\nproposed model learns discriminative graph node representations by\nincorporating both imaging and non-imaging features into the graph nodes and\nedges, respectively, with the aim of augmenting predictive capabilities and\nproviding a holistic perspective on the underlying mechanisms of brain\ndisorders. Skip connections enable the direct flow of information from the\ninput features to later layers of the network, while identity mapping helps\nmaintain the structural information of the graph during feature learning. We\nbenchmark our model against several recent baseline methods on two large\ndatasets, Autism Brain Imaging Data Exchange (ABIDE) and Alzheimer's Disease\nNeuroimaging Initiative (ADNI), for the prediction of autism spectrum disorder\nand Alzheimer's disease, respectively. Experimental results demonstrate the\ncompetitive performance of our approach in comparison with recent baselines in\nterms of several evaluation metrics, achieving relative improvements of 50% and\n13.56% in classification accuracy over graph convolutional networks on ABIDE\nand ADNI, respectively.",
            "author": [
                "Ibrahim Salim",
                "A. Ben Hamza"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07370v2",
                "http://arxiv.org/pdf/2311.07370v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07366v1",
            "title": "arfpy: A python package for density estimation and generative modeling\n  with adversarial random forests",
            "updated": "2023-11-13T14:28:21Z",
            "published": "2023-11-13T14:28:21Z",
            "summary": "This paper introduces $\\textit{arfpy}$, a python implementation of\nAdversarial Random Forests (ARF) (Watson et al., 2023), which is a lightweight\nprocedure for synthesizing new data that resembles some given data. The\nsoftware $\\textit{arfpy}$ equips practitioners with straightforward\nfunctionalities for both density estimation and generative modeling. The method\nis particularly useful for tabular data and its competitive performance is\ndemonstrated in previous literature. As a major advantage over the mostly deep\nlearning based alternatives, $\\textit{arfpy}$ combines the method's reduced\nrequirements in tuning efforts and computational resources with a user-friendly\npython interface. This supplies audiences across scientific fields with\nsoftware to generate data effortlessly.",
            "author": [
                "Kristin Blesch",
                "Marvin N. Wright"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07366v1",
                "http://arxiv.org/pdf/2311.07366v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07363v3",
            "title": "Efficient bandwidth extension of musical signals using a differentiable\n  harmonic plus noise model",
            "updated": "2023-11-27T11:36:06Z",
            "published": "2023-11-13T14:26:32Z",
            "summary": "The task of bandwidth extension addresses the generation of missing high\nfrequencies of audio signals based on knowledge of the low-frequency part of\nthe sound. This task applies to various problems, such as audio coding or audio\nrestoration. In this article, we focus on efficient bandwidth extension of\nmonophonic and polyphonic musical signals using a differentiable digital signal\nprocessing (DDSP) model. Such a model is composed of a neural network part with\nrelatively few parameters trained to infer the parameters of a differentiable\ndigital signal processing model, which efficiently generates the output\nfull-band audio signal.\n  We first address bandwidth extension of monophonic signals, and then propose\ntwo methods to explicitely handle polyphonic signals. The benefits of the\nproposed models are first demonstrated on monophonic and polyphonic synthetic\ndata against a baseline and a deep-learning-based resnet model. The models are\nnext evaluated on recorded monophonic and polyphonic data, for a wide variety\nof instruments and musical genres. We show that all proposed models surpass a\nhigher complexity deep learning model for an objective metric computed in the\nfrequency domain. A MUSHRA listening test confirms the superiority of the\nproposed approach in terms of perceptual quality.",
            "author": [
                "Pierre-Amaury Grumiaux",
                "Mathieu Lagrange"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07363v3",
                "http://arxiv.org/pdf/2311.07363v3"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07357v1",
            "title": "Registered and Segmented Deformable Object Reconstruction from a Single\n  View Point Cloud",
            "updated": "2023-11-13T14:21:55Z",
            "published": "2023-11-13T14:21:55Z",
            "summary": "In deformable object manipulation, we often want to interact with specific\nsegments of an object that are only defined in non-deformed models of the\nobject. We thus require a system that can recognize and locate these segments\nin sensor data of deformed real world objects. This is normally done using\ndeformable object registration, which is problem specific and complex to tune.\nRecent methods utilize neural occupancy functions to improve deformable object\nregistration by registering to an object reconstruction. Going one step\nfurther, we propose a system that in addition to reconstruction learns\nsegmentation of the reconstructed object. As the resulting output already\ncontains the information about the segments, we can skip the registration\nprocess. Tested on a variety of deformable objects in simulation and the real\nworld, we demonstrate that our method learns to robustly find these segments.\nWe also introduce a simple sampling algorithm to generate better training data\nfor occupancy learning.",
            "author": [
                "Pit Henrich",
                "Bal\u00e1zs Gyenes",
                "Paul Maria Scheikl",
                "Gerhard Neumann",
                "Franziska Mathis-Ullrich"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07357v1",
                "http://arxiv.org/pdf/2311.07357v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07355v2",
            "title": "ADAMM: Anomaly Detection of Attributed Multi-graphs with Metadata: A\n  Unified Neural Network Approach",
            "updated": "2023-11-18T01:23:31Z",
            "published": "2023-11-13T14:19:36Z",
            "summary": "Given a complex graph database of node- and edge-attributed multi-graphs as\nwell as associated metadata for each graph, how can we spot the anomalous\ninstances? Many real-world problems can be cast as graph inference tasks where\nthe graph representation could capture complex relational phenomena (e.g.,\ntransactions among financial accounts in a journal entry), along with metadata\nreflecting tabular features (e.g. approver, effective date, etc.). While\nnumerous anomaly detectors based on Graph Neural Networks (GNNs) have been\nproposed, none are capable of directly handling directed graphs with\nmulti-edges and self-loops. Furthermore, the simultaneous handling of\nrelational and tabular features remains an unexplored area. In this work we\npropose ADAMM, a novel graph neural network model that handles directed\nmulti-graphs, providing a unified end-to-end architecture that fuses metadata\nand graph-level representation learning through an unsupervised anomaly\ndetection objective. Experiments on datasets from two different domains,\nnamely, general-ledger journal entries from different firms (accounting) as\nwell as human GPS trajectories from thousands of individuals (urban mobility)\nvalidate ADAMM's generality and detection effectiveness of expert-guided and\nground-truth anomalies. Notably, ADAMM outperforms existing baselines that\nhandle the two data modalities (graph and metadata) separately with post hoc\nsynthesis efforts.",
            "author": [
                "Konstantinos Sotiropoulos",
                "Lingxiao Zhao",
                "Pierre Jinghong Liang",
                "Leman Akoglu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07355v2",
                "http://arxiv.org/pdf/2311.07355v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.09245v1",
            "title": "Affine Invariance in Continuous-Domain Convolutional Neural Networks",
            "updated": "2023-11-13T14:17:57Z",
            "published": "2023-11-13T14:17:57Z",
            "summary": "The notion of group invariance helps neural networks in recognizing patterns\nand features under geometric transformations. Indeed, it has been shown that\ngroup invariance can largely improve deep learning performances in practice,\nwhere such transformations are very common. This research studies affine\ninvariance on continuous-domain convolutional neural networks. Despite other\nresearch considering isometric invariance or similarity invariance, we focus on\nthe full structure of affine transforms generated by the generalized linear\ngroup $\\mathrm{GL}_2(\\mathbb{R})$. We introduce a new criterion to assess the\nsimilarity of two input signals under affine transformations. Then, unlike\nconventional methods that involve solving complex optimization problems on the\nLie group $G_2$, we analyze the convolution of lifted signals and compute the\ncorresponding integration over $G_2$. In sum, our research could eventually\nextend the scope of geometrical transformations that practical deep-learning\npipelines can handle.",
            "author": [
                "Ali Mohaddes",
                "Johannes Lederer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09245v1",
                "http://arxiv.org/pdf/2311.09245v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.ST",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07346v1",
            "title": "Goal-oriented Estimation of Multiple Markov Sources in\n  Resource-constrained Systems",
            "updated": "2023-11-13T14:03:08Z",
            "published": "2023-11-13T14:03:08Z",
            "summary": "This paper investigates goal-oriented communication for remote estimation of\nmultiple Markov sources in resource-constrained networks. An agent selects the\nupdate order of the sources and transmits the packet to a remote destination\nover an unreliable delay channel. The destination is tasked with source\nreconstruction for the purpose of actuation. We utilize the metric cost of\nactuation error (CAE) to capture the significance (semantics) of error at the\npoint of actuation. We aim to find an optimal sampling policy that minimizes\nthe time-averaged CAE subject to average resource constraints. We formulate\nthis problem as an average-cost constrained Markov Decision Process (CMDP) and\ntransform it into an unconstrained MDP by utilizing Lyapunov drift techniques.\nThen, we propose a low-complexity drift-plus-penalty(DPP) policy for systems\nwith known source/channel statistics and a Lyapunov optimization-based deep\nreinforcement learning (LO-DRL) policy for unknown environments. Our policies\nachieve near-optimal performance in CAE minimization and significantly reduce\nthe number of uninformative transmissions.",
            "author": [
                "Jiping Luo",
                "Nikolaos Pappas"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07346v1",
                "http://arxiv.org/pdf/2311.07346v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.IT",
                "cs.NI",
                "cs.SY",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07345v1",
            "title": "Zero-Shot Duet Singing Voices Separation with Diffusion Models",
            "updated": "2023-11-13T14:01:21Z",
            "published": "2023-11-13T14:01:21Z",
            "summary": "In recent studies, diffusion models have shown promise as priors for solving\naudio inverse problems. These models allow us to sample from the posterior\ndistribution of a target signal given an observed signal by manipulating the\ndiffusion process. However, when separating audio sources of the same type,\nsuch as duet singing voices, the prior learned by the diffusion process may not\nbe sufficient to maintain the consistency of the source identity in the\nseparated audio. For example, the singer may change from one to another\noccasionally. Tackling this problem will be useful for separating sources in a\nchoir, or a mixture of multiple instruments with similar timbre, without\nacquiring large amounts of paired data. In this paper, we examine this problem\nin the context of duet singing voices separation, and propose a method to\nenforce the coherency of singer identity by splitting the mixture into\noverlapping segments and performing posterior sampling in an auto-regressive\nmanner, conditioning on the previous segment. We evaluate the proposed method\non the MedleyVox dataset and show that the proposed method outperforms the\nnaive posterior sampling baseline. Our source code and the pre-trained model\nare publicly available at https://github.com/yoyololicon/duet-svs-diffusion.",
            "author": [
                "Chin-Yun Yu",
                "Emilian Postolache",
                "Emanuele Rodol\u00e0",
                "Gy\u00f6rgy Fazekas"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07345v1",
                "http://arxiv.org/pdf/2311.07345v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07344v2",
            "title": "Missing Value Imputation for Multi-attribute Sensor Data Streams via\n  Message Propagation (Extended Version)",
            "updated": "2023-11-14T14:39:58Z",
            "published": "2023-11-13T14:01:04Z",
            "summary": "Sensor data streams occur widely in various real-time applications in the\ncontext of the Internet of Things (IoT). However, sensor data streams feature\nmissing values due to factors such as sensor failures, communication errors, or\ndepleted batteries. Missing values can compromise the quality of real-time\nanalytics tasks and downstream applications. Existing imputation methods either\nmake strong assumptions about streams or have low efficiency. In this study, we\naim to accurately and efficiently impute missing values in data streams that\nsatisfy only general characteristics in order to benefit real-time applications\nmore widely. First, we propose a message propagation imputation network (MPIN)\nthat is able to recover the missing values of data instances in a time window.\nWe give a theoretical analysis of why MPIN is effective. Second, we present a\ncontinuous imputation framework that consists of data update and model update\nmechanisms to enable MPIN to perform continuous imputation both effectively and\nefficiently. Extensive experiments on multiple real datasets show that MPIN can\noutperform the existing data imputers by wide margins and that the continuous\nimputation framework is efficient and accurate.",
            "author": [
                "Xiao Li",
                "Huan Li",
                "Hua Lu",
                "Christian S. Jensen",
                "Varun Pandey",
                "Volker Markl"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07344v2",
                "http://arxiv.org/pdf/2311.07344v2"
            ],
            "primary_category": "cs.DB",
            "category": [
                "cs.DB",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07343v1",
            "title": "Fine-Tuning the Retrieval Mechanism for Tabular Deep Learning",
            "updated": "2023-11-13T13:55:52Z",
            "published": "2023-11-13T13:55:52Z",
            "summary": "While interests in tabular deep learning has significantly grown,\nconventional tree-based models still outperform deep learning methods. To\nnarrow this performance gap, we explore the innovative retrieval mechanism, a\nmethodology that allows neural networks to refer to other data points while\nmaking predictions. Our experiments reveal that retrieval-based training,\nespecially when fine-tuning the pretrained TabPFN model, notably surpasses\nexisting methods. Moreover, the extensive pretraining plays a crucial role to\nenhance the performance of the model. These insights imply that blending the\nretrieval mechanism with pretraining and transfer learning schemes offers\nconsiderable potential for advancing the field of tabular deep learning.",
            "author": [
                "Felix den Breejen",
                "Sangmin Bae",
                "Stephen Cha",
                "Tae-Young Kim",
                "Seoung Hyun Koh",
                "Se-Young Yun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07343v1",
                "http://arxiv.org/pdf/2311.07343v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07326v1",
            "title": "MetaSymNet: A Dynamic Symbolic Regression Network Capable of Evolving\n  into Arbitrary Formulations",
            "updated": "2023-11-13T13:27:59Z",
            "published": "2023-11-13T13:27:59Z",
            "summary": "Mathematical formulas serve as the means of communication between humans and\nnature, encapsulating the operational laws governing natural phenomena. The\nconcise formulation of these laws is a crucial objective in scientific research\nand an important challenge for artificial intelligence (AI). While traditional\nartificial neural networks (MLP) excel at data fitting, they often yield\nuninterpretable black box results that hinder our understanding of the\nrelationship between variables x and predicted values y. Moreover, the fixed\nnetwork architecture in MLP often gives rise to redundancy in both network\nstructure and parameters. To address these issues, we propose MetaSymNet, a\nnovel neural network that dynamically adjusts its structure in real-time,\nallowing for both expansion and contraction. This adaptive network employs the\nPANGU meta function as its activation function, which is a unique type capable\nof evolving into various basic functions during training to compose\nmathematical formulas tailored to specific needs. We then evolve the neural\nnetwork into a concise, interpretable mathematical expression. To evaluate\nMetaSymNet's performance, we compare it with four state-of-the-art symbolic\nregression algorithms across more than 10 public datasets comprising 222\nformulas. Our experimental results demonstrate that our algorithm outperforms\nothers consistently regardless of noise presence or absence. Furthermore, we\nassess MetaSymNet against MLP and SVM regarding their fitting ability and\nextrapolation capability, these are two essential aspects of machine learning\nalgorithms. The findings reveal that our algorithm excels in both areas.\nFinally, we compared MetaSymNet with MLP using iterative pruning in network\nstructure complexity. The results show that MetaSymNet's network structure\ncomplexity is obviously less than MLP under the same goodness of fit.",
            "author": [
                "Yanjie Li",
                "Weijun Li",
                "Lina Yu",
                "Min Wu",
                "Jinyi Liu",
                "Wenqiang Li",
                "Meilan Hao",
                "Shu Wei",
                "Yusong Deng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07326v1",
                "http://arxiv.org/pdf/2311.07326v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07324v1",
            "title": "DAGC: Data-Volume-Aware Adaptive Sparsification Gradient Compression for\n  Distributed Machine Learning in Mobile Computing",
            "updated": "2023-11-13T13:24:09Z",
            "published": "2023-11-13T13:24:09Z",
            "summary": "Distributed machine learning (DML) in mobile environments faces significant\ncommunication bottlenecks. Gradient compression has emerged as an effective\nsolution to this issue, offering substantial benefits in environments with\nlimited bandwidth and metered data. Yet, they encounter severe performance drop\nin non-IID environments due to a one-size-fits-all compression approach, which\ndoes not account for the varying data volumes across workers. Assigning varying\ncompression ratios to workers with distinct data distributions and volumes is\nthus a promising solution. This study introduces an analysis of distributed SGD\nwith non-uniform compression, which reveals that the convergence rate\n(indicative of the iterations needed to achieve a certain accuracy) is\ninfluenced by compression ratios applied to workers with differing volumes.\nAccordingly, we frame relative compression ratio assignment as an $n$-variables\nchi-square nonlinear optimization problem, constrained by a fixed and limited\ncommunication budget. We propose DAGC-R, which assigns the worker handling\nlarger data volumes the conservative compression. Recognizing the computational\nlimitations of mobile devices, we DAGC-A, which are computationally less\ndemanding and enhances the robustness of the absolute gradient compressor in\nnon-IID scenarios. Our experiments confirm that both the DAGC-A and DAGC-R can\nachieve better performance when dealing with highly imbalanced data volume\ndistribution and restricted communication.",
            "author": [
                "Rongwei Lu",
                "Yutong Jiang",
                "Yinan Mao",
                "Chen Tang",
                "Bin Chen",
                "Laizhong Cui",
                "Zhi Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07324v1",
                "http://arxiv.org/pdf/2311.07324v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08427v2",
            "title": "Towards a Transportable Causal Network Model Based on Observational\n  Healthcare Data",
            "updated": "2023-11-20T15:05:59Z",
            "published": "2023-11-13T13:23:31Z",
            "summary": "Over the last decades, many prognostic models based on artificial\nintelligence techniques have been used to provide detailed predictions in\nhealthcare. Unfortunately, the real-world observational data used to train and\nvalidate these models are almost always affected by biases that can strongly\nimpact the outcomes validity: two examples are values missing not-at-random and\nselection bias. Addressing them is a key element in achieving transportability\nand in studying the causal relationships that are critical in clinical decision\nmaking, going beyond simpler statistical approaches based on probabilistic\nassociation.\n  In this context, we propose a novel approach that combines selection\ndiagrams, missingness graphs, causal discovery and prior knowledge into a\nsingle graphical model to estimate the cardiovascular risk of adolescent and\nyoung females who survived breast cancer. We learn this model from data\ncomprising two different cohorts of patients. The resulting causal network\nmodel is validated by expert clinicians in terms of risk assessment, accuracy\nand explainability, and provides a prognostic model that outperforms competing\nmachine learning methods.",
            "author": [
                "Alice Bernasconi",
                "Alessio Zanga",
                "Peter J. F. Lucas",
                "Marco Scutari",
                "Fabio Stella"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08427v2",
                "http://arxiv.org/pdf/2311.08427v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07323v1",
            "title": "A Voting Approach for Explainable Classification with Rule Learning",
            "updated": "2023-11-13T13:22:21Z",
            "published": "2023-11-13T13:22:21Z",
            "summary": "State-of-the-art results in typical classification tasks are mostly achieved\nby unexplainable machine learning methods, like deep neural networks, for\ninstance. Contrarily, in this paper, we investigate the application of rule\nlearning methods in such a context. Thus, classifications become based on\ncomprehensible (first-order) rules, explaining the predictions made. In\ngeneral, however, rule-based classifications are less accurate than\nstate-of-the-art results (often significantly). As main contribution, we\nintroduce a voting approach combining both worlds, aiming to achieve comparable\nresults as (unexplainable) state-of-the-art methods, while still providing\nexplanations in the form of deterministic rules. Considering a variety of\nbenchmark data sets including a use case of significant interest to insurance\nindustries, we prove that our approach not only clearly outperforms ordinary\nrule learning methods, but also yields results on a par with state-of-the-art\noutcomes.",
            "author": [
                "Albert N\u00f6ssig",
                "Tobias Hell",
                "Georg Moser"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07323v1",
                "http://arxiv.org/pdf/2311.07323v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07321v1",
            "title": "Connecting the Dots: Graph Neural Network Powered Ensemble and\n  Classification of Medical Images",
            "updated": "2023-11-13T13:20:54Z",
            "published": "2023-11-13T13:20:54Z",
            "summary": "Deep learning models have demonstrated remarkable results for various\ncomputer vision tasks, including the realm of medical imaging. However, their\napplication in the medical domain is limited due to the requirement for large\namounts of training data, which can be both challenging and expensive to\nobtain. To mitigate this, pre-trained models have been fine-tuned on\ndomain-specific data, but such an approach can suffer from inductive biases.\nFurthermore, deep learning models struggle to learn the relationship between\nspatially distant features and their importance, as convolution operations\ntreat all pixels equally. Pioneering a novel solution to this challenge, we\nemploy the Image Foresting Transform to optimally segment images into\nsuperpixels. These superpixels are subsequently transformed into\ngraph-structured data, enabling the proficient extraction of features and\nmodeling of relationships using Graph Neural Networks (GNNs). Our method\nharnesses an ensemble of three distinct GNN architectures to boost its\nrobustness. In our evaluations targeting pneumonia classification, our\nmethodology surpassed prevailing Deep Neural Networks (DNNs) in performance,\nall while drastically cutting down on the parameter count. This not only trims\ndown the expenses tied to data but also accelerates training and minimizes\nbias. Consequently, our proposition offers a sturdy, economically viable, and\nscalable strategy for medical image classification, significantly diminishing\ndependency on extensive training data sets.",
            "author": [
                "Aryan Singh",
                "Pepijn Van de Ven",
                "Ciar\u00e1n Eising",
                "Patrick Denny"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07321v1",
                "http://arxiv.org/pdf/2311.07321v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07633v2",
            "title": "Rethinking and Benchmarking Predict-then-Optimize Paradigm for\n  Combinatorial Optimization Problems",
            "updated": "2023-11-19T05:36:04Z",
            "published": "2023-11-13T13:19:34Z",
            "summary": "Numerous web applications rely on solving combinatorial optimization\nproblems, such as energy cost-aware scheduling, budget allocation on web\nadvertising, and graph matching on social networks. However, many optimization\nproblems involve unknown coefficients, and improper predictions of these\nfactors may lead to inferior decisions which may cause energy wastage,\ninefficient resource allocation, inappropriate matching in social networks,\netc. Such a research topic is referred to as \"Predict-Then-Optimize (PTO)\"\nwhich considers the performance of prediction and decision-making in a unified\nsystem. A noteworthy recent development is the end-to-end methods by directly\noptimizing the ultimate decision quality which claims to yield better results\nin contrast to the traditional two-stage approach. However, the evaluation\nbenchmarks in this field are fragmented and the effectiveness of various models\nin different scenarios remains unclear, hindering the comprehensive assessment\nand fast deployment of these methods. To address these issues, we provide a\ncomprehensive categorization of current approaches and integrate existing\nexperimental scenarios to establish a unified benchmark, elucidating the\ncircumstances under which end-to-end training yields improvements, as well as\nthe contexts in which it performs ineffectively. We also introduce a new\ndataset for the industrial combinatorial advertising problem for inclusive\nfinance to open-source. We hope the rethinking and benchmarking of PTO could\nfacilitate more convenient evaluation and deployment, and inspire further\nimprovements both in the academy and industry within this field.",
            "author": [
                "Haoyu Geng",
                "Hang Ruan",
                "Runzhong Wang",
                "Yang Li",
                "Yang Wang",
                "Lei Chen",
                "Junchi Yan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07633v2",
                "http://arxiv.org/pdf/2311.07633v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07632v1",
            "title": "ResMGCN: Residual Message Graph Convolution Network for Fast Biomedical\n  Interactions Discovering",
            "updated": "2023-11-13T13:16:35Z",
            "published": "2023-11-13T13:16:35Z",
            "summary": "Biomedical information graphs are crucial for interaction discovering of\nbiomedical information in modern age, such as identification of multifarious\nmolecular interactions and drug discovery, which attracts increasing interests\nin biomedicine, bioinformatics, and human healthcare communities. Nowadays,\nmore and more graph neural networks have been proposed to learn the entities of\nbiomedical information and precisely reveal biomedical molecule interactions\nwith state-of-the-art results. These methods remedy the fading of features from\na far distance but suffer from remedying such problem at the expensive cost of\nredundant memory and time. In our paper, we propose a novel Residual Message\nGraph Convolution Network (ResMGCN) for fast and precise biomedical interaction\nprediction in a different idea. Specifically, instead of enhancing the message\nfrom far nodes, ResMGCN aggregates lower-order information with the next round\nhigher information to guide the node update to obtain a more meaningful node\nrepresentation. ResMGCN is able to perceive and preserve various messages from\nthe previous layer and high-order information in the current layer with least\nmemory and time cost to obtain informative representations of biomedical\nentities. We conduct experiments on four biomedical interaction network\ndatasets, including protein-protein, drug-drug, drug-target, and gene-disease\ninteractions, which demonstrates that ResMGCN outperforms previous\nstate-of-the-art models while achieving superb effectiveness on both storage\nand time.",
            "author": [
                "Zecheng Yin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07632v1",
                "http://arxiv.org/pdf/2311.07632v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "q-bio.MN"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07315v1",
            "title": "An introduction to reinforcement learning for neuroscience",
            "updated": "2023-11-13T13:10:52Z",
            "published": "2023-11-13T13:10:52Z",
            "summary": "Reinforcement learning has a rich history in neuroscience, from early work on\ndopamine as a reward prediction error signal for temporal difference learning\n(Schultz et al., 1997) to recent work suggesting that dopamine could implement\na form of 'distributional reinforcement learning' popularized in deep learning\n(Dabney et al., 2020). Throughout this literature, there has been a tight link\nbetween theoretical advances in reinforcement learning and neuroscientific\nexperiments and findings. As a result, the theories describing our experimental\ndata have become increasingly complex and difficult to navigate. In this\nreview, we cover the basic theory underlying classical work in reinforcement\nlearning and build up to an introductory overview of methods used in modern\ndeep reinforcement learning that have found applications in systems\nneuroscience. We start with an overview of the reinforcement learning problem\nand classical temporal difference algorithms, followed by a discussion of\n'model-free' and 'model-based' reinforcement learning together with methods\nsuch as DYNA and successor representations that fall in between these two\ncategories. Throughout these sections, we highlight the close parallels between\nthe machine learning methods and related work in both experimental and\ntheoretical neuroscience. We then provide an introduction to deep reinforcement\nlearning with examples of how these methods have been used to model different\nlearning phenomena in the systems neuroscience literature, such as\nmeta-reinforcement learning (Wang et al., 2018) and distributional\nreinforcement learning (Dabney et al., 2020). Code that implements the methods\ndiscussed in this work and generates the figures is also provided.",
            "author": [
                "Kristopher T. Jensen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07315v1",
                "http://arxiv.org/pdf/2311.07315v1"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07314v1",
            "title": "Semi-automatic Data Enhancement for Document-Level Relation Extraction\n  with Distant Supervision from Large Language Models",
            "updated": "2023-11-13T13:10:44Z",
            "published": "2023-11-13T13:10:44Z",
            "summary": "Document-level Relation Extraction (DocRE), which aims to extract relations\nfrom a long context, is a critical challenge in achieving fine-grained\nstructural comprehension and generating interpretable document representations.\nInspired by recent advances in in-context learning capabilities emergent from\nlarge language models (LLMs), such as ChatGPT, we aim to design an automated\nannotation method for DocRE with minimum human effort. Unfortunately, vanilla\nin-context learning is infeasible for document-level relation extraction due to\nthe plenty of predefined fine-grained relation types and the uncontrolled\ngenerations of LLMs. To tackle this issue, we propose a method integrating a\nlarge language model (LLM) and a natural language inference (NLI) module to\ngenerate relation triples, thereby augmenting document-level relation datasets.\nWe demonstrate the effectiveness of our approach by introducing an enhanced\ndataset known as DocGNRE, which excels in re-annotating numerous long-tail\nrelation types. We are confident that our method holds the potential for\nbroader applications in domain-specific relation type definitions and offers\ntangible benefits in advancing generalized language semantic comprehension.",
            "author": [
                "Junpeng Li",
                "Zixia Jia",
                "Zilong Zheng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07314v1",
                "http://arxiv.org/pdf/2311.07314v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07312v1",
            "title": "C-Procgen: Empowering Procgen with Controllable Contexts",
            "updated": "2023-11-13T13:07:48Z",
            "published": "2023-11-13T13:07:48Z",
            "summary": "We present C-Procgen, an enhanced suite of environments on top of the Procgen\nbenchmark. C-Procgen provides access to over 200 unique game contexts across 16\ngames. It allows for detailed configuration of environments, ranging from game\nmechanics to agent attributes. This makes the procedural generation process,\npreviously a black-box in Procgen, more transparent and adaptable for various\nresearch needs.The upgrade enhances dynamic context management and\nindividualized assignments, while maintaining computational efficiency.\nC-Procgen's controllable contexts make it applicable in diverse reinforcement\nlearning research areas, such as learning dynamics analysis, curriculum\nlearning, and transfer learning. We believe that C-Procgen will fill a gap in\nthe current literature and offer a valuable toolkit for future works.",
            "author": [
                "Zhenxiong Tan",
                "Kaixin Wang",
                "Xinchao Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07312v1",
                "http://arxiv.org/pdf/2311.07312v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07296v1",
            "title": "BIDRN: A Method of Bidirectional Recurrent Neural Network for Sentiment\n  Analysis",
            "updated": "2023-11-13T12:36:53Z",
            "published": "2023-11-13T12:36:53Z",
            "summary": "Text mining research has grown in importance in recent years due to the\ntremendous increase in the volume of unstructured textual data. This has\nresulted in immense potential as well as obstacles in the sector, which may be\nefficiently addressed with adequate analytical and study methods. Deep\nBidirectional Recurrent Neural Networks are used in this study to analyze\nsentiment. The method is categorized as sentiment polarity analysis because it\nmay generate a dataset with sentiment labels. This dataset can be used to train\nand evaluate sentiment analysis models capable of extracting impartial\nopinions. This paper describes the Sentiment Analysis-Deep Bidirectional\nRecurrent Neural Networks (SA-BDRNN) Scheme, which seeks to overcome the\nchallenges and maximize the potential of text mining in the context of Big\nData. The current study proposes a SA-DBRNN Scheme that attempts to give a\nsystematic framework for sentiment analysis in the context of student input on\ninstitution choice. The purpose of this study is to compare the effectiveness\nof the proposed SA- DBRNN Scheme to existing frameworks to establish a robust\ndeep neural network that might serve as an adequate classification model in the\nfield of sentiment analysis.",
            "author": [
                "Dr. D Muthusankar",
                "Dr. P Kaladevi",
                "Dr. V R Sadasivam",
                "R Praveen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07296v1",
                "http://arxiv.org/pdf/2311.07296v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07289v1",
            "title": "A probabilistic forecast methodology for volatile electricity prices in\n  the Australian National Electricity Market",
            "updated": "2023-11-13T12:33:33Z",
            "published": "2023-11-13T12:33:33Z",
            "summary": "The South Australia region of the Australian National Electricity Market\n(NEM) displays some of the highest levels of price volatility observed in\nmodern electricity markets. This paper outlines an approach to probabilistic\nforecasting under these extreme conditions, including spike filtration and\nseveral post-processing steps. We propose using quantile regression as an\nensemble tool for probabilistic forecasting, with our combined forecasts\nachieving superior results compared to all constituent models. Within our\nensemble framework, we demonstrate that averaging models with varying training\nlength periods leads to a more adaptive model and increased prediction\naccuracy. The applicability of the final model is evaluated by comparing our\nmedian forecasts with the point forecasts available from the Australian NEM\noperator, with our model outperforming these NEM forecasts by a significant\nmargin.",
            "author": [
                "Cameron Cornell",
                "Nam Trong Dinh",
                "S. Ali Pourmousavi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07289v1",
                "http://arxiv.org/pdf/2311.07289v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07286v1",
            "title": "Explaining black boxes with a SMILE: Statistical Model-agnostic\n  Interpretability with Local Explanations",
            "updated": "2023-11-13T12:28:00Z",
            "published": "2023-11-13T12:28:00Z",
            "summary": "Machine learning is currently undergoing an explosion in capability,\npopularity, and sophistication. However, one of the major barriers to\nwidespread acceptance of machine learning (ML) is trustworthiness: most ML\nmodels operate as black boxes, their inner workings opaque and mysterious, and\nit can be difficult to trust their conclusions without understanding how those\nconclusions are reached. Explainability is therefore a key aspect of improving\ntrustworthiness: the ability to better understand, interpret, and anticipate\nthe behaviour of ML models. To this end, we propose SMILE, a new method that\nbuilds on previous approaches by making use of statistical distance measures to\nimprove explainability while remaining applicable to a wide range of input data\ndomains.",
            "author": [
                "Koorosh Aslansefat",
                "Mojgan Hashemian",
                "Martin Walker",
                "Mohammed Naveed Akram",
                "Ioannis Sorokos",
                "Yiannis Papadopoulos"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07286v1",
                "http://arxiv.org/pdf/2311.07286v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "math.ST",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07285v1",
            "title": "Multi Sentence Description of Complex Manipulation Action Videos",
            "updated": "2023-11-13T12:27:06Z",
            "published": "2023-11-13T12:27:06Z",
            "summary": "Automatic video description requires the generation of natural language\nstatements about the actions, events, and objects in the video. An important\nhuman trait, when we describe a video, is that we are able to do this with\nvariable levels of detail. Different from this, existing approaches for\nautomatic video descriptions are mostly focused on single sentence generation\nat a fixed level of detail. Instead, here we address video description of\nmanipulation actions where different levels of detail are required for being\nable to convey information about the hierarchical structure of these actions\nrelevant also for modern approaches of robot learning. We propose one hybrid\nstatistical and one end-to-end framework to address this problem. The hybrid\nmethod needs much less data for training, because it models statistically\nuncertainties within the video clips, while in the end-to-end method, which is\nmore data-heavy, we are directly connecting the visual encoder to the language\ndecoder without any intermediate (statistical) processing step. Both frameworks\nuse LSTM stacks to allow for different levels of description granularity and\nvideos can be described by simple single-sentences or complex multiple-sentence\ndescriptions. In addition, quantitative results demonstrate that these methods\nproduce more realistic descriptions than other competing approaches.",
            "author": [
                "Fatemeh Ziaeetabar",
                "Reza Safabakhsh",
                "Saeedeh Momtazi",
                "Minija Tamosiunaite",
                "Florentin W\u00f6rg\u00f6tter"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07285v1",
                "http://arxiv.org/pdf/2311.07285v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07284v1",
            "title": "Learning Arithmetic Formulas in the Presence of Noise: A General\n  Framework and Applications to Unsupervised Learning",
            "updated": "2023-11-13T12:26:25Z",
            "published": "2023-11-13T12:26:25Z",
            "summary": "We present a general framework for designing efficient algorithms for\nunsupervised learning problems, such as mixtures of Gaussians and subspace\nclustering. Our framework is based on a meta algorithm that learns arithmetic\ncircuits in the presence of noise, using lower bounds. This builds upon the\nrecent work of Garg, Kayal and Saha (FOCS 20), who designed such a framework\nfor learning arithmetic circuits without any noise. A key ingredient of our\nmeta algorithm is an efficient algorithm for a novel problem called Robust\nVector Space Decomposition. We show that our meta algorithm works well when\ncertain matrices have sufficiently large smallest non-zero singular values. We\nconjecture that this condition holds for smoothed instances of our problems,\nand thus our framework would yield efficient algorithms for these problems in\nthe smoothed setting.",
            "author": [
                "Pritam Chandra",
                "Ankit Garg",
                "Neeraj Kayal",
                "Kunal Mittal",
                "Tanmay Sinha"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07284v1",
                "http://arxiv.org/pdf/2311.07284v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.CC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07283v1",
            "title": "Predictive and Prescriptive Analytics for Multi-Site Modeling of Frail\n  and Elderly Patient Services",
            "updated": "2023-11-13T12:25:45Z",
            "published": "2023-11-13T12:25:45Z",
            "summary": "Recent research has highlighted the potential of linking predictive and\nprescriptive analytics. However, it remains widely unexplored how both\nparadigms could benefit from one another to address today's major challenges in\nhealthcare. One of these is smarter planning of resource capacities for frail\nand elderly inpatient wards, addressing the societal challenge of an aging\npopulation. Frail and elderly patients typically suffer from multimorbidity and\nrequire more care while receiving medical treatment. The aim of this research\nis to assess how various predictive and prescriptive analytical methods, both\nindividually and in tandem, contribute to addressing the operational challenges\nwithin an area of healthcare that is growing in demand. Clinical and\ndemographic patient attributes are gathered from more than 165,000 patient\nrecords and used to explain and predict length of stay. To that extent, we\nemploy Classification and Regression Trees (CART) analysis to establish this\nrelationship. On the prescriptive side, deterministic and two-stage stochastic\nprograms are developed to determine how to optimally plan for beds and ward\nstaff with the objective to minimize cost. Furthermore, the two analytical\nmethodologies are linked by generating demand for the prescriptive models using\nthe CART groupings. The results show the linked methodologies provided\ndifferent but similar results compared to using averages and in doing so,\ncaptured a more realistic real-world variation in the patient length of stay.\nOur research reveals that healthcare managers should consider using predictive\nand prescriptive models to make more informed decisions. By combining\npredictive and prescriptive analytics, healthcare managers can move away from\nrelying on averages and incorporate the unique characteristics of their\npatients to create more robust planning decisions, mitigating risks caused by\nvariations in demand.",
            "author": [
                "Elizabeth Williams",
                "Daniel Gartner",
                "Paul Harper"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07283v1",
                "http://arxiv.org/pdf/2311.07283v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13569v1",
            "title": "Combinatorial Optimization with Policy Adaptation using Latent Space\n  Search",
            "updated": "2023-11-13T12:24:54Z",
            "published": "2023-11-13T12:24:54Z",
            "summary": "Combinatorial Optimization underpins many real-world applications and yet,\ndesigning performant algorithms to solve these complex, typically NP-hard,\nproblems remains a significant research challenge. Reinforcement Learning (RL)\nprovides a versatile framework for designing heuristics across a broad spectrum\nof problem domains. However, despite notable progress, RL has not yet\nsupplanted industrial solvers as the go-to solution. Current approaches\nemphasize pre-training heuristics that construct solutions but often rely on\nsearch procedures with limited variance, such as stochastically sampling\nnumerous solutions from a single policy or employing computationally expensive\nfine-tuning of the policy on individual problem instances. Building on the\nintuition that performant search at inference time should be anticipated during\npre-training, we propose COMPASS, a novel RL approach that parameterizes a\ndistribution of diverse and specialized policies conditioned on a continuous\nlatent space. We evaluate COMPASS across three canonical problems - Travelling\nSalesman, Capacitated Vehicle Routing, and Job-Shop Scheduling - and\ndemonstrate that our search strategy (i) outperforms state-of-the-art\napproaches on 11 standard benchmarking tasks and (ii) generalizes better,\nsurpassing all other approaches on a set of 18 procedurally transformed\ninstance distributions.",
            "author": [
                "Felix Chalumeau",
                "Shikha Surana",
                "Clement Bonnet",
                "Nathan Grinsztajn",
                "Arnu Pretorius",
                "Alexandre Laterre",
                "Thomas D. Barrett"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13569v1",
                "http://arxiv.org/pdf/2311.13569v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07277v1",
            "title": "AdaCCD: Adaptive Semantic Contrasts Discovery based Cross Lingual\n  Adaptation for Code Clone Detection",
            "updated": "2023-11-13T12:20:48Z",
            "published": "2023-11-13T12:20:48Z",
            "summary": "Code Clone Detection, which aims to retrieve functionally similar programs\nfrom large code bases, has been attracting increasing attention. Modern\nsoftware often involves a diverse range of programming languages. However,\ncurrent code clone detection methods are generally limited to only a few\npopular programming languages due to insufficient annotated data as well as\ntheir own model design constraints. To address these issues, we present AdaCCD,\na novel cross-lingual adaptation method that can detect cloned codes in a new\nlanguage without any annotations in that language. AdaCCD leverages\nlanguage-agnostic code representations from pre-trained programming language\nmodels and propose an Adaptively Refined Contrastive Learning framework to\ntransfer knowledge from resource-rich languages to resource-poor languages. We\nevaluate the cross-lingual adaptation results of AdaCCD by constructing a\nmultilingual code clone detection benchmark consisting of 5 programming\nlanguages. AdaCCD achieves significant improvements over other baselines, and\nit is even comparable to supervised fine-tuning.",
            "author": [
                "Yangkai Du",
                "Tengfei Ma",
                "Lingfei Wu",
                "Xuhong Zhang",
                "Shouling Ji"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07277v1",
                "http://arxiv.org/pdf/2311.07277v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07274v1",
            "title": "Phase Transition Study meets Machine Learning",
            "updated": "2023-11-13T12:15:35Z",
            "published": "2023-11-13T12:15:35Z",
            "summary": "In recent years, machine learning (ML) techniques have emerged as powerful\ntools in studying many-body complex systems, encompassing phase transitions in\nvarious domains of physics. This mini-review provides a concise yet\ncomprehensive examination of the advancements achieved in applying ML for\ninvestigating phase transitions, with a primary emphasis on those involved in\nnuclear matter studies.",
            "author": [
                "Yu-Gang Ma",
                "Long-Gang Pang",
                "Rui Wang",
                "Kai Zhou"
            ],
            "link": [
                "http://dx.doi.org/10.1088/0256-307X/40/12/122101",
                "http://arxiv.org/abs/2311.07274v1",
                "http://arxiv.org/pdf/2311.07274v1"
            ],
            "primary_category": "nucl-th",
            "category": [
                "nucl-th",
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07263v1",
            "title": "LT-ViT: A Vision Transformer for multi-label Chest X-ray classification",
            "updated": "2023-11-13T12:02:46Z",
            "published": "2023-11-13T12:02:46Z",
            "summary": "Vision Transformers (ViTs) are widely adopted in medical imaging tasks, and\nsome existing efforts have been directed towards vision-language training for\nChest X-rays (CXRs). However, we envision that there still exists a potential\nfor improvement in vision-only training for CXRs using ViTs, by aggregating\ninformation from multiple scales, which has been proven beneficial for\nnon-transformer networks. Hence, we have developed LT-ViT, a transformer that\nutilizes combined attention between image tokens and randomly initialized\nauxiliary tokens that represent labels. Our experiments demonstrate that LT-ViT\n(1) surpasses the state-of-the-art performance using pure ViTs on two publicly\navailable CXR datasets, (2) is generalizable to other pre-training methods and\ntherefore is agnostic to model initialization, and (3) enables model\ninterpretability without grad-cam and its variants.",
            "author": [
                "Umar Marikkar",
                "Sara Atito",
                "Muhammad Awais",
                "Adam Mahdi"
            ],
            "link": [
                "http://dx.doi.org/10.1109/ICIP49359.2023.10222175",
                "http://arxiv.org/abs/2311.07263v1",
                "http://arxiv.org/pdf/2311.07263v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07260v1",
            "title": "TIAGo RL: Simulated Reinforcement Learning Environments with Tactile\n  Data for Mobile Robots",
            "updated": "2023-11-13T11:50:30Z",
            "published": "2023-11-13T11:50:30Z",
            "summary": "Tactile information is important for robust performance in robotic tasks that\ninvolve physical interaction, such as object manipulation. However, with more\ndata included in the reasoning and control process, modeling behavior becomes\nincreasingly difficult. Deep Reinforcement Learning (DRL) produced promising\nresults for learning complex behavior in various domains, including\ntactile-based manipulation in robotics. In this work, we present our\nopen-source reinforcement learning environments for the TIAGo service robot.\nThey produce tactile sensor measurements that resemble those of a real\nsensorised gripper for TIAGo, encouraging research in transfer learning of DRL\npolicies. Lastly, we show preliminary training results of a learned force\ncontrol policy and compare it to a classical PI controller.",
            "author": [
                "Luca Lach",
                "Francesco Ferro",
                "Robert Haschke"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07260v1",
                "http://arxiv.org/pdf/2311.07260v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07259v1",
            "title": "Towards Bounding Causal Effects under Markov Equivalence",
            "updated": "2023-11-13T11:49:55Z",
            "published": "2023-11-13T11:49:55Z",
            "summary": "Predicting the effect of unseen interventions is a fundamental research\nquestion across the data sciences. It is well established that, in general,\nsuch questions cannot be answered definitively from observational data, e.g.,\nas a consequence of unobserved confounding. A generalization of this task is to\ndetermine non-trivial bounds on causal effects induced by the data, also known\nas the task of partial causal identification. In the literature, several\nalgorithms have been developed for solving this problem. Most, however, require\na known parametric form or a fully specified causal diagram as input, which is\nusually not available in practical applications. In this paper, we assume as\ninput a less informative structure known as a Partial Ancestral Graph, which\nrepresents a Markov equivalence class of causal diagrams and is learnable from\nobservational data. In this more \"data-driven\" setting, we provide a systematic\nalgorithm to derive bounds on causal effects that can be computed analytically.",
            "author": [
                "Alexis Bellot"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07259v1",
                "http://arxiv.org/pdf/2311.07259v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07253v1",
            "title": "Machine learning the Kondo entanglement cloud from local measurements",
            "updated": "2023-11-13T11:38:46Z",
            "published": "2023-11-13T11:38:46Z",
            "summary": "A quantum coherent screening cloud around a magnetic impurity in metallic\nsystems is the hallmark of the antiferromagnetic Kondo effect. Despite the\ncentral role of the Kondo effect in quantum materials, the structure of quantum\ncorrelations of the screening cloud has defied direct observations. In this\nwork, we introduce a machine-learning algorithm that allows to spatially map\nthe entangled electronic modes in the vicinity of the impurity site from\nexperimentally accessible data. We demonstrate that local correlators allow\nreconstructing the local many-body correlation entropy in real-space in a\ndouble Kondo system with overlapping entanglement clouds. Our machine learning\nmethodology allows bypassing the typical requirement of measuring long-range\nnon-local correlators with conventional methods. We show that our machine\nlearning algorithm is transferable between different Kondo system sizes, and we\nshow its robustness in the presence of noisy correlators. Our work establishes\nthe potential machine learning methods to map many-body entanglement from\nreal-space measurements.",
            "author": [
                "Faluke Aikebaier",
                "Teemu Ojanen",
                "Jose L. Lado"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07253v1",
                "http://arxiv.org/pdf/2311.07253v1"
            ],
            "primary_category": "cond-mat.str-el",
            "category": [
                "cond-mat.str-el"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07249v1",
            "title": "Near-Field Sparse Channel Estimation for Extremely Large-Scale RIS-Aided\n  Wireless Communications",
            "updated": "2023-11-13T11:31:36Z",
            "published": "2023-11-13T11:31:36Z",
            "summary": "A significant increase in the number of reconfigurable intelligent surface\n(RIS) elements results in a spherical wavefront in the near field of extremely\nlarge-scale RIS (XL-RIS). Although the channel matrix of the cascaded two-hop\nlink may become sparse in the polar-domain representation, their accurate\nestimation of these polar-domain parameters cannot be readily guaranteed. To\ntackle this challenge, we exploit the sparsity inherent in the cascaded\nchannel. To elaborate, we first estimate the significant path-angles and\ndistances corresponding to the common paths between the BS and the XL-RIS.\nThen, the individual path parameters associated with different users are\nrecovered. This results in a two-stage channel estimation scheme, in which\ndistinct learning-based networks are used for channel training at each stage.\nMore explicitly, in stage I, a denoising convolutional neural network (DnCNN)\nis employed for treating the grid mismatches as noise to determine the true\ngrid index of the angles and distances. By contrast, an iterative shrinkage\nthresholding algorithm (ISTA) based network is proposed for adaptively\nadjusting the column coherence of the dictionary matrix in stage II. Finally,\nour simulation results demonstrate that the proposed two-stage learning-based\nchannel estimation outperforms the state-of-the-art benchmarks.",
            "author": [
                "Zixing Tang",
                "Yuanbin Chen",
                "Ying Wang",
                "Tianqi Mao",
                "Qingqing Wu",
                "Marco Di Renzo",
                "Lajos Hanzo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07249v1",
                "http://arxiv.org/pdf/2311.07249v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07247v2",
            "title": "Simultaneous Clutter Detection and Semantic Segmentation of Moving\n  Objects for Automotive Radar Data",
            "updated": "2023-11-14T07:36:39Z",
            "published": "2023-11-13T11:29:38Z",
            "summary": "The unique properties of radar sensors, such as their robustness to adverse\nweather conditions, make them an important part of the environment perception\nsystem of autonomous vehicles. One of the first steps during the processing of\nradar point clouds is often the detection of clutter, i.e. erroneous points\nthat do not correspond to real objects. Another common objective is the\nsemantic segmentation of moving road users. These two problems are handled\nstrictly separate from each other in literature. The employed neural networks\nare always focused entirely on only one of the tasks. In contrast to this, we\nexamine ways to solve both tasks at the same time with a single jointly used\nmodel. In addition to a new augmented multi-head architecture, we also devise a\nmethod to represent a network's predictions for the two tasks with only one\noutput value. This novel approach allows us to solve the tasks simultaneously\nwith the same inference time as a conventional task-specific model. In an\nextensive evaluation, we show that our setup is highly effective and\noutperforms every existing network for semantic segmentation on the RadarScenes\ndataset.",
            "author": [
                "Johannes Kopp",
                "Dominik Kellner",
                "Aldi Piroli",
                "Vinzenz Dallabetta",
                "Klaus Dietmayer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07247v2",
                "http://arxiv.org/pdf/2311.07247v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07245v1",
            "title": "Towards Transferring Tactile-based Continuous Force Control Policies\n  from Simulation to Robot",
            "updated": "2023-11-13T11:29:06Z",
            "published": "2023-11-13T11:29:06Z",
            "summary": "The advent of tactile sensors in robotics has sparked many ideas on how\nrobots can leverage direct contact measurements of their environment\ninteractions to improve manipulation tasks. An important line of research in\nthis regard is that of grasp force control, which aims to manipulate objects\nsafely by limiting the amount of force exerted on the object. While prior works\nhave either hand-modeled their force controllers, employed model-based\napproaches, or have not shown sim-to-real transfer, we propose a model-free\ndeep reinforcement learning approach trained in simulation and then transferred\nto the robot without further fine-tuning. We therefore present a simulation\nenvironment that produces realistic normal forces, which we use to train\ncontinuous force control policies. An evaluation in which we compare against a\nbaseline and perform an ablation study shows that our approach outperforms the\nhand-modeled baseline and that our proposed inductive bias and domain\nrandomization facilitate sim-to-real transfer. Code, models, and supplementary\nvideos are available on https://sites.google.com/view/rl-force-ctrl",
            "author": [
                "Luca Lach",
                "Robert Haschke",
                "Davide Tateo",
                "Jan Peters",
                "Helge Ritter",
                "J\u00falia Borr\u00e0s",
                "Carme Torras"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07245v1",
                "http://arxiv.org/pdf/2311.07245v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07241v1",
            "title": "IndexMAC: A Custom RISC-V Vector Instruction to Accelerate\n  Structured-Sparse Matrix Multiplications",
            "updated": "2023-11-13T11:13:53Z",
            "published": "2023-11-13T11:13:53Z",
            "summary": "Structured sparsity has been proposed as an efficient way to prune the\ncomplexity of modern Machine Learning (ML) applications and to simplify the\nhandling of sparse data in hardware. The acceleration of ML models - for both\ntraining and inference - relies primarily on equivalent matrix multiplications\nthat can be executed efficiently on vector processors or custom matrix engines.\nThe goal of this work is to incorporate the simplicity of structured sparsity\ninto vector execution, thereby accelerating the corresponding matrix\nmultiplications. Toward this objective, a new vector index-multiply-accumulate\ninstruction is proposed, which enables the implementation of lowcost indirect\nreads from the vector register file. This reduces unnecessary memory traffic\nand increases data locality. The proposed new instruction was integrated in a\ndecoupled RISCV vector processor with negligible hardware cost. Extensive\nevaluation demonstrates significant speedups of 1.80x-2.14x, as compared to\nstate-of-the-art vectorized kernels, when executing layers of varying sparsity\nfrom state-of-the-art Convolutional Neural Networks (CNNs).",
            "author": [
                "V. Titopoulos",
                "K. Alexandridis",
                "C. Peltekis",
                "C. Nicopoulos",
                "G. Dimitrakopoulos"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07241v1",
                "http://arxiv.org/pdf/2311.07241v1"
            ],
            "primary_category": "cs.AR",
            "category": [
                "cs.AR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07235v1",
            "title": "DeepMetricEye: Metric Depth Estimation in Periocular VR Imagery",
            "updated": "2023-11-13T10:55:05Z",
            "published": "2023-11-13T10:55:05Z",
            "summary": "Despite the enhanced realism and immersion provided by VR headsets, users\nfrequently encounter adverse effects such as digital eye strain (DES), dry eye,\nand potential long-term visual impairment due to excessive eye stimulation from\nVR displays and pressure from the mask. Recent VR headsets are increasingly\nequipped with eye-oriented monocular cameras to segment ocular feature maps.\nYet, to compute the incident light stimulus and observe periocular condition\nalterations, it is imperative to transform these relative measurements into\nmetric dimensions. To bridge this gap, we propose a lightweight framework\nderived from the U-Net 3+ deep learning backbone that we re-optimised, to\nestimate measurable periocular depth maps. Compatible with any VR headset\nequipped with an eye-oriented monocular camera, our method reconstructs\nthree-dimensional periocular regions, providing a metric basis for related\nlight stimulus calculation protocols and medical guidelines. Navigating the\ncomplexities of data collection, we introduce a Dynamic Periocular Data\nGeneration (DPDG) environment based on UE MetaHuman, which synthesises\nthousands of training images from a small quantity of human facial scan data.\nEvaluated on a sample of 36 participants, our method exhibited notable efficacy\nin the periocular global precision evaluation experiment, and the pupil\ndiameter measurement.",
            "author": [
                "Yitong Sun",
                "Zijian Zhou",
                "Cyriel Diels",
                "Ali Asadipour"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07235v1",
                "http://arxiv.org/pdf/2311.07235v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07234v1",
            "title": "Multi-task learning for joint weakly-supervised segmentation and aortic\n  arch anomaly classification in fetal cardiac MRI",
            "updated": "2023-11-13T10:54:53Z",
            "published": "2023-11-13T10:54:53Z",
            "summary": "Congenital Heart Disease (CHD) is a group of cardiac malformations present\nalready during fetal life, representing the prevailing category of birth\ndefects globally. Our aim in this study is to aid 3D fetal vessel topology\nvisualisation in aortic arch anomalies, a group which encompasses a range of\nconditions with significant anatomical heterogeneity. We present a multi-task\nframework for automated multi-class fetal vessel segmentation from 3D black\nblood T2w MRI and anomaly classification. Our training data consists of binary\nmanual segmentation masks of the cardiac vessels' region in individual subjects\nand fully-labelled anomaly-specific population atlases. Our framework combines\ndeep learning label propagation using VoxelMorph with 3D Attention U-Net\nsegmentation and DenseNet121 anomaly classification. We target 11 cardiac\nvessels and three distinct aortic arch anomalies, including double aortic arch,\nright aortic arch, and suspected coarctation of the aorta. We incorporate an\nanomaly classifier into our segmentation pipeline, delivering a multi-task\nframework with the primary motivation of correcting topological inaccuracies of\nthe segmentation. The hypothesis is that the multi-task approach will encourage\nthe segmenter network to learn anomaly-specific features. As a secondary\nmotivation, an automated diagnosis tool may have the potential to enhance\ndiagnostic confidence in a decision support setting. Our results showcase that\nour proposed training strategy significantly outperforms label propagation and\na network trained exclusively on propagated labels. Our classifier outperforms\na classifier trained exclusively on T2w volume images, with an average balanced\naccuracy of 0.99 (0.01) after joint training. Adding a classifier improves the\nanatomical and topological accuracy of all correctly classified double aortic\narch subjects.",
            "author": [
                "Paula Ramirez",
                "Alena Uus",
                "Milou P. M. van Poppel",
                "Irina Grigorescu",
                "Johannes K. Steinweg",
                "David F. A. Lloyd",
                "Kuberan Pushparajah",
                "Andrew P. King",
                "Maria Deprez"
            ],
            "link": [
                "http://dx.doi.org/10.59275/j.melba.2023-b7bc",
                "http://arxiv.org/abs/2311.07234v1",
                "http://arxiv.org/pdf/2311.07234v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07232v1",
            "title": "Observational Detection of Higher Order Secular Perturbations in Tight\n  Hierarchical Triple Stars",
            "updated": "2023-11-13T10:52:47Z",
            "published": "2023-11-13T10:52:47Z",
            "summary": "In this work, we search for observational evidence of higher-order secular\nperturbations in three eclipsing binaries. These are slightly eccentric\nbinaries, and they form the inner pairs of tight, compact, hierarchical triple\nstar systems. We analyze simultaneously the high precision satellite ($Kepler$\nand $TESS$) light curves, eclipse timing variations, combined spectral energy\ndistributions (through catalog passband magnitudes) and, where available,\nradial velocities of KICs 9714358, 5771589 and TIC 219885468. Besides the\ndetermination of robust astrophysical and dynamical properties of the three\nsystems, we find evidence that the observed unusual eclipse timing variations\nof KIC 9714358 are a direct consequence of the octupole-order secular\neccentricity perturbations forced by an unusual, resonant behaviour between the\nlines of the apsides of the inner and outer orbital ellipses. We also show\nthat, despite its evident cyclic eclipse depth variations, KIC~5771589 is an\nalmost perfectly coplanar system (to within $0.3^\\circ$), and we explain the\nrapid eclipse depth variations with the grazing nature of the eclipses.\nFinally, we find that the inner pair of TIC~219885468 consists of two twin\nstars and, hence, in this triple there are no octupole order three-body\nperturbations. Moreover, we show that this triple is also coplanar on the same\nlevel as the former one, but due to its deep eclipses, it does not exhibit\neclipse depth variations. We intend to follow this work up with further\nanalyses and a quantitative comparison of the theoretical and the observed\nperturbations.",
            "author": [
                "Tam\u00e1s Borkovits",
                "Tibor Mitnyan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07232v1",
                "http://arxiv.org/pdf/2311.07232v1"
            ],
            "primary_category": "astro-ph.SR",
            "category": [
                "astro-ph.SR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07231v1",
            "title": "Error Analysis of Option Pricing via Deep PDE Solvers: Empirical Study",
            "updated": "2023-11-13T10:52:44Z",
            "published": "2023-11-13T10:52:44Z",
            "summary": "Option pricing, a fundamental problem in finance, often requires solving\nnon-linear partial differential equations (PDEs). When dealing with multi-asset\noptions, such as rainbow options, these PDEs become high-dimensional, leading\nto challenges posed by the curse of dimensionality. While deep learning-based\nPDE solvers have recently emerged as scalable solutions to this\nhigh-dimensional problem, their empirical and quantitative accuracy remains not\nwell-understood, hindering their real-world applicability. In this study, we\naimed to offer actionable insights into the utility of Deep PDE solvers for\npractical option pricing implementation. Through comparative experiments, we\nassessed the empirical performance of these solvers in high-dimensional\ncontexts. Our investigation identified three primary sources of errors in Deep\nPDE solvers: (i) errors inherent in the specifications of the target option and\nunderlying assets, (ii) errors originating from the asset model simulation\nmethods, and (iii) errors stemming from the neural network training. Through\nablation studies, we evaluated the individual impact of each error source. Our\nresults indicate that the Deep BSDE method (DBSDE) is superior in performance\nand exhibits robustness against variations in option specifications. In\ncontrast, some other methods are overly sensitive to option specifications,\nsuch as time to expiration. We also find that the performance of these methods\nimproves inversely proportional to the square root of batch size and the number\nof time steps. This observation can aid in estimating computational resources\nfor achieving desired accuracies with Deep PDE solvers.",
            "author": [
                "Rawin Assabumrungrat",
                "Kentaro Minami",
                "Masanori Hirano"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07231v1",
                "http://arxiv.org/pdf/2311.07231v1"
            ],
            "primary_category": "q-fin.CP",
            "category": [
                "q-fin.CP",
                "cs.LG",
                "cs.NA",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07230v1",
            "title": "How are Prompts Different in Terms of Sensitivity?",
            "updated": "2023-11-13T10:52:01Z",
            "published": "2023-11-13T10:52:01Z",
            "summary": "In-context learning (ICL) has become one of the most popular learning\nparadigms. While there is a growing body of literature focusing on prompt\nengineering, there is a lack of systematic analysis comparing the effects of\nprompts across different models and tasks. To address this gap, we present a\ncomprehensive prompt analysis based on the sensitivity of a function. Our\nanalysis reveals that sensitivity is an unsupervised proxy for model\nperformance, as it exhibits a strong negative correlation with accuracy. We use\ngradient-based saliency scores to empirically demonstrate how different prompts\naffect the relevance of input tokens to the output, resulting in different\nlevels of sensitivity. Furthermore, we introduce sensitivity-aware decoding\nwhich incorporates sensitivity estimation as a penalty term in the standard\ngreedy decoding. We show that this approach is particularly helpful when\ninformation in the input is scarce. Our work provides a fresh perspective on\nthe analysis of prompts, and contributes to a better understanding of the\nmechanism of ICL.",
            "author": [
                "Sheng Lu",
                "Hendrik Schuff",
                "Iryna Gurevych"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07230v1",
                "http://arxiv.org/pdf/2311.07230v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07226v1",
            "title": "Large Language Models for Robotics: A Survey",
            "updated": "2023-11-13T10:46:35Z",
            "published": "2023-11-13T10:46:35Z",
            "summary": "The human ability to learn, generalize, and control complex manipulation\ntasks through multi-modality feedback suggests a unique capability, which we\nrefer to as dexterity intelligence. Understanding and assessing this\nintelligence is a complex task. Amidst the swift progress and extensive\nproliferation of large language models (LLMs), their applications in the field\nof robotics have garnered increasing attention. LLMs possess the ability to\nprocess and generate natural language, facilitating efficient interaction and\ncollaboration with robots. Researchers and engineers in the field of robotics\nhave recognized the immense potential of LLMs in enhancing robot intelligence,\nhuman-robot interaction, and autonomy. Therefore, this comprehensive review\naims to summarize the applications of LLMs in robotics, delving into their\nimpact and contributions to key areas such as robot control, perception,\ndecision-making, and path planning. We first provide an overview of the\nbackground and development of LLMs for robotics, followed by a description of\nthe benefits of LLMs for robotics and recent advancements in robotics models\nbased on LLMs. We then delve into the various techniques used in the model,\nincluding those employed in perception, decision-making, control, and\ninteraction. Finally, we explore the applications of LLMs in robotics and some\npotential challenges they may face in the near future. Embodied intelligence is\nthe future of intelligent science, and LLMs-based robotics is one of the\npromising but challenging paths to achieve this.",
            "author": [
                "Fanlong Zeng",
                "Wensheng Gan",
                "Yongheng Wang",
                "Ning Liu",
                "Philip S. Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07226v1",
                "http://arxiv.org/pdf/2311.07226v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07222v2",
            "title": "Neural General Circulation Models",
            "updated": "2023-11-28T05:29:19Z",
            "published": "2023-11-13T10:40:17Z",
            "summary": "General circulation models (GCMs) are the foundation of weather and climate\nprediction. GCMs are physics-based simulators which combine a numerical solver\nfor large-scale dynamics with tuned representations for small-scale processes\nsuch as cloud formation. Recently, machine learning (ML) models trained on\nreanalysis data achieved comparable or better skill than GCMs for deterministic\nweather forecasting. However, these models have not demonstrated improved\nensemble forecasts, or shown sufficient stability for long-term weather and\nclimate simulations. Here we present the first GCM that combines a\ndifferentiable solver for atmospheric dynamics with ML components, and show\nthat it can generate forecasts of deterministic weather, ensemble weather and\nclimate on par with the best ML and physics-based methods. NeuralGCM is\ncompetitive with ML models for 1-10 day forecasts, and with the European Centre\nfor Medium-Range Weather Forecasts ensemble prediction for 1-15 day forecasts.\nWith prescribed sea surface temperature, NeuralGCM can accurately track climate\nmetrics such as global mean temperature for multiple decades, and climate\nforecasts with 140 km resolution exhibit emergent phenomena such as realistic\nfrequency and trajectories of tropical cyclones. For both weather and climate,\nour approach offers orders of magnitude computational savings over conventional\nGCMs. Our results show that end-to-end deep learning is compatible with tasks\nperformed by conventional GCMs, and can enhance the large-scale physical\nsimulations that are essential for understanding and predicting the Earth\nsystem.",
            "author": [
                "Dmitrii Kochkov",
                "Janni Yuval",
                "Ian Langmore",
                "Peter Norgaard",
                "Jamie Smith",
                "Griffin Mooers",
                "James Lottes",
                "Stephan Rasp",
                "Peter D\u00fcben",
                "Milan Kl\u00f6wer",
                "Sam Hatfield",
                "Peter Battaglia",
                "Alvaro Sanchez-Gonzalez",
                "Matthew Willson",
                "Michael P. Brenner",
                "Stephan Hoyer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07222v2",
                "http://arxiv.org/pdf/2311.07222v2"
            ],
            "primary_category": "physics.ao-ph",
            "category": [
                "physics.ao-ph",
                "cs.LG",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08426v1",
            "title": "Non-Contact Breathing Rate Detection Using Optical Flow",
            "updated": "2023-11-13T10:26:18Z",
            "published": "2023-11-13T10:26:18Z",
            "summary": "Breathing rate is a vital health metric that is an invaluable indicator of\nthe overall health of a person. In recent years, the non-contact measurement of\nhealth signals such as breathing rate has been a huge area of development, with\na wide range of applications from telemedicine to driver monitoring systems.\nThis paper presents an investigation into a method of non-contact breathing\nrate detection using a motion detection algorithm, optical flow. Optical flow\nis used to successfully measure breathing rate by tracking the motion of\nspecific points on the body. In this study, the success of optical flow when\nusing different sets of points is evaluated. Testing shows that both chest and\nfacial movement can be used to determine breathing rate but to different\ndegrees of success. The chest generates very accurate signals, with an RMSE of\n0.63 on the tested videos. Facial points can also generate reliable signals\nwhen there is minimal head movement but are much more vulnerable to noise\ncaused by head/body movements. These findings highlight the potential of\noptical flow as a non-invasive method for breathing rate detection and\nemphasize the importance of selecting appropriate points to optimize accuracy.",
            "author": [
                "Robyn Maxwell",
                "Timothy Hanley",
                "Dara Golden",
                "Adara Andonie",
                "Joseph Lemley",
                "Ashkan Parsi"
            ],
            "link": [
                "http://dx.doi.org/10.5281/zenodo.8238518",
                "http://arxiv.org/abs/2311.08426v1",
                "http://arxiv.org/pdf/2311.08426v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07216v1",
            "title": "Few Shot Learning for the Classification of Confocal Laser\n  Endomicroscopy Images of Head and Neck Tumors",
            "updated": "2023-11-13T10:17:00Z",
            "published": "2023-11-13T10:17:00Z",
            "summary": "The surgical removal of head and neck tumors requires safe margins, which are\nusually confirmed intraoperatively by means of frozen sections. This method is,\nin itself, an oversampling procedure, which has a relatively low sensitivity\ncompared to the definitive tissue analysis on paraffin-embedded sections.\nConfocal laser endomicroscopy (CLE) is an in-vivo imaging technique that has\nshown its potential in the live optical biopsy of tissue. An automated analysis\nof this notoriously difficult to interpret modality would help surgeons.\nHowever, the images of CLE show a wide variability of patterns, caused both by\nindividual factors but also, and most strongly, by the anatomical structures of\nthe imaged tissue, making it a challenging pattern recognition task. In this\nwork, we evaluate four popular few shot learning (FSL) methods towards their\ncapability of generalizing to unseen anatomical domains in CLE images. We\nevaluate this on images of sinunasal tumors (SNT) from five patients and on\nimages of the vocal folds (VF) from 11 patients using a cross-validation\nscheme. The best respective approach reached a median accuracy of 79.6% on the\nrather homogeneous VF dataset, but only of 61.6% for the highly diverse SNT\ndataset. Our results indicate that FSL on CLE images is viable, but strongly\naffected by the number of patients, as well as the diversity of anatomical\npatterns.",
            "author": [
                "Marc Aubreville",
                "Zhaoya Pan",
                "Matti Sievert",
                "Jonas Ammeling",
                "Jonathan Ganz",
                "Nicolai Oetter",
                "Florian Stelzle",
                "Ann-Kathrin Frenken",
                "Katharina Breininger",
                "Miguel Goncalves"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07216v1",
                "http://arxiv.org/pdf/2311.07216v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07213v1",
            "title": "A method for quantifying sectoral optic disc pallor in fundus\n  photographs and its association with peripapillary RNFL thickness",
            "updated": "2023-11-13T10:13:59Z",
            "published": "2023-11-13T10:13:59Z",
            "summary": "Purpose: To develop an automatic method of quantifying optic disc pallor in\nfundus photographs and determine associations with peripapillary retinal nerve\nfibre layer (pRNFL) thickness.\n  Methods: We used deep learning to segment the optic disc, fovea, and vessels\nin fundus photographs, and measured pallor. We assessed the relationship\nbetween pallor and pRNFL thickness derived from optical coherence tomography\nscans in 118 participants. Separately, we used images diagnosed by clinical\ninspection as pale (N=45) and assessed how measurements compared to healthy\ncontrols (N=46). We also developed automatic rejection thresholds, and tested\nthe software for robustness to camera type, image format, and resolution.\n  Results: We developed software that automatically quantified disc pallor\nacross several zones in fundus photographs. Pallor was associated with pRNFL\nthickness globally (\\b{eta} = -9.81 (SE = 3.16), p < 0.05), in the temporal\ninferior zone (\\b{eta} = -29.78 (SE = 8.32), p < 0.01), with the nasal/temporal\nratio (\\b{eta} = 0.88 (SE = 0.34), p < 0.05), and in the whole disc (\\b{eta} =\n-8.22 (SE = 2.92), p < 0.05). Furthermore, pallor was significantly higher in\nthe patient group. Lastly, we demonstrate the analysis to be robust to camera\ntype, image format, and resolution.\n  Conclusions: We developed software that automatically locates and quantifies\ndisc pallor in fundus photographs and found associations between pallor\nmeasurements and pRNFL thickness.\n  Translational relevance: We think our method will be useful for the\nidentification, monitoring and progression of diseases characterized by disc\npallor/optic atrophy, including glaucoma, compression, and potentially in\nneurodegenerative disorders.",
            "author": [
                "Samuel Gibbon",
                "Graciela Muniz-Terrera",
                "Fabian SL Yii",
                "Charlene Hamid",
                "Simon Cox",
                "Ian JC Maccormick",
                "Andrew J Tatham",
                "Craig Ritchie",
                "Emanuele Trucco",
                "Baljean Dhillon",
                "Thomas J MacGillivray"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07213v1",
                "http://arxiv.org/pdf/2311.07213v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07211v2",
            "title": "A Gaussian Process Based Method with Deep Kernel Learning for Pricing\n  High-dimensional American Options",
            "updated": "2023-11-22T05:48:06Z",
            "published": "2023-11-13T10:13:50Z",
            "summary": "Machine learning methods, such as Gaussian process regression (GPR), have\nbeen widely used in recent years for pricing American options. GPR is\nconsidered as a potential method for estimating the continuation value of an\noption in the regression-based Monte Carlo method. However, it has some\ndrawbacks, such as the unreliability in high-dimensional cases and the high\ncomputational cost when the number of simulated paths is large. In this paper,\nwe apply the deep kernel learning and variational inference to GPR in order to\novercome these drawbacks, and test its performance under geometric Brownian\nmotion and Merton's jump diffusion models. The experiments show that the\nproposed method outperforms the Least Square Monte Carlo method in\nhigh-dimensional cases, especially with jump diffusion models.",
            "author": [
                "Jirong Zhuang",
                "Deng Ding",
                "Weiguo Lu",
                "Xuan Wu",
                "Gangnan Yuan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07211v2",
                "http://arxiv.org/pdf/2311.07211v2"
            ],
            "primary_category": "q-fin.CP",
            "category": [
                "q-fin.CP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07204v1",
            "title": "On Elastic Language Models",
            "updated": "2023-11-13T09:55:52Z",
            "published": "2023-11-13T09:55:52Z",
            "summary": "Large-scale pretrained language models have achieved compelling performance\nin a wide range of language understanding and information retrieval tasks.\nKnowledge distillation offers an opportunity to compress a large language model\nto a small one, in order to reach a reasonable latency-performance tradeoff.\nHowever, for scenarios where the number of requests (e.g., queries submitted to\na search engine) is highly variant, the static tradeoff attained by the\ncompressed language model might not always fit. Once a model is assigned with a\nstatic tradeoff, it could be inadequate in that the latency is too high when\nthe number of requests is large or the performance is too low when the number\nof requests is small. To this end, we propose an elastic language model\n(ElasticLM) that elastically adjusts the tradeoff according to the request\nstream. The basic idea is to introduce a compute elasticity to the compressed\nlanguage model, so that the tradeoff could vary on-the-fly along scalable and\ncontrollable compute. Specifically, we impose an elastic structure to enable\nElasticLM with compute elasticity and design an elastic optimization to learn\nElasticLM under compute elasticity. To serve ElasticLM, we apply an elastic\nschedule. Considering the specificity of information retrieval, we adapt\nElasticLM to dense retrieval and reranking and present ElasticDenser and\nElasticRanker respectively. Offline evaluation is conducted on a language\nunderstanding benchmark GLUE; and several information retrieval tasks including\nNatural Question, Trivia QA, and MS MARCO. The results show that ElasticLM\nalong with ElasticDenser and ElasticRanker can perform correctly and\ncompetitively compared with an array of static baselines. Furthermore, online\nsimulation with concurrency is also carried out. The results demonstrate that\nElasticLM can provide elastic tradeoffs with respect to varying request stream.",
            "author": [
                "Chen Zhang",
                "Benyou Wang",
                "Dawei Song"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07204v1",
                "http://arxiv.org/pdf/2311.07204v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07630v1",
            "title": "Cross-modal Generative Model for Visual-Guided Binaural Stereo\n  Generation",
            "updated": "2023-11-13T09:53:14Z",
            "published": "2023-11-13T09:53:14Z",
            "summary": "Binaural stereo audio is recorded by imitating the way the human ear receives\nsound, which provides people with an immersive listening experience. Existing\napproaches leverage autoencoders and directly exploit visual spatial\ninformation to synthesize binaural stereo, resulting in a limited\nrepresentation of visual guidance. For the first time, we propose a visually\nguided generative adversarial approach for generating binaural stereo audio\nfrom mono audio. Specifically, we develop a Stereo Audio Generation Model\n(SAGM), which utilizes shared spatio-temporal visual information to guide the\ngenerator and the discriminator to work separately. The shared visual\ninformation is updated alternately in the generative adversarial stage,\nallowing the generator and discriminator to deliver their respective guided\nknowledge while visually sharing. The proposed method learns bidirectional\ncomplementary visual information, which facilitates the expression of visual\nguidance in generation. In addition, spatial perception is a crucial attribute\nof binaural stereo audio, and thus the evaluation of stereo spatial perception\nis essential. However, previous metrics failed to measure the spatial\nperception of audio. To this end, a metric to measure the spatial perception of\naudio is proposed for the first time. The proposed metric is capable of\nmeasuring the magnitude and direction of spatial perception in the temporal\ndimension. Further, considering its function, it is feasible to utilize it\ninstead of demanding user studies to some extent. The proposed method achieves\nstate-of-the-art performance on 2 datasets and 5 evaluation metrics.\nQualitative experiments and user studies demonstrate that the method generates\nspace-realistic stereo audio.",
            "author": [
                "Zhaojian Li",
                "Bin Zhao",
                "Yuan Yuan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07630v1",
                "http://arxiv.org/pdf/2311.07630v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.CV",
                "cs.LG",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07203v1",
            "title": "Optical Quantum Sensing for Agnostic Environments via Deep Learning",
            "updated": "2023-11-13T09:46:05Z",
            "published": "2023-11-13T09:46:05Z",
            "summary": "Optical quantum sensing promises measurement precision beyond classical\nsensors termed the Heisenberg limit (HL). However, conventional methodologies\noften rely on prior knowledge of the target system to achieve HL, presenting\nchallenges in practical applications. Addressing this limitation, we introduce\nan innovative Deep Learning-based Quantum Sensing scheme (DQS), enabling\noptical quantum sensors to attain HL in agnostic environments. DQS incorporates\ntwo essential components: a Graph Neural Network (GNN) predictor and a\ntrigonometric interpolation algorithm. Operating within a data-driven paradigm,\nDQS utilizes the GNN predictor, trained on offline data, to unveil the\nintrinsic relationships between the optical setups employed in preparing the\nprobe state and the resulting quantum Fisher information (QFI) after\ninteraction with the agnostic environment. This distilled knowledge facilitates\nthe identification of optimal optical setups associated with maximal QFI.\nSubsequently, DQS employs a trigonometric interpolation algorithm to recover\nthe unknown parameter estimates for the identified optical setups. Extensive\nexperiments are conducted to investigate the performance of DQS under different\nsettings up to eight photons. Our findings not only offer a new lens through\nwhich to accelerate optical quantum sensing tasks but also catalyze future\nresearch integrating deep learning and quantum mechanics.",
            "author": [
                "Zeqiao Zhou",
                "Yuxuan Du",
                "Xu-Fei Yin",
                "Shanshan Zhao",
                "Xinmei Tian",
                "Dacheng Tao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07203v1",
                "http://arxiv.org/pdf/2311.07203v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.AI",
                "physics.optics"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07202v1",
            "title": "Input Convex LSTM: A Convex Approach for Fast Lyapunov-Based Model\n  Predictive Control",
            "updated": "2023-11-13T09:41:32Z",
            "published": "2023-11-13T09:41:32Z",
            "summary": "Leveraging Input Convex Neural Networks (ICNNs), ICNN-based Model Predictive\nControl (MPC) successfully attains globally optimal solutions by upholding\nconvexity within the MPC framework. However, current ICNN architectures\nencounter the issue of vanishing gradients, which limits their ability to serve\nas deep neural networks for complex tasks. Additionally, the current neural\nnetwork-based MPC, including conventional neural network-based MPC and\nICNN-based MPC, faces slower convergence speed when compared to MPC based on\nfirst-principles models. In this study, we leverage the principles of ICNNs to\npropose a novel Input Convex LSTM for Lyapunov-based MPC, with the specific\ngoal of reducing convergence time and mitigating the vanishing gradient problem\nwhile ensuring closed-loop stability. From a simulation study of a nonlinear\nchemical reactor, we observed a mitigation of vanishing gradient problem and a\nreduction in convergence time, with a percentage decrease of 46.7%, 31.3%, and\n20.2% compared to baseline plain RNN, plain LSTM, and Input Convex Recurrent\nNeural Network, respectively.",
            "author": [
                "Zihao Wang",
                "Zhe Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07202v1",
                "http://arxiv.org/pdf/2311.07202v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CE",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07200v2",
            "title": "Normalising Flows for Bayesian Gravity Inversion",
            "updated": "2023-11-28T12:07:09Z",
            "published": "2023-11-13T09:40:53Z",
            "summary": "Gravity inversion is a commonly applied data analysis technique in the field\nof geophysics. While machine learning methods have previously been explored for\nthe problem of gravity inversion, these are deterministic approaches returning\na single solution deemed most appropriate by the algorithm. The method\npresented here takes a different approach, where gravity inversion is\nreformulated as a Bayesian parameter inference problem. Samples from the\nposterior probability distribution of source model parameters are obtained via\nthe implementation of a generative neural network architecture known as\nNormalising Flows. Due to its probabilistic nature, this framework provides the\nuser with a range of source parameters and uncertainties instead of a single\nsolution, and is inherently robust against instrumental noise. The performance\nof the Normalising Flow is compared to that of an established Bayesian method\ncalled Nested Sampling. It is shown that the new method returns results with\ncomparable accuracy 200 times faster than standard sampling methods, which\nmakes Normalising Flows a suitable method for real-time inversion in the field.\nWhen applied to data sets with high dimensionality, standard sampling methods\ncan become impractical due to long computation times. It is shown that\ninversion using Normalising Flows remains tractable even at 512 dimensions and\nonce the network is trained, the results can be obtained in $O(10)$ seconds.",
            "author": [
                "Henrietta Rakoczi",
                "Abhinav Prasad",
                "Karl Toland",
                "Christopher Messenger",
                "Giles Hammond"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07200v2",
                "http://arxiv.org/pdf/2311.07200v2"
            ],
            "primary_category": "physics.geo-ph",
            "category": [
                "physics.geo-ph",
                "physics.comp-ph",
                "physics.data-an"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07191v1",
            "title": "Applying Large Language Models for Causal Structure Learning in Non\n  Small Cell Lung Cancer",
            "updated": "2023-11-13T09:31:14Z",
            "published": "2023-11-13T09:31:14Z",
            "summary": "Causal discovery is becoming a key part in medical AI research. These methods\ncan enhance healthcare by identifying causal links between biomarkers,\ndemographics, treatments and outcomes. They can aid medical professionals in\nchoosing more impactful treatments and strategies. In parallel, Large Language\nModels (LLMs) have shown great potential in identifying patterns and generating\ninsights from text data. In this paper we investigate applying LLMs to the\nproblem of determining the directionality of edges in causal discovery.\nSpecifically, we test our approach on a deidentified set of Non Small Cell Lung\nCancer(NSCLC) patients that have both electronic health record and genomic\npanel data. Graphs are validated using Bayesian Dirichlet estimators using\ntabular data. Our result shows that LLMs can accurately predict the\ndirectionality of edges in causal graphs, outperforming existing\nstate-of-the-art methods. These findings suggests that LLMs can play a\nsignificant role in advancing causal discovery and help us better understand\ncomplex systems.",
            "author": [
                "Narmada Naik",
                "Ayush Khandelwal",
                "Mohit Joshi",
                "Madhusudan Atre",
                "Hollis Wright",
                "Kavya Kannan",
                "Scott Hill",
                "Giridhar Mamidipudi",
                "Ganapati Srinivasa",
                "Carlo Bifulco",
                "Brian Piening",
                "Kevin Matlock"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07191v1",
                "http://arxiv.org/pdf/2311.07191v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07180v1",
            "title": "Knowledge Graph Representations to enhance Intensive Care Time-Series\n  Predictions",
            "updated": "2023-11-13T09:11:55Z",
            "published": "2023-11-13T09:11:55Z",
            "summary": "Intensive Care Units (ICU) require comprehensive patient data integration for\nenhanced clinical outcome predictions, crucial for assessing patient\nconditions. Recent deep learning advances have utilized patient time series\ndata, and fusion models have incorporated unstructured clinical reports,\nimproving predictive performance. However, integrating established medical\nknowledge into these models has not yet been explored. The medical domain's\ndata, rich in structural relationships, can be harnessed through knowledge\ngraphs derived from clinical ontologies like the Unified Medical Language\nSystem (UMLS) for better predictions. Our proposed methodology integrates this\nknowledge with ICU data, improving clinical decision modeling. It combines\ngraph representations with vital signs and clinical reports, enhancing\nperformance, especially when data is missing. Additionally, our model includes\nan interpretability component to understand how knowledge graph nodes affect\npredictions.",
            "author": [
                "Samyak Jain",
                "Manuel Burger",
                "Gunnar R\u00e4tsch",
                "Rita Kuznetsova"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07180v1",
                "http://arxiv.org/pdf/2311.07180v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07179v1",
            "title": "SponTTS: modeling and transferring spontaneous style for TTS",
            "updated": "2023-11-13T09:11:27Z",
            "published": "2023-11-13T09:11:27Z",
            "summary": "Spontaneous speaking style exhibits notable differences from other speaking\nstyles due to various spontaneous phenomena (e.g., filled pauses, prolongation)\nand substantial prosody variation (e.g., diverse pitch and duration variation,\noccasional non-verbal speech like smile), posing challenges to modeling and\nprediction of spontaneous style. Moreover, the limitation of high-quality\nspontaneous data constrains spontaneous speech generation for speakers without\nspontaneous data. To address these problems, we propose SponTTS, a two-stage\napproach based on bottleneck (BN) features to model and transfer spontaneous\nstyle for TTS. In the first stage, we adopt a Conditional Variational\nAutoencoder (CVAE) to capture spontaneous prosody from a BN feature and involve\nthe spontaneous phenomena by the constraint of spontaneous phenomena embedding\nprediction loss. Besides, we introduce a flow-based predictor to predict a\nlatent spontaneous style representation from the text, which enriches the\nprosody and context-specific spontaneous phenomena during inference. In the\nsecond stage, we adopt a VITS-like module to transfer the spontaneous style\nlearned in the first stage to target speakers. Experiments demonstrate that\nSponTTS is effective in modeling spontaneous style and transferring the style\nto the target speakers, generating spontaneous speech with high naturalness,\nexpressiveness, and speaker similarity. The zero-shot spontaneous style TTS\ntest further verifies the generalization and robustness of SponTTS in\ngenerating spontaneous speech for unseen speakers.",
            "author": [
                "Hanzhao Li",
                "Xinfa Zhu",
                "Liumeng Xue",
                "Yang Song",
                "Yunlin Chen",
                "Lei Xie"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07179v1",
                "http://arxiv.org/pdf/2311.07179v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07178v1",
            "title": "Game Solving with Online Fine-Tuning",
            "updated": "2023-11-13T09:09:52Z",
            "published": "2023-11-13T09:09:52Z",
            "summary": "Game solving is a similar, yet more difficult task than mastering a game.\nSolving a game typically means to find the game-theoretic value (outcome given\noptimal play), and optionally a full strategy to follow in order to achieve\nthat outcome. The AlphaZero algorithm has demonstrated super-human level play,\nand its powerful policy and value predictions have also served as heuristics in\ngame solving. However, to solve a game and obtain a full strategy, a winning\nresponse must be found for all possible moves by the losing player. This\nincludes very poor lines of play from the losing side, for which the AlphaZero\nself-play process will not encounter. AlphaZero-based heuristics can be highly\ninaccurate when evaluating these out-of-distribution positions, which occur\nthroughout the entire search. To address this issue, this paper investigates\napplying online fine-tuning while searching and proposes two methods to learn\ntailor-designed heuristics for game solving. Our experiments show that using\nonline fine-tuning can solve a series of challenging 7x7 Killall-Go problems,\nusing only 23.54% of computation time compared to the baseline without online\nfine-tuning. Results suggest that the savings scale with problem size. Our\nmethod can further be extended to any tree search algorithm for problem\nsolving. Our code is available at\nhttps://rlg.iis.sinica.edu.tw/papers/neurips2023-online-fine-tuning-solver.",
            "author": [
                "Ti-Rong Wu",
                "Hung Guei",
                "Ting Han Wei",
                "Chung-Chin Shih",
                "Jui-Te Chin",
                "I-Chen Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07178v1",
                "http://arxiv.org/pdf/2311.07178v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.GT",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07175v1",
            "title": "Research and experimental verification on low-frequency long-range sound\n  propagation characteristics under ice-covered and range-dependent marine\n  environment in the Arctic",
            "updated": "2023-11-13T09:08:50Z",
            "published": "2023-11-13T09:08:50Z",
            "summary": "At present, research on sound propagation under the Arctic ice mainly focuses\non modeling and experimental verification of sound propagation under sea ice\ncover and unique sound velocity profiles. Among them, the main research object\nof concern is sound transmission loss, and this article will delve into the\ntime-domain waveform and fine dispersion structure of low-frequency broadband\nacoustic signals. Firstly, based on the theory of normal modes, this article\nderives the horizontal wavenumber expression and warping transformation\noperator for refractive normal modes in the Arctic deep-sea environment.\nSubsequently, based on measured ocean environmental parameters and sound field\nsimulation calculations, this article studied the general laws of low-frequency\nlong-range sound propagation signals in the Arctic deep-sea environment, and\nelucidated the impact mechanism of environmental factors such as seabed terrain\nchanges, horizontal changes in sound velocity profiles (SSPs), and sea ice\ncover on low-frequency long-range sound propagation in the Arctic. This article\nvalidates the above research viewpoint through a sound propagation experiment\nconducted in the Arctic with a propagation distance exceeding 1000km. The\nmarine environment of this experiment has obvious horizontal variation\ncharacteristics. At the same time, this article takes the lead in utilizing the\nwarping transformation of refractive normal waves in the Arctic waters to\nachieve single hydrophone based separation of normal waves and extraction of\ndispersion structures, which is conducive to future research on underwater\nsound source localization and environmental parameter inversion based on\ndispersion structures.",
            "author": [
                "Jinbao Weng",
                "Yubo Qi",
                "Yanming Yang",
                "Hongtao Wen",
                "Hongtao Zhou",
                "Ruichao Xue"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07175v1",
                "http://arxiv.org/pdf/2311.07175v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.NA",
                "math.NA",
                "physics.ao-ph",
                "physics.app-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07170v1",
            "title": "Regenerating Arbitrary Video Sequences with Distillation Path-Finding",
            "updated": "2023-11-13T09:05:30Z",
            "published": "2023-11-13T09:05:30Z",
            "summary": "If the video has long been mentioned as a widespread visualization form, the\nanimation sequence in the video is mentioned as storytelling for people.\nProducing an animation requires intensive human labor from skilled professional\nartists to obtain plausible animation in both content and motion direction,\nincredibly for animations with complex content, multiple moving objects, and\ndense movement. This paper presents an interactive framework to generate new\nsequences according to the users' preference on the starting frame. The\ncritical contrast of our approach versus prior work and existing commercial\napplications is that novel sequences with arbitrary starting frame are produced\nby our system with a consistent degree in both content and motion direction. To\nachieve this effectively, we first learn the feature correlation on the\nframeset of the given video through a proposed network called RSFNet. Then, we\ndevelop a novel path-finding algorithm, SDPF, which formulates the knowledge of\nmotion directions of the source video to estimate the smooth and plausible\nsequences. The extensive experiments show that our framework can produce new\nanimations on the cartoon and natural scenes and advance prior works and\ncommercial applications to enable users to obtain more predictable results.",
            "author": [
                "Thi-Ngoc-Hanh Le",
                "Sheng-Yi Yao",
                "Chun-Te Wu",
                "Tong-Yee Lee"
            ],
            "link": [
                "http://dx.doi.org/10.1109/TVCG.2023.3237739",
                "http://arxiv.org/abs/2311.07170v1",
                "http://arxiv.org/pdf/2311.07170v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07167v1",
            "title": "STEER: Unified Style Transfer with Expert Reinforcement",
            "updated": "2023-11-13T09:02:30Z",
            "published": "2023-11-13T09:02:30Z",
            "summary": "While text style transfer has many applications across natural language\nprocessing, the core premise of transferring from a single source style is\nunrealistic in a real-world setting. In this work, we focus on arbitrary style\ntransfer: rewriting a text from an arbitrary, unknown style to a target style.\n  We propose STEER: Unified Style Transfer with Expert Reinforcement, a unified\nframe-work developed to overcome the challenge of limited parallel data for\nstyle transfer. STEER involves automatically generating a corpus of\nstyle-transfer pairs using a product of experts during decoding. The generated\noffline data is then used to pre-train an initial policy before switching to\nonline, off-policy reinforcement learning for further improvements via\nfine-grained reward signals. STEER is unified and can transfer to multiple\ntarget styles from an arbitrary, unknown source style, making it particularly\nflexible and efficient.\n  Experimental results on a challenging dataset with text from a diverse set of\nstyles demonstrate state-of-the-art results compared to competitive baselines.\nRemarkably, STEER outperforms the 175B parameter instruction-tuned GPT-3 on\noverall style transfer quality, despite being 226 times smaller in size. We\nalso show STEER is robust, maintaining its style transfer capabilities on\nout-of-domain data, and surpassing nearly all baselines across various styles.\nThe success of our method highlights the potential of RL algorithms when\naugmented with controllable decoding to overcome the challenge of limited data\nsupervision.",
            "author": [
                "Skyler Hallinan",
                "Faeze Brahman",
                "Ximing Lu",
                "Jaehun Jung",
                "Sean Welleck",
                "Yejin Choi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07167v1",
                "http://arxiv.org/pdf/2311.07167v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07166v1",
            "title": "NDDepth: Normal-Distance Assisted Monocular Depth Estimation and\n  Completion",
            "updated": "2023-11-13T09:01:50Z",
            "published": "2023-11-13T09:01:50Z",
            "summary": "Over the past few years, monocular depth estimation and completion have been\npaid more and more attention from the computer vision community because of\ntheir widespread applications. In this paper, we introduce novel physics\n(geometry)-driven deep learning frameworks for these two tasks by assuming that\n3D scenes are constituted with piece-wise planes. Instead of directly\nestimating the depth map or completing the sparse depth map, we propose to\nestimate the surface normal and plane-to-origin distance maps or complete the\nsparse surface normal and distance maps as intermediate outputs. To this end,\nwe develop a normal-distance head that outputs pixel-level surface normal and\ndistance. Meanwhile, the surface normal and distance maps are regularized by a\ndeveloped plane-aware consistency constraint, which are then transformed into\ndepth maps. Furthermore, we integrate an additional depth head to strengthen\nthe robustness of the proposed frameworks. Extensive experiments on the\nNYU-Depth-v2, KITTI and SUN RGB-D datasets demonstrate that our method exceeds\nin performance prior state-of-the-art monocular depth estimation and completion\ncompetitors. The source code will be available at\nhttps://github.com/ShuweiShao/NDDepth.",
            "author": [
                "Shuwei Shao",
                "Zhongcai Pei",
                "Weihai Chen",
                "Peter C. Y. Chen",
                "Zhengguo Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07166v1",
                "http://arxiv.org/pdf/2311.07166v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07162v1",
            "title": "CycleGANAS: Differentiable Neural Architecture Search for CycleGAN",
            "updated": "2023-11-13T08:56:56Z",
            "published": "2023-11-13T08:56:56Z",
            "summary": "We develop a Neural Architecture Search (NAS) framework for CycleGAN that\ncarries out unpaired image-to-image translation task. Extending previous NAS\ntechniques for Generative Adversarial Networks (GANs) to CycleGAN is not\nstraightforward due to the task difference and greater search space. We design\narchitectures that consist of a stack of simple ResNet-based cells and develop\na search method that effectively explore the large search space. We show that\nour framework, called CycleGANAS, not only effectively discovers\nhigh-performance architectures that either match or surpass the performance of\nthe original CycleGAN, but also successfully address the data imbalance by\nindividual architecture search for each translation direction. To our best\nknowledge, it is the first NAS result for CycleGAN and shed light on NAS for\nmore complex structures.",
            "author": [
                "Taegun An",
                "Changhee Joo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07162v1",
                "http://arxiv.org/pdf/2311.07162v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07161v1",
            "title": "Developing a Named Entity Recognition Dataset for Tagalog",
            "updated": "2023-11-13T08:56:47Z",
            "published": "2023-11-13T08:56:47Z",
            "summary": "We present the development of a Named Entity Recognition (NER) dataset for\nTagalog. This corpus helps fill the resource gap present in Philippine\nlanguages today, where NER resources are scarce. The texts were obtained from a\npretraining corpora containing news reports, and were labeled by native\nspeakers in an iterative fashion. The resulting dataset contains ~7.8k\ndocuments across three entity types: Person, Organization, and Location. The\ninter-annotator agreement, as measured by Cohen's $\\kappa$, is 0.81. We also\nconducted extensive empirical evaluation of state-of-the-art methods across\nsupervised and transfer learning settings. Finally, we released the data and\nprocessing code publicly to inspire future work on Tagalog NLP.",
            "author": [
                "Lester James V. Miranda"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07161v1",
                "http://arxiv.org/pdf/2311.07161v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.00024v1",
            "title": "Can LLMs Patch Security Issues?",
            "updated": "2023-11-13T08:54:37Z",
            "published": "2023-11-13T08:54:37Z",
            "summary": "Large Language Models (LLMs) have shown impressive proficiency in code\ngeneration. Nonetheless, similar to human developers, these models might\ngenerate code that contains security vulnerabilities and flaws. Writing secure\ncode remains a substantial challenge, as vulnerabilities often arise during\ninteractions between programs and external systems or services, such as\ndatabases and operating systems. In this paper, we propose a novel approach,\nFeedback-Driven Solution Synthesis (FDSS), designed to explore the use of LLMs\nin receiving feedback from Bandit, which is a static code analysis tool, and\nthen the LLMs generate potential solutions to resolve security vulnerabilities.\nEach solution, along with the vulnerable code, is then sent back to the LLM for\ncode refinement. Our approach shows a significant improvement over the baseline\nand outperforms existing approaches. Furthermore, we introduce a new dataset,\nPythonSecurityEval, collected from real-world scenarios on Stack Overflow to\nevaluate the LLMs' ability to generate secure code. Code and data are available\nat \\url{https://github.com/Kamel773/LLM-code-refine}",
            "author": [
                "Kamel Alrashedy",
                "Abdullah Aljasser"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00024v1",
                "http://arxiv.org/pdf/2312.00024v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07158v1",
            "title": "Investigating students' scientific reasoning through heuristic and\n  analytical thought processes",
            "updated": "2023-11-13T08:51:24Z",
            "published": "2023-11-13T08:51:24Z",
            "summary": "In recent years there has been growing evidence that even after teaching\ndesigned to address the learning difficulties dictated by literature, many\nphysics learners fail to create the proper reasoning chains that connect the\nfundamental principles and lead to reasoned predictions. Even though students\nhave the required knowledge and skills, they are often based on a variety of\nintuitive reasoning that leads them to wrong conclusions. This research studies\nstudents' reasoning on science problems through heuristic - analytical thought\nprocesses (System 1 - System 2). System 1 operates automatically and quickly\nwith little or no effort and no sense of voluntary control, while System 2\nfocuses on the demanding mental activities that require it and is slow based on\nrules. Specifically, we seek to study those cognitive processes and information\navailable to students when they face science problems and, therefore, to\nexplore the various heuristic processes that students use when solving physics\nproblems. Our results indicated four intuitive heuristics in students' minds\nwhen they solve problems in Mechanics and especially in the unit projectile\nmotion: associative activation, processing fluency, attribute substitution and\nanchoring effect. These heuristics prevent students from applying knowledge and\nmethods that they already possess to solve a physics problem.",
            "author": [
                "Dimitrios Gousopoulos"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07158v1",
                "http://arxiv.org/pdf/2311.07158v1"
            ],
            "primary_category": "physics.ed-ph",
            "category": [
                "physics.ed-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07156v1",
            "title": "Deep mixture of linear mixed models for complex longitudinal data",
            "updated": "2023-11-13T08:50:48Z",
            "published": "2023-11-13T08:50:48Z",
            "summary": "Mixtures of linear mixed models are widely used for modelling longitudinal\ndata for which observation times differ between subjects. In typical\napplications, temporal trends are described using a basis expansion, with basis\ncoefficients treated as random effects varying by subject. Additional random\neffects can describe variation between mixture components, or other known\nsources of variation in complex experimental designs. A key advantage of these\nmodels is that they provide a natural mechanism for clustering, which can be\nhelpful for interpretation in many applications. Current versions of mixtures\nof linear mixed models are not specifically designed for the case where there\nare many observations per subject and a complex temporal trend, which requires\na large number of basis functions to capture. In this case, the\nsubject-specific basis coefficients are a high-dimensional random effects\nvector, for which the covariance matrix is hard to specify and estimate,\nespecially if it varies between mixture components. To address this issue, we\nconsider the use of recently-developed deep mixture of factor analyzers models\nas the prior for the random effects. The resulting deep mixture of linear mixed\nmodels is well-suited to high-dimensional settings, and we describe an\nefficient variational inference approach to posterior computation. The efficacy\nof the method is demonstrated on both real and simulated data.",
            "author": [
                "Lucas Kock",
                "Nadja Klein",
                "David J. Nott"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07156v1",
                "http://arxiv.org/pdf/2311.07156v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07627v1",
            "title": "A Consistent Diffusion-Based Algorithm for Semi-Supervised Graph\n  Learning",
            "updated": "2023-11-13T08:42:17Z",
            "published": "2023-11-13T08:42:17Z",
            "summary": "The task of semi-supervised classification aims at assigning labels to all\nnodes of a graph based on the labels known for a few nodes, called the seeds.\nOne of the most popular algorithms relies on the principle of heat diffusion,\nwhere the labels of the seeds are spread by thermoconductance and the\ntemperature of each node at equilibrium is used as a score function for each\nlabel. In this paper, we prove that this algorithm is not consistent unless the\ntemperatures of the nodes at equilibrium are centered before scoring. This\ncrucial step does not only make the algorithm provably consistent on a block\nmodel but brings significant performance gains on real graphs.",
            "author": [
                "Thomas Bonald",
                "Nathan de Lara"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07627v1",
                "http://arxiv.org/pdf/2311.07627v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07626v1",
            "title": "Quantum Machine Learning for Remote Sensing: Exploring potential and\n  challenges",
            "updated": "2023-11-13T08:38:44Z",
            "published": "2023-11-13T08:38:44Z",
            "summary": "The industry of quantum technologies is rapidly expanding, offering promising\nopportunities for various scientific domains. Among these emerging\ntechnologies, Quantum Machine Learning (QML) has attracted considerable\nattention due to its potential to revolutionize data processing and analysis.\nIn this paper, we investigate the application of QML in the field of remote\nsensing. It is believed that QML can provide valuable insights for analysis of\ndata from space. We delve into the common beliefs surrounding the quantum\nadvantage in QML for remote sensing and highlight the open challenges that need\nto be addressed. To shed light on the challenges, we conduct a study focused on\nthe problem of kernel value concentration, a phenomenon that adversely affects\nthe runtime of quantum computers. Our findings indicate that while this issue\nnegatively impacts quantum computer performance, it does not entirely negate\nthe potential quantum advantage in QML for remote sensing.",
            "author": [
                "Artur Miroszewski",
                "Jakub Nalepa",
                "Bertrand Le Saux",
                "Jakub Mielczarek"
            ],
            "link": [
                "http://dx.doi.org/10.2760/46796",
                "http://arxiv.org/abs/2311.07626v1",
                "http://arxiv.org/pdf/2311.07626v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07625v2",
            "title": "Activity Sparsity Complements Weight Sparsity for Efficient RNN\n  Inference",
            "updated": "2023-12-07T07:59:58Z",
            "published": "2023-11-13T08:18:44Z",
            "summary": "Artificial neural networks open up unprecedented machine learning\ncapabilities at the cost of ever growing computational requirements.\nSparsifying the parameters, often achieved through weight pruning, has been\nidentified as a powerful technique to compress the number of model parameters\nand reduce the computational operations of neural networks. Yet, sparse\nactivations, while omnipresent in both biological neural networks and deep\nlearning systems, have not been fully utilized as a compression technique in\ndeep learning. Moreover, the interaction between sparse activations and weight\npruning is not fully understood. In this work, we demonstrate that activity\nsparsity can compose multiplicatively with parameter sparsity in a recurrent\nneural network model based on the GRU that is designed to be activity sparse.\nWe achieve up to $20\\times$ reduction of computation while maintaining\nperplexities below $60$ on the Penn Treebank language modeling task. This\nmagnitude of reduction has not been achieved previously with solely sparsely\nconnected LSTMs, and the language modeling performance of our model has not\nbeen achieved previously with any sparsely activated recurrent neural networks\nor spiking neural networks. Neuromorphic computing devices are especially good\nat taking advantage of the dynamic activity sparsity, and our results provide\nstrong evidence that making deep learning models activity sparse and porting\nthem to neuromorphic devices can be a viable strategy that does not compromise\non task performance. Our results also drive further convergence of methods from\ndeep learning and neuromorphic computing for efficient machine learning.",
            "author": [
                "Rishav Mukherji",
                "Mark Sch\u00f6ne",
                "Khaleelulla Khan Nazeer",
                "Christian Mayr",
                "Anand Subramoney"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07625v2",
                "http://arxiv.org/pdf/2311.07625v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07143v1",
            "title": "Learning Symmetrization for Equivariance with Orbit Distance\n  Minimization",
            "updated": "2023-11-13T08:14:29Z",
            "published": "2023-11-13T08:14:29Z",
            "summary": "We present a general framework for symmetrizing an arbitrary neural-network\narchitecture and making it equivariant with respect to a given group. We build\nupon the proposals of Kim et al. (2023); Kaba et al. (2023) for symmetrization,\nand improve them by replacing their conversion of neural features into group\nrepresentations, with an optimization whose loss intuitively measures the\ndistance between group orbits. This change makes our approach applicable to a\nbroader range of matrix groups, such as the Lorentz group O(1, 3), than these\ntwo proposals. We experimentally show our method's competitiveness on the SO(2)\nimage classification task, and also its increased generality on the task with\nO(1, 3). Our implementation will be made accessible at\nhttps://github.com/tiendatnguyen-vision/Orbit-symmetrize.",
            "author": [
                "Tien Dat Nguyen",
                "Jinwoo Kim",
                "Hongseok Yang",
                "Seunghoon Hong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07143v1",
                "http://arxiv.org/pdf/2311.07143v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07141v2",
            "title": "SABAF: Removing Strong Attribute Bias from Neural Networks with\n  Adversarial Filtering",
            "updated": "2023-11-16T07:23:17Z",
            "published": "2023-11-13T08:13:55Z",
            "summary": "Ensuring a neural network is not relying on protected attributes (e.g., race,\nsex, age) for prediction is crucial in advancing fair and trustworthy AI. While\nseveral promising methods for removing attribute bias in neural networks have\nbeen proposed, their limitations remain under-explored. To that end, in this\nwork, we mathematically and empirically reveal the limitation of existing\nattribute bias removal methods in presence of strong bias and propose a new\nmethod that can mitigate this limitation. Specifically, we first derive a\ngeneral non-vacuous information-theoretical upper bound on the performance of\nany attribute bias removal method in terms of the bias strength, revealing that\nthey are effective only when the inherent bias in the dataset is relatively\nweak. Next, we derive a necessary condition for the existence of any method\nthat can remove attribute bias regardless of the bias strength. Inspired by\nthis condition, we then propose a new method using an adversarial objective\nthat directly filters out protected attributes in the input space while\nmaximally preserving all other attributes, without requiring any specific\ntarget label. The proposed method achieves state-of-the-art performance in both\nstrong and moderate bias settings. We provide extensive experiments on\nsynthetic, image, and census datasets, to verify the derived theoretical bound\nand its consequences in practice, and evaluate the effectiveness of the\nproposed method in removing strong attribute bias.",
            "author": [
                "Jiazhi Li",
                "Mahyar Khayatkhoei",
                "Jiageng Zhu",
                "Hanchen Xie",
                "Mohamed E. Hussein",
                "Wael AbdAlmageed"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07141v2",
                "http://arxiv.org/pdf/2311.07141v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07139v1",
            "title": "Analyzing and Predicting Low-Listenership Trends in a Large-Scale Mobile\n  Health Program: A Preliminary Investigation",
            "updated": "2023-11-13T08:11:09Z",
            "published": "2023-11-13T08:11:09Z",
            "summary": "Mobile health programs are becoming an increasingly popular medium for\ndissemination of health information among beneficiaries in less privileged\ncommunities. Kilkari is one of the world's largest mobile health programs which\ndelivers time sensitive audio-messages to pregnant women and new mothers. We\nhave been collaborating with ARMMAN, a non-profit in India which operates the\nKilkari program, to identify bottlenecks to improve the efficiency of the\nprogram. In particular, we provide an initial analysis of the trajectories of\nbeneficiaries' interaction with the mHealth program and examine elements of the\nprogram that can be potentially enhanced to boost its success. We cluster the\ncohort into different buckets based on listenership so as to analyze\nlistenership patterns for each group that could help boost program success. We\nalso demonstrate preliminary results on using historical data in a time-series\nprediction to identify beneficiary dropouts and enable NGOs in devising timely\ninterventions to strengthen beneficiary retention.",
            "author": [
                "Arshika Lalan",
                "Shresth Verma",
                "Kumar Madhu Sudan",
                "Amrita Mahale",
                "Aparna Hegde",
                "Milind Tambe",
                "Aparna Taneja"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07139v1",
                "http://arxiv.org/pdf/2311.07139v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07127v2",
            "title": "Untargeted Black-box Attacks for Social Recommendations",
            "updated": "2023-11-19T07:43:52Z",
            "published": "2023-11-13T07:40:23Z",
            "summary": "The rise of online social networks has facilitated the evolution of social\nrecommender systems, which incorporate social relations to enhance users'\ndecision-making process. With the great success of Graph Neural Networks in\nlearning node representations, GNN-based social recommendations have been\nwidely studied to model user-item interactions and user-user social relations\nsimultaneously. Despite their great successes, recent studies have shown that\nthese advanced recommender systems are highly vulnerable to adversarial\nattacks, in which attackers can inject well-designed fake user profiles to\ndisrupt recommendation performances. While most existing studies mainly focus\non targeted attacks to promote target items on vanilla recommender systems,\nuntargeted attacks to degrade the overall prediction performance are less\nexplored on social recommendations under a black-box scenario. To perform\nuntargeted attacks on social recommender systems, attackers can construct\nmalicious social relationships for fake users to enhance the attack\nperformance. However, the coordination of social relations and item profiles is\nchallenging for attacking black-box social recommendations. To address this\nlimitation, we first conduct several preliminary studies to demonstrate the\neffectiveness of cross-community connections and cold-start items in degrading\nrecommendations performance. Specifically, we propose a novel framework\nMultiattack based on multi-agent reinforcement learning to coordinate the\ngeneration of cold-start item profiles and cross-community social relations for\nconducting untargeted attacks on black-box social recommendations.\nComprehensive experiments on various real-world datasets demonstrate the\neffectiveness of our proposed attacking framework under the black-box setting.",
            "author": [
                "Wenqi Fan",
                "Shijie Wang",
                "Xiao-yong Wei",
                "Xiaowei Mei",
                "Qing Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07127v2",
                "http://arxiv.org/pdf/2311.07127v2"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07126v1",
            "title": "How to Do Machine Learning with Small Data? -- A Review from an\n  Industrial Perspective",
            "updated": "2023-11-13T07:39:13Z",
            "published": "2023-11-13T07:39:13Z",
            "summary": "Artificial intelligence experienced a technological breakthrough in science,\nindustry, and everyday life in the recent few decades. The advancements can be\ncredited to the ever-increasing availability and miniaturization of\ncomputational resources that resulted in exponential data growth. However,\nbecause of the insufficient amount of data in some cases, employing machine\nlearning in solving complex tasks is not straightforward or even possible. As a\nresult, machine learning with small data experiences rising importance in data\nscience and application in several fields. The authors focus on interpreting\nthe general term of \"small data\" and their engineering and industrial\napplication role. They give a brief overview of the most important industrial\napplications of machine learning and small data. Small data is defined in terms\nof various characteristics compared to big data, and a machine learning\nformalism was introduced. Five critical challenges of machine learning with\nsmall data in industrial applications are presented: unlabeled data, imbalanced\ndata, missing data, insufficient data, and rare events. Based on those\ndefinitions, an overview of the considerations in domain representation and\ndata acquisition is given along with a taxonomy of machine learning approaches\nin the context of small data.",
            "author": [
                "Ivan Kraljevski",
                "Yong Chul Ju",
                "Dmitrij Ivanov",
                "Constanze Tsch\u00f6pe",
                "Matthias Wolff"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07126v1",
                "http://arxiv.org/pdf/2311.07126v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07125v1",
            "title": "Attention-Challenging Multiple Instance Learning for Whole Slide Image\n  Classification",
            "updated": "2023-11-13T07:34:53Z",
            "published": "2023-11-13T07:34:53Z",
            "summary": "Overfitting remains a significant challenge in the application of Multiple\nInstance Learning (MIL) methods for Whole Slide Image (WSI) analysis.\nVisualizing heatmaps reveals that current MIL methods focus on a subset of\npredictive instances, hindering effective model generalization. To tackle this,\nwe propose Attention-Challenging MIL (ACMIL), aimed at forcing the attention\nmechanism to capture more challenging predictive instances. ACMIL incorporates\ntwo techniques, Multiple Branch Attention (MBA) to capture richer predictive\ninstances and Stochastic Top-K Instance Masking (STKIM) to suppress simple\npredictive instances. Evaluation on three WSI datasets outperforms\nstate-of-the-art methods. Additionally, through heatmap visualization, UMAP\nvisualization, and attention value statistics, this paper comprehensively\nillustrates ACMIL's effectiveness in overcoming the overfitting challenge. The\nsource code is available at \\url{https://github.com/dazhangyu123/ACMIL}.",
            "author": [
                "Yunlong Zhang",
                "Honglin Li",
                "Yuxuan Sun",
                "Sunyi Zheng",
                "Chenglu Zhu",
                "Lin Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07125v1",
                "http://arxiv.org/pdf/2311.07125v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07122v1",
            "title": "On the Dust properties of the UV galaxies in the redshift range $z \\sim\n  0.6-1.2$",
            "updated": "2023-11-13T07:31:25Z",
            "published": "2023-11-13T07:31:25Z",
            "summary": "Far-infrared (FIR) observations from the \\textit{Herschel Space Observatory}\nare used to estimate the IR properties of UV-selected galaxies. We stack the\nPACS (100, 160 $\\mu \\mathrm{m}$) and SPIRE (250, 350 and 500$\\mu \\mathrm{m}$)\nmaps of the Chandra deep field south (CDFS) on a source list of galaxies\nselected in the rest-frame ultraviolet (UV) in a redshift range of $0.6-1.2$.\nThis source list is created using observations from the XMM-OM telescope survey\nin the CDFS using the UVW1 (2910 {\\AA}) filter. The stacked data are binned\naccording to the UV luminosity function (LF) of these sources, and the average\nphotometry of the UV-selected galaxies is estimated. By fitting modified black\nbodies and IR model templates to the stacked photometry, average dust\ntemperatures and total IR luminosity are determined. The luminosity-weighted\naverage temperatures do not show significant evolution between the redshift\nbins centred at 0.7 and 1.0. The infrared excess (IRX), unobscured, and\nobscured SFR values are obtained from the UV and IR luminosities. Dust\nattenuation is constant for UV luminosities above \\num{9e10}\n$\\mathrm{L_\\odot}$, but increases as UV luminosity decreases below this\nthreshold. It remains constant as a function of IR luminosities at fixed\nredshift across the luminosity range of our sources. In comparison to local\nluminous infrared galaxies (LIRGs) with similar SFRs, the higher redshift\nstar-forming galaxies in the sample show a lesser degree of dust attenuation.\nFinally, the inferred dust attenuation is used to correct the unobscured star\nformation rate density (SFRD) in the redshift range of 0.6 to 1.2. The\ndust-corrected SFRDs are found to be consistent with measurements from\nIR-selected samples at the same redshifts.",
            "author": [
                "M. Sharma",
                "M. J. Page",
                "M. Symeonidis",
                "I. Ferreras"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07122v1",
                "http://arxiv.org/pdf/2311.07122v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07117v1",
            "title": "Olfactory learning alters navigation strategies and behavioral\n  variability in C. elegans",
            "updated": "2023-11-13T07:21:22Z",
            "published": "2023-11-13T07:21:22Z",
            "summary": "Animals adjust their behavioral response to sensory input adaptively\ndepending on past experiences. The flexible brain computation is crucial for\nsurvival and is of great interest in neuroscience. The nematode C. elegans\nmodulates its navigation behavior depending on the association of odor butanone\nwith food (appetitive training) or starvation (aversive training), and will\nthen climb up the butanone gradient or ignore it, respectively. However, the\nexact change in navigation strategy in response to learning is still unknown.\nHere we study the learned odor navigation in worms by combining precise\nexperimental measurement and a novel descriptive model of navigation. Our model\nconsists of two known navigation strategies in worms: biased random walk and\nweathervaning. We infer weights on these strategies by applying the model to\nworm navigation trajectories and the exact odor concentration it experiences.\nCompared to naive worms, appetitive trained worms up-regulate the biased random\nwalk strategy, and aversive trained worms down-regulate the weathervaning\nstrategy. The statistical model provides prediction with $>90 \\%$ accuracy of\nthe past training condition given navigation data, which outperforms the\nclassical chemotaxis metric. We find that the behavioral variability is altered\nby learning, such that worms are less variable after training compared to naive\nones. The model further predicts the learning-dependent response and\nvariability under optogenetic perturbation of the olfactory neuron\nAWC$^\\mathrm{ON}$. Lastly, we investigate neural circuits downstream from\nAWC$^\\mathrm{ON}$ that are differentially recruited for learned odor-guided\nnavigation. Together, we provide a new paradigm to quantify flexible navigation\nalgorithms and pinpoint the underlying neural substrates.",
            "author": [
                "Kevin S. Chen",
                "Jonathan W. Pillow",
                "Andrew M. Leifer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07117v1",
                "http://arxiv.org/pdf/2311.07117v1"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC",
                "physics.bio-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07114v1",
            "title": "Novel models for fatigue life prediction under wideband random loads\n  based on machine learning",
            "updated": "2023-11-13T07:09:45Z",
            "published": "2023-11-13T07:09:45Z",
            "summary": "Machine learning as a data-driven solution has been widely applied in the\nfield of fatigue lifetime prediction. In this paper, three models for wideband\nfatigue life prediction are built based on three machine learning models, i.e.\nsupport vector machine (SVM), Gaussian process regression (GPR) and artificial\nneural network (ANN). The generalization ability of the models is enhanced by\nemploying numerous power spectra samples with different bandwidth parameters\nand a variety of material properties related to fatigue life. Sufficient Monte\nCarlo numerical simulations demonstrate that the newly developed machine\nlearning models are superior to the traditional frequency-domain models in\nterms of life prediction accuracy and the ANN model has the best overall\nperformance among the three developed machine learning models.",
            "author": [
                "Hong Sun",
                "Yuanying Qiu",
                "Jing Li",
                "Jin Bai",
                "Ming Peng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07114v1",
                "http://arxiv.org/pdf/2311.07114v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "cond-mat.dis-nn",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07113v2",
            "title": "SpectralGPT: Spectral Foundation Model",
            "updated": "2023-11-25T09:11:50Z",
            "published": "2023-11-13T07:09:30Z",
            "summary": "The foundation model has recently garnered significant attention due to its\npotential to revolutionize the field of visual representation learning in a\nself-supervised manner. While most foundation models are tailored to\neffectively process RGB images for various visual tasks, there is a noticeable\ngap in research focused on spectral data, which offers valuable information for\nscene understanding, especially in remote sensing (RS) applications. To fill\nthis gap, we created for the first time a universal RS foundation model, named\nSpectralGPT, which is purpose-built to handle spectral RS images using a novel\n3D generative pretrained transformer (GPT). Compared to existing foundation\nmodels, SpectralGPT 1) accommodates input images with varying sizes,\nresolutions, time series, and regions in a progressive training fashion,\nenabling full utilization of extensive RS big data; 2) leverages 3D token\ngeneration for spatial-spectral coupling; 3) captures spectrally sequential\npatterns via multi-target reconstruction; 4) trains on one million spectral RS\nimages, yielding models with over 600 million parameters. Our evaluation\nhighlights significant performance improvements with pretrained SpectralGPT\nmodels, signifying substantial potential in advancing spectral RS big data\napplications within the field of geoscience across four downstream tasks:\nsingle/multi-label scene classification, semantic segmentation, and change\ndetection.",
            "author": [
                "Danfeng Hong",
                "Bing Zhang",
                "Xuyang Li",
                "Yuxuan Li",
                "Chenyu Li",
                "Jing Yao",
                "Naoto Yokoya",
                "Hao Li",
                "Pedram Ghamisi",
                "Xiuping Jia",
                "Antonio Plaza",
                "Gamba Paolo",
                "Jon Atli Benediktsson",
                "Jocelyn Chanussot"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07113v2",
                "http://arxiv.org/pdf/2311.07113v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07110v1",
            "title": "Adversarial Purification for Data-Driven Power System Event Classifiers\n  with Diffusion Models",
            "updated": "2023-11-13T06:52:56Z",
            "published": "2023-11-13T06:52:56Z",
            "summary": "The global deployment of the phasor measurement units (PMUs) enables\nreal-time monitoring of the power system, which has stimulated considerable\nresearch into machine learning-based models for event detection and\nclassification. However, recent studies reveal that machine learning-based\nmethods are vulnerable to adversarial attacks, which can fool the event\nclassifiers by adding small perturbations to the raw PMU data. To mitigate the\nthreats posed by adversarial attacks, research on defense strategies is\nurgently needed. This paper proposes an effective adversarial purification\nmethod based on the diffusion model to counter adversarial attacks on the\nmachine learning-based power system event classifier. The proposed method\nincludes two steps: injecting noise into the PMU data; and utilizing a\npre-trained neural network to eliminate the added noise while simultaneously\nremoving perturbations introduced by the adversarial attacks. The proposed\nadversarial purification method significantly increases the accuracy of the\nevent classifier under adversarial attacks while satisfying the requirements of\nreal-time operations. In addition, the theoretical analysis reveals that the\nproposed diffusion model-based adversarial purification method decreases the\ndistance between the original and compromised PMU data, which reduces the\nimpacts of adversarial attacks. The empirical results on a large-scale\nreal-world PMU dataset validate the effectiveness and computational efficiency\nof the proposed adversarial purification method.",
            "author": [
                "Yuanbin Cheng",
                "Koji Yamashita",
                "Jim Follum",
                "Nanpeng Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07110v1",
                "http://arxiv.org/pdf/2311.07110v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.CR",
                "cs.LG",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07103v2",
            "title": "Particle Identification at VAMOS++ with Machine Learning Techniques",
            "updated": "2023-11-14T13:56:56Z",
            "published": "2023-11-13T06:32:32Z",
            "summary": "Multi-nucleon transfer reaction between 136Xe beam and 198Pt target was\nperformed using the VAMOS++ spectrometer at GANIL to study the structure of\nn-rich nuclei around N=126. Unambiguous charge state identification was\nobtained by combining two supervised machine learning methods, deep neural\nnetwork (DNN) and positional correction using a gradient-boosting decision tree\n(GBDT). The new method reduced the complexity of the kinetic energy calibration\nand outperformed the conventional method, improving the charge state resolution\nby 8%",
            "author": [
                "Y. Cho",
                "Y. H. Kim",
                "S. Choi",
                "J. Park",
                "S. Bae",
                "K. I. Hahn",
                "Y. Son",
                "A. Navin",
                "A. Lemasson",
                "M. Rejmund",
                "D. Ramos",
                "D. Ackermann",
                "A. Utepov",
                "C. Fourgeres",
                "J. C. Thomas",
                "J. Goupil",
                "G. Fremont",
                "G. de France",
                "Y. X. Watanabe",
                "Y. Hirayama",
                "S. Jeong",
                "T. Niwase",
                "H. Miyatake",
                "P. Schury",
                "M. Rosenbusch",
                "K. Chae",
                "C. Kim",
                "S. Kim",
                "G. M. Gu",
                "M. J. Kim",
                "P. John",
                "A. N. Andreyev",
                "W. Korten",
                "F. Recchia",
                "G. de Angelis",
                "R. M. P\u00e9rez Vidal",
                "K. Rezynkina",
                "J. Ha",
                "F. Didierjean",
                "P. Marini",
                "D. Treasa",
                "I. Tsekhanovich",
                "J. Dudouet",
                "S. Bhattacharyya",
                "G. Mukherjee",
                "R. Banik",
                "S. Bhattacharya",
                "M. Mukai"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.nimb.2023.05.053",
                "http://arxiv.org/abs/2311.07103v2",
                "http://arxiv.org/pdf/2311.07103v2"
            ],
            "primary_category": "physics.ins-det",
            "category": [
                "physics.ins-det",
                "nucl-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07099v1",
            "title": "Explanation-aware Soft Ensemble Empowers Large Language Model In-context\n  Learning",
            "updated": "2023-11-13T06:13:38Z",
            "published": "2023-11-13T06:13:38Z",
            "summary": "Large language models (LLMs) have shown remarkable capabilities in various\nnatural language understanding tasks. With only a few demonstration examples,\nthese LLMs can quickly adapt to target tasks without expensive gradient\nupdates. Common strategies to boost such 'in-context' learning ability are to\nensemble multiple model decoded results and require the model to generate an\nexplanation along with the prediction. However, these models often treat\ndifferent class predictions equally and neglect the potential discrepancy\nbetween the explanations and predictions. To fully unleash the power of\nexplanations, we propose EASE, an Explanation-Aware Soft Ensemble framework to\nempower in-context learning with LLMs. We design two techniques,\nexplanation-guided ensemble, and soft probability aggregation, to mitigate the\neffect of unreliable explanations and improve the consistency between\nexplanations and final predictions. Experiments on seven natural language\nunderstanding tasks and four varying-size LLMs demonstrate the effectiveness of\nour proposed framework.",
            "author": [
                "Yue Yu",
                "Jiaming Shen",
                "Tianqi Liu",
                "Zhen Qin",
                "Jing Nathan Yan",
                "Jialu Liu",
                "Chao Zhang",
                "Michael Bendersky"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07099v1",
                "http://arxiv.org/pdf/2311.07099v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07093v2",
            "title": "On the Effectiveness of ASR Representations in Real-world Noisy Speech\n  Emotion Recognition",
            "updated": "2023-11-14T13:09:51Z",
            "published": "2023-11-13T05:45:55Z",
            "summary": "This paper proposes an efficient attempt to noisy speech emotion recognition\n(NSER). Conventional NSER approaches have proven effective in mitigating the\nimpact of artificial noise sources, such as white Gaussian noise, but are\nlimited to non-stationary noises in real-world environments due to their\ncomplexity and uncertainty. To overcome this limitation, we introduce a new\nmethod for NSER by adopting the automatic speech recognition (ASR) model as a\nnoise-robust feature extractor to eliminate non-vocal information in noisy\nspeech. We first obtain intermediate layer information from the ASR model as a\nfeature representation for emotional speech and then apply this representation\nfor the downstream NSER task. Our experimental results show that 1) the\nproposed method achieves better NSER performance compared with the conventional\nnoise reduction method, 2) outperforms self-supervised learning approaches, and\n3) even outperforms text-based approaches using ASR transcription or the ground\ntruth transcription of noisy speech.",
            "author": [
                "Xiaohan Shi",
                "Jiajun He",
                "Xingfeng Li",
                "Tomoki Toda"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07093v2",
                "http://arxiv.org/pdf/2311.07093v2"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.CL",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07092v1",
            "title": "To Tell The Truth: Language of Deception and Language Models",
            "updated": "2023-11-13T05:40:11Z",
            "published": "2023-11-13T05:40:11Z",
            "summary": "Text-based misinformation permeates online discourses, yet evidence of\npeople's ability to discern truth from such deceptive textual content is\nscarce. We analyze a novel TV game show data where conversations in a\nhigh-stake environment between individuals with conflicting objectives result\nin lies. We investigate the manifestation of potentially verifiable language\ncues of deception in the presence of objective truth, a distinguishing feature\nabsent in previous text-based deception datasets. We show that there exists a\nclass of detectors (algorithms) that have similar truth detection performance\ncompared to human subjects, even when the former accesses only the language\ncues while the latter engages in conversations with complete access to all\npotential sources of cues (language and audio-visual). Our model, built on a\nlarge language model, employs a bottleneck framework to learn discernible cues\nto determine truth, an act of reasoning in which human subjects often perform\npoorly, even with incentives. Our model detects novel but accurate language\ncues in many cases where humans failed to detect deception, opening up the\npossibility of humans collaborating with algorithms and ameliorating their\nability to detect the truth.",
            "author": [
                "Bodhisattwa Prasad Majumder",
                "Sanchaita Hazra"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07092v1",
                "http://arxiv.org/pdf/2311.07092v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07083v1",
            "title": "Dynamic Control of Spontaneous Emission Using Magnetized InSb\n  Higher-Order-Mode Antennas",
            "updated": "2023-11-13T05:19:59Z",
            "published": "2023-11-13T05:19:59Z",
            "summary": "We exploit InSb's magnetic-induced optical properties to propose THz\nsub-wavelength antenna designs that actively tune the radiative decay rates of\ndipole emitters at their proximity. The proposed designs include a spherical\nInSb antenna and a cylindrical Si-InSb hybrid antenna that demonstrate distinct\nbehaviors; the former dramatically enhances both radiative and non-radiative\ndecay rates in the epsilon-near-zero region due to the dominant contribution of\nthe Zeeman splitting electric octupole mode. The latter realizes significant\nradiative decay rate enhancement via magnetic octupole mode, mitigating the\nquenching process and accelerating the photon production rate. A deep\nlearning-based optimization of emitter positioning further enhances the quantum\nefficiency of the proposed hybrid system. These novel mechanisms are\npotentially promising for tunable THz single-photon sources in integrated\nquantum networks.",
            "author": [
                "Sina Aghili",
                "Rasoul Alaee",
                "Amirreza Ahmadnejad",
                "Ehsan Mobini",
                "Mohamadreza Mohamadpour",
                "Carsten Rockstuhl",
                "Robert W. Boyd",
                "Ksenia Dolgaleva"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07083v1",
                "http://arxiv.org/pdf/2311.07083v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "physics.app-ph",
                "physics.optics"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07079v2",
            "title": "Sample Dominance Aware Framework via Non-Parametric Estimation for\n  Spontaneous Brain-Computer Interface",
            "updated": "2023-11-15T02:51:08Z",
            "published": "2023-11-13T05:08:26Z",
            "summary": "Deep learning has shown promise in decoding brain signals, such as\nelectroencephalogram (EEG), in the field of brain-computer interfaces (BCIs).\nHowever, the non-stationary characteristics of EEG signals pose challenges for\ntraining neural networks to acquire appropriate knowledge. Inconsistent EEG\nsignals resulting from these non-stationary characteristics can lead to poor\nperformance. Therefore, it is crucial to investigate and address sample\ninconsistency to ensure robust performance in spontaneous BCIs. In this study,\nwe introduce the concept of sample dominance as a measure of EEG signal\ninconsistency and propose a method to modulate its effect on network training.\nWe present a two-stage dominance score estimation technique that compensates\nfor performance degradation caused by sample inconsistencies. Our proposed\nmethod utilizes non-parametric estimation to infer sample inconsistency and\nassigns each sample a dominance score. This score is then aggregated with the\nloss function during training to modulate the impact of sample inconsistency.\nFurthermore, we design a curriculum learning approach that gradually increases\nthe influence of inconsistent signals during training to improve overall\nperformance. We evaluate our proposed method using public spontaneous BCI\ndataset. The experimental results confirm that our findings highlight the\nimportance of addressing sample dominance for achieving robust performance in\nspontaneous BCIs.",
            "author": [
                "Byeong-Hoo Lee",
                "Byoung-Hee Kwon",
                "Seong-Whan Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07079v2",
                "http://arxiv.org/pdf/2311.07079v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07075v2",
            "title": "GazeForensics: DeepFake Detection via Gaze-guided Spatial Inconsistency\n  Learning",
            "updated": "2023-11-22T23:49:58Z",
            "published": "2023-11-13T04:48:33Z",
            "summary": "DeepFake detection is pivotal in personal privacy and public safety. With the\niterative advancement of DeepFake techniques, high-quality forged videos and\nimages are becoming increasingly deceptive. Prior research has seen numerous\nattempts by scholars to incorporate biometric features into the field of\nDeepFake detection. However, traditional biometric-based approaches tend to\nsegregate biometric features from general ones and freeze the biometric feature\nextractor. These approaches resulted in the exclusion of valuable general\nfeatures, potentially leading to a performance decline and, consequently, a\nfailure to fully exploit the potential of biometric information in assisting\nDeepFake detection. Moreover, insufficient attention has been dedicated to\nscrutinizing gaze authenticity within the realm of DeepFake detection in recent\nyears. In this paper, we introduce GazeForensics, an innovative DeepFake\ndetection method that utilizes gaze representation obtained from a 3D gaze\nestimation model to regularize the corresponding representation within our\nDeepFake detection model, while concurrently integrating general features to\nfurther enhance the performance of our model. Experiment results reveal that\nour proposed GazeForensics outperforms the current state-of-the-art methods.",
            "author": [
                "Qinlin He",
                "Chunlei Peng",
                "Decheng Liu",
                "Nannan Wang",
                "Xinbo Gao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07075v2",
                "http://arxiv.org/pdf/2311.07075v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07073v2",
            "title": "Exposition on over-squashing problem on GNNs: Current Methods,\n  Benchmarks and Challenges",
            "updated": "2023-11-17T22:51:23Z",
            "published": "2023-11-13T04:40:13Z",
            "summary": "Graph-based message-passing neural networks (MPNNs) have achieved remarkable\nsuccess in both node and graph-level learning tasks. However, several\nidentified problems, including over-smoothing (OSM), limited expressive power,\nand over-squashing (OSQ), still limit the performance of MPNNs. In particular,\nOSQ serves as the latest identified problem, where MPNNs gradually lose their\nlearning accuracy when long-range dependencies between graph nodes are\nrequired. In this work, we provide an exposition on the OSQ problem by\nsummarizing different formulations of OSQ from current literature, as well as\nthe three different categories of approaches for addressing the OSQ problem. In\naddition, we also discuss the alignment between OSQ and expressive power and\nthe trade-off between OSQ and OSM. Furthermore, we summarize the empirical\nmethods leveraged from existing works to verify the efficiency of OSQ\nmitigation approaches, with illustrations of their computational complexities.\nLastly, we list some open questions that are of interest for further\nexploration of the OSQ problem along with potential directions from the best of\nour knowledge.",
            "author": [
                "Dai Shi",
                "Andi Han",
                "Lequan Lin",
                "Yi Guo",
                "Junbin Gao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07073v2",
                "http://arxiv.org/pdf/2311.07073v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07065v1",
            "title": "Non-approximability of constructive global $\\mathcal{L}^2$ minimizers by\n  gradient descent in Deep Learning",
            "updated": "2023-11-13T04:11:25Z",
            "published": "2023-11-13T04:11:25Z",
            "summary": "We analyze geometric aspects of the gradient descent algorithm in Deep\nLearning (DL) networks. In particular, we prove that the globally minimizing\nweights and biases for the $\\mathcal{L}^2$ cost obtained constructively in\n[Chen-Munoz Ewald 2023] for underparametrized ReLU DL networks can generically\nnot be approximated via the gradient descent flow. We therefore conclude that\nthe method introduced in [Chen-Munoz Ewald 2023] is disjoint from the gradient\ndescent method.",
            "author": [
                "Thomas Chen",
                "Patricia Mu\u00f1oz Ewald"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07065v1",
                "http://arxiv.org/pdf/2311.07065v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "math-ph",
                "math.MP",
                "math.OC",
                "stat.ML",
                "57R70, 62M45"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07062v2",
            "title": "Decoupling and Interacting Multi-Task Learning Network for Joint Speech\n  and Accent Recognition",
            "updated": "2023-11-17T09:30:08Z",
            "published": "2023-11-13T04:03:22Z",
            "summary": "Accents, as variations from standard pronunciation, pose significant\nchallenges for speech recognition systems. Although joint automatic speech\nrecognition (ASR) and accent recognition (AR) training has been proven\neffective in handling multi-accent scenarios, current multi-task ASR-AR\napproaches overlook the granularity differences between tasks. Fine-grained\nunits capture pronunciation-related accent characteristics, while\ncoarse-grained units are better for learning linguistic information. Moreover,\nan explicit interaction of two tasks can also provide complementary information\nand improve the performance of each other, but it is rarely used by existing\napproaches. In this paper, we propose a novel Decoupling and Interacting\nMulti-task Network (DIMNet) for joint speech and accent recognition, which is\ncomprised of a connectionist temporal classification (CTC) branch, an AR\nbranch, an ASR branch, and a bottom feature encoder. Specifically, AR and ASR\nare first decoupled by separated branches and two-granular modeling units to\nlearn task-specific representations. The AR branch is from our previously\nproposed linguistic-acoustic bimodal AR model and the ASR branch is an\nencoder-decoder based Conformer model. Then, for the task interaction, the CTC\nbranch provides aligned text for the AR task, while accent embeddings extracted\nfrom our AR model are incorporated into the ASR branch's encoder and decoder.\nFinally, during ASR inference, a cross-granular rescoring method is introduced\nto fuse the complementary information from the CTC and attention decoder after\nthe decoupling. Our experiments on English and Chinese datasets demonstrate the\neffectiveness of the proposed model, which achieves 21.45%/28.53% AR accuracy\nrelative improvement and 32.33%/14.55% ASR error rate relative reduction over a\npublished standard baseline, respectively.",
            "author": [
                "Qijie Shao",
                "Pengcheng Guo",
                "Jinghao Yan",
                "Pengfei Hu",
                "Lei Xie"
            ],
            "link": [
                "http://dx.doi.org/10.1109/TASLP.2023.3332542",
                "http://arxiv.org/abs/2311.07062v2",
                "http://arxiv.org/pdf/2311.07062v2"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07059v1",
            "title": "Application of deep learning methods to the study of magnetic phenomena",
            "updated": "2023-11-13T03:53:09Z",
            "published": "2023-11-13T03:53:09Z",
            "summary": "Nowadays, methods and techniques of Machine Learning and Deep Learning are\nbeing used in various scientific areas. They help to automatize calculations\nwithout losing in quality. In this paper the applying of convolutional neural\nnetwork was considered in frame of problems from statistical physics and\ncomputer simulation of magnetic films. In a frame of the first task, CNN was\nused to determine critical Curie point for Ising model on 2D square lattice.\nObtained results were compared with classical Monte-Carlo methods and exact\nsolution. Systems of various lattice sizes and the influence of the size effect\non the results' accuracy were considered. Also, authors considered the\nclassical two-dimensional Heisenberg model, a spin system with direct\nshort-range exchange, and studied of its competition with the\nDzyaloshinskii-Moriya interaction. A neural network was applied to the\nrecognition of Spiral (Sp), Spiral-skyrmion (SpSk) Skyrmion (Sk),\nSkyrmion-ferromagnetic (SkF) and Ferromagnetic (FM) phases of the Heisenberg\nspin system with magnetic skyrmions. The advantage of CNN's application over\nconventional methods for determination of skyrmion's phases was revealed.",
            "author": [
                "E. V. Vasiliev",
                "D. Yu. Kapitan",
                "A. O. Korol",
                "A. E. Rybin",
                "P. A. Ovchinnikov",
                "K. S. Soldatov",
                "Yu. A. Shevchenko",
                "A. G. Makarov",
                "V. Yu. Kapitan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07059v1",
                "http://arxiv.org/pdf/2311.07059v1"
            ],
            "primary_category": "physics.comp-ph",
            "category": [
                "physics.comp-ph",
                "60-04",
                "F.1.1; J.2"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07056v1",
            "title": "Effective In-vehicle Intrusion Detection via Multi-view Statistical\n  Graph Learning on CAN Messages",
            "updated": "2023-11-13T03:49:55Z",
            "published": "2023-11-13T03:49:55Z",
            "summary": "As an important component of internet of vehicles (IoV), intelligent\nconnected vehicles (ICVs) have to communicate with external networks\nfrequently. In this case, the resource-constrained in-vehicle network (IVN) is\nfacing a wide variety of complex and changing external cyber-attacks,\nespecially the masquerade attack with high difficulty of detection while\nserious damaging effects that few counter measures can identify successfully.\nMoreover, only coarse-grained recognition can be achieved in current mainstream\nintrusion detection mechanisms, i.e., whether a whole data flow observation\nwindow contains attack labels rather than fine-grained recognition on every\nsingle data item within this window. In this paper, we propose StatGraph: an\nEffective Multi-view Statistical Graph Learning Intrusion Detection to\nimplement the fine-grained intrusion detection. Specifically, StatGraph\ngenerates two statistical graphs, timing correlation graph (TCG) and coupling\nrelationship graph (CRG), based on data streams. In given message observation\nwindows, edge attributes in TCGs represent temporal correlation between\ndifferent message IDs, while edge attributes in CRGs denote the neighbour\nrelationship and contextual similarity. Besides, a lightweight shallow layered\nGCN network is trained based graph property of TCGs and CRGs, which can learn\nthe universal laws of various patterns more effectively and further enhance the\nperformance of detection. To address the problem of insufficient attack types\nin previous intrusion detection, we select two real in-vehicle CAN datasets\nthat cover four new attacks never investigated before. Experimental result\nshows StatGraph improves both detection granularity and detection performance\nover state-of-the-art intrusion detection methods.",
            "author": [
                "Kai Wang",
                "Qiguang Jiang",
                "Bailing Wang",
                "Yongzheng Zhang",
                "Yulei Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07056v1",
                "http://arxiv.org/pdf/2311.07056v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "cs.AI",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07052v1",
            "title": "Towards the Law of Capacity Gap in Distilling Language Models",
            "updated": "2023-11-13T03:36:18Z",
            "published": "2023-11-13T03:36:18Z",
            "summary": "Language model (LM) distillation is a trending area that aims to distil the\nknowledge resided in a large teacher LM to a small student one. While various\nmethods have been proposed to push the distillation to its limits, it is still\na pain distilling LMs when a large capacity gap is exhibited between the\nteacher and the student LMs. The pain is mainly resulted by the curse of\ncapacity gap, which describes that a larger teacher LM cannot always lead to a\nbetter student LM than one distilled from a smaller teacher LM due to the\naffect of capacity gap increment. That is, there is likely an optimal point\nyielding the best student LM along the scaling course of the teacher LM. Even\nworse, the curse of capacity gap can be only partly yet not fully lifted as\nindicated in previous studies.\n  However, the tale is not ever one-sided. Although a larger teacher LM has\nbetter performance than a smaller teacher LM, it is much more\nresource-demanding especially in the context of recent large LMs (LLMs).\nConsequently, instead of sticking to lifting the curse, leaving the curse as is\nshould be arguably fine. Even better, in this paper, we reveal that the optimal\ncapacity gap is almost consistent across different student scales and\narchitectures, fortunately turning the curse into the law of capacity gap. The\nlaw later guides us to distil a 3B student LM (termed MiniMA) from a 7B teacher\nLM (adapted LLaMA2-7B). MiniMA is demonstrated to yield a new\ncompute-performance pareto frontier among existing 3B LMs on commonly used\nbenchmarks, and its instruction-tuned version (termed MiniChat) outperforms a\nwide range of 3B competitors in GPT4 evaluation and could even compete with\nseveral 7B chat models.",
            "author": [
                "Chen Zhang",
                "Dawei Song",
                "Zheyu Ye",
                "Yan Gao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07052v1",
                "http://arxiv.org/pdf/2311.07052v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07041v1",
            "title": "Deep Joint Source Channel Coding With Attention Modules Over MIMO\n  Channels",
            "updated": "2023-11-13T02:53:30Z",
            "published": "2023-11-13T02:53:30Z",
            "summary": "In this paper, we propose two deep joint source and channel coding (DJSCC)\nstructures with attention modules for the multi-input multi-output (MIMO)\nchannel, including a serial structure and a parallel structure. With singular\nvalue decomposition (SVD)-based precoding scheme, the MIMO channel can be\ndecomposed into various sub-channels, and the feature outputs will experience\nsub-channels with different channel qualities. In the serial structure, one\nsingle network is used at both the transmitter and the receiver to jointly\nprocess data streams of all MIMO subchannels, while data steams of different\nMIMO subchannels are processed independently via multiple sub-networks in the\nparallel structure. The attention modules in both serial and parallel\narchitectures enable the system to adapt to varying channel qualities and\nadjust the quantity of information outputs in accordance with the channel\nqualities. Experimental results demonstrate the proposed DJSCC structures have\nimproved image transmission performance, and reveal the phenomenon via\nnon-parameter entropy estimation that the learned DJSCC transceivers tend to\ntransmit more information over better sub-channels.",
            "author": [
                "Weiran Jiang",
                "Wei Chen",
                "Bo Ai"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07041v1",
                "http://arxiv.org/pdf/2311.07041v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07622v2",
            "title": "Pretrain like Your Inference: Masked Tuning Improves Zero-Shot Composed\n  Image Retrieval",
            "updated": "2023-11-15T04:13:37Z",
            "published": "2023-11-13T02:49:57Z",
            "summary": "Zero-shot composed image retrieval (ZS-CIR), which aims to retrieve a target\nimage based on textual modifications to a reference image without triplet\nlabeling, has gained more and more attention. Current ZS-CIR research mainly\nrelies on two unlabeled pre-trained models: the vision-language model, e.g.,\nCLIP, and the Pic2Word/textual inversion model. However, the pre-trained models\nand CIR tasks have substantial discrepancies, where the pre-trained models\nlearn the similarities between vision and language but CIR aims to learn the\nmodifications of the image guided by text. In this paper, we introduce a novel\nunlabeled and pre-trained masked tuning approach to reduce the gap between the\npre-trained model and the downstream CIR task. We first reformulate the\npre-trained vision-language contrastive learning as the CIR task, where we\nrandomly mask input image patches to generate $\\langle$masked image, text,\nimage$\\rangle$ triple from an image-text pair. Then, we propose a masked\ntuning, which uses the text and the masked image to learn the modifications of\nthe original image. With such a simple design, it can learn to capture\nfine-grained text-guided modifications. Extensive experimental results\ndemonstrate the significant superiority of our approach over the baseline\nmodels on three ZS-CIR datasets, including FashionIQ, CIRR, and CIRCO.",
            "author": [
                "Junyang Chen",
                "Hanjiang Lai"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07622v2",
                "http://arxiv.org/pdf/2311.07622v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07037v1",
            "title": "Phonological Level wav2vec2-based Mispronunciation Detection and\n  Diagnosis Method",
            "updated": "2023-11-13T02:41:41Z",
            "published": "2023-11-13T02:41:41Z",
            "summary": "The automatic identification and analysis of pronunciation errors, known as\nMispronunciation Detection and Diagnosis (MDD) plays a crucial role in Computer\nAided Pronunciation Learning (CAPL) tools such as Second-Language (L2) learning\nor speech therapy applications. Existing MDD methods relying on analysing\nphonemes can only detect categorical errors of phonemes that have an adequate\namount of training data to be modelled. With the unpredictable nature of the\npronunciation errors of non-native or disordered speakers and the scarcity of\ntraining datasets, it is unfeasible to model all types of mispronunciations.\nMoreover, phoneme-level MDD approaches have a limited ability to provide\ndetailed diagnostic information about the error made. In this paper, we propose\na low-level MDD approach based on the detection of speech attribute features.\nSpeech attribute features break down phoneme production into elementary\ncomponents that are directly related to the articulatory system leading to more\nformative feedback to the learner. We further propose a multi-label variant of\nthe Connectionist Temporal Classification (CTC) approach to jointly model the\nnon-mutually exclusive speech attributes using a single model. The pre-trained\nwav2vec2 model was employed as a core model for the speech attribute detector.\nThe proposed method was applied to L2 speech corpora collected from English\nlearners from different native languages. The proposed speech attribute MDD\nmethod was further compared to the traditional phoneme-level MDD and achieved a\nsignificantly lower False Acceptance Rate (FAR), False Rejection Rate (FRR),\nand Diagnostic Error Rate (DER) over all speech attributes compared to the\nphoneme-level equivalent.",
            "author": [
                "Mostafa Shahin",
                "Julien Epps",
                "Beena Ahmed"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07037v1",
                "http://arxiv.org/pdf/2311.07037v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07033v1",
            "title": "TTMFN: Two-stream Transformer-based Multimodal Fusion Network for\n  Survival Prediction",
            "updated": "2023-11-13T02:31:20Z",
            "published": "2023-11-13T02:31:20Z",
            "summary": "Survival prediction plays a crucial role in assisting clinicians with the\ndevelopment of cancer treatment protocols. Recent evidence shows that\nmultimodal data can help in the diagnosis of cancer disease and improve\nsurvival prediction. Currently, deep learning-based approaches have experienced\nincreasing success in survival prediction by integrating pathological images\nand gene expression data. However, most existing approaches overlook the\nintra-modality latent information and the complex inter-modality correlations.\nFurthermore, existing modalities do not fully exploit the immense\nrepresentational capabilities of neural networks for feature aggregation and\ndisregard the importance of relationships between features. Therefore, it is\nhighly recommended to address these issues in order to enhance the prediction\nperformance by proposing a novel deep learning-based method. We propose a novel\nframework named Two-stream Transformer-based Multimodal Fusion Network for\nsurvival prediction (TTMFN), which integrates pathological images and gene\nexpression data. In TTMFN, we present a two-stream multimodal co-attention\ntransformer module to take full advantage of the complex relationships between\ndifferent modalities and the potential connections within the modalities.\nAdditionally, we develop a multi-head attention pooling approach to effectively\naggregate the feature representations of the two modalities. The experiment\nresults on four datasets from The Cancer Genome Atlas demonstrate that TTMFN\ncan achieve the best performance or competitive results compared to the\nstate-of-the-art methods in predicting the overall survival of patients.",
            "author": [
                "Ruiquan Ge",
                "Xiangyang Hu",
                "Rungen Huang",
                "Gangyong Jia",
                "Yaqi Wang",
                "Renshu Gu",
                "Changmiao Wang",
                "Elazab Ahmed",
                "Linyan Wang",
                "Juan Ye",
                "Ye Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07033v1",
                "http://arxiv.org/pdf/2311.07033v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07027v1",
            "title": "Robust softmax aggregation on blockchain based federated learning with\n  convergence guarantee",
            "updated": "2023-11-13T02:25:52Z",
            "published": "2023-11-13T02:25:52Z",
            "summary": "Blockchain based federated learning is a distributed learning scheme that\nallows model training without participants sharing their local data sets, where\nthe blockchain components eliminate the need for a trusted central server\ncompared to traditional Federated Learning algorithms. In this paper we propose\na softmax aggregation blockchain based federated learning framework. First, we\npropose a new blockchain based federated learning architecture that utilizes\nthe well-tested proof-of-stake consensus mechanism on an existing blockchain\nnetwork to select validators and miners to aggregate the participants' updates\nand compute the blocks. Second, to ensure the robustness of the aggregation\nprocess, we design a novel softmax aggregation method based on approximated\npopulation loss values that relies on our specific blockchain architecture.\nAdditionally, we show our softmax aggregation technique converges to the global\nminimum in the convex setting with non-restricting assumptions. Our\ncomprehensive experiments show that our framework outperforms existing robust\naggregation algorithms in various settings by large margins.",
            "author": [
                "Huiyu Wu",
                "Diego Klabjan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07027v1",
                "http://arxiv.org/pdf/2311.07027v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07025v1",
            "title": "Embarassingly Simple Dataset Distillation",
            "updated": "2023-11-13T02:14:54Z",
            "published": "2023-11-13T02:14:54Z",
            "summary": "Dataset distillation extracts a small set of synthetic training samples from\na large dataset with the goal of achieving competitive performance on test data\nwhen trained on this sample. In this work, we tackle dataset distillation at\nits core by treating it directly as a bilevel optimization problem.\nRe-examining the foundational back-propagation through time method, we study\nthe pronounced variance in the gradients, computational burden, and long-term\ndependencies. We introduce an improved method: Random Truncated Backpropagation\nThrough Time (RaT-BPTT) to address them. RaT-BPTT incorporates a truncation\ncoupled with a random window, effectively stabilizing the gradients and\nspeeding up the optimization while covering long dependencies. This allows us\nto establish new state-of-the-art for a variety of standard dataset benchmarks.\nA deeper dive into the nature of distilled data unveils pronounced\nintercorrelation. In particular, subsets of distilled datasets tend to exhibit\nmuch worse performance than directly distilled smaller datasets of the same\nsize. Leveraging RaT-BPTT, we devise a boosting mechanism that generates\ndistilled datasets that contain subsets with near optimal performance across\ndifferent data budgets.",
            "author": [
                "Yunzhen Feng",
                "Ramakrishna Vedantam",
                "Julia Kempe"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07025v1",
                "http://arxiv.org/pdf/2311.07025v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07621v1",
            "title": "To Transformers and Beyond: Large Language Models for the Genome",
            "updated": "2023-11-13T02:13:58Z",
            "published": "2023-11-13T02:13:58Z",
            "summary": "In the rapidly evolving landscape of genomics, deep learning has emerged as a\nuseful tool for tackling complex computational challenges. This review focuses\non the transformative role of Large Language Models (LLMs), which are mostly\nbased on the transformer architecture, in genomics. Building on the foundation\nof traditional convolutional neural networks and recurrent neural networks, we\nexplore both the strengths and limitations of transformers and other LLMs for\ngenomics. Additionally, we contemplate the future of genomic modeling beyond\nthe transformer architecture based on current trends in research. The paper\naims to serve as a guide for computational biologists and computer scientists\ninterested in LLMs for genomic data. We hope the paper can also serve as an\neducational introduction and discussion for biologists to a fundamental shift\nin how we will be analyzing genomic data in the future.",
            "author": [
                "Micaela E. Consens",
                "Cameron Dufault",
                "Michael Wainberg",
                "Duncan Forster",
                "Mehran Karimzadeh",
                "Hani Goodarzi",
                "Fabian J. Theis",
                "Alan Moses",
                "Bo Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07621v1",
                "http://arxiv.org/pdf/2311.07621v1"
            ],
            "primary_category": "q-bio.GN",
            "category": [
                "q-bio.GN",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07013v1",
            "title": "A PAC-Bayesian Perspective on the Interpolating Information Criterion",
            "updated": "2023-11-13T01:48:08Z",
            "published": "2023-11-13T01:48:08Z",
            "summary": "Deep learning is renowned for its theory-practice gap, whereby principled\ntheory typically fails to provide much beneficial guidance for implementation\nin practice. This has been highlighted recently by the benign overfitting\nphenomenon: when neural networks become sufficiently large to interpolate the\ndataset perfectly, model performance appears to improve with increasing model\nsize, in apparent contradiction with the well-known bias-variance tradeoff.\nWhile such phenomena have proven challenging to theoretically study for general\nmodels, the recently proposed Interpolating Information Criterion (IIC)\nprovides a valuable theoretical framework to examine performance for\noverparameterized models. Using the IIC, a PAC-Bayes bound is obtained for a\ngeneral class of models, characterizing factors which influence generalization\nperformance in the interpolating regime. From the provided bound, we quantify\nhow the test error for overparameterized models achieving effectively zero\ntraining error depends on the quality of the implicit regularization imposed by\ne.g. the combination of model, optimizer, and parameter-initialization scheme;\nthe spectrum of the empirical neural tangent kernel; curvature of the loss\nlandscape; and noise present in the data.",
            "author": [
                "Liam Hodgkinson",
                "Chris van der Heide",
                "Robert Salomone",
                "Fred Roosta",
                "Michael W. Mahoney"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07013v1",
                "http://arxiv.org/pdf/2311.07013v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07010v1",
            "title": "From Authority-Respect to Grassroots-Dissent: Degree-Weighted Social\n  Learning and Convergence Speed",
            "updated": "2023-11-13T01:44:05Z",
            "published": "2023-11-13T01:44:05Z",
            "summary": "Opinions are influenced by neighbors, with varying degrees of emphasis based\non their connections. Some may value more connected neighbors' views due to\nauthority respect, while others might lean towards grassroots perspectives. The\nemergence of ChatGPT could signify a new ``opinion leader'' whose views people\nput a lot of weight on. This study introduces a degree-weighted DeGroot\nlearning model to examine the effects of such belief updates on learning\noutcomes, especially the speed of belief convergence. We find that greater\nrespect for authority doesn't guarantee faster convergence. The influence of\nauthority respect is non-monotonic. The convergence speed, influenced by\nincreased authority-respect or grassroots dissent, hinges on the unity of elite\nand grassroots factions. This research sheds light on the growing skepticism\ntowards public figures and the ensuing dissonance in public debate.",
            "author": [
                "Chen Cheng",
                "Xiao Han",
                "Xin Tong",
                "Yusheng Wu",
                "Yiqing Xing"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07010v1",
                "http://arxiv.org/pdf/2311.07010v1"
            ],
            "primary_category": "econ.TH",
            "category": [
                "econ.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07002v1",
            "title": "PICS in Pics: Physics Informed Contour Selection for Rapid Image\n  Segmentation",
            "updated": "2023-11-13T01:03:19Z",
            "published": "2023-11-13T01:03:19Z",
            "summary": "Effective training of deep image segmentation models is challenging due to\nthe need for abundant, high-quality annotations. Generating annotations is\nlaborious and time-consuming for human experts, especially in medical image\nsegmentation. To facilitate image annotation, we introduce Physics Informed\nContour Selection (PICS) - an interpretable, physics-informed algorithm for\nrapid image segmentation without relying on labeled data. PICS draws\ninspiration from physics-informed neural networks (PINNs) and an active contour\nmodel called snake. It is fast and computationally lightweight because it\nemploys cubic splines instead of a deep neural network as a basis function. Its\ntraining parameters are physically interpretable because they directly\nrepresent control knots of the segmentation curve. Traditional snakes involve\nminimization of the edge-based loss functionals by deriving the Euler-Lagrange\nequation followed by its numerical solution. However, PICS directly minimizes\nthe loss functional, bypassing the Euler Lagrange equations. It is the first\nsnake variant to minimize a region-based loss function instead of traditional\nedge-based loss functions. PICS uniquely models the three-dimensional (3D)\nsegmentation process with an unsteady partial differential equation (PDE),\nwhich allows accelerated segmentation via transfer learning. To demonstrate its\neffectiveness, we apply PICS for 3D segmentation of the left ventricle on a\npublicly available cardiac dataset. While doing so, we also introduce a new\nconvexity-preserving loss term that encodes the shape information of the left\nventricle to enhance PICS's segmentation quality. Overall, PICS presents\nseveral novelties in network architecture, transfer learning, and\nphysics-inspired losses for image segmentation, thereby showing promising\noutcomes and potential for further refinement.",
            "author": [
                "Vikas Dwivedi",
                "Balaji Srinivasan",
                "Ganapathy Krishnamurthi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07002v1",
                "http://arxiv.org/pdf/2311.07002v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06998v1",
            "title": "The Privacy Pillar -- A Conceptual Framework for Foundation Model-based\n  Systems",
            "updated": "2023-11-13T00:44:06Z",
            "published": "2023-11-13T00:44:06Z",
            "summary": "AI and its relevant technologies, including machine learning, deep learning,\nchatbots, virtual assistants, and others, are currently undergoing a profound\ntransformation of development and organizational processes within companies.\nFoundation models present both significant challenges and incredible\nopportunities. In this context, ensuring the quality attributes of foundation\nmodel-based systems is of paramount importance, and with a particular focus on\nthe challenging issue of privacy due to the sensitive nature of the data and\ninformation involved. However, there is currently a lack of consensus regarding\nthe comprehensive scope of both technical and non-technical issues that the\nprivacy evaluation process should encompass. Additionally, there is uncertainty\nabout which existing methods are best suited to effectively address these\nprivacy concerns. In response to this challenge, this paper introduces a novel\nconceptual framework that integrates various responsible AI patterns from\nmultiple perspectives, with the specific aim of safeguarding privacy.",
            "author": [
                "Tingting Bi",
                "Guangsheng Yu",
                "Qinghua Lu",
                "Xiwei Xu",
                "Nick Van Beest"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06998v1",
                "http://arxiv.org/pdf/2311.06998v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06996v2",
            "title": "AGRAMPLIFIER: Defending Federated Learning Against Poisoning Attacks\n  Through Local Update Amplification",
            "updated": "2023-11-23T11:30:13Z",
            "published": "2023-11-13T00:34:45Z",
            "summary": "The collaborative nature of federated learning (FL) poses a major threat in\nthe form of manipulation of local training data and local updates, known as the\nByzantine poisoning attack. To address this issue, many Byzantine-robust\naggregation rules (AGRs) have been proposed to filter out or moderate\nsuspicious local updates uploaded by Byzantine participants.\n  This paper introduces a novel approach called AGRAMPLIFIER, aiming to\nsimultaneously improve the robustness, fidelity, and efficiency of the existing\nAGRs. The core idea of AGRAMPLIFIER is to amplify the \"morality\" of local\nupdates by identifying the most repressive features of each gradient update,\nwhich provides a clearer distinction between malicious and benign updates,\nconsequently improving the detection effect. To achieve this objective, two\napproaches, namely AGRMP and AGRXAI, are proposed. AGRMP organizes local\nupdates into patches and extracts the largest value from each patch, while\nAGRXAI leverages explainable AI methods to extract the gradient of the most\nactivated features. By equipping AGRAMPLIFIER with the existing\nByzantine-robust mechanisms, we successfully enhance the model's robustness,\nmaintaining its fidelity and improving overall efficiency.\n  AGRAMPLIFIER is universally compatible with the existing Byzantine-robust\nmechanisms. The paper demonstrates its effectiveness by integrating it with all\nmainstream AGR mechanisms. Extensive evaluations conducted on seven datasets\nfrom diverse domains against seven representative poisoning attacks\nconsistently show enhancements in robustness, fidelity, and efficiency, with\naverage gains of 40.08%, 39.18%, and 10.68%, respectively.",
            "author": [
                "Zirui Gong",
                "Liyue Shen",
                "Yanjun Zhang",
                "Leo Yu Zhang",
                "Jingwei Wang",
                "Guangdong Bai",
                "Yong Xiang"
            ],
            "link": [
                "http://dx.doi.org/10.1109/TIFS.2023.3333555",
                "http://arxiv.org/abs/2311.06996v2",
                "http://arxiv.org/pdf/2311.06996v2"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06995v1",
            "title": "Scalable Delivery of Scalable Libraries and Tools: How ECP Delivered a\n  Software Ecosystem for Exascale and Beyond",
            "updated": "2023-11-13T00:30:43Z",
            "published": "2023-11-13T00:30:43Z",
            "summary": "The Exascale Computing Project (ECP) was one of the largest open-source\nscientific software development projects ever. It supported approximately 1,000\nstaff from US Department of Energy laboratories, and university and industry\npartners. About 250 staff contributed to 70 scientific libraries and tools to\nsupport applications on multiple exascale computing systems that were also\nunder development.\n  Funded as a construction project, ECP adopted an earned-value management\nsystem, based on milestones. and a key performance parameter system based, in\npart, on integrations. With accelerated delivery schedules and significant\nproject risk, we also emphasized software quality using community policies,\nautomated testing, and continuous integration. Software Development Kit teams\nprovided cross-team collaboration. Products were delivered via E4S, a curated\nportfolio of libraries and tools.\n  In this paper, we discuss the organizational and management elements that\nenabled the efficient and effective delivery of ECP libraries and tools,\nlessons learned and next steps.",
            "author": [
                "Michael A. Heroux"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06995v1",
                "http://arxiv.org/pdf/2311.06995v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06985v1",
            "title": "SELF-EXPLAIN: Teaching Large Language Models to Reason Complex Questions\n  by Themselves",
            "updated": "2023-11-12T23:14:43Z",
            "published": "2023-11-12T23:14:43Z",
            "summary": "Large language models (LLMs) can generate intermediate reasoning steps. To\nelicit the reliable reasoning, the common practice is to employ few-shot\nchain-of-thought prompting, where several in-context demonstrations for\nreasoning are prepended to the question. However, such chain-of-thought\nexamples are expensive to craft, especially for professional domains, and can\nhave high variance depending on human annotators. Therefore, this work\ninvestigates whether LLMs can teach themselves to reason without human-crafted\ndemonstrations. We propose SELF-EXPLAIN to generate CoT examples by LLMs\ninspired by \"encoding specificity\" in human memory retrieval. We find using\nself-explanations makes LLMs more confident, more calibrated and less biased\nwhen answering complex questions. Moreover, we find prompting with\nself-explanations can even significantly outperform using human-crafted CoTs on\nseveral complex question answering dataset.",
            "author": [
                "Jiachen Zhao",
                "Zonghai Yao",
                "Zhichao Yang",
                "Hong Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06985v1",
                "http://arxiv.org/pdf/2311.06985v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06978v1",
            "title": "Augmented Bridge Matching",
            "updated": "2023-11-12T22:42:34Z",
            "published": "2023-11-12T22:42:34Z",
            "summary": "Flow and bridge matching are a novel class of processes which encompass\ndiffusion models. One of the main aspect of their increased flexibility is that\nthese models can interpolate between arbitrary data distributions i.e. they\ngeneralize beyond generative modeling and can be applied to learning stochastic\n(and deterministic) processes of arbitrary transfer tasks between two given\ndistributions. In this paper, we highlight that while flow and bridge matching\nprocesses preserve the information of the marginal distributions, they do\n\\emph{not} necessarily preserve the coupling information unless additional,\nstronger optimality conditions are met. This can be problematic if one aims at\npreserving the original empirical pairing. We show that a simple modification\nof the matching process recovers this coupling by augmenting the velocity field\n(or drift) with the information of the initial sample point. Doing so, we lose\nthe Markovian property of the process but preserve the coupling information\nbetween distributions. We illustrate the efficiency of our augmentation in\nlearning mixture of image translation tasks.",
            "author": [
                "Valentin De Bortoli",
                "Guan-Horng Liu",
                "Tianrong Chen",
                "Evangelos A. Theodorou",
                "Weilie Nie"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06978v1",
                "http://arxiv.org/pdf/2311.06978v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06976v1",
            "title": "CD-COCO: A Versatile Complex Distorted COCO Database for\n  Scene-Context-Aware Computer Vision",
            "updated": "2023-11-12T22:28:19Z",
            "published": "2023-11-12T22:28:19Z",
            "summary": "The recent development of deep learning methods applied to vision has enabled\ntheir increasing integration into real-world applications to perform complex\nComputer Vision (CV) tasks. However, image acquisition conditions have a major\nimpact on the performance of high-level image processing. A possible solution\nto overcome these limitations is to artificially augment the training databases\nor to design deep learning models that are robust to signal distortions. We opt\nhere for the first solution by enriching the database with complex and\nrealistic distortions which were ignored until now in the existing databases.\nTo this end, we built a new versatile database derived from the well-known\nMS-COCO database to which we applied local and global photo-realistic\ndistortions. These new local distortions are generated by considering the scene\ncontext of the images that guarantees a high level of photo-realism.\nDistortions are generated by exploiting the depth information of the objects in\nthe scene as well as their semantics. This guarantees a high level of\nphoto-realism and allows to explore real scenarios ignored in conventional\ndatabases dedicated to various CV applications. Our versatile database offers\nan efficient solution to improve the robustness of various CV tasks such as\nObject Detection (OD), scene segmentation, and distortion-type classification\nmethods. The image database, scene classification index, and distortion\ngeneration codes are publicly available\n\\footnote{\\url{https://github.com/Aymanbegh/CD-COCO}}",
            "author": [
                "Ayman Beghdadi",
                "Azeddine Beghdadi",
                "Malik Mallem",
                "Lotfi Beji",
                "Faouzi Alaya Cheikh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06976v1",
                "http://arxiv.org/pdf/2311.06976v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.DB"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06973v1",
            "title": "Analytical Verification of Deep Neural Network Performance for\n  Time-Synchronized Distribution System State Estimation",
            "updated": "2023-11-12T22:01:34Z",
            "published": "2023-11-12T22:01:34Z",
            "summary": "Recently, we demonstrated success of a time-synchronized state estimator\nusing deep neural networks (DNNs) for real-time unobservable distribution\nsystems. In this letter, we provide analytical bounds on the performance of\nthat state estimator as a function of perturbations in the input measurements.\nIt has already been shown that evaluating performance based on only the test\ndataset might not effectively indicate a trained DNN's ability to handle input\nperturbations. As such, we analytically verify robustness and trustworthiness\nof DNNs to input perturbations by treating them as mixed-integer linear\nprogramming (MILP) problems. The ability of batch normalization in addressing\nthe scalability limitations of the MILP formulation is also highlighted. The\nframework is validated by performing time-synchronized distribution system\nstate estimation for a modified IEEE 34-node system and a real-world large\ndistribution system, both of which are incompletely observed by micro-phasor\nmeasurement units.",
            "author": [
                "Behrouz Azimian",
                "Shiva Moshtagh",
                "Anamitra Pal",
                "Shanshan Ma"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06973v1",
                "http://arxiv.org/pdf/2311.06973v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06972v1",
            "title": "An Expandable Machine Learning-Optimization Framework to Sequential\n  Decision-Making",
            "updated": "2023-11-12T21:54:53Z",
            "published": "2023-11-12T21:54:53Z",
            "summary": "We present an integrated prediction-optimization (PredOpt) framework to\nefficiently solve sequential decision-making problems by predicting the values\nof binary decision variables in an optimal solution. We address the key issues\nof sequential dependence, infeasibility, and generalization in machine learning\n(ML) to make predictions for optimal solutions to combinatorial problems. The\nsequential nature of the combinatorial optimization problems considered is\ncaptured with recurrent neural networks and a sliding-attention window. We\nintegrate an attention-based encoder-decoder neural network architecture with\nan infeasibility-elimination and generalization framework to learn high-quality\nfeasible solutions to time-dependent optimization problems. In this framework,\nthe required level of predictions is optimized to eliminate the infeasibility\nof the ML predictions. These predictions are then fixed in mixed-integer\nprogramming (MIP) problems to solve them quickly with the aid of a commercial\nsolver. We demonstrate our approach to tackling the two well-known dynamic\nNP-Hard optimization problems: multi-item capacitated lot-sizing (MCLSP) and\nmulti-dimensional knapsack (MSMK). Our results show that models trained on\nshorter and smaller-dimensional instances can be successfully used to predict\nlonger and larger-dimensional problems. The solution time can be reduced by\nthree orders of magnitude with an average optimality gap below 0.1%. We compare\nPredOpt with various specially designed heuristics and show that our framework\noutperforms them. PredOpt can be advantageous for solving dynamic MIP problems\nthat need to be solved instantly and repetitively.",
            "author": [
                "Dogacan Yilmaz",
                "\u0130. Esra B\u00fcy\u00fcktahtak\u0131n"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.ejor.2023.10.045",
                "http://arxiv.org/abs/2311.06972v1",
                "http://arxiv.org/pdf/2311.06972v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06968v1",
            "title": "Physics-Informed Data Denoising for Real-Life Sensing Systems",
            "updated": "2023-11-12T21:25:56Z",
            "published": "2023-11-12T21:25:56Z",
            "summary": "Sensors measuring real-life physical processes are ubiquitous in today's\ninterconnected world. These sensors inherently bear noise that often adversely\naffects performance and reliability of the systems they support. Classic\nfiltering-based approaches introduce strong assumptions on the time or\nfrequency characteristics of sensory measurements, while learning-based\ndenoising approaches typically rely on using ground truth clean data to train a\ndenoising model, which is often challenging or prohibitive to obtain for many\nreal-world applications. We observe that in many scenarios, the relationships\nbetween different sensor measurements (e.g., location and acceleration) are\nanalytically described by laws of physics (e.g., second-order differential\nequation). By incorporating such physics constraints, we can guide the\ndenoising process to improve even in the absence of ground truth data. In light\nof this, we design a physics-informed denoising model that leverages the\ninherent algebraic relationships between different measurements governed by the\nunderlying physics. By obviating the need for ground truth clean data, our\nmethod offers a practical denoising solution for real-world applications. We\nconducted experiments in various domains, including inertial navigation, CO2\nmonitoring, and HVAC control, and achieved state-of-the-art performance\ncompared with existing denoising methods. Our method can denoise data in real\ntime (4ms for a sequence of 1s) for low-cost noisy sensors and produces results\nthat closely align with those from high-precision, high-cost alternatives,\nleading to an efficient, cost-effective approach for more accurate sensor-based\nsystems.",
            "author": [
                "Xiyuan Zhang",
                "Xiaohan Fu",
                "Diyan Teng",
                "Chengyu Dong",
                "Keerthivasan Vijayakumar",
                "Jiayun Zhang",
                "Ranak Roy Chowdhury",
                "Junsheng Han",
                "Dezhi Hong",
                "Rashmi Kulkarni",
                "Jingbo Shang",
                "Rajesh Gupta"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06968v1",
                "http://arxiv.org/pdf/2311.06968v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "eess.SP",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06965v2",
            "title": "Anchor Data Augmentation",
            "updated": "2023-11-27T19:22:27Z",
            "published": "2023-11-12T21:08:43Z",
            "summary": "We propose a novel algorithm for data augmentation in nonlinear\nover-parametrized regression. Our data augmentation algorithm borrows from the\nliterature on causality and extends the recently proposed Anchor regression\n(AR) method for data augmentation, which is in contrast to the current\nstate-of-the-art domain-agnostic solutions that rely on the Mixup literature.\nOur Anchor Data Augmentation (ADA) uses several replicas of the modified\nsamples in AR to provide more training examples, leading to more robust\nregression predictions. We apply ADA to linear and nonlinear regression\nproblems using neural networks. ADA is competitive with state-of-the-art\nC-Mixup solutions.",
            "author": [
                "Nora Schneider",
                "Shirin Goshtasbpour",
                "Fernando Perez-Cruz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06965v2",
                "http://arxiv.org/pdf/2311.06965v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06964v1",
            "title": "Adaptive recurrent vision performs zero-shot computation scaling to\n  unseen difficulty levels",
            "updated": "2023-11-12T21:07:04Z",
            "published": "2023-11-12T21:07:04Z",
            "summary": "Humans solving algorithmic (or) reasoning problems typically exhibit solution\ntimes that grow as a function of problem difficulty. Adaptive recurrent neural\nnetworks have been shown to exhibit this property for various\nlanguage-processing tasks. However, little work has been performed to assess\nwhether such adaptive computation can also enable vision models to extrapolate\nsolutions beyond their training distribution's difficulty level, with prior\nwork focusing on very simple tasks. In this study, we investigate a critical\nfunctional role of such adaptive processing using recurrent neural networks: to\ndynamically scale computational resources conditional on input requirements\nthat allow for zero-shot generalization to novel difficulty levels not seen\nduring training using two challenging visual reasoning tasks: PathFinder and\nMazes. We combine convolutional recurrent neural networks (ConvRNNs) with a\nlearnable halting mechanism based on Graves (2016). We explore various\nimplementations of such adaptive ConvRNNs (AdRNNs) ranging from tying weights\nacross layers to more sophisticated biologically inspired recurrent networks\nthat possess lateral connections and gating. We show that 1) AdRNNs learn to\ndynamically halt processing early (or late) to solve easier (or harder)\nproblems, 2) these RNNs zero-shot generalize to more difficult problem settings\nnot shown during training by dynamically increasing the number of recurrent\niterations at test time. Our study provides modeling evidence supporting the\nhypothesis that recurrent processing enables the functional advantage of\nadaptively allocating compute resources conditional on input requirements and\nhence allowing generalization to harder difficulty levels of a visual reasoning\nproblem without training.",
            "author": [
                "Vijay Veerabadran",
                "Srinivas Ravishankar",
                "Yuan Tang",
                "Ritik Raina",
                "Virginia R. de Sa"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06964v1",
                "http://arxiv.org/pdf/2311.06964v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06962v1",
            "title": "Atlas: Hybrid Cloud Migration Advisor for Interactive Microservices",
            "updated": "2023-11-12T21:01:42Z",
            "published": "2023-11-12T21:01:42Z",
            "summary": "Hybrid cloud provides an attractive solution to microservices for better\nresource elasticity. A subset of application components can be offloaded from\nthe on-premises cluster to the cloud, where they can readily access additional\nresources. However, the selection of this subset is challenging because of the\nlarge number of possible combinations. A poor choice degrades the application\nperformance, disrupts the critical services, and increases the cost to the\nextent of making the use of hybrid cloud unviable. This paper presents Atlas, a\nhybrid cloud migration advisor. Atlas uses a data-driven approach to learn how\neach user-facing API utilizes different components and their network footprints\nto drive the migration decision. It learns to accelerate the discovery of\nhigh-quality migration plans from millions and offers recommendations with\ncustomizable trade-offs among three quality indicators: end-to-end latency of\nuser-facing APIs representing application performance, service availability,\nand cloud hosting costs. Atlas continuously monitors the application even after\nthe migration for proactive recommendations. Our evaluation shows that Atlas\ncan achieve 21% better API performance (latency) and 11% cheaper cost with less\nservice disruption than widely used solutions.",
            "author": [
                "Ka-Ho Chow",
                "Umesh Deshpande",
                "Veera Deenadhayalan",
                "Sangeetha Seshadri",
                "Ling Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06962v1",
                "http://arxiv.org/pdf/2311.06962v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06961v1",
            "title": "Empowering Learning: Standalone, Browser-Only Courses for Seamless\n  Education",
            "updated": "2023-11-12T20:59:52Z",
            "published": "2023-11-12T20:59:52Z",
            "summary": "Massive Open Online Courses (MOOCs) have transformed the educational\nlandscape, offering scalable and flexible learning opportunities, particularly\nin data-centric fields like data science and artificial intelligence.\nIncorporating AI and data science into MOOCs is a potential means of enhancing\nthe learning experience through adaptive learning approaches. In this context,\nwe introduce PyGlide, a proof-of-concept open-source MOOC delivery system that\nunderscores autonomy, transparency, and collaboration in maintaining course\ncontent. We provide a user-friendly, step-by-step guide for PyGlide,\nemphasizing its distinct advantage of not requiring any local software\ninstallation for students. Highlighting its potential to enhance accessibility,\ninclusivity, and the manageability of course materials, we showcase PyGlide's\npractical application in a continuous integration pipeline on GitHub. We\nbelieve that PyGlide charts a promising course for the future of open-source\nMOOCs, effectively addressing crucial challenges in online education.",
            "author": [
                "Babak Moghadas",
                "Brian S. Caffo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06961v1",
                "http://arxiv.org/pdf/2311.06961v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06960v1",
            "title": "Robust Regression over Averaged Uncertainty",
            "updated": "2023-11-12T20:57:30Z",
            "published": "2023-11-12T20:57:30Z",
            "summary": "We propose a new formulation of robust regression by integrating all\nrealizations of the uncertainty set and taking an averaged approach to obtain\nthe optimal solution for the ordinary least-squared regression problem. We show\nthat this formulation surprisingly recovers ridge regression and establishes\nthe missing link between robust optimization and the mean squared error\napproaches for existing regression problems. We first prove the equivalence for\nfour uncertainty sets: ellipsoidal, box, diamond, and budget, and provide\nclosed-form formulations of the penalty term as a function of the sample size,\nfeature size, as well as perturbation protection strength. We then show in\nsynthetic datasets with different levels of perturbations, a consistent\nimprovement of the averaged formulation over the existing worst-case\nformulation in out-of-sample performance. Importantly, as the perturbation\nlevel increases, the improvement increases, confirming our method's advantage\nin high-noise environments. We report similar improvements in the out-of-sample\ndatasets in real-world regression problems obtained from UCI datasets.",
            "author": [
                "Dimitris Bertsimas",
                "Yu Ma"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06960v1",
                "http://arxiv.org/pdf/2311.06960v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06958v1",
            "title": "Towards probabilistic Weather Forecasting with Conditioned\n  Spatio-Temporal Normalizing Flows",
            "updated": "2023-11-12T20:52:14Z",
            "published": "2023-11-12T20:52:14Z",
            "summary": "Generative normalizing flows are able to model multimodal spatial\ndistributions, and they have been shown to model temporal correlations\nsuccessfully as well. These models provide several benefits over other types of\ngenerative models due to their training stability, invertibility and efficiency\nin sampling and inference. This makes them a suitable candidate for stochastic\nspatio-temporal prediction problems, which are omnipresent in many fields of\nsciences, such as earth sciences, astrophysics or molecular sciences. In this\npaper, we present conditional normalizing flows for stochastic spatio-temporal\nmodelling. The method is evaluated on the task of daily temperature and hourly\ngeopotential map prediction from ERA5 datasets. Experiments show that our\nmethod is able to capture spatio-temporal correlations and extrapolates well\nbeyond the time horizon used during training.",
            "author": [
                "Christina Winkler"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06958v1",
                "http://arxiv.org/pdf/2311.06958v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06954v1",
            "title": "Multimodal Learning of Soft Robot Dynamics using Differentiable Filters",
            "updated": "2023-11-12T20:41:09Z",
            "published": "2023-11-12T20:41:09Z",
            "summary": "Differentiable Filters, as recursive Bayesian estimators, possess the ability\nto learn complex dynamics by deriving state transition and measurement models\nexclusively from data. This data-driven approach eliminates the reliance on\nexplicit analytical models while maintaining the essential algorithmic\ncomponents of the filtering process. However, the gain mechanism remains\nnon-differentiable, limiting its adaptability to specific task requirements and\ncontextual variations. To address this limitation, this paper introduces an\ninnovative approach called {\\alpha}-MDF (Attention-based Multimodal\nDifferentiable Filter). {\\alpha}-MDF leverages modern attention mechanisms to\nlearn multimodal latent representations for accurate state estimation in soft\nrobots. By incorporating attention mechanisms, {\\alpha}-MDF offers the\nflexibility to tailor the gain mechanism to the unique nature of the task and\ncontext. The effectiveness of {\\alpha}-MDF is validated through real-world\nstate estimation tasks on soft robots. Our experimental results demonstrate\nsignificant reductions in state estimation errors, consistently surpassing\ndifferentiable filter baselines by up to 45% in the domain of soft robotics.",
            "author": [
                "Xiao Liu",
                "Yifan Zhou",
                "Shuhei Ikemoto",
                "Heni Ben Amor"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06954v1",
                "http://arxiv.org/pdf/2311.06954v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06953v1",
            "title": "Bregman Proximal Method for Efficient Communications under Similarity",
            "updated": "2023-11-12T20:36:46Z",
            "published": "2023-11-12T20:36:46Z",
            "summary": "We propose a novel distributed method for monotone variational inequalities\nand convex-concave saddle point problems arising in various machine learning\napplications such as game theory and adversarial training. By exploiting\n\\textit{similarity} our algorithm overcomes communication bottleneck which is a\nmajor issue in distributed optimization. The proposed algorithm enjoys optimal\ncommunication complexity of $\\delta/\\epsilon$, where $\\epsilon$ measures the\nnon-optimality gap function, and $\\delta$ is a parameter of similarity. All the\nexisting distributed algorithms achieving this bound essentially utilize the\nEuclidean setup.\n  In contrast to them, our algorithm is built upon Bregman proximal maps and it\nis compatible with an arbitrary Bregman divergence. Thanks to this, it has more\nflexibility to fit the problem geometry than algorithms with the Euclidean\nsetup. Thereby the proposed method bridges the gap between the Euclidean and\nnon-Euclidean setting.\n  By using the restart technique, we extend our algorithm to variational\ninequalities with $\\mu$-strongly monotone operator, resulting in optimal\ncommunication complexity of $\\delta/\\mu$ (up to a logarithmic factor). Our\ntheoretical results are confirmed by numerical experiments on a stochastic\nmatrix game.",
            "author": [
                "Aleksandr Beznosikov",
                "Darina Dvinskikh",
                "Andrei Semenov",
                "Alexander Gasnikov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06953v1",
                "http://arxiv.org/pdf/2311.06953v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06952v1",
            "title": "A GPU-Accelerated Moving-Horizon Algorithm for Training Deep\n  Classification Trees on Large Datasets",
            "updated": "2023-11-12T20:34:00Z",
            "published": "2023-11-12T20:34:00Z",
            "summary": "Decision trees are essential yet NP-complete to train, prompting the\nwidespread use of heuristic methods such as CART, which suffers from\nsub-optimal performance due to its greedy nature. Recently, breakthroughs in\nfinding optimal decision trees have emerged; however, these methods still face\nsignificant computational costs and struggle with continuous features in\nlarge-scale datasets and deep trees. To address these limitations, we introduce\na moving-horizon differential evolution algorithm for classification trees with\ncontinuous features (MH-DEOCT). Our approach consists of a discrete tree\ndecoding method that eliminates duplicated searches between adjacent samples, a\nGPU-accelerated implementation that significantly reduces running time, and a\nmoving-horizon strategy that iteratively trains shallow subtrees at each node\nto balance the vision and optimizer capability. Comprehensive studies on 68 UCI\ndatasets demonstrate that our approach outperforms the heuristic method CART on\ntraining and testing accuracy by an average of 3.44% and 1.71%, respectively.\nMoreover, these numerical studies empirically demonstrate that MH-DEOCT\nachieves near-optimal performance (only 0.38% and 0.06% worse than the global\noptimal method on training and testing, respectively), while it offers\nremarkable scalability for deep trees (e.g., depth=8) and large-scale datasets\n(e.g., ten million samples).",
            "author": [
                "Jiayang Ren",
                "Valent\u00edn Osuna-Enciso",
                "Morimasa Okamoto",
                "Qiangqiang Mao",
                "Chaojie Ji",
                "Liang Cao",
                "Kaixun Hua",
                "Yankai Cao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06952v1",
                "http://arxiv.org/pdf/2311.06952v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06942v1",
            "title": "Contractive Systems Improve Graph Neural Networks Against Adversarial\n  Attacks",
            "updated": "2023-11-12T20:06:48Z",
            "published": "2023-11-12T20:06:48Z",
            "summary": "Graph Neural Networks (GNNs) have established themselves as a key component\nin addressing diverse graph-based tasks. Despite their notable successes, GNNs\nremain susceptible to input perturbations in the form of adversarial attacks.\nThis paper introduces an innovative approach to fortify GNNs against\nadversarial perturbations through the lens of contractive dynamical systems.\nOur method introduces graph neural layers based on differential equations with\ncontractive properties, which, as we show, improve the robustness of GNNs. A\ndistinctive feature of the proposed approach is the simultaneous learned\nevolution of both the node features and the adjacency matrix, yielding an\nintrinsic enhancement of model robustness to perturbations in the input\nfeatures and the connectivity of the graph. We mathematically derive the\nunderpinnings of our novel architecture and provide theoretical insights to\nreason about its expected behavior. We demonstrate the efficacy of our method\nthrough numerous real-world benchmarks, reading on par or improved performance\ncompared to existing methods.",
            "author": [
                "Moshe Eliasof",
                "Davide Murari",
                "Ferdia Sherry",
                "Carola-Bibiane Sch\u00f6nlieb"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06942v1",
                "http://arxiv.org/pdf/2311.06942v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06938v1",
            "title": "5G Networks and IoT Devices: Mitigating DDoS Attacks with Deep Learning\n  Techniques",
            "updated": "2023-11-12T19:50:49Z",
            "published": "2023-11-12T19:50:49Z",
            "summary": "The development and implementation of Internet of Things (IoT) devices have\nbeen accelerated dramatically in recent years. As a result, a super-network is\nrequired to handle the massive volumes of data collected and transmitted to\nthese devices. Fifth generation (5G) technology is a new, comprehensive\nwireless technology that has the potential to be the primary enabling\ntechnology for the IoT. The rapid spread of IoT devices can encounter many\nsecurity limits and concerns. As a result, new and serious security and privacy\nrisks have emerged. Attackers use IoT devices to launch massive attacks; one of\nthe most famous is the Distributed Denial of Service (DDoS) attack. Deep\nLearning techniques have proven their effectiveness in detecting and mitigating\nDDoS attacks. In this paper, we applied two Deep Learning algorithms\nConvolutional Neural Network (CNN) and Feed Forward Neural Network (FNN) in\ndataset was specifically designed for IoT devices within 5G networks. We\nconstructed the 5G network infrastructure using OMNeT++ with the INET and\nSimu5G frameworks. The dataset encompasses both normal network traffic and DDoS\nattacks. The Deep Learning algorithms, CNN and FNN, showed impressive accuracy\nlevels, both reaching 99%. These results underscore the potential of Deep\nLearning to enhance the security of IoT devices within 5G networks.",
            "author": [
                "Reem M. Alzhrani",
                "Mohammed A. Alliheedi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06938v1",
                "http://arxiv.org/pdf/2311.06938v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LG",
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06928v3",
            "title": "Attention for Causal Relationship Discovery from Biological Neural\n  Dynamics",
            "updated": "2023-11-23T08:40:20Z",
            "published": "2023-11-12T18:59:42Z",
            "summary": "This paper explores the potential of the transformer models for learning\nGranger causality in networks with complex nonlinear dynamics at every node, as\nin neurobiological and biophysical networks. Our study primarily focuses on a\nproof-of-concept investigation based on simulated neural dynamics, for which\nthe ground-truth causality is known through the underlying connectivity matrix.\nFor transformer models trained to forecast neuronal population dynamics, we\nshow that the cross attention module effectively captures the causal\nrelationship among neurons, with an accuracy equal or superior to that for the\nmost popular Granger causality analysis method. While we acknowledge that\nreal-world neurobiology data will bring further challenges, including dynamic\nconnectivity and unobserved variability, this research offers an encouraging\npreliminary glimpse into the utility of the transformer model for causal\nrepresentation learning in neuroscience.",
            "author": [
                "Ziyu Lu",
                "Anika Tabassum",
                "Shruti Kulkarni",
                "Lu Mi",
                "J. Nathan Kutz",
                "Eric Shea-Brown",
                "Seung-Hwan Lim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06928v3",
                "http://arxiv.org/pdf/2311.06928v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06921v1",
            "title": "Concept Matching: Clustering-based Federated Continual Learning",
            "updated": "2023-11-12T18:31:20Z",
            "published": "2023-11-12T18:31:20Z",
            "summary": "Federated Continual Learning (FCL) has emerged as a promising paradigm that\ncombines Federated Learning (FL) and Continual Learning (CL). To achieve good\nmodel accuracy, FCL needs to tackle catastrophic forgetting due to concept\ndrift over time in CL, and to overcome the potential interference among clients\nin FL. We propose Concept Matching (CM), a clustering-based framework for FCL\nto address these challenges. The CM framework groups the client models into\nconcept model clusters, and then builds different global models to capture\ndifferent concepts in FL over time. In each round, the server sends the global\nconcept models to the clients. To avoid catastrophic forgetting, each client\nselects the concept model best-matching the concept of the current data for\nfurther fine-tuning. To avoid interference among client models with different\nconcepts, the server clusters the models representing the same concept,\naggregates the model weights in each cluster, and updates the global concept\nmodel with the cluster model of the same concept. Since the server does not\nknow the concepts captured by the aggregated cluster models, we propose a novel\nserver concept matching algorithm that effectively updates a global concept\nmodel with a matching cluster model. The CM framework provides flexibility to\nuse different clustering, aggregation, and concept matching algorithms. The\nevaluation demonstrates that CM outperforms state-of-the-art systems and scales\nwell with the number of clients and the model size.",
            "author": [
                "Xiaopeng Jiang",
                "Cristian Borcea"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06921v1",
                "http://arxiv.org/pdf/2311.06921v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06918v1",
            "title": "Resource-Aware Hierarchical Federated Learning for Video Caching in\n  Wireless Networks",
            "updated": "2023-11-12T18:23:17Z",
            "published": "2023-11-12T18:23:17Z",
            "summary": "Video caching can significantly improve backhaul traffic congestion by\nlocally storing the popular content that users frequently request. A\nprivacy-preserving method is desirable to learn how users' demands change over\ntime. As such, this paper proposes a novel resource-aware hierarchical\nfederated learning (RawHFL) solution to predict users' future content requests\nunder the realistic assumptions that content requests are sporadic and users'\ndatasets can only be updated based on the requested content's information.\nConsidering a partial client participation case, we first derive the upper\nbound of the global gradient norm that depends on the clients' local training\nrounds and the successful reception of their accumulated gradients over the\nwireless links. Under delay, energy and radio resource constraints, we then\noptimize client selection and their local rounds and central processing unit\n(CPU) frequencies to minimize a weighted utility function that facilitates\nRawHFL's convergence in an energy-efficient way. Our simulation results show\nthat the proposed solution significantly outperforms the considered baselines\nin terms of prediction accuracy and total energy expenditure.",
            "author": [
                "Md Ferdous Pervej",
                "Andreas F Molisch"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06918v1",
                "http://arxiv.org/pdf/2311.06918v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "cs.LG",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06917v1",
            "title": "FLASH-RL: Federated Learning Addressing System and Static Heterogeneity\n  using Reinforcement Learning",
            "updated": "2023-11-12T18:21:00Z",
            "published": "2023-11-12T18:21:00Z",
            "summary": "Federated Learning (FL) has emerged as a promising Machine Learning paradigm,\nenabling multiple users to collaboratively train a shared model while\npreserving their local data. To minimize computing and communication costs\nassociated with parameter transfer, it is common practice in FL to select a\nsubset of clients in each training round. This selection must consider both\nsystem and static heterogeneity. Therefore, we propose FLASH-RL, a framework\nthat utilizes Double Deep QLearning (DDQL) to address both system and static\nheterogeneity in FL. FLASH-RL introduces a new reputation-based utility\nfunction to evaluate client contributions based on their current and past\nperformances. Additionally, an adapted DDQL algorithm is proposed to expedite\nthe learning process. Experimental results on MNIST and CIFAR-10 datasets have\nshown FLASH-RL's effectiveness in achieving a balanced trade-off between model\nperformance and end-to-end latency against existing solutions. Indeed, FLASH-RL\nreduces latency by up to 24.83% compared to FedAVG and 24.67% compared to\nFAVOR. It also reduces the training rounds by up to 60.44% compared to FedAVG\nand +76% compared to FAVOR. In fall detection using the MobiAct dataset,\nFLASH-RL outperforms FedAVG by up to 2.82% in model's performance and reduces\nlatency by up to 34.75%. Additionally, FLASH-RL achieves the target performance\nfaster, with up to a 45.32% reduction in training rounds compared to FedAVG.",
            "author": [
                "Sofiane Bouaziz",
                "Hadjer Benmeziane",
                "Youcef Imine",
                "Leila Hamdad",
                "Smail Niar",
                "Hamza Ouarnoughi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06917v1",
                "http://arxiv.org/pdf/2311.06917v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06916v1",
            "title": "TSViT: A Time Series Vision Transformer for Fault Diagnosis",
            "updated": "2023-11-12T18:16:48Z",
            "published": "2023-11-12T18:16:48Z",
            "summary": "Traditional fault diagnosis methods using Convolutional Neural Networks\n(CNNs) face limitations in capturing temporal features (i.e., the variation of\nvibration signals over time). To address this issue, this paper introduces a\nnovel model, the Time Series Vision Transformer (TSViT), specifically designed\nfor fault diagnosis. On one hand, TSViT model integrates a convolutional layer\nto segment vibration signals and capture local features. On the other hand, it\nemploys a transformer encoder to learn long-term temporal information. The\nexperimental results with other methods on two distinct datasets validate the\neffectiveness and generalizability of TSViT with a comparative analysis of its\nhyperparameters' impact on model performance, computational complexity, and\noverall parameter quantity. TSViT reaches average accuracies of 100% and 99.99%\non two test sets, correspondingly.",
            "author": [
                "Shouhua Zhang",
                "Jiehan Zhou",
                "Xue Ma",
                "Chenglin Wen",
                "Susanna Pirttikangas",
                "Chen Yu",
                "Weishan Zhang",
                "Chunsheng Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06916v1",
                "http://arxiv.org/pdf/2311.06916v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.AI",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06914v1",
            "title": "Model-assisted Reinforcement Learning of a Quadrotor",
            "updated": "2023-11-12T18:05:56Z",
            "published": "2023-11-12T18:05:56Z",
            "summary": "In recent times, reinforcement learning has produced baffling results when it\ncomes to performing control tasks with highly non-linear systems. The\nimpressive results always outweigh the potential vulnerabilities or\nuncertainties associated with the agents when deployed in the real-world. While\nthe performance is remarkable compared to the classical control algorithms, the\nreinforcement learning-based methods suffer from two flaws, robustness and\ninterpretability, which are vital for contemporary real-world applications. The\npaper attempts to alleviate such problems with reinforcement learning and\nproposes the concept of model-assisted reinforcement learning to induce a\nnotion of conservativeness in the agents. The control task considered for the\nexperiment involves navigating a CrazyFlie quadrotor. The paper also describes\na way of reformulating the task to have the flexibility of tuning the level of\nconservativeness via multi-objective reinforcement learning. The results\ninclude a comparison of the vanilla reinforcement learning approaches and the\nproposed approach. The metrics are evaluated by systematically injecting\ndisturbances to classify the inherent robustness and conservativeness of the\nagents. More concrete arguments are made by computing and comparing the\nbackward reachability tubes of the RL policies by solving the\nHamilton-Jacobi-Bellman partial differential equation (HJ PDE).",
            "author": [
                "Arshad Javeed"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06914v1",
                "http://arxiv.org/pdf/2311.06914v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07620v1",
            "title": "EPIM: Efficient Processing-In-Memory Accelerators based on Epitome",
            "updated": "2023-11-12T17:56:39Z",
            "published": "2023-11-12T17:56:39Z",
            "summary": "The exploration of Processing-In-Memory (PIM) accelerators has garnered\nsignificant attention within the research community. However, the utilization\nof large-scale neural networks on Processing-In-Memory (PIM) accelerators\nencounters challenges due to constrained on-chip memory capacity. To tackle\nthis issue, current works explore model compression algorithms to reduce the\nsize of Convolutional Neural Networks (CNNs). Most of these algorithms either\naim to represent neural operators with reduced-size parameters (e.g.,\nquantization) or search for the best combinations of neural operators (e.g.,\nneural architecture search). Designing neural operators to align with PIM\naccelerators' specifications is an area that warrants further study. In this\npaper, we introduce the Epitome, a lightweight neural operator offering\nconvolution-like functionality, to craft memory-efficient CNN operators for PIM\naccelerators (EPIM). On the software side, we evaluate epitomes' latency and\nenergy on PIM accelerators and introduce a PIM-aware layer-wise design method\nto enhance their hardware efficiency. We apply epitome-aware quantization to\nfurther reduce the size of epitomes. On the hardware side, we modify the\ndatapath of current PIM accelerators to accommodate epitomes and implement a\nfeature map reuse technique to reduce computation cost. Experimental results\nreveal that our 3-bit quantized EPIM-ResNet50 attains 71.59% top-1 accuracy on\nImageNet, reducing crossbar areas by 30.65 times. EPIM surpasses the\nstate-of-the-art pruning methods on PIM.",
            "author": [
                "Chenyu Wang",
                "Zhen Dong",
                "Daquan Zhou",
                "Zhenhua Zhu",
                "Yu Wang",
                "Jiashi Feng",
                "Kurt Keutzer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07620v1",
                "http://arxiv.org/pdf/2311.07620v1"
            ],
            "primary_category": "cs.AR",
            "category": [
                "cs.AR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06898v1",
            "title": "Retrieval and Generative Approaches for a Pregnancy Chatbot in Nepali\n  with Stemmed and Non-Stemmed Data : A Comparative Study",
            "updated": "2023-11-12T17:16:46Z",
            "published": "2023-11-12T17:16:46Z",
            "summary": "The field of Natural Language Processing which involves the use of artificial\nintelligence to support human languages has seen tremendous growth due to its\nhigh-quality features. Its applications such as language translation, chatbots,\nvirtual assistants, search autocomplete, and autocorrect are widely used in\nvarious domains including healthcare, advertising, customer service, and target\nadvertising. To provide pregnancy-related information a health domain chatbot\nhas been proposed and this work explores two different NLP-based approaches for\ndeveloping the chatbot. The first approach is a multiclass classification-based\nretrieval approach using BERTbased multilingual BERT and multilingual\nDistilBERT while the other approach employs a transformer-based generative\nchatbot for pregnancy-related information. The performance of both stemmed and\nnon-stemmed datasets in Nepali language has been analyzed for each approach.\nThe experimented results indicate that BERT-based pre-trained models perform\nwell on non-stemmed data whereas scratch transformer models have better\nperformance on stemmed data. Among the models tested the DistilBERT model\nachieved the highest training and validation accuracy and testing accuracy of\n0.9165 on the retrieval-based model architecture implementation on the\nnon-stemmed dataset. Similarly, in the generative approach architecture\nimplementation with transformer 1 gram BLEU and 2 gram BLEU scores of 0.3570\nand 0.1413 respectively were achieved.",
            "author": [
                "Sujan Poudel",
                "Nabin Ghimire",
                "Bipesh Subedi",
                "Saugat Singh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06898v1",
                "http://arxiv.org/pdf/2311.06898v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06894v1",
            "title": "An Application of Vector Autoregressive Model for Analyzing the Impact\n  of Weather And Nearby Traffic Flow On The Traffic Volume",
            "updated": "2023-11-12T16:45:29Z",
            "published": "2023-11-12T16:45:29Z",
            "summary": "This paper aims to predict the traffic flow at one road segment based on\nnearby traffic volume and weather conditions. Our team also discover the impact\nof weather conditions and nearby traffic volume on the traffic flow at a target\npoint. The analysis results will help solve the problem of traffic flow\nprediction and develop an optimal transport network with efficient traffic\nmovement and minimal traffic congestion. Hourly historical weather and traffic\nflow data are selected to solve this problem. This paper uses model VAR(36)\nwith time trend and constant to train the dataset and forecast. With an RMSE of\n565.0768111 on average, the model is considered appropriate although some\nstatistical tests implies that the residuals are unstable and non-normal. Also,\nthis paper points out some variables that are not useful in forecasting, which\nhelps simplify the data-collecting process when building the forecasting\nsystem.",
            "author": [
                "Anh Thi-Hoang Nguyen",
                "Dung Ha Nguyen",
                "Trong-Hop Do"
            ],
            "link": [
                "http://dx.doi.org/10.1109/RIVF55975.2022.10013894",
                "http://arxiv.org/abs/2311.06894v1",
                "http://arxiv.org/pdf/2311.06894v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06893v1",
            "title": "Methods of machine learning for the analysis of cosmic rays mass\n  composition with the KASCADE experiment data",
            "updated": "2023-11-12T16:39:04Z",
            "published": "2023-11-12T16:39:04Z",
            "summary": "We study the problem of reconstruction of high-energy cosmic rays mass\ncomposition from the experimental data of extensive air showers. We develop\nseveral machine learning methods for the reconstruction of energy spectra of\nseparate primary nuclei at energies 1-100 PeV, using the public data and\nMonte-Carlo simulations of the KASCADE experiment from the KCDC platform. We\nestimate the uncertainties of our methods, including the unfolding procedure,\nand show that the overall accuracy exceeds that of the method used in the\noriginal studies of the KASCADE experiment.",
            "author": [
                "M. Yu. Kuznetsov",
                "N. A. Petrov",
                "I. A. Plokhikh",
                "V. V. Sotnikov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06893v1",
                "http://arxiv.org/pdf/2311.06893v1"
            ],
            "primary_category": "astro-ph.HE",
            "category": [
                "astro-ph.HE",
                "astro-ph.IM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06888v1",
            "title": "Preserving Node-level Privacy in Graph Neural Networks",
            "updated": "2023-11-12T16:21:29Z",
            "published": "2023-11-12T16:21:29Z",
            "summary": "Differential privacy (DP) has seen immense applications in learning on\ntabular, image, and sequential data where instance-level privacy is concerned.\nIn learning on graphs, contrastingly, works on node-level privacy are highly\nsparse. Challenges arise as existing DP protocols hardly apply to the\nmessage-passing mechanism in Graph Neural Networks (GNNs).\n  In this study, we propose a solution that specifically addresses the issue of\nnode-level privacy. Our protocol consists of two main components: 1) a sampling\nroutine called HeterPoisson, which employs a specialized node sampling strategy\nand a series of tailored operations to generate a batch of sub-graphs with\ndesired properties, and 2) a randomization routine that utilizes symmetric\nmultivariate Laplace (SML) noise instead of the commonly used Gaussian noise.\nOur privacy accounting shows this particular combination provides a non-trivial\nprivacy guarantee. In addition, our protocol enables GNN learning with good\nperformance, as demonstrated by experiments on five real-world datasets;\ncompared with existing baselines, our method shows significant advantages,\nespecially in the high privacy regime. Experimentally, we also 1) perform\nmembership inference attacks against our protocol and 2) apply privacy audit\ntechniques to confirm our protocol's privacy integrity.\n  In the sequel, we present a study on a seemingly appealing approach\n\\cite{sajadmanesh2023gap} (USENIX'23) that protects node-level privacy via\ndifferentially private node/instance embeddings. Unfortunately, such work has\nfundamental privacy flaws, which are identified through a thorough case study.\nMore importantly, we prove an impossibility result of achieving both (strong)\nprivacy and (acceptable) utility through private instance embedding. The\nimplication is that such an approach has intrinsic utility barriers when\nenforcing differential privacy.",
            "author": [
                "Zihang Xiang",
                "Tianhao Wang",
                "Di Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06888v1",
                "http://arxiv.org/pdf/2311.06888v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06887v1",
            "title": "Anticipating User Needs: Insights from Design Fiction on Conversational\n  Agents for Computational Thinking",
            "updated": "2023-11-12T16:19:03Z",
            "published": "2023-11-12T16:19:03Z",
            "summary": "Computational thinking, and by extension, computer programming, is\nnotoriously challenging to learn. Conversational agents and generative\nartificial intelligence (genAI) have the potential to facilitate this learning\nprocess by offering personalized guidance, interactive learning experiences,\nand code generation. However, current genAI-based chatbots focus on\nprofessional developers and may not adequately consider educational needs.\nInvolving educators in conceiving educational tools is critical for ensuring\nusefulness and usability. We enlisted \\numParticipants{} instructors to engage\nin design fiction sessions in which we elicited abilities such a conversational\nagent supported by genAI should display. Participants envisioned a\nconversational agent that guides students stepwise through exercises, tuning\nits method of guidance with an awareness of the educational background, skills\nand deficits, and learning preferences. The insights obtained in this paper can\nguide future implementations of tutoring conversational agents oriented toward\nteaching computational thinking and computer programming.",
            "author": [
                "Jacob Penney",
                "Jo\u00e3o Felipe Pimentel",
                "Igor Steinmacher",
                "Marco A. Gerosa"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06887v1",
                "http://arxiv.org/pdf/2311.06887v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06879v1",
            "title": "pFedES: Model Heterogeneous Personalized Federated Learning with Feature\n  Extractor Sharing",
            "updated": "2023-11-12T15:43:39Z",
            "published": "2023-11-12T15:43:39Z",
            "summary": "As a privacy-preserving collaborative machine learning paradigm, federated\nlearning (FL) has attracted significant interest from academia and the industry\nalike. To allow each data owner (a.k.a., FL clients) to train a heterogeneous\nand personalized local model based on its local data distribution, system\nresources and requirements on model structure, the field of model-heterogeneous\npersonalized federated learning (MHPFL) has emerged. Existing MHPFL approaches\neither rely on the availability of a public dataset with special\ncharacteristics to facilitate knowledge transfer, incur high computation and\ncommunication costs, or face potential model leakage risks. To address these\nlimitations, we propose a model-heterogeneous personalized Federated learning\napproach based on feature Extractor Sharing (pFedES). It incorporates a small\nhomogeneous feature extractor into each client's heterogeneous local model.\nClients train them via the proposed iterative learning method to enable the\nexchange of global generalized knowledge and local personalized knowledge. The\nsmall local homogeneous extractors produced after local training are uploaded\nto the FL server and for aggregation to facilitate easy knowledge sharing among\nclients. We theoretically prove that pFedES can converge over wall-to-wall\ntime. Extensive experiments on two real-world datasets against six\nstate-of-the-art methods demonstrate that pFedES builds the most accurate\nmodel, while incurring low communication and computation costs. Compared with\nthe best-performing baseline, it achieves 1.61% higher test accuracy, while\nreducing communication and computation costs by 99.6% and 82.9%, respectively.",
            "author": [
                "Liping Yi",
                "Han Yu",
                "Gang Wang",
                "Xiaoguang Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06879v1",
                "http://arxiv.org/pdf/2311.06879v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07619v1",
            "title": "Modeling User Viewing Flow using Large Language Models for Article\n  Recommendation",
            "updated": "2023-11-12T15:32:57Z",
            "published": "2023-11-12T15:32:57Z",
            "summary": "This paper proposes the User Viewing Flow Modeling (SINGLE) method for the\narticle recommendation task, which models the user constant preference and\ninstant interest from user-clicked articles. Specifically, we employ a user\nconstant viewing flow modeling method to summarize the user's general interest\nto recommend articles. We utilize Large Language Models (LLMs) to capture\nconstant user preferences from previously clicked articles, such as skills and\npositions. Then we design the user instant viewing flow modeling method to\nbuild interactions between user-clicked article history and candidate articles.\nIt attentively reads the representations of user-clicked articles and aims to\nlearn the user's different interest views to match the candidate article. Our\nexperimental results on the Alibaba Technology Association (ATA) website show\nthe advantage of SINGLE, which achieves 2.4% improvements over previous\nbaseline models in the online A/B test. Our further analyses illustrate that\nSINGLE has the ability to build a more tailored recommendation system by\nmimicking different article viewing behaviors of users and recommending more\nappropriate and diverse articles to match user interests.",
            "author": [
                "Zhenghao Liu",
                "Zulong Chen",
                "Moufeng Zhang",
                "Shaoyang Duan",
                "Hong Wen",
                "Liangyue Li",
                "Nan Li",
                "Yu Gu",
                "Ge Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07619v1",
                "http://arxiv.org/pdf/2311.07619v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06876v1",
            "title": "Unified machine learning tasks and datasets for enhancing renewable\n  energy",
            "updated": "2023-11-12T15:30:44Z",
            "published": "2023-11-12T15:30:44Z",
            "summary": "Multi-tasking machine learning (ML) models exhibit prediction abilities in\ndomains with little to no training data available (few-shot and zero-shot\nlearning). Over-parameterized ML models are further capable of zero-loss\ntraining and near-optimal generalization performance. An open research question\nis, how these novel paradigms contribute to solving tasks related to enhancing\nthe renewable energy transition and mitigating climate change. A collection of\nunified ML tasks and datasets from this domain can largely facilitate the\ndevelopment and empirical testing of such models, but is currently missing.\nHere, we introduce the ETT-17 (Energy Transition Tasks-17), a collection of 17\ndatasets from six different application domains related to enhancing renewable\nenergy, including out-of-distribution validation and testing data. We unify all\ntasks and datasets, such that they can be solved using a single multi-tasking\nML model. We further analyse the dimensions of each dataset; investigate what\nthey require for designing over-parameterized models; introduce a set of\ndataset scores that describe important properties of each task and dataset; and\nprovide performance benchmarks.",
            "author": [
                "Arsam Aryandoust",
                "Thomas Rigoni",
                "Francesco di Stefano",
                "Anthony Patt"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06876v1",
                "http://arxiv.org/pdf/2311.06876v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06861v1",
            "title": "Energy-efficient Beamforming for RISs-aided Communications: Gradient\n  Based Meta Learning",
            "updated": "2023-11-12T14:34:08Z",
            "published": "2023-11-12T14:34:08Z",
            "summary": "Reconfigurable intelligent surfaces (RISs) have become a promising technology\nto meet the requirements of energy efficiency and scalability in future\nsix-generation (6G) communications. However, a significant challenge in\nRISs-aided communications is the joint optimization of active and passive\nbeamforming at base stations (BSs) and RISs respectively. Specifically, the\nmain difficulty is attributed to the highly non-convex optimization space of\nbeamforming matrices at both BSs and RISs, as well as the diversity and\nmobility of communication scenarios. To address this, we present a greenly\ngradient based meta learning beamforming (GMLB) approach. Unlike traditional\ndeep learning based methods which take channel information directly as input,\nGMLB feeds the gradient of sum rate into neural networks. Coherently, we design\na differential regulator to address the phase shift optimization of RISs.\nMoreover, we use the meta learning to iteratively optimize the beamforming\nmatrices of BSs and RISs. These techniques make the proposed method to work\nwell without requiring energy-consuming pre-training. Simulations show that\nGMLB could achieve higher sum rate than that of typical alternating\noptimization algorithms with the energy consumption by two orders of magnitude\nless.",
            "author": [
                "Xinquan Wang",
                "Fenghao Zhu",
                "Qianyun Zhou",
                "Qihao Yu",
                "Chongwen Huang",
                "Ahmed Alhammadi",
                "Zhaoyang Zhang",
                "Chau Yuen",
                "M\u00e9rouane Debbah"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06861v1",
                "http://arxiv.org/pdf/2311.06861v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06856v1",
            "title": "On learning spatial sequences with the movement of attention",
            "updated": "2023-11-12T14:14:07Z",
            "published": "2023-11-12T14:14:07Z",
            "summary": "In this paper we start with a simple question, how is it possible that humans\ncan recognize different movements over skin with only a prior visual experience\nof them? Or in general, what is the representation of spatial sequences that\nare invariant to scale, rotation, and translation across different modalities?\nTo answer, we rethink the mathematical representation of spatial sequences,\nargue against the minimum description length principle, and focus on the\nmovements of attention. We advance the idea that spatial sequences must be\nrepresented on different levels of abstraction, this adds redundancy but is\nnecessary for recognition and generalization. To address the open question of\nhow these abstractions are formed we propose two hypotheses: the first invites\nexploring selectionism learning, instead of finding parameters in some models;\nthe second proposes to find new data structures, not neural network\narchitectures, to efficiently store and operate over redundant features to be\nfurther selected. Movements of attention are central to human cognition and\nlessons should be applied to new better learning algorithms.",
            "author": [
                "Viacheslav M. Osaulenko"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06856v1",
                "http://arxiv.org/pdf/2311.06856v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06854v1",
            "title": "Multiuser Resource Allocation for Semantic-Relay-Aided Text\n  Transmissions",
            "updated": "2023-11-12T14:10:21Z",
            "published": "2023-11-12T14:10:21Z",
            "summary": "Semantic communication (SemCom) is an emerging technology that extracts\nuseful meaning from data and sends only relevant semantic information. Thus, it\nhas the great potential to improve the spectrum efficiency of conventional\nwireless systems with bit transmissions, especially in low signal-to-noise\nratio (SNR) and small bandwidth regions. However, the existing works have\nmostly overlooked the constraints of mobile devices, which may not have\nsufficient capabilities to implement resource-demanding semantic\nencoder/decoder based on deep learning. To address this issue, we propose in\nthis paper a new semantic relay (SemRelay), which is equipped with a semantic\nreceiver to assist multiuser text transmissions. Specifically, the SemRelay\ndecodes semantic information from a base station and forwards it to the users\nusing conventional bit transmission, hence effectively improving text\ntransmission efficiency. To study the multiuser resource allocation, we\nformulate an optimization problem to maximize the multiuser weighted sum-rate\nby jointly designing the SemRelay transmit power allocation and system\nbandwidth allocation. Although this problem is non-convex and hence challenging\nto solve, we propose an efficient algorithm to obtain its high-quality\nsuboptimal solution by using the block coordinate descent method. Last,\nnumerical results show the effectiveness of the proposed algorithm as well as\nsuperior performance of the proposed SemRelay over the conventional\ndecode-and-forward (DF) relay, especially in small bandwidth region.",
            "author": [
                "Zeyang Hu",
                "Tianyu Liu",
                "Changsheng You",
                "Zhaohui Yang",
                "Mingzhe Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06854v1",
                "http://arxiv.org/pdf/2311.06854v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06852v1",
            "title": "Contrastive Learning of View-Invariant Representations for Facial\n  Expressions Recognition",
            "updated": "2023-11-12T14:05:09Z",
            "published": "2023-11-12T14:05:09Z",
            "summary": "Although there has been much progress in the area of facial expression\nrecognition (FER), most existing methods suffer when presented with images that\nhave been captured from viewing angles that are non-frontal and substantially\ndifferent from those used in the training process. In this paper, we propose\nViewFX, a novel view-invariant FER framework based on contrastive learning,\ncapable of accurately classifying facial expressions regardless of the input\nviewing angles during inference. ViewFX learns view-invariant features of\nexpression using a proposed self-supervised contrastive loss which brings\ntogether different views of the same subject with a particular expression in\nthe embedding space. We also introduce a supervised contrastive loss to push\nthe learnt view-invariant features of each expression away from other\nexpressions. Since facial expressions are often distinguished with very subtle\ndifferences in the learned feature space, we incorporate the Barlow twins loss\nto reduce the redundancy and correlations of the representations in the learned\nrepresentations. The proposed method is a substantial extension of our\npreviously proposed CL-MEx, which only had a self-supervised loss. We test the\nproposed framework on two public multi-view facial expression recognition\ndatasets, KDEF and DDCF. The experiments demonstrate that our approach\noutperforms previous works in the area and sets a new state-of-the-art for both\ndatasets while showing considerably less sensitivity to challenging angles and\nthe number of output labels used for training. We also perform detailed\nsensitivity and ablation experiments to evaluate the impact of different\ncomponents of our model as well as its sensitivity to different parameters.",
            "author": [
                "Shuvendu Roy",
                "Ali Etemad"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06852v1",
                "http://arxiv.org/pdf/2311.06852v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06851v3",
            "title": "Automatic Textual Normalization for Hate Speech Detection",
            "updated": "2023-12-04T15:34:29Z",
            "published": "2023-11-12T14:01:38Z",
            "summary": "Social media data is a valuable resource for research, yet it contains a wide\nrange of non-standard words (NSW). These irregularities hinder the effective\noperation of NLP tools. Current state-of-the-art methods for the Vietnamese\nlanguage address this issue as a problem of lexical normalization, involving\nthe creation of manual rules or the implementation of multi-staged deep\nlearning frameworks, which necessitate extensive efforts to craft intricate\nrules. In contrast, our approach is straightforward, employing solely a\nsequence-to-sequence (Seq2Seq) model. In this research, we provide a dataset\nfor textual normalization, comprising 2,181 human-annotated comments with an\ninter-annotator agreement of 0.9014. By leveraging the Seq2Seq model for\ntextual normalization, our results reveal that the accuracy achieved falls\nslightly short of 70%. Nevertheless, textual normalization enhances the\naccuracy of the Hate Speech Detection (HSD) task by approximately 2%,\ndemonstrating its potential to improve the performance of complex NLP tasks.\nOur dataset is accessible for research purposes.",
            "author": [
                "Anh Thi-Hoang Nguyen",
                "Dung Ha Nguyen",
                "Nguyet Thi Nguyen",
                "Khanh Thanh-Duy Ho",
                "Kiet Van Nguyen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06851v3",
                "http://arxiv.org/pdf/2311.06851v3"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06845v1",
            "title": "Sampler Scheduler for Diffusion Models",
            "updated": "2023-11-12T13:35:25Z",
            "published": "2023-11-12T13:35:25Z",
            "summary": "Diffusion modeling (DM) has high-quality generative performance, and the\nsampling problem is an important part of the DM performance. Thanks to\nefficient differential equation solvers, the sampling speed can be reduced\nwhile higher sampling quality is guaranteed. However, currently, there is a\ncontradiction in samplers for diffusion-based generative models: the mainstream\nsampler choices are diverse, each with its own characteristics in terms of\nperformance. However, only a single sampler algorithm can be specified on all\nsampling steps in the generative process. This often makes one torn between\nsampler choices; in other words, it makes it difficult to fully utilize the\nadvantages of each sampler. In this paper, we propose the feasibility of using\ndifferent samplers (ODE/SDE) on different sampling steps of the same sampling\nprocess based on analyzing and generalizing the updating formulas of each\nmainstream sampler, and experimentally demonstrate that such a multi-sampler\nscheduling improves the sampling results to some extent. In particular, we also\nverify that the combination of using SDE in the early sampling steps and ODE in\nthe later sampling steps solves the inherent problems previously caused by\nusing both singly. We show that our design changes improve the sampling\nefficiency and quality in previous work. For instance, when Number of Function\nEvaluations (NFE) = 24, the ODE Sampler Scheduler achieves a FID score of 1.91\non the CIFAR-10 dataset, compared to 2.02 for DPM++ 2M, 1.97 for DPM2, and\n11.90 for Heun for the same NFE. Meanwhile the Sampler Scheduler with the\ncombined scheduling of SDE and ODE reaches 1.899, compared to 18.63 for Euler\na, 3.14 for DPM2 a and 23.14 for DPM++ SDE.",
            "author": [
                "Zitong Cheng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06845v1",
                "http://arxiv.org/pdf/2311.06845v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14705v1",
            "title": "Ethics and Responsible AI Deployment",
            "updated": "2023-11-12T13:32:46Z",
            "published": "2023-11-12T13:32:46Z",
            "summary": "As Artificial Intelligence (AI) becomes more prevalent, protecting personal\nprivacy is a critical ethical issue that must be addressed. This article\nexplores the need for ethical AI systems that safeguard individual privacy\nwhile complying with ethical standards. By taking a multidisciplinary approach,\nthe research examines innovative algorithmic techniques such as differential\nprivacy, homomorphic encryption, federated learning, international regulatory\nframeworks, and ethical guidelines. The study concludes that these algorithms\neffectively enhance privacy protection while balancing the utility of AI with\nthe need to protect personal data. The article emphasises the importance of a\ncomprehensive approach that combines technological innovation with ethical and\nregulatory strategies to harness the power of AI in a way that respects and\nprotects individual privacy.",
            "author": [
                "Petar Radanliev",
                "Omar Santos"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14705v1",
                "http://arxiv.org/pdf/2311.14705v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.HC",
                "cs.SI",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06840v1",
            "title": "Distribution Re-weighting and Voting Paradoxes",
            "updated": "2023-11-12T13:31:53Z",
            "published": "2023-11-12T13:31:53Z",
            "summary": "We explore a specific type of distribution shift called domain expertise, in\nwhich training is limited to a subset of all possible labels. This setting is\ncommon among specialized human experts, or specific focused studies. We show\nhow the standard approach to distribution shift, which involves re-weighting\ndata, can result in paradoxical disagreements among differing domain expertise.\nWe also demonstrate how standard adjustments for causal inference lead to the\nsame paradox. We prove that the characteristics of these paradoxes exactly\nmimic another set of paradoxes which arise among sets of voter preferences.",
            "author": [
                "Bijan Mazaheri",
                "Siddharth Jain",
                "Matthew Cook",
                "Jehoshua Bruck"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06840v1",
                "http://arxiv.org/pdf/2311.06840v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.IT",
                "cs.SI",
                "math.IT",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06839v1",
            "title": "Inference and Interference: The Role of Clipping, Pruning and Loss\n  Landscapes in Differentially Private Stochastic Gradient Descent",
            "updated": "2023-11-12T13:31:35Z",
            "published": "2023-11-12T13:31:35Z",
            "summary": "Differentially private stochastic gradient descent (DP-SGD) is known to have\npoorer training and test performance on large neural networks, compared to\nordinary stochastic gradient descent (SGD). In this paper, we perform a\ndetailed study and comparison of the two processes and unveil several new\ninsights. By comparing the behavior of the two processes separately in early\nand late epochs, we find that while DP-SGD makes slower progress in early\nstages, it is the behavior in the later stages that determines the end result.\nThis separate analysis of the clipping and noise addition steps of DP-SGD shows\nthat while noise introduces errors to the process, gradient descent can recover\nfrom these errors when it is not clipped, and clipping appears to have a larger\nimpact than noise. These effects are amplified in higher dimensions (large\nneural networks), where the loss basin occupies a lower dimensional space. We\nargue theoretically and using extensive experiments that magnitude pruning can\nbe a suitable dimension reduction technique in this regard, and find that heavy\npruning can improve the test accuracy of DPSGD.",
            "author": [
                "Lauren Watson",
                "Eric Gan",
                "Mohan Dantam",
                "Baharan Mirzasoleiman",
                "Rik Sarkar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06839v1",
                "http://arxiv.org/pdf/2311.06839v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06837v1",
            "title": "GraNNDis: Efficient Unified Distributed Training Framework for Deep GNNs\n  on Large Clusters",
            "updated": "2023-11-12T13:30:31Z",
            "published": "2023-11-12T13:30:31Z",
            "summary": "Graph neural networks (GNNs) are one of the most rapidly growing fields\nwithin deep learning. According to the growth in the dataset and the model size\nused for GNNs, an important problem is that it becomes nearly impossible to\nkeep the whole network on GPU memory. Among numerous attempts, distributed\ntraining is one popular approach to address the problem. However, due to the\nnature of GNNs, existing distributed approaches suffer from poor scalability,\nmainly due to the slow external server communications.\n  In this paper, we propose GraNNDis, an efficient distributed GNN training\nframework for training GNNs on large graphs and deep layers. GraNNDis\nintroduces three new techniques. First, shared preloading provides a training\nstructure for a cluster of multi-GPU servers. We suggest server-wise preloading\nof essential vertex dependencies to reduce the low-bandwidth external server\ncommunications. Second, we present expansion-aware sampling. Because shared\npreloading alone has limitations because of the neighbor explosion,\nexpansion-aware sampling reduces vertex dependencies that span across server\nboundaries. Third, we propose cooperative batching to create a unified\nframework for full-graph and minibatch training. It significantly reduces\nredundant memory usage in mini-batch training. From this, GraNNDis enables a\nreasonable trade-off between full-graph and mini-batch training through\nunification especially when the entire graph does not fit into the GPU memory.\nWith experiments conducted on a multi-server/multi-GPU cluster, we show that\nGraNNDis provides superior speedup over the state-of-the-art distributed GNN\ntraining frameworks.",
            "author": [
                "Jaeyong Song",
                "Hongsun Jang",
                "Jaewon Jung",
                "Youngsok Kim",
                "Jinho Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06837v1",
                "http://arxiv.org/pdf/2311.06837v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06835v1",
            "title": "Open-Set Graph Anomaly Detection via Normal Structure Regularisation",
            "updated": "2023-11-12T13:25:28Z",
            "published": "2023-11-12T13:25:28Z",
            "summary": "This paper considers an under-explored Graph Anomaly Detection (GAD) task,\nnamely open-set GAD, which aims to detect anomalous nodes using a small number\nof labelled training normal and anomaly nodes (known as seen anomalies) that\ncannot illustrate all possible inference-time abnormalities. The task has\nattracted growing attention due to the availability of anomaly prior knowledge\nfrom the label information that can help to substantially reduce detection\nerrors. However, current methods tend to over-emphasise fitting the seen\nanomalies, leading to a weak generalisation ability to detect unseen anomalies,\ni.e., those that are not illustrated by the labelled anomaly nodes. Further,\nthey were introduced to handle Euclidean data, failing to effectively capture\nimportant non-Euclidean features for GAD. In this work, we propose a novel\nopen-set GAD approach, namely normal structure regularisation (NSReg), to\nleverage the rich normal graph structure embedded in the labelled nodes to\ntackle the aforementioned two issues. In particular, NSReg trains an\nanomaly-discriminative supervised graph anomaly detector, with a plug-and-play\nregularisation term to enforce compact, semantically-rich representations of\nnormal nodes. To this end, the regularisation is designed to differentiate\nvarious types of normal nodes, including labelled normal nodes that are\nconnected in their local neighbourhood, and those that are not connected. By\ndoing so, it helps incorporate strong normality into the supervised anomaly\ndetector learning, mitigating their overfitting to the seen anomalies.\nExtensive empirical results on real-world datasets demonstrate the superiority\nof our proposed NSReg for open-set GAD.",
            "author": [
                "Qizhou Wang",
                "Guansong Pang",
                "Mahsa Salehi",
                "Wray Buntine",
                "Christopher Leckie"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06835v1",
                "http://arxiv.org/pdf/2311.06835v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06834v1",
            "title": "Osteoporosis Prediction from Hand and Wrist X-rays using Image\n  Segmentation and Self-Supervised Learning",
            "updated": "2023-11-12T13:19:00Z",
            "published": "2023-11-12T13:19:00Z",
            "summary": "Osteoporosis is a widespread and chronic metabolic bone disease that often\nremains undiagnosed and untreated due to limited access to bone mineral density\n(BMD) tests like Dual-energy X-ray absorptiometry (DXA). In response to this\nchallenge, current advancements are pivoting towards detecting osteoporosis by\nexamining alternative indicators from peripheral bone areas, with the goal of\nincreasing screening rates without added expenses or time. In this paper, we\npresent a method to predict osteoporosis using hand and wrist X-ray images,\nwhich are both widely accessible and affordable, though their link to DXA-based\ndata is not thoroughly explored. Initially, our method segments the ulnar,\nradius, and metacarpal bones using a foundational model for image segmentation.\nThen, we use a self-supervised learning approach to extract meaningful\nrepresentations without the need for explicit labels, and move on to classify\nosteoporosis in a supervised manner. Our method is evaluated on a dataset with\n192 individuals, cross-referencing their verified osteoporosis conditions\nagainst the standard DXA test. With a notable classification score (AUC=0.83),\nour model represents a pioneering effort in leveraging vision-based techniques\nfor osteoporosis identification from the peripheral skeleton sites.",
            "author": [
                "Hyungeun Lee",
                "Ung Hwang",
                "Seungwon Yu",
                "Chang-Hun Lee",
                "Kijung Yoon"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06834v1",
                "http://arxiv.org/pdf/2311.06834v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06828v1",
            "title": "Towards Continual Reinforcement Learning for Quadruped Robots",
            "updated": "2023-11-12T12:54:44Z",
            "published": "2023-11-12T12:54:44Z",
            "summary": "Quadruped robots have emerged as an evolving technology that currently\nleverages simulators to develop a robust controller capable of functioning in\nthe real-world without the need for further training. However, since it is\nimpossible to predict all possible real-world situations, our research explores\nthe possibility of enabling them to continue learning even after their\ndeployment. To this end, we designed two continual learning scenarios,\nsequentially training the robot on different environments while simultaneously\nevaluating its performance across all of them. Our approach sheds light on the\nextent of both forward and backward skill transfer, as well as the degree to\nwhich the robot might forget previously acquired skills. By addressing these\nfactors, we hope to enhance the adaptability and performance of quadruped\nrobots in real-world scenarios.",
            "author": [
                "Giovanni Minelli",
                "Vassilis Vassiliades"
            ],
            "link": [
                "http://dx.doi.org/10.2312/imet.20231258",
                "http://arxiv.org/abs/2311.06828v1",
                "http://arxiv.org/pdf/2311.06828v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06826v1",
            "title": "Fairness Hacking: The Malicious Practice of Shrouding Unfairness in\n  Algorithms",
            "updated": "2023-11-12T12:48:28Z",
            "published": "2023-11-12T12:48:28Z",
            "summary": "Fairness in machine learning (ML) is an ever-growing field of research due to\nthe manifold potential for harm from algorithmic discrimination. To prevent\nsuch harm, a large body of literature develops new approaches to quantify\nfairness. Here, we investigate how one can divert the quantification of\nfairness by describing a practice we call \"fairness hacking\" for the purpose of\nshrouding unfairness in algorithms. This impacts end-users who rely on learning\nalgorithms, as well as the broader community interested in fair AI practices.\nWe introduce two different categories of fairness hacking in reference to the\nestablished concept of p-hacking. The first category, intra-metric fairness\nhacking, describes the misuse of a particular metric by adding or removing\nsensitive attributes from the analysis. In this context, countermeasures that\nhave been developed to prevent or reduce p-hacking can be applied to similarly\nprevent or reduce fairness hacking. The second category of fairness hacking is\ninter-metric fairness hacking. Inter-metric fairness hacking is the search for\na specific fair metric with given attributes. We argue that countermeasures to\nprevent or reduce inter-metric fairness hacking are still in their infancy.\nFinally, we demonstrate both types of fairness hacking using real datasets. Our\npaper intends to serve as a guidance for discussions within the fair ML\ncommunity to prevent or reduce the misuse of fairness metrics, and thus reduce\noverall harm from ML applications.",
            "author": [
                "Kristof Meding",
                "Thilo Hagendorff"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06826v1",
                "http://arxiv.org/pdf/2311.06826v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06823v1",
            "title": "Training A Multi-stage Deep Classifier with Feedback Signals",
            "updated": "2023-11-12T12:24:07Z",
            "published": "2023-11-12T12:24:07Z",
            "summary": "Multi-Stage Classifier (MSC) - several classifiers working sequentially in an\narranged order and classification decision is partially made at each step - is\nwidely used in industrial applications for various resource limitation reasons.\nThe classifiers of a multi-stage process are usually Neural Network (NN) models\ntrained independently or in their inference order without considering the\nsignals from the latter stages. Aimed at two-stage binary classification\nprocess, the most common type of MSC, we propose a novel training framework,\nnamed Feedback Training. The classifiers are trained in an order reverse to\ntheir actual working order, and the classifier at the later stage is used to\nguide the training of initial-stage classifier via a sample weighting method.\nWe experimentally show the efficacy of our proposed approach, and its great\nsuperiority under the scenario of few-shot training.",
            "author": [
                "Chao Xu",
                "Yu Yang",
                "Rongzhao Wang",
                "Guan Wang",
                "Bojia Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06823v1",
                "http://arxiv.org/pdf/2311.06823v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06818v1",
            "title": "Cricket Player Profiling: Unraveling Strengths and Weaknesses Using Text\n  Commentary Data",
            "updated": "2023-11-12T11:51:05Z",
            "published": "2023-11-12T11:51:05Z",
            "summary": "Devising player-specific strategies in cricket necessitates a meticulous\nunderstanding of each player's unique strengths and weaknesses. Nevertheless,\nthe absence of a definitive computational approach to extract such insights\nfrom cricket players poses a significant challenge. This paper seeks to address\nthis gap by establishing computational models designed to extract the rules\ngoverning player strengths and weaknesses, thereby facilitating the development\nof tailored strategies for individual players. The complexity of this endeavor\nlies in several key areas: the selection of a suitable dataset, the precise\ndefinition of strength and weakness rules, the identification of an appropriate\nlearning algorithm, and the validation of the derived rules. To tackle these\nchallenges, we propose the utilization of unstructured data, specifically\ncricket text commentary, as a valuable resource for constructing comprehensive\nstrength and weakness rules for cricket players. We also introduce\ncomputationally feasible definitions for the construction of these rules, and\npresent a dimensionality reduction technique for the rule-building process. In\norder to showcase the practicality of this approach, we conduct an in-depth\nanalysis of cricket player strengths and weaknesses using a vast corpus of more\nthan one million text commentaries. Furthermore, we validate the constructed\nrules through two distinct methodologies: intrinsic and extrinsic. The outcomes\nof this research are made openly accessible, including the collected data,\nsource code, and results for over 250 cricket players, which can be accessed at\nhttps://bit.ly/2PKuzx8.",
            "author": [
                "Swarup Ranjan Behera",
                "Vijaya V. Saradhi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06818v1",
                "http://arxiv.org/pdf/2311.06818v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL",
                "I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06816v1",
            "title": "On original and latent space connectivity in deep neural networks",
            "updated": "2023-11-12T11:41:07Z",
            "published": "2023-11-12T11:41:07Z",
            "summary": "We study whether inputs from the same class can be connected by a continuous\npath, in original or latent representation space, such that all points on the\npath are mapped by the neural network model to the same class. Understanding\nhow the neural network views its own input space and how the latent spaces are\nstructured has value for explainability and robustness. We show that paths,\nlinear or nonlinear, connecting same-class inputs exist in all cases studied.",
            "author": [
                "Boyang Gu",
                "Anastasia Borovykh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06816v1",
                "http://arxiv.org/pdf/2311.06816v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06812v1",
            "title": "MANSY: Generalizing Neural Adaptive Immersive Video Streaming With\n  Ensemble and Representation Learning",
            "updated": "2023-11-12T11:20:25Z",
            "published": "2023-11-12T11:20:25Z",
            "summary": "The popularity of immersive videos has prompted extensive research into\nneural adaptive tile-based streaming to optimize video transmission over\nnetworks with limited bandwidth. However, the diversity of users' viewing\npatterns and Quality of Experience (QoE) preferences has not been fully\naddressed yet by existing neural adaptive approaches for viewport prediction\nand bitrate selection. Their performance can significantly deteriorate when\nusers' actual viewing patterns and QoE preferences differ considerably from\nthose observed during the training phase, resulting in poor generalization. In\nthis paper, we propose MANSY, a novel streaming system that embraces user\ndiversity to improve generalization. Specifically, to accommodate users'\ndiverse viewing patterns, we design a Transformer-based viewport prediction\nmodel with an efficient multi-viewport trajectory input output architecture\nbased on implicit ensemble learning. Besides, we for the first time combine the\nadvanced representation learning and deep reinforcement learning to train the\nbitrate selection model to maximize diverse QoE objectives, enabling the model\nto generalize across users with diverse preferences. Extensive experiments\ndemonstrate that MANSY outperforms state-of-the-art approaches in viewport\nprediction accuracy and QoE improvement on both trained and unseen viewing\npatterns and QoE preferences, achieving better generalization.",
            "author": [
                "Duo Wu",
                "Panlong Wu",
                "Miao Zhang",
                "Fangxin Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06812v1",
                "http://arxiv.org/pdf/2311.06812v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06807v1",
            "title": "On the Robustness of Question Rewriting Systems to Questions of Varying\n  Hardness",
            "updated": "2023-11-12T11:09:30Z",
            "published": "2023-11-12T11:09:30Z",
            "summary": "In conversational question answering (CQA), the task of question\nrewriting~(QR) in context aims to rewrite a context-dependent question into an\nequivalent self-contained question that gives the same answer. In this paper,\nwe are interested in the robustness of a QR system to questions varying in\nrewriting hardness or difficulty. Since there is a lack of questions classified\nbased on their rewriting hardness, we first propose a heuristic method to\nautomatically classify questions into subsets of varying hardness, by measuring\nthe discrepancy between a question and its rewrite. To find out what makes\nquestions hard or easy for rewriting, we then conduct a human evaluation to\nannotate the rewriting hardness of questions. Finally, to enhance the\nrobustness of QR systems to questions of varying hardness, we propose a novel\nlearning framework for QR that first trains a QR model independently on each\nsubset of questions of a certain level of hardness, then combines these QR\nmodels as one joint model for inference. Experimental results on two datasets\nshow that our framework improves the overall performance compared to the\nbaselines.",
            "author": [
                "Hai Ye",
                "Hwee Tou Ng",
                "Wenjuan Han"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06807v1",
                "http://arxiv.org/pdf/2311.06807v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06805v1",
            "title": "Tunable Soft Prompts are Messengers in Federated Learning",
            "updated": "2023-11-12T11:01:10Z",
            "published": "2023-11-12T11:01:10Z",
            "summary": "Federated learning (FL) enables multiple participants to collaboratively\ntrain machine learning models using decentralized data sources, alleviating\nprivacy concerns that arise from directly sharing local data. However, the lack\nof model privacy protection in FL becomes an unneglectable challenge,\nespecially when people want to federally finetune models based on a proprietary\nlarge language model. In this study, we propose a novel FL training approach\nthat accomplishes information exchange among participants via tunable soft\nprompts. These soft prompts, updated and transmitted between the server and\nclients, assume the role of the global model parameters and serve as messengers\nto deliver useful knowledge from the local data and global model. As the global\nmodel itself is not required to be shared and the local training is conducted\nbased on an auxiliary model with fewer parameters than the global model, the\nproposed approach provides protection for the global model while reducing\ncommunication and computation costs in FL. Extensive experiments show the\neffectiveness of the proposed approach compared to several baselines. We have\nreleased the source code at\n\\url{https://github.com/alibaba/FederatedScope/tree/fedsp/federatedscope/nlp/fedsp}.",
            "author": [
                "Chenhe Dong",
                "Yuexiang Xie",
                "Bolin Ding",
                "Ying Shen",
                "Yaliang Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06805v1",
                "http://arxiv.org/pdf/2311.06805v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06801v1",
            "title": "A Comprehensive Survey On Client Selections in Federated Learning",
            "updated": "2023-11-12T10:40:43Z",
            "published": "2023-11-12T10:40:43Z",
            "summary": "Federated Learning (FL) is a rapidly growing field in machine learning that\nallows data to be trained across multiple decentralized devices. The selection\nof clients to participate in the training process is a critical factor for the\nperformance of the overall system. In this survey, we provide a comprehensive\noverview of the state-of-the-art client selection techniques in FL, including\ntheir strengths and limitations, as well as the challenges and open issues that\nneed to be addressed. We cover conventional selection techniques such as random\nselection where all or partial random of clients is used for the trained. We\nalso cover performance-aware selections and as well as resource-aware\nselections for resource-constrained networks and heterogeneous networks. We\nalso discuss the usage of client selection in model security enhancement.\nLastly, we discuss open issues and challenges related to clients selection in\ndynamic constrained, and heterogeneous networks.",
            "author": [
                "Ala Gouissem",
                "Zina Chkirbene",
                "Ridha Hamila"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06801v1",
                "http://arxiv.org/pdf/2311.06801v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06798v1",
            "title": "MetaMix: Meta-state Precision Searcher for Mixed-precision Activation\n  Quantization",
            "updated": "2023-11-12T10:21:04Z",
            "published": "2023-11-12T10:21:04Z",
            "summary": "Mixed-precision quantization of efficient networks often suffer from\nactivation instability encountered in the exploration of bit selections. To\naddress this problem, we propose a novel method called MetaMix which consists\nof bit selection and weight training phases. The bit selection phase iterates\ntwo steps, (1) the mixed-precision-aware weight update, and (2) the bit-search\ntraining with the fixed mixed-precision-aware weights, both of which combined\nreduce activation instability in mixed-precision quantization and contribute to\nfast and high-quality bit selection. The weight training phase exploits the\nweights and step sizes trained in the bit selection phase and fine-tunes them\nthereby offering fast training. Our experiments with efficient and\nhard-to-quantize networks, i.e., MobileNet v2 and v3, and ResNet-18 on ImageNet\nshow that our proposed method pushes the boundary of mixed-precision\nquantization, in terms of accuracy vs. operations, by outperforming both mixed-\nand single-precision SOTA methods.",
            "author": [
                "Han-Byul Kim",
                "Joo Hyung Lee",
                "Sungjoo Yoo",
                "Hong-Seok Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06798v1",
                "http://arxiv.org/pdf/2311.06798v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06797v1",
            "title": "Dual-Branch Reconstruction Network for Industrial Anomaly Detection with\n  RGB-D Data",
            "updated": "2023-11-12T10:19:14Z",
            "published": "2023-11-12T10:19:14Z",
            "summary": "Unsupervised anomaly detection methods are at the forefront of industrial\nanomaly detection efforts and have made notable progress. Previous work\nprimarily used 2D information as input, but multi-modal industrial anomaly\ndetection based on 3D point clouds and RGB images is just beginning to emerge.\nThe regular approach involves utilizing large pre-trained models for feature\nrepresentation and storing them in memory banks. However, the above methods\nrequire a longer inference time and higher memory usage, which cannot meet the\nreal-time requirements of the industry. To overcome these issues, we propose a\nlightweight dual-branch reconstruction network(DBRN) based on RGB-D input,\nlearning the decision boundary between normal and abnormal examples. The\nrequirement for alignment between the two modalities is eliminated by using\ndepth maps instead of point cloud input. Furthermore, we introduce an\nimportance scoring module in the discriminative network to assist in fusing\nfeatures from these two modalities, thereby obtaining a comprehensive\ndiscriminative result. DBRN achieves 92.8% AUROC with high inference efficiency\non the MVTec 3D-AD dataset without large pre-trained models and memory banks.",
            "author": [
                "Chenyang Bi",
                "Yueyang Li",
                "Haichi Luo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06797v1",
                "http://arxiv.org/pdf/2311.06797v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06796v1",
            "title": "Deep Perspective Transformation Based Vehicle Localization on Bird's Eye\n  View",
            "updated": "2023-11-12T10:16:42Z",
            "published": "2023-11-12T10:16:42Z",
            "summary": "An accurate understanding of a self-driving vehicle's surrounding environment\nis crucial for its navigation system. To enhance the effectiveness of existing\nalgorithms and facilitate further research, it is essential to provide\ncomprehensive data to the routing system. Traditional approaches rely on\ninstalling multiple sensors to simulate the environment, leading to high costs\nand complexity. In this paper, we propose an alternative solution by generating\na top-down representation of the scene, enabling the extraction of distances\nand directions of other cars relative to the ego vehicle. We introduce a new\nsynthesized dataset that offers extensive information about the ego vehicle and\nits environment in each frame, providing valuable resources for similar\ndownstream tasks. Additionally, we present an architecture that transforms\nperspective view RGB images into bird's-eye-view maps with segmented\nsurrounding vehicles. This approach offers an efficient and cost-effective\nmethod for capturing crucial environmental information for self-driving cars.\nCode and dataset are available at\nhttps://github.com/IPM-HPC/Perspective-BEV-Transformer.",
            "author": [
                "Abtin Mahyar",
                "Hossein Motamednia",
                "Dara Rahmati"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06796v1",
                "http://arxiv.org/pdf/2311.06796v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06795v1",
            "title": "Learning from machine learning: optimization of the Bose-Einstein\n  condensate of the thulium atom at a 1064 trap",
            "updated": "2023-11-12T10:15:18Z",
            "published": "2023-11-12T10:15:18Z",
            "summary": "Bose-Einstein condensation is an intriguing phenomenon that has garnered\nsignificant attention in recent decades. The number of atoms within the\ncondensate determines the scale of experiments that can be performed, making it\ncrucial for quantum simulations. Consequently, a condensate of thulium atoms at\na 1064-nm dipole trap was successfully achieved, and optimization of the atom\ncount was performed. Surprisingly, the number of atoms exhibited saturation,\nclosely resembling the count achieved in a dipole trap at 532 nm. Drawing\ninsights from machine learning results, it was concluded that a 3-body\nrecombination process was likely limiting the number of atoms. This limitation\nwas successfully overcome by leveraging Fano-Feshbach resonances. Additionally,\noptimization of the cooling time was implemented.",
            "author": [
                "D. A. Kumpilov",
                "D. A. Pershin",
                "I. S. Cojocaru",
                "V. A. Khlebnikov",
                "I. A. Pyrkh",
                "A. E. Rudnev",
                "E. A. Fedotova",
                "K. A. Khoruzhii",
                "P. A. Aksentsev",
                "D. V. Gaifutdinov",
                "A. K. Zykova",
                "V. V. Tsyganok",
                "A. V. Akimov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06795v1",
                "http://arxiv.org/pdf/2311.06795v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06794v1",
            "title": "CL-Flow:Strengthening the Normalizing Flows by Contrastive Learning for\n  Better Anomaly Detection",
            "updated": "2023-11-12T10:07:03Z",
            "published": "2023-11-12T10:07:03Z",
            "summary": "In the anomaly detection field, the scarcity of anomalous samples has\ndirected the current research emphasis towards unsupervised anomaly detection.\nWhile these unsupervised anomaly detection methods offer convenience, they also\noverlook the crucial prior information embedded within anomalous samples.\nMoreover, among numerous deep learning methods, supervised methods generally\nexhibit superior performance compared to unsupervised methods. Considering the\nreasons mentioned above, we propose a self-supervised anomaly detection\napproach that combines contrastive learning with 2D-Flow to achieve more\nprecise detection outcomes and expedited inference processes. On one hand, we\nintroduce a novel approach to anomaly synthesis, yielding anomalous samples in\naccordance with authentic industrial scenarios, alongside their surrogate\nannotations. On the other hand, having obtained a substantial number of\nanomalous samples, we enhance the 2D-Flow framework by incorporating\ncontrastive learning, leveraging diverse proxy tasks to fine-tune the network.\nOur approach enables the network to learn more precise mapping relationships\nfrom self-generated labels while retaining the lightweight characteristics of\nthe 2D-Flow. Compared to mainstream unsupervised approaches, our\nself-supervised method demonstrates superior detection accuracy, fewer\nadditional model parameters, and faster inference speed. Furthermore, the\nentire training and inference process is end-to-end. Our approach showcases new\nstate-of-the-art results, achieving a performance of 99.6\\% in image-level\nAUROC on the MVTecAD dataset and 96.8\\% in image-level AUROC on the BTAD\ndataset.",
            "author": [
                "Shunfeng Wang",
                "Yueyang Li",
                "Haichi Luo",
                "Chenyang Bi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06794v1",
                "http://arxiv.org/pdf/2311.06794v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06790v1",
            "title": "The QLBS Model within the presence of feedback loops through the impacts\n  of a large trader",
            "updated": "2023-11-12T09:51:13Z",
            "published": "2023-11-12T09:51:13Z",
            "summary": "We extend the QLBS model by reformulating via considering a large trader\nwhose transactions leave a permanent impact on the evolution of the exchange\nrate process and therefore affect the price of contingent claims on such\nprocesses. Through a hypothetical limit order book we quantify the exchange\nrate altered by such transactions. We therefore define the quoted exchange rate\nprocess, for which we assume the existence of a postulated hedging strategy.\nGiven the quoted exchange rate and postulated hedging strategy, we find an\noptimal hedging strategy through batch-mode reinforcement learning given the\ntrader alters the course of the exchange rate process. We assume that the\ntrader has its own concept of fair price and we define our problem as finding\nthe hedging strategy with much lower transaction costs yet delivering a price\nthat well converges to the fair price of the trader. We show our contribution\nresults in an optimal hedging strategy with much lower transaction costs and\nconvergence to the fair price is obtained assuming sensible parameters.",
            "author": [
                "Ahmet Umur \u00d6zsoy",
                "\u00d6m\u00fcr U\u011fur"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06790v1",
                "http://arxiv.org/pdf/2311.06790v1"
            ],
            "primary_category": "q-fin.MF",
            "category": [
                "q-fin.MF"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06787v1",
            "title": "Data-Driven Moving Horizon Estimation Using Bayesian Optimization",
            "updated": "2023-11-12T09:25:53Z",
            "published": "2023-11-12T09:25:53Z",
            "summary": "In this work, an innovative data-driven moving horizon state estimation is\nproposed for model dynamic-unknown systems based on Bayesian optimization. As\nlong as the measurement data is received, a locally linear dynamics model can\nbe obtained from one Bayesian optimization-based offline learning framework.\nHerein, the learned model is continuously updated iteratively based on the\nactual observed data to approximate the actual system dynamic with the intent\nof minimizing the cost function of the moving horizon estimator until the\ndesired performance is achieved. Meanwhile, the characteristics of Bayesian\noptimization can guarantee the closest approximation of the learned model to\nthe actual system dynamic. Thus, one effective data-driven moving horizon\nestimator can be designed further on the basis of this learned model. Finally,\nthe efficiency of the proposed state estimation algorithm is demonstrated by\nseveral numerical simulations.",
            "author": [
                "Qing Sun",
                "Shuai Niu",
                "Minrui Fei"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06787v1",
                "http://arxiv.org/pdf/2311.06787v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06777v1",
            "title": "Alleviating Behavior Data Imbalance for Multi-Behavior Graph\n  Collaborative Filtering",
            "updated": "2023-11-12T08:46:07Z",
            "published": "2023-11-12T08:46:07Z",
            "summary": "Graph collaborative filtering, which learns user and item representations\nthrough message propagation over the user-item interaction graph, has been\nshown to effectively enhance recommendation performance. However, most current\ngraph collaborative filtering models mainly construct the interaction graph on\na single behavior domain (e.g. click), even though users exhibit various types\nof behaviors on real-world platforms, including actions like click, cart, and\npurchase. Furthermore, due to variations in user engagement, there exists an\nimbalance in the scale of different types of behaviors. For instance, users may\nclick and view multiple items but only make selective purchases from a small\nsubset of them. How to alleviate the behavior imbalance problem and utilize\ninformation from the multiple behavior graphs concurrently to improve the\ntarget behavior conversion (e.g. purchase) remains underexplored. To this end,\nwe propose IMGCF, a simple but effective model to alleviate behavior data\nimbalance for multi-behavior graph collaborative filtering. Specifically, IMGCF\nutilizes a multi-task learning framework for collaborative filtering on\nmulti-behavior graphs. Then, to mitigate the data imbalance issue, IMGCF\nimproves representation learning on the sparse behavior by leveraging\nrepresentations learned from the behavior domain with abundant data volumes.\nExperiments on two widely-used multi-behavior datasets demonstrate the\neffectiveness of IMGCF.",
            "author": [
                "Yijie Zhang",
                "Yuanchen Bei",
                "Shiqi Yang",
                "Hao Chen",
                "Zhiqing Li",
                "Lijia Chen",
                "Feiran Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06777v1",
                "http://arxiv.org/pdf/2311.06777v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06772v1",
            "title": "ChatAnything: Facetime Chat with LLM-Enhanced Personas",
            "updated": "2023-11-12T08:29:41Z",
            "published": "2023-11-12T08:29:41Z",
            "summary": "In this technical report, we target generating anthropomorphized personas for\nLLM-based characters in an online manner, including visual appearance,\npersonality and tones, with only text descriptions. To achieve this, we first\nleverage the in-context learning capability of LLMs for personality generation\nby carefully designing a set of system prompts. We then propose two novel\nconcepts: the mixture of voices (MoV) and the mixture of diffusers (MoD) for\ndiverse voice and appearance generation. For MoV, we utilize the text-to-speech\n(TTS) algorithms with a variety of pre-defined tones and select the most\nmatching one based on the user-provided text description automatically. For\nMoD, we combine the recent popular text-to-image generation techniques and\ntalking head algorithms to streamline the process of generating talking\nobjects. We termed the whole framework as ChatAnything. With it, users could be\nable to animate anything with any personas that are anthropomorphic using just\na few text inputs. However, we have observed that the anthropomorphic objects\nproduced by current generative models are often undetectable by pre-trained\nface landmark detectors, leading to failure of the face motion generation, even\nif these faces possess human-like appearances because those images are nearly\nseen during the training (e.g., OOD samples). To address this issue, we\nincorporate pixel-level guidance to infuse human face landmarks during the\nimage generation phase. To benchmark these metrics, we have built an evaluation\ndataset. Based on it, we verify that the detection rate of the face landmark is\nsignificantly increased from 57.0% to 92.5% thus allowing automatic face\nanimation based on generated speech content. The code and more results can be\nfound at https://chatanything.github.io/.",
            "author": [
                "Yilin Zhao",
                "Xinbin Yuan",
                "Shanghua Gao",
                "Zhijie Lin",
                "Qibin Hou",
                "Jiashi Feng",
                "Daquan Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06772v1",
                "http://arxiv.org/pdf/2311.06772v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06771v1",
            "title": "Learning Globally Optimized Language Structure via Adversarial Training",
            "updated": "2023-11-12T08:21:43Z",
            "published": "2023-11-12T08:21:43Z",
            "summary": "Recent work has explored integrating autoregressive language models with\nenergy-based models (EBMs) to enhance text generation capabilities. However,\nlearning effective EBMs for text is challenged by the discrete nature of\nlanguage. This work proposes an adversarial training strategy to address\nlimitations in prior efforts. Specifically, an iterative adversarial attack\nalgorithm is presented to generate negative samples for training the EBM by\nperturbing text from the autoregressive model. This aims to enable the EBM to\nsuppress spurious modes outside the support of the data distribution.\nExperiments on an arithmetic sequence generation task demonstrate that the\nproposed adversarial training approach can substantially enhance the quality of\ngenerated sequences compared to prior methods. The results highlight the\npromise of adversarial techniques to improve discrete EBM training. Key\ncontributions include: (1) an adversarial attack strategy tailored to text to\ngenerate negative samples, circumventing MCMC limitations; (2) an adversarial\ntraining algorithm for EBMs leveraging these attacks; (3) empirical validation\nof performance improvements on a sequence generation task.",
            "author": [
                "Xuwang Yin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06771v1",
                "http://arxiv.org/pdf/2311.06771v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06769v1",
            "title": "Learning Predictive Safety Filter via Decomposition of Robust Invariant\n  Set",
            "updated": "2023-11-12T08:11:28Z",
            "published": "2023-11-12T08:11:28Z",
            "summary": "Ensuring safety of nonlinear systems under model uncertainty and external\ndisturbances is crucial, especially for real-world control tasks. Predictive\nmethods such as robust model predictive control (RMPC) require solving\nnonconvex optimization problems online, which leads to high computational\nburden and poor scalability. Reinforcement learning (RL) works well with\ncomplex systems, but pays the price of losing rigorous safety guarantee. This\npaper presents a theoretical framework that bridges the advantages of both RMPC\nand RL to synthesize safety filters for nonlinear systems with state- and\naction-dependent uncertainty. We decompose the robust invariant set (RIS) into\ntwo parts: a target set that aligns with terminal region design of RMPC, and a\nreach-avoid set that accounts for the rest of RIS. We propose a policy\niteration approach for robust reach-avoid problems and establish its monotone\nconvergence. This method sets the stage for an adversarial actor-critic deep RL\nalgorithm, which simultaneously synthesizes a reach-avoid policy network, a\ndisturbance policy network, and a reach-avoid value network. The learned\nreach-avoid policy network is utilized to generate nominal trajectories for\nonline verification, which filters potentially unsafe actions that may drive\nthe system into unsafe regions when worst-case disturbances are applied. We\nformulate a second-order cone programming (SOCP) approach for online\nverification using system level synthesis, which optimizes for the worst-case\nreach-avoid value of any possible trajectories. The proposed safety filter\nrequires much lower computational complexity than RMPC and still enjoys\npersistent robust safety guarantee. The effectiveness of our method is\nillustrated through a numerical example.",
            "author": [
                "Zeyang Li",
                "Chuxiong Hu",
                "Weiye Zhao",
                "Changliu Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06769v1",
                "http://arxiv.org/pdf/2311.06769v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.LG",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07618v1",
            "title": "Large Language Models' Understanding of Math: Source Criticism and\n  Extrapolation",
            "updated": "2023-11-12T07:52:32Z",
            "published": "2023-11-12T07:52:32Z",
            "summary": "It has been suggested that large language models such as GPT-4 have acquired\nsome form of understanding beyond the correlations among the words in text\nincluding some understanding of mathematics as well. Here, we perform a\ncritical inquiry into this claim by evaluating the mathematical understanding\nof the GPT-4 model. Considering that GPT-4's training set is a secret, it is\nnot straightforward to evaluate whether the model's correct answers are based\non a mathematical understanding or based on replication of proofs that the\nmodel has seen before. We specifically craft mathematical questions which their\nformal proofs are not readily available on the web, proofs that are more likely\nnot seen by the GPT-4. We see that GPT-4 is unable to solve those problems\ndespite their simplicity. It is hard to find scientific evidence suggesting\nthat GPT-4 has acquired an understanding of even basic mathematical concepts. A\nstraightforward way to find failure modes of GPT-4 in theorem proving is to\ncraft questions where their formal proofs are not available on the web. Our\nfinding suggests that GPT-4's ability is to reproduce, rephrase, and polish the\nmathematical proofs that it has seen before, and not in grasping mathematical\nconcepts. We also see that GPT-4's ability to prove mathematical theorems is\ncontinuously expanding over time despite the claim that it is a fixed model. We\nsuggest that the task of proving mathematical theorems in formal language is\ncomparable to the methods used in search engines such as Google while\npredicting the next word in a sentence may be a misguided approach, a recipe\nthat often leads to excessive extrapolation and eventual failures. Prompting\nthe GPT-4 over and over may benefit the GPT-4 and the OpenAI, but we question\nwhether it is valuable for machine learning or for theorem proving.",
            "author": [
                "Roozbeh Yousefzadeh",
                "Xuenan Cao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07618v1",
                "http://arxiv.org/pdf/2311.07618v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL",
                "math.HO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06761v1",
            "title": "Learning Knowledge-Enhanced Contextual Language Representations for\n  Domain Natural Language Understanding",
            "updated": "2023-11-12T07:37:24Z",
            "published": "2023-11-12T07:37:24Z",
            "summary": "Knowledge-Enhanced Pre-trained Language Models (KEPLMs) improve the\nperformance of various downstream NLP tasks by injecting knowledge facts from\nlarge-scale Knowledge Graphs (KGs). However, existing methods for pre-training\nKEPLMs with relational triples are difficult to be adapted to close domains due\nto the lack of sufficient domain graph semantics. In this paper, we propose a\nKnowledge-enhanced lANGuAge Representation learning framework for various\nclOsed dOmains (KANGAROO) via capturing the implicit graph structure among the\nentities. Specifically, since the entity coverage rates of closed-domain KGs\ncan be relatively low and may exhibit the global sparsity phenomenon for\nknowledge injection, we consider not only the shallow relational\nrepresentations of triples but also the hyperbolic embeddings of deep\nhierarchical entity-class structures for effective knowledge fusion.Moreover,\nas two closed-domain entities under the same entity-class often have locally\ndense neighbor subgraphs counted by max point biconnected component, we further\npropose a data augmentation strategy based on contrastive learning over\nsubgraphs to construct hard negative samples of higher quality. It makes the\nunderlying KELPMs better distinguish the semantics of these neighboring\nentities to further complement the global semantic sparsity. In the\nexperiments, we evaluate KANGAROO over various knowledge-aware and general NLP\ntasks in both full and few-shot learning settings, outperforming various KEPLM\ntraining paradigms performance in closed-domains significantly.",
            "author": [
                "Ruyao Xu",
                "Taolin Zhang",
                "Chengyu Wang",
                "Zhongjie Duan",
                "Cen Chen",
                "Minghui Qiu",
                "Dawei Cheng",
                "Xiaofeng He",
                "Weining Qian"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06761v1",
                "http://arxiv.org/pdf/2311.06761v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07616v1",
            "title": "ReIDTracker Sea: the technical report of BoaTrack and SeaDronesSee-MOT\n  challenge at MaCVi of WACV24",
            "updated": "2023-11-12T07:37:07Z",
            "published": "2023-11-12T07:37:07Z",
            "summary": "Multi-Object Tracking is one of the most important technologies in maritime\ncomputer vision. Our solution tries to explore Multi-Object Tracking in\nmaritime Unmanned Aerial vehicles (UAVs) and Unmanned Surface Vehicles (USVs)\nusage scenarios. Most of the current Multi-Object Tracking algorithms require\ncomplex association strategies and association information (2D location and\nmotion, 3D motion, 3D depth, 2D appearance) to achieve better performance,\nwhich makes the entire tracking system extremely complex and heavy. At the same\ntime, most of the current Multi-Object Tracking algorithms still require video\nannotation data which is costly to obtain for training. Our solution tries to\nexplore Multi-Object Tracking in a completely unsupervised way. The scheme\naccomplishes instance representation learning by using self-supervision on\nImageNet. Then, by cooperating with high-quality detectors, the multi-target\ntracking task can be completed simply and efficiently. The scheme achieved top\n3 performance on both UAV-based Multi-Object Tracking with Reidentification and\nUSV-based Multi-Object Tracking benchmarks and the solution won the\nchampionship in many multiple Multi-Object Tracking competitions. such as\nBDD100K MOT,MOTS, Waymo 2D MOT",
            "author": [
                "Kaer Huang",
                "Weitu Chong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07616v1",
                "http://arxiv.org/pdf/2311.07616v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06758v1",
            "title": "Sharing, Teaching and Aligning: Knowledgeable Transfer Learning for\n  Cross-Lingual Machine Reading Comprehension",
            "updated": "2023-11-12T07:20:37Z",
            "published": "2023-11-12T07:20:37Z",
            "summary": "In cross-lingual language understanding, machine translation is often\nutilized to enhance the transferability of models across languages, either by\ntranslating the training data from the source language to the target, or from\nthe target to the source to aid inference. However, in cross-lingual machine\nreading comprehension (MRC), it is difficult to perform a deep level of\nassistance to enhance cross-lingual transfer because of the variation of answer\nspan positions in different languages. In this paper, we propose X-STA, a new\napproach for cross-lingual MRC. Specifically, we leverage an attentive teacher\nto subtly transfer the answer spans of the source language to the answer output\nspace of the target. A Gradient-Disentangled Knowledge Sharing technique is\nproposed as an improved cross-attention block. In addition, we force the model\nto learn semantic alignments from multiple granularities and calibrate the\nmodel outputs with teacher guidance to enhance cross-lingual transferability.\nExperiments on three multi-lingual MRC datasets show the effectiveness of our\nmethod, outperforming state-of-the-art approaches.",
            "author": [
                "Tingfeng Cao",
                "Chengyu Wang",
                "Chuanqi Tan",
                "Jun Huang",
                "Jinhui Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06758v1",
                "http://arxiv.org/pdf/2311.06758v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06756v1",
            "title": "Personalized Federated Learning via ADMM with Moreau Envelope",
            "updated": "2023-11-12T07:13:37Z",
            "published": "2023-11-12T07:13:37Z",
            "summary": "Personalized federated learning (PFL) is an approach proposed to address the\nissue of poor convergence on heterogeneous data. However, most existing PFL\nframeworks require strong assumptions for convergence. In this paper, we\npropose an alternating direction method of multipliers (ADMM) for training PFL\nmodels with Moreau envelope (FLAME), which achieves a sublinear convergence\nrate, relying on the relatively weak assumption of gradient Lipschitz\ncontinuity. Moreover, due to the gradient-free nature of ADMM, FLAME alleviates\nthe need for hyperparameter tuning, particularly in avoiding the adjustment of\nthe learning rate when training the global model. In addition, we propose a\nbiased client selection strategy to expedite the convergence of training of PFL\nmodels. Our theoretical analysis establishes the global convergence under both\nunbiased and biased client selection strategies. Our experiments validate that\nFLAME, when trained on heterogeneous data, outperforms state-of-the-art methods\nin terms of model performance. Regarding communication efficiency, it exhibits\nan average speedup of 3.75x compared to the baselines. Furthermore,\nexperimental results validate that the biased client selection strategy speeds\nup the convergence of both personalized and global models.",
            "author": [
                "Shengkun Zhu",
                "Jinshan Zeng",
                "Sheng Wang",
                "Yuan Sun",
                "Zhiyong Peng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06756v1",
                "http://arxiv.org/pdf/2311.06756v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07614v1",
            "title": "Application of a Dense Fusion Attention Network in Fault Diagnosis of\n  Centrifugal Fan",
            "updated": "2023-11-12T07:09:11Z",
            "published": "2023-11-12T07:09:11Z",
            "summary": "Although the deep learning recognition model has been widely used in the\ncondition monitoring of rotating machinery. However, it is still a challenge to\nunderstand the correspondence between the structure and function of the model\nand the diagnosis process. Therefore, this paper discusses embedding\ndistributed attention modules into dense connections instead of traditional\ndense cascading operations. It not only decouples the influence of space and\nchannel on fault feature adaptive recalibration feature weights, but also forms\na fusion attention function. The proposed dense fusion focuses on the\nvisualization of the network diagnosis process, which increases the\ninterpretability of model diagnosis. How to continuously and effectively\nintegrate different functions to enhance the ability to extract fault features\nand the ability to resist noise is answered. Centrifugal fan fault data is used\nto verify this network. Experimental results show that the network has stronger\ndiagnostic performance than other advanced fault diagnostic models.",
            "author": [
                "Ruijun Wang",
                "Yuan Liu",
                "Zhixia Fan",
                "Xiaogang Xu",
                "Huijie Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07614v1",
                "http://arxiv.org/pdf/2311.07614v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06754v1",
            "title": "From Complex to Simple: Unraveling the Cognitive Tree for Reasoning with\n  Small Language Models",
            "updated": "2023-11-12T06:56:21Z",
            "published": "2023-11-12T06:56:21Z",
            "summary": "Reasoning is a distinctive human capacity, enabling us to address complex\nproblems by breaking them down into a series of manageable cognitive steps.\nYet, complex logical reasoning is still cumbersome for language models. Based\non the dual process theory in cognitive science, we are the first to unravel\nthe cognitive reasoning abilities of language models. Our framework employs an\niterative methodology to construct a Cognitive Tree (CogTree). The root node of\nthis tree represents the initial query, while the leaf nodes consist of\nstraightforward questions that can be answered directly. This construction\ninvolves two main components: the implicit extraction module (referred to as\nthe intuitive system) and the explicit reasoning module (referred to as the\nreflective system). The intuitive system rapidly generates multiple responses\nby utilizing in-context examples, while the reflective system scores these\nresponses using comparative learning. The scores guide the intuitive system in\nits subsequent generation step. Our experimental results on two popular and\nchallenging reasoning tasks indicate that it is possible to achieve a\nperformance level comparable to that of GPT-3.5 (with 175B parameters), using a\nsignificantly smaller language model that contains fewer parameters (<=7B) than\n5% of GPT-3.5.",
            "author": [
                "Junbing Yan",
                "Chengyu Wang",
                "Taolin Zhang",
                "Xiaofeng He",
                "Jun Huang",
                "Wei Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06754v1",
                "http://arxiv.org/pdf/2311.06754v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06752v1",
            "title": "BeautifulPrompt: Towards Automatic Prompt Engineering for Text-to-Image\n  Synthesis",
            "updated": "2023-11-12T06:39:00Z",
            "published": "2023-11-12T06:39:00Z",
            "summary": "Recently, diffusion-based deep generative models (e.g., Stable Diffusion)\nhave shown impressive results in text-to-image synthesis. However, current\ntext-to-image models often require multiple passes of prompt engineering by\nhumans in order to produce satisfactory results for real-world applications. We\npropose BeautifulPrompt, a deep generative model to produce high-quality\nprompts from very simple raw descriptions, which enables diffusion-based models\nto generate more beautiful images. In our work, we first fine-tuned the\nBeautifulPrompt model over low-quality and high-quality collecting prompt\npairs. Then, to ensure that our generated prompts can generate more beautiful\nimages, we further propose a Reinforcement Learning with Visual AI Feedback\ntechnique to fine-tune our model to maximize the reward values of the generated\nprompts, where the reward values are calculated based on the PickScore and the\nAesthetic Scores. Our results demonstrate that learning from visual AI feedback\npromises the potential to improve the quality of generated prompts and images\nsignificantly. We further showcase the integration of BeautifulPrompt to a\ncloud-native AI platform to provide better text-to-image generation service in\nthe cloud.",
            "author": [
                "Tingfeng Cao",
                "Chengyu Wang",
                "Bingyan Liu",
                "Ziheng Wu",
                "Jinhui Zhu",
                "Jun Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06752v1",
                "http://arxiv.org/pdf/2311.06752v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06750v1",
            "title": "Federated Learning for Generalization, Robustness, Fairness: A Survey\n  and Benchmark",
            "updated": "2023-11-12T06:32:30Z",
            "published": "2023-11-12T06:32:30Z",
            "summary": "Federated learning has emerged as a promising paradigm for privacy-preserving\ncollaboration among different parties. Recently, with the popularity of\nfederated learning, an influx of approaches have delivered towards different\nrealistic challenges. In this survey, we provide a systematic overview of the\nimportant and recent developments of research on federated learning. Firstly,\nwe introduce the study history and terminology definition of this area. Then,\nwe comprehensively review three basic lines of research: generalization,\nrobustness, and fairness, by introducing their respective background concepts,\ntask settings, and main challenges. We also offer a detailed overview of\nrepresentative literature on both methods and datasets. We further benchmark\nthe reviewed methods on several well-known datasets. Finally, we point out\nseveral open issues in this field and suggest opportunities for further\nresearch. We also provide a public website to continuously track developments\nin this fast advancing field: https://github.com/WenkeHuang/MarsFL.",
            "author": [
                "Wenke Huang",
                "Mang Ye",
                "Zekun Shi",
                "Guancheng Wan",
                "He Li",
                "Bo Du",
                "Qiang Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06750v1",
                "http://arxiv.org/pdf/2311.06750v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06749v1",
            "title": "Aggregate, Decompose, and Fine-Tune: A Simple Yet Effective\n  Factor-Tuning Method for Vision Transformer",
            "updated": "2023-11-12T06:23:33Z",
            "published": "2023-11-12T06:23:33Z",
            "summary": "Recent advancements have illuminated the efficacy of some\ntensorization-decomposition Parameter-Efficient Fine-Tuning methods like LoRA\nand FacT in the context of Vision Transformers (ViT). However, these methods\ngrapple with the challenges of inadequately addressing inner- and cross-layer\nredundancy. To tackle this issue, we introduce EFfective Factor-Tuning (EFFT),\na simple yet effective fine-tuning method. Within the VTAB-1K dataset, our EFFT\nsurpasses all baselines, attaining state-of-the-art performance with a\ncategorical average of 75.9% in top-1 accuracy with only 0.28% of the\nparameters for full fine-tuning. Considering the simplicity and efficacy of\nEFFT, it holds the potential to serve as a foundational benchmark. The code and\nmodel are now available at\nhttps://github.com/Dongping-Chen/EFFT-EFfective-Factor-Tuning.",
            "author": [
                "Dongping Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06749v1",
                "http://arxiv.org/pdf/2311.06749v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06748v1",
            "title": "How do Minimum-Norm Shallow Denoisers Look in Function Space?",
            "updated": "2023-11-12T06:20:21Z",
            "published": "2023-11-12T06:20:21Z",
            "summary": "Neural network (NN) denoisers are an essential building block in many common\ntasks, ranging from image reconstruction to image generation. However, the\nsuccess of these models is not well understood from a theoretical perspective.\nIn this paper, we aim to characterize the functions realized by shallow ReLU NN\ndenoisers -- in the common theoretical setting of interpolation (i.e., zero\ntraining loss) with a minimal representation cost (i.e., minimal $\\ell^2$ norm\nweights). First, for univariate data, we derive a closed form for the NN\ndenoiser function, find it is contractive toward the clean data points, and\nprove it generalizes better than the empirical MMSE estimator at a low noise\nlevel. Next, for multivariate data, we find the NN denoiser functions in a\nclosed form under various geometric assumptions on the training data: data\ncontained in a low-dimensional subspace, data contained in a union of one-sided\nrays, or several types of simplexes. These functions decompose into a sum of\nsimple rank-one piecewise linear interpolations aligned with edges and/or faces\nconnecting training samples. We empirically verify this alignment phenomenon on\nsynthetic data and real images.",
            "author": [
                "Chen Zeno",
                "Greg Ongie",
                "Yaniv Blumenfeld",
                "Nir Weinberger",
                "Daniel Soudry"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06748v1",
                "http://arxiv.org/pdf/2311.06748v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06742v1",
            "title": "Meta-Reinforcement Learning for Timely and Energy-efficient Data\n  Collection in Solar-powered UAV-assisted IoT Networks",
            "updated": "2023-11-12T05:48:37Z",
            "published": "2023-11-12T05:48:37Z",
            "summary": "Unmanned aerial vehicles (UAVs) have the potential to greatly aid Internet of\nThings (IoT) networks in mission-critical data collection, thanks to their\nflexibility and cost-effectiveness. However, challenges arise due to the UAV's\nlimited onboard energy and the unpredictable status updates from sensor nodes\n(SNs), which impact the freshness of collected data. In this paper, we\ninvestigate the energy-efficient and timely data collection in IoT networks\nthrough the use of a solar-powered UAV. Each SN generates status updates at\nstochastic intervals, while the UAV collects and subsequently transmits these\nstatus updates to a central data center. Furthermore, the UAV harnesses solar\nenergy from the environment to maintain its energy level above a predetermined\nthreshold. To minimize both the average age of information (AoI) for SNs and\nthe energy consumption of the UAV, we jointly optimize the UAV trajectory, SN\nscheduling, and offloading strategy. Then, we formulate this problem as a\nMarkov decision process (MDP) and propose a meta-reinforcement learning\nalgorithm to enhance the generalization capability. Specifically, the\ncompound-action deep reinforcement learning (CADRL) algorithm is proposed to\nhandle the discrete decisions related to SN scheduling and the UAV's offloading\npolicy, as well as the continuous control of UAV flight. Moreover, we\nincorporate meta-learning into CADRL to improve the adaptability of the learned\npolicy to new tasks. To validate the effectiveness of our proposed algorithms,\nwe conduct extensive simulations and demonstrate their superiority over other\nbaseline algorithms.",
            "author": [
                "Mengjie Yi",
                "Xijun Wang",
                "Juan Liu",
                "Yan Zhang",
                "Ronghui Hou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06742v1",
                "http://arxiv.org/pdf/2311.06742v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06735v1",
            "title": "DeepQC: A Deep Learning System for Automatic Quality Control of In-situ\n  Soil Moisture Sensor Time Series Data",
            "updated": "2023-11-12T04:58:20Z",
            "published": "2023-11-12T04:58:20Z",
            "summary": "Amidst changing climate, real-time soil moisture monitoring is vital for the\ndevelopment of in-season decision support tools to help farmers manage weather\nrelated risks. Precision Sustainable Agriculture (PSA) recently established a\nreal-time soil moisture monitoring network across the central, Midwest, and\neastern U.S., but field-scale sensor observations often come with data gaps and\nanomalies. To maintain the data quality needed for development of decision\ntools, a quality control system is necessary. The International Soil Moisture\nNetwork (ISMN) introduced the Flagit module for anomaly detection in soil\nmoisture observations. However, under certain conditions, Flagit's quality\ncontrol approaches may underperform in identifying anomalies. Recently deep\nlearning methods have been successfully applied to detect anomalies in time\nseries data in various disciplines. However, their use in agriculture has not\nbeen yet investigated. This study focuses on developing a Bi-directional Long\nShort-Term Memory (LSTM) model, referred to as DeepQC, to identify anomalies in\nsoil moisture data. Manual flagged PSA observations were used for training,\nvalidation, and testing the model, following an 80:10:10 split. The study then\ncompared the DeepQC and Flagit based estimates to assess their relative\nperformance. Flagit corrected flagged 95.5% of the corrected observations and\n50.3% of the anomaly observations, indicating its limitations in identifying\nanomalies. On the other hand, the DeepQC correctly flagged 99.7% of the correct\nobservations and 95.6% of the anomalies in significantly less time,\ndemonstrating its superiority over Flagit approach. Importantly, DeepQC's\nperformance remained consistent regardless of the number of anomalies. Given\nthe promising results obtained with the DeepQC, future studies will focus on\nimplementing this model on national and global soil moisture networks.",
            "author": [
                "Lahari Bandaru",
                "Bharat C Irigireddy",
                "Brian Davis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06735v1",
                "http://arxiv.org/pdf/2311.06735v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06734v1",
            "title": "Mechanical Metamaterials Fabricated from Self-assembly: A Perspective",
            "updated": "2023-11-12T04:53:03Z",
            "published": "2023-11-12T04:53:03Z",
            "summary": "Mechanical metamaterials, whose unique mechanical properties stem from their\nstructural design rather than material constituents, are gaining popularity in\nengineering applications. In particular, recent advances in self-assembly\ntechniques offer the potential to fabricate load-bearing mechanical\nmetamaterials with unparalleled feature size control and scalability compared\nto those produced by additive manufacturing (AM). Yet, the field is still in\nits early stages. In this perspective, we first provide an overview of the\nstate-of-the-art self-assembly techniques, with a focus on the copolymer and\ncolloid crystal self-assembly processes. We then discuss current challenges and\nfuture opportunities in this research area, focusing on novel fabrication\napproaches, the need for high-throughput characterization methods, and the\nintegration of Machine Learning (ML) and lab automation for inverse design.\nGiven recent progress in all these areas, we foresee mechanical metamaterials\nfabricated from self-assembly techniques impacting a variety of applications\nrelying on lightweight, strong, and tough materials.",
            "author": [
                "Hanxun Jin",
                "Horacio D. Espinosa"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06734v1",
                "http://arxiv.org/pdf/2311.06734v1"
            ],
            "primary_category": "physics.app-ph",
            "category": [
                "physics.app-ph",
                "cond-mat.soft"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06731v1",
            "title": "An advantage based policy transfer algorithm for reinforcement learning\n  with metrics of transferability",
            "updated": "2023-11-12T04:25:53Z",
            "published": "2023-11-12T04:25:53Z",
            "summary": "Reinforcement learning (RL) can enable sequential decision-making in complex\nand high-dimensional environments if the acquisition of a new state-action pair\nis efficient, i.e., when interaction with the environment is inexpensive.\nHowever, there are a myriad of real-world applications in which a high number\nof interactions are infeasible. In these environments, transfer RL algorithms,\nwhich can be used for the transfer of knowledge from one or multiple source\nenvironments to a target environment, have been shown to increase learning\nspeed and improve initial and asymptotic performance. However, most existing\ntransfer RL algorithms are on-policy and sample inefficient, and often require\nheuristic choices in algorithm design. This paper proposes an off-policy\nAdvantage-based Policy Transfer algorithm, APT-RL, for fixed domain\nenvironments. Its novelty is in using the popular notion of ``advantage'' as a\nregularizer, to weigh the knowledge that should be transferred from the source,\nrelative to new knowledge learned in the target, removing the need for\nheuristic choices. Further, we propose a new transfer performance metric to\nevaluate the performance of our algorithm and unify existing transfer RL\nframeworks. Finally, we present a scalable, theoretically-backed task\nsimilarity measurement algorithm to illustrate the alignments between our\nproposed transferability metric and similarities between source and target\nenvironments. Numerical experiments on three continuous control benchmark tasks\ndemonstrate that APT-RL outperforms existing transfer RL algorithms on most\ntasks, and is $10\\%$ to $75\\%$ more sample efficient than learning from\nscratch.",
            "author": [
                "Md Ferdous Alam",
                "Parinaz Naghizadeh",
                "David Hoelzle"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06731v1",
                "http://arxiv.org/pdf/2311.06731v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06729v1",
            "title": "Comprehending Lexical and Affective Ontologies in the Demographically\n  Diverse Spatial Social Media Discourse",
            "updated": "2023-11-12T04:23:33Z",
            "published": "2023-11-12T04:23:33Z",
            "summary": "This study aims to comprehend linguistic and socio-demographic features,\nencompassing English language styles, conveyed sentiments, and lexical\ndiversity within spatial online social media review data. To this end, we\nundertake a case study that scrutinizes reviews composed by two distinct and\ndemographically diverse groups. Our analysis entails the extraction and\nexamination of various statistical, grammatical, and sentimental features from\nthese two groups. Subsequently, we leverage these features with machine\nlearning (ML) classifiers to discern their potential in effectively\ndifferentiating between the groups. Our investigation unveils substantial\ndisparities in certain linguistic attributes between the two groups. When\nintegrated into ML classifiers, these attributes exhibit a marked efficacy in\ndistinguishing the groups, yielding a macro F1 score of approximately 0.85.\nFurthermore, we conduct a comparative evaluation of these linguistic features\nwith word n-gram-based lexical features in discerning demographically diverse\nreview data. As expected, the n-gram lexical features, coupled with fine-tuned\ntransformer-based models, show superior performance, attaining accuracies\nsurpassing 95\\% and macro F1 scores exceeding 0.96. Our meticulous analysis and\ncomprehensive evaluations substantiate the efficacy of linguistic and\nsentimental features in effectively discerning demographically diverse review\ndata. The findings of this study provide valuable guidelines for future\nresearch endeavors concerning the analysis of demographic patterns in textual\ncontent across various social media platforms.",
            "author": [
                "Salim Sazzed"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06729v1",
                "http://arxiv.org/pdf/2311.06729v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06724v1",
            "title": "Controllable Topic-Focused Abstractive Summarization",
            "updated": "2023-11-12T03:51:38Z",
            "published": "2023-11-12T03:51:38Z",
            "summary": "Controlled abstractive summarization focuses on producing condensed versions\nof a source article to cover specific aspects by shifting the distribution of\ngenerated text towards a desired style, e.g., a set of topics. Subsequently,\nthe resulting summaries may be tailored to user-defined requirements. This\npaper presents a new Transformer-based architecture capable of producing\ntopic-focused summaries. The architecture modifies the cross-attention\nmechanism of the Transformer to bring topic-focus control to the generation\nprocess while not adding any further parameters to the model. We show that our\nmodel sets a new state of the art on the NEWTS dataset in terms of\ntopic-focused abstractive summarization as well as a topic-prevalence score.\nMoreover, we show via extensive experiments that our proposed topical\ncross-attention mechanism can be plugged into various Transformer models, such\nas BART and T5, improving their performance on the CNN/Dailymail and XSum\nbenchmark datasets for abstractive summarization. This is achieved via\nfine-tuning, without requiring training from scratch. Finally, we show through\nhuman evaluation that our model generates more faithful summaries outperforming\nthe state-of-the-art Frost model.",
            "author": [
                "Seyed Ali Bahrainian",
                "Martin Jaggi",
                "Carsten Eickhoff"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06724v1",
                "http://arxiv.org/pdf/2311.06724v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06720v1",
            "title": "Cappy: Outperforming and Boosting Large Multi-Task LMs with a Small\n  Scorer",
            "updated": "2023-11-12T03:25:34Z",
            "published": "2023-11-12T03:25:34Z",
            "summary": "Large language models (LLMs) such as T0, FLAN, and OPT-IML, excel in\nmulti-tasking under a unified instruction-following paradigm, where they also\nexhibit remarkable generalization abilities to unseen tasks. Despite their\nimpressive performance, these LLMs, with sizes ranging from several billion to\nhundreds of billions of parameters, demand substantial computational resources,\nmaking their training and inference expensive and inefficient. Furthermore,\nadapting these models to downstream applications, particularly complex tasks,\nis often unfeasible due to the extensive hardware requirements for finetuning,\neven when utilizing parameter-efficient approaches such as prompt tuning.\nAdditionally, the most powerful multi-task LLMs, such as OPT-IML-175B and\nFLAN-PaLM-540B, are not publicly accessible, severely limiting their\ncustomization potential. To address these challenges, we introduce a pretrained\nsmall scorer, Cappy, designed to enhance the performance and efficiency of\nmulti-task LLMs. With merely 360 million parameters, Cappy functions either\nindependently on classification tasks or serve as an auxiliary component for\nLLMs, boosting their performance. Moreover, Cappy enables efficiently\nintegrating downstream supervision without requiring LLM finetuning nor the\naccess to their parameters. Our experiments demonstrate that, when working\nindependently on 11 language understanding tasks from PromptSource, Cappy\noutperforms LLMs that are several orders of magnitude larger. Besides, on 45\ncomplex tasks from BIG-Bench, Cappy boosts the performance of the advanced\nmulti-task LLM, FLAN-T5, by a large margin. Furthermore, Cappy is flexible to\ncooperate with other LLM adaptations, including finetuning and in-context\nlearning, offering additional performance enhancement.",
            "author": [
                "Bowen Tan",
                "Yun Zhu",
                "Lijuan Liu",
                "Eric Xing",
                "Zhiting Hu",
                "Jindong Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06720v1",
                "http://arxiv.org/pdf/2311.06720v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06714v1",
            "title": "What factors influence the popularity of user-generated text in the\n  creative domain? A case study of book reviews",
            "updated": "2023-11-12T02:54:11Z",
            "published": "2023-11-12T02:54:11Z",
            "summary": "This study investigates a range of psychological, lexical, semantic, and\nreadability features of book reviews to elucidate the factors underlying their\nperceived popularity. To this end, we conduct statistical analyses of various\nfeatures, including the types and frequency of opinion and emotion-conveying\nterms, connectives, character mentions, word uniqueness, commonness, and\nsentence structure, among others. Additionally, we utilize two readability\ntests to explore whether reading ease is positively associated with review\npopularity. Finally, we employ traditional machine learning classifiers and\ntransformer-based fine-tuned language models with n-gram features to\nautomatically determine review popularity. Our findings indicate that, with the\nexception of a few features (e.g., review length, emotions, and word\nuniqueness), most attributes do not exhibit significant differences between\npopular and non-popular review groups. Furthermore, the poor performance of\nmachine learning classifiers using the word n-gram feature highlights the\nchallenges associated with determining popularity in creative domains. Overall,\nour study provides insights into the factors underlying review popularity and\nhighlights the need for further research in this area, particularly in the\ncreative realm.",
            "author": [
                "Salim Sazzed"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06714v1",
                "http://arxiv.org/pdf/2311.06714v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06712v2",
            "title": "PuzzleTuning: Explicitly Bridge Pathological and Natural Image with\n  Puzzles",
            "updated": "2023-11-30T10:03:17Z",
            "published": "2023-11-12T02:43:22Z",
            "summary": "Pathological image analysis is a crucial field in computer vision. Due to the\nannotation scarcity in the pathological field, recently, most of the works\nleverage self-supervised learning (SSL) trained on unlabeled pathological\nimages, hoping to mine the main representation automatically. However, there\nare two core defects in SSL-based pathological pre-training: (1) they do not\nexplicitly explore the essential focuses of the pathological field, and (2)\nthey do not effectively bridge with and thus take advantage of the large\nnatural image domain. To explicitly address them, we propose our large-scale\nPuzzleTuning framework, containing the following innovations. Firstly, we\nidentify three task focuses that can effectively bridge pathological and\nnatural domains: appearance consistency, spatial consistency, and misalignment\nunderstanding. Secondly, we devise a multiple puzzle restoring task to\nexplicitly pre-train the model with these focuses. Thirdly, for the existing\nlarge domain gap between natural and pathological fields, we introduce an\nexplicit prompt-tuning process to incrementally integrate the domain-specific\nknowledge with the natural knowledge. Additionally, we design a\ncurriculum-learning training strategy that regulates the task difficulty,\nmaking the model fit the complex multiple puzzle restoring task adaptively.\nExperimental results show that our PuzzleTuning framework outperforms the\nprevious SOTA methods in various downstream tasks on multiple datasets. The\ncode, demo, and pre-trained weights are available at\nhttps://github.com/sagizty/PuzzleTuning.",
            "author": [
                "Tianyi Zhang",
                "Shangqing Lyu",
                "Yanli Lei",
                "Sicheng Chen",
                "Nan Ying",
                "Yufang He",
                "Yu Zhao",
                "Yunlu Feng",
                "Guanglei Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06712v2",
                "http://arxiv.org/pdf/2311.06712v2"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06708v1",
            "title": "ReactionT5: a large-scale pre-trained model towards application of\n  limited reaction data",
            "updated": "2023-11-12T02:25:00Z",
            "published": "2023-11-12T02:25:00Z",
            "summary": "Transformer-based deep neural networks have revolutionized the field of\nmolecular-related prediction tasks by treating molecules as symbolic sequences.\nThese models have been successfully applied in various organic chemical\napplications by pretraining them with extensive compound libraries and\nsubsequently fine-tuning them with smaller in-house datasets for specific\ntasks. However, many conventional methods primarily focus on single molecules,\nwith limited exploration of pretraining for reactions involving multiple\nmolecules. In this paper, we propose ReactionT5, a novel model that leverages\npretraining on the Open Reaction Database (ORD), a publicly available\nlarge-scale resource. We further fine-tune this model for yield prediction and\nproduct prediction tasks, demonstrating its impressive performance even with\nlimited fine-tuning data compared to traditional models. The pre-trained\nReactionT5 model is publicly accessible on the Hugging Face platform.",
            "author": [
                "Tatsuya Sagawa",
                "Ryosuke Kojima"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06708v1",
                "http://arxiv.org/pdf/2311.06708v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06707v1",
            "title": "Transfer Learning to Detect COVID-19 Coughs with Incremental Addition of\n  Patient Coughs to Healthy People's Cough Detection Models",
            "updated": "2023-11-12T02:01:24Z",
            "published": "2023-11-12T02:01:24Z",
            "summary": "Millions of people have died worldwide from COVID-19. In addition to its high\ndeath toll, COVID-19 has led to unbearable suffering for individuals and a huge\nglobal burden to the healthcare sector. Therefore, researchers have been trying\nto develop tools to detect symptoms of this human-transmissible disease\nremotely to control its rapid spread. Coughing is one of the common symptoms\nthat researchers have been trying to detect objectively from smartphone\nmicrophone-sensing. While most of the approaches to detect and track cough\nsymptoms rely on machine learning models developed from a large amount of\npatient data, this is not possible at the early stage of an outbreak. In this\nwork, we present an incremental transfer learning approach that leverages the\nrelationship between healthy peoples' coughs and COVID-19 patients' coughs to\ndetect COVID-19 coughs with reasonable accuracy using a pre-trained healthy\ncough detection model and a relatively small set of patient coughs, reducing\nthe need for large patient dataset to train the model. This type of model can\nbe a game changer in detecting the onset of a novel respiratory virus.",
            "author": [
                "Sudip Vhaduri",
                "Seungyeon Paik",
                "Jessica E Huber"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06707v1",
                "http://arxiv.org/pdf/2311.06707v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.LG",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06702v1",
            "title": "Machine Learning for Mechanistic Models of Metapopulation Dynamics",
            "updated": "2023-11-12T01:22:36Z",
            "published": "2023-11-12T01:22:36Z",
            "summary": "Mathematical models in ecology and epidemiology must be consistent with\nobserved data in order to generate reliable knowledge and sound policy.\nMetapopulation systems, which consist of a collection of sub-populations at\nvarious locations, pose technical challenges in statistical inference due to\nnonlinear, stochastic interactions. Difficulties encountered in these\nmethodological issues can obstruct the core scientific questions concerning the\nlink between the mathematical models and the data. Progress in statistically\nefficient simulation-based inference for partially observed stochastic dynamic\nsystems has enabled the development of statistically rigorous approaches to the\nanalysis of nonlinear but low-dimensional systems. Recently, an algorithm has\nbeen developed which enables comparable inference for higher-dimensional models\narising in metapopulation systems. The COVID-19 pandemic provides a situation\nwhere mathematical models and their policy implications were widely visible,\nand we revisit an influential metapopulation model used to inform basic\nepidemiological understanding early in the pandemic. Our methods support\nself-critical data analysis, enabling us to identify and address model\nlimitations, and leading to a new model with substantially improved statistical\nfit and parameter identifiability. Our results suggest that the lockdown\ninitiated on January 23, 2020 in China was more effective than previously\nthought. We proceed to recommend statistical analysis standards for future\nmetapopulation system modeling.",
            "author": [
                "Jifan Li",
                "Edward L. Ionides",
                "Aaron A. King",
                "Mercedes Pascual",
                "Ning Ning"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06702v1",
                "http://arxiv.org/pdf/2311.06702v1"
            ],
            "primary_category": "stat.AP",
            "category": [
                "stat.AP",
                "physics.soc-ph",
                "q-bio.PE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06700v1",
            "title": "Deep JKO: time-implicit particle methods for general nonlinear gradient\n  flows",
            "updated": "2023-11-12T01:11:08Z",
            "published": "2023-11-12T01:11:08Z",
            "summary": "We develop novel neural network-based implicit particle methods to compute\nhigh-dimensional Wasserstein-type gradient flows with linear and nonlinear\nmobility functions. The main idea is to use the Lagrangian formulation in the\nJordan--Kinderlehrer--Otto (JKO) framework, where the velocity field is\napproximated using a neural network. We leverage the formulations from the\nneural ordinary differential equation (neural ODE) in the context of continuous\nnormalizing flow for efficient density computation. Additionally, we make use\nof an explicit recurrence relation for computing derivatives, which greatly\nstreamlines the backpropagation process. Our methodology demonstrates\nversatility in handling a wide range of gradient flows, accommodating various\npotential functions and nonlinear mobility scenarios. Extensive experiments\ndemonstrate the efficacy of our approach, including an illustrative example\nfrom Bayesian inverse problems. This underscores that our scheme provides a\nviable alternative solver for the Kalman-Wasserstein gradient flow.",
            "author": [
                "Wonjun Lee",
                "Li Wang",
                "Wuchen Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06700v1",
                "http://arxiv.org/pdf/2311.06700v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA",
                "math-ph",
                "math.MP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06696v1",
            "title": "Simple and Effective Input Reformulations for Translation",
            "updated": "2023-11-12T00:23:37Z",
            "published": "2023-11-12T00:23:37Z",
            "summary": "Foundation language models learn from their finetuning input context in\ndifferent ways. In this paper, we reformulate inputs during finetuning for\nchallenging translation tasks, leveraging model strengths from pretraining in\nnovel ways to improve downstream performance. These reformulations are simple\ndata level modifications, require no additional collection of training data or\nmodification of data at inference time. They can be applied either on single\nlanguage pair translation tasks or massively multilingual translation tasks.\nExperiments with these techniques demonstrate significant performance\nimprovements up to $\\textbf{3.5 chrF++ on the Flores200 translation\nbenchmark}$. We hope our research accessibly improves finetuning data\nefficiency, enabling more effective training to scalably improve\nstate-of-the-art performance. Our code is released\n$\\href{https://github.com/bri25yu/LanguageModelExperimentation}{here}.$",
            "author": [
                "Brian Yu",
                "Hansen Lillemark",
                "Kurt Keutzer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06696v1",
                "http://arxiv.org/pdf/2311.06696v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07613v1",
            "title": "A Physics-informed Machine Learning-based Control Method for Nonlinear\n  Dynamic Systems with Highly Noisy Measurements",
            "updated": "2023-11-12T00:11:52Z",
            "published": "2023-11-12T00:11:52Z",
            "summary": "This study presents a physics-informed machine learning-based control method\nfor nonlinear dynamic systems with highly noisy measurements. Existing\ndata-driven control methods that use machine learning for system identification\ncannot effectively cope with highly noisy measurements, resulting in unstable\ncontrol performance. To address this challenge, the present study extends\ncurrent physics-informed machine learning capabilities for modeling nonlinear\ndynamics with control and integrates them into a model predictive control\nframework. To demonstrate the capability of the proposed method we test and\nvalidate with two noisy nonlinear dynamic systems: the chaotic Lorenz 3 system,\nand turning machine tool. Analysis of the results illustrate that the proposed\nmethod outperforms state-of-the-art benchmarks as measured by both modeling\naccuracy and control performance for nonlinear dynamic systems under high-noise\nconditions.",
            "author": [
                "Mason Ma",
                "Jiajie Wu",
                "Chase Post",
                "Tony Shi",
                "Jingang Yi",
                "Tony Schmitz",
                "Hong Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07613v1",
                "http://arxiv.org/pdf/2311.07613v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.LG",
                "cs.SY",
                "math.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06691v1",
            "title": "Automatized Self-Supervised Learning for Skin Lesion Screening",
            "updated": "2023-11-11T23:55:40Z",
            "published": "2023-11-11T23:55:40Z",
            "summary": "The incidence rates of melanoma, the deadliest form of skin cancer, have been\nincreasing steadily worldwide, presenting a significant challenge to\ndermatologists. Early detection of melanoma is crucial for improving patient\nsurvival rates, but identifying suspicious lesions through ugly duckling (UD)\nscreening, the current method used for skin cancer screening, can be\nchallenging and often requires expertise in pigmented lesions. To address these\nchallenges and improve patient outcomes, an artificial intelligence (AI)\ndecision support tool was developed to assist dermatologists in identifying UD\nfrom wide-field patient images. The tool uses a state-of-the-art object\ndetection algorithm to identify and extract all skin lesions from patient\nimages, which are then sorted by suspiciousness using a self-supervised AI\nalgorithm. A clinical validation study was conducted to evaluate the tool's\nperformance, which demonstrated an average sensitivity of 93% for the top-10\nAI-identified UDs on skin lesions selected by the majority of experts in\npigmented skin lesions. The study also found that dermatologists confidence\nincreased, and the average majority agreement with the top-10 AI-identified UDs\nimproved to 100% when assisted by AI. The development of this AI decision\nsupport tool aims to address the shortage of specialists, enable at-risk\npatients to receive faster consultations and understand the impact of\nAI-assisted screening. The tool's automation can assist dermatologists in\nidentifying suspicious lesions and provide a more objective assessment,\nreducing subjectivity in the screening process. The future steps for this\nproject include expanding the dataset to include histologically confirmed\nmelanoma cases and increasing the number of participants for clinical\nvalidation to strengthen the tool's reliability and adapt it for real-world\nconsultation.",
            "author": [
                "Vullnet Useini",
                "Stephanie Tanadini-Lang",
                "Quentin Lohmeyer",
                "Mirko Meboldt",
                "Nicolaus Andratschke",
                "Ralph P. Braun",
                "Javier Barranco Garc\u00eda"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06691v1",
                "http://arxiv.org/pdf/2311.06691v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06690v1",
            "title": "Agnostic Membership Query Learning with Nontrivial Savings: New Results,\n  Techniques",
            "updated": "2023-11-11T23:46:48Z",
            "published": "2023-11-11T23:46:48Z",
            "summary": "(Abridged) Designing computationally efficient algorithms in the agnostic\nlearning model (Haussler, 1992; Kearns et al., 1994) is notoriously difficult.\nIn this work, we consider agnostic learning with membership queries for\ntouchstone classes at the frontier of agnostic learning, with a focus on how\nmuch computation can be saved over the trivial runtime of 2^n$. This approach\nis inspired by and continues the study of ``learning with nontrivial savings''\n(Servedio and Tan, 2017). To this end, we establish multiple agnostic learning\nalgorithms, highlighted by:\n  1. An agnostic learning algorithm for circuits consisting of a sublinear\nnumber of gates, which can each be any function computable by a sublogarithmic\ndegree k polynomial threshold function (the depth of the circuit is bounded\nonly by size). This algorithm runs in time 2^{n -s(n)} for s(n) \\approx\nn/(k+1), and learns over the uniform distribution over unlabelled examples on\n\\{0,1\\}^n.\n  2. An agnostic learning algorithm for circuits consisting of a sublinear\nnumber of gates, where each can be any function computable by a \\sym^+ circuit\nof subexponential size and sublogarithmic degree k. This algorithm runs in time\n2^{n-s(n)} for s(n) \\approx n/(k+1), and learns over distributions of\nunlabelled examples that are products of k+1 arbitrary and unknown\ndistributions, each over \\{0,1\\}^{n/(k+1)} (assume without loss of generality\nthat k+1 divides n).",
            "author": [
                "Ari Karchmer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06690v1",
                "http://arxiv.org/pdf/2311.06690v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CC",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06689v1",
            "title": "Metric Optimization and Mainstream Bias Mitigation in Recommender\n  Systems",
            "updated": "2023-11-11T23:32:42Z",
            "published": "2023-11-11T23:32:42Z",
            "summary": "The first part of this thesis focuses on maximizing the overall\nrecommendation accuracy. This accuracy is usually evaluated with some\nuser-oriented metric tailored to the recommendation scenario, but because\nrecommendation is usually treated as a machine learning problem, recommendation\nmodels are trained to maximize some other generic criteria that does not\nnecessarily align with the criteria ultimately captured by the user-oriented\nevaluation metric. Recent research aims at bridging this gap between training\nand evaluation via direct ranking optimization, but still assumes that the\nmetric used for evaluation should also be the metric used for training. We\nchallenge this assumption, mainly because some metrics are more informative\nthan others. Indeed, we show that models trained via the optimization of a loss\ninspired by Rank-Biased Precision (RBP) tend to yield higher accuracy, even\nwhen accuracy is measured with metrics other than RBP. However, the superiority\nof this RBP-inspired loss stems from further benefiting users who are already\nwell-served, rather than helping those who are not.\n  This observation inspires the second part of this thesis, where our focus\nturns to helping non-mainstream users. These are users who are difficult to\nrecommend to either because there is not enough data to model them, or because\nthey have niche taste and thus few similar users to look at when recommending\nin a collaborative way. These differences in mainstreamness introduce a bias\nreflected in an accuracy gap between users or user groups, which we try to\nnarrow.",
            "author": [
                "Roger Zhe Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06689v1",
                "http://arxiv.org/pdf/2311.06689v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06686v1",
            "title": "Jet Rotational Metrics",
            "updated": "2023-11-11T23:13:34Z",
            "published": "2023-11-11T23:13:34Z",
            "summary": "Embedding symmetries in the architectures of deep neural networks can improve\nclassification and network convergence in the context of jet substructure.\nThese results hint at the existence of symmetries in jet energy depositions,\nsuch as rotational symmetry, arising from physical features of the underlying\nprocesses. We introduce a new family of jet observables, Jet Rotational Metrics\n(JRMs), which provide insights into the degree of discrete rotational symmetry\nof a jet. We show that JRMs are formidable jet discriminants and that they\ncapture information not efficiently captured by traditional jet observables,\nsuch as N-subjettiness and Energy-Flow Polynomials.",
            "author": [
                "Alexis Romero",
                "Daniel Whiteson"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06686v1",
                "http://arxiv.org/pdf/2311.06686v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06681v1",
            "title": "SpICE: An interpretable method for spatial data",
            "updated": "2023-11-11T22:45:16Z",
            "published": "2023-11-11T22:45:16Z",
            "summary": "Statistical learning methods are widely utilized in tackling complex problems\ndue to their flexibility, good predictive performance and its ability to\ncapture complex relationships among variables. Additionally, recently developed\nautomatic workflows have provided a standardized approach to implementing\nstatistical learning methods across various applications. However these tools\nhighlight a main drawbacks of statistical learning: its lack of interpretation\nin their results. In the past few years an important amount of research has\nbeen focused on methods for interpreting black box models. Having interpretable\nstatistical learning methods is relevant to have a deeper understanding of the\nmodel. In problems were spatial information is relevant, combined interpretable\nmethods with spatial data can help to get better understanding of the problem\nand interpretation of the results.\n  This paper is focused in the individual conditional expectation (ICE-plot), a\nmodel agnostic methods for interpreting statistical learning models and\ncombined them with spatial information. ICE-plot extension is proposed where\nspatial information is used as restriction to define Spatial ICE curves\n(SpICE). Spatial ICE curves are estimated using real data in the context of an\neconomic problem concerning property valuation in Montevideo, Uruguay.\nUnderstanding the key factors that influence property valuation is essential\nfor decision-making, and spatial data plays a relevant role in this regard.",
            "author": [
                "Natalia da Silva",
                "Ignacio Alvarez-Castro",
                "Leonardo Moreno",
                "Andr\u00e9s Sosa"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06681v1",
                "http://arxiv.org/pdf/2311.06681v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06673v1",
            "title": "Dream to Adapt: Meta Reinforcement Learning by Latent Context\n  Imagination and MDP Imagination",
            "updated": "2023-11-11T22:05:10Z",
            "published": "2023-11-11T22:05:10Z",
            "summary": "Meta reinforcement learning (Meta RL) has been amply explored to quickly\nlearn an unseen task by transferring previously learned knowledge from similar\ntasks. However, most state-of-the-art algorithms require the meta-training\ntasks to have a dense coverage on the task distribution and a great amount of\ndata for each of them. In this paper, we propose MetaDreamer, a context-based\nMeta RL algorithm that requires less real training tasks and data by doing\nmeta-imagination and MDP-imagination. We perform meta-imagination by\ninterpolating on the learned latent context space with disentangled properties,\nas well as MDP-imagination through the generative world model where physical\nknowledge is added to plain VAE networks. Our experiments with various\nbenchmarks show that MetaDreamer outperforms existing approaches in data\nefficiency and interpolated generalization.",
            "author": [
                "Lu Wen",
                "Songan Zhang",
                "H. Eric Tseng",
                "Huei Peng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06673v1",
                "http://arxiv.org/pdf/2311.06673v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06672v1",
            "title": "DUBLINE: A Deep Unfolding Network for B-line Detection in Lung\n  Ultrasound Images",
            "updated": "2023-11-11T22:00:35Z",
            "published": "2023-11-11T22:00:35Z",
            "summary": "In the context of lung ultrasound, the detection of B-lines, which are\nindicative of interstitial lung disease and pulmonary edema, plays a pivotal\nrole in clinical diagnosis. Current methods still rely on visual inspection by\nexperts. Vision-based automatic B-line detection methods have been developed,\nbut their performance has yet to improve in terms of both accuracy and\ncomputational speed. This paper presents a novel approach to posing B-line\ndetection as an inverse problem via deep unfolding of the Alternating Direction\nMethod of Multipliers (ADMM). It tackles the challenges of data labelling and\nmodel training in lung ultrasound image analysis by harnessing the capabilities\nof deep neural networks and model-based methods. Our objective is to\nsubstantially enhance diagnostic accuracy while ensuring efficient real-time\ncapabilities. The results show that the proposed method runs more than 90 times\nfaster than the traditional model-based method and achieves an F1 score that is\n10.6% higher.",
            "author": [
                "Tianqi Yang",
                "Nantheera Anantrasirichai",
                "Oktay Karaku\u015f",
                "Marco Allinovi",
                "Hatice Ceylan Koydemir",
                "Alin Achim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06672v1",
                "http://arxiv.org/pdf/2311.06672v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06670v1",
            "title": "EPSAPG: A Pipeline Combining MMseqs2 and PSI-BLAST to Quickly Generate\n  Extensive Protein Sequence Alignment Profiles",
            "updated": "2023-11-11T21:40:00Z",
            "published": "2023-11-11T21:40:00Z",
            "summary": "Numerous machine learning (ML) models employed in protein function and\nstructure prediction depend on evolutionary information, which is captured\nthrough multiple-sequence alignments (MSA) or position-specific scoring\nmatrices (PSSM) as generated by PSI-BLAST. Consequently, these predictive\nmethods are burdened by substantial computational demands and prolonged\ncomputing time requirements. The principal challenge stems from the necessity\nimposed on the PSI-BLAST software to load large sequence databases sequentially\nin batches and then search for sequence alignments akin to a given query\nsequence. In the case of batch queries, the runtime scales even linearly. The\npredicament at hand is becoming more challenging as the size of bio-sequence\ndata repositories experiences exponential growth over time and as a\nconsequence, this upward trend exerts a proportional strain on the runtime of\nPSI-BLAST. To address this issue, an eminent resolution lies in leveraging the\nMMseqs2 method, capable of expediting the search process by a magnitude of 100.\nHowever, MMseqs2 cannot be directly employed to generate the final output in\nthe desired format of PSI-BLAST alignments and PSSM profiles. In this research\nwork, I developed a comprehensive pipeline that synergistically integrates both\nMMseqs2 and PSI-BLAST, resulting in the creation of a robust, optimized, and\nhighly efficient hybrid alignment pipeline. Notably, the hybrid tool exhibits a\nsignificant speed improvement, surpassing the runtime performance of PSI-BLAST\nin generating sequence alignment profiles by a factor of two orders of\nmagnitude. It is implemented in C++ and is freely available under the MIT\nlicense at https://github.com/issararab/EPSAPG.",
            "author": [
                "Issar Arab"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06670v1",
                "http://arxiv.org/pdf/2311.06670v1"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06668v2",
            "title": "In-context Vectors: Making In Context Learning More Effective and\n  Controllable Through Latent Space Steering",
            "updated": "2023-11-16T22:39:00Z",
            "published": "2023-11-11T21:19:44Z",
            "summary": "Large language models (LLMs) demonstrate emergent in-context learning\ncapabilities, where they adapt to new tasks based on example demonstrations.\nHowever, in-context learning has seen limited effectiveness in many settings,\nis difficult to quantitatively control and takes up context window space. To\novercome these limitations, we propose an alternative approach that recasts\nin-context learning as in-context vectors (ICV). Using ICV has two steps. We\nfirst use a forward pass on demonstration examples to create the in-context\nvector from the latent embedding of the LLM. This vector captures essential\ninformation about the intended task. On a new query, instead of adding\ndemonstrations to the prompt, we shift the latent states of the LLM using the\nICV. The ICV approach has several benefits: 1) it enables the LLM to more\neffectively follow the demonstration examples; 2) it's easy to control by\nadjusting the magnitude of the ICV; 3) it reduces the length of the prompt by\nremoving the in-context demonstrations; 4) ICV is computationally much more\nefficient than fine-tuning. We demonstrate that ICV achieves better performance\ncompared to standard in-context learning and fine-tuning on diverse tasks\nincluding safety, style transfer, role-playing and formatting. Moreover, we\nshow that we can flexibly teach LLM to simultaneously follow different types of\ninstructions by simple vector arithmetics on the corresponding ICVs.",
            "author": [
                "Sheng Liu",
                "Lei Xing",
                "James Zou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06668v2",
                "http://arxiv.org/pdf/2311.06668v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14704v1",
            "title": "An\u00e1lise e modelagem de jogos digitais: Relato de uma experi\u00eancia\n  educacional utlizando PBL em um grupo multidisciplinar",
            "updated": "2023-11-11T20:28:51Z",
            "published": "2023-11-11T20:28:51Z",
            "summary": "Traditional software engineering education generally emphasizes strict\ncollaboration and technical skills However active teaching strategies where\nstudents actively engage with the material transitioning from passive observers\nto active manipulators of realworld tools have shown effectiveness in software\nengineering The evolving market demands new skills in the context of digital\ntransformation presenting challenges such as modeling complex business\nscenarios and navigating the interconnections between people systems and\ntechnologies Shifting from conventional software engineering instruction to\nactive methodologies like ProblemBased Learning PBL has proven to bring\nrealworld market challenges and realities into the classroom This article\ndetails an experience from the Digital Games Analysis and Modeling course in\nthe Digital Games Masters program at Pontifical Catholic University of Sao\nPaulo It covers the discussed concepts case study rolebased work method and\nsteps of the meetings We also present examples of outcomes like requirement\ndiagrams context diagrams use case diagrams class diagrams interviews and\nothers that contributed to the Game Design Document GDD These were created by\neach group during the meetings alongside their game prototypes Additionally a\ndiscussion on the developed capabilities is included",
            "author": [
                "David de Oliveira Lemes",
                "Ezequiel Fran\u00e7a dos Santos",
                "Eduardo Romanek",
                "Celso Fujimoto",
                "Adriano Felix Valente"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14704v1",
                "http://arxiv.org/pdf/2311.14704v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06654v1",
            "title": "Unsupervised and semi-supervised co-salient object detection via\n  segmentation frequency statistics",
            "updated": "2023-11-11T19:47:16Z",
            "published": "2023-11-11T19:47:16Z",
            "summary": "In this paper, we address the detection of co-occurring salient objects\n(CoSOD) in an image group using frequency statistics in an unsupervised manner,\nwhich further enable us to develop a semi-supervised method. While previous\nworks have mostly focused on fully supervised CoSOD, less attention has been\nallocated to detecting co-salient objects when limited segmentation annotations\nare available for training. Our simple yet effective unsupervised method\nUS-CoSOD combines the object co-occurrence frequency statistics of unsupervised\nsingle-image semantic segmentations with salient foreground detections using\nself-supervised feature learning. For the first time, we show that a large\nunlabeled dataset e.g. ImageNet-1k can be effectively leveraged to\nsignificantly improve unsupervised CoSOD performance. Our unsupervised model is\na great pre-training initialization for our semi-supervised model SS-CoSOD,\nespecially when very limited labeled data is available for training. To avoid\npropagating erroneous signals from predictions on unlabeled data, we propose a\nconfidence estimation module to guide our semi-supervised training. Extensive\nexperiments on three CoSOD benchmark datasets show that both of our\nunsupervised and semi-supervised models outperform the corresponding\nstate-of-the-art models by a significant margin (e.g., on the Cosal2015\ndataset, our US-CoSOD model has an 8.8% F-measure gain over a SOTA unsupervised\nco-segmentation model and our SS-CoSOD model has an 11.81% F-measure gain over\na SOTA semi-supervised CoSOD model).",
            "author": [
                "Souradeep Chakraborty",
                "Shujon Naha",
                "Muhammet Bastan",
                "Amit Kumar K C",
                "Dimitris Samaras"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06654v1",
                "http://arxiv.org/pdf/2311.06654v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06651v1",
            "title": "Traffic Sign Recognition Using Local Vision Transformer",
            "updated": "2023-11-11T19:42:41Z",
            "published": "2023-11-11T19:42:41Z",
            "summary": "Recognition of traffic signs is a crucial aspect of self-driving cars and\ndriver assistance systems, and machine vision tasks such as traffic sign\nrecognition have gained significant attention. CNNs have been frequently used\nin machine vision, but introducing vision transformers has provided an\nalternative approach to global feature learning. This paper proposes a new\nnovel model that blends the advantages of both convolutional and\ntransformer-based networks for traffic sign recognition. The proposed model\nincludes convolutional blocks for capturing local correlations and\ntransformer-based blocks for learning global dependencies. Additionally, a\nlocality module is incorporated to enhance local perception. The performance of\nthe suggested model is evaluated on the Persian Traffic Sign Dataset and German\nTraffic Sign Recognition Benchmark and compared with SOTA convolutional and\ntransformer-based models. The experimental evaluations demonstrate that the\nhybrid network with the locality module outperforms pure transformer-based\nmodels and some of the best convolutional networks in accuracy. Specifically,\nour proposed final model reached 99.66% accuracy in the German traffic sign\nrecognition benchmark and 99.8% in the Persian traffic sign dataset, higher\nthan the best convolutional models. Moreover, it outperforms existing CNNs and\nViTs while maintaining fast inference speed. Consequently, the proposed model\nproves to be significantly faster and more suitable for real-world\napplications.",
            "author": [
                "Ali Farzipour",
                "Omid Nejati Manzari",
                "Shahriar B. Shokouhi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06651v1",
                "http://arxiv.org/pdf/2311.06651v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06650v2",
            "title": "Heuristic Optimal Transport in Branching Networks",
            "updated": "2023-12-04T16:18:37Z",
            "published": "2023-11-11T19:39:50Z",
            "summary": "Optimal transport aims to learn a mapping of sources to targets by minimizing\nthe cost, which is typically defined as a function of distance. The solution to\nthis problem consists of straight line segments optimally connecting sources to\ntargets, and it does not exhibit branching. These optimal solutions are in\nstark contrast with both natural, and man-made transportation networks, where\nbranching structures are prevalent. Here we discuss a fast heuristic branching\nmethod for optimal transport in networks, and we provide several applications.",
            "author": [
                "M. Andrecut"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06650v2",
                "http://arxiv.org/pdf/2311.06650v2"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06649v1",
            "title": "A Template Is All You Meme",
            "updated": "2023-11-11T19:38:14Z",
            "published": "2023-11-11T19:38:14Z",
            "summary": "Memes are a modern form of communication and meme templates possess a base\nsemantics that is customizable by whomever posts it on social media. Machine\nlearning systems struggle with memes, which is likely due to such systems\nhaving insufficient context to understand memes, as there is more to memes than\nthe obvious image and text. Here, to aid understanding of memes, we release a\nknowledge base of memes and information found on www.knowyourmeme.com, which we\ncall the Know Your Meme Knowledge Base (KYMKB), composed of more than 54,000\nimages. The KYMKB includes popular meme templates, examples of each template,\nand detailed information about the template. We hypothesize that meme templates\ncan be used to inject models with the context missing from previous approaches.\nTo test our hypothesis, we create a non-parametric majority-based classifier,\nwhich we call Template-Label Counter (TLC). We find TLC more effective than or\ncompetitive with fine-tuned baselines. To demonstrate the power of meme\ntemplates and the value of both our knowledge base and method, we conduct\nthorough classification experiments and exploratory data analysis in the\ncontext of five meme analysis tasks.",
            "author": [
                "Luke Bates",
                "Peter Ebert Christensen",
                "Preslav Nakov",
                "Iryna Gurevych"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06649v1",
                "http://arxiv.org/pdf/2311.06649v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06643v1",
            "title": "Privacy Risks Analysis and Mitigation in Federated Learning for Medical\n  Images",
            "updated": "2023-11-11T18:58:01Z",
            "published": "2023-11-11T18:58:01Z",
            "summary": "Federated learning (FL) is gaining increasing popularity in the medical\ndomain for analyzing medical images, which is considered an effective technique\nto safeguard sensitive patient data and comply with privacy regulations.\nHowever, several recent studies have revealed that the default settings of FL\nmay leak private training data under privacy attacks. Thus, it is still unclear\nwhether and to what extent such privacy risks of FL exist in the medical\ndomain, and if so, ``how to mitigate such risks?''. In this paper, first, we\npropose a holistic framework for Medical data Privacy risk analysis and\nmitigation in Federated Learning (MedPFL) to analyze privacy risks and develop\neffective mitigation strategies in FL for protecting private medical data.\nSecond, we demonstrate the substantial privacy risks of using FL to process\nmedical images, where adversaries can easily perform privacy attacks to\nreconstruct private medical images accurately. Third, we show that the defense\napproach of adding random noises may not always work effectively to protect\nmedical images against privacy attacks in FL, which poses unique and pressing\nchallenges associated with medical data for privacy protection.",
            "author": [
                "Badhan Chandra Das",
                "M. Hadi Amini",
                "Yanzhao Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06643v1",
                "http://arxiv.org/pdf/2311.06643v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06642v1",
            "title": "Double-Free-Layer Stochastic Magnetic Tunnel Junctions with Synthetic\n  Antiferromagnets",
            "updated": "2023-11-11T18:56:08Z",
            "published": "2023-11-11T18:56:08Z",
            "summary": "Stochastic magnetic tunnel junctions (sMTJ) using low-barrier nanomagnets\nhave shown promise as fast, energy-efficient, and scalable building blocks for\nprobabilistic computing. Despite recent experimental and theoretical progress,\nsMTJs exhibiting the ideal characteristics necessary for probabilistic bits\n(p-bit) are still lacking. Ideally, the sMTJs should have (a) voltage bias\nindependence preventing read disturbance (b) uniform randomness in the\nmagnetization angle between the free layers, and (c) fast fluctuations without\nrequiring external magnetic fields while being robust to magnetic field\nperturbations. Here, we propose a new design satisfying all of these\nrequirements, using double-free-layer sMTJs with synthetic antiferromagnets\n(SAF). We evaluate the proposed sMTJ design with experimentally benchmarked\nspin-circuit models accounting for transport physics, coupled with the\nstochastic Landau-Lifshitz-Gilbert equation for magnetization dynamics. We find\nthat the use of low-barrier SAF layers reduces dipolar coupling, achieving\nuncorrelated fluctuations at zero-magnetic field surviving up to diameters\nexceeding ($D\\approx 100$ nm) if the nanomagnets can be made thin enough\n($\\approx 1$-$2$ nm). The double-free-layer structure retains bias-independence\nand the circular nature of the nanomagnets provides near-uniform randomness\nwith fast fluctuations. Combining our full sMTJ model with advanced transistor\nmodels, we estimate the energy to generate a random bit as $\\approx$ 3.6 fJ,\nwith fluctuation rates of $\\approx$ 3.3 GHz per p-bit. Our results will guide\nthe experimental development of superior stochastic magnetic tunnel junctions\nfor large-scale and energy-efficient probabilistic computation for problems\nrelevant to machine learning and artificial intelligence.",
            "author": [
                "Kemal Selcuk",
                "Shun Kanai",
                "Rikuto Ota",
                "Hideo Ohno",
                "Shunsuke Fukami",
                "Kerem Y. Camsari"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06642v1",
                "http://arxiv.org/pdf/2311.06642v1"
            ],
            "primary_category": "cond-mat.mes-hall",
            "category": [
                "cond-mat.mes-hall",
                "cs.ET"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06639v1",
            "title": "Data-driven rules for multidimensional reflection problems",
            "updated": "2023-11-11T18:36:17Z",
            "published": "2023-11-11T18:36:17Z",
            "summary": "Over the recent past data-driven algorithms for solving stochastic optimal\ncontrol problems in face of model uncertainty have become an increasingly\nactive area of research. However, for singular controls and underlying\ndiffusion dynamics the analysis has so far been restricted to the scalar case.\nIn this paper we fill this gap by studying a multivariate singular control\nproblem for reversible diffusions with controls of reflection type. Our\ncontributions are threefold. We first explicitly determine the long-run average\ncosts as a domain-dependent functional, showing that the control problem can be\nequivalently characterized as a shape optimization problem. For given diffusion\ndynamics, assuming the optimal domain to be strongly star-shaped, we then\npropose a gradient descent algorithm based on polytope approximations to\nnumerically determine a cost-minimizing domain. Finally, we investigate\ndata-driven solutions when the diffusion dynamics are unknown to the\ncontroller. Using techniques from nonparametric statistics for stochastic\nprocesses, we construct an optimal domain estimator, whose static regret is\nbounded by the minimax optimal estimation rate of the unreflected process'\ninvariant density. In the most challenging situation, when the dynamics must be\nlearned simultaneously to controlling the process, we develop an episodic\nlearning algorithm to overcome the emerging exploration-exploitation dilemma\nand show that given the static regret as a baseline, the loss in its sublinear\nregret per time unit is of natural order compared to the one-dimensional case.",
            "author": [
                "S\u00f6ren Christensen",
                "Asbj\u00f8rn Holk Thomsen",
                "Lukas Trottner"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06639v1",
                "http://arxiv.org/pdf/2311.06639v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "math.PR",
                "math.ST",
                "stat.ML",
                "stat.TH",
                "93E35, 68T05, 49Q10, 60J60, 62M05"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06633v1",
            "title": "The Pros and Cons of Using Machine Learning and Interpretable Machine\n  Learning Methods in psychiatry detection applications, specifically\n  depression disorder: A Brief Review",
            "updated": "2023-11-11T18:31:32Z",
            "published": "2023-11-11T18:31:32Z",
            "summary": "The COVID-19 pandemic has forced many people to limit their social\nactivities, which has resulted in a rise in mental illnesses, particularly\ndepression. To diagnose these illnesses with accuracy and speed, and prevent\nsevere outcomes such as suicide, the use of machine learning has become\nincreasingly important. Additionally, to provide precise and understandable\ndiagnoses for better treatment, AI scientists and researchers must develop\ninterpretable AI-based solutions. This article provides an overview of relevant\narticles in the field of machine learning and interpretable AI, which helps to\nunderstand the advantages and disadvantages of using AI in psychiatry disorder\ndetection applications.",
            "author": [
                "Hossein Simchi",
                "Samira Tajik"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06633v1",
                "http://arxiv.org/pdf/2311.06633v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "68T01"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06632v1",
            "title": "The Exact Determinant of a Specific Class of Sparse Positive Definite\n  Matrices",
            "updated": "2023-11-11T18:31:25Z",
            "published": "2023-11-11T18:31:25Z",
            "summary": "For a specific class of sparse Gaussian graphical models, we provide a\nclosed-form solution for the determinant of the covariance matrix. In our\nframework, the graphical interaction model (i.e., the covariance selection\nmodel) is equal to replacement product of $\\mathcal{K}_{n}$ and\n$\\mathcal{K}_{n-1}$, where $\\mathcal{K}_n$ is the complete graph with $n$\nvertices. Our analysis is based on taking the Fourier transform of the local\nfactors of the model, which can be viewed as an application of the Normal\nFactor Graph Duality Theorem and holographic algorithms. The closed-form\nexpression is obtained by applying the Matrix Determinant Lemma on the\ntransformed graphical model. In this context, we will also define a notion of\nequivalence between two Gaussian graphical models.",
            "author": [
                "Mehdi Molkaraie"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06632v1",
                "http://arxiv.org/pdf/2311.06632v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "cs.NA",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06631v1",
            "title": "A 3D Conditional Diffusion Model for Image Quality Transfer -- An\n  Application to Low-Field MRI",
            "updated": "2023-11-11T18:30:56Z",
            "published": "2023-11-11T18:30:56Z",
            "summary": "Low-field (LF) MRI scanners (<1T) are still prevalent in settings with\nlimited resources or unreliable power supply. However, they often yield images\nwith lower spatial resolution and contrast than high-field (HF) scanners. This\nquality disparity can result in inaccurate clinician interpretations. Image\nQuality Transfer (IQT) has been developed to enhance the quality of images by\nlearning a mapping function between low and high-quality images. Existing IQT\nmodels often fail to restore high-frequency features, leading to blurry output.\nIn this paper, we propose a 3D conditional diffusion model to improve 3D\nvolumetric data, specifically LF MR images. Additionally, we incorporate a\ncross-batch mechanism into the self-attention and padding of our network,\nensuring broader contextual awareness even under small 3D patches. Experiments\non the publicly available Human Connectome Project (HCP) dataset for IQT and\nbrain parcellation demonstrate that our model outperforms existing methods both\nquantitatively and qualitatively. The code is publicly available at\n\\url{https://github.com/edshkim98/DiffusionIQT}.",
            "author": [
                "Seunghoi Kim",
                "Henry F. J. Tregidgo",
                "Ahmed K. Eldaly",
                "Matteo Figini",
                "Daniel C. Alexander"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06631v1",
                "http://arxiv.org/pdf/2311.06631v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06630v1",
            "title": "Search for hyperbolic encounters of compact objects in the third\n  LIGO-Virgo-KAGRA observing run",
            "updated": "2023-11-11T18:26:22Z",
            "published": "2023-11-11T18:26:22Z",
            "summary": "Gravitational-wave (GW) observations provide unique information about compact\nobjects. As detectors sensitivity increases, new astrophysical sources of GW\ncould emerge. Close hyperbolic encounters are one such source class: scattering\nof stellar mass compact objects is expected to manifest as GW burst signals in\nthe frequency band of current detectors. We present the search for GW from\nhyperbolic encounters in the second half of the third Advanced LIGO-Virgo\nobserving run (O3b). We perform a model-informed search with machine-learning\nenhanced Coherent WaveBurst algorithm. No significant event has been identified\nin addition to known detections of compact binary coalescences. We inject in\nthe O3b data non-spinning third Post-Newtonian order accurate hyperbolic\nencounter model with component masses between [2, 100] $M_{\\odot}$, impact\nparameter in [60, 100] ${GM}/{c^2}$ and eccentricity in [1.05, 1.6]. We further\ndiscuss the properties of the simulation recovered. For the first time, we\nreport the sensitivity volume achieved for such sources, which for O3b data\nreaches up to 3.9$\\pm 1.4 \\times 10^5$ Mpc$^3$year for compact objects with\nmasses between [20, 40] $M_{\\odot}$, corresponding to a rate density upper\nlimit of 0.589$\\pm$0.094 $\\times10^{-5}$Mpc$^{-3}$year$^{-1}$. Finally, we\npresent projected sensitive volume for the next observing runs of current\ndetectors, namely O4 and O5.",
            "author": [
                "Sophie Bini",
                "Shubhanshu Tiwari",
                "Yumeng Xu",
                "Leigh Smith",
                "Michael Ebersold",
                "Giacomo Principe",
                "Maria Haney",
                "Philippe Jetzer",
                "Giovanni A. Prodi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06630v1",
                "http://arxiv.org/pdf/2311.06630v1"
            ],
            "primary_category": "gr-qc",
            "category": [
                "gr-qc"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06625v1",
            "title": "Streamlining Energy Transition Scenarios to Key Policy Decisions",
            "updated": "2023-11-11T18:10:32Z",
            "published": "2023-11-11T18:10:32Z",
            "summary": "Uncertainties surrounding the energy transition often lead modelers to\npresent large sets of scenarios that are challenging for policymakers to\ninterpret and act upon. An alternative approach is to define a few qualitative\nstorylines from stakeholder discussions, which can be affected by biases and\ninfeasibilities. Leveraging decision trees, a popular machine-learning\ntechnique, we derive interpretable storylines from many quantitative scenarios\nand show how the key decisions in the energy transition are interlinked.\nSpecifically, our results demonstrate that choosing a high deployment of\nrenewables and sector coupling makes global decarbonization scenarios robust\nagainst uncertainties in climate sensitivity and demand. Also, the energy\ntransition to a fossil-free Europe is primarily determined by choices on the\nroles of bioenergy, storage, and heat electrification. Our transferrable\napproach translates vast energy model results into a small set of critical\ndecisions, guiding decision-makers in prioritizing the key factors that will\nshape the energy transition.",
            "author": [
                "Florian Joseph Baader",
                "Stefano Moret",
                "Wolfram Wiesemann",
                "Iain Staffell",
                "Andr\u00e9 Bardow"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06625v1",
                "http://arxiv.org/pdf/2311.06625v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06613v1",
            "title": "Computer Vision for Particle Size Analysis of Coarse-Grained Soils",
            "updated": "2023-11-11T17:01:24Z",
            "published": "2023-11-11T17:01:24Z",
            "summary": "Particle size analysis (PSA) is a fundamental technique for evaluating the\nphysical characteristics of soils. However, traditional methods like sieving\ncan be time-consuming and labor-intensive. In this study, we present a novel\napproach that utilizes computer vision (CV) and the Python programming language\nfor PSA of coarse-grained soils, employing a standard mobile phone camera. By\neliminating the need for a high-performance camera, our method offers\nconvenience and cost savings. Our methodology involves using the OPENCV library\nto detect and measure soil particles in digital photographs taken under\nordinary lighting conditions. For accurate particle size determination, a\ncalibration target with known dimensions is placed on a plain paper alongside\n20 different sand samples. The proposed method is compared with traditional\nsieve analysis and exhibits satisfactory performance for soil particles larger\nthan 2 mm, with a mean absolute percent error (MAPE) of approximately 6%.\nHowever, particles smaller than 2 mm result in higher MAPE, reaching up to 60%.\nTo address this limitation, we recommend using a higher-resolution camera to\ncapture images of the smaller soil particles. Furthermore, we discuss the\nadvantages, limitations, and potential future improvements of our method.\nRemarkably, the program can be executed on a mobile phone, providing immediate\nresults without the need to send soil samples to a laboratory. This\nfield-friendly feature makes our approach highly convenient for on-site usage,\noutside of a traditional laboratory setting. Ultimately, this novel method\nrepresents an initial disruption to the industry, enabling efficient particle\nsize analysis of soil without the reliance on laboratory-based sieve analysis.\nKEYWORDS: Computer vision, Grain size, ARUCO",
            "author": [
                "Sompote Youwai",
                "Parchya Makam"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06613v1",
                "http://arxiv.org/pdf/2311.06613v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06607v2",
            "title": "Monkey: Image Resolution and Text Label Are Important Things for Large\n  Multi-modal Models",
            "updated": "2023-11-24T16:21:39Z",
            "published": "2023-11-11T16:37:41Z",
            "summary": "Large Multimodal Models (LMMs) have shown promise in vision-language tasks\nbut struggle with high-resolution input and detailed scene understanding.\nAddressing these challenges, we introduce Monkey to enhance LMM capabilities.\nFirstly, Monkey processes input images by dividing them into uniform patches,\neach matching the size (e.g., 448x448) used in the original training of the\nwell-trained vision encoder. Equipped with individual adapter for each patch,\nMonkey can handle higher resolutions up to 1344x896 pixels, enabling the\ndetailed capture of complex visual information. Secondly, it employs a\nmulti-level description generation method, enriching the context for\nscene-object associations. This two-part strategy ensures more effective\nlearning from generated data: the higher resolution allows for a more detailed\ncapture of visuals, which in turn enhances the effectiveness of comprehensive\ndescriptions. Extensive ablative results validate the effectiveness of our\ndesigns. Additionally, experiments on 18 datasets further demonstrate that\nMonkey surpasses existing LMMs in many tasks like Image Captioning and various\nVisual Question Answering formats. Specially, in qualitative tests focused on\ndense text question answering, Monkey has exhibited encouraging results\ncompared with GPT4V. Code is available at\nhttps://github.com/Yuliang-Liu/Monkey.",
            "author": [
                "Zhang Li",
                "Biao Yang",
                "Qiang Liu",
                "Zhiyin Ma",
                "Shuo Zhang",
                "Jingxu Yang",
                "Yabo Sun",
                "Yuliang Liu",
                "Xiang Bai"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06607v2",
                "http://arxiv.org/pdf/2311.06607v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06597v1",
            "title": "Understanding Grokking Through A Robustness Viewpoint",
            "updated": "2023-11-11T15:45:44Z",
            "published": "2023-11-11T15:45:44Z",
            "summary": "Recently, an unusual phenomenon called grokking has gained much attention,\nwhere sometimes a neural network generalizes long after it perfectly fits the\ntraining data. We try to understand this seemingly strange phenomenon using the\nrobustness of the neural network. Using a robustness viewpoint, we show that\nthe popular $l_2$ weight norm (metric) of the neural network is actually a\nsufficient condition for grokking. As we also empirically find that $l_2$ norm\ncorrelates with grokking on the test data not in a timely way, we propose new\nmetrics based on robustness and information theory and find that our new\nmetrics correlate well with the grokking phenomenon. Based on the previous\nobservations, we propose methods to speed up the generalization process. In\naddition, we examine the standard training process on modulo addition dataset\nand find that it hardly learns other basic group operations before grokking,\nincluding the commutative law. Interestingly, the speed up of generalization\nwhen using our proposed method can be partially explained by learning the\ncommutative law, a necessary condition when the model groks on test dataset.",
            "author": [
                "Zhiquan Tan",
                "Weiran Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06597v1",
                "http://arxiv.org/pdf/2311.06597v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06595v3",
            "title": "From Classification to Generation: Insights into Crosslingual Retrieval\n  Augmented ICL",
            "updated": "2023-12-02T17:00:27Z",
            "published": "2023-11-11T15:40:21Z",
            "summary": "The remarkable ability of Large Language Models (LLMs) to understand and\nfollow instructions has sometimes been limited by their in-context learning\n(ICL) performance in low-resource languages. To address this, we introduce a\nnovel approach that leverages cross-lingual retrieval-augmented in-context\nlearning (CREA-ICL). By extracting semantically similar prompts from\nhigh-resource languages, we aim to improve the zero-shot performance of\nmultilingual pre-trained language models (MPLMs) across diverse tasks. Though\nour approach yields steady improvements in classification tasks, it faces\nchallenges in generation tasks. Our evaluation offers insights into the\nperformance dynamics of retrieval-augmented in-context learning across both\nclassification and generation domains.",
            "author": [
                "Xiaoqian Li",
                "Ercong Nie",
                "Sheng Liang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06595v3",
                "http://arxiv.org/pdf/2311.06595v3"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06586v1",
            "title": "The Power of Attention: Bridging Cognitive Load, Multimedia Learning,\n  and AI",
            "updated": "2023-11-11T14:51:26Z",
            "published": "2023-11-11T14:51:26Z",
            "summary": "This article addresses the intersection of various educational theories and\ntheir relationship with the education of computer science students, with a\nfocus on the importance of understanding computational thinking and its\napplication in education. The historical context and fundamental concepts of\nCognitive Load Theory, Multimedia Learning, and Constructivism are explored,\nhighlighting their underlying biological assumptions about human learning. It\nalso examines how these theories can be integrated with the use of Artificial\nIntelligence (AI) in education, with a particular emphasis on the attention\nmechanisms and abstract learning present in AI models like Transformers.\nLastly, the relevance of these theories and practices for computer education\nstudent training is discussed, emphasizing how the development of computational\nthinking can contribute to a more effective approach in teaching and learning.",
            "author": [
                "Herbert dos Santos Macedo",
                "Italo Thiago Felix dos Santos",
                "Edgard Luciano Oliveira da Silva"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06586v1",
                "http://arxiv.org/pdf/2311.06586v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06580v1",
            "title": "Modeling Power Systems Dynamics with Symbolic Physics-Informed Neural\n  Networks",
            "updated": "2023-11-11T14:25:39Z",
            "published": "2023-11-11T14:25:39Z",
            "summary": "In recent years, scientific machine learning, particularly physic-informed\nneural networks (PINNs), has introduced new innovative methods to understanding\nthe differential equations that describe power system dynamics, providing a\nmore efficient alternative to traditional methods. However, using a single\nneural network to capture patterns of all variables requires a large enough\nsize of networks, leading to a long time of training and still high\ncomputational costs. In this paper, we utilize the interfacing of PINNs with\nsymbolic techniques to construct multiple single-output neural networks by\ntaking the loss function apart and integrating it over the relevant domain.\nAlso, we reweigh the factors of the components in the loss function to improve\nthe performance of the network for instability systems. Our results show that\nthe symbolic PINNs provide higher accuracy with significantly fewer parameters\nand faster training time. By using the adaptive weight method, the symbolic\nPINNs can avoid the vanishing gradient problem and numerical instability.",
            "author": [
                "Huynh T. T. Tran",
                "Hieu T. Nguyen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06580v1",
                "http://arxiv.org/pdf/2311.06580v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06576v1",
            "title": "An Intelligent Social Learning-based Optimization Strategy for Black-box\n  Robotic Control with Reinforcement Learning",
            "updated": "2023-11-11T14:11:49Z",
            "published": "2023-11-11T14:11:49Z",
            "summary": "Implementing intelligent control of robots is a difficult task, especially\nwhen dealing with complex black-box systems, because of the lack of visibility\nand understanding of how these robots work internally. This paper proposes an\nIntelligent Social Learning (ISL) algorithm to enable intelligent control of\nblack-box robotic systems. Inspired by mutual learning among individuals in\nhuman social groups, ISL includes learning, imitation, and self-study styles.\nIndividuals in the learning style use the Levy flight search strategy to learn\nfrom the best performer and form the closest relationships. In the imitation\nstyle, individuals mimic the best performer with a second-level rapport by\nemploying a random perturbation strategy. In the self-study style, individuals\nlearn independently using a normal distribution sampling method while\nmaintaining a distant relationship with the best performer. Individuals in the\npopulation are regarded as autonomous intelligent agents in each style. Neural\nnetworks perform strategic actions in three styles to interact with the\nenvironment and the robot and iteratively optimize the network policy. Overall,\nISL builds on the principles of intelligent optimization, incorporating ideas\nfrom reinforcement learning, and possesses strong search capabilities, fast\ncomputation speed, fewer hyperparameters, and insensitivity to sparse rewards.\nThe proposed ISL algorithm is compared with four state-of-the-art methods on\nsix continuous control benchmark cases in MuJoCo to verify its effectiveness\nand advantages. Furthermore, ISL is adopted in the simulation and experimental\ngrasping tasks of the UR3 robot for validations, and satisfactory solutions are\nyielded.",
            "author": [
                "Xubo Yang",
                "Jian Gao",
                "Ting Wang",
                "Yaozhen He"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06576v1",
                "http://arxiv.org/pdf/2311.06576v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.NE",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06575v1",
            "title": "Sparse Attention-Based Neural Networks for Code Classification",
            "updated": "2023-11-11T14:07:12Z",
            "published": "2023-11-11T14:07:12Z",
            "summary": "Categorizing source codes accurately and efficiently is a challenging problem\nin real-world programming education platform management. In recent years,\nmodel-based approaches utilizing abstract syntax trees (ASTs) have been widely\napplied to code classification tasks. We introduce an approach named the Sparse\nAttention-based neural network for Code Classification (SACC) in this paper.\nThe approach involves two main steps: In the first step, source code undergoes\nsyntax parsing and preprocessing. The generated abstract syntax tree is split\ninto sequences of subtrees and then encoded using a recursive neural network to\nobtain a high-dimensional representation. This step simultaneously considers\nboth the logical structure and lexical level information contained within the\ncode. In the second step, the encoded sequences of subtrees are fed into a\nTransformer model that incorporates sparse attention mechanisms for the purpose\nof classification. This method efficiently reduces the computational cost of\nthe self-attention mechanisms, thus improving the training speed while\npreserving effectiveness. Our work introduces a carefully designed sparse\nattention pattern that is specifically designed to meet the unique needs of\ncode classification tasks. This design helps reduce the influence of redundant\ninformation and enhances the overall performance of the model. Finally, we also\ndeal with problems in previous related research, which include issues like\nincomplete classification labels and a small dataset size. We annotated the\nCodeNet dataset with algorithm-related labeling categories, which contains a\nsignificantly large amount of data. Extensive comparative experimental results\ndemonstrate the effectiveness and efficiency of SACC for the code\nclassification tasks.",
            "author": [
                "Ziyang Xiang",
                "Zaixi Zhang",
                "Qi Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06575v1",
                "http://arxiv.org/pdf/2311.06575v1"
            ],
            "primary_category": "cs.PL",
            "category": [
                "cs.PL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06572v1",
            "title": "Swin UNETR++: Advancing Transformer-Based Dense Dose Prediction Towards\n  Fully Automated Radiation Oncology Treatments",
            "updated": "2023-11-11T13:52:59Z",
            "published": "2023-11-11T13:52:59Z",
            "summary": "The field of Radiation Oncology is uniquely positioned to benefit from the\nuse of artificial intelligence to fully automate the creation of radiation\ntreatment plans for cancer therapy. This time-consuming and specialized task\ncombines patient imaging with organ and tumor segmentation to generate a 3D\nradiation dose distribution to meet clinical treatment goals, similar to\nvoxel-level dense prediction. In this work, we propose Swin UNETR++, that\ncontains a lightweight 3D Dual Cross-Attention (DCA) module to capture the\nintra and inter-volume relationships of each patient's unique anatomy, which\nfully convolutional neural networks lack. Our model was trained, validated, and\ntested on the Open Knowledge-Based Planning dataset. In addition to metrics of\nDose Score $\\overline{S_{\\text{Dose}}}$ and DVH Score\n$\\overline{S_{\\text{DVH}}}$ that quantitatively measure the difference between\nthe predicted and ground-truth 3D radiation dose distribution, we propose the\nqualitative metrics of average volume-wise acceptance rate\n$\\overline{R_{\\text{VA}}}$ and average patient-wise clinical acceptance rate\n$\\overline{R_{\\text{PA}}}$ to assess the clinical reliability of the\npredictions. Swin UNETR++ demonstrates near-state-of-the-art performance on\nvalidation and test dataset (validation: $\\overline{S_{\\text{DVH}}}$=1.492 Gy,\n$\\overline{S_{\\text{Dose}}}$=2.649 Gy, $\\overline{R_{\\text{VA}}}$=88.58%,\n$\\overline{R_{\\text{PA}}}$=100.0%; test: $\\overline{S_{\\text{DVH}}}$=1.634 Gy,\n$\\overline{S_{\\text{Dose}}}$=2.757 Gy, $\\overline{R_{\\text{VA}}}$=90.50%,\n$\\overline{R_{\\text{PA}}}$=98.0%), establishing a basis for future studies to\ntranslate 3D dose predictions into a deliverable treatment plan, facilitating\nfull automation.",
            "author": [
                "Kuancheng Wang",
                "Hai Siong Tan",
                "Rafe Mcbeth"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06572v1",
                "http://arxiv.org/pdf/2311.06572v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06570v1",
            "title": "OR Residual Connection Achieving Comparable Accuracy to ADD Residual\n  Connection in Deep Residual Spiking Neural Networks",
            "updated": "2023-11-11T13:36:27Z",
            "published": "2023-11-11T13:36:27Z",
            "summary": "Spiking Neural Networks (SNNs) have garnered substantial attention in\nbrain-like computing for their biological fidelity and the capacity to execute\nenergy-efficient spike-driven operations. As the demand for heightened\nperformance in SNNs surges, the trend towards training deeper networks becomes\nimperative, while residual learning stands as a pivotal method for training\ndeep neural networks. In our investigation, we identified that the SEW-ResNet,\na prominent representative of deep residual spiking neural networks,\nincorporates non-event-driven operations. To rectify this, we introduce the OR\nResidual connection (ORRC) to the architecture. Additionally, we propose the\nSynergistic Attention (SynA) module, an amalgamation of the Inhibitory\nAttention (IA) module and the Multi-dimensional Attention (MA) module, to\noffset energy loss stemming from high quantization. When integrating SynA into\nthe network, we observed the phenomenon of \"natural pruning\", where after\ntraining, some or all of the shortcuts in the network naturally drop out\nwithout affecting the model's classification accuracy. This significantly\nreduces computational overhead and makes it more suitable for deployment on\nedge devices. Experimental results on various public datasets confirmed that\nthe SynA enhanced OR-Spiking ResNet achieved single-sample classification with\nas little as 0.8 spikes per neuron. Moreover, when compared to other spike\nresidual models, it exhibited higher accuracy and lower power consumption.\nCodes are available at https://github.com/Ym-Shan/ORRC-SynA-natural-pruning.",
            "author": [
                "Yimeng Shan",
                "Xuerui Qiu",
                "Rui-jie Zhu",
                "Ruike Li",
                "Meng Wang",
                "Haicheng Qu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06570v1",
                "http://arxiv.org/pdf/2311.06570v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06567v1",
            "title": "SCADI: Self-supervised Causal Disentanglement in Latent Variable Models",
            "updated": "2023-11-11T13:33:43Z",
            "published": "2023-11-11T13:33:43Z",
            "summary": "Causal disentanglement has great potential for capturing complex situations.\nHowever, there is a lack of practical and efficient approaches. It is already\nknown that most unsupervised disentangling methods are unable to produce\nidentifiable results without additional information, often leading to randomly\ndisentangled output. Therefore, most existing models for disentangling are\nweakly supervised, providing information about intrinsic factors, which incurs\nexcessive costs. Therefore, we propose a novel model, SCADI(SElf-supervised\nCAusal DIsentanglement), that enables the model to discover semantic factors\nand learn their causal relationships without any supervision. This model\ncombines a masked structural causal model (SCM) with a pseudo-label generator\nfor causal disentanglement, aiming to provide a new direction for\nself-supervised causal disentanglement models.",
            "author": [
                "Heejeong Nam"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06567v1",
                "http://arxiv.org/pdf/2311.06567v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06564v1",
            "title": "Seeing is Believing: A Federated Learning Based Prototype to Detect\n  Wireless Injection Attacks",
            "updated": "2023-11-11T13:21:24Z",
            "published": "2023-11-11T13:21:24Z",
            "summary": "Reactive injection attacks are a class of security threats in wireless\nnetworks wherein adversaries opportunistically inject spoofing packets in the\nfrequency band of a client thereby forcing the base-station to deploy\nimpersonation-detection methods. Towards circumventing such threats, we\nimplement secret-key based physical-layer signalling methods at the clients\nwhich allow the base-stations to deploy machine learning (ML) models on their\nin-phase and quadrature samples at the baseband for attack detection. Using\nAdalm Pluto based software defined radios to implement the secret-key based\nsignalling methods, we show that robust ML models can be designed at the\nbase-stations. However, we also point out that, in practice, insufficient\navailability of training datasets at the base-stations can make these methods\nineffective. Thus, we use a federated learning framework in the backhaul\nnetwork, wherein a group of base-stations that need to protect their clients\nagainst reactive injection threats collaborate to refine their ML models by\nensuring privacy on their datasets. Using a network of XBee devices to\nimplement the backhaul network, experimental results on our federated learning\nsetup shows significant enhancements in the detection accuracy, thus presenting\nwireless security as an excellent use-case for federated learning in 6G\nnetworks and beyond.",
            "author": [
                "Aadil Hussain",
                "Nitheesh Gundapu",
                "Sarang Drugkar",
                "Suraj Kiran",
                "J. Harshan",
                "Ranjitha Prasad"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06564v1",
                "http://arxiv.org/pdf/2311.06564v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "cs.CR",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07609v1",
            "title": "Artificial Intelligence in Assessing Cardiovascular Diseases and Risk\n  Factors via Retinal Fundus Images: A Review of the Last Decade",
            "updated": "2023-11-11T13:09:11Z",
            "published": "2023-11-11T13:09:11Z",
            "summary": "Background: Cardiovascular diseases (CVDs) continue to be the leading cause\nof mortality on a global scale. In recent years, the application of artificial\nintelligence (AI) techniques, particularly deep learning (DL), has gained\nconsiderable popularity for evaluating the various aspects of CVDs. Moreover,\nusing fundus images and optical coherence tomography angiography (OCTA) to\ndiagnose retinal diseases has been extensively studied. To better understand\nheart function and anticipate changes based on microvascular characteristics\nand function, researchers are currently exploring the integration of AI with\nnon-invasive retinal scanning. Leveraging AI-assisted early detection and\nprediction of cardiovascular diseases on a large scale holds excellent\npotential to mitigate cardiovascular events and alleviate the economic burden\non healthcare systems. Method: A comprehensive search was conducted across\nvarious databases, including PubMed, Medline, Google Scholar, Scopus, Web of\nSciences, IEEE Xplore, and ACM Digital Library, using specific keywords related\nto cardiovascular diseases and artificial intelligence. Results: A total of 87\nEnglish-language publications, selected for relevance were included in the\nstudy, and additional references were considered. This study presents an\noverview of the current advancements and challenges in employing retinal\nimaging and artificial intelligence to identify cardiovascular disorders and\nprovides insights for further exploration in this field. Conclusion:\nResearchers aim to develop precise disease prognosis patterns as the aging\npopulation and global CVD burden increase. AI and deep learning are\ntransforming healthcare, offering the potential for single retinal image-based\ndiagnosis of various CVDs, albeit with the need for accelerated adoption in\nhealthcare systems.",
            "author": [
                "Mirsaeed Abdollahi",
                "Ali Jafarizadeh",
                "Amirhosein Ghafouri Asbagh",
                "Navid Sobhi",
                "Keysan Pourmoghtader",
                "Siamak Pedrammehr",
                "Houshyar Asadi",
                "Roohallah Alizadehsani",
                "Ru-San Tan",
                "U. Rajendra Acharya"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07609v1",
                "http://arxiv.org/pdf/2311.07609v1"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM",
                "cs.CV",
                "eess.IV",
                "physics.med-ph",
                "J.3.2; J.3.3"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06558v1",
            "title": "Convolve and Conquer: Data Comparison with Wiener Filters",
            "updated": "2023-11-11T12:28:31Z",
            "published": "2023-11-11T12:28:31Z",
            "summary": "Quantitative evaluations of differences and/or similarities between data\nsamples define and shape optimisation problems associated with learning data\ndistributions. Current methods to compare data often suffer from limitations in\ncapturing such distributions or lack desirable mathematical properties for\noptimisation (e.g. smoothness, differentiability, or convexity). In this paper,\nwe introduce a new method to measure (dis)similarities between paired samples\ninspired by Wiener-filter theory. The convolutional nature of Wiener filters\nallows us to comprehensively compare data samples in a globally correlated way.\nWe validate our approach in four machine learning applications: data\ncompression, medical imaging imputation, translated classification, and\nnon-parametric generative modelling. Our results demonstrate increased\nresolution in reconstructed images with better perceptual quality and higher\ndata fidelity, as well as robustness against translations, compared to\nconventional mean-squared-error analogue implementations.",
            "author": [
                "Deborah Pelacani Cruz",
                "George Strong",
                "Oscar Bates",
                "Carlos Cueto",
                "Jiashun Yao",
                "Lluis Guasch"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06558v1",
                "http://arxiv.org/pdf/2311.06558v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06557v1",
            "title": "Identification of vortex in unstructured mesh with graph neural networks",
            "updated": "2023-11-11T12:10:16Z",
            "published": "2023-11-11T12:10:16Z",
            "summary": "Deep learning has been employed to identify flow characteristics from\nComputational Fluid Dynamics (CFD) databases to assist the researcher to better\nunderstand the flow field, to optimize the geometry design and to select the\ncorrect CFD configuration for corresponding flow characteristics. Convolutional\nNeural Network (CNN) is one of the most popular algorithms used to extract and\nidentify flow features. However its use, without any additional flow field\ninterpolation, is limited to the simple domain geometry and regular meshes\nwhich limits its application to real industrial cases where complex geometry\nand irregular meshes are usually used. Aiming at the aforementioned problems,\nwe present a Graph Neural Network (GNN) based model with U-Net architecture to\nidentify the vortex in CFD results on unstructured meshes. The graph generation\nand graph hierarchy construction using algebraic multigrid method from CFD\nmeshes are introduced. A vortex auto-labeling method is proposed to label\nvortex regions in 2D CFD meshes. We precise our approach by firstly optimizing\nthe input set on CNNs, then benchmarking current GNN kernels against CNN model\nand evaluating the performances of GNN kernels in terms of classification\naccuracy, training efficiency and identified vortex morphology. Finally, we\ndemonstrate the adaptability of our approach to unstructured meshes and\ngenerality to unseen cases with different turbulence models at different\nReynolds numbers.",
            "author": [
                "Lianfa Wang",
                "Yvan Fournier",
                "Jean-Francois Wald",
                "Youssef Mesri"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.compfluid.2023.106104",
                "http://arxiv.org/abs/2311.06557v1",
                "http://arxiv.org/pdf/2311.06557v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06555v1",
            "title": "Heuristics-Driven Link-of-Analogy Prompting: Enhancing Large Language\n  Models for Document-Level Event Argument Extraction",
            "updated": "2023-11-11T12:05:01Z",
            "published": "2023-11-11T12:05:01Z",
            "summary": "In this study, we investigate in-context learning (ICL) in document-level\nevent argument extraction (EAE). The paper identifies key challenges in this\nproblem, including example selection, context length limitation, abundance of\nevent types, and the limitation of Chain-of-Thought (CoT) prompting in\nnon-reasoning tasks. To address these challenges, we introduce the\nHeuristic-Driven Link-of-Analogy (HD-LoA) prompting method. Specifically, we\nhypothesize and validate that LLMs learn task-specific heuristics from\ndemonstrations via ICL. Building upon this hypothesis, we introduce an explicit\nheuristic-driven demonstration construction approach, which transforms the\nhaphazard example selection process into a methodical method that emphasizes\ntask heuristics. Additionally, inspired by the analogical reasoning of human,\nwe propose the link-of-analogy prompting, which enables LLMs to process new\nsituations by drawing analogies to known situations, enhancing their\nadaptability. Extensive experiments show that our method outperforms the\nexisting prompting methods and few-shot supervised learning methods, exhibiting\nF1 score improvements of 4.53% and 9.38% on the document-level EAE dataset.\nFurthermore, when applied to sentiment analysis and natural language inference\ntasks, the HD-LoA prompting achieves accuracy gains of 2.87% and 2.63%,\nindicating its effectiveness across different tasks.",
            "author": [
                "Hanzhang Zhou",
                "Junlang Qian",
                "Zijian Feng",
                "Hui Lu",
                "Zixiao Zhu",
                "Kezhi Mao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06555v1",
                "http://arxiv.org/pdf/2311.06555v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06554v1",
            "title": "Graph ODE with Factorized Prototypes for Modeling Complicated\n  Interacting Dynamics",
            "updated": "2023-11-11T12:04:47Z",
            "published": "2023-11-11T12:04:47Z",
            "summary": "This paper studies the problem of modeling interacting dynamical systems,\nwhich is critical for understanding physical dynamics and biological processes.\nRecent research predominantly uses geometric graphs to represent these\ninteractions, which are then captured by powerful graph neural networks (GNNs).\nHowever, predicting interacting dynamics in challenging scenarios such as\nout-of-distribution shift and complicated underlying rules remains unsolved. In\nthis paper, we propose a new approach named Graph ODE with factorized\nprototypes (GOAT) to address the problem. The core of GOAT is to incorporate\nfactorized prototypes from contextual knowledge into a continuous graph ODE\nframework. Specifically, GOAT employs representation disentanglement and system\nparameters to extract both object-level and system-level contexts from\nhistorical trajectories, which allows us to explicitly model their independent\ninfluence and thus enhances the generalization capability under system changes.\nThen, we integrate these disentangled latent representations into a graph ODE\nmodel, which determines a combination of various interacting prototypes for\nenhanced model expressivity. The entire model is optimized using an end-to-end\nvariational inference framework to maximize the likelihood. Extensive\nexperiments in both in-distribution and out-of-distribution settings validate\nthe superiority of GOAT.",
            "author": [
                "Xiao Luo",
                "Yiyang Gu",
                "Huiyu Jiang",
                "Jinsheng Huang",
                "Wei Ju",
                "Ming Zhang",
                "Yizhou Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06554v1",
                "http://arxiv.org/pdf/2311.06554v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06553v1",
            "title": "Visual Commonsense based Heterogeneous Graph Contrastive Learning",
            "updated": "2023-11-11T12:01:18Z",
            "published": "2023-11-11T12:01:18Z",
            "summary": "How to select relevant key objects and reason about the complex relationships\ncross vision and linguistic domain are two key issues in many multi-modality\napplications such as visual question answering (VQA). In this work, we\nincorporate the visual commonsense information and propose a heterogeneous\ngraph contrastive learning method to better finish the visual reasoning task.\nOur method is designed as a plug-and-play way, so that it can be quickly and\neasily combined with a wide range of representative methods. Specifically, our\nmodel contains two key components: the Commonsense-based Contrastive Learning\nand the Graph Relation Network. Using contrastive learning, we guide the model\nconcentrate more on discriminative objects and relevant visual commonsense\nattributes. Besides, thanks to the introduction of the Graph Relation Network,\nthe model reasons about the correlations between homogeneous edges and the\nsimilarities between heterogeneous edges, which makes information transmission\nmore effective. Extensive experiments on four benchmarks show that our method\ngreatly improves seven representative VQA models, demonstrating its\neffectiveness and generalizability.",
            "author": [
                "Zongzhao Li",
                "Xiangyu Zhu",
                "Xi Zhang",
                "Zhaoxiang Zhang",
                "Zhen Lei"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06553v1",
                "http://arxiv.org/pdf/2311.06553v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06552v1",
            "title": "Stain Consistency Learning: Handling Stain Variation for Automatic\n  Digital Pathology Segmentation",
            "updated": "2023-11-11T12:00:44Z",
            "published": "2023-11-11T12:00:44Z",
            "summary": "Stain variation is a unique challenge associated with automated analysis of\ndigital pathology. Numerous methods have been developed to improve the\nrobustness of machine learning methods to stain variation, but comparative\nstudies have demonstrated limited benefits to performance. Moreover, methods to\nhandle stain variation were largely developed for H&E stained data, with\nevaluation generally limited to classification tasks. Here we propose Stain\nConsistency Learning, a novel framework combining stain-specific augmentation\nwith a stain consistency loss function to learn stain colour invariant\nfeatures. We perform the first, extensive comparison of methods to handle stain\nvariation for segmentation tasks, comparing ten methods on Masson's trichrome\nand H&E stained cell and nuclei datasets, respectively. We observed that stain\nnormalisation methods resulted in equivalent or worse performance, while stain\naugmentation or stain adversarial methods demonstrated improved performance,\nwith the best performance consistently achieved by our proposed approach. The\ncode is available at: https://github.com/mlyg/stain_consistency_learning",
            "author": [
                "Michael Yeung",
                "Todd Watts",
                "Sean YW Tan",
                "Pedro F. Ferreira",
                "Andrew D. Scott",
                "Sonia Nielles-Vallespin",
                "Guang Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06552v1",
                "http://arxiv.org/pdf/2311.06552v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06549v1",
            "title": "Zero-Shot Cross-Lingual Sentiment Classification under Distribution\n  Shift: an Exploratory Study",
            "updated": "2023-11-11T11:56:56Z",
            "published": "2023-11-11T11:56:56Z",
            "summary": "The brittleness of finetuned language model performance on\nout-of-distribution (OOD) test samples in unseen domains has been well-studied\nfor English, yet is unexplored for multi-lingual models. Therefore, we study\ngeneralization to OOD test data specifically in zero-shot cross-lingual\ntransfer settings, analyzing performance impacts of both language and domain\nshifts between train and test data. We further assess the effectiveness of\ncounterfactually augmented data (CAD) in improving OOD generalization for the\ncross-lingual setting, since CAD has been shown to benefit in a monolingual\nEnglish setting. Finally, we propose two new approaches for OOD generalization\nthat avoid the costly annotation process associated with CAD, by exploiting the\npower of recent large language models (LLMs). We experiment with 3 multilingual\nmodels, LaBSE, mBERT, and XLM-R trained on English IMDb movie reviews, and\nevaluate on OOD test sets in 13 languages: Amazon product reviews, Tweets, and\nRestaurant reviews. Results echo the OOD performance decline observed in the\nmonolingual English setting. Further, (i) counterfactuals from the original\nhigh-resource language do improve OOD generalization in the low-resource\nlanguage, and (ii) our newly proposed cost-effective approaches reach similar\nor up to +3.1% better accuracy than CAD for Amazon and Restaurant reviews.",
            "author": [
                "Maarten De Raedt",
                "Semere Kiros Bitew",
                "Fr\u00e9deric Godin",
                "Thomas Demeester",
                "Chris Develder"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06549v1",
                "http://arxiv.org/pdf/2311.06549v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06547v1",
            "title": "From Charts to Atlas: Merging Latent Spaces into One",
            "updated": "2023-11-11T11:51:41Z",
            "published": "2023-11-11T11:51:41Z",
            "summary": "Models trained on semantically related datasets and tasks exhibit comparable\ninter-sample relations within their latent spaces. We investigate in this study\nthe aggregation of such latent spaces to create a unified space encompassing\nthe combined information. To this end, we introduce Relative Latent Space\nAggregation, a two-step approach that first renders the spaces comparable using\nrelative representations, and then aggregates them via a simple mean. We\ncarefully divide a classification problem into a series of learning tasks under\nthree different settings: sharing samples, classes, or neither. We then train a\nmodel on each task and aggregate the resulting latent spaces. We compare the\naggregated space with that derived from an end-to-end model trained over all\ntasks and show that the two spaces are similar. We then observe that the\naggregated space is better suited for classification, and empirically\ndemonstrate that it is due to the unique imprints left by task-specific\nembedders within the representations. We finally test our framework in\nscenarios where no shared region exists and show that it can still be used to\nmerge the spaces, albeit with diminished benefits over naive merging.",
            "author": [
                "Donato Crisostomi",
                "Irene Cannistraci",
                "Luca Moschella",
                "Pietro Barbiero",
                "Marco Ciccone",
                "Pietro Li\u00f2",
                "Emanuele Rodol\u00e0"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06547v1",
                "http://arxiv.org/pdf/2311.06547v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06545v1",
            "title": "Understanding Generalization via Set Theory",
            "updated": "2023-11-11T11:47:29Z",
            "published": "2023-11-11T11:47:29Z",
            "summary": "Generalization is at the core of machine learning models. However, the\ndefinition of generalization is not entirely clear. We employ set theory to\nintroduce the concepts of algorithms, hypotheses, and dataset generalization.\nWe analyze the properties of dataset generalization and prove a theorem on\nsurrogate generalization procedures. This theorem leads to our generalization\nmethod. Through a generalization experiment on the MNIST dataset, we obtain\n13,541 sample bases. When we use the entire training set to evaluate the\nmodel's performance, the models achieve an accuracy of 99.945%. However, if we\nshift the sample bases or modify the neural network structure, the performance\nexperiences a significant decline. We also identify consistently mispredicted\nsamples and find that they are all challenging examples. The experiments\nsubstantiated the accuracy of the generalization definition and the\neffectiveness of the proposed methods. Both the set-theoretic deduction and the\nexperiments help us better understand generalization.",
            "author": [
                "Shiqi Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06545v1",
                "http://arxiv.org/pdf/2311.06545v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06543v1",
            "title": "Bootstrapping Robotic Skill Learning With Intuitive Teleoperation:\n  Initial Feasibility Study",
            "updated": "2023-11-11T11:37:46Z",
            "published": "2023-11-11T11:37:46Z",
            "summary": "Robotic skill learning has been increasingly studied but the demonstration\ncollections are more challenging compared to collecting images/videos in\ncomputer vision and texts in natural language processing. This paper presents a\nskill learning paradigm by using intuitive teleoperation devices to generate\nhigh-quality human demonstrations efficiently for robotic skill learning in a\ndata-driven manner. By using a reliable teleoperation interface, the da Vinci\nResearch Kit (dVRK) master, a system called dVRK-Simulator-for-Demonstration\n(dS4D) is proposed in this paper. Various manipulation tasks show the system's\neffectiveness and advantages in efficiency compared to other interfaces. Using\nthe collected data for policy learning has been investigated, which verifies\nthe initial feasibility. We believe the proposed paradigm can facilitate robot\nlearning driven by high-quality demonstrations and efficiency while generating\nthem.",
            "author": [
                "Xiangyu Chu",
                "Yunxi Tang",
                "Lam Him Kwok",
                "Yuanpei Cai",
                "Kwok Wai Samuel Au"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06543v1",
                "http://arxiv.org/pdf/2311.06543v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06542v2",
            "title": "Generation Of Colors using Bidirectional Long Short Term Memory Networks",
            "updated": "2023-11-28T13:50:12Z",
            "published": "2023-11-11T11:35:37Z",
            "summary": "Human vision can distinguish between a vast spectrum of colours, estimated to\nbe between 2 to 7 million discernible shades. However, this impressive range\ndoes not inherently imply that all these colours have been precisely named and\ndescribed within our lexicon. We often associate colours with familiar objects\nand concepts in our daily lives. This research endeavors to bridge the gap\nbetween our visual perception of countless shades and our ability to articulate\nand name them accurately. A novel model has been developed to achieve this\ngoal, leveraging Bidirectional Long Short-Term Memory (BiLSTM) networks with\nActive learning. This model operates on a proprietary dataset meticulously\ncurated for this study. The primary objective of this research is to create a\nversatile tool for categorizing and naming previously unnamed colours or\nidentifying intermediate shades that elude traditional colour terminology. The\nfindings underscore the potential of this innovative approach in\nrevolutionizing our understanding of colour perception and language. Through\nrigorous experimentation and analysis, this study illuminates a promising\navenue for Natural Language Processing (NLP) applications in diverse\nindustries. By facilitating the exploration of the vast colour spectrum the\npotential applications of NLP are extended beyond conventional boundaries.",
            "author": [
                "A. Sinha"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06542v2",
                "http://arxiv.org/pdf/2311.06542v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06537v1",
            "title": "Is Machine Learning Unsafe and Irresponsible in Social Sciences?\n  Paradoxes and Reconsidering from Recidivism Prediction Tasks",
            "updated": "2023-11-11T11:17:16Z",
            "published": "2023-11-11T11:17:16Z",
            "summary": "The paper addresses some fundamental and hotly debated issues for high-stakes\nevent predictions underpinning the computational approach to social sciences.\nWe question several prevalent views against machine learning and outline a new\nparadigm that highlights the promises and promotes the infusion of\ncomputational methods and conventional social science approaches.",
            "author": [
                "Jianhong Liu",
                "Dianshi Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06537v1",
                "http://arxiv.org/pdf/2311.06537v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.AI",
                "stat.AP",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07608v1",
            "title": "MuST: Multimodal Spatiotemporal Graph-Transformer for Hospital\n  Readmission Prediction",
            "updated": "2023-11-11T11:14:07Z",
            "published": "2023-11-11T11:14:07Z",
            "summary": "Hospital readmission prediction is considered an essential approach to\ndecreasing readmission rates, which is a key factor in assessing the quality\nand efficacy of a healthcare system. Previous studies have extensively utilized\nthree primary modalities, namely electronic health records (EHR), medical\nimages, and clinical notes, to predict hospital readmissions. However, the\nmajority of these studies did not integrate information from all three\nmodalities or utilize the spatiotemporal relationships present in the dataset.\nThis study introduces a novel model called the Multimodal Spatiotemporal\nGraph-Transformer (MuST) for predicting hospital readmissions. By employing\nGraph Convolution Networks and temporal transformers, we can effectively\ncapture spatial and temporal dependencies in EHR and chest radiographs. We then\npropose a fusion transformer to combine the spatiotemporal features from the\ntwo modalities mentioned above with the features from clinical notes extracted\nby a pre-trained, domain-specific transformer. We assess the effectiveness of\nour methods using the latest publicly available dataset, MIMIC-IV. The\nexperimental results indicate that the inclusion of multimodal features in MuST\nimproves its performance in comparison to unimodal methods. Furthermore, our\nproposed pipeline outperforms the current leading methods in the prediction of\nhospital readmissions.",
            "author": [
                "Yan Miao",
                "Lequan Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07608v1",
                "http://arxiv.org/pdf/2311.07608v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07607v1",
            "title": "Modeling Choice via Self-Attention",
            "updated": "2023-11-11T11:13:07Z",
            "published": "2023-11-11T11:13:07Z",
            "summary": "Models of choice are a fundamental input to many now-canonical optimization\nproblems in the field of Operations Management, including assortment,\ninventory, and price optimization. Naturally, accurate estimation of these\nmodels from data is a critical step in the application of these optimization\nproblems in practice, and so it is perhaps surprising that such choice\nestimation has to now been accomplished almost exclusively, both in theory and\nin practice, (a) without the use of deep learning in any meaningful way, and\n(b) via evaluation on limited data with constantly-changing metrics. This is in\nstark contrast to the vast majority of similar learning applications, for which\nthe practice of machine learning suggests that (a) neural network-based models\nare typically state-of-the-art, and (b) strict standardization on evaluation\nprocedures (datasets, metrics, etc.) is crucial. Thus motivated, we first\npropose a choice model that is the first to successfully (both theoretically\nand practically) leverage a modern neural network architectural concept\n(self-attention). Theoretically, we show that our attention-based choice model\nis a low-rank generalization of the Halo Multinomial Logit model, a recent\nmodel that parsimoniously captures irrational choice effects and has seen\nempirical success. We prove that whereas the Halo-MNL requires $\\Omega(m^2)$\ndata samples to estimate, where $m$ is the number of products, our model\nsupports a natural nonconvex estimator (in particular, that which a standard\nneural network implementation would apply) which admits a near-optimal\nstationary point with $O(m)$ samples. We then establish the first\nrealistic-scale benchmark for choice estimation on real data and use this\nbenchmark to run the largest evaluation of existing choice models to date. We\nfind that the model we propose is dominant over both short-term and long-term\ndata periods.",
            "author": [
                "Joohwan Ko",
                "Andrew A. Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07607v1",
                "http://arxiv.org/pdf/2311.07607v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06527v1",
            "title": "TURBO: The Swiss Knife of Auto-Encoders",
            "updated": "2023-11-11T10:38:29Z",
            "published": "2023-11-11T10:38:29Z",
            "summary": "We present a novel information-theoretic framework, termed as TURBO, designed\nto systematically analyse and generalise auto-encoding methods. We start by\nexamining the principles of information bottleneck and bottleneck-based\nnetworks in the auto-encoding setting and identifying their inherent\nlimitations, which become more prominent for data with multiple relevant,\nphysics-related representations. The TURBO framework is then introduced,\nproviding a comprehensive derivation of its core concept consisting of the\nmaximisation of mutual information between various data representations\nexpressed in two directions reflecting the information flows. We illustrate\nthat numerous prevalent neural network models are encompassed within this\nframework. The paper underscores the insufficiency of the information\nbottleneck concept in elucidating all such models, thereby establishing TURBO\nas a preferable theoretical reference. The introduction of TURBO contributes to\na richer understanding of data representation and the structure of neural\nnetwork models, enabling more efficient and versatile applications.",
            "author": [
                "Guillaume Qu\u00e9tant",
                "Yury Belousov",
                "Vitaliy Kinakh",
                "Slava Voloshynovskiy"
            ],
            "link": [
                "http://dx.doi.org/10.3390/e25101471",
                "http://arxiv.org/abs/2311.06527v1",
                "http://arxiv.org/pdf/2311.06527v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR",
                "cs.IT",
                "hep-ph",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06522v1",
            "title": "Semantic-aware Sampling and Transmission in Energy Harvesting Systems: A\n  POMDP Approach",
            "updated": "2023-11-11T09:48:45Z",
            "published": "2023-11-11T09:48:45Z",
            "summary": "We study real-time tracking problem in an energy harvesting system with a\nMarkov source under an imperfect channel. We consider both sampling and\ntransmission costs and different from most prior studies that assume the source\nis fully observable, the sampling cost renders the source unobservable. The\ngoal is to jointly optimize sampling and transmission policies for three\nsemantic-aware metrics: i) the age of information (AoI), ii) general\ndistortion, and iii) the age of incorrect information (AoII). To this end, we\nformulate and solve a stochastic control problem. Specifically, for the AoI\nmetric, we cast a Markov decision process (MDP) problem and solve it using\nrelative value iteration (RVI). For the distortion and AoII metrics, we utilize\nthe partially observable MDP (POMDP) modeling and leverage the notion of belief\nMDP formulation of POMDP to find optimal policies. For the distortion metric\nand the AoII metric under the perfect channel setup, we effectively truncate\nthe corresponding belief space and solve an MDP problem using RVI. For the\ngeneral setup, a deep reinforcement learning policy is proposed. Through\nsimulations, we demonstrate significant performance improvements achieved by\nthe derived policies. The results reveal various switching-type structures of\noptimal policies and show that a distortion-optimal policy is also AoII\noptimal.",
            "author": [
                "Abolfazl Zakeri",
                "Mohammad Moltafet",
                "Marian Codreanu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06522v1",
                "http://arxiv.org/pdf/2311.06522v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06518v1",
            "title": "Minimum Description Length Hopfield Networks",
            "updated": "2023-11-11T09:23:54Z",
            "published": "2023-11-11T09:23:54Z",
            "summary": "Associative memory architectures are designed for memorization but also\noffer, through their retrieval method, a form of generalization to unseen\ninputs: stored memories can be seen as prototypes from this point of view.\nFocusing on Modern Hopfield Networks (MHN), we show that a large memorization\ncapacity undermines the generalization opportunity. We offer a solution to\nbetter optimize this tradeoff. It relies on Minimum Description Length (MDL) to\ndetermine during training which memories to store, as well as how many of them.",
            "author": [
                "Matan Abudy",
                "Nur Lan",
                "Emmanuel Chemla",
                "Roni Katzir"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06518v1",
                "http://arxiv.org/pdf/2311.06518v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06517v1",
            "title": "BClean: A Bayesian Data Cleaning System",
            "updated": "2023-11-11T09:22:07Z",
            "published": "2023-11-11T09:22:07Z",
            "summary": "There is a considerable body of work on data cleaning which employs various\nprinciples to rectify erroneous data and transform a dirty dataset into a\ncleaner one. One of prevalent approaches is probabilistic methods, including\nBayesian methods. However, existing probabilistic methods often assume a\nsimplistic distribution (e.g., Gaussian distribution), which is frequently\nunderfitted in practice, or they necessitate experts to provide a complex prior\ndistribution (e.g., via a programming language). This requirement is both\nlabor-intensive and costly, rendering these methods less suitable for\nreal-world applications. In this paper, we propose BClean, a Bayesian Cleaning\nsystem that features automatic Bayesian network construction and user\ninteraction. We recast the data cleaning problem as a Bayesian inference that\nfully exploits the relationships between attributes in the observed dataset and\nany prior information provided by users. To this end, we present an automatic\nBayesian network construction method that extends a structure learning-based\nfunctional dependency discovery method with similarity functions to capture the\nrelationships between attributes. Furthermore, our system allows users to\nmodify the generated Bayesian network in order to specify prior information or\ncorrect inaccuracies identified by the automatic generation process. We also\ndesign an effective scoring model (called the compensative scoring model)\nnecessary for the Bayesian inference. To enhance the efficiency of data\ncleaning, we propose several approximation strategies for the Bayesian\ninference, including graph partitioning, domain pruning, and pre-detection. By\nevaluating on both real-world and synthetic datasets, we demonstrate that\nBClean is capable of achieving an F-measure of up to 0.9 in data cleaning,\noutperforming existing Bayesian methods by 2% and other data cleaning methods\nby 15%.",
            "author": [
                "Jianbin Qin",
                "Sifan Huang",
                "Yaoshu Wang",
                "Jing Zhu",
                "Yifan Zhang",
                "Yukai Miao",
                "Rui Mao",
                "Makoto Onizuka",
                "Chuan Xiao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06517v1",
                "http://arxiv.org/pdf/2311.06517v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.DB",
                "cs.LG",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06510v1",
            "title": "Band-wise Hyperspectral Image Pansharpening using CNN Model Propagation",
            "updated": "2023-11-11T08:53:54Z",
            "published": "2023-11-11T08:53:54Z",
            "summary": "Hyperspectral pansharpening is receiving a growing interest since the last\nfew years as testified by a large number of research papers and challenges. It\nconsists in a pixel-level fusion between a lower-resolution hyperspectral\ndatacube and a higher-resolution single-band image, the panchromatic image,\nwith the goal of providing a hyperspectral datacube at panchromatic resolution.\nThanks to their powerful representational capabilities, deep learning models\nhave succeeded to provide unprecedented results on many general purpose image\nprocessing tasks. However, when moving to domain specific problems, as in this\ncase, the advantages with respect to traditional model-based approaches are\nmuch lesser clear-cut due to several contextual reasons. Scarcity of training\ndata, lack of ground-truth, data shape variability, are some such factors that\nlimit the generalization capacity of the state-of-the-art deep learning\nnetworks for hyperspectral pansharpening. To cope with these limitations, in\nthis work we propose a new deep learning method which inherits a simple\nsingle-band unsupervised pansharpening model nested in a sequential band-wise\nadaptive scheme, where each band is pansharpened refining the model tuned on\nthe preceding one. By doing so, a simple model is propagated along the\nwavelength dimension, adaptively and flexibly, with no need to have a fixed\nnumber of spectral bands, and, with no need to dispose of large, expensive and\nlabeled training datasets. The proposed method achieves very good results on\nour datasets, outperforming both traditional and deep learning reference\nmethods. The implementation of the proposed method can be found on\nhttps://github.com/giu-guarino/R-PNN",
            "author": [
                "Giuseppe Guarino",
                "Matteo Ciotola",
                "Gemine Vivone",
                "Giuseppe Scarpa"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06510v1",
                "http://arxiv.org/pdf/2311.06510v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.12869v1",
            "title": "Progression and Challenges of IoT in Healthcare: A Short Review",
            "updated": "2023-11-11T08:38:04Z",
            "published": "2023-11-11T08:38:04Z",
            "summary": "Smart healthcare, an integral element of connected living, plays a pivotal\nrole in fulfilling a fundamental human need. The burgeoning field of smart\nhealthcare is poised to generate substantial revenue in the foreseeable future.\nIts multifaceted framework encompasses vital components such as the Internet of\nThings (IoT), medical sensors, artificial intelligence (AI), edge and cloud\ncomputing, as well as next-generation wireless communication technologies. Many\nresearch papers discuss smart healthcare and healthcare more broadly. Numerous\nnations have strategically deployed the Internet of Medical Things (IoMT)\nalongside other measures to combat the propagation of COVID-19. This combined\neffort has not only enhanced the safety of frontline healthcare workers but has\nalso augmented the overall efficacy in managing the pandemic, subsequently\nreducing its impact on human lives and mortality rates. Remarkable strides have\nbeen made in both applications and technology within the IoMT domain. However,\nit is imperative to acknowledge that this technological advancement has\nintroduced certain challenges, particularly in the realm of security. The rapid\nand extensive adoption of IoMT worldwide has magnified issues related to\nsecurity and privacy. These encompass a spectrum of concerns, ranging from\nreplay attacks, man-in-the-middle attacks, impersonation, privileged insider\nthreats, remote hijacking, password guessing, and denial of service (DoS)\nattacks, to malware incursions. In this comprehensive review, we undertake a\ncomparative analysis of existing strategies designed for the detection and\nprevention of malware in IoT environments.",
            "author": [
                "S M Atikur Rahman",
                "Sifat Ibtisum",
                "Priya Podder",
                "S. M. Saokat Hossain"
            ],
            "link": [
                "http://dx.doi.org/10.5120/ijca2023923168",
                "http://arxiv.org/abs/2311.12869v1",
                "http://arxiv.org/pdf/2311.12869v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06505v1",
            "title": "CompCodeVet: A Compiler-guided Validation and Enhancement Approach for\n  Code Dataset",
            "updated": "2023-11-11T08:21:52Z",
            "published": "2023-11-11T08:21:52Z",
            "summary": "Large language models (LLMs) have become increasingly prominent in academia\nand industry due to their remarkable performance in diverse applications. As\nthese models evolve with increasing parameters, they excel in tasks like\nsentiment analysis and machine translation. However, even models with billions\nof parameters face challenges in tasks demanding multi-step reasoning. Code\ngeneration and comprehension, especially in C and C++, emerge as significant\nchallenges. While LLMs trained on code datasets demonstrate competence in many\ntasks, they struggle with rectifying non-compilable C and C++ code. Our\ninvestigation attributes this subpar performance to two primary factors: the\nquality of the training dataset and the inherent complexity of the problem\nwhich demands intricate reasoning. Existing \"Chain of Thought\" (CoT) prompting\ntechniques aim to enhance multi-step reasoning. This approach, however, retains\nthe limitations associated with the latent drawbacks of LLMs. In this work, we\npropose CompCodeVet, a compiler-guided CoT approach to produce compilable code\nfrom non-compilable ones. Diverging from the conventional approach of utilizing\nlarger LLMs, we employ compilers as a teacher to establish a more robust\nzero-shot thought process. The evaluation of CompCodeVet on two open-source\ncode datasets shows that CompCodeVet has the ability to improve the training\ndataset quality for LLMs.",
            "author": [
                "Le Chen",
                "Arijit Bhattacharjee",
                "Nesreen K. Ahmed",
                "Niranjan Hasabnis",
                "Gal Oren",
                "Bin Lei",
                "Ali Jannesari"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06505v1",
                "http://arxiv.org/pdf/2311.06505v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06504v2",
            "title": "SCL-VI: Self-supervised Context Learning for Visual Inspection of\n  Industrial Defects",
            "updated": "2023-11-21T14:57:09Z",
            "published": "2023-11-11T08:01:40Z",
            "summary": "The unsupervised visual inspection of defects in industrial products poses a\nsignificant challenge due to substantial variations in product surfaces.\nCurrent unsupervised models struggle to strike a balance between detecting\ntexture and object defects, lacking the capacity to discern latent\nrepresentations and intricate features. In this paper, we present a novel\nself-supervised learning algorithm designed to derive an optimal encoder by\ntackling the renowned jigsaw puzzle. Our approach involves dividing the target\nimage into nine patches, tasking the encoder with predicting the relative\nposition relationships between any two patches to extract rich semantics.\nSubsequently, we introduce an affinity-augmentation method to accentuate\ndifferences between normal and abnormal latent representations. Leveraging the\nclassic support vector data description algorithm yields final detection\nresults. Experimental outcomes demonstrate that our proposed method achieves\noutstanding detection and segmentation performance on the widely used MVTec AD\ndataset, with rates of 95.8% and 96.8%, respectively, establishing a\nstate-of-the-art benchmark for both texture and object defects. Comprehensive\nexperimentation underscores the effectiveness of our approach in diverse\nindustrial applications.",
            "author": [
                "Peng Wang",
                "Haiming Yao",
                "Wenyong Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06504v2",
                "http://arxiv.org/pdf/2311.06504v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06500v1",
            "title": "Knowledge Distillation and Training Balance for Heterogeneous\n  Decentralized Multi-Modal Learning over Wireless Networks",
            "updated": "2023-11-11T07:41:51Z",
            "published": "2023-11-11T07:41:51Z",
            "summary": "Decentralized learning is widely employed for collaboratively training models\nusing distributed data over wireless networks. Existing decentralized learning\nmethods primarily focus on training single-modal networks. For the\ndecentralized multi-modal learning (DMML), the modality heterogeneity and the\nnon-independent and non-identically distributed (non-IID) data across devices\nmake it difficult for the training model to capture the correlated features\nacross different modalities. Moreover, modality competition can result in\ntraining imbalance among different modalities, which can significantly impact\nthe performance of DMML. To improve the training performance in the presence of\nnon-IID data and modality heterogeneity, we propose a novel DMML with knowledge\ndistillation (DMML-KD) framework, which decomposes the extracted feature into\nthe modality-common and the modality-specific components. In the proposed\nDMML-KD, a generator is applied to learn the global conditional distribution of\nthe modality-common features, thereby guiding the modality-common features of\ndifferent devices towards the same distribution. Meanwhile, we propose to\ndecrease the number of local iterations for the modalities with fast training\nspeed in DMML-KD to address the imbalanced training. We design a balance metric\nbased on the parameter variation to evaluate the training speed of different\nmodalities in DMML-KD. Using this metric, we optimize the number of local\niterations for different modalities on each device under the constraint of\nremaining energy on devices. Experimental results demonstrate that the proposed\nDMML-KD with training balance can effectively improve the training performance\nof DMML.",
            "author": [
                "Benshun Yin",
                "Zhiyong Chen",
                "Meixia Tao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06500v1",
                "http://arxiv.org/pdf/2311.06500v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06498v1",
            "title": "Semantic Communication for Cooperative Perception based on Importance\n  Map",
            "updated": "2023-11-11T07:33:55Z",
            "published": "2023-11-11T07:33:55Z",
            "summary": "Cooperative perception, which has a broader perception field than\nsingle-vehicle perception, has played an increasingly important role in\nautonomous driving to conduct 3D object detection. Through vehicle-to-vehicle\n(V2V) communication technology, various connected automated vehicles (CAVs) can\nshare their sensory information (LiDAR point clouds) for cooperative\nperception. We employ an importance map to extract significant semantic\ninformation and propose a novel cooperative perception semantic communication\nscheme with intermediate fusion. Meanwhile, our proposed architecture can be\nextended to the challenging time-varying multipath fading channel. To alleviate\nthe distortion caused by the time-varying multipath fading, we adopt explicit\northogonal frequency-division multiplexing (OFDM) blocks combined with channel\nestimation and channel equalization. Simulation results demonstrate that our\nproposed model outperforms the traditional separate source-channel coding over\nvarious channel models. Moreover, a robustness study indicates that only part\nof semantic information is key to cooperative perception. Although our proposed\nmodel has only been trained over one specific channel, it has the ability to\nlearn robust coded representations of semantic information that remain\nresilient to various channel models, demonstrating its generality and\nrobustness.",
            "author": [
                "Yucheng Sheng",
                "Hao Ye",
                "Le Liang",
                "Shi Jin",
                "Geoffrey Ye Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06498v1",
                "http://arxiv.org/pdf/2311.06498v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06495v1",
            "title": "LayoutPrompter: Awaken the Design Ability of Large Language Models",
            "updated": "2023-11-11T07:15:14Z",
            "published": "2023-11-11T07:15:14Z",
            "summary": "Conditional graphic layout generation, which automatically maps user\nconstraints to high-quality layouts, has attracted widespread attention today.\nAlthough recent works have achieved promising performance, the lack of\nversatility and data efficiency hinders their practical applications. In this\nwork, we propose LayoutPrompter, which leverages large language models (LLMs)\nto address the above problems through in-context learning. LayoutPrompter is\nmade up of three key components, namely input-output serialization, dynamic\nexemplar selection and layout ranking. Specifically, the input-output\nserialization component meticulously designs the input and output formats for\neach layout generation task. Dynamic exemplar selection is responsible for\nselecting the most helpful prompting exemplars for a given input. And a layout\nranker is used to pick the highest quality layout from multiple outputs of\nLLMs. We conduct experiments on all existing layout generation tasks using four\npublic datasets. Despite the simplicity of our approach, experimental results\nshow that LayoutPrompter can compete with or even outperform state-of-the-art\napproaches on these tasks without any model training or fine-tuning. This\ndemonstrates the effectiveness of this versatile and training-free approach. In\naddition, the ablation studies show that LayoutPrompter is significantly\nsuperior to the training-based baseline in a low-data regime, further\nindicating the data efficiency of LayoutPrompter. Our project is available at\nhttps://github.com/microsoft/LayoutGeneration/tree/main/LayoutPrompter.",
            "author": [
                "Jiawei Lin",
                "Jiaqi Guo",
                "Shizhao Sun",
                "Zijiang James Yang",
                "Jian-Guang Lou",
                "Dongmei Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06495v1",
                "http://arxiv.org/pdf/2311.06495v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06493v1",
            "title": "L3 Ensembles: Lifelong Learning Approach for Ensemble of Foundational\n  Language Models",
            "updated": "2023-11-11T06:59:50Z",
            "published": "2023-11-11T06:59:50Z",
            "summary": "Fine-tuning pre-trained foundational language models (FLM) for specific tasks\nis often impractical, especially for resource-constrained devices. This\nnecessitates the development of a Lifelong Learning (L3) framework that\ncontinuously adapts to a stream of Natural Language Processing (NLP) tasks\nefficiently. We propose an approach that focuses on extracting meaningful\nrepresentations from unseen data, constructing a structured knowledge base, and\nimproving task performance incrementally. We conducted experiments on various\nNLP tasks to validate its effectiveness, including benchmarks like GLUE and\nSuperGLUE. We measured good performance across the accuracy, training\nefficiency, and knowledge transfer metrics. Initial experimental results show\nthat the proposed L3 ensemble method increases the model accuracy by 4% ~ 36%\ncompared to the fine-tuned FLM. Furthermore, L3 model outperforms naive\nfine-tuning approaches while maintaining competitive or superior performance\n(up to 15.4% increase in accuracy) compared to the state-of-the-art language\nmodel (T5) for the given task, STS benchmark.",
            "author": [
                "Aidin Shiri",
                "Kaushik Roy",
                "Amit Sheth",
                "Manas Gaur"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06493v1",
                "http://arxiv.org/pdf/2311.06493v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06483v2",
            "title": "Stacked networks improve physics-informed training: applications to\n  neural networks and deep operator networks",
            "updated": "2023-11-21T04:53:27Z",
            "published": "2023-11-11T05:43:54Z",
            "summary": "Physics-informed neural networks and operator networks have shown promise for\neffectively solving equations modeling physical systems. However, these\nnetworks can be difficult or impossible to train accurately for some systems of\nequations. We present a novel multifidelity framework for stacking\nphysics-informed neural networks and operator networks that facilitates\ntraining. We successively build a chain of networks, where the output at one\nstep can act as a low-fidelity input for training the next step, gradually\nincreasing the expressivity of the learned model. The equations imposed at each\nstep of the iterative process can be the same or different (akin to simulated\nannealing). The iterative (stacking) nature of the proposed method allows us to\nprogressively learn features of a solution that are hard to learn directly.\nThrough benchmark problems including a nonlinear pendulum, the wave equation,\nand the viscous Burgers equation, we show how stacking can be used to improve\nthe accuracy and reduce the required size of physics-informed neural networks\nand operator networks.",
            "author": [
                "Amanda A Howard",
                "Sarah H Murphy",
                "Shady E Ahmed",
                "Panos Stinis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06483v2",
                "http://arxiv.org/pdf/2311.06483v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NA",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07604v1",
            "title": "Finetuning Text-to-Image Diffusion Models for Fairness",
            "updated": "2023-11-11T05:40:54Z",
            "published": "2023-11-11T05:40:54Z",
            "summary": "The rapid adoption of text-to-image diffusion models in society underscores\nan urgent need to address their biases. Without interventions, these biases\ncould propagate a distorted worldview and limit opportunities for minority\ngroups. In this work, we frame fairness as a distributional alignment problem.\nOur solution consists of two main technical contributions: (1) a distributional\nalignment loss that steers specific characteristics of the generated images\ntowards a user-defined target distribution, and (2) biased direct finetuning of\ndiffusion model's sampling process, which leverages a biased gradient to more\neffectively optimize losses defined on the generated images. Empirically, our\nmethod markedly reduces gender, racial, and their intersectional biases for\noccupational prompts. Gender bias is significantly reduced even when finetuning\njust five soft tokens. Crucially, our method supports diverse perspectives of\nfairness beyond absolute equality, which is demonstrated by controlling age to\na $75\\%$ young and $25\\%$ old distribution while simultaneously debiasing\ngender and race. Finally, our method is scalable: it can debias multiple\nconcepts at once by simply including these prompts in the finetuning data. We\nhope our work facilitates the social alignment of T2I generative AI. We will\nshare code and various debiased diffusion model adaptors.",
            "author": [
                "Xudong Shen",
                "Chao Du",
                "Tianyu Pang",
                "Min Lin",
                "Yongkang Wong",
                "Mohan Kankanhalli"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07604v1",
                "http://arxiv.org/pdf/2311.07604v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06481v1",
            "title": "Topology-Matching Normalizing Flows for Out-of-Distribution Detection in\n  Robot Learning",
            "updated": "2023-11-11T05:09:31Z",
            "published": "2023-11-11T05:09:31Z",
            "summary": "To facilitate reliable deployments of autonomous robots in the real world,\nOut-of-Distribution (OOD) detection capabilities are often required. A powerful\napproach for OOD detection is based on density estimation with Normalizing\nFlows (NFs). However, we find that prior work with NFs attempts to match the\ncomplex target distribution topologically with naive base distributions leading\nto adverse implications. In this work, we circumvent this topological mismatch\nusing an expressive class-conditional base distribution trained with an\ninformation-theoretic objective to match the required topology. The proposed\nmethod enjoys the merits of wide compatibility with existing learned models\nwithout any performance degradation and minimum computation overhead while\nenhancing OOD detection capabilities. We demonstrate superior results in\ndensity estimation and 2D object detection benchmarks in comparison with\nextensive baselines. Moreover, we showcase the applicability of the method with\na real-robot deployment.",
            "author": [
                "Jianxiang Feng",
                "Jongseok Lee",
                "Simon Geisler",
                "Stephan Gunnemann",
                "Rudolph Triebel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06481v1",
                "http://arxiv.org/pdf/2311.06481v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06480v1",
            "title": "Adversarial Fine-tuning using Generated Respiratory Sound to Address\n  Class Imbalance",
            "updated": "2023-11-11T05:02:54Z",
            "published": "2023-11-11T05:02:54Z",
            "summary": "Deep generative models have emerged as a promising approach in the medical\nimage domain to address data scarcity. However, their use for sequential data\nlike respiratory sounds is less explored. In this work, we propose a\nstraightforward approach to augment imbalanced respiratory sound data using an\naudio diffusion model as a conditional neural vocoder. We also demonstrate a\nsimple yet effective adversarial fine-tuning method to align features between\nthe synthetic and real respiratory sound samples to improve respiratory sound\nclassification performance. Our experimental results on the ICBHI dataset\ndemonstrate that the proposed adversarial fine-tuning is effective, while only\nusing the conventional augmentation method shows performance degradation.\nMoreover, our method outperforms the baseline by 2.24% on the ICBHI Score and\nimproves the accuracy of the minority classes up to 26.58%. For the\nsupplementary material, we provide the code at\nhttps://github.com/kaen2891/adversarial_fine-tuning_using_generated_respiratory_sound.",
            "author": [
                "June-Woo Kim",
                "Chihyeon Yoon",
                "Miika Toikkanen",
                "Sangmin Bae",
                "Ho-Young Jung"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06480v1",
                "http://arxiv.org/pdf/2311.06480v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.LG",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06477v3",
            "title": "Report of the 1st Workshop on Generative AI and Law",
            "updated": "2023-12-03T03:09:16Z",
            "published": "2023-11-11T04:13:37Z",
            "summary": "This report presents the takeaways of the inaugural Workshop on Generative AI\nand Law (GenLaw), held in July 2023. A cross-disciplinary group of\npractitioners and scholars from computer science and law convened to discuss\nthe technical, doctrinal, and policy challenges presented by law for Generative\nAI, and by Generative AI for law, with an emphasis on U.S. law in particular.\nWe begin the report with a high-level statement about why Generative AI is both\nimmensely significant and immensely challenging for law. To meet these\nchallenges, we conclude that there is an essential need for 1) a shared\nknowledge base that provides a common conceptual language for experts across\ndisciplines; 2) clarification of the distinctive technical capabilities of\ngenerative-AI systems, as compared and contrasted to other computer and AI\nsystems; 3) a logical taxonomy of the legal issues these systems raise; and, 4)\na concrete research agenda to promote collaboration and knowledge-sharing on\nemerging issues at the intersection of Generative AI and law. In this report,\nwe synthesize the key takeaways from the GenLaw workshop that begin to address\nthese needs. All of the listed authors contributed to the workshop upon which\nthis report is based, but they and their organizations do not necessarily\nendorse all of the specific claims in this report.",
            "author": [
                "A. Feder Cooper",
                "Katherine Lee",
                "James Grimmelmann",
                "Daphne Ippolito",
                "Christopher Callison-Burch",
                "Christopher A. Choquette-Choo",
                "Niloofar Mireshghallah",
                "Miles Brundage",
                "David Mimno",
                "Madiha Zahrah Choksi",
                "Jack M. Balkin",
                "Nicholas Carlini",
                "Christopher De Sa",
                "Jonathan Frankle",
                "Deep Ganguli",
                "Bryant Gipson",
                "Andres Guadamuz",
                "Swee Leng Harris",
                "Abigail Z. Jacobs",
                "Elizabeth Joh",
                "Gautam Kamath",
                "Mark Lemley",
                "Cass Matthews",
                "Christine McLeavey",
                "Corynne McSherry",
                "Milad Nasr",
                "Paul Ohm",
                "Adam Roberts",
                "Tom Rubin",
                "Pamela Samuelson",
                "Ludwig Schubert",
                "Kristen Vaccaro",
                "Luis Villa",
                "Felix Wu",
                "Elana Zeide"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06477v3",
                "http://arxiv.org/pdf/2311.06477v3"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06467v1",
            "title": "Adaptive Language-based Mental Health Assessment with Item-Response\n  Theory",
            "updated": "2023-11-11T03:37:17Z",
            "published": "2023-11-11T03:37:17Z",
            "summary": "Mental health issues widely vary across individuals - the manifestations of\nsigns and symptoms can be fairly heterogeneous. Recently, language-based\ndepression and anxiety assessments have shown promise for capturing this\nheterogeneous nature by evaluating a patient's own language, but such\napproaches require a large sample of words per person to be accurate. In this\nwork, we introduce adaptive language-based assessment - the task of iteratively\nestimating an individual's psychological score based on limited language\nresponses to questions that the model also decides to ask. To this end, we\nexplore two statistical learning-based approaches for measurement/scoring:\nclassical test theory (CTT) and item response theory (IRT). We find that using\nadaptive testing in general can significantly reduce the number of questions\nrequired to achieve high validity (r ~ 0.7) with standardized tests, bringing\ndown from 11 total questions down to 3 for depression and 5 for anxiety. Given\nthe combinatorial nature of the problem, we empirically evaluate multiple\nstrategies for both the ordering and scoring objectives, introducing two new\nmethods: a semi-supervised item response theory based method (ALIRT), and a\nsupervised actor-critic based model. While both of the models achieve\nsignificant improvements over random and fixed orderings, we find ALIRT to be a\nscalable model that achieves the highest accuracy with lower numbers of\nquestions (e.g. achieves Pearson r ~ 0.93 after only 3 questions versus asking\nall 11 questions). Overall, ALIRT allows prompting a reduced number of\nquestions without compromising accuracy or overhead computational costs.",
            "author": [
                "Vasudha Varadarajan",
                "Sverker Sikstr\u00f6m",
                "Oscar N. E. Kjell",
                "H. Andrew Schwartz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06467v1",
                "http://arxiv.org/pdf/2311.06467v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06460v1",
            "title": "Online Continual Learning via Logit Adjusted Softmax",
            "updated": "2023-11-11T03:03:33Z",
            "published": "2023-11-11T03:03:33Z",
            "summary": "Online continual learning is a challenging problem where models must learn\nfrom a non-stationary data stream while avoiding catastrophic forgetting.\nInter-class imbalance during training has been identified as a major cause of\nforgetting, leading to model prediction bias towards recently learned classes.\nIn this paper, we theoretically analyze that inter-class imbalance is entirely\nattributed to imbalanced class-priors, and the function learned from\nintra-class intrinsic distributions is the Bayes-optimal classifier. To that\nend, we present that a simple adjustment of model logits during training can\neffectively resist prior class bias and pursue the corresponding Bayes-optimum.\nOur proposed method, Logit Adjusted Softmax, can mitigate the impact of\ninter-class imbalance not only in class-incremental but also in realistic\ngeneral setups, with little additional computational cost. We evaluate our\napproach on various benchmarks and demonstrate significant performance\nimprovements compared to prior arts. For example, our approach improves the\nbest baseline by 4.6% on CIFAR10.",
            "author": [
                "Zhehao Huang",
                "Tao Li",
                "Chenhe Yuan",
                "Yingwen Wu",
                "Xiaolin Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06460v1",
                "http://arxiv.org/pdf/2311.06460v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07603v1",
            "title": "PECoP: Parameter Efficient Continual Pretraining for Action Quality\n  Assessment",
            "updated": "2023-11-11T02:36:38Z",
            "published": "2023-11-11T02:36:38Z",
            "summary": "The limited availability of labelled data in Action Quality Assessment (AQA),\nhas forced previous works to fine-tune their models pretrained on large-scale\ndomain-general datasets. This common approach results in weak generalisation,\nparticularly when there is a significant domain shift. We propose a novel,\nparameter efficient, continual pretraining framework, PECoP, to reduce such\ndomain shift via an additional pretraining stage. In PECoP, we introduce\n3D-Adapters, inserted into the pretrained model, to learn spatiotemporal,\nin-domain information via self-supervised learning where only the adapter\nmodules' parameters are updated. We demonstrate PECoP's ability to enhance the\nperformance of recent state-of-the-art methods (MUSDL, CoRe, and TSA) applied\nto AQA, leading to considerable improvements on benchmark datasets, JIGSAWS\n($\\uparrow6.0\\%$), MTL-AQA ($\\uparrow0.99\\%$), and FineDiving\n($\\uparrow2.54\\%$). We also present a new Parkinson's Disease dataset, PD4T, of\nreal patients performing four various actions, where we surpass\n($\\uparrow3.56\\%$) the state-of-the-art in comparison. Our code, pretrained\nmodels, and the PD4T dataset are available at https://github.com/Plrbear/PECoP.",
            "author": [
                "Amirhossein Dadashzadeh",
                "Shuchao Duan",
                "Alan Whone",
                "Majid Mirmehdi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07603v1",
                "http://arxiv.org/pdf/2311.07603v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06456v2",
            "title": "Asymmetric Contrastive Multimodal Learning for Advancing Chemical\n  Understanding",
            "updated": "2023-11-20T21:40:55Z",
            "published": "2023-11-11T01:58:45Z",
            "summary": "The versatility of multimodal deep learning holds tremendous promise for\nadvancing scientific research and practical applications. As this field\ncontinues to evolve, the collective power of cross-modal analysis promises to\ndrive transformative innovations, leading us to new frontiers in chemical\nunderstanding and discovery. Hence, we introduce Asymmetric Contrastive\nMultimodal Learning (ACML) as a novel approach tailored for molecules,\nshowcasing its potential to advance the field of chemistry. ACML harnesses the\npower of effective asymmetric contrastive learning to seamlessly transfer\ninformation from various chemical modalities to molecular graph\nrepresentations. By combining pre-trained chemical unimodal encoders and a\nshallow-designed graph encoder, ACML facilitates the assimilation of\ncoordinated chemical semantics from different modalities, leading to\ncomprehensive representation learning with efficient training. This innovative\nframework enhances the interpretability of learned representations and bolsters\nthe expressive power of graph neural networks. Through practical tasks such as\nisomer discrimination and uncovering crucial chemical properties for drug\ndiscovery, ACML exhibits its capability to revolutionize chemical research and\napplications, providing a deeper understanding of chemical semantics of\ndifferent modalities.",
            "author": [
                "Hao Xu",
                "Yifei Wang",
                "Yunrui Li",
                "Pengyu Hong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06456v2",
                "http://arxiv.org/pdf/2311.06456v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06454v1",
            "title": "A Saliency-based Clustering Framework for Identifying Aberrant\n  Predictions",
            "updated": "2023-11-11T01:53:59Z",
            "published": "2023-11-11T01:53:59Z",
            "summary": "In machine learning, classification tasks serve as the cornerstone of a wide\nrange of real-world applications. Reliable, trustworthy classification is\nparticularly intricate in biomedical settings, where the ground truth is often\ninherently uncertain and relies on high degrees of human expertise for\nlabeling. Traditional metrics such as precision and recall, while valuable, are\ninsufficient for capturing the nuances of these ambiguous scenarios. Here we\nintroduce the concept of aberrant predictions, emphasizing that the nature of\nclassification errors is as critical as their frequency. We propose a novel,\nefficient training methodology aimed at both reducing the misclassification\nrate and discerning aberrant predictions. Our framework demonstrates a\nsubstantial improvement in model performance, achieving a 20\\% increase in\nprecision. We apply this methodology to the less-explored domain of veterinary\nradiology, where the stakes are high but have not been as extensively studied\ncompared to human medicine. By focusing on the identification and mitigation of\naberrant predictions, we enhance the utility and trustworthiness of machine\nlearning classifiers in high-stakes, real-world scenarios, including new\napplications in the veterinary world.",
            "author": [
                "Aina Tersol Montserrat",
                "Alexander R. Loftus",
                "Yael Daihes"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06454v1",
                "http://arxiv.org/pdf/2311.06454v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06444v2",
            "title": "Mitigating Pooling Bias in E-commerce Search via False Negative\n  Estimation",
            "updated": "2023-11-18T19:09:35Z",
            "published": "2023-11-11T00:22:57Z",
            "summary": "Efficient and accurate product relevance assessment is critical for user\nexperiences and business success. Training a proficient relevance assessment\nmodel requires high-quality query-product pairs, often obtained through\nnegative sampling strategies. Unfortunately, current methods introduce pooling\nbias by mistakenly sampling false negatives, diminishing performance and\nbusiness impact. To address this, we present Bias-mitigating Hard Negative\nSampling (BHNS), a novel negative sampling strategy tailored to identify and\nadjust for false negatives, building upon our original False Negative\nEstimation algorithm. Our experiments in the Instacart search setting confirm\nBHNS as effective for practical e-commerce use. Furthermore, comparative\nanalyses on public dataset showcase its domain-agnostic potential for diverse\napplications.",
            "author": [
                "Xiaochen Wang",
                "Xiao Xiao",
                "Ruhan Zhang",
                "Xuan Zhang",
                "Taesik Na",
                "Tejaswi Tenneti",
                "Haixun Wang",
                "Fenglong Ma"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06444v2",
                "http://arxiv.org/pdf/2311.06444v2"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06443v1",
            "title": "CVTHead: One-shot Controllable Head Avatar with Vertex-feature\n  Transformer",
            "updated": "2023-11-11T00:19:47Z",
            "published": "2023-11-11T00:19:47Z",
            "summary": "Reconstructing personalized animatable head avatars has significant\nimplications in the fields of AR/VR. Existing methods for achieving explicit\nface control of 3D Morphable Models (3DMM) typically rely on multi-view images\nor videos of a single subject, making the reconstruction process complex.\nAdditionally, the traditional rendering pipeline is time-consuming, limiting\nreal-time animation possibilities. In this paper, we introduce CVTHead, a novel\napproach that generates controllable neural head avatars from a single\nreference image using point-based neural rendering. CVTHead considers the\nsparse vertices of mesh as the point set and employs the proposed\nVertex-feature Transformer to learn local feature descriptors for each vertex.\nThis enables the modeling of long-range dependencies among all the vertices.\nExperimental results on the VoxCeleb dataset demonstrate that CVTHead achieves\ncomparable performance to state-of-the-art graphics-based methods. Moreover, it\nenables efficient rendering of novel human heads with various expressions, head\nposes, and camera views. These attributes can be explicitly controlled using\nthe coefficients of 3DMMs, facilitating versatile and realistic animation in\nreal-time scenarios.",
            "author": [
                "Haoyu Ma",
                "Tong Zhang",
                "Shanlin Sun",
                "Xiangyi Yan",
                "Kun Han",
                "Xiaohui Xie"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06443v1",
                "http://arxiv.org/pdf/2311.06443v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06440v1",
            "title": "Separating the Wheat from the Chaff with BREAD: An open-source benchmark\n  and metrics to detect redundancy in text",
            "updated": "2023-11-11T00:11:50Z",
            "published": "2023-11-11T00:11:50Z",
            "summary": "Data quality is a problem that perpetually resurfaces throughout the field of\nNLP, regardless of task, domain, or architecture, and remains especially severe\nfor lower-resource languages. A typical and insidious issue, affecting both\ntraining data and model output, is data that is repetitive and dominated by\nlinguistically uninteresting boilerplate, such as price catalogs or\ncomputer-generated log files. Though this problem permeates many web-scraped\ncorpora, there has yet to be a benchmark to test against, or a systematic study\nto find simple metrics that generalize across languages and agree with human\njudgements of data quality. In the present work, we create and release BREAD, a\nhuman-labeled benchmark on repetitive boilerplate vs. plausible linguistic\ncontent, spanning 360 languages. We release several baseline CRED (Character\nREDundancy) scores along with it, and evaluate their effectiveness on BREAD. We\nhope that the community will use this resource to develop better filtering\nmethods, and that our reference implementations of CRED scores can become\nstandard corpus evaluation tools, driving the development of cleaner language\nmodeling corpora, especially in low-resource languages.",
            "author": [
                "Isaac Caswell",
                "Lisa Wang",
                "Isabel Papadimitriou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06440v1",
                "http://arxiv.org/pdf/2311.06440v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06438v1",
            "title": "Controllability-Constrained Deep Network Models for Enhanced Control of\n  Dynamical Systems",
            "updated": "2023-11-11T00:04:26Z",
            "published": "2023-11-11T00:04:26Z",
            "summary": "Control of a dynamical system without the knowledge of dynamics is an\nimportant and challenging task. Modern machine learning approaches, such as\ndeep neural networks (DNNs), allow for the estimation of a dynamics model from\ncontrol inputs and corresponding state observation outputs. Such data-driven\nmodels are often utilized for the derivation of model-based controllers.\nHowever, in general, there are no guarantees that a model represented by DNNs\nwill be controllable according to the formal control-theoretical meaning of\ncontrollability, which is crucial for the design of effective controllers. This\noften precludes the use of DNN-estimated models in applications, where formal\ncontrollability guarantees are required. In this proof-of-the-concept work, we\npropose a control-theoretical method that explicitly enhances models estimated\nfrom data with controllability. That is achieved by augmenting the model\nestimation objective with a controllability constraint, which penalizes models\nwith a low degree of controllability. As a result, the models estimated with\nthe proposed controllability constraint allow for the derivation of more\nefficient controllers, they are interpretable by the control-theoretical\nquantities and have a lower long-term prediction error. The proposed method\nprovides new insights on the connection between the DNN-based estimation of\nunknown dynamics and the control-theoretical guarantees of the solution\nproperties. We demonstrate the superiority of the proposed method in two\nstandard classical control systems with state observation given by low\nresolution high-dimensional images.",
            "author": [
                "Suruchi Sharma",
                "Volodymyr Makarenko",
                "Gautam Kumar",
                "Stas Tiomkin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06438v1",
                "http://arxiv.org/pdf/2311.06438v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.AI",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08422v1",
            "title": "k-Parameter Approach for False In-Season Anomaly Suppression in Daily\n  Time Series Anomaly Detection",
            "updated": "2023-11-10T23:29:32Z",
            "published": "2023-11-10T23:29:32Z",
            "summary": "Detecting anomalies in a daily time series with a weekly pattern is a common\ntask with a wide range of applications. A typical way of performing the task is\nby using decomposition method. However, the method often generates false\npositive results where a data point falls within its weekly range but is just\noff from its weekday position. We refer to this type of anomalies as \"in-season\nanomalies\", and propose a k-parameter approach to address the issue. The\napproach provides configurable extra tolerance for in-season anomalies to\nsuppress misleading alerts while preserving real positives. It yields favorable\nresult.",
            "author": [
                "Vincent Yuansang Zha",
                "Vaishnavi Kommaraju",
                "Okenna Obi-Njoku",
                "Vijay Dakshinamoorthy",
                "Anirudh Agnihotri",
                "Nantes Kirsten"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08422v1",
                "http://arxiv.org/pdf/2311.08422v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06428v2",
            "title": "A Trichotomy for Transductive Online Learning",
            "updated": "2023-11-29T23:37:43Z",
            "published": "2023-11-10T23:27:23Z",
            "summary": "We present new upper and lower bounds on the number of learner mistakes in\nthe `transductive' online learning setting of Ben-David, Kushilevitz and\nMansour (1997). This setting is similar to standard online learning, except\nthat the adversary fixes a sequence of instances $x_1,\\dots,x_n$ to be labeled\nat the start of the game, and this sequence is known to the learner.\nQualitatively, we prove a trichotomy, stating that the minimal number of\nmistakes made by the learner as $n$ grows can take only one of precisely three\npossible values: $n$, $\\Theta\\left(\\log (n)\\right)$, or $\\Theta(1)$.\nFurthermore, this behavior is determined by a combination of the VC dimension\nand the Littlestone dimension. Quantitatively, we show a variety of bounds\nrelating the number of mistakes to well-known combinatorial dimensions. In\nparticular, we improve the known lower bound on the constant in the $\\Theta(1)$\ncase from $\\Omega\\left(\\sqrt{\\log(d)}\\right)$ to $\\Omega(\\log(d))$ where $d$ is\nthe Littlestone dimension. Finally, we extend our results to cover multiclass\nclassification and the agnostic setting.",
            "author": [
                "Steve Hanneke",
                "Shay Moran",
                "Jonathan Shafer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06428v2",
                "http://arxiv.org/pdf/2311.06428v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06427v1",
            "title": "ChatGPT Prompting Cannot Estimate Predictive Uncertainty in\n  High-Resource Languages",
            "updated": "2023-11-10T23:25:34Z",
            "published": "2023-11-10T23:25:34Z",
            "summary": "ChatGPT took the world by storm for its impressive abilities. Due to its\nrelease without documentation, scientists immediately attempted to identify its\nlimits, mainly through its performance in natural language processing (NLP)\ntasks. This paper aims to join the growing literature regarding ChatGPT's\nabilities by focusing on its performance in high-resource languages and on its\ncapacity to predict its answers' accuracy by giving a confidence level. The\nanalysis of high-resource languages is of interest as studies have shown that\nlow-resource languages perform worse than English in NLP tasks, but no study so\nfar has analysed whether high-resource languages perform as well as English.\nThe analysis of ChatGPT's confidence calibration has not been carried out\nbefore either and is critical to learn about ChatGPT's trustworthiness. In\norder to study these two aspects, five high-resource languages and two NLP\ntasks were chosen. ChatGPT was asked to perform both tasks in the five\nlanguages and to give a numerical confidence value for each answer. The results\nshow that all the selected high-resource languages perform similarly and that\nChatGPT does not have a good confidence calibration, often being overconfident\nand never giving low confidence values.",
            "author": [
                "Martino Pelucchi",
                "Matias Valdenegro-Toro"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06427v1",
                "http://arxiv.org/pdf/2311.06427v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06423v1",
            "title": "Flatness-aware Adversarial Attack",
            "updated": "2023-11-10T23:10:21Z",
            "published": "2023-11-10T23:10:21Z",
            "summary": "The transferability of adversarial examples can be exploited to launch\nblack-box attacks. However, adversarial examples often present poor\ntransferability. To alleviate this issue, by observing that the diversity of\ninputs can boost transferability, input regularization based methods are\nproposed, which craft adversarial examples by combining several transformed\ninputs. We reveal that input regularization based methods make resultant\nadversarial examples biased towards flat extreme regions. Inspired by this, we\npropose an attack called flatness-aware adversarial attack (FAA) which\nexplicitly adds a flatness-aware regularization term in the optimization target\nto promote the resultant adversarial examples towards flat extreme regions. The\nflatness-aware regularization term involves gradients of samples around the\nresultant adversarial examples but optimizing gradients requires the evaluation\nof Hessian matrix in high-dimension spaces which generally is intractable. To\naddress the problem, we derive an approximate solution to circumvent the\nconstruction of Hessian matrix, thereby making FAA practical and cheap.\nExtensive experiments show the transferability of adversarial examples crafted\nby FAA can be considerably boosted compared with state-of-the-art baselines.",
            "author": [
                "Mingyuan Fan",
                "Xiaodan Li",
                "Cen Chen",
                "Yinggui Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06423v1",
                "http://arxiv.org/pdf/2311.06423v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06422v1",
            "title": "Statistical disclosure control for numeric microdata via sequential\n  joint probability preserving data shuffling",
            "updated": "2023-11-10T23:03:55Z",
            "published": "2023-11-10T23:03:55Z",
            "summary": "Traditional perturbative statistical disclosure control (SDC) approaches such\nas microaggregation, noise addition, rank swapping, etc, perturb the data in an\n``ad-hoc\" way in the sense that while they manage to preserve some particular\naspects of the data, they end up modifying others. Synthetic data approaches\nbased on the fully conditional specification data synthesis paradigm, on the\nother hand, aim to generate new datasets that follow the same joint probability\ndistribution as the original data. These synthetic data approaches, however,\nrely either on parametric statistical models, or non-parametric machine\nlearning models, which need to fit well the original data in order to generate\ncredible and useful synthetic data. Another important drawback is that they\ntend to perform better when the variables are synthesized in the correct causal\norder (i.e., in the same order as the true data generating process), which is\noften unknown in practice. To circumvent these issues, we propose a fully\nnon-parametric and model free perturbative SDC approach that approximates the\njoint distribution of the original data via sequential applications of\nrestricted permutations to the numerical microdata (where the restricted\npermutations are guided by the joint distribution of a discretized version of\nthe data). Empirical comparisons against popular SDC approaches, using both\nreal and simulated datasets, suggest that the proposed approach is competitive\nin terms of the trade-off between confidentiality and data utility.",
            "author": [
                "Elias Chaibub Neto"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06422v1",
                "http://arxiv.org/pdf/2311.06422v1"
            ],
            "primary_category": "stat.AP",
            "category": [
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06417v1",
            "title": "Resolving uncertainty on the fly: Modeling adaptive driving behavior as\n  active inference",
            "updated": "2023-11-10T22:40:41Z",
            "published": "2023-11-10T22:40:41Z",
            "summary": "Understanding adaptive human driving behavior, in particular how drivers\nmanage uncertainty, is of key importance for developing simulated human driver\nmodels that can be used in the evaluation and development of autonomous\nvehicles. However, existing traffic psychology models of adaptive driving\nbehavior either lack computational rigor or only address specific scenarios\nand/or behavioral phenomena. While models developed in the fields of machine\nlearning and robotics can effectively learn adaptive driving behavior from\ndata, due to their black box nature, they offer little or no explanation of the\nmechanisms underlying the adaptive behavior. Thus, a generalizable,\ninterpretable, computational model of adaptive human driving behavior is still\nlacking. This paper proposes such a model based on active inference, a\nbehavioral modeling framework originating in computational neuroscience. The\nmodel offers a principled solution to how humans trade progress against caution\nthrough policy selection based on the single mandate to minimize expected free\nenergy. This casts goal-seeking and information-seeking (uncertainty-resolving)\nbehavior under a single objective function, allowing the model to seamlessly\nresolve uncertainty as a means to obtain its goals. We apply the model in two\napparently disparate driving scenarios that require managing uncertainty, (1)\ndriving past an occluding object and (2) visual time sharing between driving\nand a secondary task, and show how human-like adaptive driving behavior emerges\nfrom the single principle of expected free energy minimization.",
            "author": [
                "Johan Engstr\u00f6m",
                "Ran Wei",
                "Anthony McDonald",
                "Alfredo Garcia",
                "Matt O'Kelly",
                "Leif Johnson"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06417v1",
                "http://arxiv.org/pdf/2311.06417v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06414v1",
            "title": "Knowledge Graphs are not Created Equal: Exploring the Properties and\n  Structure of Real KGs",
            "updated": "2023-11-10T22:18:09Z",
            "published": "2023-11-10T22:18:09Z",
            "summary": "Despite the recent popularity of knowledge graph (KG) related tasks and\nbenchmarks such as KG embeddings, link prediction, entity alignment and\nevaluation of the reasoning abilities of pretrained language models as KGs, the\nstructure and properties of real KGs are not well studied. In this paper, we\nperform a large scale comparative study of 29 real KG datasets from diverse\ndomains such as the natural sciences, medicine, and NLP to analyze their\nproperties and structural patterns. Based on our findings, we make several\nrecommendations regarding KG-based model development and evaluation. We believe\nthat the rich structural information contained in KGs can benefit the\ndevelopment of better KG models across fields and we hope this study will\ncontribute to breaking the existing data silos between different areas of\nresearch (e.g., ML, NLP, AI for sciences).",
            "author": [
                "Nedelina Teneva",
                "Estevam Hruschka"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06414v1",
                "http://arxiv.org/pdf/2311.06414v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06413v1",
            "title": "Forte: An Interactive Visual Analytic Tool for Trust-Augmented Net Load\n  Forecasting",
            "updated": "2023-11-10T22:15:11Z",
            "published": "2023-11-10T22:15:11Z",
            "summary": "Accurate net load forecasting is vital for energy planning, aiding decisions\non trade and load distribution. However, assessing the performance of\nforecasting models across diverse input variables, like temperature and\nhumidity, remains challenging, particularly for eliciting a high degree of\ntrust in the model outcomes. In this context, there is a growing need for\ndata-driven technological interventions to aid scientists in comprehending how\nmodels react to both noisy and clean input variables, thus shedding light on\ncomplex behaviors and fostering confidence in the outcomes. In this paper, we\npresent Forte, a visual analytics-based application to explore deep\nprobabilistic net load forecasting models across various input variables and\nunderstand the error rates for different scenarios. With carefully designed\nvisual interventions, this web-based interface empowers scientists to derive\ninsights about model performance by simulating diverse scenarios, facilitating\nan informed decision-making process. We discuss observations made using Forte\nand demonstrate the effectiveness of visualization techniques to provide\nvaluable insights into the correlation between weather inputs and net load\nforecasts, ultimately advancing grid capabilities by improving trust in\nforecasting models.",
            "author": [
                "Kaustav Bhattacharjee",
                "Soumya Kundu",
                "Indrasis Chakraborty",
                "Aritra Dasgupta"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06413v1",
                "http://arxiv.org/pdf/2311.06413v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.AI",
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06412v1",
            "title": "Online multiple testing with e-values",
            "updated": "2023-11-10T22:14:47Z",
            "published": "2023-11-10T22:14:47Z",
            "summary": "A scientist tests a continuous stream of hypotheses over time in the course\nof her investigation -- she does not test a predetermined, fixed number of\nhypotheses. The scientist wishes to make as many discoveries as possible while\nensuring the number of false discoveries is controlled -- a well recognized way\nfor accomplishing this is to control the false discovery rate (FDR). Prior\nmethods for FDR control in the online setting have focused on formulating\nalgorithms when specific dependency structures are assumed to exist between the\ntest statistics of each hypothesis. However, in practice, these dependencies\noften cannot be known beforehand or tested after the fact. Our algorithm,\ne-LOND, provides FDR control under arbitrary, possibly unknown, dependence. We\nshow that our method is more powerful than existing approaches to this problem\nthrough simulations. We also formulate extensions of this algorithm to utilize\nrandomization for increased power, and for constructing confidence intervals in\nonline selective inference.",
            "author": [
                "Ziyu Xu",
                "Aaditya Ramdas"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06412v1",
                "http://arxiv.org/pdf/2311.06412v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06403v1",
            "title": "Exploring the Mechanical Behaviors of 2D Materials in Electrochemical\n  Energy Storage Systems: Present Insights and Future Prospects",
            "updated": "2023-11-10T21:36:41Z",
            "published": "2023-11-10T21:36:41Z",
            "summary": "2D materials (2DM) and their heterostructures (2D + nD, n = 0,1,2,3) hold\nsignificant promise for applications in Electrochemical Energy Storage Systems\n(EESS), such as batteries. 2DM can serve as van der Waals (vdW) slick interface\nbetween conventional active materials (e.g., Silicon) and current collectors,\nmodifying interfacial adhesion and preventing stress-induced fractures.\nAdditionally, 2DM can replace traditional polymer binders (e.g., MXenes). This\narrangement also underscores the critical role of interfacial mechanics between\n2DM and active materials. Furthermore, 2DM can be designed to function as an\nelectrode itself. For instance, a porous graphene network has been reported to\npossesses approximately five times the capacity of a traditional graphite\nanode. Consequently, gaining a comprehensive understanding of the mechanical\nproperties of 2DM in EESS is paramount. However, modeling 2DM in EESS poses\nsignificant challenges due to the intricate coupling of mechanics and\nelectrochemistry. For instance, defective graphene tends to favor adatom\nadsorption (e.g., Li+) during charging. In cases of strong adsorption, adatoms\nmay not readily detach from electrodes during discharging. As a result, in such\nscenarios, adsorption-desorption (charge-discharge) processes govern the\nmechanical properties of 2DM when used as binders and current collectors.\nRegrettably, most existing studies on the mechanical properties of 2DM in EESS\nhave failed to adequately address these critical issues. This perspective paper\naims to provide a comprehensive overview of recent progress in the\nchemo-mechanics of 2DM's mechanical properties. A wide spectrum of multiscale\nmodeling approaches, including atomistic/molecular simulations, continuum\nmodeling, and machine learning, are discussed.",
            "author": [
                "Dibakar Datta"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06403v1",
                "http://arxiv.org/pdf/2311.06403v1"
            ],
            "primary_category": "physics.app-ph",
            "category": [
                "physics.app-ph",
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06401v3",
            "title": "Autoregressive Language Models For Estimating the Entropy of Epic EHR\n  Audit Logs",
            "updated": "2023-11-26T02:42:13Z",
            "published": "2023-11-10T21:32:34Z",
            "summary": "EHR audit logs are a highly granular stream of events that capture clinician\nactivities, and is a significant area of interest for research in\ncharacterizing clinician workflow on the electronic health record (EHR).\nExisting techniques to measure the complexity of workflow through EHR audit\nlogs (audit logs) involve time- or frequency-based cross-sectional aggregations\nthat are unable to capture the full complexity of a EHR session. We briefly\nevaluate the usage of transformer-based tabular language model (tabular LM) in\nmeasuring the entropy or disorderedness of action sequences within workflow and\nrelease the evaluated models publicly.",
            "author": [
                "Benjamin C. Warner",
                "Thomas Kannampallil",
                "Seunghwan Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06401v3",
                "http://arxiv.org/pdf/2311.06401v3"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06400v1",
            "title": "EviPrompt: A Training-Free Evidential Prompt Generation Method for\n  Segment Anything Model in Medical Images",
            "updated": "2023-11-10T21:22:22Z",
            "published": "2023-11-10T21:22:22Z",
            "summary": "Medical image segmentation has immense clinical applicability but remains a\nchallenge despite advancements in deep learning. The Segment Anything Model\n(SAM) exhibits potential in this field, yet the requirement for expertise\nintervention and the domain gap between natural and medical images poses\nsignificant obstacles. This paper introduces a novel training-free evidential\nprompt generation method named EviPrompt to overcome these issues. The proposed\nmethod, built on the inherent similarities within medical images, requires only\na single reference image-annotation pair, making it a training-free solution\nthat significantly reduces the need for extensive labeling and computational\nresources. First, to automatically generate prompts for SAM in medical images,\nwe introduce an evidential method based on uncertainty estimation without the\ninteraction of clinical experts. Then, we incorporate the human prior into the\nprompts, which is vital for alleviating the domain gap between natural and\nmedical images and enhancing the applicability and usefulness of SAM in medical\nscenarios. EviPrompt represents an efficient and robust approach to medical\nimage segmentation, with evaluations across a broad range of tasks and\nmodalities confirming its efficacy.",
            "author": [
                "Yinsong Xu",
                "Jiaqi Tang",
                "Aidong Men",
                "Qingchao Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06400v1",
                "http://arxiv.org/pdf/2311.06400v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06397v1",
            "title": "Predicting Stock Price of Construction Companies using Weighted Ensemble\n  Learning",
            "updated": "2023-11-10T20:59:56Z",
            "published": "2023-11-10T20:59:56Z",
            "summary": "Modeling the behavior of stock price data has always been one of the\nchallengeous applications of Artificial Intelligence (AI) and Machine Learning\n(ML) due to its high complexity and dependence on various conditions. Recent\nstudies show that this will be difficult to do with just one learning model.\nThe problem can be more complex for companies of construction section, due to\nthe dependency of their behavior on more conditions. This study aims to provide\na hybrid model for improving the accuracy of prediction for stock price index\nof companies in construction section. The contribution of this paper can be\nconsidered as follows: First, a combination of several prediction models is\nused to predict stock price, so that learning models can cover each other's\nerror. In this research, an ensemble model based on Artificial Neural Network\n(ANN), Gaussian Process Regression (GPR) and Classification and Regression Tree\n(CART) is presented for predicting stock price index. Second, the optimization\ntechnique is used to determine the effect of each learning model on the\nprediction result. For this purpose, first all three mentioned algorithms\nprocess the data simultaneously and perform the prediction operation. Then,\nusing the Cuckoo Search (CS) algorithm, the output weight of each algorithm is\ndetermined as a coefficient. Finally, using the ensemble technique, these\nresults are combined and the final output is generated through weighted\naveraging on optimal coefficients. The results showed that using CS\noptimization in the proposed ensemble system is highly effective in reducing\nprediction error. Comparing the evaluation results of the proposed system with\nsimilar algorithms, indicates that our model is more accurate and can be useful\nfor predicting stock price index in real-world scenarios.",
            "author": [
                "Xinyuan Song"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06397v1",
                "http://arxiv.org/pdf/2311.06397v1"
            ],
            "primary_category": "stat.AP",
            "category": [
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06396v1",
            "title": "A comprehensive analysis of concept drift locality in data streams",
            "updated": "2023-11-10T20:57:43Z",
            "published": "2023-11-10T20:57:43Z",
            "summary": "Adapting to drifting data streams is a significant challenge in online\nlearning. Concept drift must be detected for effective model adaptation to\nevolving data properties. Concept drift can impact the data distribution\nentirely or partially, which makes it difficult for drift detectors to\naccurately identify the concept drift. Despite the numerous concept drift\ndetectors in the literature, standardized procedures and benchmarks for\ncomprehensive evaluation considering the locality of the drift are lacking. We\npresent a novel categorization of concept drift based on its locality and\nscale. A systematic approach leads to a set of 2,760 benchmark problems,\nreflecting various difficulty levels following our proposed categorization. We\nconduct a comparative assessment of 9 state-of-the-art drift detectors across\ndiverse difficulties, highlighting their strengths and weaknesses for future\nresearch. We examine how drift locality influences the classifier performance\nand propose strategies for different drift categories to minimize the recovery\ntime. Lastly, we provide lessons learned and recommendations for future concept\ndrift research. Our benchmark data streams and experiments are publicly\navailable at https://github.com/gabrieljaguiar/locality-concept-drift.",
            "author": [
                "Gabriel J. Aguiar",
                "Alberto Cano"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06396v1",
                "http://arxiv.org/pdf/2311.06396v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06395v1",
            "title": "A statistical perspective on algorithm unrolling models for inverse\n  problems",
            "updated": "2023-11-10T20:52:20Z",
            "published": "2023-11-10T20:52:20Z",
            "summary": "We consider inverse problems where the conditional distribution of the\nobservation ${\\bf y}$ given the latent variable of interest ${\\bf x}$ (also\nknown as the forward model) is known, and we have access to a data set in which\nmultiple instances of ${\\bf x}$ and ${\\bf y}$ are both observed. In this\ncontext, algorithm unrolling has become a very popular approach for designing\nstate-of-the-art deep neural network architectures that effectively exploit the\nforward model. We analyze the statistical complexity of the gradient descent\nnetwork (GDN), an algorithm unrolling architecture driven by proximal gradient\ndescent. We show that the unrolling depth needed for the optimal statistical\nperformance of GDNs is of order $\\log(n)/\\log(\\varrho_n^{-1})$, where $n$ is\nthe sample size, and $\\varrho_n$ is the convergence rate of the corresponding\ngradient descent algorithm. We also show that when the negative log-density of\nthe latent variable ${\\bf x}$ has a simple proximal operator, then a GDN\nunrolled at depth $D'$ can solve the inverse problem at the parametric rate\n$O(D'/\\sqrt{n})$. Our results thus also suggest that algorithm unrolling models\nare prone to overfitting as the unrolling depth $D'$ increases. We provide\nseveral examples to illustrate these results.",
            "author": [
                "Yves Atchade",
                "Xinru Liu",
                "Qiuyun Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06395v1",
                "http://arxiv.org/pdf/2311.06395v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06394v1",
            "title": "A design of Convolutional Neural Network model for the Diagnosis of the\n  COVID-19",
            "updated": "2023-11-10T20:50:36Z",
            "published": "2023-11-10T20:50:36Z",
            "summary": "With the spread of COVID-19 around the globe over the past year, the usage of\nartificial intelligence (AI) algorithms and image processing methods to analyze\nthe X-ray images of patients' chest with COVID-19 has become essential. The\nCOVID-19 virus recognition in the lung area of a patient is one of the basic\nand essential needs of clicical centers and hospitals. Most research in this\nfield has been devoted to papers on the basis of deep learning methods\nutilizing CNNs (Convolutional Neural Network), which mainly deal with the\nscreening of sick and healthy people.In this study, a new structure of a\n19-layer CNN has been recommended for accurately recognition of the COVID-19\nfrom the X-ray pictures of chest. The offered CNN is developed to serve as a\nprecise diagnosis system for a three class (viral pneumonia, Normal, COVID) and\na four classclassification (Lung opacity, Normal, COVID-19, and pneumonia). A\ncomparison is conducted among the outcomes of the offered procedure and some\npopular pretrained networks, including Inception, Alexnet, ResNet50,\nSqueezenet, and VGG19 and based on Specificity, Accuracy, Precision,\nSensitivity, Confusion Matrix, and F1-score. The experimental results of the\noffered CNN method specify its dominance over the existing published\nprocedures. This method can be a useful tool for clinicians in deciding\nproperly about COVID-19.",
            "author": [
                "Xinyuan Song"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06394v1",
                "http://arxiv.org/pdf/2311.06394v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06390v1",
            "title": "ChatGPT in the context of precision agriculture data analytics",
            "updated": "2023-11-10T20:44:30Z",
            "published": "2023-11-10T20:44:30Z",
            "summary": "In this study we argue that integrating ChatGPT into the data processing\npipeline of automated sensors in precision agriculture has the potential to\nbring several benefits and enhance various aspects of modern farming practices.\nPolicy makers often face a barrier when they need to get informed about the\nsituation in vast agricultural fields to reach to decisions. They depend on the\nclose collaboration between agricultural experts in the field, data analysts,\nand technology providers to create interdisciplinary teams that cannot always\nbe secured on demand or establish effective communication across these diverse\ndomains to respond in real-time. In this work we argue that the speech\nrecognition input modality of ChatGPT provides a more intuitive and natural way\nfor policy makers to interact with the database of the server of an\nagricultural data processing system to which a large, dispersed network of\nautomated insect traps and sensors probes reports. The large language models\nmap the speech input to text, allowing the user to form its own version of\nunconstrained verbal query, raising the barrier of having to learn and adapt\noneself to a specific data analytics software. The output of the language model\ncan interact through Python code and Pandas with the entire database, visualize\nthe results and use speech synthesis to engage the user in an iterative and\nrefining discussion related to the data. We show three ways of how ChatGPT can\ninteract with the database of the remote server to which a dispersed network of\ndifferent modalities (optical counters, vibration recordings, pictures, and\nvideo), report. We examine the potential and the validity of the response of\nChatGPT in analyzing, and interpreting agricultural data, providing real time\ninsights and recommendations to stakeholders",
            "author": [
                "Ilyas Potamitis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06390v1",
                "http://arxiv.org/pdf/2311.06390v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "eess.SP",
                "68Txx"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06388v1",
            "title": "Sub-annular structure in black hole image from gravitational refraction",
            "updated": "2023-11-10T20:39:28Z",
            "published": "2023-11-10T20:39:28Z",
            "summary": "The images of supermassive black holes captured by the Event Horizon\nTelescope (EHT) collaboration have allowed us to have access to the physical\nprocesses that occur in the vicinity of the event horizons of these objects.\nThis has enabled us to learn more about the state of rotation of black holes,\nabout the formation of relativistic jets in their vicinity, about the magnetic\nfield in the regions close to them, and even about the existence of the photon\nring. Furthermore, black hole imaging gives rise to a new way of testing\ngeneral relativity in the strong field regime. This has initiated a line of\nresearch aimed at probing different physical scenarios. While many scenarios\nhave been proposed in the literature that yield distortion effects that would\nbe a priori detectable at the resolution achieved by future EHT observations,\nthe vast majority of those scenarios involve strange objects or exotic matter\ncontent. Here, we consider a less heterodox scenario which, involving\nnon-exotic matter, in the sense that it satisfies all energy conditions and is\ndynamically stable, also leads to a deformation of the black hole shadow. We\nconsider a specific concentration of non-emitting, relativistic matter of zero\noptical depth forming a bubble around the black hole. Due to gravitational\nrefraction, such a self-interacting -- dark -- matter concentration may produce\nsub-annular images, i.e. subleading images inside the photon ring. We calculate\nthe ray tracing in the space-time geometry produced by such a matter\nconfiguration and obtain the corresponding black hole images. While for\nconcreteness we restrict our analysis to a specific matter distribution,\nmodeling the bubble as a thin-shell, effects qualitatively similar to those\ndescribed here are expected to occur for more general density profiles.",
            "author": [
                "Gaston Giribet",
                "Emilio Rubin de Celis",
                "Pedro Schmied"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06388v1",
                "http://arxiv.org/pdf/2311.06388v1"
            ],
            "primary_category": "gr-qc",
            "category": [
                "gr-qc"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06386v1",
            "title": "Towards A Unified Neural Architecture for Visual Recognition and\n  Reasoning",
            "updated": "2023-11-10T20:27:43Z",
            "published": "2023-11-10T20:27:43Z",
            "summary": "Recognition and reasoning are two pillars of visual understanding. However,\nthese tasks have an imbalance in focus; whereas recent advances in neural\nnetworks have shown strong empirical performance in visual recognition, there\nhas been comparably much less success in solving visual reasoning. Intuitively,\nunifying these two tasks under a singular framework is desirable, as they are\nmutually dependent and beneficial. Motivated by the recent success of\nmulti-task transformers for visual recognition and language understanding, we\npropose a unified neural architecture for visual recognition and reasoning with\na generic interface (e.g., tokens) for both. Our framework enables the\nprincipled investigation of how different visual recognition tasks, datasets,\nand inductive biases can help enable spatiotemporal reasoning capabilities.\nNoticeably, we find that object detection, which requires spatial localization\nof individual objects, is the most beneficial recognition task for reasoning.\nWe further demonstrate via probing that implicit object-centric representations\nemerge automatically inside our framework. Intriguingly, we discover that\ncertain architectural choices such as the backbone model of the visual encoder\nhave a significant impact on visual reasoning, but little on object detection.\nGiven the results of our experiments, we believe that visual reasoning should\nbe considered as a first-class citizen alongside visual recognition, as they\nare strongly correlated but benefit from potentially different design choices.",
            "author": [
                "Calvin Luo",
                "Boqing Gong",
                "Ting Chen",
                "Chen Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06386v1",
                "http://arxiv.org/pdf/2311.06386v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06383v1",
            "title": "Distilling Large Language Models using Skill-Occupation Graph Context\n  for HR-Related Tasks",
            "updated": "2023-11-10T20:25:42Z",
            "published": "2023-11-10T20:25:42Z",
            "summary": "Numerous HR applications are centered around resumes and job descriptions.\nWhile they can benefit from advancements in NLP, particularly large language\nmodels, their real-world adoption faces challenges due to absence of\ncomprehensive benchmarks for various HR tasks, and lack of smaller models with\ncompetitive capabilities. In this paper, we aim to bridge this gap by\nintroducing the Resume-Job Description Benchmark (RJDB). We meticulously craft\nthis benchmark to cater to a wide array of HR tasks, including matching and\nexplaining resumes to job descriptions, extracting skills and experiences from\nresumes, and editing resumes. To create this benchmark, we propose to distill\ndomain-specific knowledge from a large language model (LLM). We rely on a\ncurated skill-occupation graph to ensure diversity and provide context for LLMs\ngeneration. Our benchmark includes over 50 thousand triples of job\ndescriptions, matched resumes and unmatched resumes. Using RJDB, we train\nmultiple smaller student models. Our experiments reveal that the student models\nachieve near/better performance than the teacher model (GPT-4), affirming the\neffectiveness of the benchmark. Additionally, we explore the utility of RJDB on\nout-of-distribution data for skill extraction and resume-job description\nmatching, in zero-shot and weak supervision manner. We release our datasets and\ncode to foster further research and industry applications.",
            "author": [
                "Pouya Pezeshkpour",
                "Hayate Iso",
                "Thom Lake",
                "Nikita Bhutani",
                "Estevam Hruschka"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06383v1",
                "http://arxiv.org/pdf/2311.06383v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06382v1",
            "title": "Transfer Learning for Structured Pruning under Limited Task Data",
            "updated": "2023-11-10T20:23:35Z",
            "published": "2023-11-10T20:23:35Z",
            "summary": "Large, pre-trained models are problematic to use in resource constrained\napplications. Fortunately, task-aware structured pruning methods offer a\nsolution. These approaches reduce model size by dropping structural units like\nlayers and attention heads in a manner that takes into account the end-task.\nHowever, these pruning algorithms require more task-specific data than is\ntypically available. We propose a framework which combines structured pruning\nwith transfer learning to reduce the need for task-specific data. Our empirical\nresults answer questions such as: How should the two tasks be coupled? What\nparameters should be transferred? And, when during training should transfer\nlearning be introduced? Leveraging these insights, we demonstrate that our\nframework results in pruned models with improved generalization over strong\nbaselines.",
            "author": [
                "Lucio Dery",
                "David Grangier",
                "Awni Hannun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06382v1",
                "http://arxiv.org/pdf/2311.06382v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06381v1",
            "title": "Optimal Fidelity Selection for Improved Performance in Human-in-the-Loop\n  Queues for Underwater Search",
            "updated": "2023-11-10T20:15:35Z",
            "published": "2023-11-10T20:15:35Z",
            "summary": "In the context of human-supervised autonomy, we study the problem of optimal\nfidelity selection for a human operator performing an underwater visual search\ntask. Human performance depends on various cognitive factors such as workload\nand fatigue. We perform human experiments in which participants perform two\ntasks simultaneously: a primary task, which is subject to evaluation, and a\nsecondary task to estimate their workload. The primary task requires\nparticipants to search for underwater mines in videos, while the secondary task\ninvolves a simple visual test where they respond when a green light displayed\non the side of their screens turns red. Videos arrive as a Poisson process and\nare stacked in a queue to be serviced by the human operator. The operator can\nchoose to watch the video with either normal or high fidelity, with normal\nfidelity videos playing at three times the speed of high fidelity ones.\nParticipants receive rewards for their accuracy in mine detection for each\nprimary task and penalties based on the number of videos waiting in the queue.\nWe consider the workload of the operator as a hidden state and model the\nworkload dynamics as an Input-Output Hidden Markov Model (IOHMM). We use a\nPartially Observable Markov Decision Process (POMDP) to learn an optimal\nfidelity selection policy, where the objective is to maximize total rewards.\nOur results demonstrate improved performance when videos are serviced based on\nthe optimal fidelity policy compared to a baseline where humans choose the\nfidelity level themselves.",
            "author": [
                "Piyush Gupta",
                "Vaibhav Srivastava"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06381v1",
                "http://arxiv.org/pdf/2311.06381v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06380v1",
            "title": "Theory and implementation of inelastic Constitutive Artificial Neural\n  Networks",
            "updated": "2023-11-10T20:13:29Z",
            "published": "2023-11-10T20:13:29Z",
            "summary": "Nature has always been our inspiration in the research, design and\ndevelopment of materials and has driven us to gain a deep understanding of the\nmechanisms that characterize anisotropy and inelastic behavior. All this\nknowledge has been accumulated in the principles of thermodynamics. Deduced\nfrom these principles, the multiplicative decomposition combined with pseudo\npotentials are powerful and universal concepts. Simultaneously, the tremendous\nincrease in computational performance enabled us to investigate and rethink our\nhistory-dependent material models to make the most of our predictions. Today,\nwe have reached a point where materials and their models are becoming\nincreasingly sophisticated. This raises the question: How do we find the best\nmodel that includes all inelastic effects to explain our complex data?\nConstitutive Artificial Neural Networks (CANN) may answer this question. Here,\nwe extend the CANNs to inelastic materials (iCANN). Rigorous considerations of\nobjectivity, rigid motion of the reference configuration, multiplicative\ndecomposition and its inherent non-uniqueness, restrictions of energy and\npseudo potential, and consistent evolution guide us towards the architecture of\nthe iCANN satisfying thermodynamics per design. We combine feed-forward\nnetworks of the free energy and pseudo potential with a recurrent neural\nnetwork approach to take time dependencies into account. We demonstrate that\nthe iCANN is capable of autonomously discovering models for artificially\ngenerated data, the response of polymers for cyclic loading and the relaxation\nbehavior of muscle data. As the design of the network is not limited to\nvisco-elasticity, our vision is that the iCANN will reveal to us new ways to\nfind the various inelastic phenomena hidden in the data and to understand their\ninteraction. Our source code, data, and examples are available at\ndoi.org/10.5281/zenodo.10066805",
            "author": [
                "Hagen Holthusen",
                "Lukas Lamm",
                "Tim Brepols",
                "Stefanie Reese",
                "Ellen Kuhl"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06380v1",
                "http://arxiv.org/pdf/2311.06380v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cond-mat.mtrl-sci",
                "65, 74",
                "I.6; J.2"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06379v1",
            "title": "DeMuX: Data-efficient Multilingual Learning",
            "updated": "2023-11-10T20:09:08Z",
            "published": "2023-11-10T20:09:08Z",
            "summary": "We consider the task of optimally fine-tuning pre-trained multilingual\nmodels, given small amounts of unlabelled target data and an annotation budget.\nIn this paper, we introduce DEMUX, a framework that prescribes the exact\ndata-points to label from vast amounts of unlabelled multilingual data, having\nunknown degrees of overlap with the target set. Unlike most prior works, our\nend-to-end framework is language-agnostic, accounts for model representations,\nand supports multilingual target configurations. Our active learning strategies\nrely upon distance and uncertainty measures to select task-specific neighbors\nthat are most informative to label, given a model. DeMuX outperforms strong\nbaselines in 84% of the test cases, in the zero-shot setting of disjoint source\nand target language sets (including multilingual target pools), across three\nmodels and four tasks. Notably, in low-budget settings (5-100 examples), we\nobserve gains of up to 8-11 F1 points for token-level tasks, and 2-5 F1 for\ncomplex tasks. Our code is released here:\nhttps://github.com/simran-khanuja/demux.",
            "author": [
                "Simran Khanuja",
                "Srinivas Gowriraj",
                "Lucio Dery",
                "Graham Neubig"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06379v1",
                "http://arxiv.org/pdf/2311.06379v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06375v1",
            "title": "Image Classification using Combination of Topological Features and\n  Neural Networks",
            "updated": "2023-11-10T20:05:40Z",
            "published": "2023-11-10T20:05:40Z",
            "summary": "In this work we use the persistent homology method, a technique in\ntopological data analysis (TDA), to extract essential topological features from\nthe data space and combine them with deep learning features for classification\ntasks. In TDA, the concepts of complexes and filtration are building blocks.\nFirstly, a filtration is constructed from some complex. Then, persistent\nhomology classes are computed, and their evolution along the filtration is\nvisualized through the persistence diagram. Additionally, we applied\nvectorization techniques to the persistence diagram to make this topological\ninformation compatible with machine learning algorithms. This was carried out\nwith the aim of classifying images from multiple classes in the MNIST dataset.\nOur approach inserts topological features into deep learning approaches\ncomposed by single and two-streams neural networks architectures based on a\nmulti-layer perceptron (MLP) and a convolutional neral network (CNN) taylored\nfor multi-class classification in the MNIST dataset. In our analysis, we\nevaluated the obtained results and compared them with the outcomes achieved\nthrough the baselines that are available in the TensorFlow library. The main\nconclusion is that topological information may increase neural network accuracy\nin multi-class classification tasks with the price of computational complexity\nof persistent homology calculation. Up to the best of our knowledge, it is the\nfirst work that combines deep learning features and the combination of\ntopological features for multi-class classification tasks.",
            "author": [
                "Mariana D\u00f3ria Prata Lima",
                "Gilson Antonio Giraldi",
                "Gast\u00e3o Flor\u00eancio Miranda Junior"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06375v1",
                "http://arxiv.org/pdf/2311.06375v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "cs.NE",
                "57T99, 57Z25",
                "I.4.10; I.2.10; I.5.4"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06374v1",
            "title": "Higher-Order Newton Methods with Polynomial Work per Iteration",
            "updated": "2023-11-10T20:02:58Z",
            "published": "2023-11-10T20:02:58Z",
            "summary": "We present generalizations of Newton's method that incorporate derivatives of\nan arbitrary order $d$ but maintain a polynomial dependence on dimension in\ntheir cost per iteration. At each step, our $d^{\\text{th}}$-order method uses\nsemidefinite programming to construct and minimize a sum of squares-convex\napproximation to the $d^{\\text{th}}$-order Taylor expansion of the function we\nwish to minimize. We prove that our $d^{\\text{th}}$-order method has local\nconvergence of order $d$. This results in lower oracle complexity compared to\nthe classical Newton method. We show on numerical examples that basins of\nattraction around local minima can get larger as $d$ increases. Under\nadditional assumptions, we present a modified algorithm, again with polynomial\ncost per iteration, which is globally convergent and has local convergence of\norder $d$.",
            "author": [
                "Amir Ali Ahmadi",
                "Abraar Chaudhry",
                "Jeffrey Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06374v1",
                "http://arxiv.org/pdf/2311.06374v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06372v1",
            "title": "Blockchain-Enabled Federated Learning Approach for Vehicular Networks",
            "updated": "2023-11-10T19:51:18Z",
            "published": "2023-11-10T19:51:18Z",
            "summary": "Data from interconnected vehicles may contain sensitive information such as\nlocation, driving behavior, personal identifiers, etc. Without adequate\nsafeguards, sharing this data jeopardizes data privacy and system security. The\ncurrent centralized data-sharing paradigm in these systems raises particular\nconcerns about data privacy. Recognizing these challenges, the shift towards\ndecentralized interactions in technology, as echoed by the principles of\nIndustry 5.0, becomes paramount. This work is closely aligned with these\nprinciples, emphasizing decentralized, human-centric, and secure technological\ninteractions in an interconnected vehicular ecosystem. To embody this, we\npropose a practical approach that merges two emerging technologies: Federated\nLearning (FL) and Blockchain. The integration of these technologies enables the\ncreation of a decentralized vehicular network. In this setting, vehicles can\nlearn from each other without compromising privacy while also ensuring data\nintegrity and accountability. Initial experiments show that compared to\nconventional decentralized federated learning techniques, our proposed approach\nsignificantly enhances the performance and security of vehicular networks. The\nsystem's accuracy stands at 91.92\\%. While this may appear to be low in\ncomparison to state-of-the-art federated learning models, our work is\nnoteworthy because, unlike others, it was achieved in a malicious vehicle\nsetting. Despite the challenging environment, our method maintains high\naccuracy, making it a competent solution for preserving data privacy in\nvehicular networks.",
            "author": [
                "Shirin Sultana",
                "Jahin Hossain",
                "Maruf Billah",
                "Hasibul Hossain Shajeeb",
                "Saifur Rahman",
                "Keyvan Ansari",
                "Khondokar Fida Hasan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06372v1",
                "http://arxiv.org/pdf/2311.06372v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06368v1",
            "title": "The AeroSonicDB (YPAD-0523) Dataset for Acoustic Detection and\n  Classification of Aircraft",
            "updated": "2023-11-10T19:41:10Z",
            "published": "2023-11-10T19:41:10Z",
            "summary": "The time and expense required to collect and label audio data has been a\nprohibitive factor in the availability of domain specific audio datasets. As\nthe predictive specificity of a classifier depends on the specificity of the\nlabels it is trained on, it follows that finely-labelled datasets are crucial\nfor advances in machine learning. Aiming to stimulate progress in the field of\nmachine listening, this paper introduces AeroSonicDB (YPAD-0523), a dataset of\nlow-flying aircraft sounds for training acoustic detection and classification\nsystems. This paper describes the method of exploiting ADS-B radio\ntransmissions to passively collect and label audio samples. Provides a summary\nof the collated dataset. Presents baseline results from three binary\nclassification models, then discusses the limitations of the current dataset\nand its future potential. The dataset contains 625 aircraft recordings ranging\nin event duration from 18 to 60 seconds, for a total of 8.87 hours of aircraft\naudio. These 625 samples feature 301 unique aircraft, each of which are\nsupplied with 14 supplementary (non-acoustic) labels to describe the aircraft.\nThe dataset also contains 3.52 hours of ambient background audio (\"silence\"),\nas a means to distinguish aircraft noise from other local environmental noises.\nAdditionally, 6 hours of urban soundscape recordings (with aircraft\nannotations) are included as an ancillary method for evaluating model\nperformance, and to provide a testing ground for real-time applications.",
            "author": [
                "Blake Downward",
                "Jon Nordby"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06368v1",
                "http://arxiv.org/pdf/2311.06368v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.LG",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06364v1",
            "title": "Relation Extraction in underexplored biomedical domains: A\n  diversity-optimised sampling and synthetic data generation approach",
            "updated": "2023-11-10T19:36:00Z",
            "published": "2023-11-10T19:36:00Z",
            "summary": "The sparsity of labelled data is an obstacle to the development of Relation\nExtraction models and the completion of databases in various biomedical areas.\nWhile being of high interest in drug-discovery, the natural-products\nliterature, reporting the identification of potential bioactive compounds from\norganisms, is a concrete example of such an overlooked topic. To mark the start\nof this new task, we created the first curated evaluation dataset and extracted\nliterature items from the LOTUS database to build training sets. To this end,\nwe developed a new sampler inspired by diversity metrics in ecology, named\nGreedy Maximum Entropy sampler, or GME-sampler\n(https://github.com/idiap/gme-sampler). The strategic optimization of both\nbalance and diversity of the selected items in the evaluation set is important\ngiven the resource-intensive nature of manual curation. After quantifying the\nnoise in the training set, in the form of discrepancies between the input\nabstracts text and the expected output labels, we explored different strategies\naccordingly. Framing the task as an end-to-end Relation Extraction, we\nevaluated the performance of standard fine-tuning as a generative task and\nfew-shot learning with open Large Language Models (LLaMA 7B-65B). In addition\nto their evaluation in few-shot settings, we explore the potential of open\nLarge Language Models (Vicuna-13B) as synthetic data generator and propose a\nnew workflow for this purpose. All evaluated models exhibited substantial\nimprovements when fine-tuned on synthetic abstracts rather than the original\nnoisy data. We provide our best performing (f1-score=59.0) BioGPT-Large model\nfor end-to-end RE of natural-products relationships along with all the\ngenerated synthetic data and the evaluation dataset. See more details at\nhttps://github.com/idiap/abroad-re.",
            "author": [
                "Maxime Delmas",
                "Magdalena Wysocka",
                "Andr\u00e9 Freitas"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06364v1",
                "http://arxiv.org/pdf/2311.06364v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06361v1",
            "title": "CALLOC: Curriculum Adversarial Learning for Secure and Robust Indoor\n  Localization",
            "updated": "2023-11-10T19:26:31Z",
            "published": "2023-11-10T19:26:31Z",
            "summary": "Indoor localization has become increasingly vital for many applications from\ntracking assets to delivering personalized services. Yet, achieving pinpoint\naccuracy remains a challenge due to variations across indoor environments and\ndevices used to assist with localization. Another emerging challenge is\nadversarial attacks on indoor localization systems that not only threaten\nservice integrity but also reduce localization accuracy. To combat these\nchallenges, we introduce CALLOC, a novel framework designed to resist\nadversarial attacks and variations across indoor environments and devices that\nreduce system accuracy and reliability. CALLOC employs a novel adaptive\ncurriculum learning approach with a domain specific lightweight scaled-dot\nproduct attention neural network, tailored for adversarial and variation\nresilience in practical use cases with resource constrained mobile devices.\nExperimental evaluations demonstrate that CALLOC can achieve improvements of up\nto 6.03x in mean error and 4.6x in worst-case error against state-of-the-art\nindoor localization frameworks, across diverse building floorplans, mobile\ndevices, and adversarial attacks scenarios.",
            "author": [
                "Danish Gufran",
                "Sudeep Pasricha"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06361v1",
                "http://arxiv.org/pdf/2311.06361v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06358v1",
            "title": "Compact Matrix Quantum Group Equivariant Neural Networks",
            "updated": "2023-11-10T19:11:13Z",
            "published": "2023-11-10T19:11:13Z",
            "summary": "We derive the existence of a new type of neural network, called a compact\nmatrix quantum group equivariant neural network, that learns from data that has\nan underlying quantum symmetry. We apply the Woronowicz formulation of\nTannaka-Krein duality to characterise the weight matrices that appear in these\nneural networks for any easy compact matrix quantum group. We show that compact\nmatrix quantum group equivariant neural networks contain, as a subclass, all\ncompact matrix group equivariant neural networks. Moreover, we obtain\ncharacterisations of the weight matrices for many compact matrix group\nequivariant neural networks that have not previously appeared in the machine\nlearning literature.",
            "author": [
                "Edward Pearce-Crump"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06358v1",
                "http://arxiv.org/pdf/2311.06358v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.CO",
                "math.CT",
                "math.RT",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06349v1",
            "title": "Interferometric Image Reconstruction using Closure Invariants and\n  Machine Learning",
            "updated": "2023-11-10T19:00:04Z",
            "published": "2023-11-10T19:00:04Z",
            "summary": "Closure invariants in interferometry carry calibration-independent\ninformation about the morphology of an observed object. Excepting simple cases,\na mapping between closure invariants and morphologies is not well established.\nWe aim to demonstrate that closure invariants can be used to classify the\nmorphology and estimate the morphological parameters using simple Machine\nLearning models. We consider 6 morphological classes -- point-like, uniform\ncircular disc, crescent, dual disc, crescent with elliptical accretion disc,\nand crescent with double jet lobes -- described by phenomenological parameters.\nUsing simple logistic regression, multi-layer perceptron (MLP), convolutional\nneural network, and random forest models on closure invariants obtained from a\nsparse aperture coverage, we find that all models except logistic regression\nare able to classify the morphology with an $F_1$ score $\\gtrsim 0.8$. The\nclassification accuracy notably improves with greater aperture coverage. We\nalso estimate morphological parameters of uniform circular disc, crescent, and\ndual disc using simple MLP models, and perform a parametric image\nreconstruction. The reconstructed images do not retain information about\nabsolute position or intensity scale. The estimated parameters and\nreconstructed images are found to correspond well with the inputs. However, the\nprediction accuracy worsens with increasing morphological complexity. This\nproof-of-concept method opens an independent approach to interferometric\nimaging under challenging observing conditions such as that faced by the Event\nHorizon Telescope and Very Long Baseline Interferometry in general, and can\ncomplement other methods to robustly constrain an object's morphology.",
            "author": [
                "Nithyanandan Thyagarajan",
                "Lucas Hoefs",
                "O. Ivy Wong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06349v1",
                "http://arxiv.org/pdf/2311.06349v1"
            ],
            "primary_category": "astro-ph.IM",
            "category": [
                "astro-ph.IM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06345v1",
            "title": "Schema Graph-Guided Prompt for Multi-Domain Dialogue State Tracking",
            "updated": "2023-11-10T19:00:02Z",
            "published": "2023-11-10T19:00:02Z",
            "summary": "Tracking dialogue states is an essential topic in task-oriented dialogue\nsystems, which involve filling in the necessary information in pre-defined\nslots corresponding to a schema. While general pre-trained language models have\nbeen shown effective in slot-filling, their performance is limited when applied\nto specific domains. We propose a graph-based framework that learns\ndomain-specific prompts by incorporating the dialogue schema. Specifically, we\nembed domain-specific schema encoded by a graph neural network into the\npre-trained language model, which allows for relations in the schema to guide\nthe model for better adaptation to the specific domain. Our experiments\ndemonstrate that the proposed graph-based method outperforms other multi-domain\nDST approaches while using similar or fewer trainable parameters. We also\nconduct a comprehensive study of schema graph architectures, parameter usage,\nand module ablation that demonstrate the effectiveness of our model on\nmulti-domain dialogue state tracking.",
            "author": [
                "Ruolin Su",
                "Ting-Wei Wu",
                "Biing-Hwang Juang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06345v1",
                "http://arxiv.org/pdf/2311.06345v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06332v1",
            "title": "Going from 3D to 1D: A one-dimensional approach to common-envelope\n  evolution",
            "updated": "2023-11-10T19:00:00Z",
            "published": "2023-11-10T19:00:00Z",
            "summary": "The common-envelope (CE) phase is a crucial stage in binary star evolution\nbecause the orbital separation can shrink drastically while ejecting the\nenvelope of a giant star. Three-dimensional (3D) hydrodynamic simulations of CE\nevolution are indispensable to learning about the mechanisms that play a role\nduring the CE phase. While these simulations offer great insight, they are\ncomputationally expensive. We propose a one-dimensional (1D) model to simulate\nthe CE phase within the stellar evolution code $\\texttt{MESA}$ by using a\nparametric drag force prescription for dynamical drag and adding the released\norbital energy as heat into the envelope. We compute CE events of a\n$0.97\\,\\mathrm{M}_\\odot$ asymptotic giant-branch star and a point mass\ncompanion with mass ratios of 0.25, 0.50, and 0.75, and compare them to 3D\nsimulations of the same setup. The 1D CE model contains two free parameters,\nwhich we demonstrate are both needed to fit the spiral-in behavior and the\nfraction of ejected envelope mass of the 1D method to the 3D simulations. For\nmass ratios of 0.25 and 0.50, we find good-fitting 1D simulations, while for a\nmass ratio of 0.75, we do not find a satisfactory fit to the 3D simulation as\nsome of the assumptions in the 1D method are no longer valid. In all our\nsimulations, we find that the released recombination energy is important to\naccelerate the envelope and drive the ejection.",
            "author": [
                "V. A. Bronner",
                "F. R. N. Schneider",
                "Ph. Podsiadlowski",
                "F. K. Roepke"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06332v1",
                "http://arxiv.org/pdf/2311.06332v1"
            ],
            "primary_category": "astro-ph.SR",
            "category": [
                "astro-ph.SR",
                "astro-ph.HE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06243v1",
            "title": "Parameter-Efficient Orthogonal Finetuning via Butterfly Factorization",
            "updated": "2023-11-10T18:59:54Z",
            "published": "2023-11-10T18:59:54Z",
            "summary": "Large foundation models are becoming ubiquitous, but training them from\nscratch is prohibitively expensive. Thus, efficiently adapting these powerful\nmodels to downstream tasks is increasingly important. In this paper, we study a\nprincipled finetuning paradigm -- Orthogonal Finetuning (OFT) -- for downstream\ntask adaptation. Despite demonstrating good generalizability, OFT still uses a\nfairly large number of trainable parameters due to the high dimensionality of\northogonal matrices. To address this, we start by examining OFT from an\ninformation transmission perspective, and then identify a few key desiderata\nthat enable better parameter-efficiency. Inspired by how the Cooley-Tukey fast\nFourier transform algorithm enables efficient information transmission, we\npropose an efficient orthogonal parameterization using butterfly structures. We\napply this parameterization to OFT, creating a novel parameter-efficient\nfinetuning method, called Orthogonal Butterfly (BOFT). By subsuming OFT as a\nspecial case, BOFT introduces a generalized orthogonal finetuning framework.\nFinally, we conduct an extensive empirical study of adapting large vision\ntransformers, large language models, and text-to-image diffusion models to\nvarious downstream tasks in vision and language.",
            "author": [
                "Weiyang Liu",
                "Zeju Qiu",
                "Yao Feng",
                "Yuliang Xiu",
                "Yuxuan Xue",
                "Longhui Yu",
                "Haiwen Feng",
                "Zhen Liu",
                "Juyeon Heo",
                "Songyou Peng",
                "Yandong Wen",
                "Michael J. Black",
                "Adrian Weller",
                "Bernhard Sch\u00f6lkopf"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06243v1",
                "http://arxiv.org/pdf/2311.06243v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06242v1",
            "title": "Florence-2: Advancing a Unified Representation for a Variety of Vision\n  Tasks",
            "updated": "2023-11-10T18:59:08Z",
            "published": "2023-11-10T18:59:08Z",
            "summary": "We introduce Florence-2, a novel vision foundation model with a unified,\nprompt-based representation for a variety of computer vision and\nvision-language tasks. While existing large vision models excel in transfer\nlearning, they struggle to perform a diversity of tasks with simple\ninstructions, a capability that implies handling the complexity of various\nspatial hierarchy and semantic granularity. Florence-2 was designed to take\ntext-prompt as task instructions and generate desirable results in text forms,\nwhether it be captioning, object detection, grounding or segmentation. This\nmulti-task learning setup demands large-scale, high-quality annotated data. To\nthis end, we co-developed FLD-5B that consists of 5.4 billion comprehensive\nvisual annotations on 126 million images, using an iterative strategy of\nautomated image annotation and model refinement. We adopted a\nsequence-to-sequence structure to train Florence-2 to perform versatile and\ncomprehensive vision tasks. Extensive evaluations on numerous tasks\ndemonstrated Florence-2 to be a strong vision foundation model contender with\nunprecedented zero-shot and fine-tuning capabilities.",
            "author": [
                "Bin Xiao",
                "Haiping Wu",
                "Weijian Xu",
                "Xiyang Dai",
                "Houdong Hu",
                "Yumao Lu",
                "Michael Zeng",
                "Ce Liu",
                "Lu Yuan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06242v1",
                "http://arxiv.org/pdf/2311.06242v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06239v1",
            "title": "Argumentation Element Annotation Modeling using XLNet",
            "updated": "2023-11-10T18:55:23Z",
            "published": "2023-11-10T18:55:23Z",
            "summary": "This study demonstrates the effectiveness of XLNet, a transformer-based\nlanguage model, for annotating argumentative elements in persuasive essays.\nXLNet's architecture incorporates a recurrent mechanism that allows it to model\nlong-term dependencies in lengthy texts. Fine-tuned XLNet models were applied\nto three datasets annotated with different schemes - a proprietary dataset\nusing the Annotations for Revisions and Reflections on Writing (ARROW) scheme,\nthe PERSUADE corpus, and the Argument Annotated Essays (AAE) dataset. The XLNet\nmodels achieved strong performance across all datasets, even surpassing human\nagreement levels in some cases. This shows XLNet capably handles diverse\nannotation schemes and lengthy essays. Comparisons between the model outputs on\ndifferent datasets also revealed insights into the relationships between the\nannotation tags. Overall, XLNet's strong performance on modeling argumentative\nstructures across diverse datasets highlights its suitability for providing\nautomated feedback on essay organization.",
            "author": [
                "Christopher Ormerod",
                "Amy Burkhardt",
                "Mackenzie Young",
                "Sue Lottridge"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06239v1",
                "http://arxiv.org/pdf/2311.06239v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06236v1",
            "title": "Deep Learning meets Blockchain for Automated and Secure Access Control",
            "updated": "2023-11-10T18:50:56Z",
            "published": "2023-11-10T18:50:56Z",
            "summary": "Access control is a critical component of computer security, governing access\nto system resources. However, designing policies and roles in traditional\naccess control can be challenging and difficult to maintain in dynamic and\ncomplex systems, which is particularly problematic for organizations with\nnumerous resources. Furthermore, traditional methods suffer from issues such as\nthird-party involvement, inefficiency, and privacy gaps, making transparent and\ndynamic access control an ongoing research problem. Moreover detecting\nmalicious activities and identifying users who are not behaving appropriately\ncan present notable difficulties. To address these challenges, we propose\nDLACB, a Deep Learning Based Access Control Using Blockchain, as a solution to\ndecentralized access control. DLACB uses blockchain to provide transparency,\ntraceability, and reliability in various domains such as medicine, finance, and\ngovernment while taking advantage of deep learning to not rely on predefined\npolicies and eventually automate access control. With the integration of\nblockchain and deep learning for access control, DLACB can provide a general\nframework applicable to various domains, enabling transparent and reliable\nlogging of all transactions. As all data is recorded on the blockchain, we have\nthe capability to identify malicious activities. We store a list of malicious\nactivities in the storage system and employ a verification algorithm to\ncross-reference it with the blockchain. We conduct measurements and comparisons\nof the smart contract processing time for the deployed access control system in\ncontrast to traditional access control methods, determining the time overhead\ninvolved. The processing time of DLBAC demonstrates remarkable stability when\nexposed to increased request volumes.",
            "author": [
                "Asma Jodeiri Akbarfam",
                "Sina Barazandeh",
                "Deepti Gupta",
                "Hoda Maleki"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06236v1",
                "http://arxiv.org/pdf/2311.06236v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06234v1",
            "title": "EVORA: Deep Evidential Traversability Learning for Risk-Aware Off-Road\n  Autonomy",
            "updated": "2023-11-10T18:49:53Z",
            "published": "2023-11-10T18:49:53Z",
            "summary": "Traversing terrain with good traction is crucial for achieving fast off-road\nnavigation. Instead of manually designing costs based on terrain features,\nexisting methods learn terrain properties directly from data via\nself-supervision, but challenges remain to properly quantify and mitigate risks\ndue to uncertainties in learned models. This work efficiently quantifies both\naleatoric and epistemic uncertainties by learning discrete traction\ndistributions and probability densities of the traction predictor's latent\nfeatures. Leveraging evidential deep learning, we parameterize Dirichlet\ndistributions with the network outputs and propose a novel uncertainty-aware\nsquared Earth Mover's distance loss with a closed-form expression that improves\nlearning accuracy and navigation performance. The proposed risk-aware planner\nsimulates state trajectories with the worst-case expected traction to handle\naleatoric uncertainty, and penalizes trajectories moving through terrain with\nhigh epistemic uncertainty. Our approach is extensively validated in simulation\nand on wheeled and quadruped robots, showing improved navigation performance\ncompared to methods that assume no slip, assume the expected traction, or\noptimize for the worst-case expected cost.",
            "author": [
                "Xiaoyi Cai",
                "Siddharth Ancha",
                "Lakshay Sharma",
                "Philip R. Osteen",
                "Bernadette Bucher",
                "Stephen Phillips",
                "Jiuguang Wang",
                "Michael Everett",
                "Nicholas Roy",
                "Jonathan P. How"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06234v1",
                "http://arxiv.org/pdf/2311.06234v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.LG",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06233v3",
            "title": "Data Contamination Quiz: A Tool to Detect and Estimate Contamination in\n  Large Language Models",
            "updated": "2023-11-20T20:43:10Z",
            "published": "2023-11-10T18:48:58Z",
            "summary": "We propose the Data Contamination Quiz, a simple and effective approach to\ndetect data contamination in large language models (LLMs) and estimate the\namount of it. Specifically, we frame data contamination detection as a series\nof multiple-choice questions. We devise a quiz format wherein three perturbed\nversions of each dataset instance are created. These changes only include\nword-level perturbations, replacing words with their contextual synonyms,\nensuring both the semantic and sentence structure remain exactly the same as\nthe original instance. Together with the original instance, these perturbed\nversions constitute the choices in the quiz. Given that the only distinguishing\nsignal among these choices is the exact wording, an LLM, when tasked with\nidentifying the original instance from the choices, opts for the original if it\nhas memorized it in its pre-training phase--a trait intrinsic to LLMs. A\ndataset partition is then marked as contaminated if the LLM's performance on\nthe quiz surpasses what random chance suggests. Our evaluation spans seven\ndatasets and their respective splits (train and test/validation) on two\nstate-of-the-art LLMs: GPT-4 and GPT-3.5. While lacking access to the\npre-training data, our results suggest that our approach not only enhances the\ndetection of data contamination but also provides an accurate estimation of its\nextent, even when the contamination signal is weak.",
            "author": [
                "Shahriar Golchin",
                "Mihai Surdeanu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06233v3",
                "http://arxiv.org/pdf/2311.06233v3"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06231v1",
            "title": "Learning Human Action Recognition Representations Without Real Humans",
            "updated": "2023-11-10T18:38:14Z",
            "published": "2023-11-10T18:38:14Z",
            "summary": "Pre-training on massive video datasets has become essential to achieve high\naction recognition performance on smaller downstream datasets. However, most\nlarge-scale video datasets contain images of people and hence are accompanied\nwith issues related to privacy, ethics, and data protection, often preventing\nthem from being publicly shared for reproducible research. Existing work has\nattempted to alleviate these problems by blurring faces, downsampling videos,\nor training on synthetic data. On the other hand, analysis on the\ntransferability of privacy-preserving pre-trained models to downstream tasks\nhas been limited. In this work, we study this problem by first asking the\nquestion: can we pre-train models for human action recognition with data that\ndoes not include real humans? To this end, we present, for the first time, a\nbenchmark that leverages real-world videos with humans removed and synthetic\ndata containing virtual humans to pre-train a model. We then evaluate the\ntransferability of the representation learned on this data to a diverse set of\ndownstream action recognition benchmarks. Furthermore, we propose a novel\npre-training strategy, called Privacy-Preserving MAE-Align, to effectively\ncombine synthetic data and human-removed real data. Our approach outperforms\nprevious baselines by up to 5% and closes the performance gap between human and\nno-human action recognition representations on downstream tasks, for both\nlinear probing and fine-tuning. Our benchmark, code, and models are available\nat https://github.com/howardzh01/PPMA .",
            "author": [
                "Howard Zhong",
                "Samarth Mishra",
                "Donghyun Kim",
                "SouYoung Jin",
                "Rameswar Panda",
                "Hilde Kuehne",
                "Leonid Karlinsky",
                "Venkatesh Saligrama",
                "Aude Oliva",
                "Rogerio Feris"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06231v1",
                "http://arxiv.org/pdf/2311.06231v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06228v2",
            "title": "Learning material synthesis-process-structure-property relationship by\n  data fusion: Bayesian Coregionalization N-Dimensional Piecewise Function\n  Learning",
            "updated": "2023-11-20T21:43:52Z",
            "published": "2023-11-10T18:34:24Z",
            "summary": "Autonomous materials research labs require the ability to combine and learn\nfrom diverse data streams. This is especially true for learning material\nsynthesis-process-structure-property relationships, key to accelerating\nmaterials optimization and discovery as well as accelerating mechanistic\nunderstanding. We present the Synthesis-process-structure-property relAtionship\ncoreGionalized lEarner (SAGE) algorithm. A fully Bayesian algorithm that uses\nmultimodal coregionalization to merge knowledge across data sources to learn\nsynthesis-process-structure-property relationships. SAGE outputs a\nprobabilistic posterior for the relationships including the most likely\nrelationships given the data.",
            "author": [
                "A. Gilad Kusne",
                "Austin McDannald",
                "Brian DeCost"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06228v2",
                "http://arxiv.org/pdf/2311.06228v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06227v1",
            "title": "Does Differential Privacy Prevent Backdoor Attacks in Practice?",
            "updated": "2023-11-10T18:32:08Z",
            "published": "2023-11-10T18:32:08Z",
            "summary": "Differential Privacy (DP) was originally developed to protect privacy.\nHowever, it has recently been utilized to secure machine learning (ML) models\nfrom poisoning attacks, with DP-SGD receiving substantial attention.\nNevertheless, a thorough investigation is required to assess the effectiveness\nof different DP techniques in preventing backdoor attacks in practice. In this\npaper, we investigate the effectiveness of DP-SGD and, for the first time in\nliterature, examine PATE in the context of backdoor attacks. We also explore\nthe role of different components of DP algorithms in defending against backdoor\nattacks and will show that PATE is effective against these attacks due to the\nbagging structure of the teacher models it employs. Our experiments reveal that\nhyperparameters and the number of backdoors in the training dataset impact the\nsuccess of DP algorithms. Additionally, we propose Label-DP as a faster and\nmore accurate alternative to DP-SGD and PATE. We conclude that while Label-DP\nalgorithms generally offer weaker privacy protection, accurate hyper-parameter\ntuning can make them more effective than DP methods in defending against\nbackdoor attacks while maintaining model accuracy.",
            "author": [
                "Fereshteh Razmi",
                "Jian Lou",
                "Li Xiong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06227v1",
                "http://arxiv.org/pdf/2311.06227v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2312.00791v1",
            "title": "Replicator-mutator dynamics of Rock-Paper-Scissors game: Learning\n  through mistakes",
            "updated": "2023-11-10T18:27:12Z",
            "published": "2023-11-10T18:27:12Z",
            "summary": "We generalize the Bush--Mosteller learning, the Roth--Erev learning, and the\nsocial learning to include mistakes such that the nonlinear replicator-mutator\nequation with either additive or multiplicative mutation is generated in an\nasymptotic limit. Subsequently, we exhaustively investigate the ubiquitous\nRock-Paper-Scissors game for some analytically tractable motifs of mutation\npattern. We consider both symmetric and asymmetric game interactions, and\nreveal that mistakes can some-times help the players learn. While the\nreplicator-mutator flow exhibits rich dynamics that include limit cycles and\nchaotic orbits, it can control chaos as well to lead to rational Nash\nequilibrium outcome. Moreover, we also report an instance of hitherto unknown\nHamiltonian structure of the replicator-mutator equation.",
            "author": [
                "Suman Chakraborty",
                "Ishita Agarwal",
                "Sagar Chakraborty"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00791v1",
                "http://arxiv.org/pdf/2312.00791v1"
            ],
            "primary_category": "physics.soc-ph",
            "category": [
                "physics.soc-ph",
                "nlin.CD",
                "q-bio.PE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06224v1",
            "title": "Harnessing Synthetic Datasets: The Role of Shape Bias in Deep Neural\n  Network Generalization",
            "updated": "2023-11-10T18:25:44Z",
            "published": "2023-11-10T18:25:44Z",
            "summary": "Recent advancements in deep learning have been primarily driven by the use of\nlarge models trained on increasingly vast datasets. While neural scaling laws\nhave emerged to predict network performance given a specific level of\ncomputational resources, the growing demand for expansive datasets raises\nconcerns. To address this, a new research direction has emerged, focusing on\nthe creation of synthetic data as a substitute. In this study, we investigate\nhow neural networks exhibit shape bias during training on synthetic datasets,\nserving as an indicator of the synthetic data quality. Specifically, our\nfindings indicate three key points: (1) Shape bias varies across network\narchitectures and types of supervision, casting doubt on its reliability as a\npredictor for generalization and its ability to explain differences in model\nrecognition compared to human capabilities. (2) Relying solely on shape bias to\nestimate generalization is unreliable, as it is entangled with diversity and\nnaturalism. (3) We propose a novel interpretation of shape bias as a tool for\nestimating the diversity of samples within a dataset. Our research aims to\nclarify the implications of using synthetic data and its associated shape bias\nin deep learning, addressing concerns regarding generalization and dataset\nquality.",
            "author": [
                "Elior Benarous",
                "Sotiris Anagnostidis",
                "Luca Biggio",
                "Thomas Hofmann"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06224v1",
                "http://arxiv.org/pdf/2311.06224v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06221v1",
            "title": "A Comparison of Lexicon-Based and ML-Based Sentiment Analysis: Are There\n  Outlier Words?",
            "updated": "2023-11-10T18:21:50Z",
            "published": "2023-11-10T18:21:50Z",
            "summary": "Lexicon-based approaches to sentiment analysis of text are based on each word\nor lexical entry having a pre-defined weight indicating its sentiment polarity.\nThese are usually manually assigned but the accuracy of these when compared\nagainst machine leaning based approaches to computing sentiment, are not known.\nIt may be that there are lexical entries whose sentiment values cause a\nlexicon-based approach to give results which are very different to a machine\nlearning approach. In this paper we compute sentiment for more than 150,000\nEnglish language texts drawn from 4 domains using the Hedonometer, a\nlexicon-based technique and Azure, a contemporary machine-learning based\napproach which is part of the Azure Cognitive Services family of APIs which is\neasy to use. We model differences in sentiment scores between approaches for\ndocuments in each domain using a regression and analyse the independent\nvariables (Hedonometer lexical entries) as indicators of each word's importance\nand contribution to the score differences. Our findings are that the importance\nof a word depends on the domain and there are no standout lexical entries which\nsystematically cause differences in sentiment scores.",
            "author": [
                "Siddhant Jaydeep Mahajani",
                "Shashank Srivastava",
                "Alan F. Smeaton"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06221v1",
                "http://arxiv.org/pdf/2311.06221v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06217v1",
            "title": "MultiIoT: Towards Large-scale Multisensory Learning for the Internet of\n  Things",
            "updated": "2023-11-10T18:13:08Z",
            "published": "2023-11-10T18:13:08Z",
            "summary": "The Internet of Things (IoT), the network integrating billions of smart\nphysical devices embedded with sensors, software, and communication\ntechnologies for the purpose of connecting and exchanging data with other\ndevices and systems, is a critical and rapidly expanding component of our\nmodern world. The IoT ecosystem provides a rich source of real-world modalities\nsuch as motion, thermal, geolocation, imaging, depth, sensors, video, and audio\nfor prediction tasks involving the pose, gaze, activities, and gestures of\nhumans as well as the touch, contact, pose, 3D of physical objects. Machine\nlearning presents a rich opportunity to automatically process IoT data at\nscale, enabling efficient inference for impact in understanding human\nwellbeing, controlling physical devices, and interconnecting smart cities. To\ndevelop machine learning technologies for IoT, this paper proposes MultiIoT,\nthe most expansive IoT benchmark to date, encompassing over 1.15 million\nsamples from 12 modalities and 8 tasks. MultiIoT introduces unique challenges\ninvolving (1) learning from many sensory modalities, (2) fine-grained\ninteractions across long temporal ranges, and (3) extreme heterogeneity due to\nunique structure and noise topologies in real-world sensors. We also release a\nset of strong modeling baselines, spanning modality and task-specific methods\nto multisensory and multitask models to encourage future research in\nmultisensory representation learning for IoT.",
            "author": [
                "Shentong Mo",
                "Paul Pu Liang",
                "Russ Salakhutdinov",
                "Louis-Philippe Morency"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06217v1",
                "http://arxiv.org/pdf/2311.06217v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL",
                "cs.CV",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06212v2",
            "title": "Differentiable VQ-VAE's for Robust White Matter Streamline Encodings",
            "updated": "2023-11-18T17:49:26Z",
            "published": "2023-11-10T17:59:43Z",
            "summary": "Given the complex geometry of white matter streamlines, Autoencoders have\nbeen proposed as a dimension-reduction tool to simplify the analysis\nstreamlines in a low-dimensional latent spaces. However, despite these recent\nsuccesses, the majority of encoder architectures only perform dimension\nreduction on single streamlines as opposed to a full bundle of streamlines.\nThis is a severe limitation of the encoder architecture that completely\ndisregards the global geometric structure of streamlines at the expense of\nindividual fibers. Moreover, the latent space may not be well structured which\nleads to doubt into their interpretability. In this paper we propose a novel\nDifferentiable Vector Quantized Variational Autoencoder, which are engineered\nto ingest entire bundles of streamlines as single data-point and provides\nreliable trustworthy encodings that can then be later used to analyze\nstreamlines in the latent space. Comparisons with several state of the art\nAutoencoders demonstrate superior performance in both encoding and synthesis.",
            "author": [
                "Andrew Lizarraga",
                "Brandon Taraku",
                "Edouardo Honig",
                "Ying Nian Wu",
                "Shantanu H. Joshi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06212v2",
                "http://arxiv.org/pdf/2311.06212v2"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06210v1",
            "title": "Optimal Cooperative Multiplayer Learning Bandits with Noisy Rewards and\n  No Communication",
            "updated": "2023-11-10T17:55:44Z",
            "published": "2023-11-10T17:55:44Z",
            "summary": "We consider a cooperative multiplayer bandit learning problem where the\nplayers are only allowed to agree on a strategy beforehand, but cannot\ncommunicate during the learning process. In this problem, each player\nsimultaneously selects an action. Based on the actions selected by all players,\nthe team of players receives a reward. The actions of all the players are\ncommonly observed. However, each player receives a noisy version of the reward\nwhich cannot be shared with other players. Since players receive potentially\ndifferent rewards, there is an asymmetry in the information used to select\ntheir actions. In this paper, we provide an algorithm based on upper and lower\nconfidence bounds that the players can use to select their optimal actions\ndespite the asymmetry in the reward information. We show that this algorithm\ncan achieve logarithmic $O(\\frac{\\log T}{\\Delta_{\\bm{a}}})$ (gap-dependent)\nregret as well as $O(\\sqrt{T\\log T})$ (gap-independent) regret. This is\nasymptotically optimal in $T$. We also show that it performs empirically better\nthan the current state of the art algorithm for this environment.",
            "author": [
                "William Chang",
                "Yuanhao Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06210v1",
                "http://arxiv.org/pdf/2311.06210v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.MA",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06202v1",
            "title": "Deep learning segmentation of fibrous cap in intravascular optical\n  coherence tomography images",
            "updated": "2023-11-10T17:37:52Z",
            "published": "2023-11-10T17:37:52Z",
            "summary": "Thin-cap fibroatheroma (TCFA) is a prominent risk factor for plaque rupture.\nIntravascular optical coherence tomography (IVOCT) enables identification of\nfibrous cap (FC), measurement of FC thicknesses, and assessment of plaque\nvulnerability. We developed a fully-automated deep learning method for FC\nsegmentation. This study included 32,531 images across 227 pullbacks from two\nregistries. Images were semi-automatically labeled using our OCTOPUS with\nexpert editing using established guidelines. We employed preprocessing\nincluding guidewire shadow detection, lumen segmentation, pixel-shifting, and\nGaussian filtering on raw IVOCT (r,theta) images. Data were augmented in a\nnatural way by changing theta in spiral acquisitions and by changing intensity\nand noise values. We used a modified SegResNet and comparison networks to\nsegment FCs. We employed transfer learning from our existing much larger,\nfully-labeled calcification IVOCT dataset to reduce deep-learning training.\nOverall, our method consistently delivered better FC segmentation results\n(Dice: 0.837+/-0.012) than other deep-learning methods. Transfer learning\nreduced training time by 84% and reduced the need for more training samples.\nOur method showed a high level of generalizability, evidenced by\nhighly-consistent segmentations across five-fold cross-validation (sensitivity:\n85.0+/-0.3%, Dice: 0.846+/-0.011) and the held-out test (sensitivity: 84.9%,\nDice: 0.816) sets. In addition, we found excellent agreement of FC thickness\nwith ground truth (2.95+/-20.73 um), giving clinically insignificant bias.\nThere was excellent reproducibility in pre- and post-stenting pullbacks\n(average FC angle: 200.9+/-128.0 deg / 202.0+/-121.1 deg). Our method will be\nuseful for multiple research purposes and potentially for planning stent\ndeployments that avoid placing a stent edge over an FC.",
            "author": [
                "Juhwan Lee",
                "Justin N. Kim",
                "Luis A. P. Dallan",
                "Vladislav N. Zimin",
                "Ammar Hoori",
                "Neda S. Hassani",
                "Mohamed H. E. Makhlouf",
                "Giulio Guagliumi",
                "Hiram G. Bezerra",
                "David L. Wilson"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06202v1",
                "http://arxiv.org/pdf/2311.06202v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06329v1",
            "title": "A Survey of AI Text-to-Image and AI Text-to-Video Generators",
            "updated": "2023-11-10T17:33:58Z",
            "published": "2023-11-10T17:33:58Z",
            "summary": "Text-to-Image and Text-to-Video AI generation models are revolutionary\ntechnologies that use deep learning and natural language processing (NLP)\ntechniques to create images and videos from textual descriptions. This paper\ninvestigates cutting-edge approaches in the discipline of Text-to-Image and\nText-to-Video AI generations. The survey provides an overview of the existing\nliterature as well as an analysis of the approaches used in various studies. It\ncovers data preprocessing techniques, neural network types, and evaluation\nmetrics used in the field. In addition, the paper discusses the challenges and\nlimitations of Text-to-Image and Text-to-Video AI generations, as well as\nfuture research directions. Overall, these models have promising potential for\na wide range of applications such as video production, content creation, and\ndigital marketing.",
            "author": [
                "Aditi Singh"
            ],
            "link": [
                "http://dx.doi.org/10.1109/AIRC57904.2023.10303174",
                "http://arxiv.org/abs/2311.06329v1",
                "http://arxiv.org/pdf/2311.06329v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14702v1",
            "title": "Transdisciplinary AI Education: The Confluence of Curricular and\n  Community Needs in the Instruction of Artificial Intelligence",
            "updated": "2023-11-10T17:26:27Z",
            "published": "2023-11-10T17:26:27Z",
            "summary": "The integration of artificial intelligence (AI) into education has the\npotential to transform the way we learn and teach. In this paper, we examine\nthe current state of AI in education and explore the potential benefits and\nchallenges of incorporating this technology into the classroom. The approaches\ncurrently available for AI education often present students with experiences\nonly focusing on discrete computer science concepts agnostic to a larger\ncurriculum. However, teaching AI must not be siloed or interdisciplinary.\nRather, AI instruction ought to be transdisciplinary, including connections to\nthe broad curriculum and community in which students are learning. This paper\ndelves into the AI program currently in development for Neom Community School\nand the larger Education, Research, and Innovation Sector in Neom, Saudi Arabia\ns new megacity under development. In this program, AI is both taught as a\nsubject and to learn other subjects within the curriculum through the school\nsystems International Baccalaureate (IB) approach, which deploys learning\nthrough Units of Inquiry. This approach to education connects subjects across a\ncurriculum under one major guiding question at a time. The proposed method\noffers a meaningful approach to introducing AI to students throughout these\nUnits of Inquiry, as it shifts AI from a subject that students like or not like\nto a subject that is taught throughout the curriculum.",
            "author": [
                "Roozbeh Aliabadi",
                "Aditi Singh",
                "Eryka Wilson"
            ],
            "link": [
                "http://dx.doi.org/10.1007/978-981-99-7947-9_11",
                "http://arxiv.org/abs/2311.14702v1",
                "http://arxiv.org/pdf/2311.14702v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06192v1",
            "title": "Greedy PIG: Adaptive Integrated Gradients",
            "updated": "2023-11-10T17:16:18Z",
            "published": "2023-11-10T17:16:18Z",
            "summary": "Deep learning has become the standard approach for most machine learning\ntasks. While its impact is undeniable, interpreting the predictions of deep\nlearning models from a human perspective remains a challenge. In contrast to\nmodel training, model interpretability is harder to quantify and pose as an\nexplicit optimization problem. Inspired by the AUC softmax information curve\n(AUC SIC) metric for evaluating feature attribution methods, we propose a\nunified discrete optimization framework for feature attribution and feature\nselection based on subset selection. This leads to a natural adaptive\ngeneralization of the path integrated gradients (PIG) method for feature\nattribution, which we call Greedy PIG. We demonstrate the success of Greedy PIG\non a wide variety of tasks, including image feature attribution, graph\ncompression/explanation, and post-hoc feature selection on tabular data. Our\nresults show that introducing adaptivity is a powerful and versatile method for\nmaking attribution methods more powerful.",
            "author": [
                "Kyriakos Axiotis",
                "Sami Abu-al-haija",
                "Lin Chen",
                "Matthew Fahrbach",
                "Gang Fu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06192v1",
                "http://arxiv.org/pdf/2311.06192v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06190v1",
            "title": "FourierGNN: Rethinking Multivariate Time Series Forecasting from a Pure\n  Graph Perspective",
            "updated": "2023-11-10T17:13:26Z",
            "published": "2023-11-10T17:13:26Z",
            "summary": "Multivariate time series (MTS) forecasting has shown great importance in\nnumerous industries. Current state-of-the-art graph neural network (GNN)-based\nforecasting methods usually require both graph networks (e.g., GCN) and\ntemporal networks (e.g., LSTM) to capture inter-series (spatial) dynamics and\nintra-series (temporal) dependencies, respectively. However, the uncertain\ncompatibility of the two networks puts an extra burden on handcrafted model\ndesigns. Moreover, the separate spatial and temporal modeling naturally\nviolates the unified spatiotemporal inter-dependencies in real world, which\nlargely hinders the forecasting performance. To overcome these problems, we\nexplore an interesting direction of directly applying graph networks and\nrethink MTS forecasting from a pure graph perspective. We first define a novel\ndata structure, hypervariate graph, which regards each series value (regardless\nof variates or timestamps) as a graph node, and represents sliding windows as\nspace-time fully-connected graphs. This perspective considers spatiotemporal\ndynamics unitedly and reformulates classic MTS forecasting into the predictions\non hypervariate graphs. Then, we propose a novel architecture Fourier Graph\nNeural Network (FourierGNN) by stacking our proposed Fourier Graph Operator\n(FGO) to perform matrix multiplications in Fourier space. FourierGNN\naccommodates adequate expressiveness and achieves much lower complexity, which\ncan effectively and efficiently accomplish the forecasting. Besides, our\ntheoretical analysis reveals FGO's equivalence to graph convolutions in the\ntime domain, which further verifies the validity of FourierGNN. Extensive\nexperiments on seven datasets have demonstrated our superior performance with\nhigher efficiency and fewer parameters compared with state-of-the-art methods.",
            "author": [
                "Kun Yi",
                "Qi Zhang",
                "Wei Fan",
                "Hui He",
                "Liang Hu",
                "Pengyang Wang",
                "Ning An",
                "Longbing Cao",
                "Zhendong Niu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06190v1",
                "http://arxiv.org/pdf/2311.06190v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06185v2",
            "title": "An Automated Pipeline for Tumour-Infiltrating Lymphocyte Scoring in\n  Breast Cancer",
            "updated": "2023-11-21T17:42:42Z",
            "published": "2023-11-10T17:06:28Z",
            "summary": "Tumour-infiltrating lymphocytes (TILs) are considered as a valuable\nprognostic markers in both triple-negative and human epidermal growth factor\nreceptor 2 (HER2) positive breast cancer. In this study, we introduce an\ninnovative deep learning pipeline based on the Efficient-UNet architecture to\npredict the TILs score for breast cancer whole-slide images (WSIs). We first\nsegment tumour and stromal regions in order to compute a tumour bulk mask. We\nthen detect TILs within the tumour-associated stroma, generating a TILs score\nby closely mirroring the pathologist's workflow. Our method exhibits\nstate-of-the-art performance in segmenting tumour/stroma areas and TILs\ndetection, as demonstrated by internal cross-validation on the TiGER Challenge\ntraining dataset and evaluation on the final leaderboards. Additionally, our\nTILs score proves competitive in predicting survival outcomes within the same\nchallenge, underscoring the clinical relevance and potential of our automated\nTILs scoring pipeline as a breast cancer prognostic tool.",
            "author": [
                "Adam J Shephard",
                "Mostafa Jahanifar",
                "Ruoyu Wang",
                "Muhammad Dawood",
                "Simon Graham",
                "Kastytis Sidlauskas",
                "Syed Ali Khurram",
                "Nasir M Rajpoot",
                "Shan E Ahmed Raza"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06185v2",
                "http://arxiv.org/pdf/2311.06185v2"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06184v1",
            "title": "Frequency-domain MLPs are More Effective Learners in Time Series\n  Forecasting",
            "updated": "2023-11-10T17:05:13Z",
            "published": "2023-11-10T17:05:13Z",
            "summary": "Time series forecasting has played the key role in different industrial,\nincluding finance, traffic, energy, and healthcare domains. While existing\nliteratures have designed many sophisticated architectures based on RNNs, GNNs,\nor Transformers, another kind of approaches based on multi-layer perceptrons\n(MLPs) are proposed with simple structure, low complexity, and {superior\nperformance}. However, most MLP-based forecasting methods suffer from the\npoint-wise mappings and information bottleneck, which largely hinders the\nforecasting performance. To overcome this problem, we explore a novel direction\nof applying MLPs in the frequency domain for time series forecasting. We\ninvestigate the learned patterns of frequency-domain MLPs and discover their\ntwo inherent characteristic benefiting forecasting, (i) global view: frequency\nspectrum makes MLPs own a complete view for signals and learn global\ndependencies more easily, and (ii) energy compaction: frequency-domain MLPs\nconcentrate on smaller key part of frequency components with compact signal\nenergy. Then, we propose FreTS, a simple yet effective architecture built upon\nFrequency-domain MLPs for Time Series forecasting. FreTS mainly involves two\nstages, (i) Domain Conversion, that transforms time-domain signals into complex\nnumbers of frequency domain; (ii) Frequency Learning, that performs our\nredesigned MLPs for the learning of real and imaginary part of frequency\ncomponents. The above stages operated on both inter-series and intra-series\nscales further contribute to channel-wise and time-wise dependency learning.\nExtensive experiments on 13 real-world benchmarks (including 7 benchmarks for\nshort-term forecasting and 6 benchmarks for long-term forecasting) demonstrate\nour consistent superiority over state-of-the-art methods.",
            "author": [
                "Kun Yi",
                "Qi Zhang",
                "Wei Fan",
                "Shoujin Wang",
                "Pengyang Wang",
                "Hui He",
                "Defu Lian",
                "Ning An",
                "Longbing Cao",
                "Zhendong Niu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06184v1",
                "http://arxiv.org/pdf/2311.06184v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06181v1",
            "title": "Application of neural networks to synchro-Compton blazar emission models",
            "updated": "2023-11-10T16:58:06Z",
            "published": "2023-11-10T16:58:06Z",
            "summary": "Jets from supermassive black holes in the centers of active galaxies are the\nmost powerful persistent sources of electromagnetic radiation in the Universe.\nTo infer the physical conditions in the otherwise out-of-reach regions of\nextragalactic jets we usually rely on fitting of their spectral energy\ndistribution (SED). The calculation of radiative models for the jet non-thermal\nemission usually relies on numerical solvers of coupled partial differential\nequations. In this work machine learning is used to tackle the problem of high\ncomputational complexity in order to significantly reduce the SED model\nevaluation time, which is needed for SED fitting with Bayesian inference\nmethods. We compute SEDs based on the synchrotron self-Compton model for blazar\nemission using the radiation code ATHE${\\nu}$A, and use them to train Neural\nNetworks exploring whether these can replace the original computational\nexpensive code. We find that a Neural Network with Gated Recurrent Unit neurons\ncan effectively replace the ATHE${\\nu}$A leptonic code for this application,\nwhile it can be efficiently coupled with MCMC and nested sampling algorithms\nfor fitting purposes. We demonstrate this through an application to simulated\ndata sets and with an application to observational data. We offer this tool in\nthe community through a public repository. We present a proof-of-concept\napplication of neural networks to blazar science. This is the first step in a\nlist of future applications involving hadronic processes and even larger\nparameter spaces.",
            "author": [
                "A. Tzavellas",
                "G. Vasilopoulos",
                "M. Petropoulou",
                "A. Mastichiadis",
                "S. I. Stathopoulos"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06181v1",
                "http://arxiv.org/pdf/2311.06181v1"
            ],
            "primary_category": "astro-ph.HE",
            "category": [
                "astro-ph.HE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06180v1",
            "title": "Exploring Generative AI assisted feedback writing for students' written\n  responses to a physics conceptual question with prompt engineering and\n  few-shot learning",
            "updated": "2023-11-10T16:57:09Z",
            "published": "2023-11-10T16:57:09Z",
            "summary": "Instructor's feedback plays a critical role in students' development of\nconceptual understanding and reasoning skills. However, grading student written\nresponses and providing personalized feedback can take a substantial amount of\ntime. In this study, we explore using GPT-3.5 to write feedback to student\nwritten responses to conceptual questions with prompt engineering and few-shot\nlearning techniques. In stage one, we used a small portion (n=20) of the\nstudent responses on one conceptual question to iteratively train GPT. Four of\nthe responses paired with human-written feedback were included in the prompt as\nexamples for GPT. We tasked GPT to generate feedback to the other 16 responses,\nand we refined the prompt after several iterations. In stage two, we gave four\nstudent researchers the 16 responses as well as two versions of feedback, one\nwritten by the authors and the other by GPT. Students were asked to rate the\ncorrectness and usefulness of each feedback, and to indicate which one was\ngenerated by GPT. The results showed that students tended to rate the feedback\nby human and GPT equally on correctness, but they all rated the feedback by GPT\nas more useful. Additionally, the successful rates of identifying GPT's\nfeedback were low, ranging from 0.1 to 0.6. In stage three, we tasked GPT to\ngenerate feedback to the rest of the student responses (n=65). The feedback was\nrated by four instructors based on the extent of modification needed if they\nwere to give the feedback to students. All the instructors rated approximately\n70% of the feedback statements needing only minor or no modification. This\nstudy demonstrated the feasibility of using Generative AI as an assistant to\ngenerating feedback for student written responses with only a relatively small\nnumber of examples. An AI assistance can be one of the solutions to\nsubstantially reduce time spent on grading student written responses.",
            "author": [
                "Tong Wan",
                "Zhongzhou Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06180v1",
                "http://arxiv.org/pdf/2311.06180v1"
            ],
            "primary_category": "physics.ed-ph",
            "category": [
                "physics.ed-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06179v3",
            "title": "Cluster Expansion by Transfer Learning from Empirical Potentials",
            "updated": "2023-11-15T13:50:47Z",
            "published": "2023-11-10T16:52:51Z",
            "summary": "Cluster expansions provide effective representations of the potential energy\nlandscape of multicomponent crystalline solids. Notwithstanding major advances\nin cluster expansion implementations, it remains computationally demanding to\nconstruct these expansions for systems of low dimension or with a large number\nof components, such as clusters, interfaces, and multimetallic alloys. We\naddress these challenges by employing transfer learning to accelerate the\ncomputationally demanding step of generating configurational data from first\nprinciples. The proposed approach exploits Bayesian inference to incorporate\nprior knowledge from physics-based or machine-learning empirical potentials,\nenabling one to identify the most informative configurations within a dataset.\nThe efficacy of the method is tested on face-centered cubic Pt:Ni binaries,\nyielding a two- to three-fold reduction in the number of first-principles\ncalculations, while ensuring robust convergence of the energies with low\nstatistical fluctuations.",
            "author": [
                "A. Dana",
                "L. Mu",
                "S. Gelin",
                "S. B. Sinnott",
                "I. Dabo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06179v3",
                "http://arxiv.org/pdf/2311.06179v3"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06176v2",
            "title": "Automatic Report Generation for Histopathology images using pre-trained\n  Vision Transformers",
            "updated": "2023-11-13T23:49:35Z",
            "published": "2023-11-10T16:48:24Z",
            "summary": "Deep learning for histopathology has been successfully used for disease\nclassification, image segmentation and more. However, combining image and text\nmodalities using current state-of-the-art methods has been a challenge due to\nthe high resolution of histopathology images. Automatic report generation for\nhistopathology images is one such challenge. In this work, we show that using\nan existing pre-trained Vision Transformer in a two-step process of first using\nit to encode 4096x4096 sized patches of the Whole Slide Image (WSI) and then\nusing it as the encoder and an LSTM decoder for report generation, we can build\na fairly performant and portable report generation mechanism that takes into\naccount the whole of the high resolution image, instead of just the patches. We\nare also able to use representations from an existing powerful pre-trained\nhierarchical vision transformer and show its usefulness in not just zero shot\nclassification but also for report generation.",
            "author": [
                "Saurav Sengupta",
                "Donald E. Brown"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06176v2",
                "http://arxiv.org/pdf/2311.06176v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14701v1",
            "title": "ChatGPT as Co-Advisor in Scientific Initiation: Action Research with\n  Project-Based Learning in Elementary Education",
            "updated": "2023-11-10T16:41:45Z",
            "published": "2023-11-10T16:41:45Z",
            "summary": "Background: In the contemporary educational landscape, technology has the\npower to drive innovative pedagogical practices. Overcoming the resistance of\nteachers and students to adopting new methods and technologies is a challenge\nthat needs to be addressed. Objectives: To evaluate the effectiveness of\nChatGPT as a co-advisor in research projects and its influence on the\nimplementation of Project-Based Learning (PBL), as well as overcoming\nresistance to the use of new pedagogical methodologies. Design: An\naction-research methodology was employed, including unstructured interviews and\nthe application of questionnaires via Google Forms. Setting and Participants:\nThe research was conducted in an elementary school, involving 353 students and\n16 teachers. Data Collection and Analysis: Data were gathered through\nobservations and notes in meetings and interviews, complemented by electronic\nquestionnaires, with quantitative and qualitative analyses performed via\nMicrosoft Excel and Google Forms. Results: The introduction of ChatGPT as a\npedagogical tool led to increased student engagement and decreased teacher\nresistance, reflected in recognition at local science fairs. Conclusion: The\nstudy confirmed the utility of ChatGPT in school research co-orientation,\nhighlighting its role in facilitating PBL and promoting cultural changes in\neducational practice, with proactive school management identified as a\ncatalysing element in adapting to educational innovations.",
            "author": [
                "Fabiano Villan",
                "Renato P. dos Santos"
            ],
            "link": [
                "http://dx.doi.org/10.17648/acta.scientiae.7474",
                "http://arxiv.org/abs/2311.14701v1",
                "http://arxiv.org/pdf/2311.14701v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.AI",
                "cs.HC",
                "J.4; K.3; I.2"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06170v1",
            "title": "Time Scale Network: A Shallow Neural Network For Time Series Data",
            "updated": "2023-11-10T16:39:55Z",
            "published": "2023-11-10T16:39:55Z",
            "summary": "Time series data is often composed of information at multiple time scales,\nparticularly in biomedical data. While numerous deep learning strategies exist\nto capture this information, many make networks larger, require more data, are\nmore demanding to compute, and are difficult to interpret. This limits their\nusefulness in real-world applications facing even modest computational or data\nconstraints and can further complicate their translation into practice. We\npresent a minimal, computationally efficient Time Scale Network combining the\ntranslation and dilation sequence used in discrete wavelet transforms with\ntraditional convolutional neural networks and back-propagation. The network\nsimultaneously learns features at many time scales for sequence classification\nwith significantly reduced parameters and operations. We demonstrate advantages\nin Atrial Dysfunction detection including: superior accuracy-per-parameter and\naccuracy-per-operation, fast training and inference speeds, and visualization\nand interpretation of learned patterns in atrial dysfunction detection on ECG\nsignals. We also demonstrate impressive performance in seizure prediction using\nEEG signals. Our network isolated a few time scales that could be strategically\nselected to achieve 90.9% accuracy using only 1,133 active parameters and\nconsistently converged on pulsatile waveform shapes. This method does not rest\non any constraints or assumptions regarding signal content and could be\nleveraged in any area of time series analysis dealing with signals containing\nfeatures at many time scales.",
            "author": [
                "Trevor Meyer",
                "Camden Shultz",
                "Najim Dehak",
                "Laureano Moro-Velazquez",
                "Pedro Irazoqui"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06170v1",
                "http://arxiv.org/pdf/2311.06170v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08421v1",
            "title": "Surrogate Neural Networks to Estimate Parametric Sensitivity of Ocean\n  Models",
            "updated": "2023-11-10T16:37:43Z",
            "published": "2023-11-10T16:37:43Z",
            "summary": "Modeling is crucial to understanding the effect of greenhouse gases, warming,\nand ice sheet melting on the ocean. At the same time, ocean processes affect\nphenomena such as hurricanes and droughts. Parameters in the models that cannot\nbe physically measured have a significant effect on the model output. For an\nidealized ocean model, we generated perturbed parameter ensemble data and\ntrained surrogate neural network models. The neural surrogates accurately\npredicted the one-step forward dynamics, of which we then computed the\nparametric sensitivity.",
            "author": [
                "Yixuan Sun",
                "Elizabeth Cucuzzella",
                "Steven Brus",
                "Sri Hari Krishna Narayanan",
                "Balu Nadiga",
                "Luke Van Roekel",
                "Jan H\u00fcckelheim",
                "Sandeep Madireddy"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08421v1",
                "http://arxiv.org/pdf/2311.08421v1"
            ],
            "primary_category": "physics.ao-ph",
            "category": [
                "physics.ao-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06169v1",
            "title": "Deep Fast Vision: A Python Library for Accelerated Deep Transfer\n  Learning Vision Prototyping",
            "updated": "2023-11-10T16:36:49Z",
            "published": "2023-11-10T16:36:49Z",
            "summary": "Deep learning-based vision is characterized by intricate frameworks that\noften necessitate a profound understanding, presenting a barrier to newcomers\nand limiting broad adoption. With many researchers grappling with the\nconstraints of smaller datasets, there's a pronounced reliance on pre-trained\nneural networks, especially for tasks such as image classification. This\nreliance is further intensified in niche imaging areas where obtaining vast\ndatasets is challenging. Despite the widespread use of transfer learning as a\nremedy to the small dataset dilemma, a conspicuous absence of tailored auto-ML\nsolutions persists. Addressing these challenges is \"Deep Fast Vision\", a python\nlibrary that streamlines the deep learning process. This tool offers a\nuser-friendly experience, enabling results through a simple nested dictionary\ndefinition, helping to democratize deep learning for non-experts. Designed for\nsimplicity and scalability, Deep Fast Vision appears as a bridge, connecting\nthe complexities of existing deep learning frameworks with the needs of a\ndiverse user base.",
            "author": [
                "Fabi Prezja"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06169v1",
                "http://arxiv.org/pdf/2311.06169v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06158v1",
            "title": "Language Models can be Logical Solvers",
            "updated": "2023-11-10T16:23:50Z",
            "published": "2023-11-10T16:23:50Z",
            "summary": "Logical reasoning is a fundamental aspect of human intelligence and a key\ncomponent of tasks like problem-solving and decision-making. Recent\nadvancements have enabled Large Language Models (LLMs) to potentially exhibit\nreasoning capabilities, but complex logical reasoning remains a challenge. The\nstate-of-the-art, solver-augmented language models, use LLMs to parse natural\nlanguage logical questions into symbolic representations first and then adopt\nexternal logical solvers to take in the symbolic representations and output the\nanswers. Despite their impressive performance, any parsing errors will\ninevitably result in the failure of the execution of the external logical\nsolver and no answer to the logical questions. In this paper, we introduce\nLoGiPT, a novel language model that directly emulates the reasoning processes\nof logical solvers and bypasses the parsing errors by learning to strict\nadherence to solver syntax and grammar. LoGiPT is fine-tuned on a newly\nconstructed instruction-tuning dataset derived from revealing and refining the\ninvisible reasoning process of deductive solvers. Experimental results on two\npublic deductive reasoning datasets demonstrate that LoGiPT outperforms\nstate-of-the-art solver-augmented LMs and few-shot prompting methods on\ncompetitive LLMs like ChatGPT or GPT-4.",
            "author": [
                "Jiazhan Feng",
                "Ruochen Xu",
                "Junheng Hao",
                "Hiteshi Sharma",
                "Yelong Shen",
                "Dongyan Zhao",
                "Weizhu Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06158v1",
                "http://arxiv.org/pdf/2311.06158v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06153v1",
            "title": "Interpretable Graph Anomaly Detection using Gradient Attention Maps",
            "updated": "2023-11-10T16:14:21Z",
            "published": "2023-11-10T16:14:21Z",
            "summary": "Detecting unusual patterns in graph data is a crucial task in data mining.\nHowever, existing methods often face challenges in consistently achieving\nsatisfactory performance and lack interpretability, which hinders our\nunderstanding of anomaly detection decisions. In this paper, we propose a novel\napproach to graph anomaly detection that leverages the power of\ninterpretability to enhance performance. Specifically, our method extracts an\nattention map derived from gradients of graph neural networks, which serves as\na basis for scoring anomalies. In addition, we conduct theoretical analysis\nusing synthetic data to validate our method and gain insights into its\ndecision-making process. To demonstrate the effectiveness of our method, we\nextensively evaluate our approach against state-of-the-art graph anomaly\ndetection techniques. The results consistently demonstrate the superior\nperformance of our method compared to the baselines.",
            "author": [
                "Yifei Yang",
                "Peng Wang",
                "Xiaofan He",
                "Dongmian Zou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06153v1",
                "http://arxiv.org/pdf/2311.06153v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06152v1",
            "title": "Going beyond persistent homology using persistent homology",
            "updated": "2023-11-10T16:12:35Z",
            "published": "2023-11-10T16:12:35Z",
            "summary": "Representational limits of message-passing graph neural networks (MP-GNNs),\ne.g., in terms of the Weisfeiler-Leman (WL) test for isomorphism, are well\nunderstood. Augmenting these graph models with topological features via\npersistent homology (PH) has gained prominence, but identifying the class of\nattributed graphs that PH can recognize remains open. We introduce a novel\nconcept of color-separating sets to provide a complete resolution to this\nimportant problem. Specifically, we establish the necessary and sufficient\nconditions for distinguishing graphs based on the persistence of their\nconnected components, obtained from filter functions on vertex and edge colors.\nOur constructions expose the limits of vertex- and edge-level PH, proving that\nneither category subsumes the other. Leveraging these theoretical insights, we\npropose RePHINE for learning topological features on graphs. RePHINE\nefficiently combines vertex- and edge-level PH, achieving a scheme that is\nprovably more powerful than both. Integrating RePHINE into MP-GNNs boosts their\nexpressive power, resulting in gains over standard PH on several benchmarks for\ngraph classification.",
            "author": [
                "Johanna Immonen",
                "Amauri H. Souza",
                "Vikas Garg"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06152v1",
                "http://arxiv.org/pdf/2311.06152v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06145v1",
            "title": "An Evaluation of Forensic Facial Recognition",
            "updated": "2023-11-10T16:02:46Z",
            "published": "2023-11-10T16:02:46Z",
            "summary": "Recent advances in machine learning and computer vision have led to reported\nfacial recognition accuracies surpassing human performance. We question if\nthese systems will translate to real-world forensic scenarios in which a\npotentially low-resolution, low-quality, partially-occluded image is compared\nagainst a standard facial database. We describe the construction of a\nlarge-scale synthetic facial dataset along with a controlled facial forensic\nlineup, the combination of which allows for a controlled evaluation of facial\nrecognition under a range of real-world conditions. Using this synthetic\ndataset, and a popular dataset of real faces, we evaluate the accuracy of two\npopular neural-based recognition systems. We find that previously reported face\nrecognition accuracies of more than 95% drop to as low as 65% in this more\nchallenging forensic scenario.",
            "author": [
                "Justin Norman",
                "Shruti Agarwal",
                "Hany Farid"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06145v1",
                "http://arxiv.org/pdf/2311.06145v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06144v1",
            "title": "Multi-Agent Reinforcement Learning for the Low-Level Control of a\n  Quadrotor UAV",
            "updated": "2023-11-10T16:02:38Z",
            "published": "2023-11-10T16:02:38Z",
            "summary": "This paper presents multi-agent reinforcement learning frameworks for the\nlow-level control of a quadrotor UAV. While single-agent reinforcement learning\nhas been successfully applied to quadrotors, training a single monolithic\nnetwork is often data-intensive and time-consuming. To address this, we\ndecompose the quadrotor dynamics into the translational dynamics and the yawing\ndynamics, and assign a reinforcement learning agent to each part for efficient\ntraining and performance improvements. The proposed multi-agent framework for\nquadrotor low-level control that leverages the underlying structures of the\nquadrotor dynamics is a unique contribution. Further, we introduce\nregularization terms to mitigate steady-state errors and to avoid aggressive\ncontrol inputs. Through benchmark studies with sim-to-sim transfer, it is\nillustrated that the proposed multi-agent reinforcement learning substantially\nimproves the convergence rate of the training and the stability of the\ncontrolled dynamics.",
            "author": [
                "Beomyeol Yu",
                "Taeyoung Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06144v1",
                "http://arxiv.org/pdf/2311.06144v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06141v1",
            "title": "Federated Learning Across Decentralized and Unshared Archives for Remote\n  Sensing Image Classification",
            "updated": "2023-11-10T15:58:53Z",
            "published": "2023-11-10T15:58:53Z",
            "summary": "Federated learning (FL) enables the collaboration of multiple deep learning\nmodels to learn from decentralized data archives (i.e., clients) without\naccessing data on clients. Although FL offers ample opportunities in knowledge\ndiscovery from distributed image archives, it is seldom considered in remote\nsensing (RS). In this paper, as a first time in RS, we present a comparative\nstudy of state-of-the-art FL algorithms. To this end, we initially provide a\nsystematic review of the FL algorithms presented in the computer vision\ncommunity for image classification problems, and select several\nstate-of-the-art FL algorithms based on their effectiveness with respect to\ntraining data heterogeneity across clients (known as non-IID data). After\npresenting an extensive overview of the selected algorithms, a theoretical\ncomparison of the algorithms is conducted based on their: 1) local training\ncomplexity; 2) aggregation complexity; 3) learning efficiency; 4) communication\ncost; and 5) scalability in terms of number of clients. As the classification\ntask, we consider multi-label classification (MLC) problem since RS images\ntypically consist of multiple classes, and thus can simultaneously be\nassociated with multi-labels. After the theoretical comparison, experimental\nanalyses are presented to compare them under different decentralization\nscenarios in terms of MLC performance. Based on our comprehensive analyses, we\nfinally derive a guideline for selecting suitable FL algorithms in RS. The code\nof this work will be publicly available at https://git.tu-berlin.de/rsim/FL-RS.",
            "author": [
                "Bar\u0131\u015f B\u00fcy\u00fckta\u015f",
                "Gencer Sumbul",
                "Beg\u00fcm Demir"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06141v1",
                "http://arxiv.org/pdf/2311.06141v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06138v1",
            "title": "Minimum norm interpolation by perceptra: Explicit regularization and\n  implicit bias",
            "updated": "2023-11-10T15:55:47Z",
            "published": "2023-11-10T15:55:47Z",
            "summary": "We investigate how shallow ReLU networks interpolate between known regions.\nOur analysis shows that empirical risk minimizers converge to a minimum norm\ninterpolant as the number of data points and parameters tends to infinity when\na weight decay regularizer is penalized with a coefficient which vanishes at a\nprecise rate as the network width and the number of data points grow. With and\nwithout explicit regularization, we numerically study the implicit bias of\ncommon optimization algorithms towards known minimum norm interpolants.",
            "author": [
                "Jiyoung Park",
                "Ian Pelakh",
                "Stephan Wojtowytsch"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06138v1",
                "http://arxiv.org/pdf/2311.06138v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06134v1",
            "title": "Supernova and solar neutrino searches at DUNE",
            "updated": "2023-11-10T15:51:16Z",
            "published": "2023-11-10T15:51:16Z",
            "summary": "The Deep Underground Neutrino Experiment (DUNE) is a next-generation\nlong-baseline experiment exploiting the liquid argon TPC technology. DUNE will\nhave sensitivity to low energy physics searches, such as the detection of\nsupernova and solar neutrinos. DUNE will consist of four modules of 70-kton\nliquid argon mass in total, placed 1.5 km underground at the Sanford\nUnderground Research Facility in the USA. These modules are being designed\nconsidering the specific requirements of the low energy physics searches. As a\nresult, DUNE will have a unique sensitivity for the detection of electron\nneutrinos from a core-collapse supernova burst, and solar and diffuse supernova\nbackground neutrinos can also be detected.",
            "author": [
                "C. Cuesta"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06134v1",
                "http://arxiv.org/pdf/2311.06134v1"
            ],
            "primary_category": "hep-ex",
            "category": [
                "hep-ex",
                "physics.ins-det"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06130v1",
            "title": "High-dimensional mixed-categorical Gaussian processes with application\n  to multidisciplinary design optimization for a green aircraft",
            "updated": "2023-11-10T15:48:51Z",
            "published": "2023-11-10T15:48:51Z",
            "summary": "Multidisciplinary design optimization (MDO) methods aim at adapting numerical\noptimization techniques to the design of engineering systems involving multiple\ndisciplines. In this context, a large number of mixed continuous, integer, and\ncategorical variables might arise during the optimization process, and\npractical applications involve a significant number of design variables.\nRecently, there has been a growing interest in mixed-categorical metamodels\nbased on Gaussian Process (GP) for Bayesian optimization. In particular, to\nhandle mixed-categorical variables, several existing approaches employ\ndifferent strategies to build the GP. These strategies either use continuous\nkernels, such as the continuous relaxation or the Gower distance-based kernels,\nor direct estimation of the correlation matrix, such as the exponential\nhomoscedastic hypersphere (EHH) or the Homoscedastic Hypersphere (HH) kernel.\nAlthough the EHH and HH kernels are shown to be very efficient and lead to\naccurate GPs, they are based on a large number of hyperparameters. In this\npaper, we address this issue by constructing mixed-categorical GPs with fewer\nhyperparameters using Partial Least Squares (PLS) regression. Our goal is to\ngeneralize Kriging with PLS, commonly used for continuous inputs, to handle\nmixed-categorical inputs. The proposed method is implemented in the open-source\nsoftware SMT and has been efficiently applied to structural and\nmultidisciplinary applications. Our method is used to effectively demonstrate\nthe structural behavior of a cantilever beam and facilitates MDO of a green\naircraft, resulting in a 439-kilogram reduction in the amount of fuel consumed\nduring a single aircraft mission.",
            "author": [
                "Paul Saves",
                "Youssef Diouane",
                "Nathalie Bartoli",
                "Thierry Lefebvre",
                "Joseph Morlier"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06130v1",
                "http://arxiv.org/pdf/2311.06130v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06118v1",
            "title": "Exploring the Efficacy of Base Data Augmentation Methods in Deep\n  Learning-Based Radiograph Classification of Knee Joint Osteoarthritis",
            "updated": "2023-11-10T15:35:00Z",
            "published": "2023-11-10T15:35:00Z",
            "summary": "Diagnosing knee joint osteoarthritis (KOA), a major cause of disability\nworldwide, is challenging due to subtle radiographic indicators and the varied\nprogression of the disease. Using deep learning for KOA diagnosis requires\nbroad, comprehensive datasets. However, obtaining these datasets poses\nsignificant challenges due to patient privacy concerns and data collection\nrestrictions. Additive data augmentation, which enhances data variability,\nemerges as a promising solution. Yet, it's unclear which augmentation\ntechniques are most effective for KOA. This study explored various data\naugmentation methods, including adversarial augmentations, and their impact on\nKOA classification model performance. While some techniques improved\nperformance, others commonly used underperformed. We identified potential\nconfounding regions within the images using adversarial augmentation. This was\nevidenced by our models' ability to classify KL0 and KL4 grades accurately,\nwith the knee joint omitted. This observation suggested a model bias, which\nmight leverage unrelated features for classification currently present in\nradiographs. Interestingly, removing the knee joint also led to an unexpected\nimprovement in KL1 classification accuracy. To better visualize these\nparadoxical effects, we employed Grad-CAM, highlighting the associated regions.\nOur study underscores the need for careful technique selection for improved\nmodel performance and identifying and managing potential confounding regions in\nradiographic KOA deep learning.",
            "author": [
                "Fabi Prezja",
                "Leevi Annala",
                "Sampsa Kiiskinen",
                "Timo Ojala"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06118v1",
                "http://arxiv.org/pdf/2311.06118v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06117v1",
            "title": "Distributionally Robust Skeleton Learning of Discrete Bayesian Networks",
            "updated": "2023-11-10T15:33:19Z",
            "published": "2023-11-10T15:33:19Z",
            "summary": "We consider the problem of learning the exact skeleton of general discrete\nBayesian networks from potentially corrupted data. Building on distributionally\nrobust optimization and a regression approach, we propose to optimize the most\nadverse risk over a family of distributions within bounded Wasserstein distance\nor KL divergence to the empirical distribution. The worst-case risk accounts\nfor the effect of outliers. The proposed approach applies for general\ncategorical random variables without assuming faithfulness, an ordinal\nrelationship or a specific form of conditional distribution. We present\nefficient algorithms and show the proposed methods are closely related to the\nstandard regularized regression approach. Under mild assumptions, we derive\nnon-asymptotic guarantees for successful structure learning with logarithmic\nsample complexities for bounded-degree graphs. Numerical study on synthetic and\nreal datasets validates the effectiveness of our method. Code is available at\nhttps://github.com/DanielLeee/drslbn.",
            "author": [
                "Yeshu Li",
                "Brian D. Ziebart"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06117v1",
                "http://arxiv.org/pdf/2311.06117v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06112v1",
            "title": "Turbulence Scaling from Deep Learning Diffusion Generative Models",
            "updated": "2023-11-10T15:27:07Z",
            "published": "2023-11-10T15:27:07Z",
            "summary": "Complex spatial and temporal structures are inherent characteristics of\nturbulent fluid flows and comprehending them poses a major challenge. This\ncomprehesion necessitates an understanding of the space of turbulent fluid flow\nconfigurations. We employ a diffusion-based generative model to learn the\ndistribution of turbulent vorticity profiles and generate snapshots of\nturbulent solutions to the incompressible Navier-Stokes equations. We consider\nthe inverse cascade in two spatial dimensions and generate diverse turbulent\nsolutions that differ from those in the training dataset. We analyze the\nstatistical scaling properties of the new turbulent profiles, calculate their\nstructure functions, energy power spectrum, velocity probability distribution\nfunction and moments of local energy dissipation. All the learnt scaling\nexponents are consistent with the expected Kolmogorov scaling and have lower\nerrors than the training ones. This agreement with established turbulence\ncharacteristics provides strong evidence of the model's capability to capture\nessential features of real-world turbulence.",
            "author": [
                "Tim Whittaker",
                "Romuald A. Janik",
                "Yaron Oz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06112v1",
                "http://arxiv.org/pdf/2311.06112v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn",
                "cs.LG",
                "nlin.CD"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06110v1",
            "title": "An Interpretable Machine Learning Framework to Understand Bikeshare\n  Demand before and during the COVID-19 Pandemic in New York City",
            "updated": "2023-11-10T15:24:23Z",
            "published": "2023-11-10T15:24:23Z",
            "summary": "In recent years, bikesharing systems have become increasingly popular as\naffordable and sustainable micromobility solutions. Advanced mathematical\nmodels such as machine learning are required to generate good forecasts for\nbikeshare demand. To this end, this study proposes a machine learning modeling\nframework to estimate hourly demand in a large-scale bikesharing system. Two\nExtreme Gradient Boosting models were developed: one using data from before the\nCOVID-19 pandemic (March 2019 to February 2020) and the other using data from\nduring the pandemic (March 2020 to February 2021). Furthermore, a model\ninterpretation framework based on SHapley Additive exPlanations was\nimplemented. Based on the relative importance of the explanatory variables\nconsidered in this study, share of female users and hour of day were the two\nmost important explanatory variables in both models. However, the month\nvariable had higher importance in the pandemic model than in the pre-pandemic\nmodel.",
            "author": [
                "Majbah Uddin",
                "Ho-Ling Hwang",
                "Md Sami Hasnine"
            ],
            "link": [
                "http://dx.doi.org/10.1080/03081060.2023.2201280",
                "http://arxiv.org/abs/2311.06110v1",
                "http://arxiv.org/pdf/2311.06110v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06108v1",
            "title": "Nonparametric consistency for maximum likelihood estimation and\n  clustering based on mixtures of elliptically-symmetric distributions",
            "updated": "2023-11-10T15:20:39Z",
            "published": "2023-11-10T15:20:39Z",
            "summary": "The consistency of the maximum likelihood estimator for mixtures of\nelliptically-symmetric distributions for estimating its population version is\nshown, where the underlying distribution $P$ is nonparametric and does not\nnecessarily belong to the class of mixtures on which the estimator is based. In\na situation where $P$ is a mixture of well enough separated but nonparametric\ndistributions it is shown that the components of the population version of the\nestimator correspond to the well separated components of $P$. This provides\nsome theoretical justification for the use of such estimators for cluster\nanalysis in case that $P$ has well separated subpopulations even if these\nsubpopulations differ from what the mixture model assumes.",
            "author": [
                "Pietro Coretto",
                "Christian Hennig"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06108v1",
                "http://arxiv.org/pdf/2311.06108v1"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "stat.ML",
                "stat.TH",
                "62H30, 62F35"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06105v1",
            "title": "Resolution of similar patterns in a solvable model of unsupervised deep\n  learning with structured data",
            "updated": "2023-11-10T15:16:05Z",
            "published": "2023-11-10T15:16:05Z",
            "summary": "Empirical data, on which deep learning relies, has substantial internal\nstructure, yet prevailing theories often disregard this aspect. Recent research\nhas led to the definition of structured data ensembles, aimed at equipping\nestablished theoretical frameworks with interpretable structural elements, a\npursuit that aligns with the broader objectives of spin glass theory. We\nconsider a one-parameter structured ensemble where data consists of correlated\npairs of patterns, and a simplified model of unsupervised learning, whereby the\ninternal representation of the training set is fixed at each layer. A mean\nfield solution of the model identifies a set of layer-wise recurrence equations\nfor the overlaps between the internal representations of an unseen input and of\nthe training set. The bifurcation diagram of this discrete-time dynamics is\ntopologically inequivalent to the unstructured one, and displays transitions\nbetween different phases, selected by varying the load (the number of training\npairs divided by the width of the network). The network's ability to resolve\ndifferent patterns undergoes a discontinuous transition to a phase where signal\nprocessing along the layers dissipates differential information about an\ninput's proximity to the different patterns in a pair. A critical value of the\nparameter tuning the correlations separates regimes where data structure\nimproves or hampers the identification of a given pair of patterns.",
            "author": [
                "Andrea Baroffio",
                "Pietro Rotondo",
                "Marco Gherardi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06105v1",
                "http://arxiv.org/pdf/2311.06105v1"
            ],
            "primary_category": "cond-mat.dis-nn",
            "category": [
                "cond-mat.dis-nn"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06104v1",
            "title": "Hamiltonian reduction using a convolutional auto-encoder coupled to an\n  Hamiltonian neural network",
            "updated": "2023-11-10T15:15:05Z",
            "published": "2023-11-10T15:15:05Z",
            "summary": "The reduction of Hamiltonian systems aims to build smaller reduced models,\nvalid over a certain range of time and parameters, in order to reduce computing\ntime. By maintaining the Hamiltonian structure in the reduced model, certain\nlong-term stability properties can be preserved. In this paper, we propose a\nnon-linear reduction method for models coming from the spatial discretization\nof partial differential equations: it is based on convolutional auto-encoders\nand Hamiltonian neural networks. Their training is coupled in order to\nsimultaneously learn the encoder-decoder operators and the reduced dynamics.\nSeveral test cases on non-linear wave dynamics show that the method has better\nreduction properties than standard linear Hamiltonian reduction methods.",
            "author": [
                "Rapha\u00ebl C\u00f4te",
                "Emmanuel Franck",
                "Laurent Navoret",
                "Guillaume Steimer",
                "Vincent Vigon"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06104v1",
                "http://arxiv.org/pdf/2311.06104v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06103v1",
            "title": "1-Lipschitz Neural Networks are more expressive with N-Activations",
            "updated": "2023-11-10T15:12:04Z",
            "published": "2023-11-10T15:12:04Z",
            "summary": "A crucial property for achieving secure, trustworthy and interpretable deep\nlearning systems is their robustness: small changes to a system's inputs should\nnot result in large changes to its outputs. Mathematically, this means one\nstrives for networks with a small Lipschitz constant. Several recent works have\nfocused on how to construct such Lipschitz networks, typically by imposing\nconstraints on the weight matrices. In this work, we study an orthogonal\naspect, namely the role of the activation function. We show that commonly used\nactivation functions, such as MaxMin, as well as all piece-wise linear ones\nwith two segments unnecessarily restrict the class of representable functions,\neven in the simplest one-dimensional setting. We furthermore introduce the new\nN-activation function that is provably more expressive than currently popular\nactivation functions. We provide code at\nhttps://github.com/berndprach/NActivation.",
            "author": [
                "Bernd Prach",
                "Christoph H. Lampert"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06103v1",
                "http://arxiv.org/pdf/2311.06103v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06102v1",
            "title": "Making LLMs Worth Every Penny: Resource-Limited Text Classification in\n  Banking",
            "updated": "2023-11-10T15:10:36Z",
            "published": "2023-11-10T15:10:36Z",
            "summary": "Standard Full-Data classifiers in NLP demand thousands of labeled examples,\nwhich is impractical in data-limited domains. Few-shot methods offer an\nalternative, utilizing contrastive learning techniques that can be effective\nwith as little as 20 examples per class. Similarly, Large Language Models\n(LLMs) like GPT-4 can perform effectively with just 1-5 examples per class.\nHowever, the performance-cost trade-offs of these methods remain underexplored,\na critical concern for budget-limited organizations. Our work addresses this\ngap by studying the aforementioned approaches over the Banking77 financial\nintent detection dataset, including the evaluation of cutting-edge LLMs by\nOpenAI, Cohere, and Anthropic in a comprehensive set of few-shot scenarios. We\ncomplete the picture with two additional methods: first, a cost-effective\nquerying method for LLMs based on retrieval-augmented generation (RAG), able to\nreduce operational costs multiple times compared to classic few-shot\napproaches, and second, a data augmentation method using GPT-4, able to improve\nperformance in data-limited scenarios. Finally, to inspire future research, we\nprovide a human expert's curated subset of Banking77, along with extensive\nerror analysis.",
            "author": [
                "Lefteris Loukas",
                "Ilias Stogiannidis",
                "Odysseas Diamantopoulos",
                "Prodromos Malakasiotis",
                "Stavros Vassos"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3604237.3626891",
                "http://arxiv.org/abs/2311.06102v1",
                "http://arxiv.org/pdf/2311.06102v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06101v1",
            "title": "In-Context Learning for MIMO Equalization Using Transformer-Based\n  Sequence Models",
            "updated": "2023-11-10T15:09:04Z",
            "published": "2023-11-10T15:09:04Z",
            "summary": "Large pre-trained sequence models, such as transformer-based architectures,\nhave been recently shown to have the capacity to carry out in-context learning\n(ICL). In ICL, a decision on a new input is made via a direct mapping of the\ninput and of a few examples from the given task, serving as the task's context,\nto the output variable. No explicit updates of model parameters are needed to\ntailor the decision to a new task. Pre-training, which amounts to a form of\nmeta-learning, is based on the observation of examples from several related\ntasks. Prior work has shown ICL capabilities for linear regression. In this\nstudy, we leverage ICL to address the inverse problem of multiple-input and\nmultiple-output (MIMO) equalization based on a context given by pilot symbols.\nA task is defined by the unknown fading channel and by the signal-to-noise\nratio (SNR) level, which may be known. To highlight the practical potential of\nthe approach, we allow for the presence of quantization of the received\nsignals. We demonstrate via numerical results that transformer-based ICL has a\nthreshold behavior, whereby, as the number of pre-training tasks grows, the\nperformance switches from that of a minimum mean squared error (MMSE) equalizer\nwith a prior determined by the pre-trained tasks to that of an MMSE equalizer\nwith the true data-generating prior.",
            "author": [
                "Matteo Zecchin",
                "Kai Yu",
                "Osvaldo Simeone"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06101v1",
                "http://arxiv.org/pdf/2311.06101v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "cs.AI",
                "cs.LG",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06095v1",
            "title": "Dual input stream transformer for eye-tracking line assignment",
            "updated": "2023-11-10T14:53:39Z",
            "published": "2023-11-10T14:53:39Z",
            "summary": "We introduce a novel Dual Input Stream Transformer (DIST) for the challenging\nproblem of assigning fixation points from eye-tracking data collected during\npassage reading to the line of text that the reader was actually focused on.\nThis post-processing step is crucial for analysis of the reading data due to\nthe presence of noise in the form of vertical drift. We evaluate DIST against\nnine classical approaches on a comprehensive suite of nine diverse datasets,\nand demonstrate DIST's superiority. By combining multiple instances of the DIST\nmodel in an ensemble we achieve an average accuracy of 98.5\\% across all\ndatasets. Our approach presents a significant step towards addressing the\nbottleneck of manual line assignment in reading research. Through extensive\nmodel analysis and ablation studies, we identify key factors that contribute to\nDIST's success, including the incorporation of line overlap features and the\nuse of a second input stream. Through evaluation on a set of diverse datasets\nwe demonstrate that DIST is robust to various experimental setups, making it a\nsafe first choice for practitioners in the field.",
            "author": [
                "Thomas M. Mercier",
                "Marcin Budka",
                "Martin R. Vasilev",
                "Julie A. Kirkby",
                "Bernhard Angele",
                "Timothy J. Slattery"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06095v1",
                "http://arxiv.org/pdf/2311.06095v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "91Cxx",
                "J.4"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06090v1",
            "title": "Regressions on quantum neural networks at maximal expressivity",
            "updated": "2023-11-10T14:43:24Z",
            "published": "2023-11-10T14:43:24Z",
            "summary": "We analyze the expressivity of a universal deep neural network that can be\norganized as a series of nested qubit rotations, accomplished by adjustable\ndata re-uploads. While the maximal expressive power increases with the depth of\nthe network and the number of qubits, it is fundamentally bounded by the data\nencoding mechanism. Focusing on regression problems, we systematically\ninvestigate the expressivity limits for different measurements and\narchitectures. The presence of entanglement, either by entangling layers or\nglobal measurements, saturate towards this bound. In these cases, entanglement\nleads to an enhancement of the approximation capabilities of the network\ncompared to local readouts of the individual qubits in non-entangling networks.\nWe attribute this enhancement to a larger survival set of Fourier harmonics\nwhen decomposing the output signal.",
            "author": [
                "Iv\u00e1n Panadero",
                "Yue Ban",
                "Hilario Espin\u00f3s",
                "Ricardo Puebla",
                "Jorge Casanova",
                "Erik Torrontegui"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06090v1",
                "http://arxiv.org/pdf/2311.06090v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06084v1",
            "title": "Perceptual impact of the loss function on deep-learning image coding\n  performance",
            "updated": "2023-11-10T14:33:03Z",
            "published": "2023-11-10T14:33:03Z",
            "summary": "Nowadays, deep-learning image coding solutions have shown similar or better\ncompression efficiency than conventional solutions based on hand-crafted\ntransforms and spatial prediction techniques. These deep-learning codecs\nrequire a large training set of images and a training methodology to obtain a\nsuitable model (set of parameters) for efficient compression. The training is\nperformed with an optimization algorithm which provides a way to minimize the\nloss function. Therefore, the loss function plays a key role in the overall\nperformance and includes a differentiable quality metric that attempts to mimic\nhuman perception. The main objective of this paper is to study the perceptual\nimpact of several image quality metrics that can be used in the loss function\nof the training process, through a crowdsourcing subjective image quality\nassessment study. From this study, it is possible to conclude that the choice\nof the quality metric is critical for the perceptual performance of the\ndeep-learning codec and that can vary depending on the image content.",
            "author": [
                "Shima Mohammadi",
                "Joao Ascenso"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06084v1",
                "http://arxiv.org/pdf/2311.06084v1"
            ],
            "primary_category": "cs.MM",
            "category": [
                "cs.MM",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06079v1",
            "title": "Enhancing Rock Image Segmentation in Digital Rock Physics: A Fusion of\n  Generative AI and State-of-the-Art Neural Networks",
            "updated": "2023-11-10T14:24:50Z",
            "published": "2023-11-10T14:24:50Z",
            "summary": "In digital rock physics, analysing microstructures from CT and SEM scans is\ncrucial for estimating properties like porosity and pore connectivity.\nTraditional segmentation methods like thresholding and CNNs often fall short in\naccurately detailing rock microstructures and are prone to noise. U-Net\nimproved segmentation accuracy but required many expert-annotated samples, a\nlaborious and error-prone process due to complex pore shapes. Our study\nemployed an advanced generative AI model, the diffusion model, to overcome\nthese limitations. This model generated a vast dataset of CT/SEM and binary\nsegmentation pairs from a small initial dataset. We assessed the efficacy of\nthree neural networks: U-Net, Attention-U-net, and TransUNet, for segmenting\nthese enhanced images. The diffusion model proved to be an effective data\naugmentation technique, improving the generalization and robustness of deep\nlearning models. TransU-Net, incorporating Transformer structures, demonstrated\nsuperior segmentation accuracy and IoU metrics, outperforming both U-Net and\nAttention-U-net. Our research advances rock image segmentation by combining the\ndiffusion model with cutting-edge neural networks, reducing dependency on\nextensive expert data and boosting segmentation accuracy and robustness.\nTransU-Net sets a new standard in digital rock physics, paving the way for\nfuture geoscience and engineering breakthroughs.",
            "author": [
                "Zhaoyang Ma",
                "Xupeng He",
                "Hyung Kwak",
                "Jun Gao",
                "Shuyu Sun",
                "Bicheng Yan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06079v1",
                "http://arxiv.org/pdf/2311.06079v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06074v1",
            "title": "Two-compartment neuronal spiking model expressing brain-state specific\n  apical-amplification, -isolation and -drive regimes",
            "updated": "2023-11-10T14:16:46Z",
            "published": "2023-11-10T14:16:46Z",
            "summary": "There is mounting experimental evidence that brain-state specific neural\nmechanisms supported by connectomic architectures serve to combine past and\ncontextual knowledge with current, incoming flow of evidence (e.g. from sensory\nsystems). Such mechanisms are distributed across multiple spatial and temporal\nscales and require dedicated support at the levels of individual neurons and\nsynapses. A prominent feature in the neocortex is the structure of large, deep\npyramidal neurons which show a peculiar separation between an apical dendritic\ncompartment and a basal dentritic/peri-somatic compartment, with distinctive\npatterns of incoming connections and brain-state specific activation\nmechanisms, namely apical-amplification, -isolation and -drive associated to\nthe wakefulness, deeper NREM sleep stages and REM sleep. The cognitive roles of\napical mechanisms have been demonstrated in behaving animals. In contrast,\nclassical models of learning spiking networks are based on single compartment\nneurons that miss the description of mechanisms to combine apical and\nbasal/somatic information. This work aims to provide the computational\ncommunity with a two-compartment spiking neuron model which includes features\nthat are essential for supporting brain-state specific learning and with a\npiece-wise linear transfer function (ThetaPlanes) at highest abstraction level\nto be used in large scale bio-inspired artificial intelligence systems. A\nmachine learning algorithm, constrained by a set of fitness functions, selected\nthe parameters defining neurons expressing the desired apical mechanisms.",
            "author": [
                "Elena Pastorelli",
                "Alper Yegenoglu",
                "Nicole Kolodziej",
                "Willem Wybo",
                "Francesco Simula",
                "Sandra Diaz",
                "Johan Frederik Storm",
                "Pier Stanislao Paolucci"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06074v1",
                "http://arxiv.org/pdf/2311.06074v1"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06070v1",
            "title": "Learning-Based Biharmonic Augmentation for Point Cloud Classification",
            "updated": "2023-11-10T14:04:49Z",
            "published": "2023-11-10T14:04:49Z",
            "summary": "Point cloud datasets often suffer from inadequate sample sizes in comparison\nto image datasets, making data augmentation challenging. While traditional\nmethods, like rigid transformations and scaling, have limited potential in\nincreasing dataset diversity due to their constraints on altering individual\nsample shapes, we introduce the Biharmonic Augmentation (BA) method. BA is a\nnovel and efficient data augmentation technique that diversifies point cloud\ndata by imposing smooth non-rigid deformations on existing 3D structures. This\napproach calculates biharmonic coordinates for the deformation function and\nlearns diverse deformation prototypes. Utilizing a CoefNet, our method predicts\ncoefficients to amalgamate these prototypes, ensuring comprehensive\ndeformation. Moreover, we present AdvTune, an advanced online augmentation\nsystem that integrates adversarial training. This system synergistically\nrefines the CoefNet and the classification network, facilitating the automated\ncreation of adaptive shape deformations contingent on the learner status.\nComprehensive experimental analysis validates the superiority of Biharmonic\nAugmentation, showcasing notable performance improvements over prevailing point\ncloud augmentation techniques across varied network designs.",
            "author": [
                "Jiacheng Wei",
                "Guosheng Lin",
                "Henghui Ding",
                "Jie Hu",
                "Kim-Hui Yap"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06070v1",
                "http://arxiv.org/pdf/2311.06070v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06067v1",
            "title": "Attributes Grouping and Mining Hashing for Fine-Grained Image Retrieval",
            "updated": "2023-11-10T14:01:56Z",
            "published": "2023-11-10T14:01:56Z",
            "summary": "In recent years, hashing methods have been popular in the large-scale media\nsearch for low storage and strong representation capabilities. To describe\nobjects with similar overall appearance but subtle differences, more and more\nstudies focus on hashing-based fine-grained image retrieval. Existing hashing\nnetworks usually generate both local and global features through attention\nguidance on the same deep activation tensor, which limits the diversity of\nfeature representations. To handle this limitation, we substitute convolutional\ndescriptors for attention-guided features and propose an Attributes Grouping\nand Mining Hashing (AGMH), which groups and embeds the category-specific visual\nattributes in multiple descriptors to generate a comprehensive feature\nrepresentation for efficient fine-grained image retrieval. Specifically, an\nAttention Dispersion Loss (ADL) is designed to force the descriptors to attend\nto various local regions and capture diverse subtle details. Moreover, we\npropose a Stepwise Interactive External Attention (SIEA) to mine critical\nattributes in each descriptor and construct correlations between fine-grained\nattributes and objects. The attention mechanism is dedicated to learning\ndiscrete attributes, which will not cost additional computations in hash codes\ngeneration. Finally, the compact binary codes are learned by preserving\npairwise similarities. Experimental results demonstrate that AGMH consistently\nyields the best performance against state-of-the-art methods on fine-grained\nbenchmark datasets.",
            "author": [
                "Xin Lu",
                "Shikun Chen",
                "Yichao Cao",
                "Xin Zhou",
                "Xiaobo Lu"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3581783.3612043",
                "http://arxiv.org/abs/2311.06067v1",
                "http://arxiv.org/pdf/2311.06067v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06066v1",
            "title": "Lidar-based Norwegian tree species detection using deep learning",
            "updated": "2023-11-10T14:01:05Z",
            "published": "2023-11-10T14:01:05Z",
            "summary": "Background: The mapping of tree species within Norwegian forests is a\ntime-consuming process, involving forest associations relying on manual\nlabeling by experts. The process can involve both aerial imagery, personal\nfamiliarity, or on-scene references, and remote sensing data. The\nstate-of-the-art methods usually use high resolution aerial imagery with\nsemantic segmentation methods. Methods: We present a deep learning based tree\nspecies classification model utilizing only lidar (Light Detection And Ranging)\ndata. The lidar images are segmented into four classes (Norway Spruce, Scots\nPine, Birch, background) with a U-Net based network. The model is trained with\nfocal loss over partial weak labels. A major benefit of the approach is that\nboth the lidar imagery and the base map for the labels have free and open\naccess. Results: Our tree species classification model achieves a\nmacro-averaged F1 score of 0.70 on an independent validation with National\nForest Inventory (NFI) in-situ sample plots. That is close to, but below the\nperformance of aerial, or aerial and lidar combined models.",
            "author": [
                "Martijn Vermeer",
                "Jacob Alexander Hay",
                "David V\u00f6lgyes",
                "Zs\u00f3fia Koma",
                "Johannes Breidenbach",
                "Daniele Stefano Maria Fantin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06066v1",
                "http://arxiv.org/pdf/2311.06066v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06062v1",
            "title": "Practical Membership Inference Attacks against Fine-tuned Large Language\n  Models via Self-prompt Calibration",
            "updated": "2023-11-10T13:55:05Z",
            "published": "2023-11-10T13:55:05Z",
            "summary": "Membership Inference Attacks (MIA) aim to infer whether a target data record\nhas been utilized for model training or not. Prior attempts have quantified the\nprivacy risks of language models (LMs) via MIAs, but there is still no\nconsensus on whether existing MIA algorithms can cause remarkable privacy\nleakage on practical Large Language Models (LLMs). Existing MIAs designed for\nLMs can be classified into two categories: reference-free and reference-based\nattacks. They are both based on the hypothesis that training records\nconsistently strike a higher probability of being sampled. Nevertheless, this\nhypothesis heavily relies on the overfitting of target models, which will be\nmitigated by multiple regularization methods and the generalization of LLMs.\nThe reference-based attack seems to achieve promising effectiveness in LLMs,\nwhich measures a more reliable membership signal by comparing the probability\ndiscrepancy between the target model and the reference model. However, the\nperformance of reference-based attack is highly dependent on a reference\ndataset that closely resembles the training dataset, which is usually\ninaccessible in the practical scenario. Overall, existing MIAs are unable to\neffectively unveil privacy leakage over practical fine-tuned LLMs that are\noverfitting-free and private. We propose a Membership Inference Attack based on\nSelf-calibrated Probabilistic Variation (SPV-MIA). Specifically, since\nmemorization in LLMs is inevitable during the training process and occurs\nbefore overfitting, we introduce a more reliable membership signal,\nprobabilistic variation, which is based on memorization rather than\noverfitting. Furthermore, we introduce a self-prompt approach, which constructs\nthe dataset to fine-tune the reference model by prompting the target LLM\nitself. In this manner, the adversary can collect a dataset with a similar\ndistribution from public APIs.",
            "author": [
                "Wenjie Fu",
                "Huandong Wang",
                "Chen Gao",
                "Guanghua Liu",
                "Yong Li",
                "Tao Jiang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06062v1",
                "http://arxiv.org/pdf/2311.06062v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06059v1",
            "title": "Improved Positional Encoding for Implicit Neural Representation based\n  Compact Data Representation",
            "updated": "2023-11-10T13:47:21Z",
            "published": "2023-11-10T13:47:21Z",
            "summary": "Positional encodings are employed to capture the high frequency information\nof the encoded signals in implicit neural representation (INR). In this paper,\nwe propose a novel positional encoding method which improves the reconstruction\nquality of the INR. The proposed embedding method is more advantageous for the\ncompact data representation because it has a greater number of frequency basis\nthan the existing methods. Our experiments shows that the proposed method\nachieves significant gain in the rate-distortion performance without\nintroducing any additional complexity in the compression task and higher\nreconstruction quality in novel view synthesis.",
            "author": [
                "Bharath Bhushan Damodaran",
                "Francois Schnitzler",
                "Anne Lambert",
                "Pierre Hellier"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06059v1",
                "http://arxiv.org/pdf/2311.06059v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06057v1",
            "title": "Ulcerative Colitis Mayo Endoscopic Scoring Classification with Active\n  Learning and Generative Data Augmentation",
            "updated": "2023-11-10T13:42:21Z",
            "published": "2023-11-10T13:42:21Z",
            "summary": "Endoscopic imaging is commonly used to diagnose Ulcerative Colitis (UC) and\nclassify its severity. It has been shown that deep learning based methods are\neffective in automated analysis of these images and can potentially be used to\naid medical doctors. Unleashing the full potential of these methods depends on\nthe availability of large amount of labeled images; however, obtaining and\nlabeling these images are quite challenging. In this paper, we propose a active\nlearning based generative augmentation method. The method involves generating a\nlarge number of synthetic samples by training using a small dataset consisting\nof real endoscopic images. The resulting data pool is narrowed down by using\nactive learning methods to select the most informative samples, which are then\nused to train a classifier. We demonstrate the effectiveness of our method\nthrough experiments on a publicly available endoscopic image dataset. The\nresults show that using synthesized samples in conjunction with active learning\nleads to improved classification performance compared to using only the\noriginal labeled examples and the baseline classification performance of 68.1%\nincreases to 74.5% in terms of Quadratic Weighted Kappa (QWK) Score. Another\nobservation is that, attaining equivalent performance using only real data\nnecessitated three times higher number of images.",
            "author": [
                "\u00dcmit Mert \u00c7a\u011flar",
                "Alperen \u0130nci",
                "O\u011fuz Hano\u011flu",
                "G\u00f6rkem Polat",
                "Alptekin Temizel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06057v1",
                "http://arxiv.org/pdf/2311.06057v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG",
                "I.2.1; I.4.9"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06056v1",
            "title": "Learning Contrastive Self-Distillation for Ultra-Fine-Grained Visual\n  Categorization Targeting Limited Samples",
            "updated": "2023-11-10T13:39:47Z",
            "published": "2023-11-10T13:39:47Z",
            "summary": "In the field of intelligent multimedia analysis, ultra-fine-grained visual\ncategorization (Ultra-FGVC) plays a vital role in distinguishing intricate\nsubcategories within broader categories. However, this task is inherently\nchallenging due to the complex granularity of category subdivisions and the\nlimited availability of data for each category. To address these challenges,\nthis work proposes CSDNet, a pioneering framework that effectively explores\ncontrastive learning and self-distillation to learn discriminative\nrepresentations specifically designed for Ultra-FGVC tasks. CSDNet comprises\nthree main modules: Subcategory-Specific Discrepancy Parsing (SSDP), Dynamic\nDiscrepancy Learning (DDL), and Subcategory-Specific Discrepancy Transfer\n(SSDT), which collectively enhance the generalization of deep models across\ninstance, feature, and logit prediction levels. To increase the diversity of\ntraining samples, the SSDP module introduces augmented samples from different\nviewpoints to spotlight subcategory-specific discrepancies. Simultaneously, the\nproposed DDL module stores historical intermediate features by a dynamic memory\nqueue, which optimizes the feature learning space through iterative contrastive\nlearning. Furthermore, the SSDT module is developed by a novel\nself-distillation paradigm at the logit prediction level of raw and augmented\nsamples, which effectively distills more subcategory-specific discrepancies\nknowledge from the inherent structure of limited training data without\nrequiring additional annotations. Experimental results demonstrate that CSDNet\noutperforms current state-of-the-art Ultra-FGVC methods, emphasizing its\npowerful efficacy and adaptability in addressing Ultra-FGVC tasks.",
            "author": [
                "Ziye Fang",
                "Xin Jiang",
                "Hao Tang",
                "Zechao Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06056v1",
                "http://arxiv.org/pdf/2311.06056v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06054v1",
            "title": "Refining the ONCE Benchmark with Hyperparameter Tuning",
            "updated": "2023-11-10T13:39:07Z",
            "published": "2023-11-10T13:39:07Z",
            "summary": "In response to the growing demand for 3D object detection in applications\nsuch as autonomous driving, robotics, and augmented reality, this work focuses\non the evaluation of semi-supervised learning approaches for point cloud data.\nThe point cloud representation provides reliable and consistent observations\nregardless of lighting conditions, thanks to advances in LiDAR sensors. Data\nannotation is of paramount importance in the context of LiDAR applications, and\nautomating 3D data annotation with semi-supervised methods is a pivotal\nchallenge that promises to reduce the associated workload and facilitate the\nemergence of cost-effective LiDAR solutions. Nevertheless, the task of\nsemi-supervised learning in the context of unordered point cloud data remains\nformidable due to the inherent sparsity and incomplete shapes that hinder the\ngeneration of accurate pseudo-labels. In this study, we consider these\nchallenges by posing the question: \"To what extent does unlabelled data\ncontribute to the enhancement of model performance?\" We show that improvements\nfrom previous semi-supervised methods may not be as profound as previously\nthought. Our results suggest that simple grid search hyperparameter tuning\napplied to a supervised model can lead to state-of-the-art performance on the\nONCE dataset, while the contribution of unlabelled data appears to be\ncomparatively less exceptional.",
            "author": [
                "Maksim Golyadkin",
                "Alexander Gambashidze",
                "Ildar Nurgaliev",
                "Ilya Makarov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06054v1",
                "http://arxiv.org/pdf/2311.06054v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06049v1",
            "title": "Privacy-Preserving Individual-Level COVID-19 Infection Prediction via\n  Federated Graph Learning",
            "updated": "2023-11-10T13:22:14Z",
            "published": "2023-11-10T13:22:14Z",
            "summary": "Accurately predicting individual-level infection state is of great value\nsince its essential role in reducing the damage of the epidemic. However, there\nexists an inescapable risk of privacy leakage in the fine-grained user mobility\ntrajectories required by individual-level infection prediction. In this paper,\nwe focus on developing a framework of privacy-preserving individual-level\ninfection prediction based on federated learning (FL) and graph neural networks\n(GNN). We propose Falcon, a Federated grAph Learning method for\nprivacy-preserving individual-level infeCtion predictiON. It utilizes a novel\nhypergraph structure with spatio-temporal hyperedges to describe the complex\ninteractions between individuals and locations in the contagion process. By\norganically combining the FL framework with hypergraph neural networks, the\ninformation propagation process of the graph machine learning is able to be\ndivided into two stages distributed on the server and the clients,\nrespectively, so as to effectively protect user privacy while transmitting\nhigh-level information. Furthermore, it elaborately designs a differential\nprivacy perturbation mechanism as well as a plausible pseudo location\ngeneration approach to preserve user privacy in the graph structure. Besides,\nit introduces a cooperative coupling mechanism between the individual-level\nprediction model and an additional region-level model to mitigate the\ndetrimental impacts caused by the injected obfuscation mechanisms. Extensive\nexperimental results show that our methodology outperforms state-of-the-art\nalgorithms and is able to protect user privacy against actual privacy attacks.\nOur code and datasets are available at the link:\nhttps://github.com/wjfu99/FL-epidemic.",
            "author": [
                "Wenjie Fu",
                "Huandong Wang",
                "Chen Gao",
                "Guanghua Liu",
                "Yong Li",
                "Tao Jiang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06049v1",
                "http://arxiv.org/pdf/2311.06049v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.10756v1",
            "title": "Earnings Prediction Using Recurrent Neural Networks",
            "updated": "2023-11-10T13:04:34Z",
            "published": "2023-11-10T13:04:34Z",
            "summary": "Firm disclosures about future prospects are crucial for corporate valuation\nand compliance with global regulations, such as the EU's MAR and the US's SEC\nRule 10b-5 and RegFD. To comply with disclosure obligations, issuers must\nidentify nonpublic information with potential material impact on security\nprices as only new, relevant and unexpected information materially affects\nprices in efficient markets. Financial analysts, assumed to represent public\nknowledge on firms' earnings prospects, face limitations in offering\ncomprehensive coverage and unbiased estimates. This study develops a neural\nnetwork to forecast future firm earnings, using four decades of financial data,\naddressing analysts' coverage gaps and potentially revealing hidden insights.\nThe model avoids selectivity and survivorship biases as it allows for missing\ndata. Furthermore, the model is able to produce both fiscal-year-end and\nquarterly earnings predictions. Its performance surpasses benchmark models from\nthe academic literature by a wide margin and outperforms analysts' forecasts\nfor fiscal-year-end earnings predictions.",
            "author": [
                "Moritz Scherrmann",
                "Ralf Elsas"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10756v1",
                "http://arxiv.org/pdf/2311.10756v1"
            ],
            "primary_category": "q-fin.ST",
            "category": [
                "q-fin.ST",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06043v1",
            "title": "Deep learning for 3D Object Detection and Tracking in Autonomous\n  Driving: A Brief Survey",
            "updated": "2023-11-10T13:03:37Z",
            "published": "2023-11-10T13:03:37Z",
            "summary": "Object detection and tracking are vital and fundamental tasks for autonomous\ndriving, aiming at identifying and locating objects from those predefined\ncategories in a scene. 3D point cloud learning has been attracting more and\nmore attention among all other forms of self-driving data. Currently, there are\nmany deep learning methods for 3D object detection. However, the tasks of\nobject detection and tracking for point clouds still need intensive study due\nto the unique characteristics of point cloud data. To help get a good grasp of\nthe present situation of this research, this paper shows recent advances in\ndeep learning methods for 3D object detection and tracking.",
            "author": [
                "Yang Peng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06043v1",
                "http://arxiv.org/pdf/2311.06043v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07598v1",
            "title": "Multi-Label Topic Model for Financial Textual Data",
            "updated": "2023-11-10T12:56:07Z",
            "published": "2023-11-10T12:56:07Z",
            "summary": "This paper presents a multi-label topic model for financial texts like ad-hoc\nannouncements, 8-K filings, finance related news or annual reports. I train the\nmodel on a new financial multi-label database consisting of 3,044 German ad-hoc\nannouncements that are labeled manually using 20 predefined, economically\nmotivated topics. The best model achieves a macro F1 score of more than 85%.\nTranslating the data results in an English version of the model with similar\nperformance. As application of the model, I investigate differences in stock\nmarket reactions across topics. I find evidence for strong positive or negative\nmarket reactions for some topics, like announcements of new Large Scale\nProjects or Bankruptcy Filings, while I do not observe significant price\neffects for some other topics. Furthermore, in contrast to previous studies,\nthe multi-label structure of the model allows to analyze the effects of\nco-occurring topics on stock market reactions. For many cases, the reaction to\na specific topic depends heavily on the co-occurrence with other topics. For\nexample, if allocated capital from a Seasoned Equity Offering (SEO) is used for\nrestructuring a company in the course of a Bankruptcy Proceeding, the market\nreacts positively on average. However, if that capital is used for covering\nunexpected, additional costs from the development of new drugs, the SEO implies\nnegative reactions on average.",
            "author": [
                "Moritz Scherrmann"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07598v1",
                "http://arxiv.org/pdf/2311.07598v1"
            ],
            "primary_category": "q-fin.ST",
            "category": [
                "q-fin.ST",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06038v1",
            "title": "2D Image head pose estimation via latent space regression under\n  occlusion settings",
            "updated": "2023-11-10T12:53:02Z",
            "published": "2023-11-10T12:53:02Z",
            "summary": "Head orientation is a challenging Computer Vision problem that has been\nextensively researched having a wide variety of applications. However, current\nstate-of-the-art systems still underperform in the presence of occlusions and\nare unreliable for many task applications in such scenarios. This work proposes\na novel deep learning approach for the problem of head pose estimation under\nocclusions. The strategy is based on latent space regression as a fundamental\nkey to better structure the problem for occluded scenarios. Our model surpasses\nseveral state-of-the-art methodologies for occluded HPE, and achieves similar\naccuracy for non-occluded scenarios. We demonstrate the usefulness of the\nproposed approach with: (i) two synthetically occluded versions of the BIWI and\nAFLW2000 datasets, (ii) real-life occlusions of the Pandora dataset, and (iii)\na real-life application to human-robot interaction scenarios where face\nocclusions often occur. Specifically, the autonomous feeding from a robotic\narm.",
            "author": [
                "Jos\u00e9 Celestino",
                "Manuel Marques",
                "Jacinto C. Nascimento",
                "Jo\u00e3o Paulo Costeira"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.patcog.2022.109288",
                "http://arxiv.org/abs/2311.06038v1",
                "http://arxiv.org/pdf/2311.06038v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06034v1",
            "title": "Structure of the space of folding protein sequences defined by large\n  language models",
            "updated": "2023-11-10T12:43:06Z",
            "published": "2023-11-10T12:43:06Z",
            "summary": "Proteins populate a manifold in the high-dimensional sequence space whose\ngeometrical structure guides their natural evolution. Leveraging\nrecently-developed structure prediction tools based on transformer models, we\nfirst examine the protein sequence landscape as defined by the folding score\nfunction. This landscape shares characteristics with optimization challenges\nencountered in machine learning and constraint satisfaction problems. Our\nanalysis reveals that natural proteins predominantly reside in wide, flat\nminima within this energy landscape. To investigate further, we employ\nstatistical mechanics algorithms specifically designed to explore regions with\nhigh local entropy in relatively flat landscapes. Our findings indicate that\nthese specialized algorithms can identify valleys with higher entropy compared\nto those found using traditional methods such as Monte Carlo Markov Chains. In\na proof-of-concept case, we find that these highly entropic minima exhibit\nsignificant similarities to natural sequences, especially in critical key sites\nand local entropy. Additionally, evaluations through Molecular Dynamics\nsuggests that the stability of these sequences closely resembles that of\nnatural proteins. Our tool combines advancements in machine learning and\nstatistical physics, providing new insights into the exploration of sequence\nlandscapes where wide, flat minima coexist alongside a majority of narrower\nminima.",
            "author": [
                "A. Zambon",
                "R. Zecchina",
                "G. Tiana"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06034v1",
                "http://arxiv.org/pdf/2311.06034v1"
            ],
            "primary_category": "q-bio.BM",
            "category": [
                "q-bio.BM",
                "q-bio.PE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06031v3",
            "title": "Diagonal Hierarchical Consistency Learning for Semi-supervised Medical\n  Image Segmentation",
            "updated": "2023-11-24T15:37:06Z",
            "published": "2023-11-10T12:38:16Z",
            "summary": "Medical image segmentation, which is essential for many clinical\napplications, has achieved almost human-level performance via data-driven deep\nlearning technologies. Nevertheless, its performance is predicated upon the\ncostly process of manually annotating a vast amount of medical images. To this\nend, we propose a novel framework for robust semi-supervised medical image\nsegmentation using diagonal hierarchical consistency learning (DiHC-Net).\nFirst, it is composed of multiple sub-models with identical multi-scale\narchitecture but with distinct sub-layers, such as up-sampling and\nnormalisation layers. Second, with mutual consistency, a novel consistency\nregularisation is enforced between one model's intermediate and final\nprediction and soft pseudo labels from other models in a diagonal hierarchical\nfashion. A series of experiments verifies the efficacy of our simple framework,\noutperforming all previous approaches on public Left Atrium (LA) dataset.",
            "author": [
                "Heejoon Koo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06031v3",
                "http://arxiv.org/pdf/2311.06031v3"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06028v1",
            "title": "Symbolic Regression as Feature Engineering Method for Machine and Deep\n  Learning Regression Tasks",
            "updated": "2023-11-10T12:34:28Z",
            "published": "2023-11-10T12:34:28Z",
            "summary": "In the realm of machine and deep learning regression tasks, the role of\neffective feature engineering (FE) is pivotal in enhancing model performance.\nTraditional approaches of FE often rely on domain expertise to manually design\nfeatures for machine learning models. In the context of deep learning models,\nthe FE is embedded in the neural network's architecture, making it hard for\ninterpretation. In this study, we propose to integrate symbolic regression (SR)\nas an FE process before a machine learning model to improve its performance. We\nshow, through extensive experimentation on synthetic and real-world\nphysics-related datasets, that the incorporation of SR-derived features\nsignificantly enhances the predictive capabilities of both machine and deep\nlearning regression models with 34-86% root mean square error (RMSE)\nimprovement in synthetic datasets and 4-11.5% improvement in real-world\ndatasets. In addition, as a realistic use-case, we show the proposed method\nimproves the machine learning performance in predicting superconducting\ncritical temperatures based on Eliashberg theory by more than 20% in terms of\nRMSE. These results outline the potential of SR as an FE component in\ndata-driven models.",
            "author": [
                "Assaf Shmuel",
                "Oren Glickman",
                "Teddy Lazebnik"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06028v1",
                "http://arxiv.org/pdf/2311.06028v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06025v2",
            "title": "ChiMed-GPT: A Chinese Medical Large Language Model with Full Training\n  Regime and Better Alignment to Human Preferences",
            "updated": "2023-11-23T10:19:47Z",
            "published": "2023-11-10T12:25:32Z",
            "summary": "Recently, the increasing demand for superior medical services has highlighted\nthe discrepancies in the medical infrastructure. With big data, especially\ntexts, forming the foundation of medical services, there is an exigent need for\neffective natural language processing (NLP) solutions tailored to the\nhealthcare domain. Conventional approaches leveraging pre-trained models\npresent promising results in this domain and current large language models\n(LLMs) offer advanced foundation for medical text processing. However, most\nmedical LLMs are trained only with supervised fine-tuning (SFT), even though it\nefficiently empowers LLMs to understand and respond to medical instructions but\nis ineffective in learning domain knowledge and aligning with human preference.\nAnother engineering barrier that prevents current medical LLM from better text\nprocessing ability is their restricted context length (e.g., 2,048 tokens),\nmaking it hard for the LLMs to process long context, which is frequently\nrequired in the medical domain. In this work, we propose ChiMed-GPT, a new\nbenchmark LLM designed explicitly for Chinese medical domain, with enlarged\ncontext length to 4,096 tokens and undergoes a comprehensive training regime\nwith pre-training, SFT, and RLHF. Evaluations on real-world tasks including\ninformation extraction, question answering, and dialogue generation demonstrate\nChiMed-GPT's superior performance over general domain LLMs. Furthermore, we\nanalyze possible biases through prompting ChiMed-GPT to perform attitude scales\nregarding discrimination of patients, so as to contribute to further\nresponsible development of LLMs in the medical domain. The code and model are\nreleased at https://github.com/synlp/ChiMed-GPT.",
            "author": [
                "Yuanhe Tian",
                "Ruyi Gan",
                "Yan Song",
                "Jiaxing Zhang",
                "Yongdong Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06025v2",
                "http://arxiv.org/pdf/2311.06025v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06024v1",
            "title": "Exploring the experiences of undergraduate physics students taking a\n  'Teaching Physics in School' module and the effects on their intentions to\n  become a secondary physics teacher",
            "updated": "2023-11-10T12:25:19Z",
            "published": "2023-11-10T12:25:19Z",
            "summary": "This article describes an undergraduate physics module at a university in\nEngland that places year 3 student physicists in secondary school classrooms\nfor a semester. This is done as a way of introducing them to the occupation of\nsecondary physics teaching using a realistic job preview approach. The module\nhelps the undergraduate students develop their communication and professional\nskills and supports the physics learning of pupils in the schools where they\nare placed. The perceptions of the participating students toward secondary\nschool physics teaching are then investigated. Two themes emerged from this\nresearch: The difficulty of explaining physics concepts to children and the\nneed to make school physics enjoyable.",
            "author": [
                "Daniel Cottle"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06024v1",
                "http://arxiv.org/pdf/2311.06024v1"
            ],
            "primary_category": "physics.ed-ph",
            "category": [
                "physics.ed-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06323v1",
            "title": "Reviewing Developments of Graph Convolutional Network Techniques for\n  Recommendation Systems",
            "updated": "2023-11-10T12:11:36Z",
            "published": "2023-11-10T12:11:36Z",
            "summary": "The Recommender system is a vital information service on today's Internet.\nRecently, graph neural networks have emerged as the leading approach for\nrecommender systems. We try to review recent literature on graph neural\nnetwork-based recommender systems, covering the background and development of\nboth recommender systems and graph neural networks. Then categorizing\nrecommender systems by their settings and graph neural networks by spectral and\nspatial models, we explore the motivation behind incorporating graph neural\nnetworks into recommender systems. We also analyze challenges and open problems\nin graph construction, embedding propagation and aggregation, and computation\nefficiency. This guides us to better explore the future directions and\ndevelopments in this domain.",
            "author": [
                "Haojun Zhu",
                "Vikram Kapoor",
                "Priya Sharma"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06323v1",
                "http://arxiv.org/pdf/2311.06323v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07597v1",
            "title": "Enhancing Actuarial Non-Life Pricing Models via Transformers",
            "updated": "2023-11-10T12:06:23Z",
            "published": "2023-11-10T12:06:23Z",
            "summary": "Currently, there is a lot of research in the field of neural networks for\nnon-life insurance pricing. The usual goal is to improve the predictive power\nvia neural networks while building upon the generalized linear model, which is\nthe current industry standard. Our paper contributes to this current journey\nvia novel methods to enhance actuarial non-life models with transformer models\nfor tabular data. We build here upon the foundation laid out by the combined\nactuarial neural network as well as the localGLMnet and enhance those models\nvia the feature tokenizer transformer. The manuscript demonstrates the\nperformance of the proposed methods on a real-world claim frequency dataset and\ncompares them with several benchmark models such as generalized linear models,\nfeed-forward neural networks, combined actuarial neural networks, LocalGLMnet,\nand pure feature tokenizer transformer. The paper shows that the new methods\ncan achieve better results than the benchmark models while preserving certain\ngeneralized linear model advantages. The paper also discusses the practical\nimplications and challenges of applying transformer models in actuarial\nsettings.",
            "author": [
                "Alexej Brauer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07597v1",
                "http://arxiv.org/pdf/2311.07597v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "q-fin.ST",
                "stat.AP",
                "62 68"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06018v1",
            "title": "U3DS$^3$: Unsupervised 3D Semantic Scene Segmentation",
            "updated": "2023-11-10T12:05:35Z",
            "published": "2023-11-10T12:05:35Z",
            "summary": "Contemporary point cloud segmentation approaches largely rely on richly\nannotated 3D training data. However, it is both time-consuming and challenging\nto obtain consistently accurate annotations for such 3D scene data. Moreover,\nthere is still a lack of investigation into fully unsupervised scene\nsegmentation for point clouds, especially for holistic 3D scenes. This paper\npresents U3DS$^3$, as a step towards completely unsupervised point cloud\nsegmentation for any holistic 3D scenes. To achieve this, U3DS$^3$ leverages a\ngeneralized unsupervised segmentation method for both object and background\nacross both indoor and outdoor static 3D point clouds with no requirement for\nmodel pre-training, by leveraging only the inherent information of the point\ncloud to achieve full 3D scene segmentation. The initial step of our proposed\napproach involves generating superpoints based on the geometric characteristics\nof each scene. Subsequently, it undergoes a learning process through a spatial\nclustering-based methodology, followed by iterative training using\npseudo-labels generated in accordance with the cluster centroids. Moreover, by\nleveraging the invariance and equivariance of the volumetric representations,\nwe apply the geometric transformation on voxelized features to provide two sets\nof descriptors for robust representation learning. Finally, our evaluation\nprovides state-of-the-art results on the ScanNet and SemanticKITTI, and\ncompetitive results on the S3DIS, benchmark datasets.",
            "author": [
                "Jiaxu Liu",
                "Zhengdi Yu",
                "Toby P. Breckon",
                "Hubert P. H. Shum"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06018v1",
                "http://arxiv.org/pdf/2311.06018v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06015v1",
            "title": "RSG: Fast Learning Adaptive Skills for Quadruped Robots by Skill Graph",
            "updated": "2023-11-10T11:59:41Z",
            "published": "2023-11-10T11:59:41Z",
            "summary": "Developing robotic intelligent systems that can adapt quickly to unseen wild\nsituations is one of the critical challenges in pursuing autonomous robotics.\nAlthough some impressive progress has been made in walking stability and skill\nlearning in the field of legged robots, their ability to fast adaptation is\nstill inferior to that of animals in nature. Animals are born with massive\nskills needed to survive, and can quickly acquire new ones, by composing\nfundamental skills with limited experience. Inspired by this, we propose a\nnovel framework, named Robot Skill Graph (RSG) for organizing massive\nfundamental skills of robots and dexterously reusing them for fast adaptation.\nBearing a structure similar to the Knowledge Graph (KG), RSG is composed of\nmassive dynamic behavioral skills instead of static knowledge in KG and enables\ndiscovering implicit relations that exist in be-tween of learning context and\nacquired skills of robots, serving as a starting point for understanding subtle\npatterns existing in robots' skill learning. Extensive experimental results\ndemonstrate that RSG can provide rational skill inference upon new tasks and\nenvironments and enable quadruped robots to adapt to new scenarios and learn\nnew skills rapidly.",
            "author": [
                "Hongyin Zhang",
                "Diyuan Shi",
                "Zifeng Zhuang",
                "Han Zhao",
                "Zhenyu Wei",
                "Feng Zhao",
                "Sibo Gai",
                "Shangke Lyu",
                "Donglin Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06015v1",
                "http://arxiv.org/pdf/2311.06015v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06012v1",
            "title": "Doubly Robust Structure Identification from Temporal Data",
            "updated": "2023-11-10T11:53:42Z",
            "published": "2023-11-10T11:53:42Z",
            "summary": "Learning the causes of time-series data is a fundamental task in many\napplications, spanning from finance to earth sciences or bio-medical\napplications. Common approaches for this task are based on vector\nauto-regression, and they do not take into account unknown confounding between\npotential causes. However, in settings with many potential causes and noisy\ndata, these approaches may be substantially biased. Furthermore, potential\ncauses may be correlated in practical applications. Moreover, existing\nalgorithms often do not work with cyclic data. To address these challenges, we\npropose a new doubly robust method for Structure Identification from Temporal\nData ( SITD ). We provide theoretical guarantees, showing that our method\nasymptotically recovers the true underlying causal structure. Our analysis\nextends to cases where the potential causes have cycles and they may be\nconfounded. We further perform extensive experiments to showcase the superior\nperformance of our method.",
            "author": [
                "Emmanouil Angelis",
                "Francesco Quinzan",
                "Ashkan Soleymani",
                "Patrick Jaillet",
                "Stefan Bauer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06012v1",
                "http://arxiv.org/pdf/2311.06012v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06010v1",
            "title": "Machine Learning-Driven Structure Prediction for Iron Hydrides",
            "updated": "2023-11-10T11:51:41Z",
            "published": "2023-11-10T11:51:41Z",
            "summary": "We created a computational workflow to analyze the potential energy surface\n(PES) of materials using machine-learned interatomic potentials in conjunction\nwith the minima hopping algorithm. We demonstrate this method by producing a\nversatile machine-learned interatomic potential for iron hydride via a neural\nnetwork using an iterative training process to explore its energy landscape\nunder different pressures. To evaluate the accuracy and comprehend the\nintricacies of the PES, we conducted comprehensive crystal structure\npredictions using our neural network-based potential paired with the minima\nhopping approach. The predictions spanned pressures ranging from ambient to 100\nGPa. Our results reproduce the experimentally verified global minimum\nstructures such as \\textit{dhcp}, \\textit{hcp}, and \\textit{fcc}, corroborating\nprevious findings. Furthermore, our in-depth exploration of the iron hydride\nPES at different pressures has revealed complex alterations and stacking faults\nin these phases, leading to the identification of several new low-enthalpy\nstructures. This investigation has not only confirmed the presence of regions\nof established FeH configurations but has also highlighted the efficacy of\nusing data-driven, extensive structure prediction methods to uncover the\nmultifaceted PES of materials.",
            "author": [
                "Hossein Tahmasbi",
                "Kushal Ramakrishna",
                "Mani Lokamani",
                "Attila Cangi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06010v1",
                "http://arxiv.org/pdf/2311.06010v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06009v1",
            "title": "Polar-Net: A Clinical-Friendly Model for Alzheimer's Disease Detection\n  in OCTA Images",
            "updated": "2023-11-10T11:49:49Z",
            "published": "2023-11-10T11:49:49Z",
            "summary": "Optical Coherence Tomography Angiography (OCTA) is a promising tool for\ndetecting Alzheimer's disease (AD) by imaging the retinal microvasculature.\nOphthalmologists commonly use region-based analysis, such as the ETDRS grid, to\nstudy OCTA image biomarkers and understand the correlation with AD. However,\nexisting studies have used general deep computer vision methods, which present\nchallenges in providing interpretable results and leveraging clinical prior\nknowledge. To address these challenges, we propose a novel deep-learning\nframework called Polar-Net. Our approach involves mapping OCTA images from\nCartesian coordinates to polar coordinates, which allows for the use of\napproximate sector convolution and enables the implementation of the ETDRS\ngrid-based regional analysis method commonly used in clinical practice.\nFurthermore, Polar-Net incorporates clinical prior information of each sector\nregion into the training process, which further enhances its performance.\nAdditionally, our framework adapts to acquire the importance of the\ncorresponding retinal region, which helps researchers and clinicians understand\nthe model's decision-making process in detecting AD and assess its conformity\nto clinical observations. Through evaluations on private and public datasets,\nwe have demonstrated that Polar-Net outperforms existing state-of-the-art\nmethods and provides more valuable pathological evidence for the association\nbetween retinal vascular changes and AD. In addition, we also show that the two\ninnovative modules introduced in our framework have a significant impact on\nimproving overall performance.",
            "author": [
                "Shouyue Liu",
                "Jinkui Hao",
                "Yanwu Xu",
                "Huazhu Fu",
                "Xinyu Guo",
                "Jiang Liu",
                "Yalin Zheng",
                "Yonghuai Liu",
                "Jiong Zhang",
                "Yitian Zhao"
            ],
            "link": [
                "http://dx.doi.org/10.1007/978-3-031-43990-2_57",
                "http://arxiv.org/abs/2311.06009v1",
                "http://arxiv.org/pdf/2311.06009v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07596v1",
            "title": "Graph GOSPA metric: a metric to measure the discrepancy between graphs\n  of different sizes",
            "updated": "2023-11-10T11:40:24Z",
            "published": "2023-11-10T11:40:24Z",
            "summary": "This paper proposes a metric to measure the dissimilarity between graphs that\nmay have a different number of nodes. The proposed metric extends the\ngeneralised optimal subpattern assignment (GOSPA) metric, which is a metric for\nsets, to graphs. The proposed graph GOSPA metric includes costs associated with\nnode attribute errors for properly assigned nodes, missed and false nodes and\nedge mismatches between graphs. The computation of this metric is based on\nfinding the optimal assignments between nodes in the two graphs, with the\npossibility of leaving some of the nodes unassigned. We also propose a lower\nbound for the metric, which is also a metric for graphs and is computable in\npolynomial time using linear programming. The metric is first derived for\nundirected unweighted graphs and it is then extended to directed and weighted\ngraphs. The properties of the metric are demonstrated via simulated and\nempirical datasets.",
            "author": [
                "Jinhao Gu",
                "\u00c1ngel F. Garc\u00eda-Fern\u00e1ndez",
                "Robert E. Firth",
                "Lennart Svensson"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07596v1",
                "http://arxiv.org/pdf/2311.07596v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06003v1",
            "title": "Passive Integrated Sensing and Communication Scheme based on RF\n  Fingerprint Information Extraction for Cell-Free RAN",
            "updated": "2023-11-10T11:30:38Z",
            "published": "2023-11-10T11:30:38Z",
            "summary": "This paper investigates how to achieve integrated sensing and communication\n(ISAC) based on a cell-free radio access network (CF-RAN) architecture with a\nminimum footprint of communication resources. We propose a new passive sensing\nscheme. The scheme is based on the radio frequency (RF) fingerprint learning of\nthe RF radio unit (RRU) to build an RF fingerprint library of RRUs. The source\nRRU is identified by comparing the RF fingerprints carried by the signal at the\nreceiver side. The receiver extracts the channel parameters from the signal and\nestimates the channel environment, thus locating the reflectors in the\nenvironment. The proposed scheme can effectively solve the problem of\ninterference between signals in the same time-frequency domain but in different\nspatial domains when multiple RRUs jointly serve users in CF-RAN architecture.\nSimulation results show that the proposed passive ISAC scheme can effectively\ndetect reflector location information in the environment without degrading the\ncommunication performance.",
            "author": [
                "Jingxuan Yu",
                "Fan Zeng",
                "Jiamin Li",
                "Feiyang Liu",
                "Pengcheng Zhu",
                "Dongming Wang",
                "Xiaohu You"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06003v1",
                "http://arxiv.org/pdf/2311.06003v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05992v1",
            "title": "Robust Adversarial Attacks Detection for Deep Learning based Relative\n  Pose Estimation for Space Rendezvous",
            "updated": "2023-11-10T11:07:31Z",
            "published": "2023-11-10T11:07:31Z",
            "summary": "Research on developing deep learning techniques for autonomous spacecraft\nrelative navigation challenges is continuously growing in recent years.\nAdopting those techniques offers enhanced performance. However, such approaches\nalso introduce heightened apprehensions regarding the trustability and security\nof such deep learning methods through their susceptibility to adversarial\nattacks. In this work, we propose a novel approach for adversarial attack\ndetection for deep neural network-based relative pose estimation schemes based\non the explainability concept. We develop for an orbital rendezvous scenario an\ninnovative relative pose estimation technique adopting our proposed\nConvolutional Neural Network (CNN), which takes an image from the chaser's\nonboard camera and outputs accurately the target's relative position and\nrotation. We perturb seamlessly the input images using adversarial attacks that\nare generated by the Fast Gradient Sign Method (FGSM). The adversarial attack\ndetector is then built based on a Long Short Term Memory (LSTM) network which\ntakes the explainability measure namely SHapley Value from the CNN-based pose\nestimator and flags the detection of adversarial attacks when acting.\nSimulation results show that the proposed adversarial attack detector achieves\na detection accuracy of 99.21%. Both the deep relative pose estimator and\nadversarial attack detector are then tested on real data captured from our\nlaboratory-designed setup. The experimental results from our\nlaboratory-designed setup demonstrate that the proposed adversarial attack\ndetector achieves an average detection accuracy of 96.29%.",
            "author": [
                "Ziwei Wang",
                "Nabil Aouf",
                "Jose Pizarro",
                "Christophe Honvault"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05992v1",
                "http://arxiv.org/pdf/2311.05992v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CR",
                "cs.LG",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05990v1",
            "title": "Gradients of metallicity and age of stars in the dwarf spheroidal\n  galaxies KKs3 and ESO269-66",
            "updated": "2023-11-10T11:02:39Z",
            "published": "2023-11-10T11:02:39Z",
            "summary": "We compare the properties of the stellar populations of the globular clusters\nand field stars in two dwarf spheroidal galaxies (dSphs): ESO269-66, a near\nneighbor of the giant S0 galaxy NGC 5128, and KKs3, one of the few extremely\nisolated dSphs within 10 Mpc. The histories of star formation in these galaxies\nare known from previous work on deep stellar photometry using images from the\nHubble Space Telescope (HST). The age and metal content for the nuclear\nglobular clusters in KKs3 and ESO269-66 are known from literature spectroscopic\nstudies: T=12.6 billion years, [Fe/H]=-1.5 and -1.55 dex. We use the Sersic\nfunction to construct and analyze the profiles of the surface density of the\nstars with high and low metallicities (red and blue) in KKs3 and ESO269-66, and\nshow that (1) the profiles of the density of red stars are steeper than those\nof blue stars, which is indicative of gradients of metallicity and age in the\ngalaxies, and (2) the globular clusters in KKs3 and ESO269-66 contain roughly 4\nand 40%, respectively, of all the old stars in the galaxies with metallicities\n[Fe/H]~-1.5 to -1.6 dex and ages of 12-14 billion years. The globular clusters\nare, therefore, relicts of the first, most powerful bursts of star formation in\nthe central regions of these objects. It is probable that, because of its\nisolation, KKs3 has lost a smaller fraction of old low-metallicity stars than\nESO269-66.",
            "author": [
                "M. E. Sharina",
                "L. N. Makarova",
                "D. I. Makarov"
            ],
            "link": [
                "http://dx.doi.org/10.1007/s10511-018-9548-3",
                "http://arxiv.org/abs/2311.05990v1",
                "http://arxiv.org/pdf/2311.05990v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05981v1",
            "title": "Comparing Male Nyala and Male Kudu Classification using Transfer\n  Learning with ResNet-50 and VGG-16",
            "updated": "2023-11-10T10:43:46Z",
            "published": "2023-11-10T10:43:46Z",
            "summary": "Reliable and efficient monitoring of wild animals is crucial to inform\nmanagement and conservation decisions. The process of manually identifying\nspecies of animals is time-consuming, monotonous, and expensive. Leveraging on\nadvances in deep learning and computer vision, we investigate in this paper the\nefficiency of pre-trained models, specifically the VGG-16 and ResNet-50 model,\nin identifying a male Kudu and a male Nyala in their natural habitats. These\npre-trained models have proven to be efficient in animal identification in\ngeneral. Still, there is little research on animals like the Kudu and Nyala,\nwho are usually well camouflaged and have similar features. The method of\ntransfer learning used in this paper is the fine-tuning method. The models are\nevaluated before and after fine-tuning. The experimental results achieved an\naccuracy of 93.2\\% and 97.7\\% for the VGG-16 and ResNet-50 models,\nrespectively, before fine-tuning and 97.7\\% for both models after fine-tuning.\nAlthough these results are impressive, it should be noted that they were taken\nover a small sample size of 550 images split in half between the two classes;\ntherefore, this might not cater to enough scenarios to get a full conclusion of\nthe efficiency of the models. Therefore, there is room for more work in getting\na more extensive dataset and testing and extending to the female counterparts\nof these species and the whole antelope species.",
            "author": [
                "T. T Lemani",
                "T. L. van Zyl"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05981v1",
                "http://arxiv.org/pdf/2311.05981v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07595v1",
            "title": "A Decision Support System for Liver Diseases Prediction: Integrating\n  Batch Processing, Rule-Based Event Detection and SPARQL Query",
            "updated": "2023-11-10T10:21:09Z",
            "published": "2023-11-10T10:21:09Z",
            "summary": "Liver diseases pose a significant global health burden, impacting a\nsubstantial number of individuals and exerting substantial economic and social\nconsequences. Rising liver problems are considered a fatal disease in many\ncountries, such as Egypt, Molda, etc. The objective of this study is to\nconstruct a predictive model for liver illness using Basic Formal Ontology\n(BFO) and detection rules derived from a decision tree algorithm. Based on\nthese rules, events are detected through batch processing using the Apache Jena\nframework. Based on the event detected, queries can be directly processed using\nSPARQL. To make the ontology operational, these Decision Tree (DT) rules are\nconverted into Semantic Web Rule Language (SWRL). Using this SWRL in the\nontology for predicting different types of liver disease with the help of the\nPellet and Drool inference engines in Protege Tools, a total of 615 records are\ntaken from different liver diseases. After inferring the rules, the result can\nbe generated for the patient according to the DT rules, and other\npatient-related details along with different precautionary suggestions can be\nobtained based on these results. Combining query results of batch processing\nand ontology-generated results can give more accurate suggestions for disease\nprevention and detection. This work aims to provide a comprehensive approach\nthat is applicable for liver disease prediction, rich knowledge graph\nrepresentation, and smart querying capabilities. The results show that\ncombining RDF data, SWRL rules, and SPARQL queries for analysing and predicting\nliver disease can help medical professionals to learn more about liver diseases\nand make a Decision Support System (DSS) for health care.",
            "author": [
                "Ritesh Chandra",
                "Sadhana Tiwari",
                "Satyam Rastogi",
                "Sonali Agarwal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07595v1",
                "http://arxiv.org/pdf/2311.07595v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05975v1",
            "title": "Sum-max Submodular Bandits",
            "updated": "2023-11-10T10:18:50Z",
            "published": "2023-11-10T10:18:50Z",
            "summary": "Many online decision-making problems correspond to maximizing a sequence of\nsubmodular functions. In this work, we introduce sum-max functions, a subclass\nof monotone submodular functions capturing several interesting problems,\nincluding best-of-$K$-bandits, combinatorial bandits, and the bandit versions\non facility location, $M$-medians, and hitting sets. We show that all functions\nin this class satisfy a key property that we call pseudo-concavity. This allows\nus to prove $\\big(1 - \\frac{1}{e}\\big)$-regret bounds for bandit feedback in\nthe nonstochastic setting of the order of $\\sqrt{MKT}$ (ignoring log factors),\nwhere $T$ is the time horizon and $M$ is a cardinality constraint. This bound,\nattained by a simple and efficient algorithm, significantly improves on the\n$\\widetilde{O}\\big(T^{2/3}\\big)$ regret bound for online monotone submodular\nmaximization with bandit feedback.",
            "author": [
                "Stephen Pasteris",
                "Alberto Rumi",
                "Fabio Vitale",
                "Nicol\u00f2 Cesa-Bianchi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05975v1",
                "http://arxiv.org/pdf/2311.05975v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05970v1",
            "title": "Quantized Distillation: Optimizing Driver Activity Recognition Models\n  for Resource-Constrained Environments",
            "updated": "2023-11-10T10:07:07Z",
            "published": "2023-11-10T10:07:07Z",
            "summary": "Deep learning-based models are at the forefront of most driver observation\nbenchmarks due to their remarkable accuracies but are also associated with high\ncomputational costs. This is challenging, as resources are often limited in\nreal-world driving scenarios. This paper introduces a lightweight framework for\nresource-efficient driver activity recognition. The framework enhances 3D\nMobileNet, a neural architecture optimized for speed in video classification,\nby incorporating knowledge distillation and model quantization to balance model\naccuracy and computational efficiency. Knowledge distillation helps maintain\naccuracy while reducing the model size by leveraging soft labels from a larger\nteacher model (I3D), instead of relying solely on original ground truth data.\nModel quantization significantly lowers memory and computation demands by using\nlower precision integers for model weights and activations. Extensive testing\non a public dataset for in-vehicle monitoring during autonomous driving\ndemonstrates that this new framework achieves a threefold reduction in model\nsize and a 1.4-fold improvement in inference time, compared to an already\noptimized architecture. The code for this study is available at\nhttps://github.com/calvintanama/qd-driver-activity-reco.",
            "author": [
                "Calvin Tanama",
                "Kunyu Peng",
                "Zdravko Marinov",
                "Rainer Stiefelhagen",
                "Alina Roitberg"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05970v1",
                "http://arxiv.org/pdf/2311.05970v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05967v1",
            "title": "Plasma Surrogate Modelling using Fourier Neural Operators",
            "updated": "2023-11-10T10:05:00Z",
            "published": "2023-11-10T10:05:00Z",
            "summary": "Predicting plasma evolution within a Tokamak reactor is crucial to realizing\nthe goal of sustainable fusion. Capabilities in forecasting the spatio-temporal\nevolution of plasma rapidly and accurately allow us to quickly iterate over\ndesign and control strategies on current Tokamak devices and future reactors.\nModelling plasma evolution using numerical solvers is often expensive,\nconsuming many hours on supercomputers, and hence, we need alternative\ninexpensive surrogate models. We demonstrate accurate predictions of plasma\nevolution both in simulation and experimental domains using deep learning-based\nsurrogate modelling tools, viz., Fourier Neural Operators (FNO). We show that\nFNO has a speedup of six orders of magnitude over traditional solvers in\npredicting the plasma dynamics simulated from magnetohydrodynamic models, while\nmaintaining a high accuracy (MSE $\\approx$ $10^{-5}$). Our modified version of\nthe FNO is capable of solving multi-variable Partial Differential Equations\n(PDE), and can capture the dependence among the different variables in a single\nmodel. FNOs can also predict plasma evolution on real-world experimental data\nobserved by the cameras positioned within the MAST Tokamak, i.e., cameras\nlooking across the central solenoid and the divertor in the Tokamak. We show\nthat FNOs are able to accurately forecast the evolution of plasma and have the\npotential to be deployed for real-time monitoring. We also illustrate their\ncapability in forecasting the plasma shape, the locations of interactions of\nthe plasma with the central solenoid and the divertor for the full duration of\nthe plasma shot within MAST. The FNO offers a viable alternative for surrogate\nmodelling as it is quick to train and infer, and requires fewer data points,\nwhile being able to do zero-shot super-resolution and getting high-fidelity\nsolutions.",
            "author": [
                "Vignesh Gopakumar",
                "Stanislas Pamela",
                "Lorenzo Zanisi",
                "Zongyi Li",
                "Ander Gray",
                "Daniel Brennand",
                "Nitesh Bhatia",
                "Gregory Stathopoulos",
                "Matt Kusner",
                "Marc Peter Deisenroth",
                "Anima Anandkumar",
                "JOREK Team",
                "MAST Team"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05967v1",
                "http://arxiv.org/pdf/2311.05967v1"
            ],
            "primary_category": "physics.plasm-ph",
            "category": [
                "physics.plasm-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05964v1",
            "title": "Multiscale Neural Operators for Solving Time-Independent PDEs",
            "updated": "2023-11-10T10:02:56Z",
            "published": "2023-11-10T10:02:56Z",
            "summary": "Time-independent Partial Differential Equations (PDEs) on large meshes pose\nsignificant challenges for data-driven neural PDE solvers. We introduce a novel\ngraph rewiring technique to tackle some of these challenges, such as\naggregating information across scales and on irregular meshes. Our proposed\napproach bridges distant nodes, enhancing the global interaction capabilities\nof GNNs. Our experiments on three datasets reveal that GNN-based methods set\nnew performance standards for time-independent PDEs on irregular meshes.\nFinally, we show that our graph rewiring strategy boosts the performance of\nbaseline methods, achieving state-of-the-art results in one of the tasks.",
            "author": [
                "Winfried Ripken",
                "Lisa Coiffard",
                "Felix Pieper",
                "Sebastian Dziadzio"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05964v1",
                "http://arxiv.org/pdf/2311.05964v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05961v1",
            "title": "Hierarchical deep learning-based adaptive time-stepping scheme for\n  multiscale simulations",
            "updated": "2023-11-10T09:47:58Z",
            "published": "2023-11-10T09:47:58Z",
            "summary": "Multiscale is a hallmark feature of complex nonlinear systems. While the\nsimulation using the classical numerical methods is restricted by the local\n\\textit{Taylor} series constraints, the multiscale techniques are often limited\nby finding heuristic closures. This study proposes a new method for simulating\nmultiscale problems using deep neural networks. By leveraging the hierarchical\nlearning of neural network time steppers, the method adapts time steps to\napproximate dynamical system flow maps across timescales. This approach\nachieves state-of-the-art performance in less computational time compared to\nfixed-step neural network solvers. The proposed method is demonstrated on\nseveral nonlinear dynamical systems, and source codes are provided for\nimplementation. This method has the potential to benefit multiscale analysis of\ncomplex systems and encourage further investigation in this area.",
            "author": [
                "Asif Hamid",
                "Danish Rafiq",
                "Shahkar Ahmad Nahvi",
                "Mohammad Abid Bazaz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05961v1",
                "http://arxiv.org/pdf/2311.05961v1"
            ],
            "primary_category": "math.DS",
            "category": [
                "math.DS",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05958v1",
            "title": "A Neural Height-Map Approach for the Binocular Photometric Stereo\n  Problem",
            "updated": "2023-11-10T09:45:53Z",
            "published": "2023-11-10T09:45:53Z",
            "summary": "In this work we propose a novel, highly practical, binocular photometric\nstereo (PS) framework, which has same acquisition speed as single view PS,\nhowever significantly improves the quality of the estimated geometry.\n  As in recent neural multi-view shape estimation frameworks such as NeRF,\nSIREN and inverse graphics approaches to multi-view photometric stereo (e.g.\nPS-NeRF) we formulate shape estimation task as learning of a differentiable\nsurface and texture representation by minimising surface normal discrepancy for\nnormals estimated from multiple varying light images for two views as well as\ndiscrepancy between rendered surface intensity and observed images. Our method\ndiffers from typical multi-view shape estimation approaches in two key ways.\nFirst, our surface is represented not as a volume but as a neural heightmap\nwhere heights of points on a surface are computed by a deep neural network.\nSecond, instead of predicting an average intensity as PS-NeRF or introducing\nlambertian material assumptions as Guo et al., we use a learnt BRDF and perform\nnear-field per point intensity rendering.\n  Our method achieves the state-of-the-art performance on the DiLiGenT-MV\ndataset adapted to binocular stereo setup as well as a new binocular\nphotometric stereo dataset - LUCES-ST.",
            "author": [
                "Fotios Logothetis",
                "Ignas Budvytis",
                "Roberto Cipolla"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05958v1",
                "http://arxiv.org/pdf/2311.05958v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05956v1",
            "title": "ID Embedding as Subtle Features of Content and Structure for Multimodal\n  Recommendation",
            "updated": "2023-11-10T09:41:28Z",
            "published": "2023-11-10T09:41:28Z",
            "summary": "Multimodal recommendation aims to model user and item representations\ncomprehensively with the involvement of multimedia content for effective\nrecommendations. Existing research has shown that it is beneficial for\nrecommendation performance to combine (user- and item-) ID embeddings with\nmultimodal salient features, indicating the value of IDs. However, there is a\nlack of a thorough analysis of the ID embeddings in terms of feature semantics\nin the literature. In this paper, we revisit the value of ID embeddings for\nmultimodal recommendation and conduct a thorough study regarding its semantics,\nwhich we recognize as subtle features of content and structures. Then, we\npropose a novel recommendation model by incorporating ID embeddings to enhance\nthe semantic features of both content and structures. Specifically, we put\nforward a hierarchical attention mechanism to incorporate ID embeddings in\nmodality fusing, coupled with contrastive learning, to enhance content\nrepresentations. Meanwhile, we propose a lightweight graph convolutional\nnetwork for each modality to amalgamate neighborhood and ID embeddings for\nimproving structural representations. Finally, the content and structure\nrepresentations are combined to form the ultimate item embedding for\nrecommendation. Extensive experiments on three real-world datasets (Baby,\nSports, and Clothing) demonstrate the superiority of our method over\nstate-of-the-art multimodal recommendation methods and the effectiveness of\nfine-grained ID embeddings.",
            "author": [
                "Yuting Liu",
                "Enneng Yang",
                "Yizhou Dang",
                "Guibing Guo",
                "Qiang Liu",
                "Yuliang Liang",
                "Linying Jiang",
                "Xingwei Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05956v1",
                "http://arxiv.org/pdf/2311.05956v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05952v1",
            "title": "Learning Broken Symmetries with Resimulation and Encouraged Invariance",
            "updated": "2023-11-10T09:34:22Z",
            "published": "2023-11-10T09:34:22Z",
            "summary": "Recognizing symmetries in data allows for significant boosts in neural\nnetwork training. In many cases, however, the underlying symmetry is present\nonly in an idealized dataset, and is broken in the training data, due to\neffects such as arbitrary and/or non-uniform detector bin edges. Standard\napproaches, such as data augmentation or equivariant networks fail to represent\nthe nature of the full, broken symmetry. We introduce a novel data-augmentation\nscheme that respects the true underlying symmetry and avoids artifacts by\naugmenting the training set with transformed pre-detector examples whose\ndetector response is then resimulated. In addition, we encourage the network to\ntreat the augmented copies identically, allowing it to learn the broken\nsymmetry. While the technique can be extended to other symmetries, we\ndemonstrate its application on rotational symmetry in particle physics\ncalorimeter images. We find that neural networks trained with pre-detector\nrotations converge to a solution more quickly than networks trained with\nstandard post-detector augmentation, and that networks modified to encourage\nsimilar internal treatment of augmentations of the same input converge even\nfaster.",
            "author": [
                "Edmund Witkowski",
                "Daniel Whiteson"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05952v1",
                "http://arxiv.org/pdf/2311.05952v1"
            ],
            "primary_category": "hep-ex",
            "category": [
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16163v1",
            "title": "IODeep: an IOD for the introduction of deep learning in the DICOM\n  standard",
            "updated": "2023-11-10T09:30:06Z",
            "published": "2023-11-10T09:30:06Z",
            "summary": "In recent years, Artificial Intelligence (AI) and in particular Deep Neural\nNetworks (DNN) became a relevant research topic in biomedical image\nsegmentation due to the availability of more and more data sets along with the\nestablishment of well known competitions. Despite the popularity of DNN based\nsegmentation on the research side, these techniques are almost unused in the\ndaily clinical practice even if they could support effectively the physician\nduring the diagnostic process. Apart from the issues related to the\nexplainability of the predictions of a neural model, such systems are not\nintegrated in the diagnostic workflow, and a standardization of their use is\nneeded to achieve this goal. This paper presents \\textit{IODeep} a new DICOM\nInformation Object Definition (IOD) aimed at storing both the weights and the\narchitecture of a DNN already trained on a particular image dataset that is\nlabeled as regards the acquisition modality, the anatomical region, and the\ndisease under investigation. The IOD architecture is presented along with a DNN\nselection algorithm from the PACS server based on the labels outlined above,\nand a simple PACS viewer purposely designed for demonstrating the effectiveness\nof the DICOM integration, while no modifications are required on the PACS\nserver side. The source code are freely available at\nhttps://github.com/CHILab1/IODeep.git",
            "author": [
                "Salvatore Contino",
                "Luca Cruciata",
                "Orazio Gambino",
                "Roberto Pirrone"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16163v1",
                "http://arxiv.org/pdf/2311.16163v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06322v2",
            "title": "Post-training Quantization with Progressive Calibration and Activation\n  Relaxing for Text-to-Image Diffusion Models",
            "updated": "2023-11-18T00:16:24Z",
            "published": "2023-11-10T09:10:09Z",
            "summary": "Diffusion models have achieved great success due to their remarkable\ngeneration ability. However, their high computational overhead is still a\ntroublesome problem. Recent studies have leveraged post-training quantization\n(PTQ) to compress diffusion models. However, most of them only focus on\nunconditional models, leaving the quantization of widely used large pretrained\ntext-to-image models, e.g., Stable Diffusion, largely unexplored. In this\npaper, we propose a novel post-training quantization method PCR (Progressive\nCalibration and Relaxing) for text-to-image diffusion models, which consists of\na progressive calibration strategy that considers the accumulated quantization\nerror across timesteps, and an activation relaxing strategy that improves the\nperformance with negligible cost. Additionally, we demonstrate the previous\nmetrics for text-to-image diffusion model quantization are not accurate due to\nthe distribution gap. To tackle the problem, we propose a novel QDiffBench\nbenchmark, which utilizes data in the same domain for more accurate evaluation.\nBesides, QDiffBench also considers the generalization performance of the\nquantized model outside the calibration dataset. Extensive experiments on\nStable Diffusion and Stable Diffusion XL demonstrate the superiority of our\nmethod and benchmark. Moreover, we are the first to achieve quantization for\nStable Diffusion XL while maintaining the performance.",
            "author": [
                "Siao Tang",
                "Xin Wang",
                "Hong Chen",
                "Chaoyu Guan",
                "Zewen Wu",
                "Yansong Tang",
                "Wenwu Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06322v2",
                "http://arxiv.org/pdf/2311.06322v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05945v1",
            "title": "Intersection-free Robot Manipulation with Soft-Rigid Coupled Incremental\n  Potential Contact",
            "updated": "2023-11-10T09:06:38Z",
            "published": "2023-11-10T09:06:38Z",
            "summary": "This paper presents a novel simulation platform, ZeMa, designed for robotic\nmanipulation tasks concerning soft objects. Such simulation ideally requires\nthree properties: two-way soft-rigid coupling, intersection-free guarantees,\nand frictional contact modeling, with acceptable runtime suitable for deep and\nreinforcement learning tasks. Current simulators often satisfy only a subset of\nthese needs, primarily focusing on distinct rigid-rigid or soft-soft\ninteractions. The proposed ZeMa prioritizes physical accuracy and integrates\nthe incremental potential contact method, offering unified dynamics simulation\nfor both soft and rigid objects. It efficiently manages soft-rigid contact,\noperating 75x faster than baseline tools with similar methodologies like\nIPC-GraspSim. To demonstrate its applicability, we employ it for parallel grasp\ngeneration, penetrated grasp repair, and reinforcement learning for grasping,\nsuccessfully transferring the trained RL policy to real-world scenarios.",
            "author": [
                "Wenxin Du",
                "Siqiong Yao",
                "Xinlei Wang",
                "Yuhang Xu",
                "Wenqiang Xu",
                "Cewu Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05945v1",
                "http://arxiv.org/pdf/2311.05945v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.08157v1",
            "title": "TransformCode: A Contrastive Learning Framework for Code Embedding via\n  Subtree transformation",
            "updated": "2023-11-10T09:05:23Z",
            "published": "2023-11-10T09:05:23Z",
            "summary": "Large-scale language models have made great progress in the field of software\nengineering in recent years. They can be used for many code-related tasks such\nas code clone detection, code-to-code search, and method name prediction.\nHowever, these large-scale language models based on each code token have\nseveral drawbacks: They are usually large in scale, heavily dependent on\nlabels, and require a lot of computing power and time to fine-tune new\ndatasets.Furthermore, code embedding should be performed on the entire code\nsnippet rather than encoding each code token. The main reason for this is that\nencoding each code token would cause model parameter inflation, resulting in a\nlot of parameters storing information that we are not very concerned about. In\nthis paper, we propose a novel framework, called TransformCode, that learns\nabout code embeddings in a contrastive learning manner. The framework uses the\nTransformer encoder as an integral part of the model. We also introduce a novel\ndata augmentation technique called abstract syntax tree transformation: This\ntechnique applies syntactic and semantic transformations to the original code\nsnippets to generate more diverse and robust anchor samples. Our proposed\nframework is both flexible and adaptable: It can be easily extended to other\ndownstream tasks that require code representation such as code clone detection\nand classification. The framework is also very efficient and scalable: It does\nnot require a large model or a large amount of training data, and can support\nany programming language.Finally, our framework is not limited to unsupervised\nlearning, but can also be applied to some supervised learning tasks by\nincorporating task-specific labels or objectives. To explore the effectiveness\nof our framework, we conducted extensive experiments on different software\nengineering tasks using different programming languages and multiple datasets.",
            "author": [
                "Zixiang Xian",
                "Rubing Huang",
                "Dave Towey",
                "Chunrong Fang",
                "Zhenyu Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08157v1",
                "http://arxiv.org/pdf/2311.08157v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05943v1",
            "title": "Prompt Problems: A New Programming Exercise for the Generative AI Era",
            "updated": "2023-11-10T09:01:34Z",
            "published": "2023-11-10T09:01:34Z",
            "summary": "Large Language Models (LLMs) are revolutionizing the field of computing\neducation with their powerful code-generating capabilities. Traditional\npedagogical practices have focused on code writing tasks, but there is now a\nshift in importance towards code reading, comprehension and evaluation of\nLLM-generated code. Alongside this shift, an important new skill is emerging --\nthe ability to solve programming tasks by constructing good prompts for\ncode-generating models. In this work we introduce a new type of programming\nexercise to hone this nascent skill: 'Prompt Problems'. Prompt Problems are\ndesigned to help students learn how to write effective prompts for AI code\ngenerators. A student solves a Prompt Problem by crafting a natural language\nprompt which, when provided as input to an LLM, outputs code that successfully\nsolves a specified programming task. We also present a new web-based tool\ncalled Promptly which hosts a repository of Prompt Problems and supports the\nautomated evaluation of prompt-generated code. We deploy Promptly for the first\ntime in one CS1 and one CS2 course and describe our experiences, which include\nstudent perceptions of this new type of activity and their interactions with\nthe tool. We find that students are enthusiastic about Prompt Problems, and\nappreciate how the problems engage their computational thinking skills and\nexpose them to new programming constructs. We discuss ideas for the future\ndevelopment of new variations of Prompt Problems, and the need to carefully\nstudy their integration into classroom practice.",
            "author": [
                "Paul Denny",
                "Juho Leinonen",
                "James Prather",
                "Andrew Luxton-Reilly",
                "Thezyrie Amarouche",
                "Brett A. Becker",
                "Brent N. Reeves"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05943v1",
                "http://arxiv.org/pdf/2311.05943v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05941v1",
            "title": "Learning-Augmented Scheduling for Solar-Powered Electric Vehicle\n  Charging",
            "updated": "2023-11-10T08:54:51Z",
            "published": "2023-11-10T08:54:51Z",
            "summary": "We tackle the complex challenge of scheduling the charging of electric\nvehicles (EVs) equipped with solar panels and batteries, particularly under\nout-of-distribution (OOD) conditions. Traditional scheduling approaches, such\nas reinforcement learning (RL) and model predictive control (MPC), often fail\nto provide satisfactory results when faced with OOD data, struggling to balance\nrobustness (worst-case performance) and consistency (near-optimal average\nperformance). To address this gap, we introduce a novel learning-augmented\npolicy. This policy employs a dynamic robustness budget, which is adapted in\nreal-time based on the reinforcement learning policy's performance.\nSpecifically, it leverages the temporal difference (TD) error, a measure of the\nlearning policy's prediction accuracy, to assess the trustworthiness of the\nmachine-learned policy. This method allows for a more effective balance between\nconsistency and robustness in EV charging schedules, significantly enhancing\nadaptability and efficiency in real-world, unpredictable environments. Our\nresults demonstrate that this approach markedly improves scheduling\neffectiveness and reliability, particularly in OOD contexts, paving the way for\nmore resilient and adaptive EV charging systems.",
            "author": [
                "Tongxin Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05941v1",
                "http://arxiv.org/pdf/2311.05941v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.LG",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05938v1",
            "title": "Efficient Learning of Fast Inverse Kinematics with Collision Avoidance",
            "updated": "2023-11-10T08:52:40Z",
            "published": "2023-11-10T08:52:40Z",
            "summary": "Fast inverse kinematics (IK) is a central component in robotic motion\nplanning. For complex robots, IK methods are often based on root search and\nnon-linear optimization algorithms. These algorithms can be massively sped up\nusing a neural network to predict a good initial guess, which can then be\nrefined in a few numerical iterations. Besides previous work on learning-based\nIK, we present a learning approach for the fundamentally more complex problem\nof IK with collision avoidance. We do this in diverse and previously unseen\nenvironments. From a detailed analysis of the IK learning problem, we derive a\nnetwork and unsupervised learning architecture that removes the need for a\nsample data generation step. Using the trained network's prediction as an\ninitial guess for a two-stage Jacobian-based solver allows for fast and\naccurate computation of the collision-free IK. For the humanoid robot, Agile\nJustin (19 DoF), the collision-free IK is solved in less than 10 milliseconds\n(on a single CPU core) and with an accuracy of 10^-4 m and 10^-3 rad based on a\nhigh-resolution world model generated from the robot's integrated 3D sensor.\nOur method massively outperforms a random multi-start baseline in a benchmark\nwith the 19 DoF humanoid and challenging 3D environments. It requires ten times\nless training time than a supervised training method while achieving comparable\nresults.",
            "author": [
                "Johannes Tenhumberg",
                "Arman Mielke",
                "Berthold B\u00e4uml"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05938v1",
                "http://arxiv.org/pdf/2311.05938v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05937v1",
            "title": "Genetic Algorithm enhanced by Deep Reinforcement Learning in parent\n  selection mechanism and mutation : Minimizing makespan in permutation flow\n  shop scheduling problems",
            "updated": "2023-11-10T08:51:42Z",
            "published": "2023-11-10T08:51:42Z",
            "summary": "This paper introduces a reinforcement learning (RL) approach to address the\nchallenges associated with configuring and optimizing genetic algorithms (GAs)\nfor solving difficult combinatorial or non-linear problems. The proposed RL+GA\nmethod was specifically tested on the flow shop scheduling problem (FSP). The\nhybrid algorithm incorporates neural networks (NN) and uses the off-policy\nmethod Q-learning or the on-policy method Sarsa(0) to control two key genetic\nalgorithm (GA) operators: parent selection mechanism and mutation. At each\ngeneration, the RL agent's action is determining the selection method, the\nprobability of the parent selection and the probability of the offspring\nmutation. This allows the RL agent to dynamically adjust the selection and\nmutation based on its learned policy. The results of the study highlight the\neffectiveness of the RL+GA approach in improving the performance of the\nprimitive GA. They also demonstrate its ability to learn and adapt from\npopulation diversity and solution improvements over time. This adaptability\nleads to improved scheduling solutions compared to static parameter\nconfigurations while maintaining population diversity throughout the\nevolutionary process.",
            "author": [
                "Maissa Irmouli",
                "Nourelhouda Benazzoug",
                "Alaa Dania Adimi",
                "Fatma Zohra Rezkellah",
                "Imane Hamzaoui",
                "Thanina Hamitouche"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05937v1",
                "http://arxiv.org/pdf/2311.05937v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05936v1",
            "title": "Aggregation Weighting of Federated Learning via Generalization Bound\n  Estimation",
            "updated": "2023-11-10T08:50:28Z",
            "published": "2023-11-10T08:50:28Z",
            "summary": "Federated Learning (FL) typically aggregates client model parameters using a\nweighting approach determined by sample proportions. However, this naive\nweighting method may lead to unfairness and degradation in model performance\ndue to statistical heterogeneity and the inclusion of noisy data among clients.\nTheoretically, distributional robustness analysis has shown that the\ngeneralization performance of a learning model with respect to any shifted\ndistribution is bounded. This motivates us to reconsider the weighting approach\nin federated learning. In this paper, we replace the aforementioned weighting\nmethod with a new strategy that considers the generalization bounds of each\nlocal model. Specifically, we estimate the upper and lower bounds of the\nsecond-order origin moment of the shifted distribution for the current local\nmodel, and then use these bounds disagreements as the aggregation proportions\nfor weightings in each communication round. Experiments demonstrate that the\nproposed weighting strategy significantly improves the performance of several\nrepresentative FL algorithms on benchmark datasets.",
            "author": [
                "Mingwei Xu",
                "Xiaofeng Cao",
                "Ivor W. Tsang",
                "James T. Kwok"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05936v1",
                "http://arxiv.org/pdf/2311.05936v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05931v1",
            "title": "Anytime-Valid Confidence Sequences for Consistent Uncertainty Estimation\n  in Early-Exit Neural Networks",
            "updated": "2023-11-10T08:38:18Z",
            "published": "2023-11-10T08:38:18Z",
            "summary": "Early-exit neural networks (EENNs) facilitate adaptive inference by producing\npredictions at multiple stages of the forward pass. In safety-critical\napplications, these predictions are only meaningful when complemented with\nreliable uncertainty estimates. Yet, due to their sequential structure, an\nEENN's uncertainty estimates should also be consistent: labels that are deemed\nimprobable at one exit should not reappear within the confidence interval / set\nof later exits. We show that standard uncertainty quantification techniques,\nlike Bayesian methods or conformal prediction, can lead to inconsistency across\nexits. We address this problem by applying anytime-valid confidence sequences\n(AVCSs) to the exits of EENNs. By design, AVCSs maintain consistency across\nexits. We examine the theoretical and practical challenges of applying AVCSs to\nEENNs and empirically validate our approach on both regression and\nclassification tasks.",
            "author": [
                "Metod Jazbec",
                "Patrick Forr\u00e9",
                "Stephan Mandt",
                "Dan Zhang",
                "Eric Nalisnick"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05931v1",
                "http://arxiv.org/pdf/2311.05931v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14699v1",
            "title": "Ontology Learning Using Formal Concept Analysis and WordNet",
            "updated": "2023-11-10T08:28:30Z",
            "published": "2023-11-10T08:28:30Z",
            "summary": "Manual ontology construction takes time, resources, and domain specialists.\nSupporting a component of this process for automation or semi-automation would\nbe good. This project and dissertation provide a Formal Concept Analysis and\nWordNet framework for learning concept hierarchies from free texts. The process\nhas steps. First, the document is Part-Of-Speech labeled, then parsed to\nproduce sentence parse trees. Verb/noun dependencies are derived from parse\ntrees next. After lemmatizing, pruning, and filtering the word pairings, the\nformal context is created. The formal context may contain some erroneous and\nuninteresting pairs because the parser output may be erroneous, not all derived\npairs are interesting, and it may be large due to constructing it from a large\nfree text corpus. Deriving lattice from the formal context may take longer,\ndepending on the size and complexity of the data. Thus, decreasing formal\ncontext may eliminate erroneous and uninteresting pairs and speed up idea\nlattice derivation. WordNet-based and Frequency-based approaches are tested.\nFinally, we compute formal idea lattice and create a classical concept\nhierarchy. The reduced concept lattice is compared to the original to evaluate\nthe outcomes. Despite several system constraints and component discrepancies\nthat may prevent logical conclusion, the following data imply idea hierarchies\nin this project and dissertation are promising. First, the reduced idea lattice\nand original concept have commonalities. Second, alternative language or\nstatistical methods can reduce formal context size. Finally, WordNet-based and\nFrequency-based approaches reduce formal context differently, and the order of\napplying them is examined to reduce context efficiently.",
            "author": [
                "Bryar A. Hassan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14699v1",
                "http://arxiv.org/pdf/2311.14699v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05928v1",
            "title": "The Shape of Learning: Anisotropy and Intrinsic Dimensions in\n  Transformer-Based Models",
            "updated": "2023-11-10T08:25:02Z",
            "published": "2023-11-10T08:25:02Z",
            "summary": "In this study, we present an investigation into the anisotropy dynamics and\nintrinsic dimension of embeddings in transformer architectures, focusing on the\ndichotomy between encoders and decoders. Our findings reveal that the\nanisotropy profile in transformer decoders exhibits a distinct bell-shaped\ncurve, with the highest anisotropy concentrations in the middle layers. This\npattern diverges from the more uniformly distributed anisotropy observed in\nencoders. In addition, we found that the intrinsic dimension of embeddings\nincreases in the initial phases of training, indicating an expansion into\nhigher-dimensional space. Which is then followed by a compression phase towards\nthe end of training with dimensionality decrease, suggesting a refinement into\nmore compact representations. Our results provide fresh insights to the\nunderstanding of encoders and decoders embedding properties.",
            "author": [
                "Anton Razzhigaev",
                "Matvey Mikhalchuk",
                "Elizaveta Goncharova",
                "Ivan Oseledets",
                "Denis Dimitrov",
                "Andrey Kuznetsov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05928v1",
                "http://arxiv.org/pdf/2311.05928v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.IT",
                "cs.LG",
                "math.GN",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05927v2",
            "title": "Automated Sperm Assessment Framework and Neural Network Specialized for\n  Sperm Video Recognition",
            "updated": "2023-11-13T01:56:27Z",
            "published": "2023-11-10T08:23:24Z",
            "summary": "Infertility is a global health problem, and an increasing number of couples\nare seeking medical assistance to achieve reproduction, at least half of which\nare caused by men. The success rate of assisted reproductive technologies\ndepends on sperm assessment, in which experts determine whether sperm can be\nused for reproduction based on morphology and motility of sperm. Previous sperm\nassessment studies with deep learning have used datasets comprising images that\ninclude only sperm heads, which cannot consider motility and other morphologies\nof sperm. Furthermore, the labels of the dataset are one-hot, which provides\ninsufficient support for experts, because assessment results are inconsistent\nbetween experts, and they have no absolute answer. Therefore, we constructed\nthe video dataset for sperm assessment whose videos include sperm head as well\nas neck and tail, and its labels were annotated with soft-label. Furthermore,\nwe proposed the sperm assessment framework and the neural network, RoSTFine,\nfor sperm video recognition. Experimental results showed that RoSTFine could\nimprove the sperm assessment performances compared to existing video\nrecognition models and focus strongly on important sperm parts (i.e., head and\nneck).",
            "author": [
                "Takuro Fujii",
                "Hayato Nakagawa",
                "Teppei Takeshima",
                "Yasushi Yumura",
                "Tomoki Hamagami"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05927v2",
                "http://arxiv.org/pdf/2311.05927v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05924v1",
            "title": "Federated Learning with Manifold Regularization and Normalized Update\n  Reaggregation",
            "updated": "2023-11-10T08:14:27Z",
            "published": "2023-11-10T08:14:27Z",
            "summary": "Federated Learning (FL) is an emerging collaborative machine learning\nframework where multiple clients train the global model without sharing their\nown datasets. In FL, the model inconsistency caused by the local data\nheterogeneity across clients results in the near-orthogonality of client\nupdates, which leads to the global update norm reduction and slows down the\nconvergence. Most previous works focus on eliminating the difference of\nparameters (or gradients) between the local and global models, which may fail\nto reflect the model inconsistency due to the complex structure of the machine\nlearning model and the Euclidean space's limitation in meaningful geometric\nrepresentations. In this paper, we propose FedMRUR by adopting the manifold\nmodel fusion scheme and a new global optimizer to alleviate the negative\nimpacts. Concretely, FedMRUR adopts a hyperbolic graph manifold regularizer\nenforcing the representations of the data in the local and global models are\nclose to each other in a low-dimensional subspace. Because the machine learning\nmodel has the graph structure, the distance in hyperbolic space can reflect the\nmodel bias better than the Euclidean distance. In this way, FedMRUR exploits\nthe manifold structures of the representations to significantly reduce the\nmodel inconsistency. FedMRUR also aggregates the client updates norms as the\nglobal update norm, which can appropriately enlarge each client's contribution\nto the global update, thereby mitigating the norm reduction introduced by the\nnear-orthogonality of client updates. Furthermore, we theoretically prove that\nour algorithm can achieve a linear speedup property for non-convex setting\nunder partial client participation.Experiments demonstrate that FedMRUR can\nachieve a new state-of-the-art (SOTA) accuracy with less communication.",
            "author": [
                "Xuming An",
                "Li Shen",
                "Han Hu",
                "Yong Luo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05924v1",
                "http://arxiv.org/pdf/2311.05924v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05922v2",
            "title": "Chain of Thought with Explicit Evidence Reasoning for Few-shot Relation\n  Extraction",
            "updated": "2023-11-15T05:23:04Z",
            "published": "2023-11-10T08:12:00Z",
            "summary": "Few-shot relation extraction involves identifying the type of relationship\nbetween two specific entities within a text, using a limited number of\nannotated samples. A variety of solutions to this problem have emerged by\napplying meta-learning and neural graph techniques which typically necessitate\na training process for adaptation. Recently, the strategy of in-context\nlearning has been demonstrating notable results without the need of training.\nFew studies have already utilized in-context learning for zero-shot information\nextraction. Unfortunately, the evidence for inference is either not considered\nor implicitly modeled during the construction of chain-of-thought prompts. In\nthis paper, we propose a novel approach for few-shot relation extraction using\nlarge language models, named CoT-ER, chain-of-thought with explicit evidence\nreasoning. In particular, CoT-ER first induces large language models to\ngenerate evidences using task-specific and concept-level knowledge. Then these\nevidences are explicitly incorporated into chain-of-thought prompting for\nrelation extraction. Experimental results demonstrate that our CoT-ER approach\n(with 0% training data) achieves competitive performance compared to the\nfully-supervised (with 100% training data) state-of-the-art approach on the\nFewRel1.0 and FewRel2.0 datasets.",
            "author": [
                "Xilai Ma",
                "Jing Li",
                "Min Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05922v2",
                "http://arxiv.org/pdf/2311.05922v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05921v1",
            "title": "A Wi-Fi Signal-Based Human Activity Recognition Using High-Dimensional\n  Factor Models",
            "updated": "2023-11-10T08:09:51Z",
            "published": "2023-11-10T08:09:51Z",
            "summary": "Passive sensing techniques based on Wi-Fi signals have emerged as a promising\ntechnology in advanced wireless communication systems due to their widespread\napplication and cost-effectiveness. However, the proliferation of low-cost\nInternet of Things (IoT) devices has led to dense network deployments,\nresulting in increased levels of noise and interference in Wi-Fi environments.\nThis, in turn, leads to noisy and redundant Channel State Information (CSI)\ndata. As a consequence, the accuracy of human activity recognition based on\nWi-Fi signals is compromised. To address this issue, we propose a novel CSI\ndata signal extraction method. We established a human activity recognition\nsystem based on the Intel 5300 network interface cards (NICs) and collected a\ndataset containing six categories of human activities. Using our approach,\nsignals extracted from the CSI data serve as inputs to machine learning (ML)\nclassification algorithms to evaluate classification performance. In comparison\nto ML methods based on Principal Component Analysis (PCA), our proposed\nHigh-Dimensional Factor Model (HDFM) method improves recognition accuracy by\n6.8%.",
            "author": [
                "Junshuo Liu",
                "Fuhai Wang",
                "Zhe Li",
                "Rujing Xiong",
                "Tiebin Mi",
                "Robert Caiming Qiu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05921v1",
                "http://arxiv.org/pdf/2311.05921v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05917v1",
            "title": "Intramolecular and water mediated tautomerism of solvated glycine",
            "updated": "2023-11-10T08:04:54Z",
            "published": "2023-11-10T08:04:54Z",
            "summary": "The understanding of prototropic tautomerism in water and the\ncharacterization of solvent effects on protomeric equilibrium pose significant\nchallenges. Using molecular dynamics simulations based on state-of-the-art deep\nlearning potential and enhanced sampling methods, we provide a comprehensive\ndescription of all configurational transformations in glycine solvated in water\nand determine accurate free energy profiles of these processes. We observe that\nthe tautomerism between the neutral and zwitterionic forms of solvated glycine\ncan occur by both intramolecular proton transfer in glycine and intermolecular\nproton transfer in the contact ion pair (anionic glycine and hydronium ion) or\nthe separated ion pair (cationic glycine and hydroxide ion).",
            "author": [
                "Pengchao Zhang",
                "Axel Tosello Gardini",
                "Xuefei Xu",
                "Michele Parrinello"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05917v1",
                "http://arxiv.org/pdf/2311.05917v1"
            ],
            "primary_category": "cond-mat.soft",
            "category": [
                "cond-mat.soft",
                "physics.chem-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05911v1",
            "title": "An alternative for one-hot encoding in neural network models",
            "updated": "2023-11-10T07:42:08Z",
            "published": "2023-11-10T07:42:08Z",
            "summary": "This paper proposes an algorithm that implements binary encoding of the\ncategorical features of neural network model input data, while also\nimplementing changes in the forward and backpropagation procedures in order to\nachieve the property of having model weight changes, that result from the\nneural network learning process for certain data instances of some feature\ncategory, only affect the forward pass calculations for input data instances of\nthat same feature category, as it is in the case of utilising one-hot encoding\nfor categorical features.",
            "author": [
                "Lazar Zlati\u0107"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05911v1",
                "http://arxiv.org/pdf/2311.05911v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05908v1",
            "title": "FlashFFTConv: Efficient Convolutions for Long Sequences with Tensor\n  Cores",
            "updated": "2023-11-10T07:33:35Z",
            "published": "2023-11-10T07:33:35Z",
            "summary": "Convolution models with long filters have demonstrated state-of-the-art\nreasoning abilities in many long-sequence tasks but lag behind the most\noptimized Transformers in wall-clock time. A major bottleneck is the Fast\nFourier Transform (FFT)--which allows long convolutions to run in $O(N logN)$\ntime in sequence length $N$ but has poor hardware utilization. In this paper,\nwe study how to optimize the FFT convolution. We find two key bottlenecks: the\nFFT does not effectively use specialized matrix multiply units, and it incurs\nexpensive I/O between layers of the memory hierarchy. In response, we propose\nFlashFFTConv. FlashFFTConv uses a matrix decomposition that computes the FFT\nusing matrix multiply units and enables kernel fusion for long sequences,\nreducing I/O. We also present two sparse convolution algorithms--1) partial\nconvolutions and 2) frequency-sparse convolutions--which can be implemented\nsimply by skipping blocks in the matrix decomposition, enabling further\nopportunities for memory and compute savings. FlashFFTConv speeds up exact FFT\nconvolutions by up to 7.93$\\times$ over PyTorch and achieves up to 4.4$\\times$\nspeedup end-to-end. Given the same compute budget, FlashFFTConv allows\nHyena-GPT-s to achieve 2.3 points better perplexity on the PILE and\nM2-BERT-base to achieve 3.3 points higher GLUE score--matching models with\ntwice the parameter count. FlashFFTConv also achieves 96.1% accuracy on\nPath-512, a high-resolution vision task where no model had previously achieved\nbetter than 50%. Furthermore, partial convolutions enable longer-sequence\nmodels--yielding the first DNA model that can process the longest human genes\n(2.3M base pairs)--and frequency-sparse convolutions speed up pretrained models\nwhile maintaining or improving model quality.",
            "author": [
                "Daniel Y. Fu",
                "Hermann Kumbong",
                "Eric Nguyen",
                "Christopher R\u00e9"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05908v1",
                "http://arxiv.org/pdf/2311.05908v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06321v1",
            "title": "Can Machine Learning Uncover Insights into Vehicle Travel Demand from\n  Our Built Environment?",
            "updated": "2023-11-10T06:52:17Z",
            "published": "2023-11-10T06:52:17Z",
            "summary": "In this paper, we propose a machine learning-based approach to address the\nlack of ability for designers to optimize urban land use planning from the\nperspective of vehicle travel demand. Research shows that our computational\nmodel can help designers quickly obtain feedback on the vehicle travel demand,\nwhich includes its total amount and temporal distribution based on the urban\nfunction distribution designed by the designers. It also assists in design\noptimization and evaluation of the urban function distribution from the\nperspective of vehicle travel. We obtain the city function distribution\ninformation and vehicle hours traveled (VHT) information by collecting the city\npoint-of-interest (POI) data and online vehicle data. The artificial neural\nnetworks (ANNs) with the best performance in prediction are selected. By using\ndata sets collected in different regions for mutual prediction and remapping\nthe predictions onto a map for visualization, we evaluate the extent to which\nthe computational model sees use across regions in an attempt to reduce the\nworkload of future urban researchers. Finally, we demonstrate the application\nof the computational model to help designers obtain feedback on vehicle travel\ndemand in the built environment and combine it with genetic algorithms to\noptimize the current state of the urban environment to provide recommendations\nto designers.",
            "author": [
                "Zixun Huang",
                "Hao Zheng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06321v1",
                "http://arxiv.org/pdf/2311.06321v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05889v1",
            "title": "Semantic Map Guided Synthesis of Wireless Capsule Endoscopy Images using\n  Diffusion Models",
            "updated": "2023-11-10T06:16:44Z",
            "published": "2023-11-10T06:16:44Z",
            "summary": "Wireless capsule endoscopy (WCE) is a non-invasive method for visualizing the\ngastrointestinal (GI) tract, crucial for diagnosing GI tract diseases. However,\ninterpreting WCE results can be time-consuming and tiring. Existing studies\nhave employed deep neural networks (DNNs) for automatic GI tract lesion\ndetection, but acquiring sufficient training examples, particularly due to\nprivacy concerns, remains a challenge. Public WCE databases lack diversity and\nquantity. To address this, we propose a novel approach leveraging generative\nmodels, specifically the diffusion model (DM), for generating diverse WCE\nimages. Our model incorporates semantic map resulted from visualization scale\n(VS) engine, enhancing the controllability and diversity of generated images.\nWe evaluate our approach using visual inspection and visual Turing tests,\ndemonstrating its effectiveness in generating realistic and diverse WCE images.",
            "author": [
                "Haejin Lee",
                "Jeongwoo Ju",
                "Jonghyuck Lee",
                "Yeoun Joo Lee",
                "Heechul Jung"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05889v1",
                "http://arxiv.org/pdf/2311.05889v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05888v1",
            "title": "Low-Multi-Rank High-Order Bayesian Robust Tensor Factorization",
            "updated": "2023-11-10T06:15:38Z",
            "published": "2023-11-10T06:15:38Z",
            "summary": "The recently proposed tensor robust principal component analysis (TRPCA)\nmethods based on tensor singular value decomposition (t-SVD) have achieved\nnumerous successes in many fields. However, most of these methods are only\napplicable to third-order tensors, whereas the data obtained in practice are\noften of higher order, such as fourth-order color videos, fourth-order\nhyperspectral videos, and fifth-order light-field images. Additionally, in the\nt-SVD framework, the multi-rank of a tensor can describe more fine-grained\nlow-rank structure in the tensor compared with the tubal rank. However,\ndetermining the multi-rank of a tensor is a much more difficult problem than\ndetermining the tubal rank. Moreover, most of the existing TRPCA methods do not\nexplicitly model the noises except the sparse noise, which may compromise the\naccuracy of estimating the low-rank tensor. In this work, we propose a novel\nhigh-order TRPCA method, named as Low-Multi-rank High-order Bayesian Robust\nTensor Factorization (LMH-BRTF), within the Bayesian framework. Specifically,\nwe decompose the observed corrupted tensor into three parts, i.e., the low-rank\ncomponent, the sparse component, and the noise component. By constructing a\nlow-rank model for the low-rank component based on the order-$d$ t-SVD and\nintroducing a proper prior for the model, LMH-BRTF can automatically determine\nthe tensor multi-rank. Meanwhile, benefiting from the explicit modeling of both\nthe sparse and noise components, the proposed method can leverage information\nfrom the noises more effectivly, leading to an improved performance of TRPCA.\nThen, an efficient variational inference algorithm is established for\nparameters estimation. Empirical studies on synthetic and real-world datasets\ndemonstrate the effectiveness of the proposed method in terms of both\nqualitative and quantitative results.",
            "author": [
                "Jianan Liu",
                "Chunguang Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05888v1",
                "http://arxiv.org/pdf/2311.05888v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05884v1",
            "title": "Hiformer: Heterogeneous Feature Interactions Learning with Transformers\n  for Recommender Systems",
            "updated": "2023-11-10T05:57:57Z",
            "published": "2023-11-10T05:57:57Z",
            "summary": "Learning feature interaction is the critical backbone to building recommender\nsystems. In web-scale applications, learning feature interaction is extremely\nchallenging due to the sparse and large input feature space; meanwhile,\nmanually crafting effective feature interactions is infeasible because of the\nexponential solution space. We propose to leverage a Transformer-based\narchitecture with attention layers to automatically capture feature\ninteractions. Transformer architectures have witnessed great success in many\ndomains, such as natural language processing and computer vision. However,\nthere has not been much adoption of Transformer architecture for feature\ninteraction modeling in industry. We aim at closing the gap. We identify two\nkey challenges for applying the vanilla Transformer architecture to web-scale\nrecommender systems: (1) Transformer architecture fails to capture the\nheterogeneous feature interactions in the self-attention layer; (2) The serving\nlatency of Transformer architecture might be too high to be deployed in\nweb-scale recommender systems. We first propose a heterogeneous self-attention\nlayer, which is a simple yet effective modification to the self-attention layer\nin Transformer, to take into account the heterogeneity of feature interactions.\nWe then introduce \\textsc{Hiformer} (\\textbf{H}eterogeneous\n\\textbf{I}nteraction Trans\\textbf{former}) to further improve the model\nexpressiveness. With low-rank approximation and model pruning, \\hiformer enjoys\nfast inference for online deployment. Extensive offline experiment results\ncorroborates the effectiveness and efficiency of the \\textsc{Hiformer} model.\nWe have successfully deployed the \\textsc{Hiformer} model to a real world large\nscale App ranking model at Google Play, with significant improvement in key\nengagement metrics (up to +2.66\\%).",
            "author": [
                "Huan Gui",
                "Ruoxi Wang",
                "Ke Yin",
                "Long Jin",
                "Maciej Kula",
                "Taibai Xu",
                "Lichan Hong",
                "Ed H. Chi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05884v1",
                "http://arxiv.org/pdf/2311.05884v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05881v1",
            "title": "Programmable Superconducting Optoelectronic Single-Photon Synapses with\n  Integrated Multi-State Memory",
            "updated": "2023-11-10T05:34:44Z",
            "published": "2023-11-10T05:34:44Z",
            "summary": "The co-location of memory and processing is a core principle of neuromorphic\ncomputing. A local memory device for synaptic weight storage has long been\nrecognized as an enabling element for large-scale, high-performance\nneuromorphic hardware. In this work, we demonstrate programmable\nsuperconducting synapses with integrated memories for use in superconducting\noptoelectronic neural systems. Superconducting nanowire single-photon detectors\nand Josephson junctions are combined into programmable synaptic circuits that\nexhibit single-photon sensitivity, memory cells with more than 400 internal\nstates, leaky integration of input spike events, and 0.4 fJ programming\nenergies (including cooling power). These results are attractive for\nimplementing a variety of supervised and unsupervised learning algorithms and\nlay the foundation for a new hardware platform optimized for large-scale\nspiking network accelerators.",
            "author": [
                "Bryce A. Primavera",
                "Saeed Khan",
                "Richard P. Mirin",
                "Sae Woo Nam",
                "Jeffrey M. Shainline"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05881v1",
                "http://arxiv.org/pdf/2311.05881v1"
            ],
            "primary_category": "physics.app-ph",
            "category": [
                "physics.app-ph",
                "cs.ET",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05878v1",
            "title": "Central Angle Optimization for 360-degree Holographic 3D Content",
            "updated": "2023-11-10T05:30:43Z",
            "published": "2023-11-10T05:30:43Z",
            "summary": "In this study, we propose a method to find an optimal central angle in deep\nlearning-based depth map estimation used to produce realistic holographic\ncontent. The acquisition of RGB-depth map images as detailed as possible must\nbe performed to generate holograms of high quality, despite the high\ncomputational cost. Therefore, we introduce a novel pipeline designed to\nanalyze various values of central angles between adjacent camera viewpoints\nequidistant from the origin of an object-centered environment. Then we propose\nthe optimal central angle to generate high-quality holographic content. The\nproposed pipeline comprises key steps such as comparing estimated depth maps\nand comparing reconstructed CGHs (Computer-Generated Holograms) from RGB images\nand estimated depth maps. We experimentally demonstrate and discuss the\nrelationship between the central angle and the quality of digital holographic\ncontent.",
            "author": [
                "Hakdong Kim",
                "Minsung Yoon",
                "Cheongwon Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05878v1",
                "http://arxiv.org/pdf/2311.05878v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05877v1",
            "title": "A Performance-Driven Benchmark for Feature Selection in Tabular Deep\n  Learning",
            "updated": "2023-11-10T05:26:10Z",
            "published": "2023-11-10T05:26:10Z",
            "summary": "Academic tabular benchmarks often contain small sets of curated features. In\ncontrast, data scientists typically collect as many features as possible into\ntheir datasets, and even engineer new features from existing ones. To prevent\noverfitting in subsequent downstream modeling, practitioners commonly use\nautomated feature selection methods that identify a reduced subset of\ninformative features. Existing benchmarks for tabular feature selection\nconsider classical downstream models, toy synthetic datasets, or do not\nevaluate feature selectors on the basis of downstream performance. Motivated by\nthe increasing popularity of tabular deep learning, we construct a challenging\nfeature selection benchmark evaluated on downstream neural networks including\ntransformers, using real datasets and multiple methods for generating\nextraneous features. We also propose an input-gradient-based analogue of Lasso\nfor neural networks that outperforms classical feature selection methods on\nchallenging problems such as selecting from corrupted or second-order features.",
            "author": [
                "Valeriia Cherepanova",
                "Roman Levin",
                "Gowthami Somepalli",
                "Jonas Geiping",
                "C. Bayan Bruss",
                "Andrew Gordon Wilson",
                "Tom Goldstein",
                "Micah Goldblum"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05877v1",
                "http://arxiv.org/pdf/2311.05877v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07593v1",
            "title": "Follow-Up Differential Descriptions: Language Models Resolve Ambiguities\n  for Image Classification",
            "updated": "2023-11-10T05:24:07Z",
            "published": "2023-11-10T05:24:07Z",
            "summary": "A promising approach for improving the performance of vision-language models\nlike CLIP for image classification is to extend the class descriptions (i.e.,\nprompts) with related attributes, e.g., using brown sparrow instead of sparrow.\nHowever, current zero-shot methods select a subset of attributes regardless of\ncommonalities between the target classes, potentially providing no useful\ninformation that would have helped to distinguish between them. For instance,\nthey may use color instead of bill shape to distinguish between sparrows and\nwrens, which are both brown. We propose Follow-up Differential Descriptions\n(FuDD), a zero-shot approach that tailors the class descriptions to each\ndataset and leads to additional attributes that better differentiate the target\nclasses. FuDD first identifies the ambiguous classes for each image, and then\nuses a Large Language Model (LLM) to generate new class descriptions that\ndifferentiate between them. The new class descriptions resolve the initial\nambiguity and help predict the correct label. In our experiments, FuDD\nconsistently outperforms generic description ensembles and naive LLM-generated\ndescriptions on 12 datasets. We show that differential descriptions are an\neffective tool to resolve class ambiguities, which otherwise significantly\ndegrade the performance. We also show that high quality natural language class\ndescriptions produced by FuDD result in comparable performance to few-shot\nadaptation methods.",
            "author": [
                "Reza Esfandiarpoor",
                "Stephen H. Bach"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07593v1",
                "http://arxiv.org/pdf/2311.07593v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05874v1",
            "title": "Testing Dependency of Unlabeled Databases",
            "updated": "2023-11-10T05:17:03Z",
            "published": "2023-11-10T05:17:03Z",
            "summary": "In this paper, we investigate the problem of deciding whether two random\ndatabases $\\mathsf{X}\\in\\mathcal{X}^{n\\times d}$ and\n$\\mathsf{Y}\\in\\mathcal{Y}^{n\\times d}$ are statistically dependent or not. This\nis formulated as a hypothesis testing problem, where under the null hypothesis,\nthese two databases are statistically independent, while under the alternative,\nthere exists an unknown row permutation $\\sigma$, such that $\\mathsf{X}$ and\n$\\mathsf{Y}^\\sigma$, a permuted version of $\\mathsf{Y}$, are statistically\ndependent with some known joint distribution, but have the same marginal\ndistributions as the null. We characterize the thresholds at which optimal\ntesting is information-theoretically impossible and possible, as a function of\n$n$, $d$, and some spectral properties of the generative distributions of the\ndatasets. For example, we prove that if a certain function of the eigenvalues\nof the likelihood function and $d$, is below a certain threshold, as\n$d\\to\\infty$, then weak detection (performing slightly better than random\nguessing) is statistically impossible, no matter what the value of $n$ is. This\nmimics the performance of an efficient test that thresholds a centered version\nof the log-likelihood function of the observed matrices. We also analyze the\ncase where $d$ is fixed, for which we derive strong (vanishing error) and weak\ndetection lower and upper bounds.",
            "author": [
                "Vered Paslev",
                "Wasim Huleihel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05874v1",
                "http://arxiv.org/pdf/2311.05874v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.IT",
                "math.IT",
                "math.ST",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05873v2",
            "title": "Provably Trainable Rotationally Equivariant Quantum Machine Learning",
            "updated": "2023-11-26T14:23:02Z",
            "published": "2023-11-10T05:10:06Z",
            "summary": "Exploiting the power of quantum computation to realise superior machine\nlearning algorithmshas been a major research focus of recent years, but the\nprospects of quantum machine learning (QML) remain dampened by considerable\ntechnical challenges. A particularly significant issue is that generic QML\nmodels suffer from so-called barren plateaus in their training landscapes --\nlarge regions where cost function gradients vanish exponentially in the number\nof qubits employed, rendering large models effectively untrainable. A leading\nstrategy for combating this effect is to build problem-specific models which\ntake into account the symmetries of their data in order to focus on a smaller,\nrelevant subset of Hilbert space. In this work, we introduce a family of\nrotationally equivariant QML models built upon the quantum Fourier transform,\nand leverage recent insights from the Lie-algebraic study of QML models to\nprove that (a subset of) our models do not exhibit barren plateaus. In addition\nto our analytical results we numerically test our rotationally equivariant\nmodels on a dataset of simulated scanning tunnelling microscope images of\nphosphorus impurities in silicon, where rotational symmetry naturally arises,\nand find that they dramatically outperform their generic counterparts in\npractice.",
            "author": [
                "Maxwell T. West",
                "Jamie Heredge",
                "Martin Sevior",
                "Muhammad Usman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05873v2",
                "http://arxiv.org/pdf/2311.05873v2"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05870v1",
            "title": "Automated Heterogeneous Low-Bit Quantization of Multi-Model Deep\n  Learning Inference Pipeline",
            "updated": "2023-11-10T05:02:20Z",
            "published": "2023-11-10T05:02:20Z",
            "summary": "Multiple Deep Neural Networks (DNNs) integrated into single Deep Learning\n(DL) inference pipelines e.g. Multi-Task Learning (MTL) or Ensemble Learning\n(EL), etc., albeit very accurate, pose challenges for edge deployment. In these\nsystems, models vary in their quantization tolerance and resource demands,\nrequiring meticulous tuning for accuracy-latency balance. This paper introduces\nan automated heterogeneous quantization approach for DL inference pipelines\nwith multiple DNNs.",
            "author": [
                "Jayeeta Mondal",
                "Swarnava Dey",
                "Arijit Mukherjee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05870v1",
                "http://arxiv.org/pdf/2311.05870v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05866v1",
            "title": "Fair Supervised Learning with A Simple Random Sampler of Sensitive\n  Attributes",
            "updated": "2023-11-10T04:38:13Z",
            "published": "2023-11-10T04:38:13Z",
            "summary": "As the data-driven decision process becomes dominating for industrial\napplications, fairness-aware machine learning arouses great attention in\nvarious areas. This work proposes fairness penalties learned by neural networks\nwith a simple random sampler of sensitive attributes for non-discriminatory\nsupervised learning. In contrast to many existing works that critically rely on\nthe discreteness of sensitive attributes and response variables, the proposed\npenalty is able to handle versatile formats of the sensitive attributes, so it\nis more extensively applicable in practice than many existing algorithms. This\npenalty enables us to build a computationally efficient group-level\nin-processing fairness-aware training framework. Empirical evidence shows that\nour framework enjoys better utility and fairness measures on popular benchmark\ndata sets than competing methods. We also theoretically characterize estimation\nerrors and loss of utility of the proposed neural-penalized risk minimization\nproblem.",
            "author": [
                "Jinwon Sohn",
                "Qifan Song",
                "Guang Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05866v1",
                "http://arxiv.org/pdf/2311.05866v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05862v1",
            "title": "Emergence and reconfiguration of modular structure for synaptic neural\n  networks during continual familiarity detection",
            "updated": "2023-11-10T04:16:38Z",
            "published": "2023-11-10T04:16:38Z",
            "summary": "While advances in artificial intelligence and neuroscience have enabled the\nemergence of neural networks capable of learning a wide variety of tasks, our\nunderstanding of the temporal dynamics of these networks remains limited. Here,\nwe study the temporal dynamics during learning of Hebbian Feedforward (HebbFF)\nneural networks in tasks of continual familiarity detection. Drawing\ninspiration from the field of network neuroscience, we examine the network's\ndynamic reconfiguration, focusing on how network modules evolve throughout\nlearning. Through a comprehensive assessment involving metrics like network\naccuracy, modular flexibility, and distribution entropy across diverse learning\nmodes, our approach reveals various previously unknown patterns of network\nreconfiguration. In particular, we find that the emergence of network\nmodularity is a salient predictor of performance, and that modularization\nstrengthens with increasing flexibility throughout learning. These insights not\nonly elucidate the nuanced interplay of network modularity, accuracy, and\nlearning dynamics but also bridge our understanding of learning in artificial\nand biological realms.",
            "author": [
                "Shi Gu",
                "Marcelo G Mattar",
                "Huajin Tang",
                "Gang Pan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05862v1",
                "http://arxiv.org/pdf/2311.05862v1"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05861v1",
            "title": "Domain Generalization by Learning from Privileged Medical Imaging\n  Information",
            "updated": "2023-11-10T04:09:52Z",
            "published": "2023-11-10T04:09:52Z",
            "summary": "Learning the ability to generalize knowledge between similar contexts is\nparticularly important in medical imaging as data distributions can shift\nsubstantially from one hospital to another, or even from one machine to\nanother. To strengthen generalization, most state-of-the-art techniques inject\nknowledge of the data distribution shifts by enforcing constraints on learned\nfeatures or regularizing parameters. We offer an alternative approach: Learning\nfrom Privileged Medical Imaging Information (LPMII). We show that using some\nprivileged information such as tumor shape or location leads to stronger domain\ngeneralization ability than current state-of-the-art techniques. This paper\ndemonstrates that by using privileged information to predict the severity of\nintra-layer retinal fluid in optical coherence tomography scans, the\nclassification accuracy of a deep learning model operating on\nout-of-distribution data improves from $0.911$ to $0.934$. This paper provides\na strong starting point for using privileged information in other medical\nproblems requiring generalization.",
            "author": [
                "Steven Korevaar",
                "Ruwan Tennakoon",
                "Ricky O'Brien",
                "Dwarikanath Mahapatra",
                "Alireza Bab-Hadiasha"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05861v1",
                "http://arxiv.org/pdf/2311.05861v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05858v3",
            "title": "Layer-wise Auto-Weighting for Non-Stationary Test-Time Adaptation",
            "updated": "2023-11-26T08:02:41Z",
            "published": "2023-11-10T03:54:40Z",
            "summary": "Given the inevitability of domain shifts during inference in real-world\napplications, test-time adaptation (TTA) is essential for model adaptation\nafter deployment. However, the real-world scenario of continuously changing\ntarget distributions presents challenges including catastrophic forgetting and\nerror accumulation. Existing TTA methods for non-stationary domain shifts,\nwhile effective, incur excessive computational load, making them impractical\nfor on-device settings. In this paper, we introduce a layer-wise auto-weighting\nalgorithm for continual and gradual TTA that autonomously identifies layers for\npreservation or concentrated adaptation. By leveraging the Fisher Information\nMatrix (FIM), we first design the learning weight to selectively focus on\nlayers associated with log-likelihood changes while preserving unrelated ones.\nThen, we further propose an exponential min-max scaler to make certain layers\nnearly frozen while mitigating outliers. This minimizes forgetting and error\naccumulation, leading to efficient adaptation to non-stationary target\ndistribution. Experiments on CIFAR-10C, CIFAR-100C, and ImageNet-C show our\nmethod outperforms conventional continual and gradual TTA approaches while\nsignificantly reducing computational load, highlighting the importance of\nFIM-based learning weight in adapting to continuously or gradually shifting\ntarget domains.",
            "author": [
                "Junyoung Park",
                "Jin Kim",
                "Hyeongjun Kwon",
                "Ilhoon Yoon",
                "Kwanghoon Sohn"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05858v3",
                "http://arxiv.org/pdf/2311.05858v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05853v1",
            "title": "Reframing Audience Expansion through the Lens of Probability Density\n  Estimation",
            "updated": "2023-11-10T03:25:53Z",
            "published": "2023-11-10T03:25:53Z",
            "summary": "Audience expansion has become an important element of prospective marketing,\nhelping marketers create target audiences based on a mere representative sample\nof their current customer base. Within the realm of machine learning, a favored\nalgorithm for scaling this sample into a broader audience hinges on a binary\nclassification task, with class probability estimates playing a crucial role.\nIn this paper, we review this technique and introduce a key change in how we\nchoose training examples to ensure the quality of the generated audience. We\npresent a simulation study based on the widely used MNIST dataset, where\nconsistent high precision and recall values demonstrate our approach's ability\nto identify the most relevant users for an expanded audience. Our results are\neasily reproducible and a Python implementation is openly available on GitHub:\n\\url{https://github.com/carvalhaes-ai/audience-expansion}",
            "author": [
                "Claudio Carvalhaes"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05853v1",
                "http://arxiv.org/pdf/2311.05853v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05846v1",
            "title": "Clipped-Objective Policy Gradients for Pessimistic Policy Optimization",
            "updated": "2023-11-10T03:02:49Z",
            "published": "2023-11-10T03:02:49Z",
            "summary": "To facilitate efficient learning, policy gradient approaches to deep\nreinforcement learning (RL) are typically paired with variance reduction\nmeasures and strategies for making large but safe policy changes based on a\nbatch of experiences. Natural policy gradient methods, including Trust Region\nPolicy Optimization (TRPO), seek to produce monotonic improvement through\nbounded changes in policy outputs. Proximal Policy Optimization (PPO) is a\ncommonly used, first-order algorithm that instead uses loss clipping to take\nmultiple safe optimization steps per batch of data, replacing the bound on the\nsingle step of TRPO with regularization on multiple steps. In this work, we\nfind that the performance of PPO, when applied to continuous action spaces, may\nbe consistently improved through a simple change in objective. Instead of the\nimportance sampling objective of PPO, we instead recommend a basic policy\ngradient, clipped in an equivalent fashion. While both objectives produce\nbiased gradient estimates with respect to the RL objective, they also both\ndisplay significantly reduced variance compared to the unbiased off-policy\npolicy gradient. Additionally, we show that (1) the clipped-objective policy\ngradient (COPG) objective is on average \"pessimistic\" compared to both the PPO\nobjective and (2) this pessimism promotes enhanced exploration. As a result, we\nempirically observe that COPG produces improved learning compared to PPO in\nsingle-task, constrained, and multi-task learning, without adding significant\ncomputational cost or complexity. Compared to TRPO, the COPG approach is seen\nto offer comparable or superior performance, while retaining the simplicity of\na first-order method.",
            "author": [
                "Jared Markowitz",
                "Edward W. Staley"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05846v1",
                "http://arxiv.org/pdf/2311.05846v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05845v1",
            "title": "Tamil-Llama: A New Tamil Language Model Based on Llama 2",
            "updated": "2023-11-10T03:02:39Z",
            "published": "2023-11-10T03:02:39Z",
            "summary": "Language modeling has witnessed remarkable advancements in recent years, with\nLarge Language Models (LLMs) like ChatGPT setting unparalleled benchmarks in\nhuman-like text generation. However, a prevailing limitation is the\nunderrepresentation of languages like Tamil in these cutting-edge models,\nleading to suboptimal performance in diverse linguistic contexts. This paper\naddresses this lacuna, enhancing the open-source LLaMA model with an addition\nof 16,000 Tamil tokens, aiming to achieve superior text generation and\ncomprehension in the Tamil language. We strategically employ the LoRA\nmethodology for efficient model training on a comprehensive Tamil corpus,\nensuring computational feasibility and model robustness. Moreover, we introduce\na Tamil-translated version of the Alpaca dataset and a subset of the OpenOrca\ndataset tailored for instruction fine-tuning. Our results showcase significant\nperformance improvements in Tamil text generation, with potential implications\nfor the broader landscape of LLMs in Indian languages. We further underscore\nour commitment to open research by making our models, datasets, and code\npublicly accessible, fostering further innovations in language modeling.",
            "author": [
                "Abhinand Balachandran"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05845v1",
                "http://arxiv.org/pdf/2311.05845v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05842v1",
            "title": "AI-native Interconnect Framework for Integration of Large Language Model\n  Technologies in 6G Systems",
            "updated": "2023-11-10T02:59:16Z",
            "published": "2023-11-10T02:59:16Z",
            "summary": "The evolution towards 6G architecture promises a transformative shift in\ncommunication networks, with artificial intelligence (AI) playing a pivotal\nrole. This paper delves deep into the seamless integration of Large Language\nModels (LLMs) and Generalized Pretrained Transformers (GPT) within 6G systems.\nTheir ability to grasp intent, strategize, and execute intricate commands will\nbe pivotal in redefining network functionalities and interactions. Central to\nthis is the AI Interconnect framework, intricately woven to facilitate\nAI-centric operations within the network. Building on the continuously evolving\ncurrent state-of-the-art, we present a new architectural perspective for the\nupcoming generation of mobile networks. Here, LLMs and GPTs will\ncollaboratively take center stage alongside traditional pre-generative AI and\nmachine learning (ML) algorithms. This union promises a novel confluence of the\nold and new, melding tried-and-tested methods with transformative AI\ntechnologies. Along with providing a conceptual overview of this evolution, we\ndelve into the nuances of practical applications arising from such an\nintegration. Through this paper, we envisage a symbiotic integration where AI\nbecomes the cornerstone of the next-generation communication paradigm, offering\ninsights into the structural and functional facets of an AI-native 6G network.",
            "author": [
                "Sasu Tarkoma",
                "Roberto Morabito",
                "Jaakko Sauvola"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05842v1",
                "http://arxiv.org/pdf/2311.05842v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05836v3",
            "title": "UMedNeRF: Uncertainty-aware Single View Volumetric Rendering for Medical\n  Neural Radiance Fields",
            "updated": "2023-11-17T02:35:52Z",
            "published": "2023-11-10T02:47:15Z",
            "summary": "In the field of clinical medicine, computed tomography (CT) is an effective\nmedical imaging modality for the diagnosis of various pathologies. Compared\nwith X-ray images, CT images can provide more information, including\nmulti-planar slices and three-dimensional structures for clinical diagnosis.\nHowever, CT imaging requires patients to be exposed to large doses of ionizing\nradiation for a long time, which may cause irreversible physical harm. In this\npaper, we propose an Uncertainty-aware MedNeRF (UMedNeRF) network based on\ngenerated radiation fields. The network can learn a continuous representation\nof CT projections from 2D X-ray images by obtaining the internal structure and\ndepth information and using adaptive loss weights to ensure the quality of the\ngenerated images. Our model is trained on publicly available knee and chest\ndatasets, and we show the results of CT projection rendering with a single\nX-ray and compare our method with other methods based on generated radiation\nfields.",
            "author": [
                "Jing Hu",
                "Qinrui Fan",
                "Shu Hu",
                "Siwei Lyu",
                "Xi Wu",
                "Xin Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05836v3",
                "http://arxiv.org/pdf/2311.05836v3"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05828v1",
            "title": "Diffusion Shape Prior for Wrinkle-Accurate Cloth Registration",
            "updated": "2023-11-10T02:20:09Z",
            "published": "2023-11-10T02:20:09Z",
            "summary": "Registering clothes from 4D scans with vertex-accurate correspondence is\nchallenging, yet important for dynamic appearance modeling and physics\nparameter estimation from real-world data. However, previous methods either\nrely on texture information, which is not always reliable, or achieve only\ncoarse-level alignment. In this work, we present a novel approach to enabling\naccurate surface registration of texture-less clothes with large deformation.\nOur key idea is to effectively leverage a shape prior learned from pre-captured\nclothing using diffusion models. We also propose a multi-stage guidance scheme\nbased on learned functional maps, which stabilizes registration for large-scale\ndeformation even when they vary significantly from training data. Using\nhigh-fidelity real captured clothes, our experiments show that the proposed\napproach based on diffusion models generalizes better than surface registration\nwith VAE or PCA-based priors, outperforming both optimization-based and\nlearning-based non-rigid registration methods for both interpolation and\nextrapolation tests.",
            "author": [
                "Jingfan Guo",
                "Fabian Prada",
                "Donglai Xiang",
                "Javier Romero",
                "Chenglei Wu",
                "Hyun Soo Park",
                "Takaaki Shiratori",
                "Shunsuke Saito"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05828v1",
                "http://arxiv.org/pdf/2311.05828v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05827v1",
            "title": "AccEPT: An Acceleration Scheme for Speeding Up Edge Pipeline-parallel\n  Training",
            "updated": "2023-11-10T02:18:33Z",
            "published": "2023-11-10T02:18:33Z",
            "summary": "It is usually infeasible to fit and train an entire large deep neural network\n(DNN) model using a single edge device due to the limited resources. To\nfacilitate intelligent applications across edge devices, researchers have\nproposed partitioning a large model into several sub-models, and deploying each\nof them to a different edge device to collaboratively train a DNN model.\nHowever, the communication overhead caused by the large amount of data\ntransmitted from one device to another during training, as well as the\nsub-optimal partition point due to the inaccurate latency prediction of\ncomputation at each edge device can significantly slow down training. In this\npaper, we propose AccEPT, an acceleration scheme for accelerating the edge\ncollaborative pipeline-parallel training. In particular, we propose a\nlight-weight adaptive latency predictor to accurately estimate the computation\nlatency of each layer at different devices, which also adapts to unseen devices\nthrough continuous learning. Therefore, the proposed latency predictor leads to\nbetter model partitioning which balances the computation loads across\nparticipating devices. Moreover, we propose a bit-level computation-efficient\ndata compression scheme to compress the data to be transmitted between devices\nduring training. Our numerical results demonstrate that our proposed\nacceleration approach is able to significantly speed up edge pipeline parallel\ntraining up to 3 times faster in the considered experimental settings.",
            "author": [
                "Yuhao Chen",
                "Yuxuan Yan",
                "Qianqian Yang",
                "Yuanchao Shu",
                "Shibo He",
                "Zhiguo Shi",
                "Jiming Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05827v1",
                "http://arxiv.org/pdf/2311.05827v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05826v1",
            "title": "Honest Score Client Selection Scheme: Preventing Federated Learning\n  Label Flipping Attacks in Non-IID Scenarios",
            "updated": "2023-11-10T02:07:41Z",
            "published": "2023-11-10T02:07:41Z",
            "summary": "Federated Learning (FL) is a promising technology that enables multiple\nactors to build a joint model without sharing their raw data. The distributed\nnature makes FL vulnerable to various poisoning attacks, including model\npoisoning attacks and data poisoning attacks. Today, many byzantine-resilient\nFL methods have been introduced to mitigate the model poisoning attack, while\nthe effectiveness when defending against data poisoning attacks still remains\nunclear. In this paper, we focus on the most representative data poisoning\nattack - \"label flipping attack\" and monitor its effectiveness when attacking\nthe existing FL methods. The results show that the existing FL methods perform\nsimilarly in Independent and identically distributed (IID) settings but fail to\nmaintain the model robustness in Non-IID settings. To mitigate the weaknesses\nof existing FL methods in Non-IID scenarios, we introduce the Honest Score\nClient Selection (HSCS) scheme and the corresponding HSCSFL framework. In the\nHSCSFL, The server collects a clean dataset for evaluation. Under each\niteration, the server collects the gradients from clients and then perform HSCS\nto select aggregation candidates. The server first evaluates the performance of\neach class of the global model and generates the corresponding risk vector to\nindicate which class could be potentially attacked. Similarly, the server\nevaluates the client's model and records the performance of each class as the\naccuracy vector. The dot product of each client's accuracy vector and global\nrisk vector is generated as the client's host score; only the top p\\% host\nscore clients are included in the following aggregation. Finally, server\naggregates the gradients and uses the outcome to update the global model. The\ncomprehensive experimental results show our HSCSFL effectively enhances the FL\nrobustness and defends against the \"label flipping attack.\"",
            "author": [
                "Yanli Li",
                "Huaming Chen",
                "Wei Bao",
                "Zhengmeng Xu",
                "Dong Yuan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05826v1",
                "http://arxiv.org/pdf/2311.05826v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05821v1",
            "title": "Let's Reinforce Step by Step",
            "updated": "2023-11-10T01:35:51Z",
            "published": "2023-11-10T01:35:51Z",
            "summary": "While recent advances have boosted LM proficiency in linguistic benchmarks,\nLMs consistently struggle to reason correctly on complex tasks like\nmathematics. We turn to Reinforcement Learning from Human Feedback (RLHF) as a\nmethod with which to shape model reasoning processes. In particular, we explore\ntwo reward schemes, outcome-supervised reward models (ORMs) and\nprocess-supervised reward models (PRMs), to optimize for logical reasoning. Our\nresults show that the fine-grained reward provided by PRM-based methods\nenhances accuracy on simple mathematical reasoning (GSM8K) while, unexpectedly,\nreducing performance in complex tasks (MATH). Furthermore, we show the critical\nrole reward aggregation functions play in model performance. Providing\npromising avenues for future research, our study underscores the need for\nfurther exploration into fine-grained reward modeling for more reliable\nlanguage models.",
            "author": [
                "Sarah Pan",
                "Vladislav Lialin",
                "Sherin Muckatira",
                "Anna Rumshisky"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05821v1",
                "http://arxiv.org/pdf/2311.05821v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05820v1",
            "title": "Machine Learning-powered Compact Modeling of Stochastic Electronic\n  Devices using Mixture Density Networks",
            "updated": "2023-11-10T01:34:18Z",
            "published": "2023-11-10T01:34:18Z",
            "summary": "The relentless pursuit of miniaturization and performance enhancement in\nelectronic devices has led to a fundamental challenge in the field of circuit\ndesign and simulation: how to accurately account for the inherent stochastic\nnature of certain devices. While conventional deterministic models have served\nas indispensable tools for circuit designers, they fall short when it comes to\ncapture the subtle yet critical variability exhibited by many electronic\ncomponents. In this paper, we present an innovative approach that transcends\nthe limitations of traditional modeling techniques by harnessing the power of\nmachine learning, specifically Mixture Density Networks (MDNs), to faithfully\nrepresent and simulate the stochastic behavior of electronic devices. We\ndemonstrate our approach to model heater cryotrons, where the model is able to\ncapture the stochastic switching dynamics observed in the experiment. Our model\nshows 0.82% mean absolute error for switching probability. This paper marks a\nsignificant step forward in the quest for accurate and versatile compact\nmodels, poised to drive innovation in the realm of electronic circuits.",
            "author": [
                "Jack Hutchins",
                "Shamiul Alam",
                "Dana S. Rampini",
                "Bakhrom G. Oripov",
                "Adam N. McCaughan",
                "Ahmedullah Aziz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05820v1",
                "http://arxiv.org/pdf/2311.05820v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05818v1",
            "title": "Learning Agile Bipedal Motions on a Quadrupedal Robot",
            "updated": "2023-11-10T01:28:18Z",
            "published": "2023-11-10T01:28:18Z",
            "summary": "Can a quadrupedal robot perform bipedal motions like humans? Although\ndeveloping human-like behaviors is more often studied on costly bipedal robot\nplatforms, we present a solution over a lightweight quadrupedal robot that\nunlocks the agility of the quadruped in an upright standing pose and is capable\nof a variety of human-like motions. Our framework is with a bi-level structure.\nAt the low level is a motion-conditioned control policy that allows the\nquadrupedal robot to track desired base and front limb movements while\nbalancing on two hind feet. The policy is commanded by a high-level motion\ngenerator that gives trajectories of parameterized human-like motions to the\nrobot from multiple modalities of human input. We for the first time\ndemonstrate various bipedal motions on a quadrupedal robot, and showcase\ninteresting human-robot interaction modes including mimicking human videos,\nfollowing natural language instructions, and physical interaction.",
            "author": [
                "Yunfei Li",
                "Jinhan Li",
                "Wei Fu",
                "Yi Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05818v1",
                "http://arxiv.org/pdf/2311.05818v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06318v1",
            "title": "Knowledge-Augmented Large Language Models for Personalized Contextual\n  Query Suggestion",
            "updated": "2023-11-10T01:18:47Z",
            "published": "2023-11-10T01:18:47Z",
            "summary": "Large Language Models (LLMs) excel at tackling various natural language\ntasks. However, due to the significant costs involved in re-training or\nfine-tuning them, they remain largely static and difficult to personalize.\nNevertheless, a variety of applications could benefit from generations that are\ntailored to users' preferences, goals, and knowledge. Among them is web search,\nwhere knowing what a user is trying to accomplish, what they care about, and\nwhat they know can lead to improved search experiences. In this work, we\npropose a novel and general approach that augments an LLM with relevant context\nfrom users' interaction histories with a search engine in order to personalize\nits outputs. Specifically, we construct an entity-centric knowledge store for\neach user based on their search and browsing activities on the web, which is\nthen leveraged to provide contextually relevant LLM prompt augmentations. This\nknowledge store is light-weight, since it only produces user-specific aggregate\nprojections of interests and knowledge onto public knowledge graphs, and\nleverages existing search log infrastructure, thereby mitigating the privacy,\ncompliance, and scalability concerns associated with building deep user\nprofiles for personalization. We then validate our approach on the task of\ncontextual query suggestion, which requires understanding not only the user's\ncurrent search context but also what they historically know and care about.\nThrough a number of experiments based on human evaluation, we show that our\napproach is significantly better than several other LLM-powered baselines,\ngenerating query suggestions that are contextually more relevant, personalized,\nand useful.",
            "author": [
                "Jinheon Baek",
                "Nirupama Chandrasekaran",
                "Silviu Cucerzan",
                "Allen herring",
                "Sujay Kumar Jauhar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06318v1",
                "http://arxiv.org/pdf/2311.06318v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05811v1",
            "title": "YOLOv5s-BC: An improved YOLOv5s-based method for real-time apple\n  detection",
            "updated": "2023-11-10T01:09:13Z",
            "published": "2023-11-10T01:09:13Z",
            "summary": "To address the issues associated with the existing algorithms for the current\napple detection, this study proposes an improved YOLOv5s-based method, named\nYOLOv5s-BC, for real-time apple detection, in which a series of modifications\nhave been introduced. Firstly, a coordinate attention (CA) block has been\nincorporated into the backbone module to construct a new backbone network.\nSecondly, the original concatenation operation has been replaced with a\nbidirectional feature pyramid network (BiFPN) in the neck module. Lastly, a new\ndetection head has been added to the head module, enabling the detection of\nsmaller and more distant targets within the field of view of the robot. The\nproposed YOLOv5s-BC model was compared to several target detection algorithms,\nincluding YOLOv5s, YOLOv4, YOLOv3, SSD, Faster R-CNN (ResNet50), and Faster\nR-CNN (VGG), with significant improvements of 4.6%, 3.6%, 20.48%, 23.22%,\n15.27%, and 15.59% in mAP, respectively. The detection accuracy of the proposed\nmodel is also greatly enhanced over the original YOLOv5s model. The model\nboasts an average detection speed of 0.018 seconds per image, and the weight\nsize is only 16.7 Mb with 4.7 Mb smaller than that of YOLOv8s, meeting the\nreal-time requirements for the picking robot. Furthermore, according to the\nheat map, our proposed model can focus more on and learn the high-level\nfeatures of the target apples, and recognize the smaller target apples better\nthan the original YOLOv5s model. Then, in other apple orchard tests, the model\ncan detect the pickable apples in real time and correctly, illustrating a\ndecent generalization ability.",
            "author": [
                "Jingfan Liu",
                "Zhaobing Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05811v1",
                "http://arxiv.org/pdf/2311.05811v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05808v2",
            "title": "Scale-MIA: A Scalable Model Inversion Attack against Secure Federated\n  Learning via Latent Space Reconstruction",
            "updated": "2023-11-14T16:33:21Z",
            "published": "2023-11-10T00:53:22Z",
            "summary": "Federated learning is known for its capability to safeguard participants'\ndata privacy. However, recently emerged model inversion attacks (MIAs) have\nshown that a malicious parameter server can reconstruct individual users' local\ndata samples through model updates. The state-of-the-art attacks either rely on\ncomputation-intensive search-based optimization processes to recover each input\nbatch, making scaling difficult, or they involve the malicious parameter server\nadding extra modules before the global model architecture, rendering the\nattacks too conspicuous and easily detectable.\n  To overcome these limitations, we propose Scale-MIA, a novel MIA capable of\nefficiently and accurately recovering training samples of clients from the\naggregated updates, even when the system is under the protection of a robust\nsecure aggregation protocol. Unlike existing approaches treating models as\nblack boxes, Scale-MIA recognizes the importance of the intricate architecture\nand inner workings of machine learning models. It identifies the latent space\nas the critical layer for breaching privacy and decomposes the complex recovery\ntask into an innovative two-step process to reduce computation complexity. The\nfirst step involves reconstructing the latent space representations (LSRs) from\nthe aggregated model updates using a closed-form inversion mechanism,\nleveraging specially crafted adversarial linear layers. In the second step, the\nwhole input batches are recovered from the LSRs by feeding them into a\nfine-tuned generative decoder.\n  We implemented Scale-MIA on multiple commonly used machine learning models\nand conducted comprehensive experiments across various settings. The results\ndemonstrate that Scale-MIA achieves excellent recovery performance on different\ndatasets, exhibiting high reconstruction rates, accuracy, and attack efficiency\non a larger scale compared to state-of-the-art MIAs.",
            "author": [
                "Shanghao Shi",
                "Ning Wang",
                "Yang Xiao",
                "Chaoyu Zhang",
                "Yi Shi",
                "Y. Thomas Hou",
                "Wenjing Lou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05808v2",
                "http://arxiv.org/pdf/2311.05808v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05807v2",
            "title": "Quantum light microscopy",
            "updated": "2023-11-24T00:22:05Z",
            "published": "2023-11-10T00:44:58Z",
            "summary": "Much of our progress in understanding microscale biology has been powered by\nadvances in microscopy. For instance, super-resolution microscopes allow the\nobservation of biological structures at near-atomic-scale resolution, while\nmulti-photon microscopes allow imaging deep into tissue. However, biological\nstructures and dynamics still often remain out of reach of existing\nmicroscopes, with further advances in signal-to-noise, resolution and speed\nneeded to access them. In many cases, the performance of microscopes is now\nlimited by quantum effects -- such as noise due to the quantisation of light\ninto photons or, for multi-photon microscopes, the low cross-section of\nmulti-photon scattering. These limitations can be overcome by exploiting\nfeatures of quantum mechanics such as entanglement. Quantum effects can also\nprovide new ways to enhance the performance of microscopes, such as new\nsuper-resolution techniques and new techniques to image at difficult to reach\nwavelengths. This review provides an overview of these various ways in which\nquantum techniques can improve microscopy, including recent experimental\nprogress. It seeks to provide a realistic picture of what is possible, and what\nthe constraints and opportunities are.",
            "author": [
                "W. P. Bowen",
                "Helen M. Chrzanowski",
                "Dan Oron",
                "Sven Ramelow",
                "Dmitry Tabakaev",
                "Alex Terrasson",
                "Rob Thew"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05807v2",
                "http://arxiv.org/pdf/2311.05807v2"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "physics.optics"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05804v1",
            "title": "Model-as-a-Service (MaaS): A Survey",
            "updated": "2023-11-10T00:35:00Z",
            "published": "2023-11-10T00:35:00Z",
            "summary": "Due to the increased number of parameters and data in the pre-trained model\nexceeding a certain level, a foundation model (e.g., a large language model)\ncan significantly improve downstream task performance and emerge with some\nnovel special abilities (e.g., deep learning, complex reasoning, and human\nalignment) that were not present before. Foundation models are a form of\ngenerative artificial intelligence (GenAI), and Model-as-a-Service (MaaS) has\nemerged as a groundbreaking paradigm that revolutionizes the deployment and\nutilization of GenAI models. MaaS represents a paradigm shift in how we use AI\ntechnologies and provides a scalable and accessible solution for developers and\nusers to leverage pre-trained AI models without the need for extensive\ninfrastructure or expertise in model training. In this paper, the introduction\naims to provide a comprehensive overview of MaaS, its significance, and its\nimplications for various industries. We provide a brief review of the\ndevelopment history of \"X-as-a-Service\" based on cloud computing and present\nthe key technologies involved in MaaS. The development of GenAI models will\nbecome more democratized and flourish. We also review recent application\nstudies of MaaS. Finally, we highlight several challenges and future issues in\nthis promising area. MaaS is a new deployment and service paradigm for\ndifferent AI-based models. We hope this review will inspire future research in\nthe field of MaaS.",
            "author": [
                "Wensheng Gan",
                "Shicheng Wan",
                "Philip S. Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05804v1",
                "http://arxiv.org/pdf/2311.05804v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05802v2",
            "title": "Generative Modeling of Residuals for Real-Time Risk-Sensitive Safety\n  with Discrete-Time Control Barrier Functions",
            "updated": "2023-11-14T00:40:42Z",
            "published": "2023-11-10T00:24:35Z",
            "summary": "A key source of brittleness for robotic systems is the presence of model\nuncertainty and external disturbances. Most existing approaches to robust\ncontrol either seek to bound the worst-case disturbance (which results in\nconservative behavior), or to learn a deterministic dynamics model (which is\nunable to capture uncertain dynamics or disturbances). This work proposes a\ndifferent approach: training a state-conditioned generative model to represent\nthe distribution of error residuals between the nominal dynamics and the actual\nsystem. In particular we introduce the Online Risk-Informed Optimization\ncontroller (ORIO), which uses Discrete-Time Control Barrier Functions, combined\nwith a learned, generative disturbance model, to ensure the safety of the\nsystem up to some level of risk. We demonstrate our approach in both\nsimulations and hardware, and show our method can learn a disturbance model\nthat is accurate enough to enable risk-sensitive control of a quadrotor flying\naggressively with an unmodelled slung load. We use a conditional variational\nautoencoder (CVAE) to learn a state-conditioned dynamics residual distribution,\nand find that the resulting probabilistic safety controller, which can be run\nat 100Hz on an embedded computer, exhibits less conservative behavior while\nretaining theoretical safety properties.",
            "author": [
                "Ryan K. Cosner",
                "Igor Sadalski",
                "Jana K. Woo",
                "Preston Culbertson",
                "Aaron D. Ames"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05802v2",
                "http://arxiv.org/pdf/2311.05802v2"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05799v1",
            "title": "Adaptive Variance Thresholding: A Novel Approach to Improve Existing\n  Deep Transfer Vision Models and Advance Automatic Knee-Joint Osteoarthritis\n  Classification",
            "updated": "2023-11-10T00:17:07Z",
            "published": "2023-11-10T00:17:07Z",
            "summary": "Knee-Joint Osteoarthritis (KOA) is a prevalent cause of global disability and\nis inherently complex to diagnose due to its subtle radiographic markers and\nindividualized progression. One promising classification avenue involves\napplying deep learning methods; however, these techniques demand extensive,\ndiversified datasets, which pose substantial challenges due to medical data\ncollection restrictions. Existing practices typically resort to smaller\ndatasets and transfer learning. However, this approach often inherits\nunnecessary pre-learned features that can clutter the classifier's vector\nspace, potentially hampering performance. This study proposes a novel paradigm\nfor improving post-training specialized classifiers by introducing adaptive\nvariance thresholding (AVT) followed by Neural Architecture Search (NAS). This\napproach led to two key outcomes: an increase in the initial accuracy of the\npre-trained KOA models and a 60-fold reduction in the NAS input vector space,\nthus facilitating faster inference speed and a more efficient hyperparameter\nsearch. We also applied this approach to an external model trained for KOA\nclassification. Despite its initial performance, the application of our\nmethodology improved its average accuracy, making it one of the top three KOA\nclassification models.",
            "author": [
                "Fabi Prezja",
                "Leevi Annala",
                "Sampsa Kiiskinen",
                "Suvi Lahtinen",
                "Timo Ojala"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05799v1",
                "http://arxiv.org/pdf/2311.05799v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05798v1",
            "title": "Synthesizing Bidirectional Temporal States of Knee Osteoarthritis\n  Radiographs with Cycle-Consistent Generative Adversarial Neural Networks",
            "updated": "2023-11-10T00:15:00Z",
            "published": "2023-11-10T00:15:00Z",
            "summary": "Knee Osteoarthritis (KOA), a leading cause of disability worldwide, is\nchallenging to detect early due to subtle radiographic indicators. Diverse,\nextensive datasets are needed but are challenging to compile because of\nprivacy, data collection limitations, and the progressive nature of KOA.\nHowever, a model capable of projecting genuine radiographs into different OA\nstages could augment data pools, enhance algorithm training, and offer\npre-emptive prognostic insights. In this study, we trained a CycleGAN model to\nsynthesize past and future stages of KOA on any genuine radiograph. The model\nwas validated using a Convolutional Neural Network that was deceived into\nmisclassifying disease stages in transformed images, demonstrating the\nCycleGAN's ability to effectively transform disease characteristics forward or\nbackward in time. The model was particularly effective in synthesizing future\ndisease states and showed an exceptional ability to retroactively transition\nlate-stage radiographs to earlier stages by eliminating osteophytes and\nexpanding knee joint space, signature characteristics of None or Doubtful KOA.\nThe model's results signify a promising potential for enhancing diagnostic\nmodels, data augmentation, and educational and prognostic usage in healthcare.\nNevertheless, further refinement, validation, and a broader evaluation process\nencompassing both CNN-based assessments and expert medical feedback are\nemphasized for future research and development.",
            "author": [
                "Fabi Prezja",
                "Leevi Annala",
                "Sampsa Kiiskinen",
                "Suvi Lahtinen",
                "Timo Ojala"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05798v1",
                "http://arxiv.org/pdf/2311.05798v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.14698v2",
            "title": "Business Policy Experiments using Fractional Factorial Designs: Consumer\n  Retention on DoorDash",
            "updated": "2023-11-29T04:23:13Z",
            "published": "2023-11-10T00:14:14Z",
            "summary": "This paper investigates an approach to both speed up business decision-making\nand lower the cost of learning through experimentation by factorizing business\npolicies and employing fractional factorial experimental designs for their\nevaluation. We illustrate how this method integrates with advances in the\nestimation of heterogeneous treatment effects, elaborating on its advantages\nand foundational assumptions. We empirically demonstrate the implementation and\nbenefits of our approach and assess its validity in evaluating consumer\npromotion policies at DoorDash, which is one of the largest delivery platforms\nin the US. Our approach discovers a policy with 5% incremental profit at 67%\nlower implementation cost.",
            "author": [
                "Yixin Tang",
                "Yicong Lin",
                "Navdeep S. Sahni"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14698v2",
                "http://arxiv.org/pdf/2311.14698v2"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "cs.LG",
                "econ.EM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05795v1",
            "title": "Improvements on Uncertainty Quantification for Node Classification via\n  Distance-Based Regularization",
            "updated": "2023-11-10T00:00:20Z",
            "published": "2023-11-10T00:00:20Z",
            "summary": "Deep neural networks have achieved significant success in the last decades,\nbut they are not well-calibrated and often produce unreliable predictions. A\nlarge number of literature relies on uncertainty quantification to evaluate the\nreliability of a learning model, which is particularly important for\napplications of out-of-distribution (OOD) detection and misclassification\ndetection. We are interested in uncertainty quantification for interdependent\nnode-level classification. We start our analysis based on graph posterior\nnetworks (GPNs) that optimize the uncertainty cross-entropy (UCE)-based loss\nfunction. We describe the theoretical limitations of the widely-used UCE loss.\nTo alleviate the identified drawbacks, we propose a distance-based\nregularization that encourages clustered OOD nodes to remain clustered in the\nlatent space. We conduct extensive comparison experiments on eight standard\ndatasets and demonstrate that the proposed regularization outperforms the\nstate-of-the-art in both OOD detection and misclassification detection.",
            "author": [
                "Russell Alan Hart",
                "Linlin Yu",
                "Yifei Lou",
                "Feng Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05795v1",
                "http://arxiv.org/pdf/2311.05795v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05794v1",
            "title": "An Experimental Design for Anytime-Valid Causal Inference on Multi-Armed\n  Bandits",
            "updated": "2023-11-09T23:57:32Z",
            "published": "2023-11-09T23:57:32Z",
            "summary": "Typically, multi-armed bandit (MAB) experiments are analyzed at the end of\nthe study and thus require the analyst to specify a fixed sample size in\nadvance. However, in many online learning applications, it is advantageous to\ncontinuously produce inference on the average treatment effect (ATE) between\narms as new data arrive and determine a data-driven stopping time for the\nexperiment. Existing work on continuous inference for adaptive experiments\nassumes that the treatment assignment probabilities are bounded away from zero\nand one, thus excluding nearly all standard bandit algorithms. In this work, we\ndevelop the Mixture Adaptive Design (MAD), a new experimental design for\nmulti-armed bandits that enables continuous inference on the ATE with\nguarantees on statistical validity and power for nearly any bandit algorithm.\nOn a high level, the MAD \"mixes\" a bandit algorithm of the user's choice with a\nBernoulli design through a tuning parameter $\\delta_t$, where $\\delta_t$ is a\ndeterministic sequence that controls the priority placed on the Bernoulli\ndesign as the sample size grows. We show that for $\\delta_t =\no\\left(1/t^{1/4}\\right)$, the MAD produces a confidence sequence that is\nasymptotically valid and guaranteed to shrink around the true ATE. We\nempirically show that the MAD improves the coverage and power of ATE inference\nin MAB experiments without significant losses in finite-sample reward.",
            "author": [
                "Biyonka Liang",
                "Iavor Bojinov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05794v1",
                "http://arxiv.org/pdf/2311.05794v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05792v1",
            "title": "Is a Seat at the Table Enough? Engaging Teachers and Students in Dataset\n  Specification for ML in Education",
            "updated": "2023-11-09T23:51:08Z",
            "published": "2023-11-09T23:51:08Z",
            "summary": "Despite the promises of ML in education, its adoption in the classroom has\nsurfaced numerous issues regarding fairness, accountability, and transparency,\nas well as concerns about data privacy and student consent. A root cause of\nthese issues is the lack of understanding of the complex dynamics of education,\nincluding teacher-student interactions, collaborative learning, and classroom\nenvironment. To overcome these challenges and fully utilize the potential of ML\nin education, software practitioners need to work closely with educators and\nstudents to fully understand the context of the data (the backbone of ML\napplications) and collaboratively define the ML data specifications. To gain a\ndeeper understanding of such a collaborative process, we conduct ten co-design\nsessions with ML software practitioners, educators, and students. In the\nsessions, teachers and students work with ML engineers, UX designers, and legal\npractitioners to define dataset characteristics for a given ML application. We\nfind that stakeholders contextualize data based on their domain and procedural\nknowledge, proactively design data requirements to mitigate downstream harms\nand data reliability concerns, and exhibit role-based collaborative strategies\nand contribution patterns. Further, we find that beyond a seat at the table,\nmeaningful stakeholder participation in ML requires structured supports:\ndefined processes for continuous iteration and co-evaluation, shared contextual\ndata quality standards, and information scaffolds for both technical and\nnon-technical stakeholders to traverse expertise boundaries.",
            "author": [
                "Mei Tan",
                "Hansol Lee",
                "Dakuo Wang",
                "Hariharan Subramonyam"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05792v1",
                "http://arxiv.org/pdf/2311.05792v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.AI",
                "cs.HC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05791v1",
            "title": "Detecting Suspicious Commenter Mob Behaviors on YouTube Using Graph2Vec",
            "updated": "2023-11-09T23:49:29Z",
            "published": "2023-11-09T23:49:29Z",
            "summary": "YouTube, a widely popular online platform, has transformed the dynamics of\ncon-tent consumption and interaction for users worldwide. With its extensive\nrange of content crea-tors and viewers, YouTube serves as a hub for video\nsharing, entertainment, and information dissemination. However, the exponential\ngrowth of users and their active engagement on the platform has raised concerns\nregarding suspicious commenter behaviors, particularly in the com-ment section.\nThis paper presents a social network analysis-based methodology for detecting\nsuspicious commenter mob-like behaviors among YouTube channels and the\nsimilarities therein. The method aims to characterize channels based on the\nlevel of such behavior and identify com-mon patterns across them. To evaluate\nthe effectiveness of the proposed model, we conducted an analysis of 20 YouTube\nchannels, consisting of 7,782 videos, 294,199 commenters, and 596,982 comments.\nThese channels were specifically selected for propagating false views about the\nU.S. Military. The analysis revealed significant similarities among the\nchannels, shedding light on the prevalence of suspicious commenter behavior. By\nunderstanding these similarities, we contribute to a better understanding of\nthe dynamics of suspicious behavior on YouTube channels, which can inform\nstrategies for addressing and mitigating such behavior.",
            "author": [
                "Shadi Shajari",
                "Mustafa Alassad",
                "Nitin Agarwal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05791v1",
                "http://arxiv.org/pdf/2311.05791v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05790v1",
            "title": "The Paradox of Noise: An Empirical Study of Noise-Infusion Mechanisms to\n  Improve Generalization, Stability, and Privacy in Federated Learning",
            "updated": "2023-11-09T23:36:18Z",
            "published": "2023-11-09T23:36:18Z",
            "summary": "In a data-centric era, concerns regarding privacy and ethical data handling\ngrow as machine learning relies more on personal information. This empirical\nstudy investigates the privacy, generalization, and stability of deep learning\nmodels in the presence of additive noise in federated learning frameworks. Our\nmain objective is to provide strategies to measure the generalization,\nstability, and privacy-preserving capabilities of these models and further\nimprove them. To this end, five noise infusion mechanisms at varying noise\nlevels within centralized and federated learning settings are explored. As\nmodel complexity is a key component of the generalization and stability of deep\nlearning models during training and evaluation, a comparative analysis of three\nConvolutional Neural Network (CNN) architectures is provided. The paper\nintroduces Signal-to-Noise Ratio (SNR) as a quantitative measure of the\ntrade-off between privacy and training accuracy of noise-infused models, aiming\nto find the noise level that yields optimal privacy and accuracy. Moreover, the\nPrice of Stability and Price of Anarchy are defined in the context of\nprivacy-preserving deep learning, contributing to the systematic investigation\nof the noise infusion strategies to enhance privacy without compromising\nperformance. Our research sheds light on the delicate balance between these\ncritical factors, fostering a deeper understanding of the implications of\nnoise-based regularization in machine learning. By leveraging noise as a tool\nfor regularization and privacy enhancement, we aim to contribute to the\ndevelopment of robust, privacy-aware algorithms, ensuring that AI-driven\nsolutions prioritize both utility and privacy.",
            "author": [
                "Elaheh Jafarigol",
                "Theodore Trafalis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05790v1",
                "http://arxiv.org/pdf/2311.05790v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05788v2",
            "title": "Structured Transforms Across Spaces with Cost-Regularized Optimal\n  Transport",
            "updated": "2023-11-23T11:29:11Z",
            "published": "2023-11-09T23:33:31Z",
            "summary": "Matching a source to a target probability measure is often solved by\ninstantiating a linear optimal transport (OT) problem, parameterized by a\nground cost function that quantifies discrepancy between points. When these\nmeasures live in the same metric space, the ground cost often defaults to its\ndistance. When instantiated across two different spaces, however, choosing that\ncost in the absence of aligned data is a conundrum. As a result, practitioners\noften resort to solving instead a quadratic Gromow-Wasserstein (GW) problem. We\nexploit in this work a parallel between GW and cost-regularized OT, the\nregularized minimization of a linear OT objective parameterized by a ground\ncost. We use this cost-regularized formulation to match measures across two\ndifferent Euclidean spaces, where the cost is evaluated between transformed\nsource points and target points. We show that several quadratic OT problems\nfall in this category, and consider enforcing structure in linear transform\n(e.g. sparsity), by introducing structure-inducing regularizers. We provide a\nproximal algorithm to extract such transforms from unaligned data, and\ndemonstrate its applicability to single-cell spatial transcriptomics/multiomics\nmatching tasks.",
            "author": [
                "Othmane Sebbouh",
                "Marco Cuturi",
                "Gabriel Peyr\u00e9"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05788v2",
                "http://arxiv.org/pdf/2311.05788v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05787v1",
            "title": "Towards stable real-world equation discovery with assessing\n  differentiating quality influence",
            "updated": "2023-11-09T23:32:06Z",
            "published": "2023-11-09T23:32:06Z",
            "summary": "This paper explores the critical role of differentiation approaches for\ndata-driven differential equation discovery. Accurate derivatives of the input\ndata are essential for reliable algorithmic operation, particularly in\nreal-world scenarios where measurement quality is inevitably compromised. We\npropose alternatives to the commonly used finite differences-based method,\nnotorious for its instability in the presence of noise, which can exacerbate\nrandom errors in the data. Our analysis covers four distinct methods:\nSavitzky-Golay filtering, spectral differentiation, smoothing based on\nartificial neural networks, and the regularization of derivative variation. We\nevaluate these methods in terms of applicability to problems, similar to the\nreal ones, and their ability to ensure the convergence of equation discovery\nalgorithms, providing valuable insights for robust modeling of real-world\nprocesses.",
            "author": [
                "Mikhail Masliaev",
                "Ilya Markov",
                "Alexander Hvatov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05787v1",
                "http://arxiv.org/pdf/2311.05787v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05784v2",
            "title": "Are \"Hierarchical\" Visual Representations Hierarchical?",
            "updated": "2023-11-23T20:45:53Z",
            "published": "2023-11-09T23:25:29Z",
            "summary": "Learned visual representations often capture large amounts of semantic\ninformation for accurate downstream applications. Human understanding of the\nworld is fundamentally grounded in hierarchy. To mimic this and further improve\nrepresentation capabilities, the community has explored \"hierarchical\" visual\nrepresentations that aim at modeling the underlying hierarchy of the visual\nworld. In this work, we set out to investigate if hierarchical visual\nrepresentations truly capture the human perceived hierarchy better than\nstandard learned representations. To this end, we create HierNet, a suite of 12\ndatasets spanning 3 kinds of hierarchy from the BREEDs subset of ImageNet.\nAfter extensive evaluation of Hyperbolic and Matryoshka Representations across\ntraining setups, we conclude that they do not capture hierarchy any better than\nthe standard representations but can assist in other aspects like search\nefficiency and interpretability. Our benchmark and the datasets are\nopen-sourced at https://github.com/ethanlshen/HierNet.",
            "author": [
                "Ethan Shen",
                "Ali Farhadi",
                "Aditya Kusupati"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05784v2",
                "http://arxiv.org/pdf/2311.05784v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05782v1",
            "title": "MPGemmFI: A Fault Injection Technique for Mixed Precision GEMM in ML\n  Applications",
            "updated": "2023-11-09T23:22:36Z",
            "published": "2023-11-09T23:22:36Z",
            "summary": "Emerging deep learning workloads urgently need fast general matrix\nmultiplication (GEMM). To meet such demand, one of the critical features of\nmachine-learning-specific accelerators such as NVIDIA Tensor Cores, AMD Matrix\nCores, and Google TPUs is the support of mixed-precision enabled GEMM. For DNN\nmodels, lower-precision FP data formats and computation offer acceptable\ncorrectness but significant performance, area, and memory footprint\nimprovement. While promising, the mixed-precision computation on error\nresilience remains unexplored. To this end, we develop a fault injection\nframework that systematically injects fault into the mixed-precision\ncomputation results. We investigate how the faults affect the accuracy of\nmachine learning applications. Based on the error resilience characteristics,\nwe offer lightweight error detection and correction solutions that\nsignificantly improve the overall model accuracy if the models experience\nhardware faults. The solutions can be efficiently integrated into the\naccelerator's pipelines.",
            "author": [
                "Bo Fang",
                "Xinyi Li",
                "Harvey Dam",
                "Cheng Tan",
                "Siva Kumar Sastry Hari",
                "Timothy Tsai",
                "Ignacio Laguna",
                "Dingwen Tao",
                "Ganesh Gopalakrishnan",
                "Prashant Nair",
                "Kevin Barker",
                "Ang Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05782v1",
                "http://arxiv.org/pdf/2311.05782v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05780v1",
            "title": "Real-time Control of Electric Autonomous Mobility-on-Demand Systems via\n  Graph Reinforcement Learning",
            "updated": "2023-11-09T22:57:21Z",
            "published": "2023-11-09T22:57:21Z",
            "summary": "Operators of Electric Autonomous Mobility-on-Demand (E-AMoD) fleets need to\nmake several real-time decisions such as matching available cars to ride\nrequests, rebalancing idle cars to areas of high demand, and charging vehicles\nto ensure sufficient range. While this problem can be posed as a linear program\nthat optimizes flows over a space-charge-time graph, the size of the resulting\noptimization problem does not allow for real-time implementation in realistic\nsettings. In this work, we present the E-AMoD control problem through the lens\nof reinforcement learning and propose a graph network-based framework to\nachieve drastically improved scalability and superior performance over\nheuristics. Specifically, we adopt a bi-level formulation where we (1) leverage\na graph network-based RL agent to specify a desired next state in the\nspace-charge graph, and (2) solve more tractable linear programs to best\nachieve the desired state while ensuring feasibility. Experiments using\nreal-world data from San Francisco and New York City show that our approach\nachieves up to 89% of the profits of the theoretically-optimal solution while\nachieving more than a 100x speedup in computational time. Furthermore, our\napproach outperforms the best domain-specific heuristics with comparable\nruntimes, with an increase in profits by up to 3x. Finally, we highlight\npromising zero-shot transfer capabilities of our learned policy on tasks such\nas inter-city generalization and service area expansion, thus showing the\nutility, scalability, and flexibility of our framework.",
            "author": [
                "Aaryan Singhal",
                "Daniele Gammelli",
                "Justin Luke",
                "Karthik Gopalakrishnan",
                "Dominik Helmreich",
                "Marco Pavone"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05780v1",
                "http://arxiv.org/pdf/2311.05780v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.LG",
                "cs.RO",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05779v1",
            "title": "Language-guided Robot Grasping: CLIP-based Referring Grasp Synthesis in\n  Clutter",
            "updated": "2023-11-09T22:55:10Z",
            "published": "2023-11-09T22:55:10Z",
            "summary": "Robots operating in human-centric environments require the integration of\nvisual grounding and grasping capabilities to effectively manipulate objects\nbased on user instructions. This work focuses on the task of referring grasp\nsynthesis, which predicts a grasp pose for an object referred through natural\nlanguage in cluttered scenes. Existing approaches often employ multi-stage\npipelines that first segment the referred object and then propose a suitable\ngrasp, and are evaluated in private datasets or simulators that do not capture\nthe complexity of natural indoor scenes. To address these limitations, we\ndevelop a challenging benchmark based on cluttered indoor scenes from OCID\ndataset, for which we generate referring expressions and connect them with\n4-DoF grasp poses. Further, we propose a novel end-to-end model (CROG) that\nleverages the visual grounding capabilities of CLIP to learn grasp synthesis\ndirectly from image-text pairs. Our results show that vanilla integration of\nCLIP with pretrained models transfers poorly in our challenging benchmark,\nwhile CROG achieves significant improvements both in terms of grounding and\ngrasping. Extensive robot experiments in both simulation and hardware\ndemonstrate the effectiveness of our approach in challenging interactive object\ngrasping scenarios that include clutter.",
            "author": [
                "Georgios Tziafas",
                "Yucheng Xu",
                "Arushi Goel",
                "Mohammadreza Kasaei",
                "Zhibin Li",
                "Hamidreza Kasaei"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05779v1",
                "http://arxiv.org/pdf/2311.05779v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05778v1",
            "title": "DONUT-hole: DONUT Sparsification by Harnessing Knowledge and Optimizing\n  Learning Efficiency",
            "updated": "2023-11-09T22:49:05Z",
            "published": "2023-11-09T22:49:05Z",
            "summary": "This paper introduces DONUT-hole, a sparse OCR-free visual document\nunderstanding (VDU) model that addresses the limitations of its predecessor\nmodel, dubbed DONUT. The DONUT model, leveraging a transformer architecture,\novercoming the challenges of separate optical character recognition (OCR) and\nvisual semantic understanding (VSU) components. However, its deployment in\nproduction environments and edge devices is hindered by high memory and\ncomputational demands, particularly in large-scale request services. To\novercome these challenges, we propose an optimization strategy based on\nknowledge distillation and model pruning. Our paradigm to produce DONUT-hole,\nreduces the model denisty by 54\\% while preserving performance. We also achieve\na global representational similarity index between DONUT and DONUT-hole based\non centered kernel alignment (CKA) metric of 0.79. Moreover, we evaluate the\neffectiveness of DONUT-hole in the document image key information extraction\n(KIE) task, highlighting its potential for developing more efficient VDU\nsystems for logistic companies.",
            "author": [
                "Azhar Shaikh",
                "Michael Cochez",
                "Denis Diachkov",
                "Michiel de Rijcke",
                "Sahar Yousefi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05778v1",
                "http://arxiv.org/pdf/2311.05778v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05769v1",
            "title": "Chatbots Are Not Reliable Text Annotators",
            "updated": "2023-11-09T22:28:14Z",
            "published": "2023-11-09T22:28:14Z",
            "summary": "Recent research highlights the significant potential of ChatGPT for text\nannotation in social science research. However, ChatGPT is a closed-source\nproduct which has major drawbacks with regards to transparency,\nreproducibility, cost, and data protection. Recent advances in open-source (OS)\nlarge language models (LLMs) offer alternatives which remedy these challenges.\nThis means that it is important to evaluate the performance of OS LLMs relative\nto ChatGPT and standard approaches to supervised machine learning\nclassification. We conduct a systematic comparative evaluation of the\nperformance of a range of OS LLM models alongside ChatGPT, using both zero- and\nfew-shot learning as well as generic and custom prompts, with results compared\nto more traditional supervised classification models. Using a new dataset of\nTweets from US news media, and focusing on simple binary text annotation tasks\nfor standard social science concepts, we find significant variation in the\nperformance of ChatGPT and OS models across the tasks, and that supervised\nclassifiers consistently outperform both. Given the unreliable performance of\nChatGPT and the significant challenges it poses to Open Science we advise\nagainst using ChatGPT for substantive text annotation tasks in social science\nresearch.",
            "author": [
                "Ross Deans Kristensen-McLachlan",
                "Miceal Canavan",
                "M\u00e1rton Kardos",
                "Mia Jacobsen",
                "Lene Aar\u00f8e"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05769v1",
                "http://arxiv.org/pdf/2311.05769v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06315v2",
            "title": "ShipGen: A Diffusion Model for Parametric Ship Hull Generation with\n  Multiple Objectives and Constraints",
            "updated": "2023-11-14T03:55:35Z",
            "published": "2023-11-09T22:26:03Z",
            "summary": "Ship design is a years-long process that requires balancing complex design\ntrade-offs to create a ship that is efficient and effective. Finding new ways\nto improve the ship design process can lead to significant cost savings for\nship building and operation. One promising technology is generative artificial\nintelligence, which has been shown to reduce design cycle time and create\nnovel, high-performing designs. In literature review, generative artificial\nintelligence has been shown to generate ship hulls; however, ship design is\nparticularly difficult as the hull of a ship requires the consideration of many\nobjectives. This paper presents a study on the generation of parametric ship\nhull designs using a parametric diffusion model that considers multiple\nobjectives and constraints for the hulls. This denoising diffusion\nprobabilistic model (DDPM) generates the tabular parametric design vectors of a\nship hull for evaluation. In addition to a tabular DDPM, this paper details\nadding guidance to improve the quality of generated ship hull designs. By\nleveraging classifier guidance, the DDPM produced feasible parametric ship\nhulls that maintain the coverage of the initial training dataset of ship hulls\nwith a 99.5% rate, a 149x improvement over random sampling of the design vector\nparameters across the design space. Parametric ship hulls produced with\nperformance guidance saw an average of 91.4% reduction in wave drag\ncoefficients and an average of a 47.9x relative increase in the total displaced\nvolume of the hulls compared to the mean performance of the hulls in the\ntraining dataset. The use of a DDPM to generate parametric ship hulls can\nreduce design time by generating high-performing hull designs for future\nanalysis. These generated hulls have low drag and high volume, which can reduce\nthe cost of operating a ship and increase its potential to generate revenue.",
            "author": [
                "Noah J. Bagazinski",
                "Faez Ahmed"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06315v2",
                "http://arxiv.org/pdf/2311.06315v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05767v1",
            "title": "Dirichlet Energy Enhancement of Graph Neural Networks by Framelet\n  Augmentation",
            "updated": "2023-11-09T22:22:18Z",
            "published": "2023-11-09T22:22:18Z",
            "summary": "Graph convolutions have been a pivotal element in learning graph\nrepresentations. However, recursively aggregating neighboring information with\ngraph convolutions leads to indistinguishable node features in deep layers,\nwhich is known as the over-smoothing issue. The performance of graph neural\nnetworks decays fast as the number of stacked layers increases, and the\nDirichlet energy associated with the graph decreases to zero as well. In this\nwork, we introduce a framelet system into the analysis of Dirichlet energy and\ntake a multi-scale perspective to leverage the Dirichlet energy and alleviate\nthe over-smoothing issue. Specifically, we develop a Framelet Augmentation\nstrategy by adjusting the update rules with positive and negative increments\nfor low-pass and high-passes respectively. Based on that, we design the Energy\nEnhanced Convolution (EEConv), which is an effective and practical operation\nthat is proved to strictly enhance Dirichlet energy. From a message-passing\nperspective, EEConv inherits multi-hop aggregation property from the framelet\ntransform and takes into account all hops in the multi-scale representation,\nwhich benefits the node classification tasks over heterophilous graphs.\nExperiments show that deep GNNs with EEConv achieve state-of-the-art\nperformance over various node classification datasets, especially for\nheterophilous graphs, while also lifting the Dirichlet energy as the network\ngoes deeper.",
            "author": [
                "Jialin Chen",
                "Yuelin Wang",
                "Cristian Bodnar",
                "Rex Ying",
                "Pietro Lio",
                "Yu Guang Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05767v1",
                "http://arxiv.org/pdf/2311.05767v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07591v1",
            "title": "Identification of Books That are Suitable for Middle School Students\n  Using Artificial Neural Networks",
            "updated": "2023-11-09T22:10:52Z",
            "published": "2023-11-09T22:10:52Z",
            "summary": "Reading right books contributes to children's imagination and brain\ndevelopment, enhances their language and emotional comprehension abilities, and\nstrengthens their relationships with others. Building upon the critical role of\nreading books in individual development, this paper aims to develop an\nalgorithm that determines the suitability of books for middle school students\nby analyzing their structural and semantic features. Using methods described,\nan algorithm will be created that can be utilized by institutions and\nindividuals responsible for children's education, such as the Ministry of\nNational Education officials and schools. This algorithm will facilitate the\nselection of books to be taught at the middle school level. With the algorithm,\nthe book selection process for the middle school curriculum can be expedited,\nand it will serve as a preliminary reference source for those who evaluate\nbooks by reading them. In this paper, the Python programming language was\nemployed, utilizing natural language processing methods. Additionally, an\nartificial neural network (ANN) was trained using the data which had been\npreprocessed to construct an original dataset. To train this network, suitable\nbooks for middle school students were provided by the MEB, Oxford and Cambridge\nand with content assessed based on the \"R\" criterion, and inappropriate books\nfor middle school students in terms of content were included. This trained\nneural network achieved a 90.06% consistency rate in determining the\nappropriateness of the test-provided books. Considering the obtained findings,\nit can be concluded that the developed software has achieved the desired\nobjective.",
            "author": [
                "Alp Niksarli",
                "Sadik Ozan Gorgu",
                "Ege Gencer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07591v1",
                "http://arxiv.org/pdf/2311.07591v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05764v1",
            "title": "Generative Explanations for Graph Neural Network: Methods and\n  Evaluations",
            "updated": "2023-11-09T22:07:15Z",
            "published": "2023-11-09T22:07:15Z",
            "summary": "Graph Neural Networks (GNNs) achieve state-of-the-art performance in various\ngraph-related tasks. However, the black-box nature often limits their\ninterpretability and trustworthiness. Numerous explainability methods have been\nproposed to uncover the decision-making logic of GNNs, by generating underlying\nexplanatory substructures. In this paper, we conduct a comprehensive review of\nthe existing explanation methods for GNNs from the perspective of graph\ngeneration. Specifically, we propose a unified optimization objective for\ngenerative explanation methods, comprising two sub-objectives: Attribution and\nInformation constraints. We further demonstrate their specific manifestations\nin various generative model architectures and different explanation scenarios.\nWith the unified objective of the explanation problem, we reveal the shared\ncharacteristics and distinctions among current methods, laying the foundation\nfor future methodological advancements. Empirical results demonstrate the\nadvantages and limitations of different explainability approaches in terms of\nexplanation performance, efficiency, and generalizability.",
            "author": [
                "Jialin Chen",
                "Kenza Amara",
                "Junchi Yu",
                "Rex Ying"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05764v1",
                "http://arxiv.org/pdf/2311.05764v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05760v1",
            "title": "MALCOM-PSGD: Inexact Proximal Stochastic Gradient Descent for\n  Communication-Efficient Decentralized Machine Learning",
            "updated": "2023-11-09T21:55:53Z",
            "published": "2023-11-09T21:55:53Z",
            "summary": "Recent research indicates that frequent model communication stands as a major\nbottleneck to the efficiency of decentralized machine learning (ML),\nparticularly for large-scale and over-parameterized neural networks (NNs). In\nthis paper, we introduce MALCOM-PSGD, a new decentralized ML algorithm that\nstrategically integrates gradient compression techniques with model\nsparsification. MALCOM-PSGD leverages proximal stochastic gradient descent to\nhandle the non-smoothness resulting from the $\\ell_1$ regularization in model\nsparsification. Furthermore, we adapt vector source coding and dithering-based\nquantization for compressed gradient communication of sparsified models. Our\nanalysis shows that decentralized proximal stochastic gradient descent with\ncompressed communication has a convergence rate of\n$\\mathcal{O}\\left(\\ln(t)/\\sqrt{t}\\right)$ assuming a diminishing learning rate\nand where $t$ denotes the number of iterations. Numerical results verify our\ntheoretical findings and demonstrate that our method reduces communication\ncosts by approximately $75\\%$ when compared to the state-of-the-art method.",
            "author": [
                "Andrew Campbell",
                "Hang Liu",
                "Leah Woldemariam",
                "Anna Scaglione"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05760v1",
                "http://arxiv.org/pdf/2311.05760v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC",
                "cs.DS",
                "cs.MA",
                "math.OC",
                "68W15, 68W10, 68W40, 90C06, 90C35, 90C25",
                "G.1.6; F.2.1; E.4"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05758v1",
            "title": "Collective Sampling: An Ex Ante Perspective",
            "updated": "2023-11-09T21:52:51Z",
            "published": "2023-11-09T21:52:51Z",
            "summary": "I study collective dynamic information acquisition. Players determine when to\nend sequential sampling via a collective choice rule. My analysis focuses on\nthe case of two players, but extends to many players. With two players,\ncollective stopping is determined either unilaterally or unanimously. I develop\na methodology to characterize equilibrium outcomes using an ex ante perspective\non posterior distributions. Under unilateral stopping, each player chooses a\nmean-preserving contraction of the other's posterior distribution; under\nunanimous stopping, they choose meanpreserving spreads. Equilibrium outcomes\ncan be determined via concavification. Players learn Pareto inefficiently: too\nlittle under unilateral stopping, while too much under unanimous stopping;\nthese learning inefficiencies are amplified when players' preferences become\nless aligned. I demonstrate the value of my methodological approach in three\napplications: committee search, dynamic persuasion, and competition in\npersuasion.",
            "author": [
                "Yangfan Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05758v1",
                "http://arxiv.org/pdf/2311.05758v1"
            ],
            "primary_category": "econ.TH",
            "category": [
                "econ.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05756v1",
            "title": "Step and Smooth Decompositions as Topological Clustering",
            "updated": "2023-11-09T21:46:22Z",
            "published": "2023-11-09T21:46:22Z",
            "summary": "We investigate a class of recovery problems for which observations are a\nnoisy combination of continuous and step functions. These problems can be seen\nas non-injective instances of non-linear ICA with direct applications to image\ndecontamination for magnetic resonance imaging. Alternately, the problem can be\nviewed as clustering in the presence of structured (smooth) contaminant. We\nshow that a global topological property (graph connectivity) interacts with a\nlocal property (the degree of smoothness of the continuous component) to\ndetermine conditions under which the components are identifiable. Additionally,\na practical estimation algorithm is provided for the case when the contaminant\nlies in a reproducing kernel Hilbert space of continuous functions. Algorithm\neffectiveness is demonstrated through a series of simulations and real-world\nstudies.",
            "author": [
                "Luciano Vinas",
                "Arash A. Amini"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05756v1",
                "http://arxiv.org/pdf/2311.05756v1"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "stat.AP",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05754v1",
            "title": "Deep Natural Language Feature Learning for Interpretable Prediction",
            "updated": "2023-11-09T21:43:27Z",
            "published": "2023-11-09T21:43:27Z",
            "summary": "We propose a general method to break down a main complex task into a set of\nintermediary easier sub-tasks, which are formulated in natural language as\nbinary questions related to the final target task. Our method allows for\nrepresenting each example by a vector consisting of the answers to these\nquestions. We call this representation Natural Language Learned Features\n(NLLF). NLLF is generated by a small transformer language model (e.g., BERT)\nthat has been trained in a Natural Language Inference (NLI) fashion, using weak\nlabels automatically obtained from a Large Language Model (LLM). We show that\nthe LLM normally struggles for the main task using in-context learning, but can\nhandle these easiest subtasks and produce useful weak labels to train a BERT.\nThe NLI-like training of the BERT allows for tackling zero-shot inference with\nany binary question, and not necessarily the ones seen during the training. We\nshow that this NLLF vector not only helps to reach better performances by\nenhancing any classifier, but that it can be used as input of an\neasy-to-interpret machine learning model like a decision tree. This decision\ntree is interpretable but also reaches high performances, surpassing those of a\npre-trained transformer in some cases.We have successfully applied this method\nto two completely different tasks: detecting incoherence in students' answers\nto open-ended mathematics exam questions, and screening abstracts for a\nsystematic literature review of scientific papers on climate change and\nagroecology.",
            "author": [
                "Felipe Urrutia",
                "Cristian Buc",
                "Valentin Barriere"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05754v1",
                "http://arxiv.org/pdf/2311.05754v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05743v1",
            "title": "Advancing Algorithmic Trading: A Multi-Technique Enhancement of Deep\n  Q-Network Models",
            "updated": "2023-11-09T21:02:03Z",
            "published": "2023-11-09T21:02:03Z",
            "summary": "This study enhances a Deep Q-Network (DQN) trading model by incorporating\nadvanced techniques like Prioritized Experience Replay, Regularized Q-Learning,\nNoisy Networks, Dueling, and Double DQN. Extensive tests on assets like BTC/USD\nand AAPL demonstrate superior performance compared to the original model, with\nmarked increases in returns and Sharpe Ratio, indicating improved risk-adjusted\nrewards. Notably, convolutional neural network (CNN) architectures, both 1D and\n2D, significantly boost returns, suggesting their effectiveness in market trend\nanalysis. Across instruments, these enhancements have yielded stable and high\ngains, eclipsing the baseline and highlighting the potential of CNNs in trading\nsystems. The study suggests that applying sophisticated deep learning within\nreinforcement learning can greatly enhance automated trading, urging further\nexploration into advanced methods for broader financial applicability. The\nfindings advocate for the continued evolution of AI in finance.",
            "author": [
                "Gang Hu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05743v1",
                "http://arxiv.org/pdf/2311.05743v1"
            ],
            "primary_category": "q-fin.CP",
            "category": [
                "q-fin.CP",
                "62-00"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05742v1",
            "title": "Optimal simulation-based Bayesian decisions",
            "updated": "2023-11-09T20:59:52Z",
            "published": "2023-11-09T20:59:52Z",
            "summary": "We present a framework for the efficient computation of optimal Bayesian\ndecisions under intractable likelihoods, by learning a surrogate model for the\nexpected utility (or its distribution) as a function of the action and data\nspaces. We leverage recent advances in simulation-based inference and Bayesian\noptimization to develop active learning schemes to choose where in parameter\nand action spaces to simulate. This allows us to learn the optimal action in as\nfew simulations as possible. The resulting framework is extremely simulation\nefficient, typically requiring fewer model calls than the associated posterior\ninference task alone, and a factor of $100-1000$ more efficient than\nMonte-Carlo based methods. Our framework opens up new capabilities for\nperforming Bayesian decision making, particularly in the previously challenging\nregime where likelihoods are intractable, and simulations expensive.",
            "author": [
                "Justin Alsing",
                "Thomas D. P. Edwards",
                "Benjamin Wandelt"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05742v1",
                "http://arxiv.org/pdf/2311.05742v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "astro-ph.IM",
                "cs.AI",
                "cs.GT",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05741v1",
            "title": "Efficiently Adapting Pretrained Language Models To New Languages",
            "updated": "2023-11-09T20:59:08Z",
            "published": "2023-11-09T20:59:08Z",
            "summary": "Recent large language models (LLM) exhibit sub-optimal performance on\nlow-resource languages, as the training data of these models is usually\ndominated by English and other high-resource languages. Furthermore, it is\nchallenging to train models for low-resource languages, especially from\nscratch, due to a lack of high quality training data. Adapting pretrained LLMs\nreduces the need for data in the new language while also providing cross\nlingual transfer capabilities. However, naively adapting to new languages leads\nto catastrophic forgetting and poor tokenizer efficiency. In this work, we\nstudy how to efficiently adapt any existing pretrained LLM to a new language\nwithout running into these issues. In particular, we improve the encoding\nefficiency of the tokenizer by adding new tokens from the target language and\nstudy the data mixing recipe to mitigate forgetting. Our experiments on\nadapting an English LLM to Hungarian and Thai show that our recipe can reach\nbetter performance than open source models on the target language, with minimal\nregressions on English.",
            "author": [
                "Zoltan Csaki",
                "Pian Pawakapan",
                "Urmish Thakker",
                "Qiantong Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05741v1",
                "http://arxiv.org/pdf/2311.05741v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05740v1",
            "title": "Generating Pragmatic Examples to Train Neural Program Synthesizers",
            "updated": "2023-11-09T20:53:00Z",
            "published": "2023-11-09T20:53:00Z",
            "summary": "Programming-by-example is the task of synthesizing a program that is\nconsistent with a set of user-provided input-output examples. As examples are\noften an under-specification of one's intent, a good synthesizer must choose\nthe intended program from the many that are consistent with the given set of\nexamples. Prior work frames program synthesis as a cooperative game between a\nlistener (that synthesizes programs) and a speaker (a user choosing examples),\nand shows that models of computational pragmatic inference are effective in\nchoosing the user intended programs. However, these models require\ncounterfactual reasoning over a large set of programs and examples, which is\ninfeasible in realistic program spaces. In this paper, we propose a novel way\nto amortize this search with neural networks. We sample pairs of programs and\nexamples via self-play between listener and speaker models, and use pragmatic\ninference to choose informative training examples from this sample.We then use\nthe informative dataset to train models to improve the synthesizer's ability to\ndisambiguate user-provided examples without human supervision. We validate our\nmethod on the challenging task of synthesizing regular expressions from example\nstrings, and find that our method (1) outperforms models trained without\nchoosing pragmatic examples by 23% (a 51% relative increase) (2) matches the\nperformance of supervised learning on a dataset of pragmatic examples provided\nby humans, despite using no human data in training.",
            "author": [
                "Saujas Vaduguru",
                "Daniel Fried",
                "Yewen Pu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05740v1",
                "http://arxiv.org/pdf/2311.05740v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05739v1",
            "title": "Deep Learning Architecture for Network-Efficiency at the Edge",
            "updated": "2023-11-09T20:52:36Z",
            "published": "2023-11-09T20:52:36Z",
            "summary": "The growing number of AI-driven applications in the mobile devices has led to\nsolutions that integrate deep learning models with the available edge-cloud\nresources; due to multiple benefits such as reduction in on-device energy\nconsumption, improved latency, improved network usage, and certain privacy\nimprovements, split learning, where deep learning models are split away from\nthe mobile device and computed in a distributed manner, has become an\nextensively explored topic. Combined with compression-aware methods where\nlearning adapts to compression of communicated data, the benefits of this\napproach have further improved and could serve as an alternative to established\napproaches like federated learning methods. In this work, we develop an\nadaptive compression-aware split learning method ('deprune') to improve and\ntrain deep learning models so that they are much more network-efficient (use\nless network resources and are faster), which would make them ideal to deploy\nin weaker devices with the help of edge-cloud resources. This method is also\nextended ('prune') to very quickly train deep learning models, through a\ntransfer learning approach, that trades off little accuracy for much more\nnetwork-efficient inference abilities. We show that the 'deprune' method can\nreduce network usage by 4x when compared with a split-learning approach (that\ndoes not use our method) without loss of accuracy, while also improving\naccuracy over compression-aware split-learning by 4 percent. Lastly, we show\nthat the 'prune' method can reduce the training time for certain models by up\nto 6x without affecting the accuracy when compared against a compression-aware\nsplit-learning approach.",
            "author": [
                "Akrit Mudvari",
                "Antero Vainio",
                "Iason Ofeidis",
                "Sasu Tarkoma",
                "Leandros Tassiulas"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05739v1",
                "http://arxiv.org/pdf/2311.05739v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05733v1",
            "title": "LogShield: A Transformer-based APT Detection System Leveraging\n  Self-Attention",
            "updated": "2023-11-09T20:43:15Z",
            "published": "2023-11-09T20:43:15Z",
            "summary": "Cyber attacks are often identified using system and network logs. There have\nbeen significant prior works that utilize provenance graphs and ML techniques\nto detect attacks, specifically advanced persistent threats, which are very\ndifficult to detect. Lately, there have been studies where transformer-based\nlanguage models are being used to detect various types of attacks from system\nlogs. However, no such attempts have been made in the case of APTs. In\naddition, existing state-of-the-art techniques that use system provenance\ngraphs, lack a data processing framework generalized across datasets for\noptimal performance. For mitigating this limitation as well as exploring the\neffectiveness of transformer-based language models, this paper proposes\nLogShield, a framework designed to detect APT attack patterns leveraging the\npower of self-attention in transformers. We incorporate customized embedding\nlayers to effectively capture the context of event sequences derived from\nprovenance graphs. While acknowledging the computational overhead associated\nwith training transformer networks, our framework surpasses existing LSTM and\nLanguage models regarding APT detection. We integrated the model parameters and\ntraining procedure from the RoBERTa model and conducted extensive experiments\non well-known APT datasets (DARPA OpTC and DARPA TC E3). Our framework achieved\nsuperior F1 scores of 98% and 95% on the two datasets respectively, surpassing\nthe F1 scores of 96% and 94% obtained by LSTM models. Our findings suggest that\nLogShield's performance benefits from larger datasets and demonstrates its\npotential for generalization across diverse domains. These findings contribute\nto the advancement of APT attack detection methods and underscore the\nsignificance of transformer-based architectures in addressing security\nchallenges in computer systems.",
            "author": [
                "Sihat Afnan",
                "Mushtari Sadia",
                "Shahrear Iqbal",
                "Anindya Iqbal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05733v1",
                "http://arxiv.org/pdf/2311.05733v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05729v1",
            "title": "GIPCOL: Graph-Injected Soft Prompting for Compositional Zero-Shot\n  Learning",
            "updated": "2023-11-09T20:32:18Z",
            "published": "2023-11-09T20:32:18Z",
            "summary": "Pre-trained vision-language models (VLMs) have achieved promising success in\nmany fields, especially with prompt learning paradigm. In this work, we propose\nGIP-COL (Graph-Injected Soft Prompting for COmpositional Learning) to better\nexplore the compositional zero-shot learning (CZSL) ability of VLMs within the\nprompt-based learning framework. The soft prompt in GIPCOL is structured and\nconsists of the prefix learnable vectors, attribute label and object label. In\naddition, the attribute and object labels in the soft prompt are designated as\nnodes in a compositional graph. The compositional graph is constructed based on\nthe compositional structure of the objects and attributes extracted from the\ntraining data and consequently feeds the updated concept representation into\nthe soft prompt to capture this compositional structure for a better prompting\nfor CZSL. With the new prompting strategy, GIPCOL achieves state-of-the-art AUC\nresults on all three CZSL benchmarks, including MIT-States, UT-Zappos, and\nC-GQA datasets in both closed and open settings compared to previous non-CLIP\nas well as CLIP-based methods. We analyze when and why GIPCOL operates well\ngiven the CLIP backbone and its training data limitations, and our findings\nshed light on designing more effective prompts for CZSL",
            "author": [
                "Guangyue Xu",
                "Joyce Chai",
                "Parisa Kordjamshidi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05729v1",
                "http://arxiv.org/pdf/2311.05729v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05728v1",
            "title": "A Physics-Informed, Deep Double Reservoir Network for Forecasting\n  Boundary Layer Velocity",
            "updated": "2023-11-09T20:31:10Z",
            "published": "2023-11-09T20:31:10Z",
            "summary": "When a fluid flows over a solid surface, it creates a thin boundary layer\nwhere the flow velocity is influenced by the surface through viscosity, and can\ntransition from laminar to turbulent at sufficiently high speeds. Understanding\nand forecasting the wind dynamics under these conditions is one of the most\nchallenging scientific problems in fluid dynamics. It is therefore of high\ninterest to formulate models able to capture the nonlinear spatio-temporal\nvelocity structure as well as produce forecasts in a computationally efficient\nmanner. Traditional statistical approaches are limited in their ability to\nproduce timely forecasts of complex, nonlinear spatio-temporal structures which\nare at the same time able to incorporate the underlying flow physics. In this\nwork, we propose a model to accurately forecast boundary layer velocities with\na deep double reservoir computing network which is capable of capturing the\ncomplex, nonlinear dynamics of the boundary layer while at the same time\nincorporating physical constraints via a penalty obtained by a Partial\nDifferential Equation (PDE). Simulation studies on a one-dimensional viscous\nfluid demonstrate how the proposed model is able to produce accurate forecasts\nwhile simultaneously accounting for energy loss. The application focuses on\nboundary layer data on a wind tunnel with a PDE penalty derived from an\nappropriate simplification of the Navier-Stokes equations, showing forecasts\nmore compliant with mass conservation.",
            "author": [
                "Matthew Bonas",
                "David H. Richter",
                "Stefano Castruccio"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05728v1",
                "http://arxiv.org/pdf/2311.05728v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05726v1",
            "title": "Neural Network Methods for Radiation Detectors and Imaging",
            "updated": "2023-11-09T20:21:51Z",
            "published": "2023-11-09T20:21:51Z",
            "summary": "Recent advances in image data processing through machine learning and\nespecially deep neural networks (DNNs) allow for new optimization and\nperformance-enhancement schemes for radiation detectors and imaging hardware\nthrough data-endowed artificial intelligence. We give an overview of data\ngeneration at photon sources, deep learning-based methods for image processing\ntasks, and hardware solutions for deep learning acceleration. Most existing\ndeep learning approaches are trained offline, typically using large amounts of\ncomputational resources. However, once trained, DNNs can achieve fast inference\nspeeds and can be deployed to edge devices. A new trend is edge computing with\nless energy consumption (hundreds of watts or less) and real-time analysis\npotential. While popularly used for edge computing, electronic-based hardware\naccelerators ranging from general purpose processors such as central processing\nunits (CPUs) to application-specific integrated circuits (ASICs) are constantly\nreaching performance limits in latency, energy consumption, and other physical\nconstraints. These limits give rise to next-generation analog neuromorhpic\nhardware platforms, such as optical neural networks (ONNs), for high parallel,\nlow latency, and low energy computing to boost deep learning acceleration.",
            "author": [
                "S. Lin",
                "S. Ning",
                "H. Zhu",
                "T. Zhou",
                "C. L. Morris",
                "S. Clayton",
                "M. Cherukara",
                "R. T. Chen",
                "Z. Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05726v1",
                "http://arxiv.org/pdf/2311.05726v1"
            ],
            "primary_category": "physics.ins-det",
            "category": [
                "physics.ins-det",
                "cs.LG",
                "physics.data-an"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05722v1",
            "title": "Verilog-to-PyG -- A Framework for Graph Learning and Augmentation on RTL\n  Designs",
            "updated": "2023-11-09T20:11:40Z",
            "published": "2023-11-09T20:11:40Z",
            "summary": "The complexity of modern hardware designs necessitates advanced methodologies\nfor optimizing and analyzing modern digital systems. In recent times, machine\nlearning (ML) methodologies have emerged as potent instruments for assessing\ndesign quality-of-results at the Register-Transfer Level (RTL) or Boolean\nlevel, aiming to expedite design exploration of advanced RTL configurations. In\nthis presentation, we introduce an innovative open-source framework that\ntranslates RTL designs into graph representation foundations, which can be\nseamlessly integrated with the PyTorch Geometric graph learning platform.\nFurthermore, the Verilog-to-PyG (V2PYG) framework is compatible with the\nopen-source Electronic Design Automation (EDA) toolchain OpenROAD, facilitating\nthe collection of labeled datasets in an utterly open-source manner.\nAdditionally, we will present novel RTL data augmentation methods (incorporated\nin our framework) that enable functional equivalent design augmentation for the\nconstruction of an extensive graph-based RTL design database. Lastly, we will\nshowcase several using cases of V2PYG with detailed scripting examples. V2PYG\ncan be found at \\url{https://yu-maryland.github.io/Verilog-to-PyG/}.",
            "author": [
                "Yingjie Li",
                "Mingju Liu",
                "Alan Mishchenko",
                "Cunxi Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05722v1",
                "http://arxiv.org/pdf/2311.05722v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AR",
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05720v1",
            "title": "Long-Horizon Dialogue Understanding for Role Identification in the Game\n  of Avalon with Large Language Models",
            "updated": "2023-11-09T20:04:08Z",
            "published": "2023-11-09T20:04:08Z",
            "summary": "Deception and persuasion play a critical role in long-horizon dialogues\nbetween multiple parties, especially when the interests, goals, and motivations\nof the participants are not aligned. Such complex tasks pose challenges for\ncurrent Large Language Models (LLM) as deception and persuasion can easily\nmislead them, especially in long-horizon multi-party dialogues. To this end, we\nexplore the game of Avalon: The Resistance, a social deduction game in which\nplayers must determine each other's hidden identities to complete their team's\nobjective. We introduce an online testbed and a dataset containing 20 carefully\ncollected and labeled games among human players that exhibit long-horizon\ndeception in a cooperative-competitive setting. We discuss the capabilities of\nLLMs to utilize deceptive long-horizon conversations between six human players\nto determine each player's goal and motivation. Particularly, we discuss the\nmultimodal integration of the chat between the players and the game's state\nthat grounds the conversation, providing further insights into the true player\nidentities. We find that even current state-of-the-art LLMs do not reach human\nperformance, making our dataset a compelling benchmark to investigate the\ndecision-making and language-processing capabilities of LLMs. Our dataset and\nonline testbed can be found at our project website:\nhttps://sstepput.github.io/Avalon-NLU/",
            "author": [
                "Simon Stepputtis",
                "Joseph Campbell",
                "Yaqi Xie",
                "Zhengyang Qi",
                "Wenxin Sharon Zhang",
                "Ruiyi Wang",
                "Sanketh Rangreji",
                "Michael Lewis",
                "Katia Sycara"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05720v1",
                "http://arxiv.org/pdf/2311.05720v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05716v1",
            "title": "ML-based Real-Time Control at the Edge: An Approach Using hls4ml",
            "updated": "2023-11-09T19:54:54Z",
            "published": "2023-11-09T19:54:54Z",
            "summary": "This study focuses on implementing a real-time control system for a particle\naccelerator facility that performs high energy physics experiments. A critical\noperating parameter in this facility is beam loss, which is the fraction of\nparticles deviating from the accelerated proton beam into a cascade of\nsecondary particles. Accelerators employ a large number of sensors to monitor\nbeam loss. The data from these sensors is monitored by human operators who\npredict the relative contribution of different sub-systems to the beam loss.\nUsing this information, they engage control interventions. In this paper, we\npresent a controller to track this phenomenon in real-time using edge-Machine\nLearning (ML) and support control with low latency and high accuracy. We\nimplemented this system on an Intel Arria 10 SoC. Optimizations at the\nalgorithm, high-level synthesis, and interface levels to improve latency and\nresource usage are presented. Our design implements a neural network, which can\npredict the main source of beam loss (between two possible causes) at speeds up\nto 575 frames per second (fps) (average latency of 1.74 ms). The practical\ndeployed system is required to operate at 320 fps, with a 3ms latency\nrequirement, which has been met by our design successfully.",
            "author": [
                "R. Shi",
                "S. Ogrenci",
                "J. M. Arnold",
                "J. R. Berlioz",
                "P. Hanlet",
                "K. J. Hazelwood",
                "M. A. Ibrahim",
                "H. Liu",
                "V. P. Nagaslaev",
                "A. Narayanan 1",
                "D. J. Nicklaus",
                "J. Mitrevski",
                "G. Pradhan",
                "A. L. Saewert",
                "B. A. Schupbach",
                "K. Seiya",
                "M. Thieme",
                "R. M. Thurman-Keup",
                "N. V. Tran"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05716v1",
                "http://arxiv.org/pdf/2311.05716v1"
            ],
            "primary_category": "cs.AR",
            "category": [
                "cs.AR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05708v1",
            "title": "Intelligent Cervical Spine Fracture Detection Using Deep Learning\n  Methods",
            "updated": "2023-11-09T19:34:42Z",
            "published": "2023-11-09T19:34:42Z",
            "summary": "Cervical spine fractures constitute a critical medical emergency, with the\npotential for lifelong paralysis or even fatality if left untreated or\nundetected. Over time, these fractures can deteriorate without intervention. To\naddress the lack of research on the practical application of deep learning\ntechniques for the detection of spine fractures, this study leverages a dataset\ncontaining both cervical spine fractures and non-fractured computed tomography\nimages. This paper introduces a two-stage pipeline designed to identify the\npresence of cervical vertebrae in each image slice and pinpoint the location of\nfractures. In the first stage, a multi-input network, incorporating image and\nimage metadata, is trained. This network is based on the Global Context Vision\nTransformer, and its performance is benchmarked against popular deep learning\nimage classification model. In the second stage, a YOLOv8 model is trained to\ndetect fractures within the images, and its effectiveness is compared to\nYOLOv5. The obtained results indicate that the proposed algorithm significantly\nreduces the workload of radiologists and enhances the accuracy of fracture\ndetection.",
            "author": [
                "Reza Behbahani Nejad",
                "Amir Hossein Komijani",
                "Esmaeil Najafi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05708v1",
                "http://arxiv.org/pdf/2311.05708v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05705v1",
            "title": "Achieving Maximum Utilization in Optimal Time for Learning or\n  Convergence in the Kolkata Paise Restaurant Problem",
            "updated": "2023-11-09T19:31:17Z",
            "published": "2023-11-09T19:31:17Z",
            "summary": "In the original version of the Kolkata Paise Restaurant (KPR) problem, where\neach of the $N$ agents (or players) choose independently every day (updating\ntheir strategy based on past experience of failures) among the $N$ restaurants,\nwhere he/she will be alone or lucky enough to be picked up randomly from the\ncrowd who arrived at that restaurant that day, to get the only food plate\nserved there. The objective of the agents are to learn themselves in the\nminimum (learning) time to have maximum success or utilization probability\n($f$). A dictator can easily solve the problem with $f = 1$ in no time, by\nasking every one to form a queue and go to the respective restaurant, resulting\nin no fluctuation and full utilization from the first day (convergence time\n$\\tau = 0$). It has already been shown that if each agent chooses randomly the\nrestaurants, $f = 1 - e^{-1} \\simeq 0.63$ and $\\tau = 0$, while the crowd\navoiding (CA) strategy (determined by yesterday's crowd size at the chosen\nrestaurant) gives ($f \\simeq 0.80$) in finite (of order ten) convergence time\n($\\tau$). Many numerical studies of modified learning strategies, actually\nindicated increased value of $f = 1 - \\alpha$ for $\\alpha \\to 0$, with $\\tau\n\\sim 1/\\alpha$. We show here using Monte Carlo technique, a modified Greedy\nCrowd Avoiding (GCA) Strategy can assure full utilization ($f = 1$) in\nconvergence time $\\tau = e N$, where $e$ denotes the Euler number. This\nobservation perhaps suggests that using non-dictated strategies for KPR, full\nutilization can never be collectively learned or achieved in finite convergence\ntime, when $N$, the number of customers or of restaurants goes to infinity.",
            "author": [
                "Aniruddha Biswas",
                "Antika Sinha",
                "Bikas K. Chakrabarti"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05705v1",
                "http://arxiv.org/pdf/2311.05705v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT",
                "physics.soc-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05698v2",
            "title": "Mirasol3B: A Multimodal Autoregressive model for time-aligned and\n  contextual modalities",
            "updated": "2023-11-13T14:53:10Z",
            "published": "2023-11-09T19:15:12Z",
            "summary": "One of the main challenges of multimodal learning is the need to combine\nheterogeneous modalities (e.g., video, audio, text). For example, video and\naudio are obtained at much higher rates than text and are roughly aligned in\ntime. They are often not synchronized with text, which comes as a global\ncontext, e.g., a title, or a description. Furthermore, video and audio inputs\nare of much larger volumes, and grow as the video length increases, which\nnaturally requires more compute dedicated to these modalities and makes\nmodeling of long-range dependencies harder.\n  We here decouple the multimodal modeling, dividing it into separate, focused\nautoregressive models, processing the inputs according to the characteristics\nof the modalities. We propose a multimodal model, called Mirasol3B, consisting\nof an autoregressive component for the time-synchronized modalities (audio and\nvideo), and an autoregressive component for the context modalities which are\nnot necessarily aligned in time but are still sequential. To address the\nlong-sequences of the video-audio inputs, we propose to further partition the\nvideo and audio sequences in consecutive snippets and autoregressively process\ntheir representations. To that end, we propose a Combiner mechanism, which\nmodels the audio-video information jointly within a timeframe. The Combiner\nlearns to extract audio and video features from raw spatio-temporal signals,\nand then learns to fuse these features producing compact but expressive\nrepresentations per snippet.\n  Our approach achieves the state-of-the-art on well established multimodal\nbenchmarks, outperforming much larger models. It effectively addresses the high\ncomputational demand of media inputs by both learning compact representations,\ncontrolling the sequence length of the audio-video feature representations, and\nmodeling their dependencies in time.",
            "author": [
                "AJ Piergiovanni",
                "Isaac Noble",
                "Dahun Kim",
                "Michael S. Ryoo",
                "Victor Gomes",
                "Anelia Angelova"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05698v2",
                "http://arxiv.org/pdf/2311.05698v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.06311v1",
            "title": "Game Theory Solutions in Sensor-Based Human Activity Recognition: A\n  Review",
            "updated": "2023-11-09T19:10:35Z",
            "published": "2023-11-09T19:10:35Z",
            "summary": "The Human Activity Recognition (HAR) tasks automatically identify human\nactivities using the sensor data, which has numerous applications in\nhealthcare, sports, security, and human-computer interaction. Despite\nsignificant advances in HAR, critical challenges still exist. Game theory has\nemerged as a promising solution to address these challenges in machine learning\nproblems including HAR. However, there is a lack of research work on applying\ngame theory solutions to the HAR problems. This review paper explores the\npotential of game theory as a solution for HAR tasks, and bridges the gap\nbetween game theory and HAR research work by suggesting novel game-theoretic\napproaches for HAR problems. The contributions of this work include exploring\nhow game theory can improve the accuracy and robustness of HAR models,\ninvestigating how game-theoretic concepts can optimize recognition algorithms,\nand discussing the game-theoretic approaches against the existing HAR methods.\nThe objective is to provide insights into the potential of game theory as a\nsolution for sensor-based HAR, and contribute to develop a more accurate and\nefficient recognition system in the future research directions.",
            "author": [
                "Mohammad Hossein Shayesteh",
                "Behrooz Sharokhzadeh",
                "Behrooz Masoumi"
            ],
            "link": [
                "http://dx.doi.org/10.22044/jadm.2023.12538.2407",
                "http://arxiv.org/abs/2311.06311v1",
                "http://arxiv.org/pdf/2311.06311v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05697v2",
            "title": "3DGAUnet: 3D generative adversarial networks with a 3D U-Net based\n  generator to achieve the accurate and effective synthesis of clinical tumor\n  image data for pancreatic cancer",
            "updated": "2023-11-27T15:08:03Z",
            "published": "2023-11-09T19:10:28Z",
            "summary": "Pancreatic ductal adenocarcinoma (PDAC) presents a critical global health\nchallenge, and early detection is crucial for improving the 5-year survival\nrate. Recent medical imaging and computational algorithm advances offer\npotential solutions for early diagnosis. Deep learning, particularly in the\nform of convolutional neural networks (CNNs), has demonstrated success in\nmedical image analysis tasks, including classification and segmentation.\nHowever, the limited availability of clinical data for training purposes\ncontinues to provide a significant obstacle. Data augmentation, generative\nadversarial networks (GANs), and cross-validation are potential techniques to\naddress this limitation and improve model performance, but effective solutions\nare still rare for 3D PDAC, where contrast is especially poor owing to the high\nheterogeneity in both tumor and background tissues. In this study, we developed\na new GAN-based model, named 3DGAUnet, for generating realistic 3D CT images of\nPDAC tumors and pancreatic tissue, which can generate the interslice connection\ndata that the existing 2D CT image synthesis models lack. Our innovation is to\ndevelop a 3D U-Net architecture for the generator to improve shape and texture\nlearning for PDAC tumors and pancreatic tissue. Our approach offers a promising\npath to tackle the urgent requirement for creative and synergistic methods to\ncombat PDAC. The development of this GAN-based model has the potential to\nalleviate data scarcity issues, elevate the quality of synthesized data, and\nthereby facilitate the progression of deep learning models to enhance the\naccuracy and early detection of PDAC tumors, which could profoundly impact\npatient outcomes. Furthermore, this model has the potential to be adapted to\nother types of solid tumors, hence making significant contributions to the\nfield of medical imaging in terms of image processing models.",
            "author": [
                "Yu Shi",
                "Hannah Tang",
                "Michael Baine",
                "Michael A. Hollingsworth",
                "Huijing Du",
                "Dandan Zheng",
                "Chi Zhang",
                "Hongfeng Yu"
            ],
            "link": [
                "http://dx.doi.org/10.3390/cancers15235496",
                "http://arxiv.org/abs/2311.05697v2",
                "http://arxiv.org/pdf/2311.05697v2"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05610v1",
            "title": "Efficient Parallelization Layouts for Large-Scale Distributed Model\n  Training",
            "updated": "2023-11-09T18:59:38Z",
            "published": "2023-11-09T18:59:38Z",
            "summary": "Efficiently training large language models requires parallelizing across\nhundreds of hardware accelerators and invoking various compute and memory\noptimizations. When combined, many of these strategies have complex\ninteractions regarding the final training efficiency. Prior work tackling this\nproblem did not have access to the latest set of optimizations, such as\nFlashAttention or sequence parallelism. In this work, we conduct a\ncomprehensive ablation study of possible training configurations for large\nlanguage models. We distill this large study into several key recommendations\nfor the most efficient training. For instance, we find that using a micro-batch\nsize of 1 usually enables the most efficient training layouts. Larger\nmicro-batch sizes necessitate activation checkpointing or higher degrees of\nmodel parallelism and also lead to larger pipeline bubbles. Our most efficient\nconfigurations enable us to achieve state-of-the-art training efficiency\nresults over a range of model sizes, most notably a Model FLOPs utilization of\n70.5% when training a 13B model.",
            "author": [
                "Johannes Hagemann",
                "Samuel Weinbach",
                "Konstantin Dobler",
                "Maximilian Schall",
                "Gerard de Melo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05610v1",
                "http://arxiv.org/pdf/2311.05610v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05607v1",
            "title": "Real-Time Neural Rasterization for Large Scenes",
            "updated": "2023-11-09T18:59:10Z",
            "published": "2023-11-09T18:59:10Z",
            "summary": "We propose a new method for realistic real-time novel-view synthesis (NVS) of\nlarge scenes. Existing neural rendering methods generate realistic results, but\nprimarily work for small scale scenes (<50 square meters) and have difficulty\nat large scale (>10000 square meters). Traditional graphics-based rasterization\nrendering is fast for large scenes but lacks realism and requires expensive\nmanually created assets. Our approach combines the best of both worlds by\ntaking a moderate-quality scaffold mesh as input and learning a neural texture\nfield and shader to model view-dependant effects to enhance realism, while\nstill using the standard graphics pipeline for real-time rendering. Our method\noutperforms existing neural rendering methods, providing at least 30x faster\nrendering with comparable or better realism for large self-driving and drone\nscenes. Our work is the first to enable real-time rendering of large real-world\nscenes.",
            "author": [
                "Jeffrey Yunfan Liu",
                "Yun Chen",
                "Ze Yang",
                "Jingkang Wang",
                "Sivabalan Manivasagam",
                "Raquel Urtasun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05607v1",
                "http://arxiv.org/pdf/2311.05607v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05606v1",
            "title": "Diffusion-Generative Multi-Fidelity Learning for Physical Simulation",
            "updated": "2023-11-09T18:59:05Z",
            "published": "2023-11-09T18:59:05Z",
            "summary": "Multi-fidelity surrogate learning is important for physical simulation\nrelated applications in that it avoids running numerical solvers from scratch,\nwhich is known to be costly, and it uses multi-fidelity examples for training\nand greatly reduces the cost of data collection. Despite the variety of\nexisting methods, they all build a model to map the input parameters outright\nto the solution output. Inspired by the recent breakthrough in generative\nmodels, we take an alternative view and consider the solution output as\ngenerated from random noises. We develop a diffusion-generative multi-fidelity\n(DGMF) learning method based on stochastic differential equations (SDE), where\nthe generation is a continuous denoising process. We propose a conditional\nscore model to control the solution generation by the input parameters and the\nfidelity. By conditioning on additional inputs (temporal or spacial variables),\nour model can efficiently learn and predict multi-dimensional solution arrays.\nOur method naturally unifies discrete and continuous fidelity modeling. The\nadvantage of our method in several typical applications shows a promising new\ndirection for multi-fidelity learning.",
            "author": [
                "Zheng Wang",
                "Shibo Li",
                "Shikai Fang",
                "Shandian Zhe"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05606v1",
                "http://arxiv.org/pdf/2311.05606v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05604v1",
            "title": "3D-QAE: Fully Quantum Auto-Encoding of 3D Point Clouds",
            "updated": "2023-11-09T18:58:33Z",
            "published": "2023-11-09T18:58:33Z",
            "summary": "Existing methods for learning 3D representations are deep neural networks\ntrained and tested on classical hardware. Quantum machine learning\narchitectures, despite their theoretically predicted advantages in terms of\nspeed and the representational capacity, have so far not been considered for\nthis problem nor for tasks involving 3D data in general. This paper thus\nintroduces the first quantum auto-encoder for 3D point clouds. Our 3D-QAE\napproach is fully quantum, i.e. all its data processing components are designed\nfor quantum hardware. It is trained on collections of 3D point clouds to\nproduce their compressed representations. Along with finding a suitable\narchitecture, the core challenges in designing such a fully quantum model\ninclude 3D data normalisation and parameter optimisation, and we propose\nsolutions for both these tasks. Experiments on simulated gate-based quantum\nhardware demonstrate that our method outperforms simple classical baselines,\npaving the way for a new research direction in 3D computer vision. The source\ncode is available at https://4dqv.mpi-inf.mpg.de/QAE3D/.",
            "author": [
                "Lakshika Rathi",
                "Edith Tretschk",
                "Christian Theobalt",
                "Rishabh Dabral",
                "Vladislav Golyanik"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05604v1",
                "http://arxiv.org/pdf/2311.05604v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05599v1",
            "title": "SynH2R: Synthesizing Hand-Object Motions for Learning Human-to-Robot\n  Handovers",
            "updated": "2023-11-09T18:57:02Z",
            "published": "2023-11-09T18:57:02Z",
            "summary": "Vision-based human-to-robot handover is an important and challenging task in\nhuman-robot interaction. Recent work has attempted to train robot policies by\ninteracting with dynamic virtual humans in simulated environments, where the\npolicies can later be transferred to the real world. However, a major\nbottleneck is the reliance on human motion capture data, which is expensive to\nacquire and difficult to scale to arbitrary objects and human grasping motions.\nIn this paper, we introduce a framework that can generate plausible human\ngrasping motions suitable for training the robot. To achieve this, we propose a\nhand-object synthesis method that is designed to generate handover-friendly\nmotions similar to humans. This allows us to generate synthetic training and\ntesting data with 100x more objects than previous work. In our experiments, we\nshow that our method trained purely with synthetic data is competitive with\nstate-of-the-art methods that rely on real human motion data both in simulation\nand on a real system. In addition, we can perform evaluations on a larger scale\ncompared to prior work. With our newly introduced test set, we show that our\nmodel can better scale to a large variety of unseen objects and human motions\ncompared to the baselines. Project page:\nhttps://eth-ait.github.io/synthetic-handovers/",
            "author": [
                "Sammy Christen",
                "Lan Feng",
                "Wei Yang",
                "Yu-Wei Chao",
                "Otmar Hilliges",
                "Jie Song"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05599v1",
                "http://arxiv.org/pdf/2311.05599v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05598v1",
            "title": "Sorting Out Quantum Monte Carlo",
            "updated": "2023-11-09T18:56:43Z",
            "published": "2023-11-09T18:56:43Z",
            "summary": "Molecular modeling at the quantum level requires choosing a parameterization\nof the wavefunction that both respects the required particle symmetries, and is\nscalable to systems of many particles. For the simulation of fermions, valid\nparameterizations must be antisymmetric with respect to the exchange of\nparticles. Typically, antisymmetry is enforced by leveraging the anti-symmetry\nof determinants with respect to the exchange of matrix rows, but this involves\ncomputing a full determinant each time the wavefunction is evaluated. Instead,\nwe introduce a new antisymmetrization layer derived from sorting, the\n$\\textit{sortlet}$, which scales as $O(N \\log N)$ with regards to the number of\nparticles -- in contrast to $O(N^3)$ for the determinant. We show numerically\nthat applying this anti-symmeterization layer on top of an attention based\nneural-network backbone yields a flexible wavefunction parameterization capable\nof reaching chemical accuracy when approximating the ground state of first-row\natoms and small molecules.",
            "author": [
                "Jack Richter-Powell",
                "Luca Thiede",
                "Al\u00e1n Asparu-Guzik",
                "David Duvenaud"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05598v1",
                "http://arxiv.org/pdf/2311.05598v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "physics.chem-ph",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05596v1",
            "title": "LLM Augmented Hierarchical Agents",
            "updated": "2023-11-09T18:54:28Z",
            "published": "2023-11-09T18:54:28Z",
            "summary": "Solving long-horizon, temporally-extended tasks using Reinforcement Learning\n(RL) is challenging, compounded by the common practice of learning without\nprior knowledge (or tabula rasa learning). Humans can generate and execute\nplans with temporally-extended actions and quickly learn to perform new tasks\nbecause we almost never solve problems from scratch. We want autonomous agents\nto have this same ability. Recently, LLMs have been shown to encode a\ntremendous amount of knowledge about the world and to perform impressive\nin-context learning and reasoning. However, using LLMs to solve real world\nproblems is hard because they are not grounded in the current task. In this\npaper we exploit the planning capabilities of LLMs while using RL to provide\nlearning from the environment, resulting in a hierarchical agent that uses LLMs\nto solve long-horizon tasks. Instead of completely relying on LLMs, they guide\na high-level policy, making learning significantly more sample efficient. This\napproach is evaluated in simulation environments such as MiniGrid, SkillHack,\nand Crafter, and on a real robot arm in block manipulation tasks. We show that\nagents trained using our approach outperform other baselines methods and, once\ntrained, don't need access to LLMs during deployment.",
            "author": [
                "Bharat Prakash",
                "Tim Oates",
                "Tinoosh Mohsenin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05596v1",
                "http://arxiv.org/pdf/2311.05596v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05589v1",
            "title": "A Coefficient Makes SVRG Effective",
            "updated": "2023-11-09T18:47:44Z",
            "published": "2023-11-09T18:47:44Z",
            "summary": "Stochastic Variance Reduced Gradient (SVRG), introduced by Johnson & Zhang\n(2013), is a theoretically compelling optimization method. However, as Defazio\n& Bottou (2019) highlights, its effectiveness in deep learning is yet to be\nproven. In this work, we demonstrate the potential of SVRG in optimizing\nreal-world neural networks. Our analysis finds that, for deeper networks, the\nstrength of the variance reduction term in SVRG should be smaller and decrease\nas training progresses. Inspired by this, we introduce a multiplicative\ncoefficient $\\alpha$ to control the strength and adjust it through a linear\ndecay schedule. We name our method $\\alpha$-SVRG. Our results show\n$\\alpha$-SVRG better optimizes neural networks, consistently reducing training\nloss compared to both baseline and the standard SVRG across various\narchitectures and image classification datasets. We hope our findings encourage\nfurther exploration into variance reduction techniques in deep learning. Code\nis available at https://github.com/davidyyd/alpha-SVRG.",
            "author": [
                "Yida Yin",
                "Zhiqiu Xu",
                "Zhiyuan Li",
                "Trevor Darrell",
                "Zhuang Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05589v1",
                "http://arxiv.org/pdf/2311.05589v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05587v3",
            "title": "Bayesian Methods for Media Mix Modelling with shape and funnel effects",
            "updated": "2023-12-07T11:25:57Z",
            "published": "2023-11-09T18:47:33Z",
            "summary": "In recent years, significant progress in generative AI has highlighted the\nimportant role of physics-inspired models that utilize advanced mathematical\nconcepts based on fundamental physics principles to enhance artificial\nintelligence capabilities. Among these models, those based on diffusion\nequations have greatly improved image quality. This study aims to explore the\npotential uses of Maxwell-Boltzmann equation, which forms the basis of the\nkinetic theory of gases, and the Michaelis-Menten model in Marketing Mix\nModelling (MMM) applications. We propose incorporating these equations into\nHierarchical Bayesian models to analyse consumer behaviour in the context of\nadvertising. These equation sets excel in accurately describing the random\ndynamics in complex systems like social interactions and consumer-advertising\ninteractions.",
            "author": [
                "Javier Marin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05587v3",
                "http://arxiv.org/pdf/2311.05587v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05584v1",
            "title": "Zero-Shot Goal-Directed Dialogue via RL on Imagined Conversations",
            "updated": "2023-11-09T18:45:16Z",
            "published": "2023-11-09T18:45:16Z",
            "summary": "Large language models (LLMs) have emerged as powerful and general solutions\nto many natural language tasks. However, many of the most important\napplications of language generation are interactive, where an agent has to talk\nto a person to reach a desired outcome. For example, a teacher might try to\nunderstand their student's current comprehension level to tailor their\ninstruction accordingly, and a travel agent might ask questions of their\ncustomer to understand their preferences in order to recommend activities they\nmight enjoy. LLMs trained with supervised fine-tuning or \"single-step\" RL, as\nwith standard RLHF, might struggle which tasks that require such goal-directed\nbehavior, since they are not trained to optimize for overall conversational\noutcomes after multiple turns of interaction. In this work, we explore a new\nmethod for adapting LLMs with RL for such goal-directed dialogue. Our key\ninsight is that, though LLMs might not effectively solve goal-directed dialogue\ntasks out of the box, they can provide useful data for solving such tasks by\nsimulating suboptimal but human-like behaviors. Given a textual description of\na goal-directed dialogue task, we leverage LLMs to sample diverse synthetic\nrollouts of hypothetical in-domain human-human interactions. Our algorithm then\nutilizes this dataset with offline reinforcement learning to train an\ninteractive conversational agent that can optimize goal-directed objectives\nover multiple turns. In effect, the LLM produces examples of possible\ninteractions, and RL then processes these examples to learn to perform more\noptimal interactions. Empirically, we show that our proposed approach achieves\nstate-of-the-art performance in various goal-directed dialogue tasks that\ninclude teaching and preference elicitation.",
            "author": [
                "Joey Hong",
                "Sergey Levine",
                "Anca Dragan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05584v1",
                "http://arxiv.org/pdf/2311.05584v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05672v2",
            "title": "Conditional Optimal Transport on Function Spaces",
            "updated": "2023-11-17T16:32:53Z",
            "published": "2023-11-09T18:44:42Z",
            "summary": "We present a systematic study of conditional triangular transport maps in\nfunction spaces from the perspective of optimal transportation and with a view\ntowards amortized Bayesian inference. More specifically, we develop a theory of\nconstrained optimal transport problems that describe block-triangular Monge\nmaps that characterize conditional measures along with their Kantorovich\nrelaxations. This generalizes the theory of optimal triangular transport to\nseparable infinite-dimensional function spaces with general cost functions. We\nfurther tailor our results to the case of Bayesian inference problems and\nobtain regularity estimates on the conditioning maps from the prior to the\nposterior. Finally, we present numerical experiments that demonstrate the\ncomputational applicability of our theoretical results for amortized and\nlikelihood-free inference of functional parameters.",
            "author": [
                "Bamdad Hosseini",
                "Alexander W. Hsu",
                "Amirhossein Taghvaei"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05672v2",
                "http://arxiv.org/pdf/2311.05672v2"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "math.PR",
                "stat.CO",
                "stat.ML",
                "49Q22, 62G86, 62F15, 60B05"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05582v1",
            "title": "Joint SDN Synchronization and Controller Placement in Wireless Networks\n  using Deep Reinforcement Learning",
            "updated": "2023-11-09T18:42:20Z",
            "published": "2023-11-09T18:42:20Z",
            "summary": "Software Defined Networking has afforded numerous benefits to the network\nusers but there are certain persisting issues with this technology, two of\nwhich are scalability and privacy. The natural solution to overcoming these\nlimitations is a distributed SDN controller architecture where multiple\ncontrollers are deployed over the network, with each controller orchestrating a\ncertain segment of the network. However, since the centralized control is the\nkey attribute of SDN that allows it to be so beneficial, a centralized logical\nview of the network will have to be maintained by each of these controllers;\nthis can be done through synchronization of the distributed controllers, where\neach controller communicates with the others to ensure that they remain\ninformed about the entire network. There is however a network cost associated\nwith constantly having to update each others about different aspects of the\nnetwork, which will become a greater issue in dynamic wireless networks. To\nminimize this network cost, there is a need to consider not only when to get\nthe update information from the neighboring controllers, but also where to\ndynamically place the controllers such that the network costs may be minimized.\nThe placement should take into consideration both communication for\nsynchronization among the distributed controllers and communication of the\ncontrollers with the network devices that they manage. In this work, we show\nthat our multi-objective deep reinforcement learning-based method performs the\nbest at achieving different application goals by developing policy for\ncontroller synchronization as well as placement, outperforming different other\npossible approaches, under a wide variety of network conditions.",
            "author": [
                "Akrit Mudvari",
                "Leandros Tassiulas"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05582v1",
                "http://arxiv.org/pdf/2311.05582v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05579v1",
            "title": "SigScatNet: A Siamese + Scattering based Deep Learning Approach for\n  Signature Forgery Detection and Similarity Assessment",
            "updated": "2023-11-09T18:38:46Z",
            "published": "2023-11-09T18:38:46Z",
            "summary": "The surge in counterfeit signatures has inflicted widespread inconveniences\nand formidable challenges for both individuals and organizations. This\ngroundbreaking research paper introduces SigScatNet, an innovative solution to\ncombat this issue by harnessing the potential of a Siamese deep learning\nnetwork, bolstered by Scattering wavelets, to detect signature forgery and\nassess signature similarity. The Siamese Network empowers us to ascertain the\nauthenticity of signatures through a comprehensive similarity index, enabling\nprecise validation and comparison. Remarkably, the integration of Scattering\nwavelets endows our model with exceptional efficiency, rendering it light\nenough to operate seamlessly on cost-effective hardware systems. To validate\nthe efficacy of our approach, extensive experimentation was conducted on two\nopen-sourced datasets: the ICDAR SigComp Dutch dataset and the CEDAR dataset.\nThe experimental results demonstrate the practicality and resounding success of\nour proposed SigScatNet, yielding an unparalleled Equal Error Rate of 3.689%\nwith the ICDAR SigComp Dutch dataset and an astonishing 0.0578% with the CEDAR\ndataset. Through the implementation of SigScatNet, our research spearheads a\nnew state-of-the-art in signature analysis in terms of EER scores and\ncomputational efficiency, offering an advanced and accessible solution for\ndetecting forgery and quantifying signature similarities. By employing\ncutting-edge Siamese deep learning and Scattering wavelets, we provide a robust\nframework that paves the way for secure and efficient signature verification\nsystems.",
            "author": [
                "Anmol Chokshi",
                "Vansh Jain",
                "Rajas Bhope",
                "Sudhir Dhage"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05579v1",
                "http://arxiv.org/pdf/2311.05579v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05573v1",
            "title": "Outlier-Robust Wasserstein DRO",
            "updated": "2023-11-09T18:32:00Z",
            "published": "2023-11-09T18:32:00Z",
            "summary": "Distributionally robust optimization (DRO) is an effective approach for\ndata-driven decision-making in the presence of uncertainty. Geometric\nuncertainty due to sampling or localized perturbations of data points is\ncaptured by Wasserstein DRO (WDRO), which seeks to learn a model that performs\nuniformly well over a Wasserstein ball centered around the observed data\ndistribution. However, WDRO fails to account for non-geometric perturbations\nsuch as adversarial outliers, which can greatly distort the Wasserstein\ndistance measurement and impede the learned model. We address this gap by\nproposing a novel outlier-robust WDRO framework for decision-making under both\ngeometric (Wasserstein) perturbations and non-geometric (total variation (TV))\ncontamination that allows an $\\varepsilon$-fraction of data to be arbitrarily\ncorrupted. We design an uncertainty set using a certain robust Wasserstein ball\nthat accounts for both perturbation types and derive minimax optimal excess\nrisk bounds for this procedure that explicitly capture the Wasserstein and TV\nrisks. We prove a strong duality result that enables tractable convex\nreformulations and efficient computation of our outlier-robust WDRO problem.\nWhen the loss function depends only on low-dimensional features of the data, we\neliminate certain dimension dependencies from the risk bounds that are\nunavoidable in the general setting. Finally, we present experiments validating\nour theory on standard regression and classification tasks.",
            "author": [
                "Sloan Nietert",
                "Ziv Goldfeld",
                "Soroosh Shafiee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05573v1",
                "http://arxiv.org/pdf/2311.05573v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05571v1",
            "title": "Effective Data-Driven Collective Variables for Free Energy Calculations\n  from Metadynamics of Paths",
            "updated": "2023-11-09T18:28:41Z",
            "published": "2023-11-09T18:28:41Z",
            "summary": "A variety of enhanced sampling methods predict multidimensional free energy\nlandscapes associated with biological and other molecular processes as a\nfunction of a few selected collective variables (CVs). The accuracy of these\nmethods is crucially dependent on the ability of the chosen CVs to capture the\nrelevant slow degrees of freedom of the system. For complex processes, finding\nsuch CVs is the real challenge. Machine learning (ML) CVs offer, in principle,\na solution to handle this problem. However, these methods rely on the\navailability of high-quality datasets -- ideally incorporating information\nabout physical pathways and transition states -- which are difficult to access,\ntherefore greatly limiting their domain of application. Here, we demonstrate\nhow these datasets can be generated by means of enhanced sampling simulations\nin trajectory space via the metadynamics of paths [arXiv:2002.09281] algorithm.\nThe approach is expected to provide a general and efficient way to generate\nefficient high quality d CVs for the fast prediction of free energy landscapes.\nWe demonstrate our approach on two numerical examples, a two-dimensional model\npotential and the isomerization of alanine dipeptide, using deep targeted\ndiscriminant analysis as our ML-based CV of choice.",
            "author": [
                "Lukas M\u00fcllender",
                "Andrea Rizzi",
                "Michele Parrinello",
                "Paolo Carloni",
                "Davide Mandelli"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05571v1",
                "http://arxiv.org/pdf/2311.05571v1"
            ],
            "primary_category": "physics.comp-ph",
            "category": [
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05567v1",
            "title": "Exploring Emotion Expression Recognition in Older Adults Interacting\n  with a Virtual Coach",
            "updated": "2023-11-09T18:22:32Z",
            "published": "2023-11-09T18:22:32Z",
            "summary": "The EMPATHIC project aimed to design an emotionally expressive virtual coach\ncapable of engaging healthy seniors to improve well-being and promote\nindependent aging. One of the core aspects of the system is its human sensing\ncapabilities, allowing for the perception of emotional states to provide a\npersonalized experience. This paper outlines the development of the emotion\nexpression recognition module of the virtual coach, encompassing data\ncollection, annotation design, and a first methodological approach, all\ntailored to the project requirements. With the latter, we investigate the role\nof various modalities, individually and combined, for discrete emotion\nexpression recognition in this context: speech from audio, and facial\nexpressions, gaze, and head dynamics from video. The collected corpus includes\nusers from Spain, France, and Norway, and was annotated separately for the\naudio and video channels with distinct emotional labels, allowing for a\nperformance comparison across cultures and label types. Results confirm the\ninformative power of the modalities studied for the emotional categories\nconsidered, with multimodal methods generally outperforming others (around 68%\naccuracy with audio labels and 72-74% with video labels). The findings are\nexpected to contribute to the limited literature on emotion recognition applied\nto older adults in conversational human-machine interaction.",
            "author": [
                "Cristina Palmero",
                "Mikel deVelasco",
                "Mohamed Amine Hmani",
                "Aymen Mtibaa",
                "Leila Ben Letaifa",
                "Pau Buch-Cardona",
                "Raquel Justo",
                "Terry Amorese",
                "Eduardo Gonz\u00e1lez-Fraile",
                "Bego\u00f1a Fern\u00e1ndez-Ruanova",
                "Jofre Tenorio-Laranga",
                "Anna Torp Johansen",
                "Micaela Rodrigues da Silva",
                "Liva Jenny Martinussen",
                "Maria Stylianou Korsnes",
                "Gennaro Cordasco",
                "Anna Esposito",
                "Mounim A. El-Yacoubi",
                "Dijana Petrovska-Delacr\u00e9taz",
                "M. In\u00e9s Torres",
                "Sergio Escalera"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05567v1",
                "http://arxiv.org/pdf/2311.05567v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.HC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05565v1",
            "title": "High-Performance Transformers for Table Structure Recognition Need Early\n  Convolutions",
            "updated": "2023-11-09T18:20:52Z",
            "published": "2023-11-09T18:20:52Z",
            "summary": "Table structure recognition (TSR) aims to convert tabular images into a\nmachine-readable format, where a visual encoder extracts image features and a\ntextual decoder generates table-representing tokens. Existing approaches use\nclassic convolutional neural network (CNN) backbones for the visual encoder and\ntransformers for the textual decoder. However, this hybrid CNN-Transformer\narchitecture introduces a complex visual encoder that accounts for nearly half\nof the total model parameters, markedly reduces both training and inference\nspeed, and hinders the potential for self-supervised learning in TSR. In this\nwork, we design a lightweight visual encoder for TSR without sacrificing\nexpressive power. We discover that a convolutional stem can match classic CNN\nbackbone performance, with a much simpler model. The convolutional stem strikes\nan optimal balance between two crucial factors for high-performance TSR: a\nhigher receptive field (RF) ratio and a longer sequence length. This allows it\nto \"see\" an appropriate portion of the table and \"store\" the complex table\nstructure within sufficient context length for the subsequent transformer. We\nconducted reproducible ablation studies and open-sourced our code at\nhttps://github.com/poloclub/tsr-convstem to enhance transparency, inspire\ninnovations, and facilitate fair comparisons in our domain as tables are a\npromising modality for representation learning.",
            "author": [
                "ShengYun Peng",
                "Seongmin Lee",
                "Xiaojing Wang",
                "Rajarajeswari Balasubramaniyan",
                "Duen Horng Chau"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05565v1",
                "http://arxiv.org/pdf/2311.05565v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05559v1",
            "title": "Disentangling Quantum and Classical Contributions in Hybrid Quantum\n  Machine Learning Architectures",
            "updated": "2023-11-09T18:13:50Z",
            "published": "2023-11-09T18:13:50Z",
            "summary": "Quantum computing offers the potential for superior computational\ncapabilities, particularly for data-intensive tasks. However, the current state\nof quantum hardware puts heavy restrictions on input size. To address this,\nhybrid transfer learning solutions have been developed, merging pre-trained\nclassical models, capable of handling extensive inputs, with variational\nquantum circuits. Yet, it remains unclear how much each component - classical\nand quantum - contributes to the model's results. We propose a novel hybrid\narchitecture: instead of utilizing a pre-trained network for compression, we\nemploy an autoencoder to derive a compressed version of the input data. This\ncompressed data is then channeled through the encoder part of the autoencoder\nto the quantum component. We assess our model's classification capabilities\nagainst two state-of-the-art hybrid transfer learning architectures, two purely\nclassical architectures and one quantum architecture. Their accuracy is\ncompared across four datasets: Banknote Authentication, Breast Cancer\nWisconsin, MNIST digits, and AudioMNIST. Our research suggests that classical\ncomponents significantly influence classification in hybrid transfer learning,\na contribution often mistakenly ascribed to the quantum element. The\nperformance of our model aligns with that of a variational quantum circuit\nusing amplitude embedding, positioning it as a feasible alternative.",
            "author": [
                "Michael K\u00f6lle",
                "Jonas Maurer",
                "Philipp Altmann",
                "Leo S\u00fcnkel",
                "Jonas Stein",
                "Claudia Linnhoff-Popien"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05559v1",
                "http://arxiv.org/pdf/2311.05559v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05557v1",
            "title": "Exploiting Neural-Network Statistics for Low-Power DNN Inference",
            "updated": "2023-11-09T18:05:46Z",
            "published": "2023-11-09T18:05:46Z",
            "summary": "Specialized compute blocks have been developed for efficient DNN execution.\nHowever, due to the vast amount of data and parameter movements, the\ninterconnects and on-chip memories form another bottleneck, impairing power and\nperformance. This work addresses this bottleneck by contributing a low-power\ntechnique for edge-AI inference engines that combines overhead-free coding with\na statistical analysis of the data and parameters of neural networks. Our\napproach reduces the interconnect and memory power consumption by up to 80% for\nstate-of-the-art benchmarks while providing additional power savings for the\ncompute blocks by up to 39%. These power improvements are achieved with no loss\nof accuracy and negligible hardware cost.",
            "author": [
                "Lennart Bamberg",
                "Ardalan Najafi",
                "Alberto Garcia-Ortiz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05557v1",
                "http://arxiv.org/pdf/2311.05557v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05556v1",
            "title": "LCM-LoRA: A Universal Stable-Diffusion Acceleration Module",
            "updated": "2023-11-09T18:04:15Z",
            "published": "2023-11-09T18:04:15Z",
            "summary": "Latent Consistency Models (LCMs) have achieved impressive performance in\naccelerating text-to-image generative tasks, producing high-quality images with\nminimal inference steps. LCMs are distilled from pre-trained latent diffusion\nmodels (LDMs), requiring only ~32 A100 GPU training hours. This report further\nextends LCMs' potential in two aspects: First, by applying LoRA distillation to\nStable-Diffusion models including SD-V1.5, SSD-1B, and SDXL, we have expanded\nLCM's scope to larger models with significantly less memory consumption,\nachieving superior image generation quality. Second, we identify the LoRA\nparameters obtained through LCM distillation as a universal Stable-Diffusion\nacceleration module, named LCM-LoRA. LCM-LoRA can be directly plugged into\nvarious Stable-Diffusion fine-tuned models or LoRAs without training, thus\nrepresenting a universally applicable accelerator for diverse image generation\ntasks. Compared with previous numerical PF-ODE solvers such as DDIM,\nDPM-Solver, LCM-LoRA can be viewed as a plug-in neural PF-ODE solver that\npossesses strong generalization abilities. Project page:\nhttps://github.com/luosiallen/latent-consistency-model.",
            "author": [
                "Simian Luo",
                "Yiqin Tan",
                "Suraj Patil",
                "Daniel Gu",
                "Patrick von Platen",
                "Apolin\u00e1rio Passos",
                "Longbo Huang",
                "Jian Li",
                "Hang Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05556v1",
                "http://arxiv.org/pdf/2311.05556v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05553v2",
            "title": "Removing RLHF Protections in GPT-4 via Fine-Tuning",
            "updated": "2023-11-10T21:17:17Z",
            "published": "2023-11-09T17:54:59Z",
            "summary": "As large language models (LLMs) have increased in their capabilities, so does\ntheir potential for dual use. To reduce harmful outputs, produces and vendors\nof LLMs have used reinforcement learning with human feedback (RLHF). In tandem,\nLLM vendors have been increasingly enabling fine-tuning of their most powerful\nmodels. However, concurrent work has shown that fine-tuning can remove RLHF\nprotections. We may expect that the most powerful models currently available\n(GPT-4) are less susceptible to fine-tuning attacks.\n  In this work, we show the contrary: fine-tuning allows attackers to remove\nRLHF protections with as few as 340 examples and a 95% success rate. These\ntraining examples can be automatically generated with weaker models. We further\nshow that removing RLHF protections does not decrease usefulness on\nnon-censored outputs, providing evidence that our fine-tuning strategy does not\ndecrease usefulness despite using weaker models to generate training data. Our\nresults show the need for further research on protections on LLMs.",
            "author": [
                "Qiusi Zhan",
                "Richard Fang",
                "Rohan Bindu",
                "Akul Gupta",
                "Tatsunori Hashimoto",
                "Daniel Kang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05553v2",
                "http://arxiv.org/pdf/2311.05553v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.13571v1",
            "title": "Ball Mill Fault Prediction Based on Deep Convolutional Auto-Encoding\n  Network",
            "updated": "2023-11-09T17:49:07Z",
            "published": "2023-11-09T17:49:07Z",
            "summary": "Ball mills play a critical role in modern mining operations, making their\nbearing failures a significant concern due to the potential loss of production\nefficiency and economic consequences. This paper presents an anomaly detection\nmethod based on Deep Convolutional Auto-encoding Neural Networks (DCAN) for\naddressing the issue of ball mill bearing fault detection. The proposed\napproach leverages vibration data collected during normal operation for\ntraining, overcoming challenges such as labeling issues and data imbalance\noften encountered in supervised learning methods. DCAN includes the modules of\nconvolutional feature extraction and transposed convolutional feature\nreconstruction, demonstrating exceptional capabilities in signal processing and\nfeature extraction. Additionally, the paper describes the practical deployment\nof the DCAN-based anomaly detection model for bearing fault detection,\nutilizing data from the ball mill bearings of Wuhan Iron & Steel Resources\nGroup and fault data from NASA's bearing vibration dataset. Experimental\nresults validate the DCAN model's reliability in recognizing fault vibration\npatterns. This method holds promise for enhancing bearing fault detection\nefficiency, reducing production interruptions, and lowering maintenance costs.",
            "author": [
                "Xinkun Ai",
                "Kun Liu",
                "Wei Zheng",
                "Yonggang Fan",
                "Xinwu Wu",
                "Peilong Zhang",
                "LiYe Wang",
                "JanFeng Zhu",
                "Yuan Pan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.13571v1",
                "http://arxiv.org/pdf/2311.13571v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05550v1",
            "title": "Towards End-to-End Spoken Grammatical Error Correction",
            "updated": "2023-11-09T17:49:02Z",
            "published": "2023-11-09T17:49:02Z",
            "summary": "Grammatical feedback is crucial for L2 learners, teachers, and testers.\nSpoken grammatical error correction (GEC) aims to supply feedback to L2\nlearners on their use of grammar when speaking. This process usually relies on\na cascaded pipeline comprising an ASR system, disfluency removal, and GEC, with\nthe associated concern of propagating errors between these individual modules.\nIn this paper, we introduce an alternative \"end-to-end\" approach to spoken GEC,\nexploiting a speech recognition foundation model, Whisper. This foundation\nmodel can be used to replace the whole framework or part of it, e.g., ASR and\ndisfluency removal. These end-to-end approaches are compared to more standard\ncascaded approaches on the data obtained from a free-speaking spoken language\nassessment test, Linguaskill. Results demonstrate that end-to-end spoken GEC is\npossible within this architecture, but the lack of available data limits\ncurrent performance compared to a system using large quantities of text-based\nGEC data. Conversely, end-to-end disfluency detection and removal, which is\neasier for the attention-based Whisper to learn, does outperform cascaded\napproaches. Additionally, the paper discusses the challenges of providing\nfeedback to candidates when using end-to-end systems for spoken GEC.",
            "author": [
                "Stefano Bann\u00f2",
                "Rao Ma",
                "Mengjie Qian",
                "Kate M. Knill",
                "Mark J. F. Gales"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05550v1",
                "http://arxiv.org/pdf/2311.05550v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05548v1",
            "title": "L-WaveBlock: A Novel Feature Extractor Leveraging Wavelets for\n  Generative Adversarial Networks",
            "updated": "2023-11-09T17:47:32Z",
            "published": "2023-11-09T17:47:32Z",
            "summary": "Generative Adversarial Networks (GANs) have risen to prominence in the field\nof deep learning, facilitating the generation of realistic data from random\nnoise. The effectiveness of GANs often depends on the quality of feature\nextraction, a critical aspect of their architecture. This paper introduces\nL-WaveBlock, a novel and robust feature extractor that leverages the\ncapabilities of the Discrete Wavelet Transform (DWT) with deep learning\nmethodologies. L-WaveBlock is catered to quicken the convergence of GAN\ngenerators while simultaneously enhancing their performance. The paper\ndemonstrates the remarkable utility of L-WaveBlock across three datasets, a\nroad satellite imagery dataset, the CelebA dataset and the GoPro dataset,\nshowcasing its ability to ease feature extraction and make it more efficient.\nBy utilizing DWT, L-WaveBlock efficiently captures the intricate details of\nboth structural and textural details, and further partitions feature maps into\northogonal subbands across multiple scales while preserving essential\ninformation at the same time. Not only does it lead to faster convergence, but\nalso gives competent results on every dataset by employing the L-WaveBlock. The\nproposed method achieves an Inception Score of 3.6959 and a Structural\nSimilarity Index of 0.4261 on the maps dataset, a Peak Signal-to-Noise Ratio of\n29.05 and a Structural Similarity Index of 0.874 on the CelebA dataset. The\nproposed method performs competently to the state-of-the-art for the image\ndenoising dataset, albeit not better, but still leads to faster convergence\nthan conventional methods. With this, L-WaveBlock emerges as a robust and\nefficient tool for enhancing GAN-based image generation, demonstrating superior\nconvergence speed and competitive performance across multiple datasets for\nimage resolution, image generation and image denoising.",
            "author": [
                "Mirat Shah",
                "Vansh Jain",
                "Anmol Chokshi",
                "Guruprasad Parasnis",
                "Pramod Bide"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05548v1",
                "http://arxiv.org/pdf/2311.05548v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05546v1",
            "title": "Multi-Agent Quantum Reinforcement Learning using Evolutionary\n  Optimization",
            "updated": "2023-11-09T17:45:32Z",
            "published": "2023-11-09T17:45:32Z",
            "summary": "Multi-Agent Reinforcement Learning is becoming increasingly more important in\ntimes of autonomous driving and other smart industrial applications.\nSimultaneously a promising new approach to Reinforcement Learning arises using\nthe inherent properties of quantum mechanics, reducing the trainable parameters\nof a model significantly. However, gradient-based Multi-Agent Quantum\nReinforcement Learning methods often have to struggle with barren plateaus,\nholding them back from matching the performance of classical approaches. We\nbuild upon a existing approach for gradient free Quantum Reinforcement Learning\nand propose tree approaches with Variational Quantum Circuits for Multi-Agent\nReinforcement Learning using evolutionary optimization. We evaluate our\napproach in the Coin Game environment and compare them to classical approaches.\nWe showed that our Variational Quantum Circuit approaches perform significantly\nbetter compared to a neural network with a similar amount of trainable\nparameters. Compared to the larger neural network, our approaches archive\nsimilar results using $97.88\\%$ less parameters.",
            "author": [
                "Michael K\u00f6lle",
                "Felix Topp",
                "Thomy Phan",
                "Philipp Altmann",
                "Jonas N\u00fc\u00dflein",
                "Claudia Linnhoff-Popien"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05546v1",
                "http://arxiv.org/pdf/2311.05546v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.AI",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05540v1",
            "title": "Usability and Adoption of Graphical Data-Driven Development Tools",
            "updated": "2023-11-09T17:35:47Z",
            "published": "2023-11-09T17:35:47Z",
            "summary": "Software development of modern, data-driven applications still relies on\ntools that use interaction paradigms that have remained mostly unchanged for\ndecades. While rich forms of interactions exist as an alternative to textual\ncommand input, they find little adoption in professional software creation. In\nthis work, we compare graphical programming using direct manipulation to the\ntraditional, textual way of creating data-driven applications to determine the\nbenefits and drawbacks of each. In a between-subjects user study (N=18), we\ncompared developing a machine learning architecture with a graphical editor to\ntraditional code-based development. While qualitative and quantitative measures\nshow general benefits of graphical direct manipulation, the user's subjective\nperception does not always match this. Participants were aware of the possible\nbenefits of such tools but were still biased in their perception. Our findings\nhighlight that alternative software creation tools cannot just rely on good\nusability but must emphasize the demands of their specific target group, e.g.\nuser control and flexibility, if they want long-term benefits and adoption.",
            "author": [
                "Thomas Weber",
                "Sven Mayer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05540v1",
                "http://arxiv.org/pdf/2311.05540v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05539v1",
            "title": "A Deep Learning Method for Simultaneous Denoising and Missing Wedge\n  Reconstruction in Cryogenic Electron Tomography",
            "updated": "2023-11-09T17:34:57Z",
            "published": "2023-11-09T17:34:57Z",
            "summary": "Cryogenic electron tomography (cryo-ET) is a technique for imaging biological\nsamples such as viruses, cells, and proteins in 3D. A microscope collects a\nseries of 2D projections of the sample, and the goal is to reconstruct the 3D\ndensity of the sample called the tomogram. This is difficult as the 2D\nprojections have a missing wedge of information and are noisy. Tomograms\nreconstructed with conventional methods, such as filtered back-projection,\nsuffer from the noise, and from artifacts and anisotropic resolution due to the\nmissing wedge of information. To improve the visual quality and resolution of\nsuch tomograms, we propose a deep-learning approach for simultaneous denoising\nand missing wedge reconstruction called DeepDeWedge. DeepDeWedge is based on\nfitting a neural network to the 2D projections with a self-supervised loss\ninspired by noise2noise-like methods. The algorithm requires no training or\nground truth data. Experiments on synthetic and real cryo-ET data show that\nDeepDeWedge achieves competitive performance for deep learning-based denoising\nand missing wedge reconstruction of cryo-ET tomograms.",
            "author": [
                "Simon Wiedemann",
                "Reinhard Heckel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05539v1",
                "http://arxiv.org/pdf/2311.05539v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05538v1",
            "title": "Embedding Space Interpolation Beyond Mini-Batch, Beyond Pairs and Beyond\n  Examples",
            "updated": "2023-11-09T17:34:53Z",
            "published": "2023-11-09T17:34:53Z",
            "summary": "Mixup refers to interpolation-based data augmentation, originally motivated\nas a way to go beyond empirical risk minimization (ERM). Its extensions mostly\nfocus on the definition of interpolation and the space (input or feature) where\nit takes place, while the augmentation process itself is less studied. In most\nmethods, the number of generated examples is limited to the mini-batch size and\nthe number of examples being interpolated is limited to two (pairs), in the\ninput space.\n  We make progress in this direction by introducing MultiMix, which generates\nan arbitrarily large number of interpolated examples beyond the mini-batch size\nand interpolates the entire mini-batch in the embedding space. Effectively, we\nsample on the entire convex hull of the mini-batch rather than along linear\nsegments between pairs of examples.\n  On sequence data, we further extend to Dense MultiMix. We densely interpolate\nfeatures and target labels at each spatial location and also apply the loss\ndensely. To mitigate the lack of dense labels, we inherit labels from examples\nand weight interpolation factors by attention as a measure of confidence.\n  Overall, we increase the number of loss terms per mini-batch by orders of\nmagnitude at little additional cost. This is only possible because of\ninterpolating in the embedding space. We empirically show that our solutions\nyield significant improvement over state-of-the-art mixup methods on four\ndifferent benchmarks, despite interpolation being only linear. By analyzing the\nembedding space, we show that the classes are more tightly clustered and\nuniformly spread over the embedding space, thereby explaining the improved\nbehavior.",
            "author": [
                "Shashanka Venkataramanan",
                "Ewa Kijak",
                "Laurent Amsaleg",
                "Yannis Avrithis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05538v1",
                "http://arxiv.org/pdf/2311.05538v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05532v1",
            "title": "Uncertainty-Aware Bayes' Rule and Its Applications",
            "updated": "2023-11-09T17:24:12Z",
            "published": "2023-11-09T17:24:12Z",
            "summary": "Bayes' rule has enabled innumerable powerful algorithms of statistical signal\nprocessing and statistical machine learning. However, when there exist model\nmisspecifications in prior distributions and/or data distributions, the direct\napplication of Bayes' rule is questionable. Philosophically, the key is to\nbalance the relative importance of prior and data distributions when\ncalculating posterior distributions: if prior (resp. data) distributions are\noverly conservative, we should upweight the prior belief (resp. data evidence);\nif prior (resp. data) distributions are overly opportunistic, we should\ndownweight the prior belief (resp. data evidence). This paper derives a\ngeneralized Bayes' rule, called uncertainty-aware Bayes' rule, to technically\nrealize the above philosophy, i.e., to combat the model uncertainties in prior\ndistributions and/or data distributions. Simulated and real-world experiments\nshowcase the superiority of the presented uncertainty-aware Bayes' rule over\nthe conventional Bayes' rule: In particular, the uncertainty-aware Kalman\nfilter, the uncertainty-aware particle filter, and the uncertainty-aware\ninteractive multiple model filter are suggested and validated.",
            "author": [
                "Shixiong Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05532v1",
                "http://arxiv.org/pdf/2311.05532v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05529v1",
            "title": "Information-theoretic generalization bounds for learning from quantum\n  data",
            "updated": "2023-11-09T17:21:38Z",
            "published": "2023-11-09T17:21:38Z",
            "summary": "Learning tasks play an increasingly prominent role in quantum information and\ncomputation. They range from fundamental problems such as state discrimination\nand metrology over the framework of quantum probably approximately correct\n(PAC) learning, to the recently proposed shadow variants of state tomography.\nHowever, the many directions of quantum learning theory have so far evolved\nseparately. We propose a general mathematical formalism for describing quantum\nlearning by training on classical-quantum data and then testing how well the\nlearned hypothesis generalizes to new data. In this framework, we prove bounds\non the expected generalization error of a quantum learner in terms of classical\nand quantum information-theoretic quantities measuring how strongly the\nlearner's hypothesis depends on the specific data seen during training.\n  To achieve this, we use tools from quantum optimal transport and quantum\nconcentration inequalities to establish non-commutative versions of decoupling\nlemmas that underlie recent information-theoretic generalization bounds for\nclassical machine learning.\n  Our framework encompasses and gives intuitively accessible generalization\nbounds for a variety of quantum learning scenarios such as quantum state\ndiscrimination, PAC learning quantum states, quantum parameter estimation, and\nquantumly PAC learning classical functions. Thereby, our work lays a foundation\nfor a unifying quantum information-theoretic perspective on quantum learning.",
            "author": [
                "Matthias Caro",
                "Tom Gur",
                "Cambyse Rouz\u00e9",
                "Daniel Stilck Fran\u00e7a",
                "Sathyawageeswar Subramanian"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05529v1",
                "http://arxiv.org/pdf/2311.05529v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.CC",
                "cs.IT",
                "cs.LG",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.07590v2",
            "title": "Technical Report: Large Language Models can Strategically Deceive their\n  Users when Put Under Pressure",
            "updated": "2023-11-27T15:17:49Z",
            "published": "2023-11-09T17:12:44Z",
            "summary": "We demonstrate a situation in which Large Language Models, trained to be\nhelpful, harmless, and honest, can display misaligned behavior and\nstrategically deceive their users about this behavior without being instructed\nto do so. Concretely, we deploy GPT-4 as an agent in a realistic, simulated\nenvironment, where it assumes the role of an autonomous stock trading agent.\nWithin this environment, the model obtains an insider tip about a lucrative\nstock trade and acts upon it despite knowing that insider trading is\ndisapproved of by company management. When reporting to its manager, the model\nconsistently hides the genuine reasons behind its trading decision. We perform\na brief investigation of how this behavior varies under changes to the setting,\nsuch as removing model access to a reasoning scratchpad, attempting to prevent\nthe misaligned behavior by changing system instructions, changing the amount of\npressure the model is under, varying the perceived risk of getting caught, and\nmaking other simple changes to the environment. To our knowledge, this is the\nfirst demonstration of Large Language Models trained to be helpful, harmless,\nand honest, strategically deceiving their users in a realistic situation\nwithout direct instructions or training for deception.",
            "author": [
                "J\u00e9r\u00e9my Scheurer",
                "Mikita Balesni",
                "Marius Hobbhahn"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07590v2",
                "http://arxiv.org/pdf/2311.07590v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05521v2",
            "title": "BakedAvatar: Baking Neural Fields for Real-Time Head Avatar Synthesis",
            "updated": "2023-11-28T15:31:46Z",
            "published": "2023-11-09T17:05:53Z",
            "summary": "Synthesizing photorealistic 4D human head avatars from videos is essential\nfor VR/AR, telepresence, and video game applications. Although existing Neural\nRadiance Fields (NeRF)-based methods achieve high-fidelity results, the\ncomputational expense limits their use in real-time applications. To overcome\nthis limitation, we introduce BakedAvatar, a novel representation for real-time\nneural head avatar synthesis, deployable in a standard polygon rasterization\npipeline. Our approach extracts deformable multi-layer meshes from learned\nisosurfaces of the head and computes expression-, pose-, and view-dependent\nappearances that can be baked into static textures for efficient rasterization.\nWe thus propose a three-stage pipeline for neural head avatar synthesis, which\nincludes learning continuous deformation, manifold, and radiance fields,\nextracting layered meshes and textures, and fine-tuning texture details with\ndifferential rasterization. Experimental results demonstrate that our\nrepresentation generates synthesis results of comparable quality to other\nstate-of-the-art methods while significantly reducing the inference time\nrequired. We further showcase various head avatar synthesis results from\nmonocular videos, including view synthesis, face reenactment, expression\nediting, and pose editing, all at interactive frame rates.",
            "author": [
                "Hao-Bin Duan",
                "Miao Wang",
                "Jin-Chuan Shi",
                "Xu-Chuan Chen",
                "Yan-Pei Cao"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3618399",
                "http://arxiv.org/abs/2311.05521v2",
                "http://arxiv.org/pdf/2311.05521v2"
            ],
            "primary_category": "cs.GR",
            "category": [
                "cs.GR",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05513v1",
            "title": "From Learning Management System to Affective Tutoring system: a\n  preliminary study",
            "updated": "2023-11-09T16:52:44Z",
            "published": "2023-11-09T16:52:44Z",
            "summary": "In this study, we investigate the combination of indicators, including\nperformance, behavioral engagement, and emotional engagement, to identify\nstudents experiencing difficulties. We analyzed data from two primary sources:\ndigital traces extracted from th e Learning Management System (LMS) and images\ncaptured by students' webcams. The digital traces provided insights into\nstudents' interactions with the educational content, while the images were\nutilized to analyze their emotional expressions during learnin g activities. By\nutilizing real data collected from students at a French engineering school,\nrecorded during the 2022 2023 academic year, we observed a correlation between\npositive emotional states and improved academic outcomes. These preliminary\nfindings support the notion that emotions play a crucial role in\ndifferentiating between high achieving and low achieving students.",
            "author": [
                "Nadaud Edouard",
                "Geoffroy Thibault",
                "Khelifi Tesnim",
                "Yaacoub Antoun",
                "Haidar Siba",
                "Ben Rabah Nourh\u00c8ne",
                "Aubin Jean Pierre",
                "Prevost Lionel",
                "Le Grand Benedicte"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05513v1",
                "http://arxiv.org/pdf/2311.05513v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05511v2",
            "title": "Anytime-Constrained Reinforcement Learning",
            "updated": "2023-11-14T06:46:06Z",
            "published": "2023-11-09T16:51:26Z",
            "summary": "We introduce and study constrained Markov Decision Processes (cMDPs) with\nanytime constraints. An anytime constraint requires the agent to never violate\nits budget at any point in time, almost surely. Although Markovian policies are\nno longer sufficient, we show that there exist optimal deterministic policies\naugmented with cumulative costs. In fact, we present a fixed-parameter\ntractable reduction from anytime-constrained cMDPs to unconstrained MDPs. Our\nreduction yields planning and learning algorithms that are time and\nsample-efficient for tabular cMDPs so long as the precision of the costs is\nlogarithmic in the size of the cMDP. However, we also show that computing\nnon-trivial approximately optimal policies is NP-hard in general. To circumvent\nthis bottleneck, we design provable approximation algorithms that efficiently\ncompute or learn an arbitrarily accurate approximately feasible policy with\noptimal value so long as the maximum supported cost is bounded by a polynomial\nin the cMDP or the absolute budget. Given our hardness results, our\napproximation guarantees are the best possible under worst-case analysis.",
            "author": [
                "Jeremy McMahan",
                "Xiaojin Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05511v2",
                "http://arxiv.org/pdf/2311.05511v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05501v1",
            "title": "Dirichlet Active Learning",
            "updated": "2023-11-09T16:39:02Z",
            "published": "2023-11-09T16:39:02Z",
            "summary": "This work introduces Dirichlet Active Learning (DiAL), a Bayesian-inspired\napproach to the design of active learning algorithms. Our framework models\nfeature-conditional class probabilities as a Dirichlet random field and lends\nobservational strength between similar features in order to calibrate the\nrandom field. This random field can then be utilized in learning tasks: in\nparticular, we can use current estimates of mean and variance to conduct\nclassification and active learning in the context where labeled data is scarce.\nWe demonstrate the applicability of this model to low-label rate graph learning\nby constructing ``propagation operators'' based upon the graph Laplacian, and\noffer computational studies demonstrating the method's competitiveness with the\nstate of the art. Finally, we provide rigorous guarantees regarding the ability\nof this approach to ensure both exploration and exploitation, expressed\nrespectively in terms of cluster exploration and increased attention to\ndecision boundaries.",
            "author": [
                "Kevin Miller",
                "Ryan Murray"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05501v1",
                "http://arxiv.org/pdf/2311.05501v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05490v1",
            "title": "General Policies, Subgoal Structure, and Planning Width",
            "updated": "2023-11-09T16:30:22Z",
            "published": "2023-11-09T16:30:22Z",
            "summary": "It has been observed that many classical planning domains with atomic goals\ncan be solved by means of a simple polynomial exploration procedure, called IW,\nthat runs in time exponential in the problem width, which in these cases is\nbounded and small. Yet, while the notion of width has become part of\nstate-of-the-art planning algorithms such as BFWS, there is no good explanation\nfor why so many benchmark domains have bounded width when atomic goals are\nconsidered. In this work, we address this question by relating bounded width\nwith the existence of general optimal policies that in each planning instance\nare represented by tuples of atoms of bounded size. We also define the notions\nof (explicit) serializations and serialized width that have a broader scope as\nmany domains have a bounded serialized width but no bounded width. Such\nproblems are solved non-optimally in polynomial time by a suitable variant of\nthe Serialized IW algorithm. Finally, the language of general policies and the\nsemantics of serializations are combined to yield a simple, meaningful, and\nexpressive language for specifying serializations in compact form in the form\nof sketches, which can be used for encoding domain control knowledge by hand or\nfor learning it from small examples. Sketches express general problem\ndecompositions in terms of subgoals, and sketches of bounded width express\nproblem decompositions that can be solved in polynomial time.",
            "author": [
                "Blai Bonet",
                "Hector Geffner"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05490v1",
                "http://arxiv.org/pdf/2311.05490v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05486v1",
            "title": "Disease Gene Prioritization With Quantum Walks",
            "updated": "2023-11-09T16:21:34Z",
            "published": "2023-11-09T16:21:34Z",
            "summary": "Disease gene prioritization assigns scores to genes or proteins according to\ntheir likely relevance for a given disease based on a provided set of seed\ngenes. Here, we describe a new algorithm for disease gene prioritization based\non continuous-time quantum walks using the adjacency matrix of a\nprotein-protein interaction (PPI) network. Our algorithm can be seen as a\nquantum version of a previous method known as the diffusion kernel, but,\nimportantly, has higher performance in predicting disease genes, and also\npermits the encoding of seed node self-loops into the underlying Hamiltonian,\nwhich offers yet another boost in performance. We demonstrate the success of\nour proposed method by comparing it to several well-known gene prioritization\nmethods on three disease sets, across seven different PPI networks. In order to\ncompare these methods, we use cross-validation and examine the mean reciprocal\nranks and recall values. We further validate our method by performing an\nenrichment analysis of the predicted genes for coronary artery disease. We also\ninvestigate the impact of adding self-loops to the seeds, and argue that they\nallow the quantum walker to remain more local to low-degree seed nodes.",
            "author": [
                "Harto Saarinen",
                "Mark Goldsmith",
                "Rui-Sheng Wang",
                "Joseph Loscalzo",
                "Sabrina Maniscalco"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05486v1",
                "http://arxiv.org/pdf/2311.05486v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.LG",
                "q-bio.MN"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05481v2",
            "title": "META4: Semantically-Aligned Generation of Metaphoric Gestures Using\n  Self-Supervised Text and Speech Representation",
            "updated": "2023-11-21T10:26:29Z",
            "published": "2023-11-09T16:16:31Z",
            "summary": "Image Schemas are repetitive cognitive patterns that influence the way we\nconceptualize and reason about various concepts present in speech. These\npatterns are deeply embedded within our cognitive processes and are reflected\nin our bodily expressions including gestures. Particularly, metaphoric gestures\npossess essential characteristics and semantic meanings that align with Image\nSchemas, to visually represent abstract concepts. The shape and form of\ngestures can convey abstract concepts, such as extending the forearm and hand\nor tracing a line with hand movements to visually represent the image schema of\nPATH. Previous behavior generation models have primarily focused on utilizing\nspeech (acoustic features and text) to drive the generation model of virtual\nagents. They have not considered key semantic information as those carried by\nImage Schemas to effectively generate metaphoric gestures. To address this\nlimitation, we introduce META4, a deep learning approach that generates\nmetaphoric gestures from both speech and Image Schemas. Our approach has two\nprimary goals: computing Image Schemas from input text to capture the\nunderlying semantic and metaphorical meaning, and generating metaphoric\ngestures driven by speech and the computed image schemas. Our approach is the\nfirst method for generating speech driven metaphoric gestures while leveraging\nthe potential of Image Schemas. We demonstrate the effectiveness of our\napproach and highlight the importance of both speech and image schemas in\nmodeling metaphoric gestures.",
            "author": [
                "Mireille Fares",
                "Catherine Pelachaud",
                "Nicolas Obin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05481v2",
                "http://arxiv.org/pdf/2311.05481v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05479v1",
            "title": "Retinal OCT Synthesis with Denoising Diffusion Probabilistic Models for\n  Layer Segmentation",
            "updated": "2023-11-09T16:09:24Z",
            "published": "2023-11-09T16:09:24Z",
            "summary": "Modern biomedical image analysis using deep learning often encounters the\nchallenge of limited annotated data. To overcome this issue, deep generative\nmodels can be employed to synthesize realistic biomedical images. In this\nregard, we propose an image synthesis method that utilizes denoising diffusion\nprobabilistic models (DDPMs) to automatically generate retinal optical\ncoherence tomography (OCT) images. By providing rough layer sketches, the\ntrained DDPMs can generate realistic circumpapillary OCT images. We further\nfind that more accurate pseudo labels can be obtained through knowledge\nadaptation, which greatly benefits the segmentation task. Through this, we\nobserve a consistent improvement in layer segmentation accuracy, which is\nvalidated using various neural networks. Furthermore, we have discovered that a\nlayer segmentation model trained solely with synthesized images can achieve\ncomparable results to a model trained exclusively with real images. These\nfindings demonstrate the promising potential of DDPMs in reducing the need for\nmanual annotations of retinal OCT images.",
            "author": [
                "Yuli Wu",
                "Weidong He",
                "Dennis Eschweiler",
                "Ningxin Dou",
                "Zixin Fan",
                "Shengli Mi",
                "Peter Walter",
                "Johannes Stegmaier"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05479v1",
                "http://arxiv.org/pdf/2311.05479v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "physics.med-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05477v1",
            "title": "Using ResNet to Utilize 4-class T2-FLAIR Slice Classification Based on\n  the Cholinergic Pathways Hyperintensities Scale for Pathological Aging",
            "updated": "2023-11-09T16:08:55Z",
            "published": "2023-11-09T16:08:55Z",
            "summary": "The Cholinergic Pathways Hyperintensities Scale (CHIPS) is a visual rating\nscale used to assess the extent of cholinergic white matter hyperintensities in\nT2-FLAIR images, serving as an indicator of dementia severity. However, the\nmanual selection of four specific slices for rating throughout the entire brain\nis a time-consuming process. Our goal was to develop a deep learning-based\nmodel capable of automatically identifying the four slices relevant to CHIPS.\nTo achieve this, we trained a 4-class slice classification model (BSCA) using\nthe ADNI T2-FLAIR dataset (N=150) with the assistance of ResNet. Subsequently,\nwe tested the model's performance on a local dataset (N=30). The results\ndemonstrated the efficacy of our model, with an accuracy of 99.82% and an\nF1-score of 99.83%. This achievement highlights the potential impact of BSCA as\nan automatic screening tool, streamlining the selection of four specific\nT2-FLAIR slices that encompass white matter landmarks along the cholinergic\npathways. Clinicians can leverage this tool to assess the risk of clinical\ndementia development efficiently.",
            "author": [
                "Wei-Chun Kevin Tsai",
                "Yi-Chien Liu",
                "Ming-Chun Yu",
                "Chia-Ju Chou",
                "Sui-Hing Yan",
                "Yang-Teng Fan",
                "Yan-Hsiang Huang",
                "Yen-Ling Chiu",
                "Yi-Fang Chuang",
                "Ran-Zan Wang",
                "Yao-Chia Shih"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05477v1",
                "http://arxiv.org/pdf/2311.05477v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05473v1",
            "title": "Do Ensembling and Meta-Learning Improve Outlier Detection in Randomized\n  Controlled Trials?",
            "updated": "2023-11-09T16:05:38Z",
            "published": "2023-11-09T16:05:38Z",
            "summary": "Modern multi-centre randomized controlled trials (MCRCTs) collect massive\namounts of tabular data, and are monitored intensively for irregularities by\nhumans. We began by empirically evaluating 6 modern machine learning-based\noutlier detection algorithms on the task of identifying irregular data in 838\ndatasets from 7 real-world MCRCTs with a total of 77,001 patients from over 44\ncountries. Our results reinforce key findings from prior work in the outlier\ndetection literature on data from other domains. Existing algorithms often\nsucceed at identifying irregularities without any supervision, with at least\none algorithm exhibiting positive performance 70.6% of the time. However,\nperformance across datasets varies substantially with no single algorithm\nperforming consistently well, motivating new techniques for unsupervised model\nselection or other means of aggregating potentially discordant predictions from\nmultiple candidate models. We propose the Meta-learned Probabilistic Ensemble\n(MePE), a simple algorithm for aggregating the predictions of multiple\nunsupervised models, and show that it performs favourably compared to recent\nmeta-learning approaches for outlier detection model selection. While\nmeta-learning shows promise, small ensembles outperform all forms of\nmeta-learning on average, a negative result that may guide the application of\ncurrent outlier detection approaches in healthcare and other real-world\ndomains.",
            "author": [
                "Walter Nelson",
                "Jonathan Ranisau",
                "Jeremy Petch"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05473v1",
                "http://arxiv.org/pdf/2311.05473v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05472v1",
            "title": "Text Representation Distillation via Information Bottleneck Principle",
            "updated": "2023-11-09T16:04:17Z",
            "published": "2023-11-09T16:04:17Z",
            "summary": "Pre-trained language models (PLMs) have recently shown great success in text\nrepresentation field. However, the high computational cost and high-dimensional\nrepresentation of PLMs pose significant challenges for practical applications.\nTo make models more accessible, an effective method is to distill large models\ninto smaller representation models. In order to relieve the issue of\nperformance degradation after distillation, we propose a novel Knowledge\nDistillation method called IBKD. This approach is motivated by the Information\nBottleneck principle and aims to maximize the mutual information between the\nfinal representation of the teacher and student model, while simultaneously\nreducing the mutual information between the student model's representation and\nthe input data. This enables the student model to preserve important learned\ninformation while avoiding unnecessary information, thus reducing the risk of\nover-fitting. Empirical studies on two main downstream applications of text\nrepresentation (Semantic Textual Similarity and Dense Retrieval tasks)\ndemonstrate the effectiveness of our proposed approach.",
            "author": [
                "Yanzhao Zhang",
                "Dingkun Long",
                "Zehan Li",
                "Pengjun Xie"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05472v1",
                "http://arxiv.org/pdf/2311.05472v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05464v1",
            "title": "3DStyle-Diffusion: Pursuing Fine-grained Text-driven 3D Stylization with\n  2D Diffusion Models",
            "updated": "2023-11-09T15:51:27Z",
            "published": "2023-11-09T15:51:27Z",
            "summary": "3D content creation via text-driven stylization has played a fundamental\nchallenge to multimedia and graphics community. Recent advances of cross-modal\nfoundation models (e.g., CLIP) have made this problem feasible. Those\napproaches commonly leverage CLIP to align the holistic semantics of stylized\nmesh with the given text prompt. Nevertheless, it is not trivial to enable more\ncontrollable stylization of fine-grained details in 3D meshes solely based on\nsuch semantic-level cross-modal supervision. In this work, we propose a new\n3DStyle-Diffusion model that triggers fine-grained stylization of 3D meshes\nwith additional controllable appearance and geometric guidance from 2D\nDiffusion models. Technically, 3DStyle-Diffusion first parameterizes the\ntexture of 3D mesh into reflectance properties and scene lighting using\nimplicit MLP networks. Meanwhile, an accurate depth map of each sampled view is\nachieved conditioned on 3D mesh. Then, 3DStyle-Diffusion leverages a\npre-trained controllable 2D Diffusion model to guide the learning of rendered\nimages, encouraging the synthesized image of each view semantically aligned\nwith text prompt and geometrically consistent with depth map. This way\nelegantly integrates both image rendering via implicit MLP networks and\ndiffusion process of image synthesis in an end-to-end fashion, enabling a\nhigh-quality fine-grained stylization of 3D meshes. We also build a new dataset\nderived from Objaverse and the evaluation protocol for this task. Through both\nqualitative and quantitative experiments, we validate the capability of our\n3DStyle-Diffusion. Source code and data are available at\n\\url{https://github.com/yanghb22-fdu/3DStyle-Diffusion-Official}.",
            "author": [
                "Haibo Yang",
                "Yang Chen",
                "Yingwei Pan",
                "Ting Yao",
                "Zhineng Chen",
                "Tao Mei"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05464v1",
                "http://arxiv.org/pdf/2311.05464v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05463v1",
            "title": "ControlStyle: Text-Driven Stylized Image Generation Using Diffusion\n  Priors",
            "updated": "2023-11-09T15:50:52Z",
            "published": "2023-11-09T15:50:52Z",
            "summary": "Recently, the multimedia community has witnessed the rise of diffusion models\ntrained on large-scale multi-modal data for visual content creation,\nparticularly in the field of text-to-image generation. In this paper, we\npropose a new task for ``stylizing'' text-to-image models, namely text-driven\nstylized image generation, that further enhances editability in content\ncreation. Given input text prompt and style image, this task aims to produce\nstylized images which are both semantically relevant to input text prompt and\nmeanwhile aligned with the style image in style. To achieve this, we present a\nnew diffusion model (ControlStyle) via upgrading a pre-trained text-to-image\nmodel with a trainable modulation network enabling more conditions of text\nprompts and style images. Moreover, diffusion style and content regularizations\nare simultaneously introduced to facilitate the learning of this modulation\nnetwork with these diffusion priors, pursuing high-quality stylized\ntext-to-image generation. Extensive experiments demonstrate the effectiveness\nof our ControlStyle in producing more visually pleasing and artistic results,\nsurpassing a simple combination of text-to-image model and conventional style\ntransfer techniques.",
            "author": [
                "Jingwen Chen",
                "Yingwei Pan",
                "Ting Yao",
                "Tao Mei"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05463v1",
                "http://arxiv.org/pdf/2311.05463v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05461v1",
            "title": "Control3D: Towards Controllable Text-to-3D Generation",
            "updated": "2023-11-09T15:50:32Z",
            "published": "2023-11-09T15:50:32Z",
            "summary": "Recent remarkable advances in large-scale text-to-image diffusion models have\ninspired a significant breakthrough in text-to-3D generation, pursuing 3D\ncontent creation solely from a given text prompt. However, existing text-to-3D\ntechniques lack a crucial ability in the creative process: interactively\ncontrol and shape the synthetic 3D contents according to users' desired\nspecifications (e.g., sketch). To alleviate this issue, we present the first\nattempt for text-to-3D generation conditioning on the additional hand-drawn\nsketch, namely Control3D, which enhances controllability for users. In\nparticular, a 2D conditioned diffusion model (ControlNet) is remoulded to guide\nthe learning of 3D scene parameterized as NeRF, encouraging each view of 3D\nscene aligned with the given text prompt and hand-drawn sketch. Moreover, we\nexploit a pre-trained differentiable photo-to-sketch model to directly estimate\nthe sketch of the rendered image over synthetic 3D scene. Such estimated sketch\nalong with each sampled view is further enforced to be geometrically consistent\nwith the given sketch, pursuing better controllable text-to-3D generation.\nThrough extensive experiments, we demonstrate that our proposal can generate\naccurate and faithful 3D scenes that align closely with the input text prompts\nand sketches.",
            "author": [
                "Yang Chen",
                "Yingwei Pan",
                "Yehao Li",
                "Ting Yao",
                "Tao Mei"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05461v1",
                "http://arxiv.org/pdf/2311.05461v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05452v1",
            "title": "Transformer-based Model for Oral Epithelial Dysplasia Segmentation",
            "updated": "2023-11-09T15:40:42Z",
            "published": "2023-11-09T15:40:42Z",
            "summary": "Oral epithelial dysplasia (OED) is a premalignant histopathological diagnosis\ngiven to lesions of the oral cavity. OED grading is subject to large\ninter/intra-rater variability, resulting in the under/over-treatment of\npatients. We developed a new Transformer-based pipeline to improve detection\nand segmentation of OED in haematoxylin and eosin (H&E) stained whole slide\nimages (WSIs). Our model was trained on OED cases (n = 260) and controls (n =\n105) collected using three different scanners, and validated on test data from\nthree external centres in the United Kingdom and Brazil (n = 78). Our internal\nexperiments yield a mean F1-score of 0.81 for OED segmentation, which reduced\nslightly to 0.71 on external testing, showing good generalisability, and\ngaining state-of-the-art results. This is the first externally validated study\nto use Transformers for segmentation in precancerous histology images. Our\npublicly available model shows great promise to be the first step of a\nfully-integrated pipeline, allowing earlier and more efficient OED diagnosis,\nultimately benefiting patient outcomes.",
            "author": [
                "Adam J Shephard",
                "Hanya Mahmood",
                "Shan E Ahmed Raza",
                "Anna Luiza Damaceno Araujo",
                "Alan Roger Santos-Silva",
                "Marcio Ajudarte Lopes",
                "Pablo Agustin Vargas",
                "Kris McCombe",
                "Stephanie Craig",
                "Jacqueline James",
                "Jill Brooks",
                "Paul Nankivell",
                "Hisham Mehanna",
                "Syed Ali Khurram",
                "Nasir M Rajpoot"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05452v1",
                "http://arxiv.org/pdf/2311.05452v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05451v1",
            "title": "All Should Be Equal in the Eyes of Language Models: Counterfactually\n  Aware Fair Text Generation",
            "updated": "2023-11-09T15:39:40Z",
            "published": "2023-11-09T15:39:40Z",
            "summary": "Fairness in Language Models (LMs) remains a longstanding challenge, given the\ninherent biases in training data that can be perpetuated by models and affect\nthe downstream tasks. Recent methods employ expensive retraining or attempt\ndebiasing during inference by constraining model outputs to contrast from a\nreference set of biased templates or exemplars. Regardless, they dont address\nthe primary goal of fairness to maintain equitability across different\ndemographic groups. In this work, we posit that inferencing LMs to generate\nunbiased output for one demographic under a context ensues from being aware of\noutputs for other demographics under the same context. To this end, we propose\nCounterfactually Aware Fair InferencE (CAFIE), a framework that dynamically\ncompares the model understanding of diverse demographics to generate more\nequitable sentences. We conduct an extensive empirical evaluation using base\nLMs of varying sizes and across three diverse datasets and found that CAFIE\noutperforms strong baselines. CAFIE produces fairer text and strikes the best\nbalance between fairness and language modeling capability",
            "author": [
                "Pragyan Banerjee",
                "Abhinav Java",
                "Surgan Jandial",
                "Simra Shahid",
                "Shaz Furniturewala",
                "Balaji Krishnamurthy",
                "Sumit Bhatia"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05451v1",
                "http://arxiv.org/pdf/2311.05451v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CY",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05450v1",
            "title": "Cognitively Inspired Components for Social Conversational Agents",
            "updated": "2023-11-09T15:38:58Z",
            "published": "2023-11-09T15:38:58Z",
            "summary": "Current conversational agents (CA) have seen improvement in conversational\nquality in recent years due to the influence of large language models (LLMs)\nlike GPT3. However, two key categories of problem remain. Firstly there are the\nunique technical problems resulting from the approach taken in creating the CA,\nsuch as scope with retrieval agents and the often nonsensical answers of former\ngenerative agents. Secondly, humans perceive CAs as social actors, and as a\nresult expect the CA to adhere to social convention. Failure on the part of the\nCA in this respect can lead to a poor interaction and even the perception of\nthreat by the user. As such, this paper presents a survey highlighting a\npotential solution to both categories of problem through the introduction of\ncognitively inspired additions to the CA. Through computational facsimiles of\nsemantic and episodic memory, emotion, working memory, and the ability to\nlearn, it is possible to address both the technical and social problems\nencountered by CAs.",
            "author": [
                "Alex Clay",
                "Eduardo Alonso",
                "Esther Mondrag\u00f3n"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05450v1",
                "http://arxiv.org/pdf/2311.05450v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "I.2.0"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05449v1",
            "title": "Understanding emotions in the context of IT-based self-monitoring",
            "updated": "2023-11-09T15:38:05Z",
            "published": "2023-11-09T15:38:05Z",
            "summary": "This study explores the intersection of information technology-based\nself-monitoring (ITSM) and emotional responses in chronic care. It critiques\nthe lack of theoretical depth in current ITSM research and proposes a dynamic\nemotion process theory to understand ITSM's impact on users' emotions.\nUtilizing computational grounded theory and machine learning analysis of\nhypertension app reviews, the research seeks to extend emotion theory by\nexamining ITSM stimuli and their influence on emotional episodes, moving beyond\ndiscrete emotion models towards a continuous, nuanced understanding of\nemotional responses.",
            "author": [
                "Danielly de Paula",
                "Florian Borchert",
                "Ariane Sasso",
                "Falk Uebernickel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05449v1",
                "http://arxiv.org/pdf/2311.05449v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05445v1",
            "title": "Airfoil generation and feature extraction using the conditional\n  VAE-WGAN-gp",
            "updated": "2023-11-09T15:31:53Z",
            "published": "2023-11-09T15:31:53Z",
            "summary": "A machine learning method was applied to solve an inverse airfoil design\nproblem. A conditional VAE-WGAN-gp model, which couples the conditional\nvariational autoencoder (VAE) and Wasserstein generative adversarial network\nwith gradient penalty (WGAN-gp), is proposed for an airfoil generation method,\nand then it is compared with the WGAN-gp and VAE models. The VAEGAN model\ncouples the VAE and GAN models, which enables feature extraction in the GAN\nmodels. In airfoil generation tasks, to generate airfoil shapes that satisfy\nlift coefficient requirements, it is known that VAE outperforms WGAN-gp with\nrespect to the accuracy of the reproduction of the lift coefficient, whereas\nGAN outperforms VAE with respect to the smoothness and variations of generated\nshapes. In this study, VAE-WGAN-gp demonstrated a good performance in all three\naspects. Latent distribution was also studied to compare the feature extraction\nability of the proposed method.",
            "author": [
                "Kazuo Yonekura",
                "Yuki Tomori",
                "Katsuyuki Suzuki"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05445v1",
                "http://arxiv.org/pdf/2311.05445v1"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05440v2",
            "title": "A Practical Approach to Novel Class Discovery in Tabular Data",
            "updated": "2023-12-05T16:46:09Z",
            "published": "2023-11-09T15:24:44Z",
            "summary": "The problem of Novel Class Discovery (NCD) consists in extracting knowledge\nfrom a labeled set of known classes to accurately partition an unlabeled set of\nnovel classes. While NCD has recently received a lot of attention from the\ncommunity, it is often solved on computer vision problems and under unrealistic\nconditions. In particular, the number of novel classes is usually assumed to be\nknown in advance, and their labels are sometimes used to tune hyperparameters.\nMethods that rely on these assumptions are not applicable in real-world\nscenarios. In this work, we focus on solving NCD in tabular data when no prior\nknowledge of the novel classes is available. To this end, we propose to tune\nthe hyperparameters of NCD methods by adapting the $k$-fold cross-validation\nprocess and hiding some of the known classes in each fold. Since we have found\nthat methods with too many hyperparameters are likely to overfit these hidden\nclasses, we define a simple deep NCD model. This method is composed of only the\nessential elements necessary for the NCD problem and performs impressively well\nunder realistic conditions. Furthermore, we find that the latent space of this\nmethod can be used to reliably estimate the number of novel classes.\nAdditionally, we adapt two unsupervised clustering algorithms ($k$-means and\nSpectral Clustering) to leverage the knowledge of the known classes. Extensive\nexperiments are conducted on 7 tabular datasets and demonstrate the\neffectiveness of the proposed method and hyperparameter tuning process, and\nshow that the NCD problem can be solved without relying on knowledge from the\nnovel classes.",
            "author": [
                "Colin Troisemaine",
                "Alexandre Reiffers-Masson",
                "St\u00e9phane Gosselin",
                "Vincent Lemaire",
                "Sandrine Vaton"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05440v2",
                "http://arxiv.org/pdf/2311.05440v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05437v1",
            "title": "LLaVA-Plus: Learning to Use Tools for Creating Multimodal Agents",
            "updated": "2023-11-09T15:22:26Z",
            "published": "2023-11-09T15:22:26Z",
            "summary": "LLaVA-Plus is a general-purpose multimodal assistant that expands the\ncapabilities of large multimodal models. It maintains a skill repository of\npre-trained vision and vision-language models and can activate relevant tools\nbased on users' inputs to fulfill real-world tasks. LLaVA-Plus is trained on\nmultimodal instruction-following data to acquire the ability to use tools,\ncovering visual understanding, generation, external knowledge retrieval, and\ncompositions. Empirical results show that LLaVA-Plus outperforms LLaVA in\nexisting capabilities and exhibits new ones. It is distinct in that the image\nquery is directly grounded and actively engaged throughout the entire human-AI\ninteraction sessions, significantly improving tool use performance and enabling\nnew scenarios.",
            "author": [
                "Shilong Liu",
                "Hao Cheng",
                "Haotian Liu",
                "Hao Zhang",
                "Feng Li",
                "Tianhe Ren",
                "Xueyan Zou",
                "Jianwei Yang",
                "Hang Su",
                "Jun Zhu",
                "Lei Zhang",
                "Jianfeng Gao",
                "Chunyuan Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05437v1",
                "http://arxiv.org/pdf/2311.05437v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL",
                "cs.LG",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05436v1",
            "title": "Fair Wasserstein Coresets",
            "updated": "2023-11-09T15:21:56Z",
            "published": "2023-11-09T15:21:56Z",
            "summary": "Recent technological advancements have given rise to the ability of\ncollecting vast amounts of data, that often exceed the capacity of commonly\nused machine learning algorithms. Approaches such as coresets and synthetic\ndata distillation have emerged as frameworks to generate a smaller, yet\nrepresentative, set of samples for downstream training. As machine learning is\nincreasingly applied to decision-making processes, it becomes imperative for\nmodelers to consider and address biases in the data concerning subgroups\ndefined by factors like race, gender, or other sensitive attributes. Current\napproaches focus on creating fair synthetic representative samples by\noptimizing local properties relative to the original samples. These methods,\nhowever, are not guaranteed to positively affect the performance or fairness of\ndownstream learning processes. In this work, we present Fair Wasserstein\nCoresets (FWC), a novel coreset approach which generates fair synthetic\nrepresentative samples along with sample-level weights to be used in downstream\nlearning tasks. FWC aims to minimize the Wasserstein distance between the\noriginal datasets and the weighted synthetic samples while enforcing (an\nempirical version of) demographic parity, a prominent criterion for algorithmic\nfairness, via a linear constraint. We show that FWC can be thought of as a\nconstrained version of Lloyd's algorithm for k-medians or k-means clustering.\nOur experiments, conducted on both synthetic and real datasets, demonstrate the\nscalability of our approach and highlight the competitive performance of FWC\ncompared to existing fair clustering approaches, even when attempting to\nenhance the fairness of the latter through fair pre-processing techniques.",
            "author": [
                "Zikai Xiong",
                "Niccol\u00f2 Dalmasso",
                "Vamsi K. Potluru",
                "Tucker Balch",
                "Manuela Veloso"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05436v1",
                "http://arxiv.org/pdf/2311.05436v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.CY",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05435v2",
            "title": "Parkinson's Disease Detection through Vocal Biomarkers and Advanced\n  Machine Learning Algorithms",
            "updated": "2023-12-03T00:40:49Z",
            "published": "2023-11-09T15:21:10Z",
            "summary": "Parkinson's disease (PD) is a prevalent neurodegenerative disorder known for\nits impact on motor neurons, causing symptoms like tremors, stiffness, and gait\ndifficulties. This study explores the potential of vocal feature alterations in\nPD patients as a means of early disease prediction. This research aims to\npredict the onset of Parkinson's disease. Utilizing a variety of advanced\nmachine-learning algorithms, including XGBoost, LightGBM, Bagging, AdaBoost,\nand Support Vector Machine, among others, the study evaluates the predictive\nperformance of these models using metrics such as accuracy, area under the\ncurve (AUC), sensitivity, and specificity. The findings of this comprehensive\nanalysis highlight LightGBM as the most effective model, achieving an\nimpressive accuracy rate of 96% alongside a matching AUC of 96%. LightGBM\nexhibited a remarkable sensitivity of 100% and specificity of 94.43%,\nsurpassing other machine learning algorithms in accuracy and AUC scores. Given\nthe complexities of Parkinson's disease and its challenges in early diagnosis,\nthis study underscores the significance of leveraging vocal biomarkers coupled\nwith advanced machine-learning techniques for precise and timely PD detection.",
            "author": [
                "Md Abu Sayed",
                "Maliha Tayaba",
                "MD Tanvir Islam",
                "Md Eyasin Ul Islam Pavel",
                "Md Tuhin Mia",
                "Eftekhar Hossain Ayon",
                "Nur Nob",
                "Bishnu Padh Ghosh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05435v2",
                "http://arxiv.org/pdf/2311.05435v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05434v1",
            "title": "Core determinants of quality criteria for mhealth for hypertension:\n  evidence from machine learning instruments",
            "updated": "2023-11-09T15:17:57Z",
            "published": "2023-11-09T15:17:57Z",
            "summary": "Uncontrolled hypertension is a global problem that needs to be addressed.\nDespite the many mHealth solutions in the market, the nonadherence relative to\nintended use jeopardizes treatment success. Although investigating user\nexperience is one of the most important mechanisms for understanding mHealth\ndiscontinuance, surprisingly, the core determinants of overall user experience\n(i.e., positive and negative) about mHealth apps for hypertension are unknown.\nTo address the mentioned gap in knowledge, this study adopts the computational\ngrounded theory methodological framework and employs advanced deep learning\nalgorithms to predict core quality criteria that affect overall user experience\nof hypertension apps published in the Apple App Store. This study contributes\nto theory and practice of designing evidence-based interventions for\nhypertension in the form of propositions and provide valuable managerial\nimplications and recommendations for manufacturers.",
            "author": [
                "Danielly de Paula",
                "Ariane Sasso",
                "Justus Coester",
                "Erwin Boettinger"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05434v1",
                "http://arxiv.org/pdf/2311.05434v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05430v2",
            "title": "Taxonomy for Resident Space Objects in LEO: A Deep Learning Approach",
            "updated": "2023-11-15T22:12:59Z",
            "published": "2023-11-09T15:14:08Z",
            "summary": "The increasing number of RSOs has raised concerns about the risk of\ncollisions and catastrophic incidents for all direct and indirect users of\nspace. To mitigate this issue, it is essential to have a good understanding of\nthe various RSOs in orbit and their behaviour. A well-established taxonomy\ndefining several classes of RSOs is a critical step in achieving this\nunderstanding. This taxonomy helps assign objects to specific categories based\non their main characteristics, leading to better tracking services.\nFurthermore, a well-established taxonomy can facilitate research and analysis\nprocesses by providing a common language and framework for better understanding\nthe factors that influence RSO behaviour in space. These factors, in turn, help\ndesign more efficient and effective strategies for space traffic management.\nOur work proposes a new taxonomy for RSOs focusing on the low Earth orbit\nregime to enhance space traffic management. In addition, we present a deep\nlearning-based model that uses an autoencoder architecture to reduce the\nfeatures representing the characteristics of the RSOs. The autoencoder\ngenerates a lower-dimensional space representation that is then explored using\ntechniques such as Uniform Manifold Approximation and Projection to identify\nfundamental clusters of RSOs based on their unique characteristics. This\napproach captures the complex and non-linear relationships between the features\nand the RSOs' classes identified. Our proposed taxonomy and model offer a\nsignificant contribution to the ongoing efforts to mitigate the overall risks\nposed by the increasing number of RSOs in orbit.",
            "author": [
                "Marta Guimar\u00e3es",
                "Cl\u00e1udia Soares",
                "Chiara Manfletti"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05430v2",
                "http://arxiv.org/pdf/2311.05430v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05426v2",
            "title": "Statistical Learning of Conjunction Data Messages Through a Bayesian\n  Non-Homogeneous Poisson Process",
            "updated": "2023-11-15T22:13:06Z",
            "published": "2023-11-09T15:04:14Z",
            "summary": "Current approaches for collision avoidance and space traffic management face\nmany challenges, mainly due to the continuous increase in the number of objects\nin orbit and the lack of scalable and automated solutions. To avoid\ncatastrophic incidents, satellite owners/operators must be aware of their\nassets' collision risk to decide whether a collision avoidance manoeuvre needs\nto be performed. This process is typically executed through the use of warnings\nissued in the form of CDMs which contain information about the event, such as\nthe expected TCA and the probability of collision. Our previous work presented\na statistical learning model that allowed us to answer two important questions:\n(1) Will any new conjunctions be issued in the next specified time interval?\n(2) When and with what uncertainty will the next CDM arrive? However, the model\nwas based on an empirical Bayes homogeneous Poisson process, which assumes that\nthe arrival rates of CDMs are constant over time. In fact, the rate at which\nthe CDMs are issued depends on the behaviour of the objects as well as on the\nscreening process performed by third parties. Thus, in this work, we extend the\nprevious study and propose a Bayesian non-homogeneous Poisson process\nimplemented with high precision using a Probabilistic Programming Language to\nfully describe the underlying phenomena. We compare the proposed solution with\na baseline model to demonstrate the added value of our approach. The results\nshow that this problem can be successfully modelled by our Bayesian\nnon-homogeneous Poisson Process with greater accuracy, contributing to the\ndevelopment of automated collision avoidance systems and helping operators\nreact timely but sparingly with satellite manoeuvres.",
            "author": [
                "Marta Guimar\u00e3es",
                "Cl\u00e1udia Soares",
                "Chiara Manfletti"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05426v2",
                "http://arxiv.org/pdf/2311.05426v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05425v1",
            "title": "Active Mining Sample Pair Semantics for Image-text Matching",
            "updated": "2023-11-09T15:03:57Z",
            "published": "2023-11-09T15:03:57Z",
            "summary": "Recently, commonsense learning has been a hot topic in image-text matching.\nAlthough it can describe more graphic correlations, commonsense learning still\nhas some shortcomings: 1) The existing methods are based on triplet semantic\nsimilarity measurement loss, which cannot effectively match the intractable\nnegative in image-text sample pairs. 2) The weak generalization ability of the\nmodel leads to the poor effect of image and text matching on large-scale\ndatasets. According to these shortcomings. This paper proposes a novel\nimage-text matching model, called Active Mining Sample Pair Semantics\nimage-text matching model (AMSPS). Compared with the single semantic learning\nmode of the commonsense learning model with triplet loss function, AMSPS is an\nactive learning idea. Firstly, the proposed Adaptive Hierarchical Reinforcement\nLoss (AHRL) has diversified learning modes. Its active learning mode enables\nthe model to more focus on the intractable negative samples to enhance the\ndiscriminating ability. In addition, AMSPS can also adaptively mine more hidden\nrelevant semantic representations from uncommented items, which greatly\nimproves the performance and generalization ability of the model. Experimental\nresults on Flickr30K and MSCOCO universal datasets show that our proposed\nmethod is superior to advanced comparison methods.",
            "author": [
                "Yongfeng Chena",
                "Jin Liua",
                "Zhijing Yang",
                "Ruihan Chena",
                "Junpeng Tan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05425v1",
                "http://arxiv.org/pdf/2311.05425v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05421v1",
            "title": "Diffusion Based Causal Representation Learning",
            "updated": "2023-11-09T14:59:26Z",
            "published": "2023-11-09T14:59:26Z",
            "summary": "Causal reasoning can be considered a cornerstone of intelligent systems.\nHaving access to an underlying causal graph comes with the promise of\ncause-effect estimation and the identification of efficient and safe\ninterventions. However, learning causal representations remains a major\nchallenge, due to the complexity of many real-world systems. Previous works on\ncausal representation learning have mostly focused on Variational Auto-Encoders\n(VAE). These methods only provide representations from a point estimate, and\nthey are unsuitable to handle high dimensions. To overcome these problems, we\nproposed a new Diffusion-based Causal Representation Learning (DCRL) algorithm.\nThis algorithm uses diffusion-based representations for causal discovery. DCRL\noffers access to infinite dimensional latent codes, which encode different\nlevels of information in the latent code. In a first proof of principle, we\ninvestigate the use of DCRL for causal representation learning. We further\ndemonstrate experimentally that this approach performs comparably well in\nidentifying the causal structure and causal variables.",
            "author": [
                "Amir Mohammad Karimi Mamaghan",
                "Andrea Dittadi",
                "Stefan Bauer",
                "Karl Henrik Johansson",
                "Francesco Quinzan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05421v1",
                "http://arxiv.org/pdf/2311.05421v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05420v1",
            "title": "Counterfactually Fair Representation",
            "updated": "2023-11-09T14:58:53Z",
            "published": "2023-11-09T14:58:53Z",
            "summary": "The use of machine learning models in high-stake applications (e.g.,\nhealthcare, lending, college admission) has raised growing concerns due to\npotential biases against protected social groups. Various fairness notions and\nmethods have been proposed to mitigate such biases. In this work, we focus on\nCounterfactual Fairness (CF), a fairness notion that is dependent on an\nunderlying causal graph and first proposed by Kusner \\textit{et\nal.}~\\cite{kusner2017counterfactual}; it requires that the outcome an\nindividual perceives is the same in the real world as it would be in a\n\"counterfactual\" world, in which the individual belongs to another social\ngroup. Learning fair models satisfying CF can be challenging. It was shown in\n\\cite{kusner2017counterfactual} that a sufficient condition for satisfying CF\nis to \\textbf{not} use features that are descendants of sensitive attributes in\nthe causal graph. This implies a simple method that learns CF models only using\nnon-descendants of sensitive attributes while eliminating all descendants.\nAlthough several subsequent works proposed methods that use all features for\ntraining CF models, there is no theoretical guarantee that they can satisfy CF.\nIn contrast, this work proposes a new algorithm that trains models using all\nthe available features. We theoretically and empirically show that models\ntrained with this method can satisfy CF\\footnote{The code repository for this\nwork can be found in\n\\url{https://github.com/osu-srml/CF_Representation_Learning}}.",
            "author": [
                "Zhiqun Zuo",
                "Mohammad Mahdi Khalili",
                "Xueru Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05420v1",
                "http://arxiv.org/pdf/2311.05420v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05418v1",
            "title": "Generalization in medical AI: a perspective on developing scalable\n  models",
            "updated": "2023-11-09T14:54:28Z",
            "published": "2023-11-09T14:54:28Z",
            "summary": "Over the past few years, research has witnessed the advancement of deep\nlearning models trained on large datasets, some even encompassing millions of\nexamples. While these impressive performance on their hidden test sets, they\noften underperform when assessed on external datasets. Recognizing the critical\nrole of generalization in medical AI development, many prestigious journals now\nrequire reporting results both on the local hidden test set as well as on\nexternal datasets before considering a study for publication. Effectively, the\nfield of medical AI has transitioned from the traditional usage of a single\ndataset that is split into train and test to a more comprehensive framework\nusing multiple datasets, some of which are used for model development (source\ndomain) and others for testing (target domains). However, this new experimental\nsetting does not necessarily resolve the challenge of generalization. This is\nbecause of the variability encountered in intended use and specificities across\nhospital cultures making the idea of universally generalizable systems a myth.\nOn the other hand, the systematic, and a fortiori recurrent re-calibration, of\nmodels at the individual hospital level, although ideal, may be overoptimistic\ngiven the legal, regulatory and technical challenges that are involved.\nRe-calibration using transfer learning may not even be possible in some\ninstances where reference labels of target domains are not available. In this\nperspective we establish a hierarchical three-level scale system reflecting the\ngeneralization level of a medical AI algorithm. This scale better reflects the\ndiversity of real-world medical scenarios per which target domain data for\nre-calibration of models may or not be available and if it is, may or not have\nreference labels systematically available.",
            "author": [
                "Joachim A. Behar",
                "Jeremy Levy",
                "Leo Anthony Celi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05418v1",
                "http://arxiv.org/pdf/2311.05418v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05417v2",
            "title": "Predicting the Position Uncertainty at the Time of Closest Approach with\n  Diffusion Models",
            "updated": "2023-11-15T22:13:11Z",
            "published": "2023-11-09T14:54:08Z",
            "summary": "The risk of collision between resident space objects has significantly\nincreased in recent years. As a result, spacecraft collision avoidance\nprocedures have become an essential part of satellite operations. To ensure\nsafe and effective space activities, satellite owners and operators rely on\nconstantly updated estimates of encounters. These estimates include the\nuncertainty associated with the position of each object at the expected TCA.\nThese estimates are crucial in planning risk mitigation measures, such as\ncollision avoidance manoeuvres. As the TCA approaches, the accuracy of these\nestimates improves, as both objects' orbit determination and propagation\nprocedures are made for increasingly shorter time intervals. However, this\nimprovement comes at the cost of taking place close to the critical decision\nmoment. This means that safe avoidance manoeuvres might not be possible or\ncould incur significant costs. Therefore, knowing the evolution of this\nvariable in advance can be crucial for operators. This work proposes a machine\nlearning model based on diffusion models to forecast the position uncertainty\nof objects involved in a close encounter, particularly for the secondary object\n(usually debris), which tends to be more unpredictable. We compare the\nperformance of our model with other state-of-the-art solutions and a na\\\"ive\nbaseline approach, showing that the proposed solution has the potential to\nsignificantly improve the safety and effectiveness of spacecraft operations.",
            "author": [
                "Marta Guimar\u00e3es",
                "Cl\u00e1udia Soares",
                "Chiara Manfletti"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05417v2",
                "http://arxiv.org/pdf/2311.05417v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05412v2",
            "title": "The Use of Quantitative Metrics and Machine Learning to Predict\n  Radiologist Interpretations of MRI Image Quality and Artifacts",
            "updated": "2023-11-21T00:30:22Z",
            "published": "2023-11-09T14:50:17Z",
            "summary": "A dataset of 3D-GRE and 3D-TSE brain 3T post contrast T1-weighted images as\npart of a quality improvement project were collected and shown to five\nneuro-radiologists who evaluated each sequence for both image quality and\nimaging artifacts. The same scans were processed using the MRQy tool for\nobjective, quantitative image quality metrics. Using the combined radiologist\nand quantitative metrics dataset, a decision tree classifier with a bagging\nensemble approach was trained to predict radiologist assessment using the\nquantitative metrics. A machine learning model was developed for the following\nthree tasks: (1) determine the best model / performance for each MRI sequence\nand evaluation metric, (2) determine the best model / performance across all\nMRI sequences for each evaluation metric, and (3) determine the best general\nmodel / performance across all MRI sequences and evaluations. Model performance\nfor imaging artifact was slightly higher than image quality, for example, the\nfinal generalized model AUROC for image quality was 0.77 (0.41 - 0.84, 95% CI)\nwhile imaging artifact was 0.78 (0.60 - 0.93, 95% CI). Further, it was noted\nthat the generalized model performed slightly better than the individual models\n(AUROC 0.69 for 3D-GRE image quality, for example), indicating the value in\ncomprehensive training data for these applications. These models could be\ndeployed in the clinic as automatic checks for real-time image acquisition to\nprevent patient re-scanning requiring another appointment after retrospective\nradiologist analysis or improve reader confidence in the study. Further work\nneeds to be done to validate the model described here on an external dataset.\nThe results presented here suggest that MRQy could be used as a foundation for\nquantitative metrics as a surrogate for radiologist assessment.",
            "author": [
                "Lucas McCullum",
                "John Wood",
                "Maria Gule-Monroe",
                "Ho-Ling Anthony Liu",
                "Melissa Chen",
                "Komal Shah",
                "Noah Nathan Chasen",
                "Vinodh Kumar",
                "Ping Hou",
                "Jason Stafford",
                "Caroline Chung",
                "Moiz Ahmad",
                "Christopher Walker",
                "Joshua Yung"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05412v2",
                "http://arxiv.org/pdf/2311.05412v2"
            ],
            "primary_category": "physics.med-ph",
            "category": [
                "physics.med-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05407v1",
            "title": "Data Distillation for Neural Network Potentials toward Foundational\n  Dataset",
            "updated": "2023-11-09T14:41:45Z",
            "published": "2023-11-09T14:41:45Z",
            "summary": "Machine learning (ML) techniques and atomistic modeling have rapidly\ntransformed materials design and discovery. Specifically, generative models can\nswiftly propose promising materials for targeted applications. However, the\npredicted properties of materials through the generative models often do not\nmatch with calculated properties through ab initio calculations. This\ndiscrepancy can arise because the generated coordinates are not fully relaxed,\nwhereas the many properties are derived from relaxed structures. Neural\nnetwork-based potentials (NNPs) can expedite the process by providing relaxed\nstructures from the initially generated ones. Nevertheless, acquiring data to\ntrain NNPs for this purpose can be extremely challenging as it needs to\nencompass previously unknown structures. This study utilized extended ensemble\nmolecular dynamics (MD) to secure a broad range of liquid- and solid-phase\nconfigurations in one of the metallic systems, nickel. Then, we could\nsignificantly reduce them through active learning without losing much accuracy.\nWe found that the NNP trained from the distilled data could predict different\nenergy-minimized closed-pack crystal structures even though those structures\nwere not explicitly part of the initial data. Furthermore, the data can be\ntranslated to other metallic systems (aluminum and niobium), without repeating\nthe sampling and distillation processes. Our approach to data acquisition and\ndistillation has demonstrated the potential to expedite NNP development and\nenhance materials design and discovery by integrating generative models.",
            "author": [
                "Gang Seob Jung",
                "Sangkeun Lee",
                "Jong Youl Choi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05407v1",
                "http://arxiv.org/pdf/2311.05407v1"
            ],
            "primary_category": "physics.comp-ph",
            "category": [
                "physics.comp-ph",
                "cs.LG",
                "physics.chem-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05400v1",
            "title": "SIRE: scale-invariant, rotation-equivariant estimation of artery\n  orientations using graph neural networks",
            "updated": "2023-11-09T14:32:57Z",
            "published": "2023-11-09T14:32:57Z",
            "summary": "Blood vessel orientation as visualized in 3D medical images is an important\ndescriptor of its geometry that can be used for centerline extraction and\nsubsequent segmentation and visualization. Arteries appear at many scales and\nlevels of tortuosity, and determining their exact orientation is challenging.\nRecent works have used 3D convolutional neural networks (CNNs) for this\npurpose, but CNNs are sensitive to varying vessel sizes and orientations. We\npresent SIRE: a scale-invariant, rotation-equivariant estimator for local\nvessel orientation. SIRE is modular and can generalise due to symmetry\npreservation.\n  SIRE consists of a gauge equivariant mesh CNN (GEM-CNN) operating on multiple\nnested spherical meshes with different sizes in parallel. The features on each\nmesh are a projection of image intensities within the corresponding sphere.\nThese features are intrinsic to the sphere and, in combination with the\nGEM-CNN, lead to SO(3)-equivariance. Approximate scale invariance is achieved\nby weight sharing and use of a symmetric maximum function to combine\nmulti-scale predictions. Hence, SIRE can be trained with arbitrarily oriented\nvessels with varying radii to generalise to vessels with a wide range of\ncalibres and tortuosity.\n  We demonstrate the efficacy of SIRE using three datasets containing vessels\nof varying scales: the vascular model repository (VMR), the ASOCA coronary\nartery set, and a set of abdominal aortic aneurysms (AAAs). We embed SIRE in a\ncenterline tracker which accurately tracks AAAs, regardless of the data SIRE is\ntrained with. Moreover, SIRE can be used to track coronary arteries, even when\ntrained only with AAAs.\n  In conclusion, by incorporating SO(3) and scale symmetries, SIRE can\ndetermine the orientations of vessels outside of the training domain, forming a\nrobust and data-efficient solution to geometric analysis of blood vessels in 3D\nmedical images.",
            "author": [
                "Dieuwertje Alblas",
                "Julian Suk",
                "Christoph Brune",
                "Kak Khee Yeung",
                "Jelmer M. Wolterink"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05400v1",
                "http://arxiv.org/pdf/2311.05400v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05398v1",
            "title": "The Sample Complexity Of ERMs In Stochastic Convex Optimization",
            "updated": "2023-11-09T14:29:25Z",
            "published": "2023-11-09T14:29:25Z",
            "summary": "Stochastic convex optimization is one of the most well-studied models for\nlearning in modern machine learning. Nevertheless, a central fundamental\nquestion in this setup remained unresolved: \"How many data points must be\nobserved so that any empirical risk minimizer (ERM) shows good performance on\nthe true population?\" This question was proposed by Feldman (2016), who proved\nthat $\\Omega(\\frac{d}{\\epsilon}+\\frac{1}{\\epsilon^2})$ data points are\nnecessary (where $d$ is the dimension and $\\epsilon>0$ is the accuracy\nparameter). Proving an $\\omega(\\frac{d}{\\epsilon}+\\frac{1}{\\epsilon^2})$ lower\nbound was left as an open problem. In this work we show that in fact\n$\\tilde{O}(\\frac{d}{\\epsilon}+\\frac{1}{\\epsilon^2})$ data points are also\nsufficient. This settles the question and yields a new separation between ERMs\nand uniform convergence. This sample complexity holds for the classical setup\nof learning bounded convex Lipschitz functions over the Euclidean unit ball. We\nfurther generalize the result and show that a similar upper bound holds for all\nsymmetric convex bodies. The general bound is composed of two terms: (i) a term\nof the form $\\tilde{O}(\\frac{d}{\\epsilon})$ with an inverse-linear dependence\non the accuracy parameter, and (ii) a term that depends on the statistical\ncomplexity of the class of $\\textit{linear}$ functions (captured by the\nRademacher complexity). The proof builds a mechanism for controlling the\nbehavior of stochastic convex optimization problems.",
            "author": [
                "Daniel Carmon",
                "Roi Livni",
                "Amir Yehudayoff"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05398v1",
                "http://arxiv.org/pdf/2311.05398v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05667v1",
            "title": "A theory for the sparsity emerged in the Forward Forward algorithm",
            "updated": "2023-11-09T14:08:41Z",
            "published": "2023-11-09T14:08:41Z",
            "summary": "This report explores the theory that explains the high sparsity phenomenon\n\\citep{tosato2023emergent} observed in the forward-forward algorithm\n\\citep{hinton2022forward}. The two theorems proposed predict the sparsity\nchanges of a single data point's activation in two cases: Theorem\n\\ref{theorem:1}: Decrease the goodness of the whole batch. Theorem\n\\ref{theorem:2}: Apply the complete forward forward algorithm to decrease the\ngoodness for negative data and increase the goodness for positive data. The\ntheory aligns well with the experiments tested on the MNIST dataset.",
            "author": [
                "Yukun Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05667v1",
                "http://arxiv.org/pdf/2311.05667v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05379v1",
            "title": "Memorisation Cartography: Mapping out the Memorisation-Generalisation\n  Continuum in Neural Machine Translation",
            "updated": "2023-11-09T14:03:51Z",
            "published": "2023-11-09T14:03:51Z",
            "summary": "When training a neural network, it will quickly memorise some source-target\nmappings from your dataset but never learn some others. Yet, memorisation is\nnot easily expressed as a binary feature that is good or bad: individual\ndatapoints lie on a memorisation-generalisation continuum. What determines a\ndatapoint's position on that spectrum, and how does that spectrum influence\nneural models' performance? We address these two questions for neural machine\ntranslation (NMT) models. We use the counterfactual memorisation metric to (1)\nbuild a resource that places 5M NMT datapoints on a memorisation-generalisation\nmap, (2) illustrate how the datapoints' surface-level characteristics and a\nmodels' per-datum training signals are predictive of memorisation in NMT, (3)\nand describe the influence that subsets of that map have on NMT systems'\nperformance.",
            "author": [
                "Verna Dankers",
                "Ivan Titov",
                "Dieuwke Hupkes"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05379v1",
                "http://arxiv.org/pdf/2311.05379v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05373v1",
            "title": "What is prompt literacy? An exploratory study of language learners'\n  development of new literacy skill using generative AI",
            "updated": "2023-11-09T13:58:34Z",
            "published": "2023-11-09T13:58:34Z",
            "summary": "In the current study,we propose that, in the era of generative AI, there is\nnow a new form of literacy called \"prompt literacy,\" which refers to the\nability to generate precise prompts as input for AI systems, interpret the\noutputs, and iteratively refine prompts to achieve desired results. To explore\nthe emergence and development of this literacy skill, the current study\nexamined 30 EFL students' engagement in an AI-powered image creation project,\nthrough which they created artworks representing the socio-cultural meanings of\nEnglish words by iteratively drafting and refining prompts in generative AI\ntools. By examining AI-generated images and the participants' drafting and\nrevision of their prompts, this study demonstrated the emergence of learners'\nprompt literacy skills. The survey data further showed the participants'\nperceived improvement in their vocabulary learning strategies as a result of\nengaging in the target AI-powered project. In addition, the participants'\npost-project reflection revealed three benefits of developing prompt literacy:\nenjoyment from manifesting imagined outcomes; recognition of its importance for\ncommunication, problem-solving and career development; and the enhanced\nunderstanding of the collaborative nature of human-AI interaction. These\nfindings suggest that prompt literacy is an increasingly crucial literacy for\nthe AI era.",
            "author": [
                "Yohan Hwang",
                "Jang Ho Lee",
                "Dongkwang Shin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05373v1",
                "http://arxiv.org/pdf/2311.05373v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05371v2",
            "title": "Training Robust Deep Physiological Measurement Models with Synthetic\n  Video-based Data",
            "updated": "2023-11-15T13:57:53Z",
            "published": "2023-11-09T13:55:45Z",
            "summary": "Recent advances in supervised deep learning techniques have demonstrated the\npossibility to remotely measure human physiological vital signs (e.g.,\nphotoplethysmograph, heart rate) just from facial videos. However, the\nperformance of these methods heavily relies on the availability and diversity\nof real labeled data. Yet, collecting large-scale real-world data with\nhigh-quality labels is typically challenging and resource intensive, which also\nraises privacy concerns when storing personal bio-metric data. Synthetic\nvideo-based datasets (e.g., SCAMPS \\cite{mcduff2022scamps}) with\nphoto-realistic synthesized avatars are introduced to alleviate the issues\nwhile providing high-quality synthetic data. However, there exists a\nsignificant gap between synthetic and real-world data, which hinders the\ngeneralization of neural models trained on these synthetic datasets. In this\npaper, we proposed several measures to add real-world noise to synthetic\nphysiological signals and corresponding facial videos. We experimented with\nindividual and combined augmentation methods and evaluated our framework on\nthree public real-world datasets. Our results show that we were able to reduce\nthe average MAE from 6.9 to 2.0.",
            "author": [
                "Yuxuan Ou",
                "Yuzhe Zhang",
                "Yuntang Wang",
                "Shwetak Patel",
                "Daniel McDuf",
                "Yuzhe Yang",
                "Xin Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05371v2",
                "http://arxiv.org/pdf/2311.05371v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05363v1",
            "title": "Beyond the training set: an intuitive method for detecting distribution\n  shift in model-based optimization",
            "updated": "2023-11-09T13:44:28Z",
            "published": "2023-11-09T13:44:28Z",
            "summary": "Model-based optimization (MBO) is increasingly applied to design problems in\nscience and engineering. A common scenario involves using a fixed training set\nto train models, with the goal of designing new samples that outperform those\npresent in the training data. A major challenge in this setting is distribution\nshift, where the distributions of training and design samples are different.\nWhile some shift is expected, as the goal is to create better designs, this\nchange can negatively affect model accuracy and subsequently, design quality.\nDespite the widespread nature of this problem, addressing it demands deep\ndomain knowledge and artful application. To tackle this issue, we propose a\nstraightforward method for design practitioners that detects distribution\nshifts. This method trains a binary classifier using knowledge of the unlabeled\ndesign distribution to separate the training data from the design data. The\nclassifier's logit scores are then used as a proxy measure of distribution\nshift. We validate our method in a real-world application by running offline\nMBO and evaluate the effect of distribution shift on design quality. We find\nthat the intensity of the shift in the design distribution varies based on the\nnumber of steps taken by the optimization algorithm, and our simple approach\ncan identify these shifts. This enables users to constrain their search to\nregions where the model's predictions are reliable, thereby increasing the\nquality of designs.",
            "author": [
                "Farhan Damani",
                "David H Brookes",
                "Theodore Sternlieb",
                "Cameron Webster",
                "Stephen Malina",
                "Rishi Jajoo",
                "Kathy Lin",
                "Sam Sinai"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05363v1",
                "http://arxiv.org/pdf/2311.05363v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05360v1",
            "title": "Basis functions nonlinear data-enabled predictive control: Consistent\n  and computationally efficient formulations",
            "updated": "2023-11-09T13:39:41Z",
            "published": "2023-11-09T13:39:41Z",
            "summary": "This paper considers the extension of data-enabled predictive control (DeePC)\nto nonlinear systems via general basis functions. Firstly, we formulate a basis\nfunctions DeePC behavioral predictor and we identify necessary and sufficient\nconditions for equivalence with a corresponding basis functions multi-step\nidentified predictor. The derived conditions yield a dynamic regularization\ncost function that enables a well-posed (i.e., consistent) basis functions\nformulation of nonlinear DeePC. To optimize computational efficiency of basis\nfunctions DeePC we further develop two alternative formulations that use a\nsimpler, sparse regularization cost function and ridge regression,\nrespectively. Consistency implications for Koopman DeePC as well as several\nmethods for constructing the basis functions representation are also indicated.\nThe effectiveness of the developed consistent basis functions DeePC\nformulations is illustrated on a benchmark nonlinear pendulum state-space\nmodel, for both noise free and noisy data.",
            "author": [
                "Mircea Lazar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05360v1",
                "http://arxiv.org/pdf/2311.05360v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.LG",
                "cs.SY",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05346v1",
            "title": "Accelerated Shapley Value Approximation for Data Evaluation",
            "updated": "2023-11-09T13:15:36Z",
            "published": "2023-11-09T13:15:36Z",
            "summary": "Data valuation has found various applications in machine learning, such as\ndata filtering, efficient learning and incentives for data sharing. The most\npopular current approach to data valuation is the Shapley value. While popular\nfor its various applications, Shapley value is computationally expensive even\nto approximate, as it requires repeated iterations of training models on\ndifferent subsets of data. In this paper we show that the Shapley value of data\npoints can be approximated more efficiently by leveraging the structural\nproperties of machine learning problems. We derive convergence guarantees on\nthe accuracy of the approximate Shapley value for different learning settings\nincluding Stochastic Gradient Descent with convex and non-convex loss\nfunctions. Our analysis suggests that in fact models trained on small subsets\nare more important in the context of data valuation. Based on this idea, we\ndescribe $\\delta$-Shapley -- a strategy of only using small subsets for the\napproximation. Experiments show that this approach preserves approximate value\nand rank of data, while achieving speedup of up to 9.9x. In pre-trained\nnetworks the approach is found to bring more efficiency in terms of accurate\nevaluation using small subsets.",
            "author": [
                "Lauren Watson",
                "Zeno Kujawa",
                "Rayna Andreeva",
                "Hao-Tsung Yang",
                "Tariq Elahi",
                "Rik Sarkar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05346v1",
                "http://arxiv.org/pdf/2311.05346v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05344v1",
            "title": "Visually Guided Model Predictive Robot Control via 6D Object Pose\n  Localization and Tracking",
            "updated": "2023-11-09T13:13:42Z",
            "published": "2023-11-09T13:13:42Z",
            "summary": "The objective of this work is to enable manipulation tasks with respect to\nthe 6D pose of a dynamically moving object using a camera mounted on a robot.\nExamples include maintaining a constant relative 6D pose of the robot arm with\nrespect to the object, grasping the dynamically moving object, or\nco-manipulating the object together with a human. Fast and accurate 6D pose\nestimation is crucial to achieve smooth and stable robot control in such\nsituations. The contributions of this work are three fold. First, we propose a\nnew visual perception module that asynchronously combines accurate\nlearning-based 6D object pose localizer and a high-rate model-based 6D pose\ntracker. The outcome is a low-latency accurate and temporally consistent 6D\nobject pose estimation from the input video stream at up to 120 Hz. Second, we\ndevelop a visually guided robot arm controller that combines the new visual\nperception module with a torque-based model predictive control algorithm.\nAsynchronous combination of the visual and robot proprioception signals at\ntheir corresponding frequencies results in stable and robust 6D object pose\nguided robot arm control. Third, we experimentally validate the proposed\napproach on a challenging 6D pose estimation benchmark and demonstrate 6D\nobject pose-guided control with dynamically moving objects on a real 7 DoF\nFranka Emika Panda robot.",
            "author": [
                "Mederic Fourmy",
                "Vojtech Priban",
                "Jan Kristof Behrens",
                "Nicolas Mansard",
                "Josef Sivic",
                "Vladimir Petrik"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05344v1",
                "http://arxiv.org/pdf/2311.05344v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05334v1",
            "title": "Real-time Addressee Estimation: Deployment of a Deep-Learning Model on\n  the iCub Robot",
            "updated": "2023-11-09T13:01:21Z",
            "published": "2023-11-09T13:01:21Z",
            "summary": "Addressee Estimation is the ability to understand to whom a person is\ntalking, a skill essential for social robots to interact smoothly with humans.\nIn this sense, it is one of the problems that must be tackled to develop\neffective conversational agents in multi-party and unstructured scenarios. As\nhumans, one of the channels that mainly lead us to such estimation is the\nnon-verbal behavior of speakers: first of all, their gaze and body pose.\nInspired by human perceptual skills, in the present work, a deep-learning model\nfor Addressee Estimation relying on these two non-verbal features is designed,\ntrained, and deployed on an iCub robot. The study presents the procedure of\nsuch implementation and the performance of the model deployed in real-time\nhuman-robot interaction compared to previous tests on the dataset used for the\ntraining.",
            "author": [
                "Carlo Mazzola",
                "Francesco Rea",
                "Alessandra Sciutti"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05334v1",
                "http://arxiv.org/pdf/2311.05334v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.LG",
                "I.2.9; I.2.10; H.1.2"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05323v1",
            "title": "Spatial Attention-based Distribution Integration Network for Human Pose\n  Estimation",
            "updated": "2023-11-09T12:43:01Z",
            "published": "2023-11-09T12:43:01Z",
            "summary": "In recent years, human pose estimation has made significant progress through\nthe implementation of deep learning techniques. However, these techniques still\nface limitations when confronted with challenging scenarios, including\nocclusion, diverse appearances, variations in illumination, and overlap. To\ncope with such drawbacks, we present the Spatial Attention-based Distribution\nIntegration Network (SADI-NET) to improve the accuracy of localization in such\nsituations. Our network consists of three efficient models: the receptive\nfortified module (RFM), spatial fusion module (SFM), and distribution learning\nmodule (DLM). Building upon the classic HourglassNet architecture, we replace\nthe basic block with our proposed RFM. The RFM incorporates a dilated residual\nblock and attention mechanism to expand receptive fields while enhancing\nsensitivity to spatial information. In addition, the SFM incorporates\nmulti-scale characteristics by employing both global and local attention\nmechanisms. Furthermore, the DLM, inspired by residual log-likelihood\nestimation (RLE), reconfigures a predicted heatmap using a trainable\ndistribution weight. For the purpose of determining the efficacy of our model,\nwe conducted extensive experiments on the MPII and LSP benchmarks.\nParticularly, our model obtained a remarkable $92.10\\%$ percent accuracy on the\nMPII test dataset, demonstrating significant improvements over existing models\nand establishing state-of-the-art performance.",
            "author": [
                "Sihan Gao",
                "Jing Zhu",
                "Xiaoxuan Zhuang",
                "Zhaoyue Wang",
                "Qijin Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05323v1",
                "http://arxiv.org/pdf/2311.05323v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05320v1",
            "title": "Dual-phase xenon time projection chambers for rare-event searches",
            "updated": "2023-11-09T12:40:48Z",
            "published": "2023-11-09T12:40:48Z",
            "summary": "In the past decade, dual-phase xenon time projection chambers (Xe-TPCs) have\nemerged as some of the most powerful detectors in the fields of astroparticle\nphysics and rare-event searches. Developed primarily towards the direct\ndetection of dark matter particles, experiments presently operating deep\nunderground have reached target masses at the multi-tonne scale, energy\nthresholds around 1\\,keV and radioactivity-induced background rates similar to\nthose from solar neutrinos. These unique properties, together with demonstrated\nstable operation over several years, allow for the exploration of new territory\nvia high-sensitivity searches for a plethora of ultra-rare interactions. These\ninclude searches for particle dark matter, for second order weak decays, and\nthe observation of astrophysical neutrinos. We first review some properties of\nxenon as a radiation detection medium and the operation principles of\ndual-phase Xe-TPCs together with their energy calibration and resolution. We\nthen discuss the status of currently running experiments and of proposed\nnext-generation projects, describing some of the technological challenges. We\nend by looking at their sensitivity to dark matter candidates, to second order\nweak decays and to solar and supernova neutrinos. Experiments based on\ndual-phase Xe-TPCs are difficult, and, like all good experiments, they are\nconstantly pushed to their limits. Together with many other endeavours in\nastroparticle physics and cosmology they will continue to push at the borders\nof the unknown, hopefully to reveal profound new knowledge about our cosmos.",
            "author": [
                "Laura Baudis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05320v1",
                "http://arxiv.org/pdf/2311.05320v1"
            ],
            "primary_category": "physics.ins-det",
            "category": [
                "physics.ins-det",
                "astro-ph.IM",
                "hep-ex",
                "nucl-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05317v1",
            "title": "RepQ: Generalizing Quantization-Aware Training for Re-Parametrized\n  Architectures",
            "updated": "2023-11-09T12:25:39Z",
            "published": "2023-11-09T12:25:39Z",
            "summary": "Existing neural networks are memory-consuming and computationally intensive,\nmaking deploying them challenging in resource-constrained environments.\nHowever, there are various methods to improve their efficiency. Two such\nmethods are quantization, a well-known approach for network compression, and\nre-parametrization, an emerging technique designed to improve model\nperformance. Although both techniques have been studied individually, there has\nbeen limited research on their simultaneous application. To address this gap,\nwe propose a novel approach called RepQ, which applies quantization to\nre-parametrized networks. Our method is based on the insight that the test\nstage weights of an arbitrary re-parametrized layer can be presented as a\ndifferentiable function of trainable parameters. We enable quantization-aware\ntraining by applying quantization on top of this function. RepQ generalizes\nwell to various re-parametrized models and outperforms the baseline method LSQ\nquantization scheme in all experiments.",
            "author": [
                "Anastasiia Prutianova",
                "Alexey Zaytsev",
                "Chung-Kuei Lee",
                "Fengyu Sun",
                "Ivan Koryakovskiy"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05317v1",
                "http://arxiv.org/pdf/2311.05317v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05316v1",
            "title": "ABIGX: A Unified Framework for eXplainable Fault Detection and\n  Classification",
            "updated": "2023-11-09T12:22:44Z",
            "published": "2023-11-09T12:22:44Z",
            "summary": "For explainable fault detection and classification (FDC), this paper proposes\na unified framework, ABIGX (Adversarial fault reconstruction-Based Integrated\nGradient eXplanation). ABIGX is derived from the essentials of previous\nsuccessful fault diagnosis methods, contribution plots (CP) and\nreconstruction-based contribution (RBC). It is the first explanation framework\nthat provides variable contributions for the general FDC models. The core part\nof ABIGX is the adversarial fault reconstruction (AFR) method, which rethinks\nthe FR from the perspective of adversarial attack and generalizes to fault\nclassification models with a new fault index. For fault classification, we put\nforward a new problem of fault class smearing, which intrinsically hinders the\ncorrect explanation. We prove that ABIGX effectively mitigates this problem and\noutperforms the existing gradient-based explanation methods. For fault\ndetection, we theoretically bridge ABIGX with conventional fault diagnosis\nmethods by proving that CP and RBC are the linear specifications of ABIGX. The\nexperiments evaluate the explanations of FDC by quantitative metrics and\nintuitive illustrations, the results of which show the general superiority of\nABIGX to other advanced explanation methods.",
            "author": [
                "Yue Zhuo",
                "Jinchuan Qian",
                "Zhihuan Song",
                "Zhiqiang Ge"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05316v1",
                "http://arxiv.org/pdf/2311.05316v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05310v1",
            "title": "SPADES: A Realistic Spacecraft Pose Estimation Dataset using Event\n  Sensing",
            "updated": "2023-11-09T12:14:47Z",
            "published": "2023-11-09T12:14:47Z",
            "summary": "In recent years, there has been a growing demand for improved autonomy for\nin-orbit operations such as rendezvous, docking, and proximity maneuvers,\nleading to increased interest in employing Deep Learning-based Spacecraft Pose\nEstimation techniques. However, due to limited access to real target datasets,\nalgorithms are often trained using synthetic data and applied in the real\ndomain, resulting in a performance drop due to the domain gap. State-of-the-art\napproaches employ Domain Adaptation techniques to mitigate this issue. In the\nsearch for viable solutions, event sensing has been explored in the past and\nshown to reduce the domain gap between simulations and real-world scenarios.\nEvent sensors have made significant advancements in hardware and software in\nrecent years. Moreover, the characteristics of the event sensor offer several\nadvantages in space applications compared to RGB sensors. To facilitate further\ntraining and evaluation of DL-based models, we introduce a novel dataset,\nSPADES, comprising real event data acquired in a controlled laboratory\nenvironment and simulated event data using the same camera intrinsics.\nFurthermore, we propose an effective data filtering method to improve the\nquality of training data, thus enhancing model performance. Additionally, we\nintroduce an image-based event representation that outperforms existing\nrepresentations. A multifaceted baseline evaluation was conducted using\ndifferent event representations, event filtering strategies, and algorithmic\nframeworks, and the results are summarized. The dataset will be made available\nat http://cvi2.uni.lu/spades.",
            "author": [
                "Arunkumar Rathinam",
                "Haytam Qadadri",
                "Djamila Aouada"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05310v1",
                "http://arxiv.org/pdf/2311.05310v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05304v2",
            "title": "Data Valuation and Detections in Federated Learning",
            "updated": "2023-11-13T13:27:39Z",
            "published": "2023-11-09T12:01:32Z",
            "summary": "Federated Learning (FL) enables collaborative model training while preserving\nthe privacy of raw data. A challenge in this framework is the fair and\nefficient valuation of data, which is crucial for incentivizing clients to\ncontribute high-quality data in the FL task. In scenarios involving numerous\ndata clients within FL, it is often the case that only a subset of clients and\ndatasets are pertinent to a specific learning task, while others might have\neither a negative or negligible impact on the model training process. This\npaper introduces a novel privacy-preserving method for evaluating client\ncontributions and selecting relevant datasets without a pre-specified training\nalgorithm in an FL task. Our proposed approach FedBary, utilizes Wasserstein\ndistance within the federated context, offering a new solution for data\nvaluation in the FL framework. This method ensures transparent data valuation\nand efficient computation of the Wasserstein barycenter and reduces the\ndependence on validation datasets. Through extensive empirical experiments and\ntheoretical analyses, we demonstrate the potential of this data valuation\nmethod as a promising avenue for FL research.",
            "author": [
                "Wenqian Li",
                "Shuran Fu",
                "Fengrui Zhang",
                "Yan Pang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05304v2",
                "http://arxiv.org/pdf/2311.05304v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05303v1",
            "title": "Reliable and Efficient Data Collection in UAV-based IoT Networks",
            "updated": "2023-11-09T11:59:47Z",
            "published": "2023-11-09T11:59:47Z",
            "summary": "Internet of Things (IoT) involves sensors for monitoring and wireless\nnetworks for efficient communication. However, resource-constrained IoT devices\nand limitations in existing wireless technologies hinder its full potential.\nIntegrating Unmanned Aerial Vehicles (UAVs) into IoT networks can address some\nchallenges by expanding its' coverage, providing security, and bringing\ncomputing closer to IoT devices. Nevertheless, effective data collection in\nUAV-assisted IoT networks is hampered by factors, including dynamic UAV\nbehavior, environmental variables, connectivity instability, and security\nconsiderations. In this survey, we first explore UAV-based IoT networks,\nfocusing on communication and networking aspects. Next, we cover various\nUAV-based data collection methods their advantages and disadvantages, followed\nby a discussion on performance metrics for data collection. As this article\nprimarily emphasizes reliable and efficient data collection in UAV-assisted IoT\nnetworks, we briefly discuss existing research on data accuracy and\nconsistency, network connectivity, and data security and privacy to provide\ninsights into reliable data collection. Additionally, we discuss efficient data\ncollection strategies in UAV-based IoT networks, covering trajectory and path\nplanning, collision avoidance, sensor network clustering, data aggregation, UAV\nswarm formations, and artificial intelligence for optimization. We also present\ntwo use cases of UAVs as a service for enhancing data collection reliability\nand efficiency. Finally, we discuss future challenges in data collection for\nUAV-assisted IoT networks.",
            "author": [
                "Poorvi Joshi",
                "Alakesh Kalita",
                "Mohan Gurusamy"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05303v1",
                "http://arxiv.org/pdf/2311.05303v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "cs.LG",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05298v1",
            "title": "Improving Vision-and-Language Reasoning via Spatial Relations Modeling",
            "updated": "2023-11-09T11:54:55Z",
            "published": "2023-11-09T11:54:55Z",
            "summary": "Visual commonsense reasoning (VCR) is a challenging multi-modal task, which\nrequires high-level cognition and commonsense reasoning ability about the real\nworld. In recent years, large-scale pre-training approaches have been developed\nand promoted the state-of-the-art performance of VCR. However, the existing\napproaches almost employ the BERT-like objectives to learn multi-modal\nrepresentations. These objectives motivated from the text-domain are\ninsufficient for the excavation on the complex scenario of visual modality.\nMost importantly, the spatial distribution of the visual objects is basically\nneglected. To address the above issue, we propose to construct the spatial\nrelation graph based on the given visual scenario. Further, we design two\npre-training tasks named object position regression (OPR) and spatial relation\nclassification (SRC) to learn to reconstruct the spatial relation graph\nrespectively. Quantitative analysis suggests that the proposed method can guide\nthe representations to maintain more spatial context and facilitate the\nattention on the essential visual regions for reasoning. We achieve the\nstate-of-the-art results on VCR and two other vision-and-language reasoning\ntasks VQA, and NLVR.",
            "author": [
                "Cheng Yang",
                "Rui Xu",
                "Ye Guo",
                "Peixiang Huang",
                "Yiru Chen",
                "Wenkui Ding",
                "Zhongyuan Wang",
                "Hong Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05298v1",
                "http://arxiv.org/pdf/2311.05298v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05297v1",
            "title": "Do personality tests generalize to Large Language Models?",
            "updated": "2023-11-09T11:54:01Z",
            "published": "2023-11-09T11:54:01Z",
            "summary": "With large language models (LLMs) appearing to behave increasingly human-like\nin text-based interactions, it has become popular to attempt to evaluate\nvarious properties of these models using tests originally designed for humans.\nWhile re-using existing tests is a resource-efficient way to evaluate LLMs,\ncareful adjustments are usually required to ensure that test results are even\nvalid across human sub-populations. Thus, it is not clear to what extent\ndifferent tests' validity generalizes to LLMs. In this work, we provide\nevidence that LLMs' responses to personality tests systematically deviate from\ntypical human responses, implying that these results cannot be interpreted in\nthe same way as human test results. Concretely, reverse-coded items (e.g. \"I am\nintroverted\" vs \"I am extraverted\") are often both answered affirmatively by\nLLMs. In addition, variation across different prompts designed to \"steer\" LLMs\nto simulate particular personality types does not follow the clear separation\ninto five independent personality factors from human samples. In light of these\nresults, we believe it is important to pay more attention to tests' validity\nfor LLMs before drawing strong conclusions about potentially ill-defined\nconcepts like LLMs' \"personality\".",
            "author": [
                "Florian E. Dorner",
                "Tom S\u00fchr",
                "Samira Samadi",
                "Augustin Kelava"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05297v1",
                "http://arxiv.org/pdf/2311.05297v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05296v1",
            "title": "DeeLM: Dependency-enhanced Large Language Model for Sentence Embeddings",
            "updated": "2023-11-09T11:53:52Z",
            "published": "2023-11-09T11:53:52Z",
            "summary": "Recent studies have proposed using large language models (LLMs) for sentence\nembeddings. However, most existing LLMs are built with an autoregressive\narchitecture that primarily captures forward dependencies while neglecting\nbackward dependencies. Previous work has highlighted the importance of backward\ndependencies in improving sentence embeddings. To address this issue, in this\npaper, we first present quantitative evidence demonstrating the limited\nlearning of backward dependencies in LLMs. Then, we propose a novel approach\ncalled Dependency-Enhanced Large Language Model (DeeLM) to improve sentence\nembeddings. Specifically, we found a turning point in LLMs, where surpassing\nspecific LLM layers leads to a significant performance drop in the semantic\ntextual similarity (STS) task. STS is a crucial task for evaluating sentence\nembeddings. We then extract the layers after the turning point to make them\nbidirectional, allowing for the learning of backward dependencies. Extensive\nexperiments demonstrate that DeeLM outperforms baselines and achieves\nstate-of-the-art performance across various STS tasks.",
            "author": [
                "Xianming Li",
                "Jing Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05296v1",
                "http://arxiv.org/pdf/2311.05296v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.16162v1",
            "title": "Leveraging Artificial Intelligence Technology for Mapping Research to\n  Sustainable Development Goals: A Case Study",
            "updated": "2023-11-09T11:44:22Z",
            "published": "2023-11-09T11:44:22Z",
            "summary": "The number of publications related to the Sustainable Development Goals\n(SDGs) continues to grow. These publications cover a diverse spectrum of\nresearch, from humanities and social sciences to engineering and health. Given\nthe imperative of funding bodies to monitor outcomes and impacts, linking\npublications to relevant SDGs is critical but remains time-consuming and\ndifficult given the breadth and complexity of the SDGs. A publication may\nrelate to several goals (interconnection feature of goals), and therefore\nrequire multidisciplinary knowledge to tag accurately. Machine learning\napproaches are promising and have proven particularly valuable for tasks such\nas manual data labeling and text classification. In this study, we employed\nover 82,000 publications from an Australian university as a case study. We\nutilized a similarity measure to map these publications onto Sustainable\nDevelopment Goals (SDGs). Additionally, we leveraged the OpenAI GPT model to\nconduct the same task, facilitating a comparative analysis between the two\napproaches. Experimental results show that about 82.89% of the results obtained\nby the similarity measure overlap (at least one tag) with the outputs of the\nGPT model. The adopted model (similarity measure) can complement GPT model for\nSDG classification. Furthermore, deep learning methods, which include the\nsimilarity measure used here, are more accessible and trusted for dealing with\nsensitive data without the use of commercial AI services or the deployment of\nexpensive computing resources to operate large language models. Our study\ndemonstrates how a crafted combination of the two methods can achieve reliable\nresults for mapping research to the SDGs.",
            "author": [
                "Hui Yin",
                "Amir Aryani",
                "Gavin Lambert",
                "Marcus White",
                "Luis Salvador-Carulla",
                "Shazia Sadiq",
                "Elvira Sojli",
                "Jennifer Boddy",
                "Greg Murray",
                "Wing Wah Tham"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16162v1",
                "http://arxiv.org/pdf/2311.16162v1"
            ],
            "primary_category": "cs.DL",
            "category": [
                "cs.DL",
                "cs.AI",
                "cs.CL",
                "I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05665v1",
            "title": "Explainable artificial intelligence for Healthcare applications using\n  Random Forest Classifier with LIME and SHAP",
            "updated": "2023-11-09T11:43:10Z",
            "published": "2023-11-09T11:43:10Z",
            "summary": "With the advances in computationally efficient artificial Intelligence (AI)\ntechniques and their numerous applications in our everyday life, there is a\npressing need to understand the computational details hidden in black box AI\ntechniques such as most popular machine learning and deep learning techniques;\nthrough more detailed explanations. The origin of explainable AI (xAI) is\ncoined from these challenges and recently gained more attention by the\nresearchers by adding explainability comprehensively in traditional AI systems.\nThis leads to develop an appropriate framework for successful applications of\nxAI in real life scenarios with respect to innovations, risk mitigation,\nethical issues and logical values to the users. In this book chapter, an\nin-depth analysis of several xAI frameworks and methods including LIME (Local\nInterpretable Model-agnostic Explanations) and SHAP (SHapley Additive\nexPlanations) are provided. Random Forest Classifier as black box AI is used on\na publicly available Diabetes symptoms dataset with LIME and SHAP for better\ninterpretations. The results obtained are interesting in terms of transparency,\nvalid and trustworthiness in diabetes disease prediction.",
            "author": [
                "Mrutyunjaya Panda",
                "Soumya Ranjan Mahanta"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05665v1",
                "http://arxiv.org/pdf/2311.05665v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05283v1",
            "title": "Native point defects in HgCdTe infrared detector material: Identifying\n  nonradiative recombination centers from first principles",
            "updated": "2023-11-09T11:26:38Z",
            "published": "2023-11-09T11:26:38Z",
            "summary": "We investigate the native point defects in the long-wavelength infrared\n(LWIR) detector material Hg$_{0.25}$Cd$_{0.25}$Te using a dielectric-dependent\nhybrid density functional combined with spin-orbit coupling. Characterizing\nthese point defects is essential to as they are responsible for intrinsic\ndoping and nonradiative recombination centers in the detector material. The\ndielectric-dependent hybrid functional allows for an accurate description of\nthe band gap ($E_g$) for Hg$_{1-x}$Cd$_{x}$Te (MCT) over the entire\ncompositional range, a level of accuracy challenging with standard hybrid\nfunctionals. Our comprehensive examination of the native point defects confirms\nthat the two isoelectronic cation vacancies ($V_\\text{Hg}$ and $V_\\text{Cd}$)\nare the primary sources of $p$-type conductivity in the LWIR material given\ntheir low defect formation energies and the presence of a shallow acceptor\nlevel $(-/0)$ near the valence-band maximum (VBM). In addition to the shallow\nacceptor level, the cation vacancies exhibit a deep charge transition level\n$(2-/-)$ situated at $E_g/2$ above the VBM, which is characteristic of\nnonradiative recombination centers. While other point defects generally do not\nexhibit deep levels, our results indicate that two donor interstitials,\nspecifically the Te and the Hg interstitials, could potentially account for the\ndeep centers in the LWIR MCT.",
            "author": [
                "Wei Chen",
                "Gian-Marco Rignanese",
                "Jifeng Liu",
                "Geoffroy Hautier"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05283v1",
                "http://arxiv.org/pdf/2311.05283v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "physics.app-ph",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.09241v1",
            "title": "Chain of Images for Intuitively Reasoning",
            "updated": "2023-11-09T11:14:51Z",
            "published": "2023-11-09T11:14:51Z",
            "summary": "The human brain is naturally equipped to comprehend and interpret visual\ninformation rapidly. When confronted with complex problems or concepts, we use\nflowcharts, sketches, and diagrams to aid our thought process. Leveraging this\ninherent ability can significantly enhance logical reasoning. However, current\nLarge Language Models (LLMs) do not utilize such visual intuition to help their\nthinking. Even the most advanced version language models (e.g., GPT-4V and\nLLaVA) merely align images into textual space, which means their reasoning\nprocesses remain purely verbal. To mitigate such limitations, we present a\nChain of Images (CoI) approach, which can convert complex language reasoning\nproblems to simple pattern recognition by generating a series of images as\nintermediate representations. Furthermore, we have developed a CoI evaluation\ndataset encompassing 15 distinct domains where images can intuitively aid\nproblem-solving. Based on this dataset, we aim to construct a benchmark to\nassess the capability of future multimodal large-scale models to leverage\nimages for reasoning. In supporting our CoI reasoning, we introduce a symbolic\nmultimodal large language model (SyMLLM) that generates images strictly based\non language instructions and accepts both text and image as input. Experiments\non Geometry, Chess and Common Sense tasks sourced from the CoI evaluation\ndataset show that CoI improves performance significantly over the pure-language\nChain of Thoughts (CoT) baselines. The code is available at\nhttps://github.com/GraphPKU/CoI.",
            "author": [
                "Fanxu Meng",
                "Haotong Yang",
                "Yiding Wang",
                "Muhan Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09241v1",
                "http://arxiv.org/pdf/2311.09241v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05273v1",
            "title": "Few-Shot Recognition and Classification of Jamming Signal via CGAN-Based\n  Fusion CNN Algorithm",
            "updated": "2023-11-09T11:03:26Z",
            "published": "2023-11-09T11:03:26Z",
            "summary": "The precise classification of jamming signals holds paramount significance in\nthe effective implementation of anti-jamming strategies within communication\nsystems subject to intricate environmental variables. In light of this\nimperative, we propose an innovative fusion algorithm based on conditional\ngenerative adversarial network (CGAN) and convolutional neural network (CNN) to\nsolve the problem of difficulty in applying deep learning (DL) algorithms due\nto the instantaneous nature of jamming signals in practical communication\nsystems. Compared with previous methods, our algorithm achieved an 8%\nimprovement in accuracy even when working with a limited dataset. Unlike\nprevious research, we have simulated real-world satellite communication\nscenarios using a hardware platform and validated our algorithm using the\nresulting time-domain waveform data. The experimental results indicate that our\nalgorithm still performs extremely well, which demonstrates significant\npotential for practical application in real-world communication scenarios.",
            "author": [
                "Xuhui Ding",
                "Yue Zhang",
                "Gaoyang Li",
                "Neng Ye",
                "Yuting Guo",
                "Takuya Mabuchi",
                "Hitomi Anzai",
                "Kai Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05273v1",
                "http://arxiv.org/pdf/2311.05273v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05270v1",
            "title": "Evaluation of Data Processing and Machine Learning Techniques in\n  P300-based Authentication using Brain-Computer Interfaces",
            "updated": "2023-11-09T10:57:23Z",
            "published": "2023-11-09T10:57:23Z",
            "summary": "Brain-Computer Interfaces (BCIs) are used in various application scenarios\nallowing direct communication between the brain and computers. Specifically,\nelectroencephalography (EEG) is one of the most common techniques for obtaining\nevoked potentials resulting from external stimuli, as the P300 potential is\nelicited from known images. The combination of Machine Learning (ML) and P300\npotentials is promising for authenticating subjects since the brain waves\ngenerated by each person when facing a particular stimulus are unique. However,\nexisting authentication solutions do not extensively explore P300 potentials\nand fail when analyzing the most suitable processing and ML-based\nclassification techniques. Thus, this work proposes i) a framework for\nauthenticating BCI users using the P300 potential; ii) the validation of the\nframework on ten subjects creating an experimental scenario employing a\nnon-invasive EEG-based BCI; and iii) the evaluation of the framework\nperformance defining two experiments (binary and multiclass ML classification)\nand three testing configurations incrementally analyzing the performance of\ndifferent processing techniques and the differences between classifying with\nepochs or statistical values. This framework achieved a performance close to\n100\\% f1-score in both experiments for the best classifier, highlighting its\neffectiveness in accurately authenticating users and demonstrating the\nfeasibility of performing EEG-based authentication using P300 potentials.",
            "author": [
                "Eduardo L\u00f3pez Bernal",
                "Sergio L\u00f3pez Bernal",
                "Gregorio Mart\u00ednez P\u00e9rez",
                "Alberto Huertas Celdr\u00e1n"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05270v1",
                "http://arxiv.org/pdf/2311.05270v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05265v1",
            "title": "Don't Waste a Single Annotation: Improving Single-Label Classifiers\n  Through Soft Labels",
            "updated": "2023-11-09T10:47:39Z",
            "published": "2023-11-09T10:47:39Z",
            "summary": "In this paper, we address the limitations of the common data annotation and\ntraining methods for objective single-label classification tasks. Typically,\nwhen annotating such tasks annotators are only asked to provide a single label\nfor each sample and annotator disagreement is discarded when a final hard label\nis decided through majority voting. We challenge this traditional approach,\nacknowledging that determining the appropriate label can be difficult due to\nthe ambiguity and lack of context in the data samples. Rather than discarding\nthe information from such ambiguous annotations, our soft label method makes\nuse of them for training. Our findings indicate that additional annotator\ninformation, such as confidence, secondary label and disagreement, can be used\nto effectively generate soft labels. Training classifiers with these soft\nlabels then leads to improved performance and calibration on the hard label\ntest set.",
            "author": [
                "Ben Wu",
                "Yue Li",
                "Yida Mu",
                "Carolina Scarton",
                "Kalina Bontcheva",
                "Xingyi Song"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05265v1",
                "http://arxiv.org/pdf/2311.05265v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05261v1",
            "title": "RAGLog: Log Anomaly Detection using Retrieval Augmented Generation",
            "updated": "2023-11-09T10:40:04Z",
            "published": "2023-11-09T10:40:04Z",
            "summary": "The ability to detect log anomalies from system logs is a vital activity\nneeded to ensure cyber resiliency of systems. It is applied for fault\nidentification or facilitate cyber investigation and digital forensics.\nHowever, as logs belonging to different systems and components differ\nsignificantly, the challenge to perform such analysis is humanly challenging\nfrom the volume, variety and velocity of logs. This is further complicated by\nthe lack or unavailability of anomalous log entries to develop trained machine\nlearning or artificial intelligence models for such purposes. In this research\nwork, we explore the use of a Retrieval Augmented Large Language Model that\nleverages a vector database to detect anomalies from logs. We used a Question\nand Answer configuration pipeline. To the best of our knowledge, our experiment\nwhich we called RAGLog is a novel one and the experimental results show much\npromise.",
            "author": [
                "Jonathan Pan",
                "Swee Liang Wong",
                "Yidi Yuan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05261v1",
                "http://arxiv.org/pdf/2311.05261v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05256v1",
            "title": "Latent Task-Specific Graph Network Simulators",
            "updated": "2023-11-09T10:30:51Z",
            "published": "2023-11-09T10:30:51Z",
            "summary": "Simulating dynamic physical interactions is a critical challenge across\nmultiple scientific domains, with applications ranging from robotics to\nmaterial science. For mesh-based simulations, Graph Network Simulators (GNSs)\npose an efficient alternative to traditional physics-based simulators. Their\ninherent differentiability and speed make them particularly well-suited for\ninverse design problems. Yet, adapting to new tasks from limited available data\nis an important aspect for real-world applications that current methods\nstruggle with. We frame mesh-based simulation as a meta-learning problem and\nuse a recent Bayesian meta-learning method to improve GNSs adaptability to new\nscenarios by leveraging context data and handling uncertainties. Our approach,\nlatent task-specific graph network simulator, uses non-amortized task posterior\napproximations to sample latent descriptions of unknown system properties.\nAdditionally, we leverage movement primitives for efficient full trajectory\nprediction, effectively addressing the issue of accumulating errors encountered\nby previous auto-regressive methods. We validate the effectiveness of our\napproach through various experiments, performing on par with or better than\nestablished baseline methods. Movement primitives further allow us to\naccommodate various types of context data, as demonstrated through the\nutilization of point clouds during inference. By combining GNSs with\nmeta-learning, we bring them closer to real-world applicability, particularly\nin scenarios with smaller datasets.",
            "author": [
                "Philipp Dahlinger",
                "Niklas Freymuth",
                "Michael Volpp",
                "Tai Hoang",
                "Gerhard Neumann"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05256v1",
                "http://arxiv.org/pdf/2311.05256v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05248v1",
            "title": "A General Space of Belief Updates for Model Misspecification in Bayesian\n  Networks",
            "updated": "2023-11-09T10:09:58Z",
            "published": "2023-11-09T10:09:58Z",
            "summary": "In an ideal setting for Bayesian agents, a perfect description of the rules\nof the environment (i.e., the objective observation model) is available,\nallowing them to reason through the Bayesian posterior to update their beliefs\nin an optimal way. But such an ideal setting hardly ever exists in the natural\nworld, so agents have to make do with reasoning about how they should update\ntheir beliefs simultaneously. This introduces a number of related challenges\nfor a number of research areas: (1) For Bayesian statistics, this deviation of\nthe subjective model from the true data-generating mechanism is termed model\nmisspecification in the literature. (2) For neuroscience, it introduces the\nnecessity to model how the agents' belief updates (how they use evidence to\nupdate their belief) and how their belief changes over time. The current paper\naddresses these two challenges by (a) providing a general class of\nposteriors/belief updates called cut-posteriors of Bayesian networks that have\na much greater expressivity, and (b) parameterizing the space of possible\nposteriors to make meta-learning (i.e., choosing the belief update from this\nspace in a principled manner) possible. For (a), it is noteworthy that any\ncut-posterior has local computation only, making computation tractable for\nhuman or artificial agents. For (b), a Markov Chain Monte Carlo algorithm to\nperform such meta-learning will be sketched here, though it is only an\nillustration and but no means the only possible meta-learning procedure\npossible for the space of cut-posteriors. Operationally, this work gives a\ngeneral algorithm to take in an arbitrary Bayesian network and output all\npossible cut-posteriors in the space.",
            "author": [
                "Tianjin Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05248v1",
                "http://arxiv.org/pdf/2311.05248v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "math.ST",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05245v1",
            "title": "Uncertainty Wrapper in the medical domain: Establishing transparent\n  uncertainty quantification for opaque machine learning models in practice",
            "updated": "2023-11-09T09:58:02Z",
            "published": "2023-11-09T09:58:02Z",
            "summary": "When systems use data-based models that are based on machine learning (ML),\nerrors in their results cannot be ruled out. This is particularly critical if\nit remains unclear to the user how these models arrived at their decisions and\nif errors can have safety-relevant consequences, as is often the case in the\nmedical field. In such cases, the use of dependable methods to quantify the\nuncertainty remaining in a result allows the user to make an informed decision\nabout further usage and draw possible conclusions based on a given result. This\npaper demonstrates the applicability and practical utility of the Uncertainty\nWrapper using flow cytometry as an application from the medical field that can\nbenefit from the use of ML models in conjunction with dependable and\ntransparent uncertainty quantification.",
            "author": [
                "Lisa J\u00f6ckel",
                "Michael Kl\u00e4s",
                "Georg Popp",
                "Nadja Hilger",
                "Stephan Fricke"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05245v1",
                "http://arxiv.org/pdf/2311.05245v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05241v1",
            "title": "When Meta-Learning Meets Online and Continual Learning: A Survey",
            "updated": "2023-11-09T09:49:50Z",
            "published": "2023-11-09T09:49:50Z",
            "summary": "Over the past decade, deep neural networks have demonstrated significant\nsuccess using the training scheme that involves mini-batch stochastic gradient\ndescent on extensive datasets. Expanding upon this accomplishment, there has\nbeen a surge in research exploring the application of neural networks in other\nlearning scenarios. One notable framework that has garnered significant\nattention is meta-learning. Often described as \"learning to learn,\"\nmeta-learning is a data-driven approach to optimize the learning algorithm.\nOther branches of interest are continual learning and online learning, both of\nwhich involve incrementally updating a model with streaming data. While these\nframeworks were initially developed independently, recent works have started\ninvestigating their combinations, proposing novel problem settings and learning\nalgorithms. However, due to the elevated complexity and lack of unified\nterminology, discerning differences between the learning frameworks can be\nchallenging even for experienced researchers. To facilitate a clear\nunderstanding, this paper provides a comprehensive survey that organizes\nvarious problem settings using consistent terminology and formal descriptions.\nBy offering an overview of these learning paradigms, our work aims to foster\nfurther advancements in this promising area of research.",
            "author": [
                "Jaehyeon Son",
                "Soochan Lee",
                "Gunhee Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05241v1",
                "http://arxiv.org/pdf/2311.05241v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05221v2",
            "title": "Let's Get the FACS Straight -- Reconstructing Obstructed Facial Features",
            "updated": "2023-11-10T07:38:33Z",
            "published": "2023-11-09T09:09:20Z",
            "summary": "The human face is one of the most crucial parts in interhuman communication.\nEven when parts of the face are hidden or obstructed the underlying facial\nmovements can be understood. Machine learning approaches often fail in that\nregard due to the complexity of the facial structures. To alleviate this\nproblem a common approach is to fine-tune a model for such a specific\napplication. However, this is computational intensive and might have to be\nrepeated for each desired analysis task. In this paper, we propose to\nreconstruct obstructed facial parts to avoid the task of repeated fine-tuning.\nAs a result, existing facial analysis methods can be used without further\nchanges with respect to the data. In our approach, the restoration of facial\nfeatures is interpreted as a style transfer task between different recording\nsetups. By using the CycleGAN architecture the requirement of matched pairs,\nwhich is often hard to fullfill, can be eliminated. To proof the viability of\nour approach, we compare our reconstructions with real unobstructed recordings.\nWe created a novel data set in which 36 test subjects were recorded both with\nand without 62 surface electromyography sensors attached to their faces. In our\nevaluation, we feature typical facial analysis tasks, like the computation of\nFacial Action Units and the detection of emotions. To further assess the\nquality of the restoration, we also compare perceptional distances. We can\nshow, that scores similar to the videos without obstructing sensors can be\nachieved.",
            "author": [
                "Tim B\u00fcchner",
                "Sven Sickert",
                "Gerd Fabian Volk",
                "Christoph Anders",
                "Orlando Guntinas-Lichius",
                "Joachim Denzler"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05221v2",
                "http://arxiv.org/pdf/2311.05221v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05210v1",
            "title": "From \"What\" to \"When\" -- a Spiking Neural Network Predicting Rare Events\n  and Time to their Occurrence",
            "updated": "2023-11-09T08:47:23Z",
            "published": "2023-11-09T08:47:23Z",
            "summary": "In the reinforcement learning (RL) tasks, the ability to predict receiving\nreward in the near or more distant future means the ability to evaluate the\ncurrent state as more or less close to the target state (labelled by the reward\nsignal). In the present work, we utilize a spiking neural network (SNN) to\npredict time to the next target event (reward - in case of RL). In the context\nof SNNs, events are represented as spikes emitted by network neurons or input\nnodes. It is assumed that target events are indicated by spikes emitted by a\nspecial network input node. Using description of the current state encoded in\nthe form of spikes from the other input nodes, the network should predict\napproximate time of the next target event. This research paper presents a novel\napproach to learning the corresponding predictive model by an SNN consisting of\nleaky integrate-and-fire (LIF) neurons. The proposed method leverages specially\ndesigned local synaptic plasticity rules and a novel columnar-layered SNN\narchitecture. Similar to our previous works, this study places a strong\nemphasis on the hardware-friendliness of the proposed models, ensuring their\nefficient implementation on modern and future neuroprocessors. The approach\nproposed was tested on a simple reward prediction task in the context of one of\nthe RL benchmark ATARI games, ping-pong. It was demonstrated that the SNN\ndescribed in this paper gives superior prediction accuracy in comparison with\nprecise machine learning techniques, such as decision tree algorithms and\nconvolutional neural networks.",
            "author": [
                "Mikhail Kiselev"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05210v1",
                "http://arxiv.org/pdf/2311.05210v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05203v1",
            "title": "Whisper in Focus: Enhancing Stuttered Speech Classification with Encoder\n  Layer Optimization",
            "updated": "2023-11-09T08:32:49Z",
            "published": "2023-11-09T08:32:49Z",
            "summary": "In recent years, advancements in the field of speech processing have led to\ncutting-edge deep learning algorithms with immense potential for real-world\napplications. The automated identification of stuttered speech is one of such\napplications that the researchers are addressing by employing deep learning\ntechniques. Recently, researchers have utilized Wav2vec2.0, a speech\nrecognition model to classify disfluency types in stuttered speech. Although\nWav2vec2.0 has shown commendable results, its ability to generalize across all\ndisfluency types is limited. In addition, since its base model uses 12 encoder\nlayers, it is considered a resource-intensive model. Our study unravels the\ncapabilities of Whisper for the classification of disfluency types in stuttered\nspeech. We have made notable contributions in three pivotal areas: enhancing\nthe quality of SEP28-k benchmark dataset, exploration of Whisper for\nclassification, and introducing an efficient encoder layer freezing strategy.\nThe optimized Whisper model has achieved the average F1-score of 0.81, which\nproffers its abilities. This study also unwinds the significance of deeper\nencoder layers in the identification of disfluency types, as the results\ndemonstrate their greater contribution compared to initial layers. This\nresearch represents substantial contributions, shifting the emphasis towards an\nefficient solution, thereby thriving towards prospective innovation.",
            "author": [
                "Huma Ameer",
                "Seemab Latif",
                "Rabia Latif",
                "Sana Mukhtar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05203v1",
                "http://arxiv.org/pdf/2311.05203v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.LG",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05199v1",
            "title": "BrainNetDiff: Generative AI Empowers Brain Network Generation via\n  Multimodal Diffusion Model",
            "updated": "2023-11-09T08:27:12Z",
            "published": "2023-11-09T08:27:12Z",
            "summary": "Brain network analysis has emerged as pivotal method for gaining a deeper\nunderstanding of brain functions and disease mechanisms. Despite the existence\nof various network construction approaches, shortcomings persist in the\nlearning of correlations between structural and functional brain imaging data.\nIn light of this, we introduce a novel method called BrainNetDiff, which\ncombines a multi-head Transformer encoder to extract relevant features from\nfMRI time series and integrates a conditional latent diffusion model for brain\nnetwork generation. Leveraging a conditional prompt and a fusion attention\nmechanism, this method significantly improves the accuracy and stability of\nbrain network generation. To the best of our knowledge, this represents the\nfirst framework that employs diffusion for the fusion of the multimodal brain\nimaging and brain network generation from images to graphs. We validate\napplicability of this framework in the construction of brain network across\nhealthy and neurologically impaired cohorts using the authentic dataset.\nExperimental results vividly demonstrate the significant effectiveness of the\nproposed method across the downstream disease classification tasks. These\nfindings convincingly emphasize the prospective value in the field of brain\nnetwork research, particularly its key significance in neuroimaging analysis\nand disease diagnosis. This research provides a valuable reference for the\nprocessing of multimodal brain imaging data and introduces a novel, efficient\nsolution to the field of neuroimaging.",
            "author": [
                "Yongcheng Zong",
                "Shuqiang Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05199v1",
                "http://arxiv.org/pdf/2311.05199v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05198v1",
            "title": "Adaptive-Labeling for Enhancing Remote Sensing Cloud Understanding",
            "updated": "2023-11-09T08:23:45Z",
            "published": "2023-11-09T08:23:45Z",
            "summary": "Cloud analysis is a critical component of weather and climate science,\nimpacting various sectors like disaster management. However, achieving\nfine-grained cloud analysis, such as cloud segmentation, in remote sensing\nremains challenging due to the inherent difficulties in obtaining accurate\nlabels, leading to significant labeling errors in training data. Existing\nmethods often assume the availability of reliable segmentation annotations,\nlimiting their overall performance. To address this inherent limitation, we\nintroduce an innovative model-agnostic Cloud Adaptive-Labeling (CAL) approach,\nwhich operates iteratively to enhance the quality of training data annotations\nand consequently improve the performance of the learned model. Our methodology\ncommences by training a cloud segmentation model using the original\nannotations. Subsequently, it introduces a trainable pixel intensity threshold\nfor adaptively labeling the cloud training images on the fly. The newly\ngenerated labels are then employed to fine-tune the model. Extensive\nexperiments conducted on multiple standard cloud segmentation benchmarks\ndemonstrate the effectiveness of our approach in significantly boosting the\nperformance of existing segmentation models. Our CAL method establishes new\nstate-of-the-art results when compared to a wide array of existing\nalternatives.",
            "author": [
                "Jay Gala",
                "Sauradip Nag",
                "Huichou Huang",
                "Ruirui Liu",
                "Xiatian Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05198v1",
                "http://arxiv.org/pdf/2311.05198v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05197v2",
            "title": "Deep Learning in Computed Tomography Pulmonary Angiography Imaging: A\n  Dual-Pronged Approach for Pulmonary Embolism Detection",
            "updated": "2023-12-05T08:13:34Z",
            "published": "2023-11-09T08:23:44Z",
            "summary": "The increasing reliance on Computed Tomography Pulmonary Angiography for\nPulmonary Embolism (PE) diagnosis presents challenges and a pressing need for\nimproved diagnostic solutions. The primary objective of this study is to\nleverage deep learning techniques to enhance the Computer Assisted Diagnosis of\nPE. In this study, we propose a classifier-guided detection approach that\neffectively leverages the classifier's probabilistic inference to direct the\ndetection predictions, marking a novel contribution in the domain of automated\nPE diagnosis. Our end-to-end classification framework introduces an\nAttention-Guided Convolutional Neural Network (AG-CNN) that leverages local\ncontext by utilizing an attention mechanism. This approach emulates the\nattention of a human expert by looking at both global appearances and local\nlesion regions before forming a conclusive decision. The classifier achieves a\nnotable AUROC, sensitivity, specificity and F1-score of 0.927, 0.862, 0.879 and\n0.805 respectively on the FUMPE dataset with Inception-v3 backbone\narchitecture. Moreover, AG-CNN outperforms the baseline DenseNet-121 model,\nachieving an 8.1% AUROC gain. While prior studies have primarily focused on PE\ndetection in main arteries, our utilization of state-of-the-art object\ndetection models and ensembling techniques significantly enhances detection\naccuracy for small embolisms in the peripheral arteries. Finally, our proposed\nclassifier-guided detection approach further refines the detection metrics\ncontributing new state-of-the-art to the community: mAP$_{50}$, sensitivity and\nF1-score of 0.846, 0.901 and 0.779 respectively outperforming the former\nbenchmark with a significant 3.7% improvement in mAP$_{50}$. Our research aims\nto elevate PE patient care by integrating AI solutions into clinical workflows,\nhighlighting the potential of human-AI collaboration in medical diagnostics.",
            "author": [
                "Fabiha Bushra",
                "Muhammad E. H. Chowdhury",
                "Rusab Sarmun",
                "Saidul Kabir",
                "Menatalla Said",
                "Sohaib Bassam Zoghoul",
                "Adam Mushtak",
                "Israa Al-Hashimi",
                "Abdulrahman Alqahtani",
                "Anwarul Hasan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05197v2",
                "http://arxiv.org/pdf/2311.05197v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05661v1",
            "title": "Prompt Engineering a Prompt Engineer",
            "updated": "2023-11-09T08:00:32Z",
            "published": "2023-11-09T08:00:32Z",
            "summary": "Prompt engineering is a challenging yet crucial task for optimizing the\nperformance of large language models (LLMs). It requires complex reasoning to\nexamine the model's errors, hypothesize what is missing or misleading in the\ncurrent prompt, and communicate the task with clarity. While recent works\nindicate that LLMs can be meta-prompted to perform automatic prompt\nengineering, their potentials may not be fully untapped due to the lack of\nsufficient guidance to elicit complex reasoning capabilities in LLMs in the\nmeta-prompt. In this work, we investigate the problem of \"prompt engineering a\nprompt engineer\" -- constructing a meta-prompt that more effectively guides\nLLMs to perform automatic prompt engineering. We introduce and analyze key\ncomponents, such as a step-by-step reasoning template and context\nspecification, which lead to improved performance. In addition, inspired by\ncommon optimization concepts such as batch size, step size and momentum, we\nintroduce their verbalized counterparts to the meta-prompt and investigate\ntheir effects. Our final method, named PE2, finds a prompt that outperforms\n\"let's think step by step\" by 6.3% on the MultiArith dataset and 3.1% on the\nGSM8K dataset. To demonstrate its versatility, we apply PE2 to the Instruction\nInduction benchmark, a suite of counterfactual tasks, and a lengthy, real-world\nindustrial prompt. In these settings, PE2 achieves strong performance and\noutperforms prior automatic prompt engineering baselines. Further, we show that\nPE2 makes meaningful and targeted prompt edits, amends erroneous or incomplete\nprompts, and presents non-trivial counterfactual reasoning abilities.",
            "author": [
                "Qinyuan Ye",
                "Maxamed Axmed",
                "Reid Pryzant",
                "Fereshte Khani"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05661v1",
                "http://arxiv.org/pdf/2311.05661v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05188v1",
            "title": "Sound field reconstruction using neural processes with dynamic kernels",
            "updated": "2023-11-09T07:59:03Z",
            "published": "2023-11-09T07:59:03Z",
            "summary": "Accurately representing the sound field with the high spatial resolution is\ncritical for immersive and interactive sound field reproduction technology. To\nminimize experimental effort, data-driven methods have been proposed to\nestimate sound fields from a small number of discrete observations. In\nparticular, kernel-based methods using Gaussian Processes (GPs) with a\ncovariance function to model spatial correlations have been used for sound\nfield reconstruction. However, these methods have limitations due to the fixed\nkernels having limited expressiveness, requiring manual identification of\noptimal kernels for different sound fields. In this work, we propose a new\napproach that parameterizes GPs using a deep neural network based on Neural\nProcesses (NPs) to reconstruct the magnitude of the sound field. This method\nhas the advantage of dynamically learning kernels from simulated data using an\nattention mechanism, allowing for greater flexibility and adaptability to the\nacoustic properties of the sound field. Numerical experiments demonstrate that\nour proposed approach outperforms current methods in reconstructing accuracy,\nproviding a promising alternative for sound field reconstruction.",
            "author": [
                "Zining Liang",
                "Wen Zhang",
                "Thushara D. Abhayapala"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05188v1",
                "http://arxiv.org/pdf/2311.05188v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05185v1",
            "title": "Mixture of Weak & Strong Experts on Graphs",
            "updated": "2023-11-09T07:45:05Z",
            "published": "2023-11-09T07:45:05Z",
            "summary": "Realistic graphs contain both rich self-features of nodes and informative\nstructures of neighborhoods, jointly handled by a GNN in the typical setup. We\npropose to decouple the two modalities by mixture of weak and strong experts\n(Mowst), where the weak expert is a light-weight Multi-layer Perceptron (MLP),\nand the strong expert is an off-the-shelf Graph Neural Network (GNN). To adapt\nthe experts' collaboration to different target nodes, we propose a \"confidence\"\nmechanism based on the dispersion of the weak expert's prediction logits. The\nstrong expert is conditionally activated when either the node's classification\nrelies on neighborhood information, or the weak expert has low model quality.\nWe reveal interesting training dynamics by analyzing the influence of the\nconfidence function on loss: our training algorithm encourages the\nspecialization of each expert by effectively generating soft splitting of the\ngraph. In addition, our \"confidence\" design imposes a desirable bias toward the\nstrong expert to benefit from GNN's better generalization capability. Mowst is\neasy to optimize and achieves strong expressive power, with a computation cost\ncomparable to a single GNN. Empirically, Mowst shows significant accuracy\nimprovement on 6 standard node classification benchmarks (including both\nhomophilous and heterophilous graphs).",
            "author": [
                "Hanqing Zeng",
                "Hanjia Lyu",
                "Diyi Hu",
                "Yinglong Xia",
                "Jiebo Luo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05185v1",
                "http://arxiv.org/pdf/2311.05185v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05171v1",
            "title": "Rethinking Residual Connection in Training Large-Scale Spiking Neural\n  Networks",
            "updated": "2023-11-09T06:48:29Z",
            "published": "2023-11-09T06:48:29Z",
            "summary": "Spiking Neural Network (SNN) is known as the most famous brain-inspired\nmodel, but the non-differentiable spiking mechanism makes it hard to train\nlarge-scale SNNs. To facilitate the training of large-scale SNNs, many training\nmethods are borrowed from Artificial Neural Networks (ANNs), among which deep\nresidual learning is the most commonly used. But the unique features of SNNs\nmake prior intuition built upon ANNs not available for SNNs. Although there are\na few studies that have made some pioneer attempts on the topology of Spiking\nResNet, the advantages of different connections remain unclear. To tackle this\nissue, we analyze the merits and limitations of various residual connections\nand empirically demonstrate our ideas with extensive experiments. Then, based\non our observations, we abstract the best-performing connections into densely\nadditive (DA) connection, extend such a concept to other topologies, and\npropose four architectures for training large-scale SNNs, termed DANet, which\nbrings up to 13.24% accuracy gain on ImageNet. Besides, in order to present a\ndetailed methodology for designing the topology of large-scale SNNs, we further\nconduct in-depth discussions on their applicable scenarios in terms of their\nperformance on various scales of datasets and demonstrate their advantages over\nprior architectures. At a low training expense, our best-performing\nResNet-50/101/152 obtain 73.71%/76.13%/77.22% top-1 accuracy on ImageNet with 4\ntime steps. We believe that this work shall give more insights for future works\nto design the topology of their networks and promote the development of\nlarge-scale SNNs. The code will be publicly available.",
            "author": [
                "Yudong Li",
                "Yunlin Lei",
                "Xu Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05171v1",
                "http://arxiv.org/pdf/2311.05171v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05168v1",
            "title": "FireMatch: A Semi-Supervised Video Fire Detection Network Based on\n  Consistency and Distribution Alignment",
            "updated": "2023-11-09T06:43:53Z",
            "published": "2023-11-09T06:43:53Z",
            "summary": "Deep learning techniques have greatly enhanced the performance of fire\ndetection in videos. However, video-based fire detection models heavily rely on\nlabeled data, and the process of data labeling is particularly costly and\ntime-consuming, especially when dealing with videos. Considering the limited\nquantity of labeled video data, we propose a semi-supervised fire detection\nmodel called FireMatch, which is based on consistency regularization and\nadversarial distribution alignment. Specifically, we first combine consistency\nregularization with pseudo-label. For unlabeled data, we design video data\naugmentation to obtain corresponding weakly augmented and strongly augmented\nsamples. The proposed model predicts weakly augmented samples and retains\npseudo-label above a threshold, while training on strongly augmented samples to\npredict these pseudo-labels for learning more robust feature representations.\nSecondly, we generate video cross-set augmented samples by adversarial\ndistribution alignment to expand the training data and alleviate the decline in\nclassification performance caused by insufficient labeled data. Finally, we\nintroduce a fairness loss to help the model produce diverse predictions for\ninput samples, thereby addressing the issue of high confidence with the\nnon-fire class in fire classification scenarios. The FireMatch achieved an\naccuracy of 76.92% and 91.81% on two real-world fire datasets, respectively.\nThe experimental results demonstrate that the proposed method outperforms the\ncurrent state-of-the-art semi-supervised classification methods.",
            "author": [
                "Qinghua Lin",
                "Zuoyong Li",
                "Kun Zeng",
                "Haoyi Fan",
                "Wei Li",
                "Xiaoguang Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05168v1",
                "http://arxiv.org/pdf/2311.05168v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "http://www.w3.org/2005/Atom",
            "@type": "Entry",
            "@id": "urn:research:http://arxiv.org/abs/2311.05167v1",
            "title": "Perfecting Liquid-State Theories with Machine Intelligence",
            "updated": "2023-11-09T06:43:13Z",
            "published": "2023-11-09T06:43:13Z",
            "summary": "Recent years have seen a significant increase in the use of machine\nintelligence for predicting electronic structure, molecular force fields, and\nthe physicochemical properties of various condensed systems. However,\nsubstantial challenges remain in developing a comprehensive framework capable\nof handling a wide range of atomic compositions and thermodynamic conditions.\nThis perspective discusses potential future developments in liquid-state\ntheories leveraging on recent advancements of functional machine learning. By\nharnessing the strengths of theoretical analysis and machine learning\ntechniques including surrogate models, dimension reduction and uncertainty\nquantification, we envision that liquid-state theories will gain significant\nimprovements in accuracy, scalability and computational efficiency, enabling\ntheir broader applications across diverse materials and chemical systems.",
            "author": [
                "Jianzhong Wu",
                "Mengyang Gu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05167v1",
                "http://arxiv.org/pdf/2311.05167v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph",
                "cond-mat.soft",
                "cs.LG",
                "physics.comp-ph",
                "stat.AP"
            ]
        }
    }
]